text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Training a new generation of computational neuroscientists bridging neurobiology The Training Program in Computational Neuroscience (TPCN) will support integrated undergraduate and graduate training in computational neuroscience at New York University. The program will be hosted by the Center for Neural Science (CNS), with participation of faculty in the Departments of Psychology, Mathematics, and Computer Science, and the Institute of Neuroscience at the School of Medicine. The TPCN will fit well with NYU’s unique strengths and recent developments: (1) NYU is one of a few universities with a critical mass of computational neuroscientists. NYU has had a Sloan-Swartz Center for Theoretical Neuroscience since 1994. In the past three years alone, NYU has hired three computational neuroscientists. (2) CNS established an undergraduate major in neuroscience as early as 1992, and thus has a long track record in undergraduate education, it now has 136 students in the current academic year. (3) Recent faculty hiring in CNS, Psychology, and the School of Medicine has greatly expanded our teaching and research capabilities in the neuroscience of cognitive functions and their impairments associated with mental disorders. (3) As NYU is undertaking a merge of two historically separated neuroscience graduate programs (at CNS and the School of Medicine), this training grant will ensure that computational modeling, which has become indispensible in neuroscience, will be front-and-center in the integrated graduate program. (4) NYU is a major center of Artificial Intelligence and Data Science, with close links to Facebook’s AI Center and the Simons Center for Data Analysis. Our training faculty together with these connections will give our students ample opportunities to acquire machine learning techniques for data analysis and learn about brain-like AI algorithms. The proposed training program will support coherent undergraduate and graduate training in computational neuroscience at NYU. It will have several unique features: (1) Innovative mentorship methods: For example, (a) graduate trainees will mentor undergraduate trainees, (b) faculty will explicitly discuss human factors in academic practice; (c) there will be post-mortems after seminars by outside speakers. (2) Computational psychiatry: We propose new courses and research opportunities that are designed specifically to link cognitive function and the neurobiology of neural circuits. We propose innovative education in the nascent field of Computational Psychiatry, to bring theory and circuit modeling to clinical research in mental health. (3) Broad preparation: We aim to prepare trainees for jobs not only in academia, but also in medical and industry research. To achieve this, we will utilize our strength in machine learning and data science to broaden computational neuroscience training. The Program Directors have complementary strengths and will have complementary roles in the program. Wang will supervise graduate trainees and focus on training in mechanistic/circuit-level side of computational neuroscience as well as computational psychiatry. Ma will supervise undergraduate trainees and focus on the computational/behavioral side. This grant will support training of a new generation of graduate and undergraduate students in  computational neuroscience, which has become increasingly important to meet the challenges of  making discoveries with new data analysis tools and of understanding highly nonlinear complex  neural circuits. A salient component of our program is training in the nascent field  of   Computational  Psychiatry,  bridging  basic  neuroscience  and clinical research on mental  disorders. Therefore, the proposed program has the potential of making  a significant impact on  mental health.",Training a new generation of computational neuroscientists bridging neurobiology,9767751,R90DA043849,"['Academia', 'Algorithms', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Clinical Research', 'Computer Simulation', 'Data Analyses', 'Data Science', 'Development', 'Education', 'Educational process of instructing', 'Ensure', 'Facebook', 'Faculty', 'Generations', 'Grant', 'Human', 'Impairment', 'Industry', 'Institutes', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurosciences', 'New York', 'Occupations', 'Preparation', 'Psychiatry', 'Psychology', 'Research', 'Role', 'Science', 'Side', 'Students', 'Supervision', 'Teacher Professional Development', 'Techniques', 'Training', 'Training Programs', 'Universities', 'cognitive function', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'design', 'innovation', 'mathematical sciences', 'medical schools', 'neural circuit', 'programs', 'relating to nervous system', 'theories', 'undergraduate education', 'undergraduate student']",NIDA,NEW YORK UNIVERSITY,R90,2019,204981,0.03594438421696144
"SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community Physics-based simulations provide a powerful framework for understanding biological form and function. They harmonize heterogeneous experimental data with real-world physical constraints, helping researchers understand biological systems as they engineer novel drugs, new diagnostics, medical devices, and surgical interventions. The rise in new sensors and simulation tools is generating an increasing amount of data, but this data is often inaccessible, preventing reuse and limiting scientific progress. In 2005, we launched SimTK, a website to develop and share biosimulation tools, models, and data, to address these issues. SimTK now supports 62,000+ researchers globally and 950+ projects. Members use it to meet their grants’ data sharing responsibilities; experiment with new ways of collaborating; and build communities around their datasets and tools. However, challenges remain: many researchers still do not share their digital assets due to the time needed to prepare, document, and maintain those assets, and since SimTK hosts a growing number of diverse digital assets, the site now also faces the challenge of making these assets discoverable and reusable. Thus, we propose a plan to extend SimTK and implement new solutions to promote scientific data sharing and reuse. First, we will maintain the reliable, user-friendly foundation upon which SimTK is built, continuing to provide the excellent support our members expect and supporting the site’s existing features for sharing and building communities. Second, we will implement methods to establish a culture of model and data sharing in the biomechanics community. We will encourage researchers to adopt new habits, making sharing part of their workflow, by enabling the software and systems they use to automatically upload models and data to SimTK via an application programming interface (API) and by recruiting leading researchers in the community to serve as beta testers and role models. Third, we will create tools to easily replicate and extend biomechanics simulations. Containers and cloud computing services allow researchers to capture and share a snapshot of their computing environment, enabling unprecedented fidelity in sharing. We will integrate these technologies into SimTK and provide custom, easy-to-use interfaces to replicate and extend simulation studies. Lastly, we will develop a metadata standard for models and data for the biomechanics community, increasing reusability and discoverability of the rich set of resources shared on SimTK. We will use the new standard on SimTK and fill in the metadata fields automatically using natural language processing and machine learning, minimizing the burden and inaccuracies of manual metadata entry. We will evaluate our success in achieving these aims by tracking the number of assets shared and the frequency they are used as a springboard to new research. These changes will accelerate biomechanics research and provide new tools to increase the reusability and impact of shared resources. By lowering barriers to data sharing in the biosimulation community, SimTK will continue to serve as a model for how to create national infrastructure for scientific subdisciplines. SimTK is a vibrant hub for the development and sharing of simulation software, data, and models of biological structures and processes. SimTK-based resources are being used to design medical devices and drugs, to generate new diagnostics, to create surgical interventions, and to provide insights into biology. The proposed enhancements to SimTK will accelerate progress in the field by lowering barriers to and standardizing data and model sharing, thus 1) increasing the quantity and also, importantly, the quality of resources that researchers share and 2) enabling others to reproduce and build on the wealth of past biomechanics research studies.",SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community,9636581,R01GM124443,"['Achievement', 'Address', 'Adopted', 'Biological', 'Biological Models', 'Biology', 'Biomechanics', 'Biophysics', 'Cloud Computing', 'Code', 'Communities', 'Computer software', 'Consumption', 'Custom', 'Data', 'Data Files', 'Data Set', 'Development', 'Documentation', 'Ecosystem', 'Engineering', 'Ensure', 'Environment', 'Explosion', 'Face', 'Foundations', 'Frequencies', 'Goals', 'Grant', 'Habits', 'Infrastructure', 'Letters', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Device', 'Medical Device Designs', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Operative Surgical Procedures', 'Pharmaceutical Preparations', 'Physics', 'Process', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Security', 'Services', 'Site', 'Standardization', 'Structure', 'System', 'Technology', 'Time', 'Update', 'Work', 'application programming interface', 'base', 'biological systems', 'biomechanical model', 'community building', 'complex biological systems', 'data access', 'data sharing', 'digital', 'experience', 'experimental study', 'insight', 'member', 'new technology', 'novel diagnostics', 'novel therapeutics', 'prevent', 'recruit', 'research study', 'response', 'role model', 'sensor', 'simulation', 'simulation software', 'software systems', 'success', 'tool', 'user-friendly', 'web site']",NIGMS,STANFORD UNIVERSITY,R01,2019,489919,0.0013932243045326686
"Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches Project Summary The form (or shape) and function relationship of anatomical structures is a central theme in biology where abnor- mal shape changes are closely tied to pathological functions. Morphometrics has been an indispensable quan- titative tool in medical and biological sciences to study anatomical forms for more than 100 years. Recently, the increased availability of high-resolution in-vivo images of anatomy has led to the development of a new generation of morphometric approaches, called statistical shape modeling (SSM), that take advantage of modern computa- tional techniques to model anatomical shapes and their variability within populations with unprecedented detail. SSM stands to revolutionize morphometric analysis, but its widespread adoption is hindered by a number of sig- niﬁcant challenges, including the complexity of the approaches and their increased computational requirements, relative to traditional morphometrics. Arguably, however, the most important roadblock to more widespread adop- tion is the lack of user-friendly and scalable software tools for a variety of anatomical surfaces that can be readily incorporated into biomedical research labs. The goal of this proposal is thus to address these challenges in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM), which automat- ically constructs optimal statistical landmark-based shape models of ensembles of anatomical shapes without relying on any speciﬁc surface parameterization. The proposed research will provide an automated, general- purpose, and scalable computational solution for constructing shape models of general anatomy. In Aim 1, we will build computational and machine learning algorithms to model anatomies with complex surface topologies (e.g., surface openings and shared boundaries) and highly variable anatomical populations. In Aim 2, we will introduce an end-to-end machine learning approach to extract statistical shape representation directly from im- ages, requiring no parameter tuning, image pre-processing, or user assistance. In Aim 3, we will provide intuitive graphical user interfaces and visualization tools to incorporate user-deﬁned modeling preferences and promote the visual interpretation of shape models. We will also make use of recent advances in cloud computing to enable researchers with limited computational resources and/or large cohorts to build and execute custom SSM work- ﬂows using remote scalable computational resources. Algorithmic developments will be thoroughly evaluated and validated using existing, fully funded, large-scale, and constantly growing databases of CT and MRI images lo- cated on-site. Furthermore, we will develop and disseminate standard workﬂows and domain-speciﬁc use cases for complex anatomies to promote reproducibility. Efforts to develop the proposed technology are aligned with the mission of the National Institute of General Medical Sciences (NIGMS), and its third strategic goal: to bridge biology and quantitative science for better global health through supporting the development of and access to computational research tools for biomedical research. Our long-term goal is to increase the clinical utility and widespread adoption of SSM, and the proposed research will establish the groundwork for achieving this goal. Project Narrative This project will develop general-purpose, scalable, and open-source statistical shape modeling (SSM) tools, which will present unique capabilities for automated anatomy modeling with less user input. The proposed tech- nology will introduce a number of signiﬁcant improvements to current SSM approaches and tools, including the support for challenging modeling problems, inferring shapes directly from images (and hence bypassing the seg- mentation step), parallel optimizations for speed, and new user interfaces that will be much easier and scalable than the current tools. The proposed technology will constitute an indispensable resource for the biomedical and clinical communities that will enable new avenues for biomedical research and clinical investigations, provide new ways to answer biologically related questions, allow new types of questions to be asked, and open the door for the integration of SSM with clinical care.","Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches",9803774,R01AR076120,"['Address', 'Adoption', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomic Surface', 'Anatomy', 'Area', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Brain', 'Bypass', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Collection', 'Communities', 'Complex', 'Complex Analysis', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Felis catus', 'Funding', 'Generations', 'Geometry', 'Goals', 'Human', 'Ice', 'Image', 'Imagery', 'Injury', 'Intuition', 'Laboratory Research', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematical Computing', 'Measures', 'Medical', 'Medicine', 'Mission', 'Modeling', 'Modernization', 'Modification', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Occupations', 'Online Systems', 'Organism', 'Orthopedics', 'Pathologic', 'Population', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Shapes', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Speed', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Variant', 'Visual', 'Visualization software', 'Work', 'base', 'biomedical resource', 'clinical care', 'clinical investigation', 'clinically relevant', 'cohort', 'computerized tools', 'computing resources', 'deep learning', 'experience', 'flexibility', 'global health', 'graphical user interface', 'image archival system', 'image processing', 'imaging Segmentation', 'in vivo imaging', 'innovation', 'machine learning algorithm', 'model development', 'multidisciplinary', 'open source', 'particle', 'preference', 'software development', 'tool', 'usability', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2019,631809,0.002461098314450759
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9706046,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophageal', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'improved', 'in vivo', 'learning strategy', 'lymph nodes', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'random forest', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2019,347834,0.0064977420675960025
"Genomic sequencing to aid diagnosis in pediatric and prenatal practice: Examining clinical utility, ethical implications, payer coverage, and data integration in a diverse population. PROJECT SUMMARY I propose to gain experience in what are becoming the next big topics in genomic medicine – the integration of “big data” using data science in order to achieve “precision health” – what could be summed up as “data science of the future”. These topics emerge from - but go beyond - the narrower concept of “precision medicine” as the use of genetic information for treatment decisions. The goal is to develop experience in data science and precision health so that my work can serve as a bridge between my field of economics and these fields - and begin to prepare for the future challenges as they emerge. PROJECT NARRATIVE Both data science and precision health will be critical components of future health care interventions and impact patients, providers, and society. “Big Data” using data science includes the aggregation and analysis of data across platforms (includes information from, e.g. genetic testing, biosensors, wearables, and electronic health records, with such data analyzed using, e.g. artificial intelligence and machine learning). Precision Health uses a “big data” approach to focus on disease prevention and detection throughout one’s lifetime.","Genomic sequencing to aid diagnosis in pediatric and prenatal practice: Examining clinical utility, ethical implications, payer coverage, and data integration in a diverse population.",9929780,U01HG009599,"['Artificial Intelligence', 'Big Data', 'Biosensor', 'Childhood', 'Clinical', 'Data Analyses', 'Data Science', 'Detection', 'Diagnosis', 'Economics', 'Electronic Health Record', 'Ethics', 'Future', 'Genetic screening method', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Healthcare', 'Intervention', 'Machine Learning', 'Patients', 'Population Heterogeneity', 'Precision Health', 'Provider', 'Societies', 'Source', 'Sum', 'Work', 'data integration', 'disorder prevention', 'experience', 'formal learning', 'genetic information', 'informal learning', 'precision medicine', 'prenatal']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",U01,2019,166973,0.010942649227093471
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,9859232,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Dimensions', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'One-Step dentin bonding system', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2019,345016,-1.5006771319665991e-05
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,9857305,R00HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Infrastructure', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'blockchain', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'comparative effectiveness', 'computer science', 'data sharing', 'design', 'digital', 'effectiveness research', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'learning strategy', 'machine learning algorithm', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'point of care', 'predictive modeling', 'preservation', 'privacy protection', 'programs', 'public trust', 'structural genomics', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R00,2019,249000,0.004927709209659669
"Training the next generation of leaders in biomedical engineering design Project Summary/Abstract The next generation of bioengineering and biomedical researchers will have unprecedented access to technologies including wireless health, big data, genetic sequencing, and machine learning approaches to enable modern diagnostic and therapeutic techniques. This presents individuals trained at the interface of technology and biomedicine with an enormous opportunity to address the world’s needs in health and medicine. In the Bioengineering Department at the University of California, Los Angeles, we aim to develop students into leaders able to seamlessly identify clinical needs that technology can address, design and validate solutions that address these needs, communicate with a variety of stakeholders to build teams invested in problem-oriented solutions, and to navigate the regulatory and commercial pathways necessary to enable their technologies to thrive. The Bioengineering Capstone Series at UCLA leverages resources available at UCLA to enable students to: 1) gain insight into clinical needs directly from clinicians and educators across the Ronald Reagan Medical Center, David Geffen School of Medicine, School of Dentistry and UCLA Health System, 2) design their solutions through mentorship from engineering professors, 3) understand the complexities of the biomedical industry with support from the UCLA Technology Development Group and members of the Department of Engineering Industry Advisory Board, 4) utilize modern technologies in wireless health and data science by collaborating with the Center of Excellence for Mobile Sensor Data- to-Knowledge (MD2K) and Mobile Health (mHealth) Institute at UCLA, and 5) work with the National Science Foundation Precise Advanced Technologies and Health Systems for Underserved Populations Engineering Research Center (NSF PATHS- UP ERC) to learn to target and communicate their technologies to maximize societal benefits. Statement of Public Health Relevance: To prepare the next generation of engineers with skills in the design of therapeutics and medical devices, this research education program will provide bioengineering students at UCLA with enhanced opportunities to engage in real world design for biomedical applications. We will guide students through the medical design process from identifying needs, creating solutions which address these needs, and communicating the significance of their contributions to the greater community, ultimately yielding a larger pool of well-trained engineers to address biomedical challenges. !",Training the next generation of leaders in biomedical engineering design,9709138,R25EB027626,"['Address', 'Applied Research', 'Area', 'Big Data', 'Biomedical Engineering', 'Biomedical Technology', 'California', 'Clinic', 'Clinical', 'Communication', 'Communities', 'Data', 'Data Science', 'Device or Instrument Development', 'Devices', 'Diagnostic', 'Educational workshop', 'Engineering', 'Event', 'Faculty', 'Fostering', 'Foundations', 'Freedom', 'Future', 'Genetic', 'Goals', 'Health', 'Health Sciences', 'Health Technology', 'Health system', 'Healthcare', 'High School Student', 'Home environment', 'Individual', 'Industry', 'Infrastructure', 'Institutes', 'Instruction', 'Intellectual Property', 'Investments', 'Laboratories', 'Learning', 'Los Angeles', 'Machine Learning', 'Medical', 'Medical Device', 'Medical center', 'Medicine', 'Mentorship', 'Modernization', 'Pathway interactions', 'Patient Monitoring', 'Physiological', 'Process', 'Recommendation', 'Regulation', 'Research', 'Research Personnel', 'Resources', 'STEM field', 'School Dentistry', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Series', 'Societies', 'Structure', 'Students', 'System', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Training', 'Translations', 'Travel', 'Underrepresented Students', 'Underserved Population', 'Universities', 'Wireless Technology', 'Work', 'base', 'career', 'clinically actionable', 'cloud based', 'commercialization', 'data to knowledge', 'deep learning', 'design', 'education research', 'engineering design', 'experience', 'insight', 'interest', 'lectures', 'mHealth', 'medical schools', 'member', 'multidisciplinary', 'next generation', 'outreach', 'product development', 'professor', 'programs', 'public health relevance', 'sensor', 'skills', 'technology development', 'undergraduate student']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R25,2019,21600,0.012570940406218771
"INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE Project Summary  To understand the many disorders of the brain it is necessary to grapple with its complexity.  Increasingly large and complicated data sets are being collected, but the tools for analyzing and  modeling the data are not yet available. More researchers trained in computational neuroscience are  desperately needed. This project supports graduate and undergraduate training programs in  computational neuroscience (TPCN) at both Carnegie Mellon University (CMU) and the University of  Pittsburgh (Pitt), and a summer school in computational neuroscience for undergraduates, which are  available to students coming from colleges and universities throughout the United States.  The CMU-Pitt TPCN has 16 training faculty in computational neuroscience, 22 training faculty whose  laboratories are primarily experimental, and 20 training faculty whose laboratories are both  computational and experimental. At the graduate level the TPCN offers a PhD program in Neural  Computation (PNC) and joint PhD programs with CMU’s Department of Statistics (PNC-Stat) and its  Machine Learning Department (PNC- MLD), all set within a highly collegial, cross-disciplinary  environment of our Center for the Neural Basis of Cognition (CNBC), which is operated jointly by  CMU and Pitt. The CNBC was established in 1994 to foster interdisciplinary research on the neural  mechanisms of brain function, and now comprises 145 faculty having appointments in 22 departments.  At the undergraduate level a substantial pool of local students is supplemented during the summer  by a cohort of students from across the country. During this renewal funding period the project is  strengthening the role of statistics and machine learning throughout the training programs; (2) revising the summer undergraduate program by creating a didactic two-week “boot camp” at the  beginning, which includes a 20-lecture overview of computational neuroscience; (3) creating online  materials, in conjunction with the boot camp, that will serve not only our own students but also  the greater world of training in computational neuroscience; and (4) enhancing our minority  recruitment by (a) taking advantage of the boot camp and online materials, as well as making  promotional visits to targeted campuses, and (b) creating and running a one-year “bridge” program  to better prepare under-represented minorities for PhD programs.  TPCN trainees work in vertically integrated, cross-disciplinary research teams. Graduate students  take a year- long course in computational neuroscience that bridges modeling and modern statistical  machine learning approaches to neuroscience. To ensure their competency in core neuroscience  principles they also take courses in cognitive neuroscience, neurophysiology, and systems  neuroscience. They then pursue depth in a relevant quantitative discipline, such as computer  science, engineering, mathematics, or statistics. Graduate students have extended experience in at  least one experimental laboratory, and they take part in journal clubs and seminars within the  large Pittsburgh neuroscience community. Year-long undergraduates take courses in mathematics,  computer programming, statistics, and neuroscience; they take an additional course in neuroscience  or psychology and a course in computational neuroscience; and they complete a year-long research  project. In addition, they complete the TPCN summer program. Undergraduate trainees in the summer  program go through the boot camp on topics in computational neuroscience, including tutorials in  Matlab, statistical methods, fundamentals of differential equations, and ideas of neural coding;  they then complete a research project under careful guidance. All trainees will receive training in  responsible conduct of research. Across 5 years of funding, the TPCN supports 20 NRSA graduate  students, 10 non-NRSA graduate students, 30 undergraduate year-long fellows, and 60 undergraduate  summer fellows. Project Narrative  Research in neuroscience is crucial for attacking the causes of neurological and mental health  disorders. If the field of neuroscience is to continue its rapid advance, neuroscientists must use,  understand, and develop new technologies, acquire and analyze ever larger data sets, and grapple  more directly with the complexity of neurobiological systems. The primary goal of these training  programs will be to help train a new generation of interdisciplinary neuroscientists with strong  quantitative skills.",INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE,9763514,R90DA023426,"['Appointment', 'Brain', 'Brain Diseases', 'Code', 'Cognition', 'Communities', 'Competence', 'Country', 'Data Set', 'Differential Equation', 'Discipline', 'Doctor of Philosophy', 'Educational Status', 'Engineering', 'Ensure', 'Environment', 'Faculty', 'Fostering', 'Funding', 'Interdisciplinary Study', 'Joints', 'Journals', 'Laboratories', 'Machine Learning', 'Mathematics', 'Minority Recruitment', 'Modeling', 'Modernization', 'National Research Service Awards', 'Neurosciences', 'Psychology', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Running', 'Schools', 'Statistical Methods', 'Students', 'System', 'Teacher Professional Development', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States', 'Universities', 'Visit', 'Work', 'bridge program', 'cognitive neuroscience', 'cohort', 'college', 'computational neuroscience', 'computer program', 'computer science', 'data modeling', 'experience', 'graduate student', 'lectures', 'neuromechanism', 'neurophysiology', 'programs', 'relating to nervous system', 'responsible research conduct', 'statistics', 'summer program', 'tool', 'undergraduate student']",NIDA,CARNEGIE-MELLON UNIVERSITY,R90,2019,305372,0.03394526838430016
"Transforming Analytical Learning in the Era of Big Data PROJECT SUMMARY In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio)statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field of health big data. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offers and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will primarily draw from the expertise and experience of faculty from three different departments within three different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science, Medicine, Population Health, Social and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including statistical modeling, data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high- dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and medical imaging. The diseases and conditions they study include obesity, diabetes, cardiovascular disease, cancer, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and success with the current summer program on Big Data led by this team with 164 students trained in the last 4 years (2015-2018) including 90 female students and 30 students from underrepresented minority groups. Fourteen of these participants from the last three years are currently graduate students in Michigan Biostatistics. The ongoing program has gained traction in the national landscape of summer research programs with 20% rate of admission and 80% rate of acceptance among those who are offered this opportunity. The program has consistently received very strong evaluation and our past alumni have become brand ambassadors and advocates for our program. We plan to build on the success and legacy of this program in the next three year funding cycle of this grant (2019-2021). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 45 undergraduates nationally and internationally, with 20 domestic students supported by the requested SIBS funding mechanism and others supported by supplementary institutional and foundation support. We propose to expose the trainees to diverse techniques, skills and problems in the field of health Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. They will engage in mentored research projects in three primary areas of health big data: Electronic Health Records/Medical Claims, Genomics and Imaging. Some of the projects will be defined in the area of cardiovascular precision medicine, defined by a team of highly quantitative researchers engaged in cardiovascular research that uses big data. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by U-M researchers, outside guests and a professional development workshop to prepare the students for graduate school. We propose an inter-SIBS collaboration with Dordt College summer program trainees who will attend this concluding symposium. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world. We will offer multiple professional development opportunities and resources for graduate school preparation to our trainees so that they can reflect and plan beyond their senior year. All of our proposed activities are reflected through our three specific aims: Teaching, Mentoring and Dissemination. PROJECT NARRATIVE We propose a six week long undergraduate summer institute: “Transforming Analytical Learning in the Era of Big Data” to be held at the Department of Biostatistics, University of Michigan (U-M), Ann Arbor, with a group of approximately 45 undergraduate students recruited nationally and internationally, from 2019-2021. Funding is requested for 20 domestic students with supplementary funding expected to be garnered through institutional resources and private foundation support. The program builds on the success of our existing Big Data Summer Institute (BDSI) supported by a NIH BD2K Courses and Skills grant award that is ending in 2018. We plan to expose program students to diverse techniques, skills and problems in the field of Big Data and Human Health. We enhance our ongoing summer program structure in the current proposal by involving a team of researchers working at the intersection of cardiovascular research and data science with a focus on cardiovascular precision medicine where some of the new mentored research projects will be defined. We primarily focus on three genres of health Big Data arising in Electronic Health Records/Medical Claims, Genomics and Imaging. The trainees will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Computational Medicine and Bioinformatics, Statistics, Computer Science and Engineering, Information Sciences, Epidemiology and Medicine, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by (U-M) researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm and engage them in influential research related to human health.",Transforming Analytical Learning in the Era of Big Data,9733542,R25HL147207,"['Admission activity', 'Adverse drug effect', 'Advocate', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Award', 'Basic Science', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Sciences', 'Code', 'Collaborations', 'Collection', 'Computing Methodologies', 'Data', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Epidemiology', 'Epigenetic Process', 'Evaluation', 'Exposure to', 'Faculty', 'Female', 'Foundations', 'Funding', 'Funding Mechanisms', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Human', 'Image', 'Influentials', 'Information Sciences', 'Injury', 'International', 'Kidney Diseases', 'Learning', 'Literature', 'Machine Learning', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Medical Imaging', 'Medical Records', 'Medicine', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Minority Groups', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Prevention', 'Privatization', 'Problem Sets', 'Public Health Informatics', 'Public Health Schools', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'STEM program', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Social Behavior', 'Social Sciences', 'Statistical Methods', 'Statistical Models', 'Structure', 'Student recruitment', 'Students', 'Talents', 'Techniques', 'Traction', 'Training', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Woman', 'Work', 'base', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'data visualization', 'design', 'experience', 'graduate school preparation', 'graduate student', 'high dimensionality', 'instructor', 'interest', 'lectures', 'medical schools', 'member', 'metabolomics', 'nervous system disorder', 'network models', 'next generation', 'novel therapeutics', 'open source', 'personalized medicine', 'population health', 'posters', 'precision medicine', 'programs', 'recruit', 'signal processing', 'skills', 'statistics', 'student training', 'success', 'summer institute', 'summer program', 'summer research', 'symposium', 'tool', 'undergraduate student', 'underrepresented minority student', 'wiki']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2019,250974,0.06034460722122381
"Technology-supported training and quality assurance for psychosocial interventions Millions of Americans receive psychosocial interventions such as psychotherapy each year for treatment of mental health, behavioral health, and addiction problems. Evidence-based psychotherapies such as cognitive-behavioral therapy (CBT) are increasingly emphasized in professional practice guidelines, taught in training programs, sought out by consumers, and valued by payers. Yet, at present, there is no scalable method for evaluating the quality of psychotherapy services. In research settings, human-based behavioral coding methods are used, but these are time consuming, costly, and rarely used in real-world clinical settings.  Psychotherapy is a “talk based” treatment, and as such, the active ingredients and quality of the therapy are found in the spoken language and interaction of clinician and client. The current proposal will develop a software system (CORE-CBT) that will automatically generate a summary report of quality metrics for CBT, from an audio recording of a CBT session, using speech signal processing and machine learning. Importantly, the current work builds from previous, successful work in developing CORE-MI, an automated system for evaluating motivational interviewing for addiction. The existing CORE-MI tool and the expertise gained through its development will serve as the foundation for the current proposal.  Our technical team is complemented by clinical and implementation expertise via the partnership of the Beck Community Initiative (BCI) with Philadelphia’s DBHIDS. Since 2007, BCI has partnered in training staff at 60 programs in the DBHIDS network to deliver high-quality CBT, including objective quality ratings via the Cognitive Therapy Rating Scale (CTRS). Through ongoing training efforts, the BCI has generated an archive of over 6,500 recorded CBT sessions, of which more than 2,300 have been CTRS-coded for quality. This session archive and ongoing real-world trainings in the DBHIDS network provide the perfect context to develop CORE-CBT, a tool that automates quality coding for CBT.  Aim 1: ​Extend and evaluate machine learning algorithms to automatically code CBT competence, using an archive of more than 2,000 CBT fidelity-coded sessions. ​Aim 2: ​Adapt and enhance front-end user interface and session reports with key stakeholders (frontline clinicians, supervisors, and clinic administrators), evaluating acceptability, appropriateness, and feasibility. ​Aim 3: ​Evaluate CORE-CBT technology during CBT training in 4 BCI partner clinics in the DBHIDS network, with approximately 48-64 frontline clinicians and 4,000 sessions, assessing both implementation outcomes (adoption, sustainment) and service outcomes (increased capacity, efficiency, and effectiveness of training). ​Aim 4:​ Evaluate the appropriateness of CORE-CBT and its metrics for quality assurance (clinics) and value-based reimbursement (payers), using an in-person participatory design workshop. An advisory board of behavioral health payers will provide feedback over the course of the study to maximize generalizability and future uptake in large healthcare systems. PROJECT NARRATIVE Evidence-based psychotherapies such as cognitive-behavioral therapy (CBT) are increasingly emphasized in professional practice guidelines, taught in training programs, sought out by consumers, and valued by payers. Yet, at present, there is no scalable method for evaluating the quality of psychotherapy services. The current study will develop and evaluate a clinical support software tool (CORE-CBT) that uses speech signal processing and machine learning to automate and scale up the evaluation of quality in CBT.",Technology-supported training and quality assurance for psychosocial interventions,9829235,R56MH118550,"['Administrator', 'Adoption', 'Adult', 'Alcohol or Other Drugs use', 'Alcohols', 'American', 'Archives', 'Behavioral', 'Case Study', 'Client', 'Client satisfaction', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Cognitive Therapy', 'Communities', 'Competence', 'Complement', 'Computer software', 'Consumption', 'Data', 'Development', 'Documentation', 'Educational workshop', 'Effectiveness', 'Evaluation', 'Evidence based practice', 'Feedback', 'Foundations', 'Future', 'Gold', 'Health Personnel', 'Health Services Research', 'Healthcare Systems', 'Human', 'Intellectual functioning disability', 'Intervention', 'Language', 'Machine Learning', 'Major Depressive Disorder', 'Measurement', 'Measures', 'Mental Health', 'Mental Health Services', 'Mental disorders', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Outpatients', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Philadelphia', 'Practice Guidelines', 'Professional Practice', 'Professional counselor', 'Provider', 'Psychotherapy', 'Reporting', 'Research', 'Research Methodology', 'Self-Help Devices', 'Services', 'Software Tools', 'Speech', 'Standardization', 'Summary Reports', 'Supervision', 'System', 'Technology', 'Time', 'Training', 'Training Programs', 'Training Support', 'Veterans', 'Vision', 'Work', 'addiction', 'base', 'behavioral health', 'clinical implementation', 'cloud based', 'community setting', 'cost', 'design', 'effectiveness research', 'evidence base', 'innovation', 'machine learning algorithm', 'motivational enhancement therapy', 'programs', 'psychosocial', 'quality assurance', 'scale up', 'signal processing', 'software systems', 'support tools', 'tool', 'uptake', 'user centered design', 'virtual', 'visual feedback', 'years lived with disability']",NIMH,UNIVERSITY OF PENNSYLVANIA,R56,2019,831604,-0.018943211335147096
"Big Omics Data Engine 2 Supercomputer Computational and data science has transformed biomedical scientific discovery: its approaches are embedded into a wide range of workflows for diseases such as schizophrenia, depression, Alzheimer's, epilepsy, influenza, autism, drug addiction, pediatric cardiac care, Inflammatory Bowel Disease, prostate cancer and multiple myleloma. Sixty-one basic and translational researchers at Mount Sinai representing over $100 million in NIH funding, along with their collaborators from 75 external institutions, have utilized the Big Omics Data Engine (BODE) supercomputer to elucidate significant scientific findings in over 167 publications, including high impact journals such as Nature and Science, with 2,427 citations in three years. These researchers have also shared the data generated on BODE throughout their consortia and into national data sharing repositories. BODE is nearing the end of its vendor maintainable life, and researchers need increased computational throughput and storage space. To empower researchers to not only continue their inquiries, but to also tackle more complex scientific questions with decreased time to solution, we propose the Big Omics Data Engine 2 Supercomputer (BODE2). BODE2 will contain a total of 3,200 Intel Cascade Lake cores with 15 terabytes of memory and 14 petabytes of raw storage, and will leverage an existing 250 terabytes of SSDs. An instrument of this size is not available elsewhere affordably. With the proposed instrument, researchers will be able to take advantage of three major benefits: (1) the ability to receive results faster for overall greater scientific throughput; (2) the ability to increase the fidelity of their simulations and analyses; and (3) the ability to migrate research applications seamlessly to the software environment for greater scientific productivity. As with data produced on BODE, BODE2 data products will also be shared with the broader scientific community. BODE2 will provide the critical infrastructure needed by the wide range of researchers and clinicians for the genetics and population analysis, gene expression, machine learning and structural and chemical biology approaches used to make advances in these diseases. A specialized Big Omics Data Engine 2 Supercomputer instrument will provide necessary computational and data science infrastructure for 61 research projects with 75 collaborating institutions in diverse areas such as Alzheimer's, autism, schizophrenia, drug addiction, influenza, pediatric cardiac care, depression, epilepsy, prostate cancer and multiple myeloma. Data generated from this instrument will be shared in national databases.",Big Omics Data Engine 2 Supercomputer,9708160,S10OD026880,"['Alzheimer&apos', 's Disease', 'Biology', 'Cardiac', 'Caring', 'Chemicals', 'Childhood', 'Communities', 'Complex', 'Computational Science', 'Computer software', 'Data', 'Data Science', 'Disease', 'Drug Addiction', 'Environment', 'Epilepsy', 'Funding', 'Gene Expression', 'Inflammatory Bowel Diseases', 'Influenza', 'Infrastructure', 'Institution', 'Journals', 'Life', 'Machine Learning', 'Malignant neoplasm of prostate', 'Memory', 'Mental Depression', 'Nature', 'Population Analysis', 'Productivity', 'Publications', 'Research', 'Research Personnel', 'Schizophrenia', 'Science', 'Structure', 'Time', 'United States National Institutes of Health', 'Vendor', 'autism spectrum disorder', 'data sharing', 'genetic analysis', 'instrument', 'petabyte', 'repository', 'simulation', 'supercomputer', 'terabyte', 'translational scientist']",OD,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,S10,2019,1998264,-0.028948452968925592
"HERCULES: Exposome Research Center PROJECT SUMMARY: HERCULES The vision of the HERCULES P30 is to demonstrably advance the role of environmental health sciences in clinical and public health settings using the platform of the exposome. Healthcare and biomedical research have become increasingly genome-centric. While much of this is due to the impressive achievements in genomics, which have consistently outpaced gains in environmental health, it is our contention that a more persuasive case needs to be made for environmental factors. Science and intuition support the idea that the environment plays just as large of a role as genetics for the majority of diseases. The exposome, which embraces a strategy and scale similar to genomic research, is poised to elevate the environment in discussions of health and disease. We will continue to grow and enhance the environmental health science research portfolio at Emory through cutting-edge technologies and innovative data solutions. We will build upon the superb relationships we have built with the local community and continue to push the mission of NIEHS on campus and across the scientific landscape. Based on the extraordinary progress over our first three years, we propose to retain our theme to use exposome-related concepts and approaches to improve human health. This simple and unifying vision will continue to stimulate discovery, promote collaboration, and enhance communication through the following Specific Aims: Specific Aim 1. To marshal physical and intellectual resources to support exposome-related approaches (high-resolution metabolomics, analytical chemistry, systems biology, machine learning, bioinformatics, high-throughput toxicology, and spatial and temporal statistical models) through cores, pilot funding, mentoring, and research forums. Specific Aim 2. To make major contributions towards exposome and environmental health science research. Specific Aim 3. To provide career development activities around innovative and emerging concepts and approaches related to the exposome. Specific Aim 4. To enhance and expand existing relationships with community partners to resolve environmental health issues in the community using exposome principles. Specific Aim 5. To provide infrastructure and resources to facilitate rapid translation of novel scientific findings into the development of prevention and treatment strategies in humans. Pursuit of HERCULES' aims will advance environmental health sciences within our institutions and in the scientific community. PROJECT NARRATIVE: HERCULES Human health and disease is dictated by a combination of genetic and environmental factors. The HERCULES Center is focused on providing a more comprehensive assessment of these environmental influences by utilizing exposome-based concepts and approaches.",HERCULES: Exposome Research Center,9672444,P30ES019776,"['Achievement', 'Analytical Chemistry', 'Award', 'Bioinformatics', 'Biomedical Research', 'Climate', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Community Outreach', 'Core Facility', 'Data', 'Data Science', 'Development', 'Discipline', 'Disease', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Care Research', 'Health Sciences', 'Human', 'Individual', 'Infrastructure', 'Institution', 'Intuition', 'Leadership', 'Letters', 'Machine Learning', 'Marshal', 'Mentors', 'Mission', 'National Institute of Environmental Health Sciences', 'Phase', 'Play', 'Prevention strategy', 'Productivity', 'Public Health', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Statistical Models', 'Strategic Planning', 'Systems Biology', 'Technology', 'Toxicology', 'Translations', 'Update', 'Vision', 'base', 'career development', 'catalyst', 'health science research', 'improved', 'innovation', 'metabolomics', 'novel', 'operation', 'ranpirnase', 'treatment strategy']",NIEHS,EMORY UNIVERSITY,P30,2019,1515934,0.01771188660310311
"HERCULES: Exposome Research Center PROJECT SUMMARY: HERCULES The vision of the HERCULES P30 is to demonstrably advance the role of environmental health sciences in clinical and public health settings using the platform of the exposome. Healthcare and biomedical research have become increasingly genome-centric. While much of this is due to the impressive achievements in genomics, which have consistently outpaced gains in environmental health, it is our contention that a more persuasive case needs to be made for environmental factors. Science and intuition support the idea that the environment plays just as large of a role as genetics for the majority of diseases. The exposome, which embraces a strategy and scale similar to genomic research, is poised to elevate the environment in discussions of health and disease. We will continue to grow and enhance the environmental health science research portfolio at Emory through cutting-edge technologies and innovative data solutions. We will build upon the superb relationships we have built with the local community and continue to push the mission of NIEHS on campus and across the scientific landscape. Based on the extraordinary progress over our first three years, we propose to retain our theme to use exposome-related concepts and approaches to improve human health. This simple and unifying vision will continue to stimulate discovery, promote collaboration, and enhance communication through the following Specific Aims: Specific Aim 1. To marshal physical and intellectual resources to support exposome-related approaches (high-resolution metabolomics, analytical chemistry, systems biology, machine learning, bioinformatics, high-throughput toxicology, and spatial and temporal statistical models) through cores, pilot funding, mentoring, and research forums. Specific Aim 2. To make major contributions towards exposome and environmental health science research. Specific Aim 3. To provide career development activities around innovative and emerging concepts and approaches related to the exposome. Specific Aim 4. To enhance and expand existing relationships with community partners to resolve environmental health issues in the community using exposome principles. Specific Aim 5. To provide infrastructure and resources to facilitate rapid translation of novel scientific findings into the development of prevention and treatment strategies in humans. Pursuit of HERCULES' aims will advance environmental health sciences within our institutions and in the scientific community. PROJECT NARRATIVE: HERCULES Human health and disease is dictated by a combination of genetic and environmental factors. The HERCULES Center is focused on providing a more comprehensive assessment of these environmental influences by utilizing exposome-based concepts and approaches.",HERCULES: Exposome Research Center,10012073,P30ES019776,"['Achievement', 'Analytical Chemistry', 'Award', 'Bioinformatics', 'Biomedical Research', 'Climate', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Community Outreach', 'Core Facility', 'Data', 'Data Science', 'Development', 'Discipline', 'Disease', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Care Research', 'Health Sciences', 'Human', 'Individual', 'Infrastructure', 'Institution', 'Intuition', 'Leadership', 'Letters', 'Machine Learning', 'Marshal', 'Mentors', 'Mission', 'National Institute of Environmental Health Sciences', 'Phase', 'Play', 'Prevention strategy', 'Productivity', 'Public Health', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Statistical Models', 'Strategic Planning', 'Systems Biology', 'Technology', 'Toxicology', 'Translations', 'Update', 'Vision', 'base', 'career development', 'catalyst', 'health science research', 'improved', 'innovation', 'metabolomics', 'novel', 'operation', 'ranpirnase', 'treatment strategy']",NIEHS,EMORY UNIVERSITY,P30,2019,77975,0.01771188660310311
"Intelligent deployment of containerized bioinformatics workflows on the cloud PROJECT SUMMARY Cloud computing has emerged as a promising solution to address the challenges of big data. Public cloud vendors provide computing as-a-utility enabling users to pay only for the resources that are actually used. In this application, we will develop methods and tools to enable biomedical researchers to optimize the costs of cloud computing when analyzing biomedical big data. Infrastructure-as-a-Service (IaaS) cloud provides computing as a utility, on-demand, to end users, enabling cloud resources to be rapidly provisioned and scaled to meet computational and performance requirements. In addition, dynamic intelligent allocation of cloud computing resources has great potential to both improve performance and reduce hosting costs. Unfortunately, determining the most cost-effective and efficient ways to deploy modules on the cloud is non- trivial, due to a plethora of cloud vendors, each providing different types of virtual machines with different capabilities, performance trade-offs, and pricing structures. In addition, modern bioinformatics workflows consist of multiple modules, applications and libraries, each with their own set of software dependencies. Software containers package binary executables and scripts into modules with their software dependencies. With containers that compartmentalize software dependencies, modules implemented as containers can be mixed and matched to create workflows that give identical results on any platform. The high degree of reproducibility and flexibility of software containers makes them ideal instruments for disseminating complex bioinformatics workflows. Our overarching goal is to deliver the latest technological advances in containers and cloud computing to a typical biomedical researcher with limited resources who works with big data. Specifically, we will develop a user-friendly drag-and-drop interface to enable biomedical researchers to build and edit containerized workflows. Most importantly, users can choose to deploy and scale selected modules in the workflow on cloud computing platforms in a transparent, yet guided fashion, to optimize cost and performance. Our aim is to provide a federated approach that leverages resources from multiple cloud vendors. We have assembled a team of interdisciplinary scientists with expertise in bioinformatics, cloud and distributed computing, and machine learning. As part of this application, we will work closely with end users who routinely generate and analyze RNA-seq data. We will illustrate how our containerized, cloud-enabled methods and tools will benefit bioinformatics analyses. Project Narrative Cloud computing has emerged as a promising solution to address the challenge of analyzing diverse and massive data generated to advance our understanding of health and diseases. We will develop methods and tools to build and intelligently deploy modular and cloud-enabled bioinformatics workflows. These tools will allow the biomedical community to optimize the costs associated with cloud computing and to facilitate the replication of scientific results.",Intelligent deployment of containerized bioinformatics workflows on the cloud,9827788,R01GM126019,"['Address', 'Big Data', 'Bioinformatics', 'Case Study', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Dependence', 'Development', 'Disease', 'Docking', 'Documentation', 'Drops', 'Drug toxicity', 'Educational Materials', 'Ensure', 'Feedback', 'Generations', 'Goals', 'Health', 'Hospitals', 'Image', 'Infrastructure', 'Intelligence', 'Libraries', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Performance', 'Price', 'Privatization', 'RNA analysis', 'Reproducibility', 'Research Personnel', 'Resources', 'Schedule', 'Scientist', 'Services', 'Software Tools', 'Structure', 'Technical Expertise', 'Technology Transfer', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'cloud platform', 'cluster computing', 'computational platform', 'computing resources', 'cost', 'cost effective', 'distributed data', 'expectation', 'flexibility', 'graphical user interface', 'improved', 'instrument', 'outreach', 'predictive modeling', 'prototype', 'tool', 'tool development', 'transcriptome sequencing', 'user-friendly', 'virtual', 'web site']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2019,33190,0.005783599197093029
"Intelligent deployment of containerized bioinformatics workflows on the cloud PROJECT SUMMARY Cloud computing has emerged as a promising solution to address the challenges of big data. Public cloud vendors provide computing as-a-utility enabling users to pay only for the resources that are actually used. In this application, we will develop methods and tools to enable biomedical researchers to optimize the costs of cloud computing when analyzing biomedical big data. Infrastructure-as-a-Service (IaaS) cloud provides computing as a utility, on-demand, to end users, enabling cloud resources to be rapidly provisioned and scaled to meet computational and performance requirements. In addition, dynamic intelligent allocation of cloud computing resources has great potential to both improve performance and reduce hosting costs. Unfortunately, determining the most cost-effective and efficient ways to deploy modules on the cloud is non- trivial, due to a plethora of cloud vendors, each providing different types of virtual machines with different capabilities, performance trade-offs, and pricing structures. In addition, modern bioinformatics workflows consist of multiple modules, applications and libraries, each with their own set of software dependencies. Software containers package binary executables and scripts into modules with their software dependencies. With containers that compartmentalize software dependencies, modules implemented as containers can be mixed and matched to create workflows that give identical results on any platform. The high degree of reproducibility and flexibility of software containers makes them ideal instruments for disseminating complex bioinformatics workflows. Our overarching goal is to deliver the latest technological advances in containers and cloud computing to a typical biomedical researcher with limited resources who works with big data. Specifically, we will develop a user-friendly drag-and-drop interface to enable biomedical researchers to build and edit containerized workflows. Most importantly, users can choose to deploy and scale selected modules in the workflow on cloud computing platforms in a transparent, yet guided fashion, to optimize cost and performance. Our aim is to provide a federated approach that leverages resources from multiple cloud vendors. We have assembled a team of interdisciplinary scientists with expertise in bioinformatics, cloud and distributed computing, and machine learning. As part of this application, we will work closely with end users who routinely generate and analyze RNA-seq data. We will illustrate how our containerized, cloud-enabled methods and tools will benefit bioinformatics analyses. Project Narrative Cloud computing has emerged as a promising solution to address the challenge of analyzing diverse and massive data generated to advance our understanding of health and diseases. We will develop methods and tools to build and intelligently deploy modular and cloud-enabled bioinformatics workflows. These tools will allow the biomedical community to optimize the costs associated with cloud computing and to facilitate the replication of scientific results.",Intelligent deployment of containerized bioinformatics workflows on the cloud,9693030,R01GM126019,"['Address', 'Big Data', 'Bioinformatics', 'Case Study', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Dependence', 'Development', 'Disease', 'Docking', 'Documentation', 'Drops', 'Drug toxicity', 'Educational Materials', 'Ensure', 'Feedback', 'Generations', 'Goals', 'Health', 'Hospitals', 'Image', 'Infrastructure', 'Intelligence', 'Libraries', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Performance', 'Price', 'Privatization', 'RNA analysis', 'Reproducibility', 'Research Personnel', 'Resources', 'Schedule', 'Scientist', 'Services', 'Software Tools', 'Structure', 'Technical Expertise', 'Technology Transfer', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'cloud platform', 'cluster computing', 'computational platform', 'computing resources', 'cost', 'cost effective', 'distributed data', 'expectation', 'flexibility', 'graphical user interface', 'improved', 'instrument', 'outreach', 'predictive modeling', 'prototype', 'tool', 'tool development', 'transcriptome sequencing', 'user-friendly', 'virtual', 'web site']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2019,36510,0.005783599197093029
"Intelligent deployment of containerized bioinformatics workflows on the cloud PROJECT SUMMARY Cloud computing has emerged as a promising solution to address the challenges of big data. Public cloud vendors provide computing as-a-utility enabling users to pay only for the resources that are actually used. In this application, we will develop methods and tools to enable biomedical researchers to optimize the costs of cloud computing when analyzing biomedical big data. Infrastructure-as-a-Service (IaaS) cloud provides computing as a utility, on-demand, to end users, enabling cloud resources to be rapidly provisioned and scaled to meet computational and performance requirements. In addition, dynamic intelligent allocation of cloud computing resources has great potential to both improve performance and reduce hosting costs. Unfortunately, determining the most cost-effective and efficient ways to deploy modules on the cloud is non- trivial, due to a plethora of cloud vendors, each providing different types of virtual machines with different capabilities, performance trade-offs, and pricing structures. In addition, modern bioinformatics workflows consist of multiple modules, applications and libraries, each with their own set of software dependencies. Software containers package binary executables and scripts into modules with their software dependencies. With containers that compartmentalize software dependencies, modules implemented as containers can be mixed and matched to create workflows that give identical results on any platform. The high degree of reproducibility and flexibility of software containers makes them ideal instruments for disseminating complex bioinformatics workflows. Our overarching goal is to deliver the latest technological advances in containers and cloud computing to a typical biomedical researcher with limited resources who works with big data. Specifically, we will develop a user-friendly drag-and-drop interface to enable biomedical researchers to build and edit containerized workflows. Most importantly, users can choose to deploy and scale selected modules in the workflow on cloud computing platforms in a transparent, yet guided fashion, to optimize cost and performance. Our aim is to provide a federated approach that leverages resources from multiple cloud vendors. We have assembled a team of interdisciplinary scientists with expertise in bioinformatics, cloud and distributed computing, and machine learning. As part of this application, we will work closely with end users who routinely generate and analyze RNA-seq data. We will illustrate how our containerized, cloud-enabled methods and tools will benefit bioinformatics analyses. Project Narrative Cloud computing has emerged as a promising solution to address the challenge of analyzing diverse and massive data generated to advance our understanding of health and diseases. We will develop methods and tools to build and intelligently deploy modular and cloud-enabled bioinformatics workflows. These tools will allow the biomedical community to optimize the costs associated with cloud computing and to facilitate the replication of scientific results.",Intelligent deployment of containerized bioinformatics workflows on the cloud,9625823,R01GM126019,"['Address', 'Big Data', 'Bioinformatics', 'Case Study', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Dependence', 'Development', 'Disease', 'Docking', 'Documentation', 'Drops', 'Drug toxicity', 'Educational Materials', 'Ensure', 'Feedback', 'Generations', 'Goals', 'Health', 'Hospitals', 'Image', 'Infrastructure', 'Intelligence', 'Libraries', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Performance', 'Price', 'Privatization', 'RNA analysis', 'Reproducibility', 'Research Personnel', 'Resources', 'Schedule', 'Scientist', 'Services', 'Software Tools', 'Structure', 'Technical Expertise', 'Technology Transfer', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'cloud platform', 'cluster computing', 'computational platform', 'computing resources', 'cost', 'cost effective', 'distributed data', 'expectation', 'flexibility', 'graphical user interface', 'improved', 'instrument', 'outreach', 'predictive modeling', 'prototype', 'tool', 'tool development', 'transcriptome sequencing', 'user-friendly', 'virtual', 'web site']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2019,343157,0.005783599197093029
"Arkansas Bioinformatics Consortium Project Summary/Abstract The Arkansas Research Alliance proposes to hold five annual workshops on the subject of bioinformatics. The purpose is to bring six major Arkansas institutions into closer collaboration. Those institutions are: University of Arkansas-Fayetteville; Arkansas State University; University of Arkansas for Medical Sciences; University of Arkansas at Little Rock; University of Arkansas at Pine Bluff; and the National Center for Toxicological Research. The workshops will focus on capabilities at each of the six in sciences related to bioinformatics including artificial intelligence, big data, machine learning, food and agriculture, high speed computing, and visualization capabilities. As this work progresses, educational coordination and student encouragement will be important components. Principals from all six institutions are collaborating to accomplish the workshop goals. Project Narrative The FDA ability to protect the public health is directly related to its ability to access and utilize the latest scientific data. Increased proficiency in collecting, presenting, validating, understanding, and drawing quantitative inference from the massive volume of new scientific results is necessary for success in that effort. The complexity involved requires continued development of new tools available and being developed within the realm of information technology, and the workshops proposed here will address this need. Specific Aims  • Thoroughly understand the resources in Arkansas available for furthering the capabilities in  bioinformatics and its associated needs, e.g., access to high speed computing capability and use  of computational tools. • Develop a set of plans to harness and grow those capabilities, especially those that are relevant  to the needs of NCTR and FDA. • Stimulate interest and capability across Arkansas in bioinformatics to produce a larger cadre of  expertise as these plans are implemented. • Enlist NCTR’s help in directing the effort toward seeking local, national and international data  that can be more effectively analyzed to produce results needed by FDA and others, e.g.,  reviewing decades of genomic/treatment data on myeloma patients at the University of  Arkansas for Medical Sciences. • Develop ways in which the Arkansas capabilities can be combined into a coordinated, synergistic  force larger than the sum of its parts. • Encourage students and faculty in the development of new models and techniques to be used in  bioinformatics and related fields. • Improve inter-institutional communication, including developing standardized bioinformatics  curricula and more universal course acceptance.",Arkansas Bioinformatics Consortium,9911854,R13FD006690,[' '],FDA,ARKANSAS RESEARCH ALLIANCE,R13,2019,15000,0.013986083910968203
"Big Data, Big Models, and Big Bias?: A decision making framework for vital rate estimates based on extrapolation Project Summary/Abstract The past decades have seen a flurry of methods that use extrapolation, smoothing, and other forms of information sharing to compensate for limited and incomplete data. In places without comprehensive vital registration or public health monitoring systems, extrapolation and information sharing techniques are particularly appealing, since there typically is simply not enough data available to produce estimates with sufficient temporal or spatial resolution to influence public health decision making. This proposal reframes uncertainty in extrapolated estimates of vital rates in terms of decision-making. A decision-making framework (i) is grounded in familiar language for policymakers and public health officials, (ii)characterizes consequential and inconsequential model decisions based on variability in outcomes, and (iii) in- corporates both extrapolation and sampling uncertainty. A cornerstone of this project is a novel collaboration with researchers and policymakers at the World Bank. Through this collaboration, we will pilot the proposed decision-making tools and conduct experiments with local and national policymakers in realistic settings. Project Narrative Predictions based on machine learning models are increasingly common inputs into decision making processes across scientific domains. In this proposal I develop and evaluate strategies for making public health decisions based on predicted vital rates, particularly in places without full coverage civil registration. Results from the project will improve strategies for allocating resources for disease surveillance and health monitoring in scarce resource settings.","Big Data, Big Models, and Big Bias?: A decision making framework for vital rate estimates based on extrapolation",9780910,DP2MH122405,"['Big Data', 'Collaborations', 'Consequentialism', 'Data', 'Decision Making', 'Disease Surveillance', 'Health', 'Language', 'Machine Learning', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Process', 'Public Health', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'System', 'Techniques', 'Uncertainty', 'World Bank', 'base', 'experimental study', 'improved', 'novel', 'tool']",NIMH,UNIVERSITY OF WASHINGTON,DP2,2019,2332500,-0.007942858575205644
"Conference on Modern Challenges in Imaging in the Footsteps of Allan Cormack Project Summary: Tufts University physics professor Allan Cormack pioneered the field of tomography. His seminal work, from 1963 and 1964, provided both the mathematical foundations of computerized tomography (CT), and tangible proof-of-concept by engineering a rudimentary CT scanner. Taken together, this effort represented the first practical method to ""see into"" an object without physically breaking it open. Along with the engineer Godfrey Hounsfield, he won the 1979 Nobel Prize in Physiology or Medicine for these contributions. Since then, tomography has broadened to include a wide range of modalities and problems. This field is unique for the rich interplay among applications in medicine, security, earth sciences, industry, physics, and the mathematics required to solve these problems. This international conference at Tufts, “Modern Challenges in Imaging: In the Footsteps of Allan Cormack” will honor the achievements of Cormack and reflect this diversity in the field by gathering top international researchers in mathematics, engineering, science, and medicine to communicate the most current research and challenges in the field. This will include work on mathematical models of emerging modalities, tomographic machine learning, dynamic methods, and spectral imaging with applications include medicine and security. The best research from the conference will be disseminated in a special issue of the journal Inverse Problems. Talks will be posted on the conference website. The organizers will recruit a diverse set of experienced participants and trainees, and the conference will be advertised in a range of publications reflecting the scientific and demographic diversity of the field. This conference is unique in that it combines high-level mathematical participants with experts in medical and industrial CT. It is structured to encourage participants from different fields to talk with each other, broaden their horizons, and make connections between problems and methodologies in the various fields. Several of the plenary talks will provide introductions to the areas. Trainees will be integrated into the conference through an informal welcome lunch and a poster session to introduce them to researchers in the field. This supports goals 1, 4, and 5, of the NIBIB: Researchers will present innovative biomedical technologies, engineering solutions, and mathematical methods to better image the body and objects more generally. The synergy between research areas will support the translation of technologies from the academic sphere to medical utility. The training opportunities for graduate students and beginners support the training of the next generation of diverse scientists. Project Narrative This conference will bring together medical, scientific, engineering, and applied mathematical researchers to present their newest research for a range of tomographic problems. Graduate students and beginners will be encouraged to participate and learn by being offered introductory talks, a student poster session, a welcome event, and an informal atmosphere. The conference will be structured so researchers will learn about important challenges in practical tomography as well as new techniques and methods, thereby creating synergies and research connections among the areas.",Conference on Modern Challenges in Imaging in the Footsteps of Allan Cormack,9837131,R13EB028700,"['Achievement', 'Advertising', 'Algorithms', 'Area', 'Biomedical Technology', 'Communication', 'Development', 'Earth science', 'Engineering', 'Environment', 'Event', 'Fertilization', 'Foundations', 'Goals', 'Image', 'Individual', 'Industrialization', 'Industry', 'International', 'Journals', 'Lead', 'Learning', 'Lightning', 'Machine Learning', 'Mathematics', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Modality', 'Modernization', 'National Institute of Biomedical Imaging and Bioengineering', 'Nobel Prize', 'Outcome', 'Participant', 'Physics', 'Physiology', 'Population', 'Problem Solving', 'Publications', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Security', 'Seminal', 'Societies', 'Structure', 'Students', 'Techniques', 'Technology', 'Time', 'Training Support', 'Translations', 'Underrepresented Groups', 'Universities', 'Work', 'X-Ray Computed Tomography', 'cohort', 'demographics', 'design', 'experience', 'graduate student', 'higher level mathematics', 'informal atmosphere', 'innovation', 'mathematical methods', 'mathematical model', 'meetings', 'member', 'next generation', 'posters', 'professor', 'recruit', 'spectrograph', 'symposium', 'synergism', 'tomography', 'training opportunity', 'web site']",NIBIB,TUFTS UNIVERSITY MEDFORD,R13,2019,10000,0.011101020923676416
"Summer Institute in Neuroimaging and Data Science Project Summary/Abstract The study of the human brain with neuroimaging technologies is at the cusp of an exciting era of Big Data. Many data collection projects, such as the NIH-funded Human Connectome Project, have made large, high- quality datasets of human neuroimaging data freely available to researchers. These large data sets promise to provide important new insights about human brain structure and function, and to provide us the clues needed to address a variety of neurological and psychiatric disorders. However, neuroscience researchers still face substantial challenges in capitalizing on these data, because these Big Data require a different set of technical and theoretical tools than those that are required for analyzing traditional experimental data. These skills and ideas, collectively referred to as Data Science, include knowledge in computer science and software engineering, databases, machine learning and statistics, and data visualization.  The Summer Institute in Data Science for Neuroimaging will combine instruction by experts in data science methodology and by leading neuroimaging researchers that are applying data science to answer scientiﬁc ques- tions about the human brain. In addition to lectures on the theoretical background of data science methodology and its application to neuroimaging, the course will emphasize experiential hands-on training in problem-solving tutorials, as well as project-based learning, in which the students will create small projects based on openly available datasets. Summer Institute in Neuroimaging and Data Science: Project Narrative The Summer Institute in Neuroimaging and Data Science will provide training in modern data science tools and methods, such as programming, data management, machine learning and data visualization. Through lectures, hands-on training sessions and team projects, it will empower scientists from a variety of backgrounds in the use of these tools in research on the human brain and on neurological and psychiatric brain disorders.",Summer Institute in Neuroimaging and Data Science,9650637,R25MH112480,"['Address', 'Adopted', 'Big Data', 'Brain', 'Brain Diseases', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Data Set', 'Databases', 'Discipline', 'Face', 'Faculty', 'Fostering', 'Funding', 'Habits', 'Home environment', 'Human', 'Image', 'Institutes', 'Institution', 'Instruction', 'Internet', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mental disorders', 'Methodology', 'Methods', 'Modernization', 'Neurologic', 'Neurosciences', 'Participant', 'Positioning Attribute', 'Problem Solving', 'Psychology', 'Reproducibility', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Software Engineering', 'Software Tools', 'Structure', 'Students', 'Technology', 'Testing', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'career', 'classification algorithm', 'computer science', 'connectome', 'data management', 'data visualization', 'design', 'e-science', 'experimental study', 'high dimensionality', 'insight', 'instructor', 'interdisciplinary collaboration', 'knowledge base', 'lectures', 'nervous system disorder', 'neurogenetics', 'neuroimaging', 'novel', 'open source', 'prediction algorithm', 'programs', 'project-based learning', 'skills', 'statistics', 'success', 'summer institute', 'theories', 'tool']",NIMH,UNIVERSITY OF WASHINGTON,R25,2019,199118,-0.006953217115588497
"QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine  The purpose of this proposal is to develop a combination of innovative statistical and data visualization approaches using patient-generated health data, including mobile health (mHealth) data from wearable devices and smartphones, and patient-reported outcomes, to improve outcomes for patients with Inflammatory Bowel Diseases (IBDs). This research will offer new insights into how to process and transform patient-generated health data into precise lifestyle recommendations to help achieve remission of symptoms. The specific aims of this research are: 1) To develop new preprocessing methods for publicly available, heterogeneous, time-varied mHealth data to develop a high quality mHealth dataset; 2) To develop and apply novel machine learning methods to obtain accurate predictions and formal statistical inference for the influence of lifestyle features on disease activity in IBDs; and 3) To design and develop innovative, interactive data visualization tools for knowledge discovery. The methods developed in the areas of preprocessing of mHealth data, calibration for mHealth devices, machine learning, and interactive data visualization will be broadly applicable to other mHealth data, chronic conditions beyond IBDs, and other fields in which the data streams are highly variable, intermittent, and periodic. This work is highly relevant to the mission of the NIH BD2K initiative which supports the development of innovative and transformative approaches and tools to accelerate the integration of Big Data and data science into biomedical research. This project will also enhance training in the development and use of methods for biomedical Big Data science and mentor the next generation of multidisciplinary scientists. The proposed research is relevant to public health by seeking to improve symptoms for patients with inflammatory bowel diseases, which are chronic, life-long conditions with waxing and waning symptoms. Developing novel statistical and visualization methods to provide a more nuanced understanding of the precise relationship between physical activity and sleep to disease activity is relevant to BD2K's mission.",QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine ,9741121,R01EB025024,"['Adrenal Cortex Hormones', 'Adult', 'Affect', 'Americas', 'Area', 'Behavior', 'Big Data', 'Big Data to Knowledge', 'Biomedical Research', 'Calibration', 'Caring', 'Cellular Phone', 'Characteristics', 'Chronic', 'Crohn&apos', 's disease', 'Data', 'Data Science', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Outcome', 'Disease remission', 'Dose', 'Effectiveness', 'Flare', 'Foundations', 'Functional disorder', 'Funding', 'Imagery', 'Immunosuppression', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Institute of Medicine (U.S.)', 'Knowledge Discovery', 'Life', 'Life Style', 'Life Style Modification', 'Longitudinal Surveys', 'Longitudinal cohort study', 'Machine Learning', 'Mathematics', 'Measures', 'Mentors', 'Methods', 'Mission', 'Moderate Activity', 'Morbidity - disease rate', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Periodicity', 'Phenotype', 'Physical activity', 'Precision therapeutics', 'Process', 'Public Health', 'Quality of life', 'Recommendation', 'Reporting', 'Research', 'Research Institute', 'Schools', 'Scientist', 'Sleep', 'Sleep disturbances', 'Stream', 'Symptoms', 'Therapeutic', 'Time', 'Training', 'Ulcerative Colitis', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Visualization software', 'Waxes', 'Work', 'base', 'big biomedical data', 'clinical remission', 'comparative effectiveness', 'cost', 'data visualization', 'design', 'disorder risk', 'effectiveness research', 'health data', 'improved', 'improved outcome', 'individual patient', 'innovation', 'insight', 'large bowel Crohn&apos', 's disease', 'learning strategy', 'lifestyle factors', 'mHealth', 'member', 'multidisciplinary', 'next generation', 'novel', 'precision medicine', 'side effect', 'sleep quality', 'symptomatic improvement', 'tool', 'wearable device']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2019,281932,-0.009421614212643953
"Statistical Methods for Ultrahigh-dimensional Biomedical Data This proposal develops novel statistics and machine learning methods for distributed analysis of big data in biomedical studies and precision medicine and for selecting a small group of molecules that are associated with biological and clinical outcomes from high-throughput data such as microarray, proteomic, and next generation sequence from biomedical research, especially for autism studies and Alzheimer’s disease research. It focuses on developing efficient distributed statistical methods for Big Data computing, storage, and communication, and for solving distributed health data collected at different locations that are hard to aggregate in meta-analysis due to privacy and ownership concerns. It develops both computationally and statistically efficient methods and valid statistical tools for exploring heterogeneity of big data in precision medicine, for studying associations of genomics and genetic information with clinical and biological outcomes, and for feature selection and model building in presence of errors-in- variables, endogeneity, and heavy-tail error distributions, and for predicting clinical outcomes and understanding molecular mechanisms. It introduces more robust and powerful statistical tests for selection of significant genes, SNPs, and proteins in presence of dependence of data, valid control of false discovery rate for dependent test statistics, and evaluation of treatment effects on a group of molecules. The strength and weakness of each proposed method will be critically analyzed via theoretical investigations and simulation studies. Related software will be developed for free dissemination. Data sets from ongoing autism research, Alzheimer’s disease, and other biomedical studies will be analyzed by using the newly developed methods and the results will be further biologically confirmed and investigated. The research findings will have strong impact on statistical analysis of high throughput big data for biomedical research and on understanding heterogeneity for precision medicine and molecular mechanisms of autism, Alzheimer’s disease, and other diseases. This proposal develops novel statistical machine learning methods and bioinformatic tools for finding genes, proteins, and SNPs that are associated with clinical outcomes and discovering heterogeneity for precision medicine. Data sets from ongoing autism research, Alzheimer’s disease and other biomedical studies will be critically analyzed using the newly developed statistical methods, and the results will be further biologically confirmed and investigated. The research findings will have strong impact on developing therapeutic targets and understanding heterogeneity for precision and molecular mechanisms of autism, Alzheimer’s diseases, and other diseases. !",Statistical Methods for Ultrahigh-dimensional Biomedical Data,9634069,R01GM072611,"['Address', 'Alzheimer&apos', 's Disease', 'Big Data', 'Big Data Methods', 'Biological', 'Biomedical Research', 'Brain', 'Classification', 'Clinical', 'Communication', 'Computer software', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Databases', 'Dependence', 'Dimensions', 'Disease', 'Disease Progression', 'Evaluation', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genomics', 'Heterogeneity', 'Internet', 'Investigation', 'Learning', 'Linear Models', 'Location', 'Machine Learning', 'Meta-Analysis', 'Methods', 'Molecular', 'Outcome', 'Ownership', 'Patients', 'Polynomial Models', 'Principal Component Analysis', 'Privacy', 'Proteins', 'Proteomics', 'Research', 'Role', 'Statistical Data Interpretation', 'Statistical Methods', 'Tail', 'Techniques', 'Testing', 'Time', 'autism spectrum disorder', 'big biomedical data', 'bioinformatics tool', 'cell type', 'computing resources', 'genetic information', 'health data', 'high dimensionality', 'high throughput analysis', 'improved', 'learning strategy', 'macrophage', 'model building', 'next generation', 'novel', 'precision medicine', 'predict clinical outcome', 'simulation', 'statistics', 'therapeutic target', 'tool', 'transcriptome sequencing', 'treatment effect']",NIGMS,PRINCETON UNIVERSITY,R01,2019,293003,-0.019719329287953297
"Preparing the Next Generation of Biostatisticians in the Era of Data and Translational Sciences PROJECT SUMMARY/ABSTRACT In the era of newly emerging computational tools for data science, biostatisticians need to play a fundamental role in health sciences research. There is an urgent need to encourage US Citizens and Permanent Residents to pursue graduate training in biostatistics. The design, conduct, and analysis of clinical trials and observational studies; the setting of regulatory policy; and the conception of laboratory experiments have been shaped by the fundamental contributions of biostatisticians for decades. Advances in genomics, medical imaging technologies, and computational biology; the increasing emphasis on precision and evidence-based medicine; and the widespread adoption of electronic health records; demand the skills of biostatisticians trained to collaborate effectively in a multidisciplinary environment and to develop statistical and machine learning methods to address the challenges presented by this data-rich revolutionary era of health sciences research. The proposed summer program which includes world-renowned clinical scientists and biostatisticians from two local universities, will provide an immense opportunity for student participants to learn basic yet modern statistical methods that are critical to uncovering new insights from such big and complex biomedical data and also illustrate the potential pitfalls of confounding and bias that may arise when analyzing biomedical data. A unique feature of the proposed training program is thus to expose the participants to not only basic statistical methods but also to the topics of computer science and bioinformatics which will be invaluable in creating the multidisciplinary teams required to tackle the complex research questions that often requires multipronged approaches. The proposed six-week training program will be structured around the NIH's Translation Science Spectrum and will introduce participants to opportunities in biostatistics through the lens of the science advanced by the contributions of biostatisticians. Following an initial set of weeks on basic training of biostatistical methods, the program will culminate in a data hack-a-thon style competition in which participants will employ the statistical and scientific knowledge gained during the program to produce the most innovative, statistically-sound, scientifically-relevant and effectively-communicated response to a set of research questions. The proposed research education program will enroll up to 20 such participants from across the nation and, through lectures, field trips, and opportunities to analyze data from real health sciences, inspire them to pursue graduate training. The program will draw upon considerable past collaborations and complementary resources of two local world-renowned universities to provide participants with an unparalleled view of the field, including award-winning instructors, internationally known methodological and clinical researchers, and a local area rich in opportunities to showcase careers in biostatistics. Special efforts will be made to enroll participants from underrepresented groups. Participants will be followed after completion, and the numbers attending graduate school in statistics and pursuing biostatistics careers will be documented. PROJECT NARRATIVE Biostatisticians are indispensible contributors to health sciences research. The demand for professionals with advanced training in biostatistics is high and will continue to increase, especially with the expanding challenges posed by big biomedical data. This six week summer research education program, a joint effort of North Carolina State University and Duke University, will enroll up to 20 US citizen/permanent resident participants from across the nation in the summers of 2020-2022 and expose them to the opportunities presented by careers in biostatistics and encourage them to seek graduate training in the field.",Preparing the Next Generation of Biostatisticians in the Era of Data and Translational Sciences,9734597,R25HL147228,"['Address', 'Adoption', 'Area', 'Attention', 'Award', 'Bioinformatics', 'Biomedical Research', 'Biometry', 'Biostatistical Methods', 'Clinical', 'Clinical Trials', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Conceptions', 'Data', 'Data Science', 'Development', 'Discipline', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Environment', 'Evaluation', 'Evidence Based Medicine', 'Exposure to', 'Faculty', 'Future', 'Genomics', 'Goals', 'Health Sciences', 'Health system', 'Imaging technology', 'Institution', 'International', 'Joints', 'Knowledge', 'Learning', 'Machine Learning', 'Medical Imaging', 'Medical center', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Names', 'National Heart, Lung, and Blood Institute', 'North Carolina', 'Observational Study', 'Participant', 'Play', 'Policies', 'Positioning Attribute', 'Principal Investigator', 'Program Effectiveness', 'Request for Applications', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Schools', 'Science', 'Scientist', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Students', 'Talents', 'Training', 'Training Programs', 'Translational Research', 'Translations', 'Underrepresented Groups', 'United States National Institutes of Health', 'Universities', 'analytical method', 'big biomedical data', 'career', 'career development', 'cohort', 'computer science', 'computerized tools', 'data resource', 'design', 'education research', 'experience', 'field trip', 'graduate student', 'health science research', 'innovation', 'insight', 'instructor', 'interest', 'investigator training', 'laboratory experiment', 'learning strategy', 'lectures', 'lens', 'multidisciplinary', 'next generation', 'programs', 'public health research', 'recruit', 'response', 'skills', 'sound', 'statistics', 'summer institute', 'summer program', 'summer research', 'tool', 'undergraduate student']",NHLBI,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R25,2019,249789,0.03533572961483691
"Boston University CCCR OVERALL ABSTRACT The Boston University CCCR will serve as a central resource for clinical research focused mostly on the most common musculoskeletal disorders, osteoarthritis and gout and will also provide research resources for investigator based research in scleroderma, spondyloarthritis, musculoskeletal pain and osteoporosis. Center grant funding has supported 30-35 papers annually in peer reviewed journals, most in the leading arthritis journals and some in leading general medical journals. This center has trained many of the leading clinical researchers in rheumatology throughout the US and internationally, and many of these former trainees have active collaborations with the center. We will include a broad research community and a core group of faculty in this CCCR. The research community's ready access to core faculty and to the sophisticated research methods and assistance they provide will enhance the clinical and translational research of the community and will increase collaborative opportunities for the core faculty and the community. The CCCR updates BU's historical focus on epidemiologic methods to include new approaches to causal inference and adds new methods in machine learning and mobile health. The Research and Evaluation Support Core Unit (RESCU) is the focal point of this CCCR. A key feature is the weekly research (RESCU meetings in which ongoing and proposed research projects are critically evaluated. This feature ensures frequent interactions between clinician researchers, epidemiologists and biostatisticians who are the core members of the CCCR. The RESCU core unit has provided critical support for other Center grants related to rheumatic and arthritic disorders at Boston University, three current R01/U01's; five current NIH K awards (one K24, 3 K23's, one K01), an R03, an NIH trial planning grant (U34), and multiple ACR RRF awards. The overall goal of this center is to carry out and disseminate high-level clinical research informed both by state of the art clinical research methods and by clinical and biological scientific discoveries. Ultimately, we aim either to prevent the diseases we are studying or to improve the lives of those living with the diseases. NARRATIVE The Boston University Core Center for Clinical Research will provide broad clinical research methods expertise to a large multidisciplinary group of investigators whose research focuses on osteoarthritis and gout with a secondary emphasis on scleroderma, spondyloarthritis, osteoporosis and musculoskeletal pain. The group, which includes persons with backgrounds in rheumatology, physical therapy, epidemiology, biostatistics and  . behavioral science, meets weekly to critically review research projects and serves a broad research community with which it actively engages. It has been successful in publishing influential papers on the diseases of focus and in training many of the clinical research faculty in the US and internationally",Boston University CCCR,9851583,P30AR072571,"['Allied Health Profession', 'Area', 'Arthritis', 'Award', 'Behavioral Sciences', 'Biological', 'Biometry', 'Boston', 'Clinical', 'Clinical Research', 'Cohort Studies', 'Collaborations', 'Communities', 'Complement', 'Computerized Medical Record', 'Consensus', 'Consultations', 'Databases', 'Degenerative polyarthritis', 'Disease', 'Ensure', 'Environment', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Europe', 'Evaluation', 'Excision', 'Faculty', 'Funding', 'Goals', 'Gout', 'Grant', 'Health', 'Influentials', 'Infusion procedures', 'Institutes', 'Institution', 'International', 'Journals', 'K-Series Research Career Programs', 'Machine Learning', 'Medical', 'Medical Research', 'Medical center', 'Methods', 'Musculoskeletal Diseases', 'Musculoskeletal Pain', 'New England', 'Osteoporosis', 'Outcome', 'Pain', 'Paper', 'Peer Review', 'Persons', 'Physical therapy', 'Privatization', 'Productivity', 'Public Health Schools', 'Publications', 'Publishing', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rheumatism', 'Rheumatology', 'Risk Factors', 'Schools', 'Scleroderma', 'Spondylarthritis', 'Talents', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Update', 'base', 'cohort', 'design', 'epidemiology study', 'faculty community', 'faculty research', 'improved', 'innovation', 'interdisciplinary collaboration', 'learning strategy', 'mHealth', 'medical schools', 'meetings', 'member', 'multidisciplinary', 'novel', 'novel strategies', 'patient oriented', 'prevent', 'programs', 'protocol development', 'statistical service', 'success']",NIAMS,BOSTON UNIVERSITY MEDICAL CAMPUS,P30,2019,741688,-0.0022478735091961514
"Acquisition of a next-generation computing cluster We request funds to purchase our next-generation computing cluster to support computationally intensive NIH-funded research at Washington University in St. Louis. This system will become the foundation of the Center for High Performance Computing (CHPC) to support our active, diverse user community. It has been designed to meet our current and future computing needs. It adds additional capabilities to support emerging fields such as “Deep Learning”. The CHPC currently supports over 775 users from 300 different groups across 33 departments. 58 papers have cited the CHPC. The Center has a proven funding model and is economically sustainable. The Center has partnered with other University organizations to offer training workshops, not only on the use of the cluster, but also on introductory programming for users with no prior programming experience. If this proposal is funded, we will be able to continue to support this ever-growing diverse community of researchers. The proposed system would replace critical components including the management node, the login nodes, the storage, and upgrade the Infiniband networking. We would add substantial upgrades to our computing power with state-of-the-art processors, increased memory capacity for growing jobs, General Purpose Graphical Processing units (GPGPUs), and new capabilities for “Deep Learning”. Nearly all fields of NIH-funded research are faced with increasingly large data sets that require additional computing power to analyze. We propose building a next-generation computing cluster to support this research. Our Center has a proven track record in supporting a large, diverse group of users in all aspects of their computationally demanding research.",Acquisition of a next-generation computing cluster,9707936,S10OD025200,"['Communities', 'Educational workshop', 'Foundations', 'Funding', 'Future', 'High Performance Computing', 'Memory', 'Modeling', 'Occupations', 'Paper', 'Research', 'Research Personnel', 'System', 'Training', 'United States National Institutes of Health', 'Universities', 'Washington', 'cluster computing', 'deep learning', 'design', 'experience', 'next generation']",OD,WASHINGTON UNIVERSITY,S10,2019,597200,0.004484966139386728
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9626416,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Infrastructure', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'analysis pipeline', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2019,2000000,-0.0029911983325882543
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9731439,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image Analysis', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Non-aphasic', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2019,39939,-0.03955528075106911
"Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software. Abstract (Proposal title: Neuroscience Gateway to Enable Dissemination of Computational and Data Processing Tools and Software.): This proposal presents a focused plan for expanding the capabilities of the Neuroscience Gateway (NSG) to meet the evolving needs of neuroscientists engaged in computationally intensive research. The NSG project began in 2012 with support from the NSF. Its initial goal was to catalyze progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists faced in large scale modeling projects involving tools and software which require and run efficiently on high performance computing (HPC) resources. NSG's success is reflected in the facts that (1) its base of registered users has grown continually since it started operation in early 2013 (more than 800 at present), (2) every year the NSG team successfully acquires ever larger allocations of supercomputer time (recently more than 10,000,000 core hours/year) on academic HPC resources of the Extreme Science and Engineering Discovery (XSEDE – that coordinates NSF supercomputer centers) program by writing proposals that go through an extremely competitive peer review process, and (3) it has contributed to large number of publications and Ph.D thesis. In recent years experimentalists, cognitive neuroscientists and others have begun using NSG for brain image data processing, data analysis and machine learning. NSG now provides over 20 tools on HPC resources for modeling, simulation and data processing. While NSG is currently well used by the neuroscience community, there is increasing interest from that community in applying it to a wider range of tasks than originally conceived. For example, some are trying to use it as an environment for dissemination of lab-developed tools, even though NSG is not suitable for that use because of delays from the batch queue wait times of production HPC resources, and lack of features and resources for an interactive, graphical, and collaborative environment needed for tool development, benchmarking and testing. “Forced” use of NSG for development and dissemination makes NSG's operators a “person-in-the-middle” bottleneck in the process. Another issue is that newly developed data processing tools require high throughput computing (HTC) usage mode, as opposed to HPC, but currently NSG does not provide access to compute resources suitable for HTC. Additionally, data processing workflows require features such as the ability to transfer large size data, process shared data, and visualize output results, which are not currently available on NSG. The work we propose will enhance NSG by adding the features that it needs to be a suitable and efficient dissemination environment for lab-developed neuroscience tools to the broader neuroscience community. This will allow tool developers to disseminate their lab-developed tools on NSG taking advantage of the current functionalities that are being well served on NSG for the last six years such as a growing user base, an easy user interface, an open environment, the ability to access and run jobs on powerful compute resources, availability of free supercomputer time, a well-established training and outreach program, and a functioning user support system. All of these well-functioning features of NSG will make it an ideal environment for dissemination and use of lab-developed computational and data processing neuroscience tools. The Neuroscience Gateway (NSG) was first implemented to enable large scale computational modeling of brain cells and circuits used to study neural function in health and disease. This new project extends NSG's utility to support development, dissemination and use of new tools by the neuroscience community for analyzing enormous data sets produced by advanced experimental methods in neuroscience.",Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software.,9882822,U24EB029005,"['Behavioral', 'Benchmarking', 'Brain imaging', 'Cells', 'Cognitive', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Development', 'Disease', 'Education', 'Education and Outreach', 'Educational workshop', 'Electroencephalography', 'Engineering', 'Environment', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Hour', 'Human Resources', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurosciences Research', 'Occupations', 'Output', 'Peer Review', 'Persons', 'Process', 'Production', 'Psychologist', 'Publications', 'Reaction Time', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Software Tools', 'Students', 'Support System', 'System', 'Testing', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Wait Time', 'Work', 'Workload', 'Writing', 'base', 'bioimaging', 'brain cell', 'collaborative environment', 'computational neuroscience', 'computerized data processing', 'computing resources', 'data sharing', 'image processing', 'interest', 'models and simulation', 'open data', 'operation', 'outreach program', 'programs', 'response', 'success', 'supercomputer', 'tool', 'tool development', 'trend', 'webinar']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2019,390806,0.013731708714656492
"Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!) PROJECT SUMMARY/ABSTRACT Our society faces significant challenges in providing quality health care that is accessible by each person and is sensitive to each person's individual lifestyle and individual health needs. Due to recent advances in sensing technologies that have improved in accuracy, increased in throughput, and reduced in cost, it has become relatively easy to gather high resolution behavioral and individualized health data at scale. The resulting big datasets can be analyzed to understand the link between behavior and health and to design healthy behavior interventions. In this emerging area, however, very few courses are currently available for teaching researchers and practitioners about the foundational principles and best practices behind collecting, storing, analyzing, and using behavior- based sensor data. Teaching these skills can help the next generation of students thrive in the increasingly digital world.  The goal of this application is to design online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to WSU faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.  This contribution is significant because not only large research groups but even individual investigators can create large data sets that provide valuable, in-the-moment information about human behavior. They need to be able to handle the challenges that arise when working with sensor- based behavior data. Because students will receive hands-on training with actual sensor datasets and analysis tools, they will know how to get the best results from available tools and will be able to interpret the significance of analysis results.  Our proposed online course program, called AHA!, builds on the investigators' extensive experience and ongoing collaboration at Washington State University on the development of smart home and mobile health app design, activity recognition, scalable biological data mining, and the use of these technologies for clinical applications. Our approach will be to design online course modules to train individuals in the analysis of behavior-based sensor data using clinical case studies (Aim 1). We will design an educational program that involves students from diverse backgrounds and that is findable, accessible, interoperable, and reusable (Aim 2). Finally, we will conduct a thorough evaluation to monitor success and incrementally improve the program (Aim 3). All of the materials will be designed for continued use beyond the funding period of the program. PROJECT NARRATIVE  This program focuses on the development and dissemination of online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to Washington State University faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.",Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!),9696381,R25EB024327,"['Address', 'Aging', 'Area', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Big Data', 'Biological', 'Case Study', 'Charge', 'Chronic Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Data', 'Data Set', 'Development', 'Discipline', 'E-learning', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Evaluation', 'FAIR principles', 'Face', 'Faculty', 'Feedback', 'Foundations', 'Funding', 'General Population', 'Goals', 'Health', 'Human', 'Immersion Investigative Technique', 'Individual', 'Interdisciplinary Study', 'Life Style', 'Link', 'Longevity', 'Machine Learning', 'Methods', 'Mobile Health Application', 'Monitor', 'Performance', 'Persons', 'Precision Medicine Initiative', 'Pythons', 'Rehabilitation Nursing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Site', 'Societies', 'Structure', 'Students', 'Suggestion', 'Techniques', 'Technology', 'Training', 'Universities', 'Washington', 'Work', 'base', 'behavior influence', 'behavioral health', 'biocomputing', 'career networking', 'clinical application', 'cognitive rehabilitation', 'cost', 'course development', 'course module', 'data mining', 'design', 'digital', 'experience', 'health care quality', 'health data', 'improved', 'innovation', 'learning materials', 'learning strategy', 'mHealth', 'next generation', 'online course', 'programs', 'recruit', 'responsible research conduct', 'scale up', 'sensor', 'sensor technology', 'skills', 'smart home', 'statistics', 'success', 'synergism', 'tool', 'web page']",NIBIB,WASHINGTON STATE UNIVERSITY,R25,2019,150529,0.022407389241209212
"New Jersey Alliance for Clinical Translational Science: NJ ACTS Coordinated by Rutgers Biomedical and Health Sciences (RBHS), the New Jersey Alliance for Clinical and Translational Science (NJ ACTS) comprises a consortium with Rutgers and Princeton Universities (PU), NJ Institute for Technology (NJIT), medical, nursing, dental and public health schools, hospitals, community health centers, outpatient practices, industry, policymakers and health information exchanges. All Alliance universities and affiliates have provided substantial resources and contributed to the planning, development and leadership of the consortium. With access to ~7 million people, NJ ACTS serves as a ‘natural laboratory’ for translational and clinical research. With a state population of ~9 million, New Jersey ranks 11th in the US, 1st in population density and higher than average in racial and ethnic diversity. Surprisingly, NJ has no CTSA Hub to coordinate translational and clinical research. Our CTSA Hub focuses on two overarching themes: the heterogeneity of disease pathogenesis and response to treatment, and the value of linking large clinical databases with interventional clinical investigations to identify cause-and-effect and predict therapeutic responses. NJ ACTS will provide: innovative approaches to link information from large databases and electronic health records to inform clinical trial design, execution and analysis; and novel platforms for biomarker discovery using fluorescence in situ hybridization and machine learning to identify unique neural signatures of chronic illness. NJ ACTS will access a large health system with significant member diversity; a rich legacy of community engagement and community-based research platforms; and proven approaches to enhance workforce development in clinical research. With a substantial investment in streamlining research administration and IRB practices at Rutgers and with the inception of NJ ACTS, there exists an unparalleled opportunity for logarithmic growth in clinical research in New Jersey. To build our capacity for participant and clinical interactions as a CTSA Hub, the newly established Trial Accelerator and Recruitment Office will coordinate feasibility assessment, implementation, recruitment, and evaluation of clinical studies. Additionally, our organization of five clinical research units into a cohesive network provides extraordinary expertise in strategic locations to enhance participant recruitment from diverse communities with a particular focus on: children; the elderly; those with serious mental illness or substance abuse issues; low-income individuals served by Medicaid; those with HIV/AIDS; and people of all ages who are minorities, underserved, and victims of health and environmental disparities. With a history of collaboration, partners and affiliates share unique skills, expertise, training and mentoring capabilities that will be greatly amplified within the infrastructure of a CTSA Hub. Princeton and NJIT, without medical schools or hospital affiliates, seeks collaboration with Rutgers to provide clinical research platforms; Rutgers seeks the PU and NJIT expertise in novel informatics platforms, expertise in natural language and ontology, machine learning and cognitive neurosciences. Together NJ ACTS will provide an alliance that will catalyze clinical research and training across New Jersey to improve population health and contribute to the CTSA Consortium. In this revised application, the overall themes remain unchanged but Cores leadership and direction has been markedly refined. Project Narrative The New Jersey Alliance for Clinical and Translational Science (NJ ACTS), as a member of the CTSA Consortium, unites Rutgers University, Princeton University, the New Jersey Institute of Technology, clinical, community and industry partners in a shared vision to make New Jersey a healthier state. Building on New Jersey’s already significant capabilities to promote and facilitate clinical and translational research, NJ ACTS will serve as a catalyst, inspiring new approaches to diagnose and manage disease, and fostering career development of the next generation of translational researchers, and promoting population health.",New Jersey Alliance for Clinical Translational Science: NJ ACTS,9831333,UL1TR003017,"['AIDS/HIV problem', 'Address', 'Affect', 'Age', 'Asian Indian', 'Behavioral', 'Biometry', 'Child', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cohort Studies', 'Collaborations', 'Communities', 'Community Health Centers', 'Cuban', 'Databases', 'Dental', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline of Nursing', 'Disease Management', 'Diverse Workforce', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Fluorescent in Situ Hybridization', 'Fostering', 'Foundations', 'Government', 'Growth', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitals', 'Image', 'Improve Access', 'Individual', 'Industry', 'Informatics', 'Infrastructure', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Investigation', 'Investments', 'Laboratories', 'Leadership', 'Life Style', 'Link', 'Location', 'Longevity', 'Low income', 'Machine Learning', 'Medicaid', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Minority', 'Minority Groups', 'Mission', 'Muslim population group', 'New Jersey', 'Not Hispanic or Latino', 'Ontology', 'Oral health', 'Outpatients', 'Parents', 'Participant', 'Pathogenesis', 'Patient Recruitments', 'Perception', 'Population', 'Population Density', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Preventive Intervention', 'Process', 'Public Health', 'Public Health Schools', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'School Nursing', 'Science', 'Solid', 'South Asian', 'Special Populations Research', 'Substance abuse problem', 'Technology', 'Therapeutic', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Universities', 'Vision', 'Workforce Development', 'analytical tool', 'base', 'biomarker discovery', 'career development', 'catalyst', 'clinical care', 'clinical investigation', 'cognitive neuroscience', 'cohesion', 'community based participatory research', 'disease heterogeneity', 'ethnic diversity', 'ethnic minority population', 'follower of religion Jewish', 'improved', 'industry partner', 'innovation', 'interdisciplinary approach', 'logarithm', 'medical schools', 'member', 'natural language', 'next generation', 'novel', 'novel strategies', 'population health', 'programs', 'racial diversity', 'racial minority', 'recruit', 'relating to nervous system', 'research clinical testing', 'response', 'severe mental illness', 'skills', 'success', 'tool', 'translational scientist', 'treatment response', 'trial design']",NCATS,RUTGERS BIOMEDICAL/HEALTH SCIENCES-RBHS,UL1,2019,4776211,0.01084647093803171
"Integrating multidimensional genomic data to discover clinically-relevant predictive models The goal of this NIH Pathway to Independence award is to provide Dr. Brittany Lasseigne with an extensive training program to prepare her to be an effective independent investigator who uses computational genomics to study complex human diseases. We propose a formal one-year training and mentoring program in genomics, computer science, statistics, and career development to build on her 8+ years of hands-on training, followed by a three-year structured and independent research program. Research will focus on the integration of multidimensional genomic data sets in the context of complex human diseases. A critical barrier in genomic research is the complexity of data integration: the ability to leverage overlapping and unique information captured by different genomic assays would improve our understanding of data integration and generate clinically relevant genomic signatures. To meet this need, we propose to integrate a combination of genomic data we generated with public data to (1) infer genomic instability signatures from different data types, (2) improve clinically relevant phenotype prediction by building multi-omics machine learning classifiers and reducing phenotype heterogeneity, and (3) create a cloud-enabled R package and associated Shiny application to accelerate future research. The proposed work will advance our understanding of data integration, allow inference of genomic instabilities across data sets, and generate high performance classifiers for assessing clinically relevant phenotypes in both cancer and psychiatric disease using frameworks that will be broadly applicable across other complex diseases. It will also facilitate prioritization of experiments in future studies by informing on the orthogonality of genomic assays, thereby allowing more efficient study designs to capture as much information as possible within a given sample size or scope of experimentation. Collectively, this additional training will allow Dr. Lasseigne to develop new multidimensional data integration approaches and translational questions applicable across complex diseases when independent. Dr. Richard Myers (HudsonAlpha) and Dr. Gregory Cooper (HudsonAlpha), leaders in applying genetics and genomics to complex human diseases, and an Advisory Committee of additional experts including Dr. Barbara Wold (Caltech), Dr. Eddy Yang (UAB), and Dr. Timothy Reddy (Duke), will provide mentoring throughout this award. The mentored phase will take place at the HudsonAlpha Institute for Biotechnology, an ideal environment for this training with extensive translational science collaborations, expert faculty and staff, and state-of-the art computational and laboratory resources devoted to genomics. This combination will maximize Dr. Lasseigne's training program, facilitating her transition to an independent, tenure-track investigator at a university with a strong commitment to data-driven approaches to complex human disease research, i.e. strong genomics research programs with clinical collaborators, ideally at, or affiliated with, an academic medical center. Project Narrative The major outcome of this project will be a scientist with the necessary research, mentoring, teaching, and career development training to run an independent research program in computational genomics. The research proposed will apply novel strategies to further develop integrative machine learning analyses of multidimensional genomic data, discover clinically relevant predictive models, and create computational tools to accelerate future research.",Integrating multidimensional genomic data to discover clinically-relevant predictive models,9901758,R00HG009678,"['Academic Medical Centers', 'Advisory Committees', 'Award', 'Bioconductor', 'Biological', 'Biological Assay', 'Biotechnology', 'Budgets', 'Cancer Etiology', 'Cell Proliferation', 'Cells', 'Characteristics', 'Chemotherapy-Oncologic Procedure', 'Chromosomal Instability', 'Chromosomes', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Copy Number Polymorphism', 'Coupling', 'CpG Island Methylator Phenotype', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Educational process of instructing', 'Environment', 'Faculty', 'Future', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Genomic Instability', 'Genomics', 'Goals', 'Heterogeneity', 'Imagery', 'Individual', 'Institutes', 'Instruction', 'Laboratories', 'Lasso', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mental disorders', 'Mentors', 'Methodology', 'Methylation', 'MicroRNAs', 'Microsatellite Instability', 'Modeling', 'Molecular Profiling', 'Neurons', 'Outcome', 'Pathway interactions', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Signal Transduction', 'Standardization', 'Structure', 'Systems Biology', 'Techniques', 'Testing', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Work', 'Yang', 'biomarker performance', 'career development', 'clinically relevant', 'computer science', 'computerized tools', 'data integration', 'data reduction', 'experimental study', 'genomic data', 'genomic signature', 'human disease', 'improved', 'insight', 'multidimensional data', 'multiple omics', 'novel strategies', 'predictive modeling', 'programs', 'promoter', 'protein metabolite', 'response', 'single cell sequencing', 'statistics', 'tenure track', 'tool']",NHGRI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R00,2019,249000,0.008633736972344415
"Accelerating Multi-modal Biomarker Discovery in Translational Research with Cloud Data Integration Project Summary/Abstract Cytobank is the leading cloud-based platform for analysis and storage of single cell flow and mass cytometry data, technologies that are essential for investigating the interplay between the immune system and disease conditions including cancer. There are numerous data analysis steps between raw data and insight especially for many single-cell technologies, where the data analysis is complex, highly expert-driven and/or reliant on novel computational methodologies. Cytobank already makes major contributions (1) centralizing single-cell cytometry data, (2) providing data analysis traceability that removes knowledge sharing complexities, and (3) establishing a platform that increases access to cutting edge algorithms and makes complex machine learning methods easy for biologists to use. However, as the amount, complexity, and different types of single cell data and other associated data increases and the number of workflows and single-cell algorithms to analyze the data also increases, the need for open and easy access to existing and new tools and secure, complete storage of the workflows and the resulting data has increased to the point of being critical for supporting basic and translational research collaborations and enabling them to efficiently achieve their objectives including biomarker discovery and development. The proposed project significantly extends the capabilities of the Cytobank platform. This will benefit the community by (1) enabling scalable and secure access to a number of new single-cell data analysis tools that will result in new automated workflows, and (2) enable more efficient cross platform knowledge generation with increased meta-analysis capabilities across experiments and data types. The potential of this project is that thousands of scientists around the world will be able to more easily leverage additional single-cell cytometry, transcript, and other data in their translational research data analysis including automating analysis that has primarily been dominated by expert-driven annotation, thus providing a central repository and knowledge management framework that will accelerate biomarker discovery and precision medicine. Project Narrative Single-cell biology and Immunotherapy are exploding and generating larger and more complex datasets in combination clinical trials. To take full advantage of these revolutions, the iteration and dissemination of advanced single-cell data analysis algorithms (many of whose development was funded by the NIH) needs to scale at the same rate as single-cell data generation technologies are scaling, and multi-omics data analysis and visualization must be integrated and automated. This project will greatly accelerate scientific research, transparency, and reproducibility by significantly lowering the barrier to perform complex data analysis of multiple types of high-dimensional data, providing the biomedical research community with access to powerful tools needed in immuno-oncology, autoimmunity and other high-impact disease areas.",Accelerating Multi-modal Biomarker Discovery in Translational Research with Cloud Data Integration,9672504,R44GM117914,"['Algorithmic Analysis', 'Algorithms', 'Area', 'Autoimmunity', 'B-Cell Acute Lymphoblastic Leukemia', 'Basic Science', 'Biological Markers', 'Biomedical Research', 'Cells', 'Cellular biology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Follicular Lymphoma', 'Foundations', 'Funding', 'Generations', 'Immune System Diseases', 'Immune system', 'Immunologic Monitoring', 'Immunology', 'Immunooncology', 'Immunotherapy', 'Information Resources Management', 'Knowledge', 'Label', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Meta-Analysis', 'Modality', 'Modeling', 'Multiomic Data', 'Outcome', 'Patients', 'Phase', 'Population', 'Positioning Attribute', 'Regimen', 'Relapse', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Scientist', 'Secure', 'System', 'Target Populations', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Toxic effect', 'Transcript', 'Translational Research', 'Treatment Efficacy', 'United States National Institutes of Health', 'Work', 'anti-cancer', 'automated analysis', 'base', 'biomarker development', 'biomarker discovery', 'biomarker validation', 'clinically actionable', 'cloud based', 'cost effective', 'cytokine', 'data integration', 'data management', 'data visualization', 'experimental study', 'high dimensionality', 'immunotherapy trials', 'improved', 'insight', 'learning strategy', 'multidimensional data', 'multimodal data', 'multimodality', 'novel', 'outcome prediction', 'personalized medicine', 'population based', 'precision medicine', 'predict clinical outcome', 'predictive marker', 'predictive modeling', 'relapse prediction', 'repository', 'response', 'single cell analysis', 'single cell technology', 'single-cell RNA sequencing', 'synergism', 'tool', 'transcriptome sequencing', 'transcriptomics', 'tumor']",NIGMS,"CYTOBANK, INC.",R44,2019,652516,-0.0037305246246320573
"Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning There is an enormous need for qualified people to pursue careers in STEM (Noonan, 2017). However, the lack of a strong foundation in mathematics means students are less likely to pursue STEM majors and careers (Chen, 2013; Griffith, 2010; Huang, Taddese, & Walter, E, 2000; Kokkelenberg & Sinha, 2010; Lowell et. al., 2009). Students from low-income families, women, and underrepresented minorities are also less likely to major in STEM (Bettinger, 2010; Griffith, 2010; Hill, Corbett & Rose, 2010; Kokkelenberg & Sinha, 2010). Improving math learning in the elementary grades is important to ensure children have the essential foundational skills and strong self-efficacy beliefs to be able to succeed with later mathematics and pursue careers in STEM. With this Fast-Track grant, Class Store ( CS ) , we propose to transform the way in which students learn Number and Operations in Base Ten. CS will be an engaging, commercially available, classroom-based economy game for tablets and Chromebooks that focuses on multi-digit operations. CS will encourage conceptual understanding and build math self-efficacy for students in grades K-5 within the context of a digital, classroom-based marketplace. Within the game, students will create stores, craft objects to sell, engage in selling/purchasing transactions, and work together to increase the value of the economy. In addition, the game will utilize artificial intelligence (AI) to detect strategies students use and help teachers facilitate rich mathematical discussions thereby enhancing students’ reasoning skills. Outcomes. The proposal will encourage three main outcomes, namely: 1) algorithms for detecting math strategies students use, 2) a discussion support dashboard, and 3) algorithms for predicting at-risk status. A key research aim is to determine whether the software can predict math strategies students use and detect which students are at-risk academically as compared to standardized assessment data, which will help teachers intervene appropriately. The discussion support dashboard will help to promote rich mathematical discussion, thereby improving students’ mathematical justification and conceptual understanding. The engaging game will bolster students’ motivation and self-efficacy in mathematics. Improving students’ academic outcomes and self-efficacy in base ten during elementary school will promote later success in high school mathematics. Since the number of advanced math classes students take is correlated with likelihood to complete a STEM degree, (Chen, 2013) a distal outcome of this proposal is increasing students pursuing careers in STEM. There is an enormous need for students majoring in the fields of Science, Technology, Engineering and Mathematics (STEM), yet lacking a strong foundation in mathematics makes students, especially women, minorities and those from low-income backgrounds, less likely to pursue careers in STEM. Class Store will bolster students’ mathematics abilities, including mathematical reasoning and self-efficacy, in the foundational area of Number and Operations in Base 10 in the short and long term. This will, in turn, lead to several positive distal outcomes, such as increased STEM majors and careers.",Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning,9852112,R44GM130197,"['Achievement', 'Algorithms', 'Area', 'Artificial Intelligence', 'Belief', 'Child', 'Code', 'Computer software', 'Data', 'Data Files', 'Detection', 'Digit structure', 'Distal', 'Elements', 'Ensure', 'Foundational Skills', 'Foundations', 'Goals', 'Grant', 'High School Student', 'Intervention', 'Investments', 'Lead', 'Learning', 'Low income', 'Marketing', 'Mathematics', 'Measures', 'Minority', 'Modeling', 'Outcome', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Research', 'Risk', 'STEM field', 'Sales', 'Scheme', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self Efficacy', 'Standardization', 'Structure', 'Students', 'Tablets', 'Testing', 'Transact', 'Underrepresented Minority', 'Woman', 'Work', 'base', 'career', 'dashboard', 'design', 'digital', 'elementary school', 'experience', 'field study', 'fifth grade', 'fourth grade', 'high school', 'improved', 'iterative design', 'lower income families', 'mathematical ability', 'mathematical learning', 'mathematical theory', 'operation', 'prediction algorithm', 'prototype', 'second grade', 'skills', 'student participation', 'success', 'support tools', 'teacher', 'usability']",NIGMS,"TEACHLEY, LLC",R44,2019,413898,0.02652493499100191
"Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership ﻿    DESCRIPTION (provided by applicant): The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The aims to achieve the goals are: 1) Implement an integrated didactic program to enhance student self-efficacy with computational and informatics tool development and use for interrogating and interpreting Big Data, including a two-semester bioinformatics course in Bioinformatics, informed by the expertise of UIUC KnowEnG BD2K Center faculty with additional Special Topics courses available remotely from UIUC. 2) Develop an integrated academic year (Fisk, or partners) and summer research program at the UIUC KnowEnG BD2K Center to assure student exposure to a participation in the life cycle of a `Big Data' research problem. 3) Implement a professional skills development program that assures successful transition of undergraduate participants to a Ph.D. (or MD/PhD Program) in Big Data- reliant biomedical research. 4) Launch a faculty development program in bioinformatics that leads to embracing Big Data problems in courses in multiple disciplines for impact on all Fisk undergraduate STEM majors. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fisk R25 mentors, of value for their broader education and research training goals at UIUC and Mayo. PUBLIC HEALTH RELEVANCE: The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fis R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.  ",Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership,9729464,R25MD010396,"['Address', 'Articulation', 'Base Pairing', 'Big Data', 'Big Data Methods', 'Big Data to Knowledge', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Career Choice', 'Cellular biology', 'Chemicals', 'Collaborations', 'Communication', 'Complement', 'Computers', 'Core Facility', 'Development Plans', 'Discipline', 'Doctor of Philosophy', 'Education Projects', 'Educational Curriculum', 'Educational workshop', 'Elements', 'Exposure to', 'Faculty', 'Faculty Workshop', 'Fostering', 'Funding', 'Genomics', 'Goals', 'Grant', 'Illinois', 'Informatics', 'Journals', 'Learning', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Manuscripts', 'Mathematics', 'Mentors', 'Molecular Biology', 'Oral', 'Participant', 'Program Development', 'Proteomics', 'Reading', 'Research', 'Research Ethics', 'Research Personnel', 'Research Training', 'Role', 'STEM field', 'Science', 'Scientist', 'Self Efficacy', 'Students', 'Systems Biology', 'Teacher Professional Development', 'Technology', 'Time', 'Training', 'Training Programs', 'Training and Education', 'Underrepresented Minority', 'Universities', 'Work', 'Writing', 'base', 'career', 'computer science', 'computerized tools', 'data acquisition', 'data sharing', 'deep learning', 'experience', 'faculty research', 'individualized medicine', 'informatics\xa0tool', 'innovation', 'minority scientist', 'posters', 'programs', 'public health relevance', 'recruit', 'responsible research conduct', 'skill acquisition', 'skills', 'summer research', 'tool development', 'undergraduate research', 'undergraduate student']",NIMHD,FISK UNIVERSITY,R25,2019,216000,0.056210408849727125
"Administrative Supplement to the OAIC Pepper Center Coordinating Center We wish to advantage of 2 new key opportunities that could significantly enhance achievement of the overall goals of the OIAC Coordinating Center (OAIC CC) and 2 key, unexpected administrative needs. Project 1) Develop, test and implement an innovative set of tools to perform Integrative Data Analysis (IDA) for combining and analyzing independent data sets across the OAIC network An over-arching goal of the OAIC CC is to build collaborations between OAICs that unlock synergy. Each of the OAICs has many small/medium-sized completed studies relevant to the OAIC theme, and that have measured key domains of physical function. Combining these studies could provide large, powerful databases for answering critical questions not possible with individual studies. However, this is currently not possible because different measurement instruments are often used across centers and across studies. This project overcomes this critical limitation by taking advantage of 2 newly available technologies and an ongoing study. IDA is a set of strategies in which two or more independent data sets which contain measures addressing similar domains but using different measurement instruments are combined into one and then statistically analyzed. The proposed project is timely because it leverages an ongoing clinical study to validate new procedures for harmonizing measures of physical and cognitive function across 20 Pepper center studies. The resources created by the project will significantly enhance collaboration across the OAIC program network, benefiting researchers at all OAICs, and can be disseminated to other NIA center programs. Project 2) Develop a robust, interactive database of OAIC Program accomplishments that will automatically be updated via an efficient, streamlined, electronic annual reporting process.  It is widely believed that the NIA-funded Pepper Center program has been highly productive. However, there is no means of assessing the overall effectiveness of the Pepper Center, or of ‘cataloging’ its impressive accomplishments. This project will take advantage of new open-source technology to efficiently develop a robust, comprehensive, searchable, interactive database of past accomplishments. It will also develop a streamlined electronic Annual Directory Report template, and link it to the new OAIC database so that it is automatically updated each year. Achieving the goals of this project will reduce administrative burden for sites, facilitate NIA review of performance of centers, and create an annually updated database of OAIC accomplishments, projects, publications, and outcomes, and facilitate collaborations between centers and investigators across NIA programs. This application also requests support for 2 key, unexpected administrative needs that have arisen: 1) Increase in funding amount for the annual OAIC CC Multi-center pilot project. 2) Support for additional Pepper Centers that will soon be added to the OAIC network. Relevance Statement for OAIC Coordinating Center Administrative Supplement The Coordinating Center of the OAIC coordinates the activities of all the individual centers in the NIA- funded, OAIC network; its over-arching goal is to build collaborations between the individual OAICs and thereby unlock synergy and enable projects that could not be undertaken by any single OAIC center. This administrative supplement application proposes 2 developmental projects that will significantly enhance the capabilities of the OAIC to achieve these goals and which takes advantage of newly available methods and technology. This also includes additional support for the possible increase in the number of Pepper Centers and an increase in the pilot award budget.",Administrative Supplement to the OAIC Pepper Center Coordinating Center,9961004,U24AG059624,"['Achievement', 'Address', 'Administrative Supplement', 'Aging', 'Annual Reports', 'Award', 'Budgets', 'Capsicum', 'Cataloging', 'Catalogs', 'Clinical', 'Clinical Research', 'Cognition', 'Collaborations', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Directories', 'Effectiveness', 'Elderly', 'Equipment and supply inventories', 'Evaluation', 'Funding', 'Goals', 'Health', 'Individual', 'Link', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Online Systems', 'Outcome', 'Participant', 'Performance', 'Physical Function', 'Pilot Projects', 'Procedures', 'Process', 'Psychometrics', 'Publications', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Site', 'Source', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Update', 'Walking', 'analytical method', 'analytical tool', 'base', 'cognitive function', 'cost effective', 'data modeling', 'forest', 'innovation', 'instrument', 'interest', 'lifestyle intervention', 'new technology', 'novel', 'open source', 'programs', 'recruit', 'response', 'synergism', 'theories', 'tool']",NIA,WAKE FOREST UNIVERSITY HEALTH SCIENCES,U24,2019,149775,0.0166493823758666
"IGF::OT::IGF  BIOINFORMATICS SUPPORT FOR THE NIEHS IN DIR & DNTP The purpose of this contract is to provide bioinformatic support to researchers in the Divisions of National Toxicology Program (DNTP) and Intramural Research (DIR) at the National Institute of Environmental Health Sciences (NIEHS). NIEHS researchers conduct studies that produce large amounts of data, varying in size and complexity. Fields of scientific study are diverse and include toxicology, genomics, transcriptomics, high throughput screening (HTS) data and data extraction from diverse text resources. The variety and complexity of NIEHS scientific studies dictates the need for innovative analytical techniques and the development of new software tools. Bioinformatic data analyses are required to support accurate and precise interpretation of study results. Specific bioinformatics needs include data analysis, data mining, creating bioinformatics pipelines for gene expression and pathway analysis and computational support for the vast amount of data collected through studies conducted at NIEHS and NIEHS contract laboratories. n/a",IGF::OT::IGF  BIOINFORMATICS SUPPORT FOR THE NIEHS IN DIR & DNTP,9915697,73201700001C,"['Artificial Intelligence', 'Bioinformatics', 'Biological Assay', 'ChIP-seq', 'Chemical Exposure', 'Chemicals', 'Contractor', 'Contracts', 'DNA Methylation', 'DNA Sequence', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Epigenetic Process', 'Evaluation', 'Exons', 'Gene Expression', 'Genes', 'Genomics', 'Informatics', 'Intramural Research', 'Knowledge', 'Laboratories', 'Literature', 'Measures', 'Mining', 'National Institute of Environmental Health Sciences', 'National Toxicology Program', 'Output', 'Pathway Analysis', 'Peer Review', 'Privatization', 'Programming Languages', 'Proteomics', 'Publications', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Sampling', 'Scientific Evaluation', 'Scientist', 'Series', 'Software Tools', 'Specific qualifier value', 'Technology', 'Text', 'Toxicogenomics', 'Toxicology', 'analysis pipeline', 'bioinformatics tool', 'bisulfite sequencing', 'cheminformatics', 'computational intelligence', 'data integration', 'data mining', 'differential expression', 'high throughput screening', 'innovation', 'meetings', 'metabolomics', 'method development', 'next generation sequencing', 'physical property', 'programs', 'screening', 'technique development', 'transcriptomics', 'whole genome']",NIEHS,"SCIOME, LLC",N01,2019,2464037,0.005794611444858666
"A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers PROJECT SUMMARY/ABSTRACT  This application, “A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,” is in response to PAR-16-238, Dissemination and Implementation Research in Health (R01). Acute respiratory distress syndrome (ARDS) has high prevalence (10% of intensive care unit admissions) and mortality up to 46%. Low tidal volume ventilation (LTVV) is the most effective therapy for ARDS, lowering mortality by 20-25%, and is part of standard practice. However, use of LTVV is as low as 19% of ARDS patients. There is a poor understanding of the barriers to LTVV adoption: current approaches are deficient because they incorporate biases, lack consistency and comprehensiveness, ignore the influence of interpersonal network- or team- based factors, and do not address setting-specific variation. Our research team has previously identified some patient- and clinician-specific facilitators of and barriers to LTVV adoption. We have used two state-of-the-art data driven methods—data science and network analysis—to preliminarily quantify the impact of a diverse array of potential factors affecting LTVV adoption, including network- and team-based factors. The proposed research is guided by the Consolidated Framework for Implementation Research (CFIR) and Rogers' Diffusion of Innovations theory. The overall goals of the proposed research are to understand the differences in facilitators and barriers to LTVV adoption between academic and community settings through a definitive, systematic study in a large, diverse consortium of medical centers, and to advance implementation science by providing a model for how data science and network analysis can be applied to understand the adoption of a complex intervention. The overarching hypothesis is that there are different patient-, clinician-, network-, and team-based facilitators and barriers to LTVV adoption in academic and community settings. We will determine whether different patient- and clinician- (Aim 1 cohort study, clinician survey, and data science analysis), clinician interpersonal network- (Aim 2 network analysis), and team structure and dynamics-based (Aim 3 team construction and modeling) facilitators of and barriers to LTVV adoption exist between academic and community hospital settings. Successful completion of the proposed research will provide a comprehensive understanding of the differences in the facilitators of and barriers to LTVV adoption between academic and community settings, and will advance implementation science by serving as a model of how data science and network analysis can be applied to complex implementation problems. Implementation strategies that account for all these factors may be more likely to lead to significant practice change. PROJECT NARRATIVE  Acute respiratory distress syndrome (ARDS) has high prevalence and mortality among critically ill patients; low tidal volume ventilation is the most effective therapy for ARDS but is used infrequently. Successful completion of the proposed research will identify differences in the facilitators of and barriers to adoption of low tidal volume ventilation between academic and community hospital settings in a large and diverse consortium of medical centers. The proposed research will generate a model of how data science and network analysis can be used to understand the implementation of a complex evidence-based practice.",A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,9781491,R01HL140362,"['Acute', 'Admission activity', 'Adoption', 'Adult Respiratory Distress Syndrome', 'Affect', 'Attitude', 'Caring', 'Characteristics', 'Cohort Studies', 'Community Hospitals', 'Complex', 'Critical Illness', 'Data', 'Data Science', 'Diffusion of Innovation', 'Environment', 'Environmental air flow', 'Evidence based practice', 'Goals', 'Health', 'Healthcare Systems', 'Height', 'High Prevalence', 'Hypoxemia', 'Individual', 'Inflammatory', 'Intensive Care Units', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Medical center', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'Nurses', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Professional Organizations', 'Pulmonary Edema', 'Research', 'Severities', 'Speed', 'Structure', 'Surveys', 'Syndrome', 'System', 'Testing', 'Tidal Volume', 'Variant', 'base', 'community setting', 'computer science', 'dissemination research', 'effective therapy', 'experimental study', 'health care settings', 'implementation research', 'implementation science', 'implementation strategy', 'learning strategy', 'lung injury', 'mortality', 'multidisciplinary', 'novel', 'research data dissemination', 'respiratory', 'response', 'theories']",NHLBI,NORTHSHORE UNIVERSITY HEALTHSYSTEM,R01,2019,747700,0.005072721312108212
"CSHL Computational and Comparative Genomics Course The Cold Spring Harbor Laboratory proposes to continue a course entitled “Computational and Comparative Genomics”, to be held in the Fall of 2017 – 2019. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases that they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions. NARRATIVE The Computational & Comparative Genomics, a 9 day course, is designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.",CSHL Computational and Comparative Genomics Course,9724498,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'Course Content', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genome', 'Home environment', 'Institution', 'International', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Research Training', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Training Programs', 'Universities', 'Update', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'graduate student', 'instructor', 'interest', 'laboratory experience', 'lecturer', 'programs', 'promoter', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2019,67704,0.0003234322433067134
"Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome Addiction is a highly complex disease with risk factors that include genetic variants and differences in development, sex, and environment. The long term potential of precision medicine to improve drug treatment and prevention depends on gaining a much better understanding how genetics, drugs, brain cells, and neuronal circuitry interact to influence behavior. There are serious technical barriers that prevent researchers and clinicians from incorporating more powerful computational and predictive methods in addiction research. The purpose of the NIDA P30 Core Center of Excellence in Omics, Systems Genetics, and the Addictome is to empower and train researchers supported by NIH, NIDA, NIAAA, and other federal and state institutions to use more quantitative and testable ways to analyze genetic, epigenetic, and the environmental factors that influence drug abuse risk and treatment. In the Transcriptome Informatics and Mechanisms research core we assemble and upgrade hundreds of large genome (DNA) and transcriptome (RNA) datasets for experimental rodent (rat) models of addiction. In the Systems Analytics and Modeling research core, we are using innovative systems genetics methods (gene mapping) to understand the linkage between DNA differences, environmental risks such as stress, and the differential risk of drug abuse and relapse. Our Pilot core is catalyzing new collaborations among young investigator in the field of addiction research. In sum the Center is a national resource for more reproducible research in addiction. We are centralizing, archiving, distributing, analyzing and integrating high quality data, metadata, using open software systems in collaboration with many other teams of researchers. Our goal is to help build toward an NIDA Addictome Portal that will include all genomic research relevant to addiction research. PROJECT NARRATIVE The NIDA Core Center of Excellence in Omics, Systems Genetics, and the Addictome (OSGA) provides genomic and computational support to a large number of research scientists working on mechanisms and treatment of addiction. The two main research cores of OSGA are providing support for transcriptome, epigenome, and metagenome studies of rat models of addiction at many levels of analysis. We are also creating open access tools and a powerful web portal to catalyze more effective and replicable use of massive datasets generated by programs in addiction biology and treatment.","Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome",9716628,P30DA044223,"['Archives', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Bioinformatics', 'Biology', 'Biometry', 'Cellular Assay', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consult', 'DNA', 'DNA Sequence', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Interactions', 'Drug abuse', 'Educational workshop', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Epigenetic Process', 'Foundations', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Hybrids', 'Image', 'Imagery', 'Informatics', 'Institution', 'Joints', 'Leadership', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences Research', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Prevention', 'Proteome', 'Publications', 'Publishing', 'Quantitative Genetics', 'Quantitative Trait Loci', 'RNA', 'Rattus', 'Relapse', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Rodent', 'Role', 'Scientist', 'Site', 'Standardization', 'Statistical Models', 'Stress', 'Sum', 'System', 'Systems Analysis', 'Testing', 'Training', 'Translations', 'United States National Institutes of Health', 'Update', 'Variant', 'Work', 'addiction', 'base', 'behavior influence', 'brain cell', 'career', 'cohort', 'computerized tools', 'computing resources', 'data archive', 'data integration', 'data modeling', 'data warehouse', 'deep learning', 'digital imaging', 'drug relapse', 'epigenome', 'experience', 'genetic analysis', 'genetic variant', 'genomic variation', 'graphical user interface', 'health record', 'high dimensionality', 'improved', 'innovation', 'insight', 'metagenome', 'mouse model', 'multiple omics', 'neurogenomics', 'neuronal circuitry', 'novel', 'precision medicine', 'prevent', 'programs', 'ranpirnase', 'rat genome', 'repository', 'sex', 'single cell analysis', 'software systems', 'tool', 'transcriptome', 'transcriptomics', 'web portal']",NIDA,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,P30,2019,763474,-0.006378251379133539
"The Center for Innovation in Intensive Longitudinal Studies (CIILS) PROJECT SUMMARY Significance. The Intensive Longitudinal Behavior Network (ILHBN) provides an unprecedented opportunity to advance and shape the future landscape of health behavior science and related intervention practice. The proposed Research Coordinating Center, the Center for Innovation in Intensive Longitudinal Studies (CIILS), housed at the Pennsylvania State University (Penn State), will bring together an interdisciplinary team to synergistically support and coordinate research activities across a diverse portfolio of anticipated U01 projects to accomplish the Network’s larger goal of sustained innovation in the use of intensive longitudinal data (ILD) and associated methods in the study of health behavior change, and in informing prevention and intervention designs. Innovation. The proposed organizational structure of the ILHBN as a small-world network is motivated by our team’s collective decades of experience with multidisciplinary and multi-site collaborations, and is designed to facilitate information flow, collective decision making, and coordination of goals and effort within the ILHBN. Approach. CIILS consists of five Cores with expertise in management of multi-site projects and coordinating centers (Administrative Core); development of novel methods for analysis of ILD (Methods Core); ILD collection, harmonization, sharing, security, as well as collection of digital footprints (Data Core); ILD design, harmonization and instrumentation support (Design Core); and integration of health behavior theories, translation, and implementation of within-person health preventions/interventions (Theory Core). Key personnel with rich and complementary expertise are supported by a roster of advisory Co-Is at Penn State and distributed consultants who are leaders and innovators in their respective fields. Institutional support and contributed staff time by Penn State provide robust infrastructure, expertise, and “boots on the ground” to support the operation and coordination activities of ILHBN; and a wealth of additional resources to elevate and broaden the collective impacts of the Network. PROJECT NARRATIVE This project proposes an RCC, the Center for Innovation in Intensive Longitudinal Studies (CIILS), housed at the Pennsylvania State University, to provide a repertoire of expertise and resources to support the Intensive Longitudinal Health Behavior Network (ILHBN). Our interdisciplinary team – consisting of social scientists with expertise in design and management of intensive longitudinal studies; methodological experts who are leading figures in developing novel within-person analytic techniques; health theorists and prevention/intervention experts well-versed in the translation of health theories into within-person health intervention; cyberscience experts with expertise in collection of digital footprints, data security and data sharing issues; and administrative personnel with expertise in management and coordination of network activities – is uniquely poised to advance the collective innovations of the ILHBN by synergistically supporting and coordinating research activities across a diverse portfolio of anticipated U01 projects.",The Center for Innovation in Intensive Longitudinal Studies (CIILS),9788202,U24AA027684,"['Administrative Personnel', 'Algorithms', 'Behavior', 'Big Data', 'Collaborations', 'Collection', 'Communication', 'Communities', 'Consultations', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Security', 'Databases', 'Decision Making', 'Development', 'Devices', 'Future', 'General Population', 'Goals', 'Health', 'Health Sciences', 'Health behavior', 'Health behavior change', 'Healthcare', 'Human Resources', 'Individual', 'Infrastructure', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Neurobiology', 'Pennsylvania', 'Persons', 'Positioning Attribute', 'Preventive Intervention', 'Privacy', 'Process', 'Production', 'Progress Reports', 'Protocols documentation', 'Publications', 'Records', 'Regulation', 'Reporting', 'Research', 'Research Activity', 'Research Design', 'Resources', 'Science', 'Scientist', 'Security', 'Shapes', 'Site', 'Social Work', 'Source', 'Structure', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Training', 'Translations', 'United States National Institutes of Health', 'Universities', 'Update', 'Visualization software', 'Workplace', 'control theory', 'data management', 'data portal', 'data sharing', 'data visualization', 'data warehouse', 'design', 'digital', 'dynamic system', 'experience', 'human subject', 'innovation', 'instrumentation', 'member', 'multidisciplinary', 'novel', 'operation', 'organizational structure', 'preservation', 'social', 'success', 'theories', 'therapy design', 'tool']",NIAAA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,U24,2019,114747,0.003983265503648803
"AUGS/DUKE UrogynCREST program PROJECT SUMMARY Health Services Research (HSR) and predictive analytics are rapidly growing fields and will have enormous implications for women’s health research in pelvic floor disorders (PFDs). The AUGS/DUKE Urogynecology Clinical Research Educational Scientist Training (UrogynCREST) program will prepare participants to recognize the critical role that data play in delivering high quality health care. It brings together expertise in health service and women’s health research, medical informatics and prediction modeling. This program will target Urogynecology Faculty at the Assistant Professor level who seek successful careers in health services research (HSR) and analytics. Participants will obtain skills through a combination of didactic and interactive coursework; hands-on manipulation of data through extraction, cleaning, and analysis; and project-based one on one mentoring. The UrogynCREST program will be an interactive, hands-on educational program with centralized activities organized and delivered by distance through a popular on-line learning platform called Sakai, with educational software designed to support teaching, research and collaboration. A diverse faculty with expertise in data sciences teaches courses and the advanced methodology required to perform HSR. Yearly in-person meetings at the annual American Urogynecologic Society meeting enhance networking and the development of partnerships between participants from various institutions, as well as, interactions with the mentors and other HSR in the field. The program’s strategy allows national leaders with particular skills in the field to provide their knowledge to the participants and help mentor them through development of a relevant research question and identification of an appropriate and existing database(s) to address the question. With the guidance of a dedicated statistician and analyst programmer, participants will learn and perform the necessary computer programming needed to extract, clean and analyze these data. Participants whose projects involve the development of prediction models in the form of scores, nomograms or other tools will learn how to build and validate such tools in the existing project. Each participant’s project will culminate in the completion of a submitted manuscript to a peer- reviewed journal or study proposal and publicly available tools when relevant. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and resources for invigorating data discovery and tools for investigations in HSR specifically addressing (PFDs). PROJECT NARRATIVE: The AUGS/DUKE UrogynCREST program will prepare participants to recognize the critical role that data play in delivering high quality health care for pelvic floor disorders. It will add structure to the health data science education for Assistant Professor Level Faculty in Urogynecology by bringing together expertise in health service and women’s health research, medical informatics, and prediction modeling. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and mentorship for invigorating data discovery and tools for investigations in health service research specifically addressing pelvic floor disorders.",AUGS/DUKE UrogynCREST program,9703267,R25HD094667,"['Address', 'Age', 'American', 'Area', 'Caring', 'Clinical Research', 'Collaborations', 'Communities', 'Connective Tissue', 'Data', 'Data Discovery', 'Data Science', 'Databases', 'Development', 'E-learning', 'Educational process of instructing', 'Faculty', 'Fecal Incontinence', 'Fostering', 'Future', 'Goals', 'Health Services', 'Health Services Research', 'Healthcare', 'Infrastructure', 'Institution', 'Instruction', 'Investigation', 'Journals', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Manuscripts', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modernization', 'Muscle', 'Nomograms', 'Participant', 'Peer Review', 'Pelvic Floor Disorders', 'Pelvis', 'Persons', 'Play', 'Predictive Analytics', 'Process', 'Public Health', 'Research', 'Resources', 'Role', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Shapes', 'Societies', 'Software Design', 'Structure', 'Techniques', 'Testing', 'Training Programs', 'Urinary Incontinence', 'Woman', 'Women&apos', 's Health', 'base', 'career', 'clinical decision-making', 'clinical development', 'computer program', 'computer science', 'design', 'health care quality', 'health data', 'improved', 'injured', 'innovation', 'meetings', 'pelvic organ prolapse', 'predictive modeling', 'professor', 'programs', 'recruit', 'science education', 'skills', 'social', 'tool']",NICHD,DUKE UNIVERSITY,R25,2019,161462,0.0196010517068736
"COINSTAC: Decentralized, Scalable Analysis of Loosely Coupled Data The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the dat as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community becomes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group).    The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates  dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented storage vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and privacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix factorization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities. PUBLIC HEALTH RELEVANCE: Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don't have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this 'missing data' and allow for pooling of both open and 'closed' repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed computational solution for a large toolkit of widely used algorithms.","COINSTAC: Decentralized, Scalable Analysis of Loosely Coupled Data",9938885,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithmic Analysis', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Set', 'Decentralization', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'Intelligence', 'International', 'Knowledge', 'Language', 'Letters', 'Linear Models', 'Location', 'Logistics', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Source', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'Validation', 'base', 'commune', 'computational platform', 'computer framework', 'computing resources', 'connectome', 'cost', 'data anonymization', 'data sharing', 'distributed data', 'flexibility', 'imaging genetics', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'open data', 'peer', 'preservation', 'public health relevance', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2019,585151,0.013223679113036327
"Augmented Reality Platform for Feedback and Assessment in STEM elementary education ABSTRACT This SBIR Phase I project will build evidence-based content, challenges and assessments that promote: simulation-based learning; troubleshooting and critical-thinking; and diversity and inclusion in STEM learning. The approach will be transferable by design to teaching and measuring learner performance across scientific disciplines. Emerging digital content in virtual (VR) and augmented reality (AR) is already transforming science, technology, engineering, and math (STEM) education from the abstract and static learning models of the past to the applied and dynamic learning experiences of the future. These technologies have promise in delivering simulation environments capable of nurturing deep learning and higher-level thinking in K-12 students through practical experience, hand-on exercises and real-life applications, such as troubleshooting. Digital AR and VR educational content is beginning to address and develop these skills, but a platform has yet to be developed to effectively enable broad adoption in elementary settings. Cost efficient methods to provide formative feedback and gather summative evaluations for Next Generation Science Standards (NGSS) is also an unmet need. The successful completion of the proposed project will provide an evidence-centered content delivery and assessment framework as well as tool for addressing NGSS performance expectations that is transferable across topic areas and readily scalable for large-scale national implementation. The content will intentionally incorporate aspects of context and diversity of characters to ensure inclusion of groups that are historically underrepresented – specifically females and ethnic minorities. NARRATIVE Success in the workforce of the future will require the high-level thinking skills that the Next Generation Science Standards (NGSS) emphasize. Emerging digital content in virtual (VR) and augmented reality (AR) is transforming science and engineering education from the abstract and static learning models of the past to the applied and dynamic learning experiences of the future, through practical simulation-based experiences, but these lack the capability for performance assessment crucial to teachers and decision makers. By providing a readily scalable and flexible platform, the proposed approach promises to accelerate access to high-quality, inclusive, and evidence-centered AR content delivery and assessment of NGSS standards which in turn provides students with the skills they need for success.",Augmented Reality Platform for Feedback and Assessment in STEM elementary education,9847434,R43GM134813,"['Address', 'Adoption', 'Area', 'Augmented Reality', 'Award', 'Businesses', 'Career Choice', 'Child', 'Critical Thinking', 'Data', 'Development', 'Discipline', 'E-learning', 'Education', 'Educational process of instructing', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Exercise', 'Feedback', 'Female', 'Funding', 'Future', 'Hand', 'Indiana', 'Industry', 'K-12 student', 'Learning', 'Life', 'Longevity', 'Mathematics', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Next Generation Science Standards', 'Output', 'Perception', 'Performance', 'Phase', 'Problem Solving', 'Process', 'Reporting', 'Research', 'SECTM1 gene', 'Science', 'Science, Technology, Engineering and Mathematics', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Small Business Innovation Research Grant', 'Students', 'System', 'Technology', 'Testing', 'Thinking', 'Translating', 'Universities', 'Validation', 'Woman', 'Writing', 'Youth', 'base', 'cost efficient', 'deep learning', 'design', 'digital', 'digital media', 'educational atmosphere', 'engineering design', 'ethnic minority population', 'evidence base', 'expectation', 'experience', 'flexibility', 'girls', 'innovation', 'interest', 'mathematical learning', 'mobile application', 'pedagogy', 'prototype', 'simulation', 'simulation game', 'skills', 'success', 'teacher', 'theories', 'tool', 'virtual', 'virtual reality']",NIGMS,"EXPLORE INTERACTIVE, LLC",R43,2019,295622,0.007988327852362639
"LSUHSC-New Orleans Postbaccalaureate Research Education Program in Biomedical Sciences PROJECT SUMMARY/ABSTRACT The overall goal of the Postbaccalaureate Research Education Program (PREP) in Biomedical Sciences (BMS) at the Louisiana State University Health Sciences Center in New Orleans (LSUHSC-NO) is to enhance the diversity of the research workforce by increasing competitiveness for acceptance and completion of PhD and MD/PhD programs by underrepresented minorities (URM). LSUHSC-NO PREP will accept 39 recent URM baccalaureate science graduates over 5 yrs for intensive research and innovative academic training experi- ences to foster success in BMS doctoral degree programs. Over 300 URM science baccalaureates are award- ed annually to URM students by universities located within 100 miles of LSUHSC-NO representing 32% of all science degrees; however, URM constitute only 10% of enrolled PhD and MD/PhD students nationwide, and 12% at LSUHSC-NO. The PREP will enhance competitiveness for acceptance, retention, and completion of BMS PhD programs by the Scholars by providing 1) intensive research experiences with committed research faculty, and 2) complementary skills development during the 1-yr training. PREP training will focus on building solid foundations in research skills by providing concentrated education in scientific critical thinking, analysis of results, statistics, and writing; inventive and personalized test-taking skills to improve GRE scores and success in graduate courses; oral and poster scientific presentations; responsible and ethical conduct in research; and writing a resume, personal statement, and selecting and applying to graduate schools. Scholars will participate in works-in-progress, journal clubs, and workshops hosted by PREP faculty, visitors, and recruitment contacts; join graduate students in skills development programs; present their research at the annual PREP poster sym- posium and local and national scientific conferences; mentor summer research fellows; and assist in communi- ty science education programs. The PREP will provide forums for the Scholars to engage in research and skills acquisition and active demonstration of knowledge. Over 60 LSUHSC-NO active research faculty, committed to the PREP, have extensive experience in mentoring high school, undergraduate, medical, predoctoral, and postdoctoral students representing URM in the BMS through NIH T32, R25, R35, and other funding mecha- nisms. There are 8 active LSUHSC-NO summer programs which provide research experiences to 75 URM fel- lows annually from which future PREP Scholars will be prescreened and recruited. Scholar recruitment efforts will extend to 4 local historically black colleges and 2 state universities to develop a community-wide mecha- nism to support the URM BMS workforce. The program will be critically evaluated using formative and summa- tive methodologies and descriptive, quantitative, and qualitative statistics to document success. The overall goal is for PREP Scholars to have an enhanced competitiveness for acceptance into rigorous graduate pro- grams with the confidence and essential research skills required to earn a PhD or MD/PhD degree, establish rewarding and successful BMS research careers, and serve as role-models for future URM students. PROJECT NARRATIVE The goal of the LSUHSC-NO PREP is to prepare individuals from backgrounds underrepresented in the biomedical sciences, who have recently completed their baccalaureate science degrees, for successful enrollment, retention, and completion of a PhD or MD-PhD training program. We aim to enhance the diversity of the biomedical research workforce by preparing PREP Scholars for the rigors and challenges of a biomedical doctoral degree program so that they will successfully obtain a PhD degree or MD/PhD degree and contribute their expertise to the biomedical scientific community.",LSUHSC-New Orleans Postbaccalaureate Research Education Program in Biomedical Sciences,9754847,R25GM121189,"['Academic Training', 'Anxiety', 'Award', 'Bachelor&apos', 's Degree', 'Basic Science', 'Biomedical Research', 'Centers of Research Excellence', 'Cities', 'Clinical Sciences', 'Communities', 'Critical Thinking', 'Data Analyses', 'Degree program', 'Dentistry', 'Development', 'Development Plans', 'Doctor of Philosophy', 'Doctor&apos', 's Degree', 'Education', 'Educational workshop', 'Enrollment', 'Environment', 'Ethics', 'Exercise', 'Extramural Activities', 'Faculty', 'Fostering', 'Foundations', 'Funding', 'Funding Mechanisms', 'Future', 'Goals', 'Health Sciences', 'Historically Black Colleges and Universities', 'Individual', 'Journals', 'Knowledge', 'Laboratory Research', 'Learning', 'Louisiana', 'Machine Learning', 'Manuscripts', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Minority Enrollment', 'NCI Scholars Program', 'Oral', 'Population', 'Postdoctoral Fellow', 'Program Development', 'Public Health', 'Research', 'Research Ethics', 'Research Project Grants', 'Resources', 'Rewards', 'Schools', 'Science', 'Scientist', 'Solid', 'Statistical Methods', 'Structure', 'Students', 'Study Skills', 'Sum', 'Technical Expertise', 'Testing', 'Time Management', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Visit', 'Work', 'Writing', 'career', 'design', 'doctoral student', 'education research', 'experience', 'faculty research', 'graduate student', 'gulf coast', 'high school', 'improved', 'innovation', 'invention', 'medical schools', 'member', 'minority communities', 'novel', 'posters', 'pre-doctoral', 'programs', 'recruit', 'role model', 'science education', 'skill acquisition', 'skills', 'skills training', 'statistics', 'success', 'summer program', 'summer research', 'symposium', 'undergraduate student', 'underrepresented minority student', 'university student']",NIGMS,LSU HEALTH SCIENCES CENTER,R25,2019,308173,0.036005226631489105
"UTMB Clinical and Translational Science Award UTMB's CTSA-linked KL2 Scholars Program addresses the significant need for developing future clinical and translational (C&T) investigators, with emphases on team-based research, leadership development, and mentorship training. In our new CTSA hub, we will build on our current CTSA's successes over the past 5½ years, with unique innovative integration of exceptional training approaches, including: 1) mentored career development within CTSA-supported multidisciplinary translational teams (MTTs); 2) an emphasis on individual development plans (IDPs) and pre-established C&T research competencies tailored to the needs of the individual scholar, but also emphasizing team-based competencies; 3) development of leadership competencies through participation in a new Leadership Development Academy; 4) an Academy of Research Mentors (ARM), based within our Institute for Translational Sciences (ITS), to foster mentoring and mentor training; 5) a linked Translational Research Scholars Program (TRSP), which provides an expanded peer group and a wider impact across the institution, with twice-monthly career development seminars and a focus on scholars' research; 6) development of entrepreneurial skills and leadership through participation in a UT System-funded Healthcare Entrepreneurship Program; and 7) collaboration and dissemination of program experience to other CTSA hubs in the Texas Regional CTSA Consortium, and the national CTSA Consortium. An important feature of our KL2 Scholars Program is its linked position within the continuum of career development, from graduate student training in our CTSA TL1 Training Core to the production of independently funded C&T faculty members. Our program is enhanced with by financial support from our Provost's office for scholar expenses, ITS education administrators, the ARM, and the Office of Faculty Affairs, which is focused on faculty development at UTMB. UTMB also ranks nationally in promoting diversity, which will enhance our recruitment of underrepresented minority scholars by the participation of faculty from our Hispanic Center of Excellence, and our Medical School Enrichment Program. Our KL2 Program is well-integrated with other institutional education activities, including our Human Pathophysiology and Translational Medicine graduate program, and courses targeted toward scientific writing, biostatistics, and study design. Early-career faculty as Phase 1 TRSP scholars can compete to become CTSA-supported KL2 Scholars, and with acquisition of their first mentored K-level grants (e.g., K08), advance to a Phase 2 TRSP Scholar, then focusing on the transition from mentored to independent grant funding. Upon acquisition of independent (e.g. R01) funding, scholars advance to become Phase 3 TRSP Scholars and Associate Members in the ARM, to facilitate their development of mentoring skills, and eventually to full ARM membership, with demonstrated success in C&T science mentoring. Our KL2 Scholars Program thus integrates novel team-based training, leadership, and mentoring approaches to foster the career development of future leaders in C&T research. n/a",UTMB Clinical and Translational Science Award,9689119,KL2TR001441,"['Academy', 'Address', 'Administrator', 'Biological', 'Biological Markers', 'Biometry', 'Biopsy', 'Body Surface Area', 'Burn injury', 'Characteristics', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical and Translational Science Awards', 'Collaborations', 'Competence', 'Data', 'Dependence', 'Development', 'Development Plans', 'Down-Regulation', 'Education', 'Enrollment', 'Entrepreneurship', 'Evolution', 'Expression Profiling', 'Faculty', 'Failure', 'Financial Support', 'Fostering', 'Freezing', 'Functional disorder', 'Funding', 'Future', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Grant', 'Healthcare', 'Hepatitis C virus', 'Hispanics', 'Human', 'Individual', 'Infection', 'Inflammation', 'Institutes', 'Institution', 'Interferons', 'Intervention', 'Leadership', 'Link', 'Liver Fibrosis', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Medicare', 'Medicare claim', 'Medicine', 'Mentors', 'Mentorship', 'MicroRNAs', 'Modeling', 'NCI Scholars Program', 'Participant', 'Pathway interactions', 'Patients', 'Peer Group', 'Phase', 'Physicians', 'Positioning Attribute', 'Process', 'Production', 'Protocols documentation', 'Regimen', 'Research', 'Research Design', 'Rice', 'System', 'TNFSF15 gene', 'Teacher Professional Development', 'Techniques', 'Testing', 'Texas', 'Time', 'Tissues', 'Training', 'Translational Research', 'Underrepresented Minority', 'Variant', 'Writing', 'base', 'career development', 'cohort', 'college', 'demographics', 'early-career faculty', 'experience', 'graduate student', 'innovation', 'leadership development', 'liver biopsy', 'medical schools', 'member', 'microbial', 'multidisciplinary', 'novel', 'outcome forecast', 'peripheral blood', 'predict clinical outcome', 'program dissemination', 'programs', 'recruit', 'response', 'science education', 'skills', 'structural genomics', 'student training', 'success', 'translational medicine', 'translational scientist']",NCATS,UNIVERSITY OF TEXAS MED BR GALVESTON,KL2,2019,423432,0.029434272522208087
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive, PhysioBank, was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. PhysioToolkit, its software collection, supports exploration and quantitative analyses of PhysioBank and similar data with a wide range of well-documented, rigorously tested open-source software that can be run on any platform. PhysioNet's team of researchers leverages results of other funded projects to drive the creation and enrichment of: i) Data collections that provide increasingly comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC III (Medical Information Mart for Intensive Care) Database of critical care patients; ii) Analytic methods that lead to more timely and accurate diagnoses of major public health problems (such as life-threatening cardiac arrhythmias, infant apneas, fall risk in older individuals and those with neurologic disease, and seizures), and iii) Elucidation of dynamical changes associated with a variety of pathophysiologic processes and aging (such as cardiopulmonary interactions during sleep disordered breathing syndromes); User interfaces, reference materials and services that add value and improve accessibility to PhysioNet's data and software (such as PhysioNetWorks, a virtual laboratory for data sharing). Impact: Cited in The White House Fact Sheet on Big Data Across the Federal Government (March 29, 2012), PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are inaccessible otherwise. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world- wide, growing community of researchers, clinicians, educators, students, and medical instrument and software developers, retrieve about 380 GB of data per day. By providing free access to its unique and wide-ranging data and software collections, PhysioNet is invaluable to studies that currently result in an impressive average of nearly 250 new scholarly articles per month by academic, clinical, and industry-affiliated researchers worldwide. Over the next year we aim to sustain and enhance PhysioNet's impact with new technology and data; and complete the 2019 PhysioNet/Computing in Cardiology Challenge on sepsis. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,9993811,R01GM104987,"['Aging', 'Algorithms', 'Apnea', 'Area', 'Arrhythmia', 'Big Data', 'Biomedical Research', 'Boston', 'Bypass', 'Cardiology', 'Cardiopulmonary', 'Categories', 'Clinical', 'Clinical Data', 'Cloud Service', 'Collection', 'Communities', 'Community Outreach', 'Complex', 'Computer software', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Dedications', 'Development', 'Diagnostic radiologic examination', 'Entropy', 'FAIR principles', 'Federal Government', 'Functional disorder', 'Funding', 'Grant', 'Imagery', 'Individual', 'Industry', 'Infant', 'Infrastructure', 'Intensive Care', 'Israel', 'Journals', 'Laboratories', 'Lead', 'Licensing', 'Life', 'Link', 'Machine Learning', 'Maintenance', 'Medical', 'Medical center', 'Methods', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Phase Transition', 'Physiological', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Role', 'Running', 'Seizures', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Students', 'Switzerland', 'Syndrome', 'Testing', 'Thoracic Radiography', 'Time', 'United States National Institutes of Health', 'University Hospitals', 'Visit', 'accurate diagnosis', 'analytical method', 'clinical application', 'computerized data processing', 'computing resources', 'data archive', 'data sharing', 'experience', 'fall risk', 'heart rate variability', 'improved', 'innovation', 'instrument', 'instrumentation', 'interest', 'member', 'nervous system disorder', 'new technology', 'open source', 'preservation', 'repository', 'signal processing', 'software repository', 'symposium', 'time interval', 'virtual laboratory']",NIGMS,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2019,409563,-0.007984621454350185
"Semantic Data Lake for Biomedical Research Capitalizing on the transformative opportunities afforded by the extremely large and ever-growing volume, velocity, and variety of biomedical data being continuously produced is a major challenge. The development and increasingly widespread adoption of several new technologies, including next generation genetic sequencing, electronic health records and clinical trials systems, and research data warehouses means that we are in the midst of a veritable explosion in data production. This in turn results in the migration of the bottleneck in scientific productivity into data management and interpretation: tools are urgently needed to assist cancer researchers in the assembly, integration, transformation, and analysis of these Big Data sets. In this project, we propose to develop the Semantic Data Lake for Biomedical Research (SDL-BR) system, a cluster-computing software environment that enables rapid data ingestion, multifaceted data modeling, logical and semantic querying and data transformation, and intelligent resource discovery. SDL-BR is based on the idea of a data lake, a distributed store that does not make any assumptions about the structure of incoming data, and that delays modeling decisions until data is to be used. This project adds to the data lake paradigm methods for semantic data modeling, integration, and querying, and for resource discovery based on learned relationships between users and data resources. The SDL-BR System is a distributed computing software solution that enables research institutions to manage, integrate, and make available large institutional data sets to researchers, and that permits users to generate data models specific to particular applications. It uses state of the art cluster computing, Semantic Web, and machine learning technologies to provide for rapid data ingestion, semantic modeling and querying, and search and discovery of data resources through a sophisticated, Web-based user interface.",Semantic Data Lake for Biomedical Research,9765194,R44CA206782,"['Acute', 'Address', 'Adoption', 'Area', 'Big Data', 'Biomedical Computing', 'Biomedical Research', 'Catalogs', 'Chronic Myeloid Leukemia', 'Clinical', 'Clinical Trials', 'Collection', 'Colorectal Cancer', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Discovery', 'Data Quality', 'Data Science', 'Data Set', 'Data Sources', 'Demographic Factors', 'Development', 'Electronic Health Record', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Evaluation', 'Explosion', 'Generations', 'Genetic', 'Genetic Markers', 'High-Throughput Nucleotide Sequencing', 'Individual', 'Informatics', 'Ingestion', 'Institution', 'Intelligence', 'Knowledge', 'Knowledge Extraction', 'Legal', 'Legal patent', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Monitor', 'Non-Small-Cell Lung Carcinoma', 'Online Systems', 'Ontology', 'Phase', 'Policies', 'Precision therapeutics', 'Procedures', 'Process', 'Production', 'Productivity', 'Recommendation', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Security', 'Semantics', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Testing', 'Vocabulary', 'Work', 'base', 'cancer therapy', 'clinical data warehouse', 'cluster computing', 'computer based Semantic Analysis', 'cost effective', 'data access', 'data exchange', 'data integration', 'data management', 'data modeling', 'data resource', 'data warehouse', 'design', 'disease heterogeneity', 'experience', 'genetic information', 'handheld mobile device', 'indexing', 'individualized medicine', 'melanoma', 'migration', 'natural language', 'new technology', 'next generation', 'novel', 'off-patent', 'precision medicine', 'prototype', 'success', 'systems research', 'targeted treatment', 'technology development', 'time use', 'tool']",NCI,"INFOTECH SOFT, INC.",R44,2019,238768,-0.013619005250789505
"Accelerating collaborative, cumulative, and open intervention science with an e-intervention authoring platform Background. Research has identified a wide range of evidence-based interventions for key behavioral health risks such as poor diet, smoking, unhealthy alcohol use, or a sedentary lifestyle. However, to be truly successful, behavioral intervention science should fulfill at least three key criteria: (1) demonstration of cumulative increases in intervention efficacy; (2) provision of interventions that reach a high proportion of those in need; and (3) demonstration of a meaningful population impact/reduction in disease burden. It currently meets none of these. Some reasons for this include (1) over-reliance on an imprecise delivery mechanism (people; usually therapists or coaches of some kind) that is difficult to train to fidelity on a large scale, and that cannot be manipulated with precision; (2) use of sample sizes that may be far below what is needed to accurately characterize heterogeneity of response; and (3) cross-study variability in therapist characteristics, sample characteristics, and measurement strategy. All of this combines to create a science that lacks evidence of cumulative improvements upon prior benchmarks. Proposed solution. Mobile technology shows significant promise as an intervention delivery mechanism that is replicable, transparent, modular, and precise. However, progress in the development and implementation of mobile interventions has been slowed by factors such as the tremendous time and money needed to develop an intervention; limitations in cross-platform compatibility and interoperability; and lack of a consistent system around which to collaborate. To address these needs, the PI developed the Computerized Intervention Authoring System (CIAS), which facilitates behavioral intervention science by allowing investigators to directly develop sophisticated and interactive mobile applications without programming. CIAS is already being used by investigators outside of the PI’s own lab, a process that has revealed significant interest in this software from a wide range of NIH-funded investigators, as well as significant limitations. Current aims. The proposed application will address these limitations, making CIAS into a significant, open-source, and virtually unique non-commercial research resource. In Aim 1, we will engage in sustained user experience testing designed to make the tool far more intuitive to use. This process is expected to result in a dramatic reorganization of the investigator interface, as well as in a complete set of evidence-based user training and support materials. In Aim 2, we will add a range of features and capabilities to make CIAS more powerful, flexible, and interoperable (e.g., by building to SMART Health IT standards, as well as FHIR open specifications to facilitate integration with Electronic Health Records). In Aim 3, we will engage in focused efforts to promote the use of CIAS as part of multi-lab collaborations using open science practices (e.g., via integration with the Open Science Framework). Importantly, we will engage in all of the above with the assistance of a highly accomplished panel of advisors who will help ensure that the final product is broadly relevant, future-facing, and usable to a broad range of behavioral scientists. Technology-delivered interventions are showing great potential to help people modify unhealthy behaviors like substance use, poor diet, and poor medication adherence. However, designing these interventions is time- consuming and expensive, which is slowing down research in this area as well as the rate at which such technology can help people. This project will take existing research software and significantly enhance it so it can allow scientists to easily and quickly collaborate to develop powerful interventions for mobile devices.","Accelerating collaborative, cumulative, and open intervention science with an e-intervention authoring platform",9882671,U24EB028990,"['Address', 'Adult', 'Alcohol or Other Drugs use', 'Apple', 'Area', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Benchmarking', 'Budgets', 'Cessation of life', 'Characteristics', 'Code', 'Collaborations', 'Computer software', 'Computers', 'Consumption', 'Development', 'Diet', 'Documentation', 'Eating', 'Ecosystem', 'Electronic Health Record', 'Elements', 'Ensure', 'Evaluation', 'Evidence based intervention', 'Fast Healthcare Interoperability Resources', 'Funding', 'Future', 'Health', 'Heterogeneity', 'Human', 'Intervention', 'Intervention Studies', 'Interview', 'Intuition', 'Investments', 'Language', 'Machine Learning', 'Measurement', 'Methods', 'Modification', 'National Institute of Biomedical Imaging and Bioengineering', 'Operating System', 'Outcome', 'Persons', 'Population', 'Process', 'Public Health Informatics', 'Publications', 'Research', 'Research Personnel', 'Resources', 'Risk', 'SMART health', 'Sample Size', 'Sampling', 'Science', 'Scientist', 'Smoking', 'Support System', 'System', 'Technology', 'Testing', 'Text Messaging', 'Time', 'Training', 'Training Support', 'Translations', 'Treatment Efficacy', 'United States National Institutes of Health', 'Work', 'alcohol misuse', 'base', 'behavioral health', 'brief intervention', 'burden of illness', 'computerized', 'cost', 'design', 'diet and exercise', 'evidence base', 'experience', 'flexibility', 'good diet', 'handheld mobile device', 'healthy weight', 'interest', 'interoperability', 'intervention effect', 'mHealth', 'medication compliance', 'mobile application', 'mobile computing', 'open data', 'open source', 'prevent', 'reduced substance use', 'repository', 'response', 'sedentary lifestyle', 'software development', 'symposium', 'therapy design', 'therapy development', 'tool', 'user centered design', 'virtual', 'web site']",NIBIB,WAYNE STATE UNIVERSITY,U24,2019,399297,-0.017845732580273933
"Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)? PROJECT SUMMARY The North Coast Conference on Precision Medicine is a national annual mid-sized conference series held in Cleveland, Ohio. The conference series aims to serve as a venue for the continuing education and exchange of scientific ideas related to the rapidly evolving and highly interdisciplinary landscape that is precision medicine research. The topics for each conference coincide with the national conversation and research agenda set by national research programs focused on precision medicine. The 2018 conference is a symposium that will focus on issues related to return of genomic results both in clinical and research settings with an emphasis on diverse populations. The conference will be organized as a traditional format with invited speakers from among national experts for topics ranging from issues returning research results to culturally diverse participants and family members, inclusion of diverse patient and participant populations in the Clinical Sequencing Evidence- Generating Research (CSER) consortium and the Trans-Omics for Precision Medicine (TOPMed) Program, pharmacogenomics-guided dosing and race/ethnicity, strategies used to return results, among others. 2019 and beyond conference topics are being considered from previous symposia attendees and trends in precision medicine research. Odd-numbered year conferences include a workshop component that has previously covered outcome and exposure variable extraction from electronic health records. Future workshop topics being considered include integration of multiple ‘omics, drug response in different populations, pharmacogenomics clinical implementation, precision medicine in cancer, data sharing and informed consent, and the use of apps for recruitment, diagnosis, follow-up, and treatment. Our second major objective of this conference series is the promotion of diversity in the biomedical workforce. It is well-known that the pipeline from training to full professor for women in biomedical research is leaky whereas the pipeline for under-represented minorities is practically non-existent. Drawing from national and local sources, we vet women and under-represented minorities for every invited speaker opportunity, thereby providing valuable career currency and networking opportunities. We will also encourage women and under-represented minorities, particularly at the trainee level, to attend and participate in this conference series to spur interest in pursuing precision medicine research as a career. Overall, the North Coast Conference on Precision Medicine series is a valuable addition to the national conference landscape, and with its unique location and low cost to participants, will serve as an important educational opportunity as precision medicine research accelerates in earnest. PROJECT NARRATIVE The North Coast Conference on Precision Medicine is a yearly fall conference series in Cleveland, Ohio designed as a continuing education forum in the burgeoning area of precision medicine research. The conference brings together national experts on a host of topics ranging from bioethics to bioinformatics to biomedical informatics to speak and lead workshops on timely challenges posed in translating complex genomic and health data into clinical practice. The conference series also serves to promote diversity in the biomedical workforce. This year’s symposium will focus issues related to return of genomic results in both clinical and research settings with an emphasis on diverse populations.",Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)?,9762963,R13HG010286,"['Academic Medical Centers', 'Acceleration', 'African American', 'Area', 'Back', 'Big Data', 'Bioethics', 'Bioinformatics', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Computational Biology', 'Computer Simulation', 'Continuing Education', 'Custom', 'Data', 'Databases', 'Diagnosis', 'Dose', 'Educational workshop', 'Electronic Health Record', 'Ensure', 'Ethnic Origin', 'Family member', 'Funding', 'Future', 'Generations', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidental Findings', 'Informed Consent', 'Infrastructure', 'Institution', 'Knowledge', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mining', 'Names', 'Ohio', 'Outcome', 'PMI cohort', 'Participant', 'Pathogenicity', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Population Heterogeneity', 'Prevention', 'Process', 'Race', 'Research', 'Research Personnel', 'Resources', 'Schedule', 'Science', 'Series', 'Source', 'Surveys', 'Technology', 'Time', 'Training', 'Trans-Omics for Precision Medicine', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Minority', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'Woman', 'base', 'big biomedical data', 'biomedical informatics', 'career', 'clinical care', 'clinical implementation', 'clinical practice', 'clinical sequencing', 'clinically relevant', 'cost', 'cost effective', 'data sharing', 'design', 'falls', 'follow-up', 'forging', 'frontier', 'genome-wide', 'genomic data', 'health data', 'health disparity', 'health information technology', 'incentive program', 'individual patient', 'interest', 'medical specialties', 'multiple omics', 'patient population', 'point of care', 'posters', 'precision medicine', 'programs', 'recruit', 'response', 'science education', 'senior faculty', 'symposium', 'trend']",NHGRI,CASE WESTERN RESERVE UNIVERSITY,R13,2019,10000,0.005699283282037243
"ACTIVE: Abilities Captured Through Interactive Video Evaluation (DDT COA 000032) Project Summary/Abstract Technology has the potential to accelerate clinical research and reduce the burden of participation in rare diseases such as Duchenne Muscular Dystrophy (DMD). DMD is an x-linked genetic disorder that results in progressive muscle weakness with loss of ambulation by 10-12 years of age, progression of arm weakness resulting in difficulty with self-feeding and other self-care activities in adolescence, and death resulting from cardiopulmonary insufficiency by age 30 years. Studies in rare diseases are inherently difficult due to a small recruitment pool and a limited number of sites that possess the experience and resources to participate as a study site. An outcome measure that quantifies change in both ambulant and non-ambulant individuals with minimal evaluator training could enable more efficient data collection in multi-site clinical trials. Our upcoming submission, DDT COA 0032, Abilities Captured Through Interactive Video Evaluation (ACTIVE), has the potential to meet this need. ACTIVE is a 65-second game utilizing a skeletal-tracking algorithm to quantify workspace volume (WSV) elicited through maximal arm reaching overhead, side-to-side, and forward while also encouraging trunk lean in each direction. Our studies have shown that ACTIVE is valid and reliable in quantifying WSV in persons with DMD across the span of age and abilities. However, to increase access and portability of a tool for use across trial sites, it is critical that tool has sound scientific and technological construction. ACTIVE WSV was originally built upon the Microsoft Kinect and Kinect One for Xbox platforms. The skeletal tracking algorithm developed by Microsoft vastly exceeds all other programs as it had the full backing of the Microsoft machine. Unfortunately, the Kinect, in its additional sense, has been abandoned for more current artificial intelligence applications. The Microsoft Kinect Azure will soon be released with higher resolution and programming capabilities. Our full DDT submission has been delayed as each new camera release has required reprogramming of our software to ensure valid and reliable results. Our team has recently expanded to include software development partners, The Plan Works (thePlan), who have the technological expertise to alter our current codebase to ensure transfer of ACTIVE across camera sensor platforms is more efficient and reliable as we expect ongoing technological advances to provide opportunities for continued advances. To this end, our current application seeks support to verify the technology of the ACTIVE WSV system to 1) confirm the use of unique code that can be ported across platforms over time and 2) improving the ease of use and limit training needed at a growing number of inexperienced centers. Project Narrative Our upcoming submission, DDT COA 0032, Abilities Captured Through Interactive Video Evaluation (ACTIVE), is a 65-second outcome assessment that quantifies a person’s workspace volume and has the potential to expand the enrollment pool by measuring both ambulant and non-ambulant subjects. While the scientific construction of the tool is sound, ongoing technological advances and changes have made it challenging to port our software across camera platforms. Our proposal seeks funding to support final software updates to ensure changes in technology components (i.e. camera sensor systems) or coding instability will not interfere with clinical trial data collection and allow us to complete our final submission package.",ACTIVE: Abilities Captured Through Interactive Video Evaluation (DDT COA 000032),9989528,U01FD006883,[' '],FDA,RESEARCH INST NATIONWIDE CHILDREN'S HOSP,U01,2019,215170,0.0012764376413310597
"CORE CENTER FOR CLINICAL RESEACH IN TOTAL JOINT ARTHROPLASTY (CORE-TJA) ABSTRACT - OVERALL Total joint arthroplasty (TJA) is the most common and fastest growing surgery in the nation. There are currently more than 7 million Americans living with artificial joints. Despite the high surgery volume, the evidence base for TJA procedures, technologies and associated interventions are limited. Many surgical approaches and implant technologies in TJA are adopted based on theoretical grounds with limited clinical evidence. The wider TJA research community needs access to large, high quality and rich data sources and state-of-the-art clinical research standards and information technologies to overcome methodological and practical challenges in studies of surgical and nonsurgical interventions in TJA. The overarching goal of Mayo Core Center for Clinical Research in Total Joint Arthroplasty (CORE-TJA) is to facilitate innovative, methodologically rigorous and interdisciplinary clinical research that will directly improve TJA care and the outcomes. The CORE-TJA will serve as a disease (TJA) and theme-focused Center providing shared methodological expertise, education and data resources. The CORE-TJA will leverage big data resources for TJA research, provide customized methodology resources in epidemiology, biostatistics, health services research and medical informatics, and establish synergistic interactions around an integrated Core (American Joint Replacement Registry – AJRR). The Specific Aims of CORE-TJA are: (1) To provide administrative and scientific oversight of CORE-TJA activities (Administrative Core), (2) To provide integrated services, access to large databases and novel analytical methods for clinical research in TJA (Methodology Core); and (3) To meet the unique data needs of the TJA research community and to strengthen the national capacity for large-scale observational and interventional studies in TJA using national registry data (Resource Core). The CORE-TJA will be integrated within the long-standing and highly centralized clinical research environment of the Mayo Clinic, thereby leveraging existing expertise and infrastructure resources, including the Center for Clinical and Translational Science. All CORE-TJA activities will be evaluated using robust metrics to ensure continuous evaluation, flexibility and improvement in response to the most pressing needs of the TJA research community. NARRATIVE The Mayo Core Center for Clinical Research in Total Joint Arthroplasty (CORE-TJA) will provide methodological expertise and access to nationwide data resources to facilitate innovative, methodologically rigorous and interdisciplinary clinical research in TJA. The clinical research needs of the TJA research community that will be addressed by the CORE-TJA include training of the next generation of TJA researchers, customized consultations, facilitated access to high quality, rich data sources and national TJA registry data as well as informatics and methodology support.",CORE CENTER FOR CLINICAL RESEACH IN TOTAL JOINT ARTHROPLASTY (CORE-TJA),9850367,P30AR076312,"['Address', 'Adopted', 'Adoption', 'Advisory Committees', 'American', 'Area', 'Berry', 'Big Data', 'Biometry', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Communication', 'Communities', 'Consultations', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Element', 'Data Sources', 'Databases', 'Development', 'Disease', 'Documentation', 'Education', 'Electronic Health Record', 'Ensure', 'Environment', 'Epidemiology', 'Evaluation', 'Future', 'Goals', 'Health Services Research', 'Hip region structure', 'Implant', 'Informatics', 'Information Technology', 'Infrastructure', 'Intervention', 'Intervention Studies', 'Joint Prosthesis', 'Knee', 'Leadership', 'Link', 'Medical Informatics', 'Methodology', 'Modeling', 'Musculoskeletal', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Outcome', 'Patient Care', 'Patients', 'Policies', 'Positioning Attribute', 'Procedures', 'Productivity', 'Registries', 'Replacement Arthroplasty', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Surgeon', 'Technology', 'Time', 'Training', 'Translating', 'Translational Research', 'Translations', 'United States', 'Vision', 'analytical method', 'base', 'care outcomes', 'cost', 'data registry', 'data resource', 'education resources', 'evidence base', 'experience', 'flexibility', 'improved', 'improved outcome', 'innovation', 'next generation', 'novel', 'outreach', 'programs', 'response', 'skills', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,P30,2019,644134,0.007836626181192088
"CRCNS: US-France Data Sharing Proposal: Lowering the barrier of entry to network neuroscience The field of network neuroscience has developed powerful analysis tools for studying brain networks and holds promise for deepening our understanding of the role played by brain networks in health, disease, development, and cognition. Despite widespread interest, barriers exist that prevent these tools from having broader impact. These include (1) unstandardized practices for sharing and documenting software, (2) long delays from when a method is first introduced to when it becomes publicly available, and (3) gaps in theoretic knowledge and understanding leading to incorrect, delays due to mistakes, and errors in reported results. These barriers ultimately slow the rate of neuroscientific discovery and stall progress in applied domains. To overcome these challenges, we will use open science methods and cloud-computing, to increase the availability of network neuroscience tools. We will use the platform ""brainlife.io"" for sharing these tools, which will be packaged into self-contained, standardized, reproducible Apps, shared with and modified by a community of users, and integrated into existing brainlife.io analysis pipelines. Apps will also be accompanied by links to primary sources, in-depth tutorials, and documentation, and worked-through examples, highlighting their correct usage and offering solutions for mitigating possible pitfalls. In standardizing and packaging network neuroscience tools as Apps, this proposed research will engage a new generation of neuroscientists, providing them powerful new and leading to new discoveries. Second, the proposed research will contribute growing suite of modeling analysis that can be modified to suit specialized purposes. Finally, the Brainlife.io platform will serve as part of the infrastructure supporting neuroscience research. Altogether, these advances will lead to new opportunities in network neuroscience research and further stimulate its growth while increasing synergies with other domains in neuroscience. Structural and functional networks support cognitive processes. Miswiring networks lead to maladaptive behavior and neuropsychicatric disorders. Network neuroscience is a young field that provides a quantitative framework for modeling brain networks. This project will make network neuroscientific tools available to new users via open science and cloud-computing. New applications of these tools this will lead deeper insight into the role of networks in health as well as in clinical disorders.",CRCNS: US-France Data Sharing Proposal: Lowering the barrier of entry to network neuroscience,9916138,R01EB029272,"['Address', 'Aging', 'Biophysics', 'Brain', 'Cloud Computing', 'Cognition', 'Communities', 'Complex Analysis', 'Computer software', 'Data', 'Data Set', 'Development', 'Disease', 'Documentation', 'Ecosystem', 'Education', 'Elements', 'France', 'Funding', 'Generations', 'Graph', 'Growth', 'Instruction', 'Knowledge', 'Language', 'Lead', 'Libraries', 'Link', 'Literature', 'Machine Learning', 'Mathematics', 'Methods', 'Modeling', 'Neurosciences', 'Pathway Analysis', 'Play', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Science', 'Sociology', 'Standardization', 'Structure', 'Study models', 'System', 'Techniques', 'Time', 'Training', 'analysis pipeline', 'brain computer interface', 'cloud based', 'cyber infrastructure', 'data sharing', 'experience', 'innovation', 'insight', 'learning strategy', 'network architecture', 'network models', 'neuroimaging', 'open data', 'prevent', 'relating to nervous system', 'statistics', 'tool']",NIBIB,INDIANA UNIVERSITY BLOOMINGTON,R01,2019,215134,-0.015907479562313444
"Deep Fractions Learning: A Core Curriculum of Games, Inquiry, and Collaboration There is an enormous deficit in students’ understanding of fractions in the United States. Fifth grade fraction knowledge predicts high school math performance, even when controlling for working memory, whole number knowledge, IQ, reading ability, and demographic factors (Siegler et al., 2012). Therefore, addressing this deficit is a particularly important area for early intervention. With this Fast-Track grant, Deep Fractions Learning , we propose to transform the way in which students learn core math curriculum so that materials are more interactive and engaging, promote deeper learning of content, and are aligned with the Common Core. More specifically, we will develop and evaluate a digital curriculum for grades 3-5 covering the fractions domain that combines games, collaboration, and an inquiry approach. We propose to develop an innovative technology infrastructure that will integrate Teachley learning games, Success for All’s (SFA) cooperative learning framework, and rigorous lesson content. We will integrate research into the design process and work with Johns Hopkins University to evaluate the efficacy of the intervention. Outcomes. The intervention will encourage four direct outcomes for students, namely improved: 1) conceptual understanding of fractions, 2) procedural fluency with fractions operations, 3) mathematical justification, and 4) motivation. First, the curriculum will build both conceptual understanding and procedural fluency, providing strong visual models within engaging games that motivate students to practice. The collaborative learning model and inquiry approach will improve students’ mathematical justification. Finally, we encourage these outcomes within a motivational support structure designed to foster engagement and self-efficacy. Improving students’ academic outcomes and self-efficacy in the area of fractions during elementary school will promote later success in high school mathematics. Since each additional math class students complete in high school more than doubles the odds of college completion (Adelman, 2006), the intervention has the potential to make a real difference in whether students achieve sustainable careers versus being stuck in low-wage jobs. Fractions knowledge in the fifth grade strongly predicts high school math performance, even when controlling for working memory, whole number knowledge, IQ, reading ability, and demographic factors (Siegler et al., 2012). Intervention in this essential content area will improve students’ math ability in the short and long term, which in turn will lead to several positive distal outcomes, such as greater high school graduation rates and college attendance.","Deep Fractions Learning: A Core Curriculum of Games, Inquiry, and Collaboration",9789518,R44GM130162,"['Active Learning', 'Address', 'Area', 'Behavior', 'Child', 'Collaborations', 'Common Core', 'Control Groups', 'Demographic Factors', 'Distal', 'Early Intervention', 'Educational Curriculum', 'Ethnic Origin', 'Fostering', 'Goals', 'Graduation Rates', 'Grant', 'High School Student', 'Infrastructure', 'Instruction', 'Intervention', 'Investments', 'Knowledge', 'Learning', 'Maps', 'Mathematics', 'Mathematics Curriculum', 'Measures', 'Modeling', 'Motivation', 'Occupations', 'Online Systems', 'Outcome', 'Performance', 'Phase', 'Privatization', 'Process', 'Research', 'Sampling', 'Self Efficacy', 'Services', 'Short-Term Memory', 'Structure', 'Students', 'Treatment Efficacy', 'United States', 'Universities', 'Visual', 'Wages', 'Work', 'boys', 'career', 'college', 'dashboard', 'deep learning', 'design', 'digital', 'elementary school', 'fifth grade', 'fourth grade', 'girls', 'high school', 'improved', 'innovation', 'innovative technologies', 'mathematical ability', 'operation', 'prototype', 'reading ability', 'success', 'teacher', 'third grade', 'usability']",NIGMS,"TEACHLEY, LLC",R44,2019,463456,0.014508911450409999
"Mixed Reality System for STEM Education and the promotion of health-related careers Project Summary/Abstract Proposed is a system to combine and leverage the advantages of existing medical props with interactive media to provide engaging and cooperative group STEM learning experiences. Significance: The PowerPoint lecture style has become the standard method for teaching groups of students. Unfortunately, this style does not emphasize student-instructor or student-student instruction, and in fact seems to have made students even less engaged than before. Broad agreement exists in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning exercises. Despite their substantial benefits, physical props are fundamentally limited as they are primarily static (e.g. fixed coloration, disease depiction), their internal structures (with limited exceptions) often bear little resemblance to actual human anatomy, and they are passive objects. Hypothesis: A system which can provide more engaging interaction with physical props will be able to improve student retention and increase interest in STEM related subjects. Specific Aims: To prove the feasibility of the proposed system in Phase I IDL will 1) Determine stakeholder requirements through round table discussions; 2) Create prototype system hardware & software to augment learning with physical props; and 3) Validate the prototype system through a pilot study. The overall Phase I effort will demonstrate the ability of the proposed system to augment learning with physical props. In the Phase II effort IDL will ready the system for commercialization by 1) Developing production-quality software, hardware, and user interfaces; 2) Developing a set of comprehensive curricula for the system; and 3) Validating the system through human subject testing. Project Narrative Passive learning methods, i.e. PowerPoint lectures, have become the standard method for teaching groups of students topics including Anatomy and Physiology in spite of broad agreement in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning; however, these props are fundamentally limited.",Mixed Reality System for STEM Education and the promotion of health-related careers,9851024,R44GM130247,"['3-Dimensional', 'Agreement', 'Algorithmic Software', 'Anatomy', 'Biological', 'Biological Sciences', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Development', 'Disease', 'Disease Progression', 'Dissection', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Environment', 'Exercise', 'Hand', 'Health', 'Health Promotion and Education', 'Hour', 'Human', 'Hybrids', 'Image', 'Instruction', 'Intervention', 'Learning', 'Location', 'Manikins', 'Medical', 'Minnesota', 'Modeling', 'Participant', 'Phase', 'Physiological', 'Physiology', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Production', 'Role', 'Sampling', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Slide', 'Small Business Innovation Research Grant', 'Structure', 'Students', 'Support Groups', 'System', 'Teaching Method', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'animation', 'career', 'college', 'commercialization', 'design', 'digital media', 'experience', 'flexibility', 'guided inquiry', 'hands-on learning', 'human subject', 'improved', 'innovation', 'instructor', 'interactive tool', 'interest', 'learning strategy', 'lectures', 'machine vision', 'mid-career faculty', 'mixed reality', 'pedagogy', 'prototype', 'retention rate', 'science education', 'software systems']",NIGMS,"INNOVATIVE DESIGN LABS, INC.",R44,2019,782476,0.008275876977055667
"Augmented Reality System for the Education of Clinical Caregivers of Older Adults Project Summary/Abstract Proposed is a system to combine and leverage the advantages of both existing physical mannequin-based training and virtual media to support clinical learning using Augmented Reality (AR). Significance: Education in clinical settings is often challenging, infeasible, risky, difficult to organize, time-consuming, and expensive. Due to these barriers, the value of mannequin-based simulation is well recognized and is incorporated extensively into medical education. In general, the purpose of mannequin use in education is to simulate a physical ""patient"" on which to learn, demonstrate, and test skill without fear of harming patients prior to entering clinical environments. Despite their substantial benefits, physical mannequins have several fundamental limitations that do not allow them to demonstrate the many unique phases and expressions of a disease or person-to-person differences in anatomy and physiology. This limits the ability for a learner to view dynamic changes over time and to explore disease progression and consequences of interventions. Hypothesis: This research hypothesizes that existing, current mannequins can be enhanced through an innovative and practical Augmented Reality solution. In the Phase I effort a prototype system and sample educational material covering Pressure Ulcer care was developed and analyzed through pilot studies with Nursing educators, Doctoral Degree in Nursing (DNP) students, and pre-licensure students. The pilot results of the technology demonstrated a high degree of positivity and exceptional enthusiasm and all Phase I metrics of success were met or exceeded. Specific Aims: In Phase II the following aims are proposed: 1) Design a comprehensive suite of course content and design the technology's integration into a College of Nursing course, 2) Develop a production-ready system, and 3) Validate the system utility through human subject testing and expert evaluation of the system. Project Narrative Over the past decade, medical simulation has been experiencing explosive growth and widespread adoption. There are now over 800 medical simulation centers in the US alone, located in medical schools, nursing schools, hospitals, military simulation centers, and schools of allied health professions. The global market for Mannequin-Based Simulation is projected to reach $1 Billion by 2020. It is hypothesized that the combination of existing physical mannequin-based training with virtual media will open new possibilities for exploration and enhanced learning interactions for medical education. 3T",Augmented Reality System for the Education of Clinical Caregivers of Older Adults,9778054,R44AG057257,"['Adoption', 'Adult', 'Algorithmic Software', 'Allied Health Profession', 'Anatomy', 'Area', 'Augmented Reality', 'Caregivers', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consumption', 'Course Content', 'Decubitus ulcer', 'Development', 'Discipline of Nursing', 'Disease', 'Disease Progression', 'Dissection', 'Doctor&apos', 's Degree', 'Education', 'Educational Curriculum', 'Educational Materials', 'Elderly', 'Environment', 'Evaluation', 'Focus Groups', 'Fright', 'Goals', 'Growth', 'Hospitals', 'Hour', 'Human', 'Image', 'Individual', 'Injury', 'Intervention', 'Laboratories', 'Learning', 'Licensure', 'Location', 'Manikins', 'Medical', 'Medical Education', 'Military Personnel', 'Minnesota', 'Modeling', 'Movement', 'Nursing Faculty', 'Nursing Schools', 'Nursing Students', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiology', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Production', 'Research', 'Sampling', 'School Nursing', 'Schools', 'Scientist', 'Severity of illness', 'Skin', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'animation', 'base', 'caregiver education', 'college', 'commercialization', 'cost', 'design', 'experience', 'flexibility', 'human subject', 'impression', 'innovation', 'medical schools', 'miniaturize', 'person centered', 'pressure', 'professor', 'programs', 'prototype', 'simulation', 'skills', 'success', 'teacher', 'virtual']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2019,779815,-0.011031297795861443
"An interactive, digital platform to transform biological learning Abstract: The next generation of health care professionals will need to understand the foundational principles of biology. Science textbooks play a critical role in supporting biological understanding in school, yet these books are not designed to meet the diverse learning needs of students in today’s classrooms. By their nature, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current Life Science textbooks and to revolutionize reading with adaptable texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned inheritance (NGSS LS3A) content into Spanish (Aim 1); designing, developing, and testing the application to function through a web browser (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content to address 12 additional NGSS standards in English and Spanish (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive reading technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning needs. This Fast-Track project will produce an interactive, digital textbook to support students’ understanding of Life Science by giving them the ability to seamlessly move between different reading levels and languages and to play games that enhance their understanding of scientific language and concepts. This project will also solicit feedback from teachers and students to develop teacher support materials and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform biological learning",9778578,R44GM133245,"['Address', 'Adoption', 'Biological', 'Biological Sciences', 'Biology', 'Books', 'Brain', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Gametogenesis', 'Health Professional', 'Healthcare', 'Home environment', 'Individual', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Nature', 'Phase', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Spinal Cord', 'Students', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'Vocabulary', 'base', 'concept mapping', 'design', 'digital', 'education resources', 'egg', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'reading ability', 'resource guides', 'response', 'science teacher', 'scientific literacy', 'skills', 'sperm cell', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2019,225000,0.011957743171417822
"Environmental Health Research Experiences for Teachers in High-Poverty Schools: A Professional DevelopmentProgram Abstract The current project proposes an innovative professional development (PD) program in environmental health research experiences for science high-school teachers from schools with high poverty levels in North Carolina. In a collaborative effort, experts from the College of Education and scientists affiliated with the Center for Human Health and Environment (CHHE), and the Comparative Medicine Institute (CMI) at NC State University will provide teachers (N=40) with unique authentic lab experiences. The 8-week summer research PD program aims at enhancing teachers' environmental health literacy and research skills that will support novel science teaching strategies. The specific aims addressed by the program are the following: 1) to provide teachers with a practical understanding of the scientific method in mentored research projects examining links between environmental stressors and health; 2) to provide teachers with an understanding of core conceptual issues in toxicology; 3) to train teachers in ethical issues in scientific conduct, science communication, and public health; 4) to immerse teachers in authentic research lab experiences by using a cognitive apprenticeship model; and 5) to develop a comprehensive evaluation plan in order to assess the short- and long- term PD outcomes. In the proposed environmental health science (EHS) research PD program, teachers will be integrated into genuine research projects and attend lab meetings, gaining general knowledge of how research is conducted and specialized knowledge related to ongoing projects in their host lab. Additionally, teachers in the program will come together one day per week in a workshop environment, to share their diversity of research experiences and gain additional training in biological concepts and ethical issues related to environmental health sciences. Project Narrative Environmental health research experiences are often inaccessible to high-school teachers, particularly in high-poverty schools. Our PD program will provide teachers with scientific knowledge and resources to improve their classroom instruction by adopting a curriculum grounded in environmental health research. Further, teachers' newly acquired EHS knowledge and research skills have the potential to improve student science learning, and promote interest and readiness for STEM careers. By exposing students to novel instructional strategies, students will acquire not just STEM specialized knowledge, but develop STEM domain identification. This is particularly important for science, given the fact that students from high- poverty schools are economically disadvantaged and may comprise a large proportion of individuals from minority groups that are underrepresented in science.",Environmental Health Research Experiences for Teachers in High-Poverty Schools: A Professional DevelopmentProgram,9605786,R25ES028974,"['Address', 'Adopted', 'Area', 'Biological', 'Biological Models', 'Biomedical Research', 'Case Study', 'Cognitive', 'Communication', 'Communities', 'Data', 'Development', 'Dose', 'Economically Deprived Population', 'Education', 'Educational Activities', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Ensure', 'Environment', 'Environmental Health', 'Ethical Issues', 'Ethics', 'Evaluation', 'Experimental Designs', 'Exposure to', 'Faculty', 'Goals', 'Health', 'High School Faculty', 'Human', 'Individual', 'Institute of Medicine (U.S.)', 'Instruction', 'Interview', 'K-12 Faculty', 'Knowledge', 'Learning', 'Link', 'Mentors', 'Methods', 'Minority Groups', 'Modeling', 'North Carolina', 'Outcome', 'Participant', 'Poverty', 'Poverty Areas', 'Predisposition', 'Program Development', 'Program Evaluation', 'Public Health', 'Readiness', 'Research', 'Research Project Grants', 'Resources', 'STEM career', 'School Teachers', 'Schools', 'Science', 'Scientist', 'Students', 'Surveys', 'Teacher Professional Development', 'Teaching Method', 'Testing', 'Time', 'Toxicology', 'Training', 'Training Programs', 'Translating', 'Underrepresented Groups', 'Universities', 'Validity and Reliability', 'apprenticeship', 'base', 'college', 'comparative', 'deep learning', 'design', 'environmental stressor', 'experience', 'experimental study', 'exposure route', 'health literacy', 'health science research', 'high school program', 'improved', 'innovation', 'interest', 'laboratory experience', 'meetings', 'next generation', 'novel', 'outreach', 'pedagogical content', 'programs', 'response', 'science teacher', 'skills', 'socioeconomic disadvantage', 'socioeconomic disparity', 'stressor', 'summer research', 'teacher', 'tool']",NIEHS,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R25,2019,99506,0.024100816442846545
"Big Flow Cytometry Data: Data Standards, Integration and Analysis PROJECT SUMMARY Flow cytometry is a single-cell measurement technology that is data-rich and plays a critical role in basic research and clinical diagnostics. The volume and dimensionality of data sets currently produced with modern instrumentation is orders of magnitude greater than in the past. Automated analysis methods in the field have made great progress in the past five years. The tools are available to perform automated cell population identification, but the infrastructure, methods and data standards do not yet exist to integrate and compare non-standardized big flow cytometry data sets available in public repositories. This proposal will develop the data standards, software infrastructure and computational methods to enable researchers to leverage the large amount of public cytometry data in order to integrate, re-analyze, and draw novel biological insights from these data sets. The impact of this project will be to provide researchers with tools that can be used to bridge the gap between inference from isolated single experiments or studies, to insights drawn from large data sets from cross-study analysis and multi-center trials. PROJECT NARRATIVE The aims of this project are to develop standards, software and methods for integrating and analyzing big and diverse flow cytometry data sets. The project will enable users of cytometry to directly compare diverse and non-standardized cytometry data to each other and make biological inferences about them. The domain of application spans all disease areas where cytometry is utilized.","Big Flow Cytometry Data: Data Standards, Integration and Analysis",9731544,R01GM118417,"['Address', 'Adoption', 'Advisory Committees', 'Archives', 'Area', 'Basic Science', 'Bioconductor', 'Biological', 'Biological Assay', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Data Files', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Environment', 'Flow Cytometry', 'Foundations', 'Genes', 'Goals', 'Heterogeneity', 'Immune System Diseases', 'Immunologic Monitoring', 'Industry', 'Informatics', 'Infrastructure', 'International', 'Knock-out', 'Knowledge', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modernization', 'Mouse Strains', 'Multicenter Trials', 'Mus', 'Output', 'Phenotype', 'Play', 'Population', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Societies', 'Software Tools', 'Standardization', 'Technology', 'Testing', 'Validation', 'Work', 'automated analysis', 'base', 'bioinformatics tool', 'body system', 'cancer diagnosis', 'clinical diagnostics', 'community based evaluation', 'computerized tools', 'data exchange', 'data integration', 'data submission', 'data warehouse', 'experimental study', 'human disease', 'insight', 'instrument', 'instrumentation', 'mammalian genome', 'multidimensional data', 'novel', 'operation', 'phenotypic data', 'repository', 'research and development', 'software development', 'statistics', 'supervised learning', 'tool', 'vaccine development']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2019,350620,-0.002244982904308015
"INvestigations In Gout, Hyperuricemia, and comorbidiTies (INSIGHT) Center of Research Translation (CORT) Project Summary Gout impacts around 4% of the U.S. adult population and is the most common form of inflammatory arthritis in men. The incidence of gout is increasing worldwide. Gout significantly burdens the healthcare system, and is associated with both decreased work productivity and quality of life. With the ever-increasing impact of gout and its associated comorbidities on the population, investigation of novel translational mechanisms mediating gout flares as well as approaches to improving gout and hyperuricemia outcomes comprise an unmet and urgent medical need. When funded, the INvestigationS In Gout, Hyperuricemia, and comorbidiTies (INSIGHT) Center of Research Translation (CORT) included 4 active research projects and an Administrative Core focused on the theme, “Gout, Hyperuricemia, and Associated Comorbidities”. Projects include studies to: determine if adenosine monophosphate-activated protein kinase (AMPK) activity metabolomics have promise as gout biomarkers independent of serum urate (P1), examine the influence of key gene-environment interactions within an internet study of gout flares (P2), unravel the functional genomics of urate transporter genes identified in previously reported genome wide association studies (P3), and investigate the mechanism of urate lowering therapy on renal function within VA STOP-GOUT (P4). Projects range from basic research translation of underlying genetics and inflammatory pathobiology of gout, to understanding mechanisms of CKD progression in gout, and translation of genetic interaction with environmental factors and medications, to precision medicine. The proposed revision project (P5) aims to utilize a novel emergency department based intervention to test methods to improve the care gout patients in the Deep South, with a secondary goal of concurrently enhancing participation of minorities in research. The revised INSIGHT CORT aims to: (1) Conduct five outstanding, innovative, and synergistic research projects drawing on the unique strengths of multidisciplinary research teams at our four major centers: University of Alabama at Birmingham, Harvard University, University of California San Diego, and now Vanderbilt University Medical Center; (2) Foster the development of pilot and feasibility projects and the development and application of new translational methods to research in gout and hyperuricemia and their associated major comorbidities, particularly CKD and metabolic syndrome; and (3) Promote training of translational investigators in current methods of research applicable to gout and hyperuricemia through enrichment activities overseen by our Administrative Core. The proposed revision project directly ties to the CORT through patient enrollment into the Gout CORT Registry and Biorepository, which contributes clinical data and biological samples to projects. The INSIGHT CORT is a multi-disciplinary translational research program at UAB and partner institutions. We have assembled an outstanding team and are uniquely prepared and strongly committed to scientific rigor, innovation, and development of knowledge and translational techniques. Project Narrative The prevalence of gout has been steadily increasing over several decades and is correlated with the rising burden of obesity, chronic cardiac and renal disease; all conditions overrepresented in the Southeastern U.S. – particularly in African Americans. Through a novel emergency department led intervention we aim to improve the care patients with gout receive, both during acute exacerbations and long-term. A secondary goal of the project is to concurrently enhance participation of minorities in biomedical research in the Deep South.","INvestigations In Gout, Hyperuricemia, and comorbidiTies (INSIGHT) Center of Research Translation (CORT)",9902085,P50AR060772,"['Absenteeism', 'Academic Medical Centers', 'Accident and Emergency department', 'Acute', 'Address', 'Adenosine Monophosphate', 'Adult', 'Affect', 'African American', 'Alabama', 'Basic Science', 'Biological', 'Biological Markers', 'Biomedical Research', 'Biometry', 'California', 'Caring', 'Chronic', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical Data', 'Clinical Informatics', 'Clinical Trials', 'Communities', 'Comorbidity', 'Computerized Medical Record', 'Continuity of Patient Care', 'Deep South', 'Development', 'Diabetes Mellitus', 'Disease Progression', 'Doctor of Philosophy', 'Early identification', 'Educational Intervention', 'Emergency Department-based Intervention', 'Emergency Medicine', 'Enrollment', 'Environmental Risk Factor', 'Epidemic', 'Epidemiology', 'Face', 'Flare', 'Fostering', 'Frequencies', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Translation', 'Goals', 'Gout', 'Health', 'Healthcare', 'Healthcare Systems', 'Heart Diseases', 'Hyperuricemia', 'Incidence', 'Inflammatory', 'Inflammatory Arthritis', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'International', 'Internet', 'Intervention', 'Investigation', 'Kidney Diseases', 'Knowledge', 'Laboratories', 'Link', 'Mediating', 'Medical', 'Metabolic syndrome', 'Methodology', 'Methods', 'Minority', 'Minority Participation', 'Mission', 'Modernization', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Nephrology', 'Obesity', 'Outcome', 'Patient Care', 'Patient Education', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Premature Mortality', 'Prevalence', 'Productivity', 'Protein Kinase', 'Quality of life', 'Recommendation', 'Registries', 'Renal function', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rheumatology', 'Sampling', 'Serum', 'Specimen', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Translational Research', 'Universities', 'Urate', 'Work', 'aging population', 'base', 'biobank', 'clinically relevant', 'functional genomics', 'gene environment interaction', 'genome wide association study', 'health care service utilization', 'health disparity', 'improved', 'innovation', 'men', 'metabolomics', 'minority health', 'multidisciplinary', 'novel', 'personalized medicine', 'precision medicine', 'productivity loss', 'recruit', 'tool', 'translational research program', 'translational scientist', 'urate transporter']",NIAMS,UNIVERSITY OF ALABAMA AT BIRMINGHAM,P50,2019,961116,-0.0038007874157549386
"Washington University School of Medicine Undiagnosed Diseases Network Clinical Site 1.0 PROJECT SUMMARY The scientific premise of this application is that the individualized translational research process of the Undiagnosed Diseases Network (UDN) developed during Phase I is scalable and that its impact on patients, families, and disease discovery can be advanced and sustained by addition of a Clinical Site at Washington University School of Medicine (WUSM). WUSM represents a large academic medical center that is fully integrated with world-renowned basic science capabilities and demonstrated expertise in a gene first approach for patients with undiagnosed diseases. The highly collaborative clinical and biomedical research culture at WUSM promotes interactions within and across Departments, with institutional genomic, clinical, computational, and model system experts, and with colleagues regionally, nationally, and internationally. These interactions support recruitment, selection, evaluation, diagnosis discovery, and follow up of pediatric and adult patients with undiagnosed diseases through both established networks and individual referrals. Building on this infrastructure, WUSM faculty and staff will advance the success of the UDN in diagnosing and managing disease in undiagnosed patients by, first, using, refining, and improving protocols designed during Phase I of the UDN for comprehensive, timely clinical evaluations of 30 undiagnosed patients annually. Secondly, we will collect, securely store, and share standardized, high-quality clinical and laboratory data including genotyping, phenotyping, and documentation of environmental exposures and promote an integrated and collaborative community across the UDN and among laboratory and clinical investigators focused on defining the pathophysiology, cell biologic, and molecular mechanisms that cause these difficult to diagnose diseases. Thirdly, the WUSM UDN Clinical Site will propose a bioinformatics plan for leveraging institutional infrastructure and expertise to develop innovative strategies to improve discovery of pathogenic variants. Fourthly, the assessment, dissemination, outreach, and training plan will accelerate assessment and dissemination of data, protocols, consent materials, and methods, availability of educational and outreach materials for participants, clinicians, and other researchers, engagement of underrepresented minorities, and training for students, fellows, staff, and faculty in collaboration with WUSM’s Clinical and Translational Science Award infrastructure. Finally, WUSM will make a clear institutional commitment to maintain its Clinical Site, to adapt UDN Phase I practices for sustainability, to contribute to formation of a sustainable national UDN resource, and to adapt to unique needs and unexpected circumstances that may arise once Common Fund support ends in fiscal year 2022. 2.0 PROJECT NARRATIVE Undiagnosed diseases in children and adults represent frustrating and costly challenges for patients, families, physicians, and society. Building on established institutional infrastructure similar to the Undiagnosed Diseases Network (UDN), Washington University School of Medicine (WUSM) will establish a UDN Clinical Site to improve the level of diagnosis and care for patients with undiagnosed diseases, facilitate research into the etiology of undiagnosed diseases, and promote an integrated and collaborative community across multiple UDN Clinical Sites, Sequencing Cores, Model Organisms Screening Centers, and among laboratory and clinical investigators. Specifically, the WUSM UDN Clinical Site will annually recruit, select, evaluate, and follow 30 participants with disorders in any clinical specialty, adult and pediatric, provide comprehensive clinical evaluations that require <5 days and follow up, and participate in all UDN protocols, data management and sharing, and sustainability planning.",Washington University School of Medicine Undiagnosed Diseases Network Clinical Site,9789913,U01HG010215,"['Academic Medical Centers', 'Accreditation', 'Adult', 'Animal Model', 'Basic Science', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Businesses', 'Cells', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical and Translational Science Awards', 'Collaborations', 'Communities', 'Computer Simulation', 'Consent', 'DNA Sequencing Facility', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Management', 'Documentation', 'Environmental Exposure', 'Etiology', 'Evaluation', 'Expert Systems', 'Faculty', 'Family', 'Family Physicians', 'Functional disorder', 'Funding', 'Genes', 'Genomics', 'Genotype', 'Geographic Locations', 'Individual', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Methods', 'Molecular', 'Monitor', 'Network-based', 'Participant', 'Pathogenicity', 'Patient Care', 'Patients', 'Phase', 'Phase I Clinical Trials', 'Phenotype', 'Process', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Review Committee', 'Secure', 'Societies', 'Standardization', 'Time', 'Training', 'Translational Research', 'Underrepresented Minority', 'Universities', 'Variant', 'Washington', 'clinical practice', 'clinical research site', 'cost', 'data management', 'data sharing', 'deep learning', 'design', 'disease diagnosis', 'exome sequencing', 'experience', 'follow-up', 'genetic variant', 'genome sequencing', 'improved', 'innovation', 'medical schools', 'medical specialties', 'network models', 'operation', 'outreach', 'recruit', 'research clinical testing', 'screening', 'sequencing platform', 'student training', 'success', 'transcriptome sequencing']",NHGRI,WASHINGTON UNIVERSITY,U01,2019,750000,0.012077823451963388
"Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND) Project Summary/Abstract  This Phase III (P-III) COBRE project will extend the cores that have been successfully leveraged in our Phase I (P-I) and Phase II (P-II) COBRE projects and sustain these unique resources in New Mexico through the im- plementation of a business plan. Over the past eight years we have built up infrastructure and created a cutting edge brain imaging center, our P-II project is just over half-way through and is even more successful than our P- I was at this point in time. The Mind Research Network (MRN) houses an Elekta Neuromag 306-channel MEG System, a high density EEG lab, a 3T Siemens Trio MRI scanner, and a mobile 1.5T Siemens Avanto MRI scanner. Additional resources include a centralized neuroinformatics system, a strong IT management plan, and state-of-the-art image analysis expertise and tools. This P-III COBRE center will continue our momentum and move the cores we have developed into a position of long term sustainability. We will continue with the technical cores established during the P-II project including multimodal data acquisition (MDA), algorithm and data analy- sis (ADA), and biostatistics and neuro-informatics (BNI). These cores have begun to serve MRN and the greater community, as well as other institutions including extensive collaborations with IDeA funded projects in New Mexico and other states. We believe this P-III COBRE is extremely well-positioned to establish and sustain New Mexico as one of the premier brain imaging sites. We include an extensive pilot project program (PPP) that is built on the successful pilot programs implemented as part of the earlier COBRE phases. This includes an ex- tensive educational, mentoring, and faculty development program to carefully mentor and position faculty who use the cores to maximize their potential to successfully compete for external funding, thus fulfilling the ultimate goals of the COBRE program. 2 Narrative  This Phase III COBRE project is a natural extension of our Phase I and II COBRE projects which were cen- tered on mentoring individual researchers along with building the necessary infrastructure to support multimodal neuroimaging in mental illness. During this time, cutting-edge cores were developed that facilitated not only our local projects but also research at multiple institutions across New Mexico; the cores served as neuroimaging facilities and training centers for others to utilize. The Phase III project will ensure the sustainability of these cores as they transition to being fully funded by a broad cadre of users with various funding sources. We propose three technical cores including a multimodal data acquisition (MDA) core, an algorithm and data analysis (ADA) core, and a biostatistics and neuro-informatics (BNI) core. These cores have already shown their utility and have begun to be leveraged by users outside the COBRE. In addition, we propose a robust pilot project program (PPP) to continue to seed and enable new users of the cores to ultimately grow and sustain world class brain imaging research within our IDeA state, thus fulfilling the ultimate goals of the COBRE program. 1",Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND),9700159,P30GM122734,"['Algorithmic Analysis', 'Appointment', 'Area', 'Awareness', 'Biology', 'Biometry', 'Bipolar Depression', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Businesses', 'Centers of Research Excellence', 'Chemistry', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Core Facility', 'Data', 'Data Analyses', 'Department of Energy', 'Development', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Genetic', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Leadership', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Magnetoencephalography', 'Major Depressive Disorder', 'Mental Depression', 'Mental disorders', 'Mentors', 'Methods', 'Mind-Body Method', 'Mission', 'Multimodal Imaging', 'Neurobiology', 'Neurologic', 'Neurosciences', 'New Mexico', 'Paper', 'Patients', 'Peer Review', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Program Development', 'Psychiatry', 'Publications', 'Recording of previous events', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Role', 'Schizophrenia', 'Seeds', 'Site', 'Structure', 'System', 'Teacher Professional Development', 'Time', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Vision', 'base', 'cohesion', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'deep learning', 'density', 'design', 'distinguished professor', 'improved', 'independent component analysis', 'meetings', 'multimodal data', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'neuropsychiatric disorder', 'programs', 'tool']",NIGMS,THE MIND RESEARCH NETWORK,P30,2019,1290517,0.00265890337490124
"Training a new generation of computational neuroscientists bridging neurobiology The Training Program in Computational Neuroscience (TPCN) will support integrated undergraduate and graduate training in computational neuroscience at New York University. The program will be hosted by the Center for Neural Science (CNS), with participation of faculty in the Departments of Psychology, Mathematics, and Computer Science, and the Institute of Neuroscience at the School of Medicine. The TPCN will fit well with NYU’s unique strengths and recent developments: (1) NYU is one of a few universities with a critical mass of computational neuroscientists. NYU has had a Sloan-Swartz Center for Theoretical Neuroscience since 1994. In the past three years alone, NYU has hired three computational neuroscientists. (2) CNS established an undergraduate major in neuroscience as early as 1992, and thus has a long track record in undergraduate education, it now has 136 students in the current academic year. (3) Recent faculty hiring in CNS, Psychology, and the School of Medicine has greatly expanded our teaching and research capabilities in the neuroscience of cognitive functions and their impairments associated with mental disorders. (3) As NYU is undertaking a merge of two historically separated neuroscience graduate programs (at CNS and the School of Medicine), this training grant will ensure that computational modeling, which has become indispensible in neuroscience, will be front-and-center in the integrated graduate program. (4) NYU is a major center of Artificial Intelligence and Data Science, with close links to Facebook’s AI Center and the Simons Center for Data Analysis. Our training faculty together with these connections will give our students ample opportunities to acquire machine learning techniques for data analysis and learn about brain-like AI algorithms. The proposed training program will support coherent undergraduate and graduate training in computational neuroscience at NYU. It will have several unique features: (1) Innovative mentorship methods: For example, (a) graduate trainees will mentor undergraduate trainees, (b) faculty will explicitly discuss human factors in academic practice; (c) there will be post-mortems after seminars by outside speakers. (2) Computational psychiatry: We propose new courses and research opportunities that are designed specifically to link cognitive function and the neurobiology of neural circuits. We propose innovative education in the nascent field of Computational Psychiatry, to bring theory and circuit modeling to clinical research in mental health. (3) Broad preparation: We aim to prepare trainees for jobs not only in academia, but also in medical and industry research. To achieve this, we will utilize our strength in machine learning and data science to broaden computational neuroscience training. The Program Directors have complementary strengths and will have complementary roles in the program. Wang will supervise graduate trainees and focus on training in mechanistic/circuit-level side of computational neuroscience as well as computational psychiatry. Ma will supervise undergraduate trainees and focus on the computational/behavioral side. This grant will support training of a new generation of graduate and undergraduate students in  computational neuroscience, which has become increasingly important to meet the challenges of  making discoveries with new data analysis tools and of understanding highly nonlinear complex  neural circuits. A salient component of our program is training in the nascent field  of   Computational  Psychiatry,  bridging  basic  neuroscience  and clinical research on mental  disorders. Therefore, the proposed program has the potential of making  a significant impact on  mental health.",Training a new generation of computational neuroscientists bridging neurobiology,9544939,R90DA043849,"['Academia', 'Algorithms', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Clinical Research', 'Computer Simulation', 'Data Analyses', 'Data Science', 'Development', 'Education', 'Educational process of instructing', 'Ensure', 'Faculty', 'Generations', 'Grant', 'Human', 'Impairment', 'Industry', 'Institutes', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurosciences', 'New York', 'Occupations', 'Preparation', 'Psychiatry', 'Psychology', 'Research', 'Role', 'Science', 'Side', 'Students', 'Supervision', 'Teacher Professional Development', 'Techniques', 'Training', 'Training Programs', 'Universities', 'cognitive function', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'design', 'innovation', 'mathematical sciences', 'medical schools', 'neural circuit', 'programs', 'relating to nervous system', 'theories', 'undergraduate education', 'undergraduate student']",NIDA,NEW YORK UNIVERSITY,R90,2018,210165,0.03594438421696144
"SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community Physics-based simulations provide a powerful framework for understanding biological form and function. They harmonize heterogeneous experimental data with real-world physical constraints, helping researchers understand biological systems as they engineer novel drugs, new diagnostics, medical devices, and surgical interventions. The rise in new sensors and simulation tools is generating an increasing amount of data, but this data is often inaccessible, preventing reuse and limiting scientific progress. In 2005, we launched SimTK, a website to develop and share biosimulation tools, models, and data, to address these issues. SimTK now supports 62,000+ researchers globally and 950+ projects. Members use it to meet their grants’ data sharing responsibilities; experiment with new ways of collaborating; and build communities around their datasets and tools. However, challenges remain: many researchers still do not share their digital assets due to the time needed to prepare, document, and maintain those assets, and since SimTK hosts a growing number of diverse digital assets, the site now also faces the challenge of making these assets discoverable and reusable. Thus, we propose a plan to extend SimTK and implement new solutions to promote scientific data sharing and reuse. First, we will maintain the reliable, user-friendly foundation upon which SimTK is built, continuing to provide the excellent support our members expect and supporting the site’s existing features for sharing and building communities. Second, we will implement methods to establish a culture of model and data sharing in the biomechanics community. We will encourage researchers to adopt new habits, making sharing part of their workflow, by enabling the software and systems they use to automatically upload models and data to SimTK via an application programming interface (API) and by recruiting leading researchers in the community to serve as beta testers and role models. Third, we will create tools to easily replicate and extend biomechanics simulations. Containers and cloud computing services allow researchers to capture and share a snapshot of their computing environment, enabling unprecedented fidelity in sharing. We will integrate these technologies into SimTK and provide custom, easy-to-use interfaces to replicate and extend simulation studies. Lastly, we will develop a metadata standard for models and data for the biomechanics community, increasing reusability and discoverability of the rich set of resources shared on SimTK. We will use the new standard on SimTK and fill in the metadata fields automatically using natural language processing and machine learning, minimizing the burden and inaccuracies of manual metadata entry. We will evaluate our success in achieving these aims by tracking the number of assets shared and the frequency they are used as a springboard to new research. These changes will accelerate biomechanics research and provide new tools to increase the reusability and impact of shared resources. By lowering barriers to data sharing in the biosimulation community, SimTK will continue to serve as a model for how to create national infrastructure for scientific subdisciplines. SimTK is a vibrant hub for the development and sharing of simulation software, data, and models of biological structures and processes. SimTK-based resources are being used to design medical devices and drugs, to generate new diagnostics, to create surgical interventions, and to provide insights into biology. The proposed enhancements to SimTK will accelerate progress in the field by lowering barriers to and standardizing data and model sharing, thus 1) increasing the quantity and also, importantly, the quality of resources that researchers share and 2) enabling others to reproduce and build on the wealth of past biomechanics research studies.",SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community,9523638,R01GM124443,"['Achievement', 'Address', 'Adopted', 'Biological', 'Biological Models', 'Biology', 'Biomechanics', 'Biophysics', 'Cloud Computing', 'Code', 'Communities', 'Computer software', 'Custom', 'Data', 'Data Files', 'Data Set', 'Development', 'Documentation', 'Ecosystem', 'Engineering', 'Ensure', 'Environment', 'Explosion', 'Face', 'Foundations', 'Frequencies', 'Goals', 'Grant', 'Habits', 'Letters', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Device', 'Medical Device Designs', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Operative Surgical Procedures', 'Pharmaceutical Preparations', 'Physics', 'Process', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Sharing', 'Resources', 'Security', 'Services', 'Site', 'Standardization', 'Structure', 'System', 'Technology', 'Time', 'Update', 'Work', 'application programming interface', 'base', 'biological systems', 'biomechanical model', 'community building', 'complex biological systems', 'data access', 'data sharing', 'digital', 'experience', 'experimental study', 'insight', 'member', 'new technology', 'novel diagnostics', 'novel therapeutics', 'prevent', 'recruit', 'research study', 'response', 'role model', 'sensor', 'simulation', 'simulation software', 'software systems', 'success', 'tool', 'user-friendly', 'web site']",NIGMS,STANFORD UNIVERSITY,R01,2018,478806,0.0013932243045326686
"Adapting the Berkeley Big Data Analytics Stack to Genomics and Health Project Summary We propose building a computational platform based on the high performance Berkeley Big Data Analytics Stack (BDAS) to support a new ecosystem of Clinical Decision Support (CDS) applications. This platform will make it faster, easier, and less expensive to develop molecular Clinical Decision Support Systems. These systems require real-time queries of globally distributed data, efficient machine learning on large genomic datasets, and must be secure, fault-tolerant and scalable. BDAS and associated technologies are designed to help us meet these challenges and are therefore ideal building blocks to help us create our computational platform. To encourage the adoption of standards for the querying and sharing of large genomic datasets, we will adapt the BDAS stack to support the standards of the Global Alliance for Genomics and Health (GA4GH). Project Narrative Funding this work will help establish a production quality FOSS implementation of the important Global Alliance for Genomics and Health standards. Without such open-source implementations, a fragmented and proprietary platform ecosystem would slow down innovation as well as divert resources away from the practice of medicine.",Adapting the Berkeley Big Data Analytics Stack to Genomics and Health,9566212,R44GM119858,"['Adoption', 'Algorithms', 'Apache', 'Big Data', 'Big Data to Knowledge', 'Businesses', 'Capital', 'Clinical Decision Support Systems', 'Cloud Computing', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Contractor', 'Data', 'Data Analytics', 'Data Set', 'Distributed Systems', 'Ecosystem', 'Ensure', 'Feedback', 'Funding', 'Genome', 'Genomics', 'Health', 'Individual', 'Industrialization', 'Industry', 'Ingestion', 'Institutes', 'International', 'Leadership', 'Letters', 'Machine Learning', 'Maintenance', 'Measures', 'Medicine', 'Molecular', 'Performance', 'Phase', 'Phenotype', 'Policies', 'Production', 'Provider', 'Publications', 'Resources', 'Running', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Software Tools', 'Source', 'System', 'Technology', 'Time', 'Training', 'Variant', 'Work', 'base', 'clinical decision support', 'cloud platform', 'cluster computing', 'commercialization', 'design', 'distributed data', 'genomic data', 'health care delivery', 'individual patient', 'innovation', 'open source', 'operation', 'petabyte', 'precision medicine', 'symposium', 'web services', 'whole genome']",NIGMS,"CUROVERSE INNOVATIONS, INC.",R44,2018,1069680,0.013671574917505576
"INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE Project Summary  To understand the many disorders of the brain it is necessary to grapple with its complexity.  Increasingly large and complicated data sets are being collected, but the tools for analyzing and  modeling the data are not yet available. More researchers trained in computational neuroscience are  desperately needed. This project supports graduate and undergraduate training programs in  computational neuroscience (TPCN) at both Carnegie Mellon University (CMU) and the University of  Pittsburgh (Pitt), and a summer school in computational neuroscience for undergraduates, which are  available to students coming from colleges and universities throughout the United States.  The CMU-Pitt TPCN has 16 training faculty in computational neuroscience, 22 training faculty whose  laboratories are primarily experimental, and 20 training faculty whose laboratories are both  computational and experimental. At the graduate level the TPCN offers a PhD program in Neural  Computation (PNC) and joint PhD programs with CMU’s Department of Statistics (PNC-Stat) and its  Machine Learning Department (PNC- MLD), all set within a highly collegial, cross-disciplinary  environment of our Center for the Neural Basis of Cognition (CNBC), which is operated jointly by  CMU and Pitt. The CNBC was established in 1994 to foster interdisciplinary research on the neural  mechanisms of brain function, and now comprises 145 faculty having appointments in 22 departments.  At the undergraduate level a substantial pool of local students is supplemented during the summer  by a cohort of students from across the country. During this renewal funding period the project is  strengthening the role of statistics and machine learning throughout the training programs; (2) revising the summer undergraduate program by creating a didactic two-week “boot camp” at the  beginning, which includes a 20-lecture overview of computational neuroscience; (3) creating online  materials, in conjunction with the boot camp, that will serve not only our own students but also  the greater world of training in computational neuroscience; and (4) enhancing our minority  recruitment by (a) taking advantage of the boot camp and online materials, as well as making  promotional visits to targeted campuses, and (b) creating and running a one-year “bridge” program  to better prepare under-represented minorities for PhD programs.  TPCN trainees work in vertically integrated, cross-disciplinary research teams. Graduate students  take a year- long course in computational neuroscience that bridges modeling and modern statistical  machine learning approaches to neuroscience. To ensure their competency in core neuroscience  principles they also take courses in cognitive neuroscience, neurophysiology, and systems  neuroscience. They then pursue depth in a relevant quantitative discipline, such as computer  science, engineering, mathematics, or statistics. Graduate students have extended experience in at  least one experimental laboratory, and they take part in journal clubs and seminars within the  large Pittsburgh neuroscience community. Year-long undergraduates take courses in mathematics,  computer programming, statistics, and neuroscience; they take an additional course in neuroscience  or psychology and a course in computational neuroscience; and they complete a year-long research  project. In addition, they complete the TPCN summer program. Undergraduate trainees in the summer  program go through the boot camp on topics in computational neuroscience, including tutorials in  Matlab, statistical methods, fundamentals of differential equations, and ideas of neural coding;  they then complete a research project under careful guidance. All trainees will receive training in  responsible conduct of research. Across 5 years of funding, the TPCN supports 20 NRSA graduate  students, 10 non-NRSA graduate students, 30 undergraduate year-long fellows, and 60 undergraduate  summer fellows. Project Narrative  Research in neuroscience is crucial for attacking the causes of neurological and mental health  disorders. If the field of neuroscience is to continue its rapid advance, neuroscientists must use,  understand, and develop new technologies, acquire and analyze ever larger data sets, and grapple  more directly with the complexity of neurobiological systems. The primary goal of these training  programs will be to help train a new generation of interdisciplinary neuroscientists with strong  quantitative skills.",INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE,9548637,R90DA023426,"['Appointment', 'Brain', 'Brain Diseases', 'Code', 'Cognition', 'Communities', 'Competence', 'Country', 'Data Set', 'Differential Equation', 'Discipline', 'Doctor of Philosophy', 'Educational Status', 'Engineering', 'Ensure', 'Environment', 'Faculty', 'Fostering', 'Funding', 'Interdisciplinary Study', 'Joints', 'Journals', 'Laboratories', 'Machine Learning', 'Mathematics', 'Minority Recruitment', 'Modeling', 'Modernization', 'National Research Service Awards', 'Neurosciences', 'Psychology', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Running', 'Schools', 'Statistical Methods', 'Students', 'System', 'Teacher Professional Development', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States', 'Universities', 'Visit', 'Work', 'bridge program', 'cognitive neuroscience', 'cohort', 'college', 'computational neuroscience', 'computer program', 'computer science', 'data modeling', 'experience', 'graduate student', 'lectures', 'neuromechanism', 'neurophysiology', 'programs', 'relating to nervous system', 'responsible research conduct', 'statistics', 'summer program', 'tool', 'undergraduate student']",NIDA,CARNEGIE-MELLON UNIVERSITY,R90,2018,305372,0.03394526838430016
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,9549126,K99HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'comparative effectiveness', 'computer science', 'data sharing', 'design', 'digital', 'effectiveness research', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'learning strategy', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'point of care', 'predictive modeling', 'privacy protection', 'programs', 'public trust', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2018,81977,0.004927709209659669
"Intelligent deployment of containerized bioinformatics workflows on the cloud PROJECT SUMMARY Cloud computing has emerged as a promising solution to address the challenges of big data. Public cloud vendors provide computing as-a-utility enabling users to pay only for the resources that are actually used. In this application, we will develop methods and tools to enable biomedical researchers to optimize the costs of cloud computing when analyzing biomedical big data. Infrastructure-as-a-Service (IaaS) cloud provides computing as a utility, on-demand, to end users, enabling cloud resources to be rapidly provisioned and scaled to meet computational and performance requirements. In addition, dynamic intelligent allocation of cloud computing resources has great potential to both improve performance and reduce hosting costs. Unfortunately, determining the most cost-effective and efficient ways to deploy modules on the cloud is non- trivial, due to a plethora of cloud vendors, each providing different types of virtual machines with different capabilities, performance trade-offs, and pricing structures. In addition, modern bioinformatics workflows consist of multiple modules, applications and libraries, each with their own set of software dependencies. Software containers package binary executables and scripts into modules with their software dependencies. With containers that compartmentalize software dependencies, modules implemented as containers can be mixed and matched to create workflows that give identical results on any platform. The high degree of reproducibility and flexibility of software containers makes them ideal instruments for disseminating complex bioinformatics workflows. Our overarching goal is to deliver the latest technological advances in containers and cloud computing to a typical biomedical researcher with limited resources who works with big data. Specifically, we will develop a user-friendly drag-and-drop interface to enable biomedical researchers to build and edit containerized workflows. Most importantly, users can choose to deploy and scale selected modules in the workflow on cloud computing platforms in a transparent, yet guided fashion, to optimize cost and performance. Our aim is to provide a federated approach that leverages resources from multiple cloud vendors. We have assembled a team of interdisciplinary scientists with expertise in bioinformatics, cloud and distributed computing, and machine learning. As part of this application, we will work closely with end users who routinely generate and analyze RNA-seq data. We will illustrate how our containerized, cloud-enabled methods and tools will benefit bioinformatics analyses. Project Narrative Cloud computing has emerged as a promising solution to address the challenge of analyzing diverse and massive data generated to advance our understanding of health and diseases. We will develop methods and tools to build and intelligently deploy modular and cloud-enabled bioinformatics workflows. These tools will allow the biomedical community to optimize the costs associated with cloud computing and to facilitate the replication of scientific results.",Intelligent deployment of containerized bioinformatics workflows on the cloud,9422475,R01GM126019,"['Address', 'Big Data', 'Bioinformatics', 'Case Study', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Dependence', 'Development', 'Disease', 'Docking', 'Documentation', 'Drops', 'Drug toxicity', 'Educational Materials', 'Ensure', 'Feedback', 'Generations', 'Goals', 'Health', 'Hospitals', 'Image', 'Libraries', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Performance', 'Price', 'Privatization', 'RNA analysis', 'Reproducibility', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Schedule', 'Scientist', 'Services', 'Software Tools', 'Structure', 'Technical Expertise', 'Technology Transfer', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'cloud platform', 'cluster computing', 'computing resources', 'cost', 'cost effective', 'distributed data', 'expectation', 'flexibility', 'graphical user interface', 'improved', 'instrument', 'outreach', 'predictive modeling', 'prototype', 'tool', 'tool development', 'transcriptome sequencing', 'user-friendly', 'virtual', 'web site']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2018,356646,0.005783599197093029
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9478117,U54AI117924,"['Address', 'Biological', 'Blood coagulation', 'Breast Cancer Risk Factor', 'Clinical', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'biomedical scientist', 'clinical investigation', 'clinical predictors', 'education research', 'graduate student', 'high dimensionality', 'improved', 'innovation', 'interest', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning', 'undergraduate student']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2018,897471,0.00016662745926958368
"HERCULES: Exposome Research Center PROJECT SUMMARY: HERCULES The vision of the HERCULES P30 is to demonstrably advance the role of environmental health sciences in clinical and public health settings using the platform of the exposome. Healthcare and biomedical research have become increasingly genome-centric. While much of this is due to the impressive achievements in genomics, which have consistently outpaced gains in environmental health, it is our contention that a more persuasive case needs to be made for environmental factors. Science and intuition support the idea that the environment plays just as large of a role as genetics for the majority of diseases. The exposome, which embraces a strategy and scale similar to genomic research, is poised to elevate the environment in discussions of health and disease. We will continue to grow and enhance the environmental health science research portfolio at Emory through cutting-edge technologies and innovative data solutions. We will build upon the superb relationships we have built with the local community and continue to push the mission of NIEHS on campus and across the scientific landscape. Based on the extraordinary progress over our first three years, we propose to retain our theme to use exposome-related concepts and approaches to improve human health. This simple and unifying vision will continue to stimulate discovery, promote collaboration, and enhance communication through the following Specific Aims: Specific Aim 1. To marshal physical and intellectual resources to support exposome-related approaches (high-resolution metabolomics, analytical chemistry, systems biology, machine learning, bioinformatics, high-throughput toxicology, and spatial and temporal statistical models) through cores, pilot funding, mentoring, and research forums. Specific Aim 2. To make major contributions towards exposome and environmental health science research. Specific Aim 3. To provide career development activities around innovative and emerging concepts and approaches related to the exposome. Specific Aim 4. To enhance and expand existing relationships with community partners to resolve environmental health issues in the community using exposome principles. Specific Aim 5. To provide infrastructure and resources to facilitate rapid translation of novel scientific findings into the development of prevention and treatment strategies in humans. Pursuit of HERCULES' aims will advance environmental health sciences within our institutions and in the scientific community. PROJECT NARRATIVE: HERCULES Human health and disease is dictated by a combination of genetic and environmental factors. The HERCULES Center is focused on providing a more comprehensive assessment of these environmental influences by utilizing exposome-based concepts and approaches.",HERCULES: Exposome Research Center,9490340,P30ES019776,"['Achievement', 'Analytical Chemistry', 'Award', 'Bioinformatics', 'Biomedical Research', 'Climate', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Community Outreach', 'Core Facility', 'Data', 'Data Science', 'Development', 'Discipline', 'Disease', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Care Research', 'Health Sciences', 'Human', 'Individual', 'Institution', 'Intuition', 'Leadership', 'Letters', 'Machine Learning', 'Marshal', 'Mentors', 'Mission', 'National Institute of Environmental Health Sciences', 'Phase', 'Play', 'Prevention strategy', 'Productivity', 'Public Health', 'Research', 'Research Activity', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Statistical Models', 'Strategic Planning', 'Systems Biology', 'Technology', 'Toxicology', 'Translations', 'Update', 'Vision', 'base', 'career development', 'catalyst', 'health science research', 'improved', 'innovation', 'metabolomics', 'novel', 'operation', 'ranpirnase', 'treatment strategy']",NIEHS,EMORY UNIVERSITY,P30,2018,1536744,0.01771188660310311
"HERCULES: Exposome Research Center PROJECT SUMMARY: HERCULES The vision of the HERCULES P30 is to demonstrably advance the role of environmental health sciences in clinical and public health settings using the platform of the exposome. Healthcare and biomedical research have become increasingly genome-centric. While much of this is due to the impressive achievements in genomics, which have consistently outpaced gains in environmental health, it is our contention that a more persuasive case needs to be made for environmental factors. Science and intuition support the idea that the environment plays just as large of a role as genetics for the majority of diseases. The exposome, which embraces a strategy and scale similar to genomic research, is poised to elevate the environment in discussions of health and disease. We will continue to grow and enhance the environmental health science research portfolio at Emory through cutting-edge technologies and innovative data solutions. We will build upon the superb relationships we have built with the local community and continue to push the mission of NIEHS on campus and across the scientific landscape. Based on the extraordinary progress over our first three years, we propose to retain our theme to use exposome-related concepts and approaches to improve human health. This simple and unifying vision will continue to stimulate discovery, promote collaboration, and enhance communication through the following Specific Aims: Specific Aim 1. To marshal physical and intellectual resources to support exposome-related approaches (high-resolution metabolomics, analytical chemistry, systems biology, machine learning, bioinformatics, high-throughput toxicology, and spatial and temporal statistical models) through cores, pilot funding, mentoring, and research forums. Specific Aim 2. To make major contributions towards exposome and environmental health science research. Specific Aim 3. To provide career development activities around innovative and emerging concepts and approaches related to the exposome. Specific Aim 4. To enhance and expand existing relationships with community partners to resolve environmental health issues in the community using exposome principles. Specific Aim 5. To provide infrastructure and resources to facilitate rapid translation of novel scientific findings into the development of prevention and treatment strategies in humans. Pursuit of HERCULES' aims will advance environmental health sciences within our institutions and in the scientific community. PROJECT NARRATIVE: HERCULES Human health and disease is dictated by a combination of genetic and environmental factors. The HERCULES Center is focused on providing a more comprehensive assessment of these environmental influences by utilizing exposome-based concepts and approaches.",HERCULES: Exposome Research Center,9764035,P30ES019776,"['Achievement', 'Analytical Chemistry', 'Award', 'Bioinformatics', 'Biomedical Research', 'Climate', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Community Outreach', 'Core Facility', 'Data', 'Data Science', 'Development', 'Discipline', 'Disease', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Care Research', 'Health Sciences', 'Human', 'Individual', 'Institution', 'Intuition', 'Leadership', 'Letters', 'Machine Learning', 'Marshal', 'Mentors', 'Mission', 'National Institute of Environmental Health Sciences', 'Phase', 'Play', 'Prevention strategy', 'Productivity', 'Public Health', 'Research', 'Research Activity', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Statistical Models', 'Strategic Planning', 'Systems Biology', 'Technology', 'Toxicology', 'Translations', 'Update', 'Vision', 'base', 'career development', 'catalyst', 'health science research', 'improved', 'innovation', 'metabolomics', 'novel', 'operation', 'ranpirnase', 'treatment strategy']",NIEHS,EMORY UNIVERSITY,P30,2018,74880,0.01771188660310311
"HERCULES: Exposome Research Center PROJECT SUMMARY: HERCULES The vision of the HERCULES P30 is to demonstrably advance the role of environmental health sciences in clinical and public health settings using the platform of the exposome. Healthcare and biomedical research have become increasingly genome-centric. While much of this is due to the impressive achievements in genomics, which have consistently outpaced gains in environmental health, it is our contention that a more persuasive case needs to be made for environmental factors. Science and intuition support the idea that the environment plays just as large of a role as genetics for the majority of diseases. The exposome, which embraces a strategy and scale similar to genomic research, is poised to elevate the environment in discussions of health and disease. We will continue to grow and enhance the environmental health science research portfolio at Emory through cutting-edge technologies and innovative data solutions. We will build upon the superb relationships we have built with the local community and continue to push the mission of NIEHS on campus and across the scientific landscape. Based on the extraordinary progress over our first three years, we propose to retain our theme to use exposome-related concepts and approaches to improve human health. This simple and unifying vision will continue to stimulate discovery, promote collaboration, and enhance communication through the following Specific Aims: Specific Aim 1. To marshal physical and intellectual resources to support exposome-related approaches (high-resolution metabolomics, analytical chemistry, systems biology, machine learning, bioinformatics, high-throughput toxicology, and spatial and temporal statistical models) through cores, pilot funding, mentoring, and research forums. Specific Aim 2. To make major contributions towards exposome and environmental health science research. Specific Aim 3. To provide career development activities around innovative and emerging concepts and approaches related to the exposome. Specific Aim 4. To enhance and expand existing relationships with community partners to resolve environmental health issues in the community using exposome principles. Specific Aim 5. To provide infrastructure and resources to facilitate rapid translation of novel scientific findings into the development of prevention and treatment strategies in humans. Pursuit of HERCULES' aims will advance environmental health sciences within our institutions and in the scientific community. PROJECT NARRATIVE: HERCULES Human health and disease is dictated by a combination of genetic and environmental factors. The HERCULES Center is focused on providing a more comprehensive assessment of these environmental influences by utilizing exposome-based concepts and approaches.",HERCULES: Exposome Research Center,9764029,P30ES019776,"['Achievement', 'Analytical Chemistry', 'Award', 'Bioinformatics', 'Biomedical Research', 'Climate', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Community Outreach', 'Core Facility', 'Data', 'Data Science', 'Development', 'Discipline', 'Disease', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Care Research', 'Health Sciences', 'Human', 'Individual', 'Institution', 'Intuition', 'Leadership', 'Letters', 'Machine Learning', 'Marshal', 'Mentors', 'Mission', 'National Institute of Environmental Health Sciences', 'Phase', 'Play', 'Prevention strategy', 'Productivity', 'Public Health', 'Research', 'Research Activity', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Statistical Models', 'Strategic Planning', 'Systems Biology', 'Technology', 'Toxicology', 'Translations', 'Update', 'Vision', 'base', 'career development', 'catalyst', 'health science research', 'improved', 'innovation', 'metabolomics', 'novel', 'operation', 'ranpirnase', 'treatment strategy']",NIEHS,EMORY UNIVERSITY,P30,2018,114880,0.01771188660310311
"Device for real-time streaming of preclinical research data into a central cloud-based platform Project Summary BehaviorCloud is a unified cloud platform where biomedical researchers can collect, analyze, and share preclinical research data – specifically behavioral and phenotype data from animal models. Traditionally researchers collect data from many disparate instruments and store data on PCs running single license software. Raw data is stored across several locations, analysis is restricted to the PC used to collect the data, and opportunities for collaboration, remote-participation, and data sharing are limited. BehaviorCloud is leveraging cloud data streaming and storage to overcome these barriers to discovery. In 2017 BehaviorCloud released a first version of the underlying cloud platform as well as BehaviorCloud Camera, an open-source “reference implementation” that demonstrates automated video tracking of animal behavior on the BehaviorCloud platform using a consumer-grade smartphone. This tool and the underlying platform are both in active use across academic and pharmaceutical labs. The aim of this Phase I SBIR application is to develop patent-pending “Bridge” technology that allows data streaming from third-party instrumentation into the central web platform. Researchers will bypass the original software and PCs associated with their instruments to control trials through their BehaviorCloud account and receive data back in real-time. BehaviorCloud will provide a public repository to aggregate all of these data and accelerate discovery by providing computational tools for large-scale meta-analysis and machine learning based predictive analytics. Project Narrative BehaviorCloud is a unified cloud platform where biomedical researchers can collect, analyze, and share preclinical research data – specifically behavioral and phenotype data from animal models. The goal of this Phase I SBIR application is to develop the technology to enable streaming of data from all kinds of behavioral and phenotyping instrumentation into the BehaviorCloud platform. BehaviorCloud will aggregate these data into a repository and accelerate discovery by providing tools for collaboration and meta-analysis.",Device for real-time streaming of preclinical research data into a central cloud-based platform,9621228,R43OD025448,"['Adoption', 'Animal Behavior', 'Animal Experimentation', 'Animal Model', 'Area', 'Back', 'Behavioral', 'Bypass', 'Carbon Dioxide', 'Cellular Phone', 'Collaborations', 'Computer software', 'Computers', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Development', 'Devices', 'Goals', 'Heart Rate', 'Information Systems', 'Internet', 'Intervention', 'Legal patent', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Meta-Analysis', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Physiological', 'Positioning Attribute', 'Predictive Analytics', 'Process', 'Research', 'Research Contracts', 'Research Personnel', 'Resources', 'Running', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Standardization', 'Stimulus', 'Stream', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'cloud based', 'cloud platform', 'computerized tools', 'control trial', 'data management', 'data sharing', 'data warehouse', 'design', 'experimental study', 'instrument', 'instrumentation', 'laptop', 'open source', 'phenotypic data', 'pre-clinical', 'pre-clinical research', 'prototype', 'repository', 'tool', 'wasting', 'web interface']",OD,"BEHAVIORCLOUD, LLC",R43,2018,220420,-0.00484167413977592
"Statistical Methods for Ultrahigh-dimensional Biomedical Data This proposal develops novel statistics and machine learning methods for distributed analysis of big data in biomedical studies and precision medicine and for selecting a small group of molecules that are associated with biological and clinical outcomes from high-throughput data such as microarray, proteomic, and next generation sequence from biomedical research, especially for autism studies and Alzheimer’s disease research. It focuses on developing efficient distributed statistical methods for Big Data computing, storage, and communication, and for solving distributed health data collected at different locations that are hard to aggregate in meta-analysis due to privacy and ownership concerns. It develops both computationally and statistically efficient methods and valid statistical tools for exploring heterogeneity of big data in precision medicine, for studying associations of genomics and genetic information with clinical and biological outcomes, and for feature selection and model building in presence of errors-in- variables, endogeneity, and heavy-tail error distributions, and for predicting clinical outcomes and understanding molecular mechanisms. It introduces more robust and powerful statistical tests for selection of significant genes, SNPs, and proteins in presence of dependence of data, valid control of false discovery rate for dependent test statistics, and evaluation of treatment effects on a group of molecules. The strength and weakness of each proposed method will be critically analyzed via theoretical investigations and simulation studies. Related software will be developed for free dissemination. Data sets from ongoing autism research, Alzheimer’s disease, and other biomedical studies will be analyzed by using the newly developed methods and the results will be further biologically confirmed and investigated. The research findings will have strong impact on statistical analysis of high throughput big data for biomedical research and on understanding heterogeneity for precision medicine and molecular mechanisms of autism, Alzheimer’s disease, and other diseases. This proposal develops novel statistical machine learning methods and bioinformatic tools for finding genes, proteins, and SNPs that are associated with clinical outcomes and discovering heterogeneity for precision medicine. Data sets from ongoing autism research, Alzheimer’s disease and other biomedical studies will be critically analyzed using the newly developed statistical methods, and the results will be further biologically confirmed and investigated. The research findings will have strong impact on developing therapeutic targets and understanding heterogeneity for precision and molecular mechanisms of autism, Alzheimer’s diseases, and other diseases. !",Statistical Methods for Ultrahigh-dimensional Biomedical Data,9448918,R01GM072611,"['Address', 'Alzheimer&apos', 's Disease', 'Autistic Disorder', 'Big Data', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Brain', 'Classification', 'Clinical', 'Communication', 'Computer software', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Databases', 'Dependence', 'Dimensions', 'Disease', 'Disease Progression', 'Evaluation', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genomics', 'Heterogeneity', 'Internet', 'Investigation', 'Learning', 'Linear Models', 'Location', 'Machine Learning', 'Meta-Analysis', 'Methods', 'Molecular', 'Outcome', 'Ownership', 'Patients', 'Polynomial Models', 'Principal Component Analysis', 'Privacy', 'Proteins', 'Proteomics', 'Research', 'Role', 'Statistical Data Interpretation', 'Statistical Methods', 'Tail', 'Techniques', 'Testing', 'Time', 'big biomedical data', 'cell type', 'computing resources', 'genetic information', 'health data', 'high dimensionality', 'high throughput analysis', 'improved', 'learning strategy', 'macrophage', 'model building', 'next generation', 'novel', 'precision medicine', 'predict clinical outcome', 'simulation', 'statistics', 'therapeutic target', 'tool', 'transcriptome sequencing', 'treatment effect']",NIGMS,PRINCETON UNIVERSITY,R01,2018,308503,-0.019719329287953297
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9547466,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophageal', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'improved', 'in vivo', 'learning strategy', 'lymph nodes', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2018,347834,0.0064977420675960025
"Summer Institute in Neuroimaging and Data Science Project Summary/Abstract The study of the human brain with neuroimaging technologies is at the cusp of an exciting era of Big Data. Many data collection projects, such as the NIH-funded Human Connectome Project, have made large, high- quality datasets of human neuroimaging data freely available to researchers. These large data sets promise to provide important new insights about human brain structure and function, and to provide us the clues needed to address a variety of neurological and psychiatric disorders. However, neuroscience researchers still face substantial challenges in capitalizing on these data, because these Big Data require a different set of technical and theoretical tools than those that are required for analyzing traditional experimental data. These skills and ideas, collectively referred to as Data Science, include knowledge in computer science and software engineering, databases, machine learning and statistics, and data visualization.  The Summer Institute in Data Science for Neuroimaging will combine instruction by experts in data science methodology and by leading neuroimaging researchers that are applying data science to answer scientiﬁc ques- tions about the human brain. In addition to lectures on the theoretical background of data science methodology and its application to neuroimaging, the course will emphasize experiential hands-on training in problem-solving tutorials, as well as project-based learning, in which the students will create small projects based on openly available datasets. Summer Institute in Neuroimaging and Data Science: Project Narrative The Summer Institute in Neuroimaging and Data Science will provide training in modern data science tools and methods, such as programming, data management, machine learning and data visualization. Through lectures, hands-on training sessions and team projects, it will empower scientists from a variety of backgrounds in the use of these tools in research on the human brain and on neurological and psychiatric brain disorders.",Summer Institute in Neuroimaging and Data Science,9491911,R25MH112480,"['Address', 'Adopted', 'Big Data', 'Brain', 'Brain Diseases', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Data Set', 'Databases', 'Discipline', 'Face', 'Faculty', 'Fostering', 'Funding', 'Habits', 'Home environment', 'Human', 'Image', 'Institutes', 'Institution', 'Instruction', 'Internet', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mental disorders', 'Methodology', 'Methods', 'Modernization', 'Neurologic', 'Neurosciences', 'Participant', 'Positioning Attribute', 'Problem Solving', 'Psychology', 'Reproducibility', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Software Engineering', 'Software Tools', 'Structure', 'Students', 'Technology', 'Testing', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'career', 'computer science', 'connectome', 'data management', 'data visualization', 'design', 'e-science', 'experimental study', 'high dimensionality', 'insight', 'instructor', 'interdisciplinary collaboration', 'knowledge base', 'lectures', 'nervous system disorder', 'neurogenetics', 'neuroimaging', 'novel', 'open source', 'prediction algorithm', 'programs', 'project-based learning', 'skills', 'statistics', 'success', 'summer institute', 'theories', 'tool']",NIMH,UNIVERSITY OF WASHINGTON,R25,2018,199622,-0.006953217115588497
"QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine  The purpose of this proposal is to develop a combination of innovative statistical and data visualization approaches using patient-generated health data, including mobile health (mHealth) data from wearable devices and smartphones, and patient-reported outcomes, to improve outcomes for patients with Inflammatory Bowel Diseases (IBDs). This research will offer new insights into how to process and transform patient-generated health data into precise lifestyle recommendations to help achieve remission of symptoms. The specific aims of this research are: 1) To develop new preprocessing methods for publicly available, heterogeneous, time-varied mHealth data to develop a high quality mHealth dataset; 2) To develop and apply novel machine learning methods to obtain accurate predictions and formal statistical inference for the influence of lifestyle features on disease activity in IBDs; and 3) To design and develop innovative, interactive data visualization tools for knowledge discovery. The methods developed in the areas of preprocessing of mHealth data, calibration for mHealth devices, machine learning, and interactive data visualization will be broadly applicable to other mHealth data, chronic conditions beyond IBDs, and other fields in which the data streams are highly variable, intermittent, and periodic. This work is highly relevant to the mission of the NIH BD2K initiative which supports the development of innovative and transformative approaches and tools to accelerate the integration of Big Data and data science into biomedical research. This project will also enhance training in the development and use of methods for biomedical Big Data science and mentor the next generation of multidisciplinary scientists. The proposed research is relevant to public health by seeking to improve symptoms for patients with inflammatory bowel diseases, which are chronic, life-long conditions with waxing and waning symptoms. Developing novel statistical and visualization methods to provide a more nuanced understanding of the precise relationship between physical activity and sleep to disease activity is relevant to BD2K's mission.",QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine ,9572992,R01EB025024,"['Adrenal Cortex Hormones', 'Adult', 'Adverse effects', 'Affect', 'Americas', 'Area', 'Behavior', 'Big Data', 'Big Data to Knowledge', 'Biomedical Research', 'Calibration', 'Caring', 'Cellular Phone', 'Characteristics', 'Chronic', 'Crohn&apos', 's disease', 'Data', 'Data Science', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Outcome', 'Disease remission', 'Dose', 'Effectiveness', 'Flare', 'Foundations', 'Functional disorder', 'Funding', 'Imagery', 'Immunosuppression', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Institute of Medicine (U.S.)', 'Knowledge Discovery', 'Life', 'Life Style', 'Life Style Modification', 'Longitudinal Surveys', 'Longitudinal cohort study', 'Machine Learning', 'Mathematics', 'Measures', 'Mentors', 'Methods', 'Mission', 'Moderate Activity', 'Morbidity - disease rate', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Periodicity', 'Phenotype', 'Physical activity', 'Precision therapeutics', 'Process', 'Public Health', 'Quality of life', 'Recommendation', 'Reporting', 'Research', 'Research Institute', 'Schools', 'Scientist', 'Sleep', 'Sleep disturbances', 'Stream', 'Symptoms', 'Therapeutic', 'Time', 'Training', 'Ulcerative Colitis', 'United States Agency for Healthcare Research and Quality', 'United States National Institutes of Health', 'Visualization software', 'Waxes', 'Work', 'base', 'big biomedical data', 'clinical remission', 'comparative effectiveness', 'cost', 'data visualization', 'design', 'disorder risk', 'effectiveness research', 'health data', 'improved', 'improved outcome', 'individual patient', 'innovation', 'insight', 'large bowel Crohn&apos', 's disease', 'learning strategy', 'lifestyle factors', 'mHealth', 'member', 'multidisciplinary', 'next generation', 'novel', 'precision medicine', 'sleep quality', 'symptomatic improvement', 'tool', 'wearable device']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2018,297237,-0.009421614212643953
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9420662,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2018,2000000,-0.0029911983325882543
"NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR) DESCRIPTION (provided by applicant):  We propose to establish a NIDA Center of Excellence for Computational Drug Abuse Research (CDAR) between the University of Pittsburgh (Pitt) and (CMU), with the goal of advancing and ensuring the productive and broad usage of state-of-the-art computational technologies that will facilitate and enhance drug abuse (DA) research, both in the local (Pittsburgh) area and nationwide. To this end, we will develop/integrate tools for DA-domain-specific chemical-to-protein-to-genomics mapping using cheminformatics, computational biology and computational genomics methods by centralizing computational chemical genomics (or chemogenomics) resources while also making them available on a cloud server. The Center will foster collaboration and advance knowledge-based translational research and increase the effectiveness of ongoing funded research project (FRPs) via the following Research Support Cores: (1) The Computational Chemogenomics Core for DA (CC4DA) will help address polydrug addiction/polypharmacology by developing new chemogenomics tools and by compiling the data collected/generated, along with those from other Cores, into a DA knowledge-based chemogenomics (DA-KB) repository that will be made accessible to the DA community. (2) The Computational Biology Core (CB4DA) will focus on developing a resource for structure-based investigation of the interactions among substances of DA and their target proteins, in addition to assessing the drugability of receptors and transporters involved in DA and addiction. These activities will be complemented by quantitative systems pharmacology methods to enable a systems-level approach to DA research. (3) The Computational Genomics Core (CG4DA) will carry out genome-wide discovery of new DA targets, markers, and epigenetic influences using developed machine learning models and algorithms. (4) The Administrative Core will coordinate Center activities, provide management to oversee the CDAR activities in consultation with the Scientific Steering Committee (SSC) and an External Advisory Board (EAB), ensure the effective dissemination of software/data among the Cores and the FRPs, and establish mentoring mechanisms to train junior researchers. Overall, the Center will strive to achieve the long-term goal of translating advances in computational chemistry, biology and genomics toward the development of novel personalized DA therapeutics. We propose a Computational Drug Abuse Research (CDAR) Center, as a joint initiative between the  University of Pittsburgh and Carnegie Mellon University. The Center consist of three Cores (CC4DA, CB4DA  and CG4DA) that will leverage our expertise in computational chemogenomics, computational biology, and  computational genomics to facilitate basic and translational drug abuse and medication research.",NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR),9527792,P30DA035778,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cannabinoids', 'Categories', 'Cells', 'Chemicals', 'Clinical Trials Network', 'Cloud Computing', 'Cocaine', 'Collaborations', 'Communities', 'Complement', 'Computational Biology', 'Computer software', 'Consultations', 'Data', 'Databases', 'Development', 'Doctor of Philosophy', 'Drug Addiction', 'Drug Receptors', 'Drug abuse', 'Effectiveness', 'Endocytosis', 'Ensure', 'Environmental Risk Factor', 'Epigenetic Process', 'Feedback', 'Fostering', 'Funding', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Intervention', 'Investigation', 'Joints', 'Leadership', 'Link', 'Machine Learning', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'National Institute of Drug Abuse', 'Neuropharmacology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacology', 'Phenotype', 'Proteins', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Science', 'Signal Transduction', 'Software Tools', 'Source', 'Structure', 'Substance Use Disorder', 'System', 'Systems Biology', 'Technology', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Universities', 'addiction', 'algorithmic methodologies', 'base', 'biobehavior', 'cheminformatics', 'cloud based', 'cloud platform', 'computational chemistry', 'computer science', 'data mining', 'design', 'distinguished professor', 'dopamine transporter', 'drug abuse prevention', 'falls', 'genome-wide', 'genome-wide analysis', 'improved', 'insight', 'knowledge base', 'member', 'novel', 'novel therapeutics', 'operation', 'prevent', 'professor', 'repository', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P30,2018,1080816,-0.0033933146064795586
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9612777,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image Analysis', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2018,39939,-0.03955528075106911
"Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership ﻿    DESCRIPTION (provided by applicant): The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The aims to achieve the goals are: 1) Implement an integrated didactic program to enhance student self-efficacy with computational and informatics tool development and use for interrogating and interpreting Big Data, including a two-semester bioinformatics course in Bioinformatics, informed by the expertise of UIUC KnowEnG BD2K Center faculty with additional Special Topics courses available remotely from UIUC. 2) Develop an integrated academic year (Fisk, or partners) and summer research program at the UIUC KnowEnG BD2K Center to assure student exposure to a participation in the life cycle of a `Big Data' research problem. 3) Implement a professional skills development program that assures successful transition of undergraduate participants to a Ph.D. (or MD/PhD Program) in Big Data- reliant biomedical research. 4) Launch a faculty development program in bioinformatics that leads to embracing Big Data problems in courses in multiple disciplines for impact on all Fisk undergraduate STEM majors. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fisk R25 mentors, of value for their broader education and research training goals at UIUC and Mayo. PUBLIC HEALTH RELEVANCE: The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fis R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.  ",Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership,9503633,R25MD010396,"['Address', 'Articulation', 'Base Pairing', 'Big Data', 'Big Data to Knowledge', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Career Choice', 'Cellular biology', 'Chemicals', 'Collaborations', 'Communication', 'Complement', 'Computers', 'Core Facility', 'Development Plans', 'Discipline', 'Doctor of Philosophy', 'Education Projects', 'Educational Curriculum', 'Educational workshop', 'Elements', 'Exposure to', 'Faculty', 'Faculty Workshop', 'Fostering', 'Funding', 'Genomics', 'Goals', 'Grant', 'Illinois', 'Informatics', 'Journals', 'Learning', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Manuscripts', 'Mathematics', 'Mentors', 'Molecular Biology', 'Oral', 'Participant', 'Program Development', 'Proteomics', 'Reading', 'Research', 'Research Ethics', 'Research Personnel', 'Research Training', 'Role', 'STEM field', 'Science', 'Scientist', 'Self Efficacy', 'Students', 'Systems Biology', 'Teacher Professional Development', 'Technology', 'Time', 'Training', 'Training Programs', 'Training and Education', 'Underrepresented Minority', 'Universities', 'Work', 'Writing', 'base', 'career', 'computer science', 'data acquisition', 'data sharing', 'deep learning', 'experience', 'faculty research', 'individualized medicine', 'innovation', 'minority scientist', 'posters', 'programs', 'public health relevance', 'recruit', 'responsible research conduct', 'skill acquisition', 'skills', 'summer research', 'tool', 'tool development', 'undergraduate research', 'undergraduate student']",NIMHD,FISK UNIVERSITY,R25,2018,216000,0.056210408849727125
"Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!) PROJECT SUMMARY/ABSTRACT Our society faces significant challenges in providing quality health care that is accessible by each person and is sensitive to each person's individual lifestyle and individual health needs. Due to recent advances in sensing technologies that have improved in accuracy, increased in throughput, and reduced in cost, it has become relatively easy to gather high resolution behavioral and individualized health data at scale. The resulting big datasets can be analyzed to understand the link between behavior and health and to design healthy behavior interventions. In this emerging area, however, very few courses are currently available for teaching researchers and practitioners about the foundational principles and best practices behind collecting, storing, analyzing, and using behavior- based sensor data. Teaching these skills can help the next generation of students thrive in the increasingly digital world.  The goal of this application is to design online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to WSU faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.  This contribution is significant because not only large research groups but even individual investigators can create large data sets that provide valuable, in-the-moment information about human behavior. They need to be able to handle the challenges that arise when working with sensor- based behavior data. Because students will receive hands-on training with actual sensor datasets and analysis tools, they will know how to get the best results from available tools and will be able to interpret the significance of analysis results.  Our proposed online course program, called AHA!, builds on the investigators' extensive experience and ongoing collaboration at Washington State University on the development of smart home and mobile health app design, activity recognition, scalable biological data mining, and the use of these technologies for clinical applications. Our approach will be to design online course modules to train individuals in the analysis of behavior-based sensor data using clinical case studies (Aim 1). We will design an educational program that involves students from diverse backgrounds and that is findable, accessible, interoperable, and reusable (Aim 2). Finally, we will conduct a thorough evaluation to monitor success and incrementally improve the program (Aim 3). All of the materials will be designed for continued use beyond the funding period of the program. PROJECT NARRATIVE  This program focuses on the development and dissemination of online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to Washington State University faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.",Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!),9482420,R25EB024327,"['Address', 'Aging', 'Area', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Big Data', 'Biological', 'Case Study', 'Charge', 'Chronic Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Data', 'Data Set', 'Development', 'Discipline', 'E-learning', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Evaluation', 'FAIR principles', 'Face', 'Faculty', 'Feedback', 'Foundations', 'Funding', 'General Population', 'Goals', 'Health', 'Home environment', 'Human', 'Immersion Investigative Technique', 'Individual', 'Interdisciplinary Study', 'Life Style', 'Link', 'Longevity', 'Machine Learning', 'Methods', 'Mobile Health Application', 'Monitor', 'Performance', 'Persons', 'Precision Medicine Initiative', 'Pythons', 'Rehabilitation Nursing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Site', 'Societies', 'Structure', 'Students', 'Suggestion', 'Techniques', 'Technology', 'Training', 'Universities', 'Washington', 'Work', 'base', 'behavior influence', 'behavioral health', 'biocomputing', 'career networking', 'clinical application', 'cognitive rehabilitation', 'cost', 'course development', 'course module', 'data mining', 'design', 'digital', 'experience', 'health care quality', 'health data', 'improved', 'innovation', 'learning materials', 'learning strategy', 'mHealth', 'next generation', 'online course', 'programs', 'recruit', 'responsible research conduct', 'scale up', 'sensor', 'sensor technology', 'skills', 'statistics', 'success', 'synergism', 'tool', 'web page']",NIBIB,WASHINGTON STATE UNIVERSITY,R25,2018,169419,0.022407389241209212
"Towards a FAIR Digital Ecosystem in the Cloud Cloud Computing, Big Data Analytics, and Artificial Intelligence are transforming biomedical research. The NIH Data Commons will provide a common, cloud-agnostic, harmonized environment where these technologies can be deployed to serve NIH intra- and extra-mural researchers, implementing FAIR principles [Wilkinson2016]. Our proposal provides two essential capabilities: (1) Global Unique Identification (GUIDs) and (2) Digital Object Publication, Citation, Replication and Reuse. We propose a FAIR biomedical ecosystem where all primary and derived digital objects (e.g., datasets, software) receive GUIDs, assisting with Findability and Accessibility, Reusability, data provenance, reproducibility, and accountability of research outcomes. GUIDs will provide full Interoperability between DOIs and prefix: accession based Compact Identifiers through a common resolution services prefix registry. All digital objects will interoperate with multiple, hybrid clouds—open source and commercial—enabling researchers to select computing resources best matching their needs. 1 - The Global Unique Identifier (GUID) Capability provides a persistent, machine resolvable identifier platform for all FAIR objects in the Commons, fully aligned with community practices, recommendations, and metadata models. 2 - The Cloud Dataverse for Biomedical Digital Object Publication, Citation, Replication, and Reuse applies FAIR principles to primary and derived datasets, computational provenance, and software, making them fully FAIR compliant, while documenting the production processes. Cloud Dataverse integrates with multiple cloud computing solutions. As an example, with these capabilities, a researcher can extract a subset of data from TOPMed or GTEx and publish it in Cloud Dataverse, with its associated metadata, provenance, and terms of use. In publications, she can cite the data and software according to Data Citation Publishers guidelines [Cousijn2017] and Software Citation Principles [Smith2016]. Other researchers can access the dataset using the GUID in the citation, resolving the repository’s dataset landing page (as recommended by the Data Citation Principles [Martone2014, Fenner2017, Starr2015]). From this landing page, researchers can repeat the original calculation, perform new computations on the dataset, or use the provenance graph to learn how the dataset was created. The data and software published in the repository reflect the evolving nature of research; anyone can publish new versions with the provenance documenting the process. Our open-source software platforms used in production, adhere to FAIR principles, and provide the basis for the two capabilities: GUIDs and Cloud Dataverse enabling the use cases above. We will expand upon them, produce new tools, and reach a wider community. Currently GUIDs and provenance describe datasets; we will generalize these mechanisms to support other digital objects, focusing on software in the pilot phase. We will connect and harmonize DataCite, identifiers.org, and N2T/EZID services to provide GUIDs; and integrate the Dataverse repository software with the Massachusetts Open Cloud, built on top of the OpenStack cloud platform, and public commercial clouds (Microsoft Azure, Google Cloud) to provide Cloud Dataverse. Our past experience producing sustainable services for overlapping communities of developers and users demonstrates our ability to apply our expertise to supporting the larger and more diverse NIH Data Commons user community. n/a",Towards a FAIR Digital Ecosystem in the Cloud,9672008,OT3OD025456,"['Accountability', 'Artificial Intelligence', 'Big Data', 'Biomedical Research', 'Cloud Computing', 'Communities', 'Community Practice', 'Computer software', 'Data', 'Data Analytics', 'Data Provenance', 'Data Set', 'Ecosystem', 'Environment', 'FAIR principles', 'Genotype-Tissue Expression Project', 'Graph', 'Guidelines', 'Hybrids', 'Learning', 'Massachusetts', 'Metadata', 'Modeling', 'Nature', 'Outcomes Research', 'Phase', 'Process', 'Production', 'Publications', 'Publishing', 'Recommendation', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Services', 'Technology', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'base', 'cloud platform', 'computing resources', 'digital', 'digital ecosystem', 'experience', 'interoperability', 'open source', 'repository', 'software repository', 'tool']",OD,HARVARD UNIVERSITY,OT3,2018,347221,-0.004316835912879408
"Towards a FAIR Digital Ecosystem in the Cloud Cloud Computing, Big Data Analytics, and Artificial Intelligence are transforming biomedical research. The NIH Data Commons will provide a common, cloud-agnostic, harmonized environment where these technologies can be deployed to serve NIH intra- and extra-mural researchers, implementing FAIR principles [Wilkinson2016]. Our proposal provides two essential capabilities: (1) Global Unique Identification (GUIDs) and (2) Digital Object Publication, Citation, Replication and Reuse. We propose a FAIR biomedical ecosystem where all primary and derived digital objects (e.g., datasets, software) receive GUIDs, assisting with Findability and Accessibility, Reusability, data provenance, reproducibility, and accountability of research outcomes. GUIDs will provide full Interoperability between DOIs and prefix: accession based Compact Identifiers through a common resolution services prefix registry. All digital objects will interoperate with multiple, hybrid clouds—open source and commercial—enabling researchers to select computing resources best matching their needs. 1 - The Global Unique Identifier (GUID) Capability provides a persistent, machine resolvable identifier platform for all FAIR objects in the Commons, fully aligned with community practices, recommendations, and metadata models. 2 - The Cloud Dataverse for Biomedical Digital Object Publication, Citation, Replication, and Reuse applies FAIR principles to primary and derived datasets, computational provenance, and software, making them fully FAIR compliant, while documenting the production processes. Cloud Dataverse integrates with multiple cloud computing solutions. As an example, with these capabilities, a researcher can extract a subset of data from TOPMed or GTEx and publish it in Cloud Dataverse, with its associated metadata, provenance, and terms of use. In publications, she can cite the data and software according to Data Citation Publishers guidelines [Cousijn2017] and Software Citation Principles [Smith2016]. Other researchers can access the dataset using the GUID in the citation, resolving the repository’s dataset landing page (as recommended by the Data Citation Principles [Martone2014, Fenner2017, Starr2015]). From this landing page, researchers can repeat the original calculation, perform new computations on the dataset, or use the provenance graph to learn how the dataset was created. The data and software published in the repository reflect the evolving nature of research; anyone can publish new versions with the provenance documenting the process. Our open-source software platforms used in production, adhere to FAIR principles, and provide the basis for the two capabilities: GUIDs and Cloud Dataverse enabling the use cases above. We will expand upon them, produce new tools, and reach a wider community. Currently GUIDs and provenance describe datasets; we will generalize these mechanisms to support other digital objects, focusing on software in the pilot phase. We will connect and harmonize DataCite, identifiers.org, and N2T/EZID services to provide GUIDs; and integrate the Dataverse repository software with the Massachusetts Open Cloud, built on top of the OpenStack cloud platform, and public commercial clouds (Microsoft Azure, Google Cloud) to provide Cloud Dataverse. Our past experience producing sustainable services for overlapping communities of developers and users demonstrates our ability to apply our expertise to supporting the larger and more diverse NIH Data Commons user community. n/a",Towards a FAIR Digital Ecosystem in the Cloud,9559873,OT3OD025456,"['Accountability', 'Artificial Intelligence', 'Big Data', 'Biomedical Research', 'Cloud Computing', 'Communities', 'Community Practice', 'Computer software', 'Data', 'Data Analytics', 'Data Provenance', 'Data Set', 'Ecosystem', 'Environment', 'FAIR principles', 'Genotype-Tissue Expression Project', 'Graph', 'Guidelines', 'Hybrids', 'Learning', 'Massachusetts', 'Metadata', 'Modeling', 'Nature', 'Outcomes Research', 'Phase', 'Process', 'Production', 'Publications', 'Publishing', 'Recommendation', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Services', 'Technology', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'base', 'cloud platform', 'computing resources', 'digital', 'digital ecosystem', 'experience', 'interoperability', 'open source', 'repository', 'software repository', 'tool']",OD,HARVARD UNIVERSITY,OT3,2018,300000,-0.004316835912879408
"Integrating multidimensional genomic data to discover clinically-relevant predictive models The goal of this NIH Pathway to Independence award is to provide Dr. Brittany Lasseigne with an extensive training program to prepare her to be an effective independent investigator who uses computational genomics to study complex human diseases. We propose a formal one-year training and mentoring program in genomics, computer science, statistics, and career development to build on her 8+ years of hands-on training, followed by a three-year structured and independent research program. Research will focus on the integration of multidimensional genomic data sets in the context of complex human diseases. A critical barrier in genomic research is the complexity of data integration: the ability to leverage overlapping and unique information captured by different genomic assays would improve our understanding of data integration and generate clinically relevant genomic signatures. To meet this need, we propose to integrate a combination of genomic data we generated with public data to (1) infer genomic instability signatures from different data types, (2) improve clinically relevant phenotype prediction by building multi-omics machine learning classifiers and reducing phenotype heterogeneity, and (3) create a cloud-enabled R package and associated Shiny application to accelerate future research. The proposed work will advance our understanding of data integration, allow inference of genomic instabilities across data sets, and generate high performance classifiers for assessing clinically relevant phenotypes in both cancer and psychiatric disease using frameworks that will be broadly applicable across other complex diseases. It will also facilitate prioritization of experiments in future studies by informing on the orthogonality of genomic assays, thereby allowing more efficient study designs to capture as much information as possible within a given sample size or scope of experimentation. Collectively, this additional training will allow Dr. Lasseigne to develop new multidimensional data integration approaches and translational questions applicable across complex diseases when independent. Dr. Richard Myers (HudsonAlpha) and Dr. Gregory Cooper (HudsonAlpha), leaders in applying genetics and genomics to complex human diseases, and an Advisory Committee of additional experts including Dr. Barbara Wold (Caltech), Dr. Eddy Yang (UAB), and Dr. Timothy Reddy (Duke), will provide mentoring throughout this award. The mentored phase will take place at the HudsonAlpha Institute for Biotechnology, an ideal environment for this training with extensive translational science collaborations, expert faculty and staff, and state-of-the art computational and laboratory resources devoted to genomics. This combination will maximize Dr. Lasseigne's training program, facilitating her transition to an independent, tenure-track investigator at a university with a strong commitment to data-driven approaches to complex human disease research, i.e. strong genomics research programs with clinical collaborators, ideally at, or affiliated with, an academic medical center. Project Narrative The major outcome of this project will be a scientist with the necessary research, mentoring, teaching, and career development training to run an independent research program in computational genomics. The research proposed will apply novel strategies to further develop integrative machine learning analyses of multidimensional genomic data, discover clinically relevant predictive models, and create computational tools to accelerate future research.",Integrating multidimensional genomic data to discover clinically-relevant predictive models,9526698,K99HG009678,"['Academic Medical Centers', 'Advisory Committees', 'Award', 'Bioconductor', 'Biological', 'Biological Assay', 'Biotechnology', 'Budgets', 'Cancer Etiology', 'Cell Proliferation', 'Cells', 'Characteristics', 'Chemotherapy-Oncologic Procedure', 'Chromosomal Instability', 'Chromosomes', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Copy Number Polymorphism', 'Coupling', 'CpG Island Methylator Phenotype', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Educational process of instructing', 'Environment', 'Faculty', 'Future', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Genomic Instability', 'Genomics', 'Goals', 'Heterogeneity', 'Imagery', 'Individual', 'Institutes', 'Instruction', 'Laboratories', 'Lasso', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mental disorders', 'Mentors', 'Methodology', 'Methylation', 'MicroRNAs', 'Microsatellite Instability', 'Modeling', 'Molecular Profiling', 'Neurons', 'Outcome', 'Pathway interactions', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Signal Transduction', 'Standardization', 'Structure', 'Systems Biology', 'Techniques', 'Testing', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Work', 'Yang', 'biomarker performance', 'career development', 'clinically relevant', 'computer science', 'computerized tools', 'data integration', 'data reduction', 'experimental study', 'genomic data', 'genomic signature', 'human disease', 'improved', 'insight', 'multiple omics', 'novel strategies', 'predictive modeling', 'programs', 'promoter', 'protein metabolite', 'response', 'single cell sequencing', 'statistics', 'tenure track', 'tool']",NHGRI,HUDSON-ALPHA INSTITUTE FOR BIOTECHNOLOGY,K99,2018,112117,0.008633736972344415
"Accelerating Multi-modal Biomarker Discovery in Translational Research with Cloud Data Integration Project Summary/Abstract Cytobank is the leading cloud-based platform for analysis and storage of single cell flow and mass cytometry data, technologies that are essential for investigating the interplay between the immune system and disease conditions including cancer. There are numerous data analysis steps between raw data and insight especially for many single-cell technologies, where the data analysis is complex, highly expert-driven and/or reliant on novel computational methodologies. Cytobank already makes major contributions (1) centralizing single-cell cytometry data, (2) providing data analysis traceability that removes knowledge sharing complexities, and (3) establishing a platform that increases access to cutting edge algorithms and makes complex machine learning methods easy for biologists to use. However, as the amount, complexity, and different types of single cell data and other associated data increases and the number of workflows and single-cell algorithms to analyze the data also increases, the need for open and easy access to existing and new tools and secure, complete storage of the workflows and the resulting data has increased to the point of being critical for supporting basic and translational research collaborations and enabling them to efficiently achieve their objectives including biomarker discovery and development. The proposed project significantly extends the capabilities of the Cytobank platform. This will benefit the community by (1) enabling scalable and secure access to a number of new single-cell data analysis tools that will result in new automated workflows, and (2) enable more efficient cross platform knowledge generation with increased meta-analysis capabilities across experiments and data types. The potential of this project is that thousands of scientists around the world will be able to more easily leverage additional single-cell cytometry, transcript, and other data in their translational research data analysis including automating analysis that has primarily been dominated by expert-driven annotation, thus providing a central repository and knowledge management framework that will accelerate biomarker discovery and precision medicine. Project Narrative Single-cell biology and Immunotherapy are exploding and generating larger and more complex datasets in combination clinical trials. To take full advantage of these revolutions, the iteration and dissemination of advanced single-cell data analysis algorithms (many of whose development was funded by the NIH) needs to scale at the same rate as single-cell data generation technologies are scaling, and multi-omics data analysis and visualization must be integrated and automated. This project will greatly accelerate scientific research, transparency, and reproducibility by significantly lowering the barrier to perform complex data analysis of multiple types of high-dimensional data, providing the biomedical research community with access to powerful tools needed in immuno-oncology, autoimmunity and other high-impact disease areas.",Accelerating Multi-modal Biomarker Discovery in Translational Research with Cloud Data Integration,9464486,R44GM117914,"['Acute Lymphocytic Leukemia', 'Algorithmic Analysis', 'Algorithms', 'Area', 'Autoimmunity', 'B-Lymphocytes', 'Basic Science', 'Biological Markers', 'Biomedical Research', 'Cells', 'Cellular biology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Follicular Lymphoma', 'Foundations', 'Funding', 'Generations', 'Immune System Diseases', 'Immune system', 'Immunologic Monitoring', 'Immunology', 'Immunooncology', 'Immunotherapy', 'Information Resources Management', 'Knowledge', 'Label', 'Link', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Meta-Analysis', 'Modality', 'Modeling', 'Outcome', 'Patients', 'Phase', 'Population', 'Positioning Attribute', 'Regimen', 'Relapse', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Scientist', 'Secure', 'System', 'Target Populations', 'Technology', 'Testing', 'The Cancer Genome Atlas', 'Toxic effect', 'Transcript', 'Translational Research', 'Treatment Efficacy', 'United States National Institutes of Health', 'Work', 'anti-cancer', 'base', 'biomarker development', 'biomarker discovery', 'biomarker validation', 'clinically actionable', 'cloud based', 'cost effective', 'cytokine', 'data integration', 'data management', 'data visualization', 'experimental study', 'high dimensionality', 'immunotherapy trials', 'improved', 'insight', 'learning strategy', 'multiple omics', 'novel', 'outcome prediction', 'personalized medicine', 'population based', 'precision medicine', 'predict clinical outcome', 'predictive marker', 'predictive modeling', 'relapse prediction', 'repository', 'response', 'single cell analysis', 'single cell technology', 'single-cell RNA sequencing', 'synergism', 'tool', 'transcriptome sequencing', 'transcriptomics', 'tumor']",NIGMS,"CYTOBANK, INC.",R44,2018,613841,-0.0037305246246320573
"Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning Project​ ​Summary/Abstract  There​ ​is​ ​an​ ​enormous​ ​need​ ​for​ ​qualified​ ​people​ ​to​ ​pursue​ ​careers​ ​in​ ​STEM​ ​(Noonan, 2017).​ ​However,​ ​the​ ​lack​ ​of​ ​a​ ​strong​ ​foundation​ ​in​ ​mathematics​ ​means​ ​students​ ​are​ ​less​ ​likely to​ ​pursue​ ​STEM​ ​majors​ ​and​ ​careers​ ​(Chen,​ ​2013;​ ​Griffith,​ ​2010;​ ​Huang,​ ​Taddese,​ ​&​ ​Walter,​ ​E, 2000;​ ​Kokkelenberg​ ​&​ ​Sinha,​ ​2010;​ ​Lowell​ ​et.​ ​al.,​ ​2009).​ ​Students​ ​from​ ​low-income​ ​families, women,​ ​and​ ​underrepresented​ ​minorities​ ​are​ ​also​ ​less​ ​likely​ ​to​ ​major​ ​in​ ​STEM​ ​(Bettinger,​ ​2010; Griffith,​ ​2010;​ ​Hill,​ ​Corbett​ ​&​ ​Rose,​ ​2010;​ ​Kokkelenberg​ ​&​ ​Sinha,​ ​2010).​ ​Improving​ ​math learning​ ​in​ ​the​ ​elementary​ ​grades​ ​is​ ​important​ ​to​ ​ensure​ ​children​ ​have​ ​the​ ​essential foundational​ ​skills​ ​and​ ​strong​ ​self-efficacy​ ​beliefs​ ​to​ ​be​ ​able​ ​to​ ​succeed​ ​with​ ​later​ ​mathematics and​ ​pursue​ ​careers​ ​in​ ​STEM.​ ​With​ ​this​ ​Fast-Track​ ​grant,​ ​​Class​ ​Store​ ​​(​CS​)​,​ ​we​ ​propose​ ​to transform​ ​the​ ​way​ ​in​ ​which​ ​students​ ​learn​ ​​Number​ ​and​ ​Operations​ ​in​ ​Base​ ​Ten.​​ ​​CS​ ​​will​ ​be​ ​​an engaging,​ ​commercially​ ​available,​ ​classroom-based​ ​economy​ ​game​ ​for​ ​tablets​ ​and Chromebooks​ ​that​ ​focuses​ ​on​ ​multi-digit​ ​operations.​ C​​ S​​ ​will​​ ​encourage​ ​conceptual understanding​ ​and​ ​build​ ​math​ ​self-efficacy​ ​for​ ​students​ ​in​ ​grades​ ​K-5​ ​within​ ​the​ ​context​ ​of​ ​a digital,​ ​classroom-based​ ​marketplace.​ ​Within​ ​the​ ​game,​ ​students​ ​will​ ​create​ ​stores,​ ​craft​ ​objects to​ ​sell,​ ​engage​ ​in​ ​selling/purchasing​ ​transactions,​ ​and​ ​work​ ​together​ ​to​ ​increase​ ​the​ ​value​ ​of​ ​the economy.​ ​In​ ​addition,​ ​the​ ​game​ ​will​ ​utilize​ ​​artificial​ ​intelligence​ ​(AI)​ ​to​ ​detect​ ​strategies​ ​students use​ ​and​ ​help​ ​teachers​ ​facilitate​ ​rich​ ​mathematical​ ​discussions​ ​thereby​ ​enhancing​ ​students’ reasoning​ ​skills.  Outcomes.​ ​​The​ ​proposal​ ​will​ ​encourage​ ​three​ ​main​ ​outcomes,​ ​namely:​ ​1)​ ​algorithms​ ​for detecting​ ​math​ ​strategies​ ​students​ ​use,​ ​2)​ ​a​ ​discussion​ ​support​ ​dashboard,​ ​and​ ​3)​ ​algorithms for​ ​predicting​ ​at-risk​ ​status.​ ​A​ ​key​ ​research​ ​aim​ ​is​ ​to​ ​determine​ ​whether​ ​the​ ​software​ ​can​ ​predict math​ ​strategies​ ​students​ ​use​ ​and​ ​detect​ ​which​ ​students​ ​are​ ​at-risk​ ​academically​ ​as​ ​compared to​ ​standardized​ ​assessment​ ​data,​ ​which​ ​will​ ​help​ ​teachers​ ​intervene​ ​appropriately.​ ​The discussion​ ​support​ ​dashboard​ ​will​ ​help​ ​to​ ​promote​ ​rich​ ​mathematical​ ​discussion,​ ​thereby improving​ ​students’​ ​mathematical​ ​justification​ ​and​ ​conceptual​ ​understanding.​ ​The​ ​engaging game​ ​will​ ​bolster​ ​students’​ ​motivation​ ​and​ ​self-efficacy​ ​in​ ​mathematics.  Improving​ ​students’​ ​academic​ ​outcomes​ ​and​ ​self-efficacy​ ​in​ ​base​ ​ten​ ​during​ ​elementary school​ ​will​ ​promote​ ​later​ ​success​ ​in​ ​high​ ​school​ ​mathematics.​ ​Since​ ​the​ ​number​ ​of​ ​advanced math​ ​classes​ ​students​ ​take​ ​is​ ​correlated​ ​with​ ​likelihood​ ​to​ ​complete​ ​a​ ​STEM​ ​degree,​ ​(Chen, 2013)​ ​a​ ​distal​ ​outcome​ ​of​ ​this​ ​proposal​ ​is​ ​increasing​ ​students​ ​pursuing​ ​careers​ ​in​ ​STEM. Project​ ​Narrative  There​ ​is​ ​an​ ​enormous​ ​need​ ​for​ ​students​ ​majoring​ ​in​ ​the​ ​fields​ ​of​ ​Science,​ ​Technology, Engineering​ ​and​ ​Mathematics​ ​(STEM),​ ​yet​ ​lacking​ ​a​ ​strong​ ​foundation​ ​in​ ​mathematics​ ​makes students,​ ​especially​ ​women,​ ​minorities​ ​and​ ​those​ ​from​ ​low-income​ ​backgrounds,​ ​less​ ​likely​ ​to pursue​ ​careers​ ​in​ ​STEM.​ ​​Class​ ​Store​​ ​will​ ​bolster​ ​students’​ ​mathematics​ ​abilities,​ ​including mathematical​ ​reasoning​ ​and​ ​self-efficacy,​ ​in​ ​the​ ​foundational​ ​area​ ​of​ N​​ umber​ ​and​ ​Operations​ ​in Base​ ​10​​ ​in​ ​the​ ​short​ ​and​ ​long​ ​term.​ ​This​ ​will,​ ​in​ ​turn,​ ​lead​ ​to​ ​several​ ​positive​ ​distal​ ​outcomes, such​ ​as​ ​increased​ ​STEM​ ​majors​ ​and​ ​careers.",Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning,9621064,R44GM130197,"['Achievement', 'Algorithms', 'Area', 'Artificial Intelligence', 'Belief', 'Child', 'Childhood Cancer Survivor Study', 'Code', 'Computer software', 'Data', 'Data Files', 'Detection', 'Digit structure', 'Distal', 'Elements', 'Ensure', 'Foundational Skills', 'Foundations', 'Goals', 'Grant', 'High School Student', 'Intervention', 'Investments', 'Lead', 'Learning', 'Low income', 'Marketing', 'Mathematics', 'Measures', 'Minority', 'Modeling', 'Outcome', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Research', 'Risk', 'Sales', 'Scheme', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self Efficacy', 'Standardization', 'Structure', 'Students', 'Tablets', 'Testing', 'Transact', 'Underrepresented Minority', 'Woman', 'Work', 'base', 'career', 'dashboard', 'design', 'digital', 'elementary school', 'experience', 'field study', 'fifth grade', 'fourth grade', 'high school', 'improved', 'iterative design', 'lower income families', 'mathematical ability', 'mathematical learning', 'mathematical theory', 'operation', 'prediction algorithm', 'prototype', 'second grade', 'skills', 'student participation', 'success', 'support tools', 'teacher', 'usability']",NIGMS,"TEACHLEY, LLC",R44,2018,149887,0.010968033888460488
"CSHL Computational and Comparative Genomics Course The Cold Spring Harbor Laboratory proposes to continue a course entitled “Computational and Comparative Genomics”, to be held in the Fall of 2017 – 2019. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases that they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions. NARRATIVE The Computational & Comparative Genomics, a 9 day course, is designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.",CSHL Computational and Comparative Genomics Course,9545035,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'Course Content', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genome', 'Home environment', 'Institution', 'International', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Research Training', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Training Programs', 'Universities', 'Update', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'graduate student', 'instructor', 'interest', 'laboratory experience', 'lecturer', 'programs', 'promoter', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2018,67704,0.0003234322433067134
"A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers PROJECT SUMMARY/ABSTRACT  This application, “A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,” is in response to PAR-16-238, Dissemination and Implementation Research in Health (R01). Acute respiratory distress syndrome (ARDS) has high prevalence (10% of intensive care unit admissions) and mortality up to 46%. Low tidal volume ventilation (LTVV) is the most effective therapy for ARDS, lowering mortality by 20-25%, and is part of standard practice. However, use of LTVV is as low as 19% of ARDS patients. There is a poor understanding of the barriers to LTVV adoption: current approaches are deficient because they incorporate biases, lack consistency and comprehensiveness, ignore the influence of interpersonal network- or team- based factors, and do not address setting-specific variation. Our research team has previously identified some patient- and clinician-specific facilitators of and barriers to LTVV adoption. We have used two state-of-the-art data driven methods—data science and network analysis—to preliminarily quantify the impact of a diverse array of potential factors affecting LTVV adoption, including network- and team-based factors. The proposed research is guided by the Consolidated Framework for Implementation Research (CFIR) and Rogers' Diffusion of Innovations theory. The overall goals of the proposed research are to understand the differences in facilitators and barriers to LTVV adoption between academic and community settings through a definitive, systematic study in a large, diverse consortium of medical centers, and to advance implementation science by providing a model for how data science and network analysis can be applied to understand the adoption of a complex intervention. The overarching hypothesis is that there are different patient-, clinician-, network-, and team-based facilitators and barriers to LTVV adoption in academic and community settings. We will determine whether different patient- and clinician- (Aim 1 cohort study, clinician survey, and data science analysis), clinician interpersonal network- (Aim 2 network analysis), and team structure and dynamics-based (Aim 3 team construction and modeling) facilitators of and barriers to LTVV adoption exist between academic and community hospital settings. Successful completion of the proposed research will provide a comprehensive understanding of the differences in the facilitators of and barriers to LTVV adoption between academic and community settings, and will advance implementation science by serving as a model of how data science and network analysis can be applied to complex implementation problems. Implementation strategies that account for all these factors may be more likely to lead to significant practice change. PROJECT NARRATIVE  Acute respiratory distress syndrome (ARDS) has high prevalence and mortality among critically ill patients; low tidal volume ventilation is the most effective therapy for ARDS but is used infrequently. Successful completion of the proposed research will identify differences in the facilitators of and barriers to adoption of low tidal volume ventilation between academic and community hospital settings in a large and diverse consortium of medical centers. The proposed research will generate a model of how data science and network analysis can be used to understand the implementation of a complex evidence-based practice.",A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,9594103,R01HL140362,"['Acute', 'Admission activity', 'Adoption', 'Adult Respiratory Distress Syndrome', 'Affect', 'Attitude', 'Caring', 'Characteristics', 'Cohort Studies', 'Community Hospitals', 'Complex', 'Critical Illness', 'Data', 'Data Science', 'Diffusion of Innovation', 'Environment', 'Environmental air flow', 'Evidence based practice', 'Goals', 'Health', 'Healthcare Systems', 'Height', 'High Prevalence', 'Hypoxemia', 'Individual', 'Inflammatory', 'Intensive Care Units', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Medical center', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'Nurses', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Professional Organizations', 'Pulmonary Edema', 'Research', 'Severities', 'Speed', 'Structure', 'Surveys', 'Syndrome', 'System', 'Testing', 'Tidal Volume', 'Variant', 'base', 'community setting', 'computer science', 'dissemination research', 'effective therapy', 'experimental study', 'health care settings', 'implementation research', 'implementation science', 'implementation strategy', 'learning strategy', 'lung injury', 'mortality', 'multidisciplinary', 'novel', 'research data dissemination', 'respiratory', 'response', 'theories']",NHLBI,NORTHSHORE UNIVERSITY HEALTHSYSTEM,R01,2018,793267,0.005072721312108212
"Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II Project Summary Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Clinical performance assessment emphasizes learner evaluation over learner development, lacks rigor and utility for developmental purposes, and clinical teachers have expressed particular difficulty with diagnosing reasoning deficits for remediation purposes. Further, medical students' diagnostic reasoning does not improve over the course of clinical training and senior medical students have highly variable diagnostic performance that is often rated below expectations according to theory-based and validated scoring criteria. Independent practice does not necessarily enhance the context for clinical reasoning; the majority of physicians' medical errors are thought to be diagnostic in nature. We propose to improve undergraduate medical education to minimize the time to clinical competency for first year residents through targeted diagnostic reasoning skill development that (1) integrates basic science and clinical instruction; (2) provides deliberate practice with structured, case-based learning opportunities; and (3) enables anytime/anywhere learning that fits with the demanding schedules of most medical students. Southern Illinois University School of Medicine (SIUSOM) is a recognized leader in using performance-based clinical competency exams to enhance reasoning skill acquisition among medical students. These exams feature clinical scenarios with standardized patients followed by diagnostic justification essays which require students to explicitly describe the thought process used to reach a final diagnosis. These essays are the most reliable method of assessing diagnostic strategies but are not in use in the majority of medical schools, though interest in improving diagnostic reasoning instruction and assessment during undergraduate medical education is widespread. Barriers to the widespread adoption of this approach are 1) the time-consuming need to hand score each essay; and 2) the difficulty in accurately and consistently identifying the causes of strategy failures. This project will develop an application to provide automated scoring of diagnostic justification essays, identification of the underlying causes of failure when students perform poorly, and feedback with instructional strategies for remediation specific to each deficit. We propose these specific aims: 1) Improve reliability of human scoring of DXJ essays. 2) Extend the automated scoring algorithms. 3) Automated reasoning failure categorization and remediation. 4) Complete the software development required for delivering the commercial product. 5) Evaluate predictive validity of automatically scored DXJ essays. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine. Project Narrative Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Better preparation during undergraduate medical education can shorten the time to competency of first year residents, improving patient outcomes. We propose to develop and test a technology-enabled, deliberate-practice approach to training diagnostic strategy that includes automated scoring of diagnostic justification essays, identification of specific diagnostic strategy failures and targeted remediation. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine.","Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II",9537633,R42GM108104,"['Address', 'Adopted', 'Adoption', 'Algorithms', 'Basic Science', 'Caring', 'Case Based Learning', 'Case Study', 'Charge', 'Classification', 'Clinical', 'Clinical Competence', 'Community Health Education', 'Competence', 'Consult', 'Custom', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Education', 'Educational Technology', 'Educational process of instructing', 'Ensure', 'Environment', 'Equation', 'Evaluation', 'Faculty', 'Failure', 'Feedback', 'Future', 'Goals', 'Hand', 'Hospitals', 'Human', 'Illinois', 'Incubators', 'Instruction', 'Leadership', 'Learning', 'Letters', 'Machine Learning', 'Measures', 'Medical', 'Medical Education', 'Medical Errors', 'Medical Students', 'Medicine', 'Methods', 'Modeling', 'Nature', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern Recognition', 'Performance', 'Phase', 'Physicians', 'Preparation', 'Process', 'Recommendation', 'Role', 'Sales', 'Schedule', 'Semantics', 'Standardization', 'Structure', 'Students', 'Suggestion', 'Supervision', 'System', 'Taxonomy', 'Teaching Method', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validity and Reliability', 'Variant', 'base', 'educational atmosphere', 'essays', 'evidence base', 'expectation', 'improved', 'innovation', 'interest', 'medical schools', 'prototype', 'remediation', 'research and development', 'skill acquisition', 'skills', 'software development', 'teacher', 'theories', 'tool', 'undergraduate medical education', 'undergraduate student', 'virtual']",NIGMS,"PARALLEL CONSULTING, LLC",R42,2018,489952,0.0004131722057627061
"MICCAI 2018 - 21th International Conference on Medical Image Computing and Computer Assisted Intervention Project Summary The Medical Image Computing and Computer Assisted Intervention (MICCAI) society is dedicated to the promotion, preservation, facilitation of research and education in the fields of medical image computing (MIC) and computer assisted interventions (CAI) including biomedical imaging and robotics; this is achieved through the organization and operation of regular international conferences of highest quality and publications which promote and foster the exchange and dissemination of advanced knowledge, expertise and experience in the field produced by leading institutions and outstanding scientists, physicians, and educators around the world. MICCAI Conferences have their roots and origin in three separate but related conferences beginning in early 1990s, the Visualization in Biomedical Computing (VBC), Computer Vision and Virtual Reality in Robotics and Medicine (CVRMed), and Medical Robotics and Computer Assisted Surgery (MRCAS), which merged into a single annual conference in 1998. MICCAI Conferences have defined a new scientific discipline over the years and have become the premier conference in the field with their proceedings having an impact factor comparable to high-impact computational journals. Conference topics include, computer vision & image processing for medical imaging, computer-aided diagnosis, computer-assisted intervention & surgery, guidance systems & robotics, visualization and virtual reality, bioscience and biology applications, specific imaging systems and new biomedical imaging applications, spanning disciplines such as radiology, pathology, surgery, oncology, cardiology, physiology, and psychiatry. The main MICCAI conference includes three days of oral presentations and poster sessions. The quality and importance of poster presentations are considered to be on a par with those of oral presentations, with both undergoing a rigorous double-blinded peer-review (~30% acceptance) and several presented papers becoming landmark publications over the years reaching up to 2,000 citations. The conference series includes community-driven software challenges, workshops and tutorials just before and/or after the main conference. These satellite events focus in detail on the current status and advances in topics relevant to MICCAI and are very highly attended. The MICCAI Conferences span the entire globe and are usually rotated among the American, European, and Asian continents. Attendance typically includes more than 45 countries, with strong student representation (~40%). The MICCAI 2018 Conference will be held in Granada, Spain in September 16th-20th, 2018. An innovative aspect of MICCAI 2018 is the initiation of a “Mentoring Program” to connect students and young investigators with established mentors from academia and industry. Along with the mission of “Women in MICCAI” committee, this proposal requests funds to initiate and ultimately sustain student travel awards to specifically enhance diversity in conference attendance, including women, underrepresented minorities, students with disabilities, and students from disadvantaged backgrounds, to present their work, providing them with a unique opportunity to reach an international audience for career development and collaborations. Project Narrative The MICCAI 2018 Conference will be held in Granada, Spain during September 16th-20th, 2018. The MICCAI conferences are the premier meeting in the medical image computing (MIC) and computer assisted intervention (CAI) communities, having introduced several landmark papers and providing a springboard for young scientists to establish themselves in the field. This proposal requests funds to provide travel awards for students, focusing on enhancing diversity by supporting the participation of women, underrepresented minorities, students with disabilities, and from disadvantaged backgrounds, to present their work, providing them with an opportunity for visibility in an established international audience, foster professional development and collaborations.",MICCAI 2018 - 21th International Conference on Medical Image Computing and Computer Assisted Intervention,9617533,R13CA225202,"['Academia', 'Address', 'American', 'Area', 'Asians', 'Award', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Cardiology', 'Climate', 'Clinic', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Computer-Assisted Surgery', 'Country', 'Development', 'Disadvantaged', 'Discipline', 'Double-Blind Method', 'Education', 'Educational workshop', 'Ensure', 'European', 'Event', 'Female', 'Fostering', 'Funding', 'Grant', 'Imagery', 'Industrialization', 'Industry', 'Institution', 'International', 'Intervention', 'Journals', 'Knowledge', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Minority', 'Mission', 'Occupations', 'Operative Surgical Procedures', 'Oral', 'Paper', 'Pathology', 'Peer Review', 'Physicians', 'Physiology', 'Plant Roots', 'Policies', 'Psychiatry', 'Publications', 'Publishing', 'Radiology Specialty', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Personnel', 'Research Support', 'Robotics', 'Scientist', 'Series', 'Sex Bias', 'Societies', 'Spain', 'Students', 'System', 'Translations', 'Travel', 'United States National Institutes of Health', 'Woman', 'Work', 'Writing', 'base', 'bioimaging', 'career', 'career development', 'community intervention', 'computer science', 'design', 'digital imaging', 'disabled students', 'disadvantaged student', 'experience', 'image processing', 'imaging system', 'improved', 'innovation', 'lecture notes', 'meetings', 'new technology', 'oncology', 'operation', 'peer', 'posters', 'preservation', 'programs', 'prototype', 'racial and ethnic', 'research and development', 'social', 'symposium', 'underrepresented minority student', 'virtual reality', 'women faculty']",NCI,UNIVERSITY OF PENNSYLVANIA,R13,2018,5000,0.004718306542907783
"Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome Addiction is a highly complex disease with risk factors that include genetic variants and differences in development, sex, and environment. The long term potential of precision medicine to improve drug treatment and prevention depends on gaining a much better understanding how genetics, drugs, brain cells, and neuronal circuitry interact to influence behavior. There are serious technical barriers that prevent researchers and clinicians from incorporating more powerful computational and predictive methods in addiction research. The purpose of the NIDA P30 Core Center of Excellence in Omics, Systems Genetics, and the Addictome is to empower and train researchers supported by NIH, NIDA, NIAAA, and other federal and state institutions to use more quantitative and testable ways to analyze genetic, epigenetic, and the environmental factors that influence drug abuse risk and treatment. In the Transcriptome Informatics and Mechanisms research core we assemble and upgrade hundreds of large genome (DNA) and transcriptome (RNA) datasets for experimental rodent (rat) models of addiction. In the Systems Analytics and Modeling research core, we are using innovative systems genetics methods (gene mapping) to understand the linkage between DNA differences, environmental risks such as stress, and the differential risk of drug abuse and relapse. Our Pilot core is catalyzing new collaborations among young investigator in the field of addiction research. In sum the Center is a national resource for more reproducible research in addiction. We are centralizing, archiving, distributing, analyzing and integrating high quality data, metadata, using open software systems in collaboration with many other teams of researchers. Our goal is to help build toward an NIDA Addictome Portal that will include all genomic research relevant to addiction research. PROJECT NARRATIVE The NIDA Core Center of Excellence in Omics, Systems Genetics, and the Addictome (OSGA) provides genomic and computational support to a large number of research scientists working on mechanisms and treatment of addiction. The two main research cores of OSGA are providing support for transcriptome, epigenome, and metagenome studies of rat models of addiction at many levels of analysis. We are also creating open access tools and a powerful web portal to catalyze more effective and replicable use of massive datasets generated by programs in addiction biology and treatment.","Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome",9531327,P30DA044223,"['Archives', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Bioinformatics', 'Biology', 'Biometry', 'Cellular Assay', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consult', 'DNA', 'DNA Sequence', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Interactions', 'Drug abuse', 'Educational workshop', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Epigenetic Process', 'Foundations', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Hybrids', 'Image', 'Imagery', 'Informatics', 'Institution', 'Joints', 'Leadership', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences Research', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Prevention', 'Proteome', 'Publications', 'Publishing', 'Quantitative Genetics', 'Quantitative Trait Loci', 'RNA', 'Rattus', 'Relapse', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Rodent', 'Role', 'Scientist', 'Site', 'Standardization', 'Statistical Models', 'Stress', 'Sum', 'System', 'Systems Analysis', 'Testing', 'Training', 'Translations', 'United States National Institutes of Health', 'Update', 'Variant', 'Work', 'addiction', 'base', 'behavior influence', 'brain cell', 'career', 'cohort', 'computerized tools', 'computing resources', 'data archive', 'data integration', 'data modeling', 'data warehouse', 'deep learning', 'digital imaging', 'drug relapse', 'epigenome', 'experience', 'genetic analysis', 'genetic variant', 'genomic variation', 'graphical user interface', 'health record', 'high dimensionality', 'improved', 'innovation', 'insight', 'metagenome', 'mouse model', 'multiple omics', 'neurogenomics', 'neuronal circuitry', 'novel', 'precision medicine', 'prevent', 'programs', 'ranpirnase', 'rat genome', 'repository', 'sex', 'single cell analysis', 'software systems', 'tool', 'transcriptome', 'transcriptomics', 'web portal']",NIDA,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,P30,2018,773018,-0.006378251379133539
"The Center for Innovation in Intensive Longitudinal Studies (CIILS) PROJECT SUMMARY Significance. The Intensive Longitudinal Behavior Network (ILHBN) provides an unprecedented opportunity to advance and shape the future landscape of health behavior science and related intervention practice. The proposed Research Coordinating Center, the Center for Innovation in Intensive Longitudinal Studies (CIILS), housed at the Pennsylvania State University (Penn State), will bring together an interdisciplinary team to synergistically support and coordinate research activities across a diverse portfolio of anticipated U01 projects to accomplish the Network’s larger goal of sustained innovation in the use of intensive longitudinal data (ILD) and associated methods in the study of health behavior change, and in informing prevention and intervention designs. Innovation. The proposed organizational structure of the ILHBN as a small-world network is motivated by our team’s collective decades of experience with multidisciplinary and multi-site collaborations, and is designed to facilitate information flow, collective decision making, and coordination of goals and effort within the ILHBN. Approach. CIILS consists of five Cores with expertise in management of multi-site projects and coordinating centers (Administrative Core); development of novel methods for analysis of ILD (Methods Core); ILD collection, harmonization, sharing, security, as well as collection of digital footprints (Data Core); ILD design, harmonization and instrumentation support (Design Core); and integration of health behavior theories, translation, and implementation of within-person health preventions/interventions (Theory Core). Key personnel with rich and complementary expertise are supported by a roster of advisory Co-Is at Penn State and distributed consultants who are leaders and innovators in their respective fields. Institutional support and contributed staff time by Penn State provide robust infrastructure, expertise, and “boots on the ground” to support the operation and coordination activities of ILHBN; and a wealth of additional resources to elevate and broaden the collective impacts of the Network. PROJECT NARRATIVE This project proposes an RCC, the Center for Innovation in Intensive Longitudinal Studies (CIILS), housed at the Pennsylvania State University, to provide a repertoire of expertise and resources to support the Intensive Longitudinal Health Behavior Network (ILHBN). Our interdisciplinary team – consisting of social scientists with expertise in design and management of intensive longitudinal studies; methodological experts who are leading figures in developing novel within-person analytic techniques; health theorists and prevention/intervention experts well-versed in the translation of health theories into within-person health intervention; cyberscience experts with expertise in collection of digital footprints, data security and data sharing issues; and administrative personnel with expertise in management and coordination of network activities – is uniquely poised to advance the collective innovations of the ILHBN by synergistically supporting and coordinating research activities across a diverse portfolio of anticipated U01 projects.",The Center for Innovation in Intensive Longitudinal Studies (CIILS),9571275,U24AA027684,"['Administrative Personnel', 'Algorithms', 'Behavior', 'Big Data', 'Collaborations', 'Collection', 'Communication', 'Communities', 'Consultations', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Security', 'Databases', 'Decision Making', 'Development', 'Devices', 'Future', 'General Population', 'Goals', 'Health', 'Health Sciences', 'Health behavior', 'Health behavior change', 'Healthcare', 'Human Resources', 'Individual', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Neurobiology', 'Pennsylvania', 'Persons', 'Positioning Attribute', 'Preventive Intervention', 'Privacy', 'Process', 'Production', 'Progress Reports', 'Protocols documentation', 'Publications', 'Records', 'Regulation', 'Reporting', 'Research', 'Research Activity', 'Research Design', 'Research Infrastructure', 'Resources', 'Science', 'Scientist', 'Security', 'Shapes', 'Site', 'Social Work', 'Source', 'Structure', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Training', 'Translations', 'United States National Institutes of Health', 'Universities', 'Update', 'Visualization software', 'Workplace', 'control theory', 'data management', 'data portal', 'data sharing', 'data visualization', 'data warehouse', 'design', 'digital', 'dynamic system', 'experience', 'human subject', 'innovation', 'instrumentation', 'member', 'multidisciplinary', 'novel', 'operation', 'organizational structure', 'social', 'success', 'theories', 'therapy design', 'tool']",NIAAA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,U24,2018,220751,0.003983265503648803
"COINSTAC: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway5,10. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume11, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community be- comes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group2). The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates a dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informat- ics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an inde- pendent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented stor- age vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and pri- vacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix fac- torization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities. 4 Project Narrative  Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don’t have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this ‘missing data’ and allow for pooling of both open and ‘closed’ repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed compu- tational solution for a large toolkit of widely used algorithms. 3","COINSTAC: decentralized, scalable analysis of loosely coupled data",9717051,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithmic Analysis', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Set', 'Decentralization', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Letters', 'Linear Models', 'Location', 'Logistics', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Source', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'base', 'commune', 'computer framework', 'computing resources', 'connectome', 'cost', 'data sharing', 'distributed data', 'flexibility', 'imaging genetics', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'open data', 'peer', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,THE MIND RESEARCH NETWORK,R01,2018,282320,0.011510196948289947
"COINSTAC: decentralized, scalable analysis of loosely coupled data ﻿    DESCRIPTION (provided by applicant):     The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway5,10. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume11, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the dat as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community becomes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group2).    The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates  dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented storage vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and privacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix factorization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities. PUBLIC HEALTH RELEVANCE: Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don't have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this 'missing data' and allow for pooling of both open and 'closed' repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed computational solution for a large toolkit of widely used algorithms.","COINSTAC: decentralized, scalable analysis of loosely coupled data",9473021,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithmic Analysis', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Set', 'Decentralization', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Letters', 'Linear Models', 'Location', 'Logistics', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Source', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'base', 'commune', 'computer framework', 'computing resources', 'connectome', 'cost', 'data sharing', 'distributed data', 'flexibility', 'imaging genetics', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'open data', 'peer', 'public health relevance', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,THE MIND RESEARCH NETWORK,R01,2018,649098,0.01415621069844561
"LSUHSC-New Orleans Postbaccalaureate Research Education Program in Biomedical Sciences PROJECT SUMMARY/ABSTRACT The overall goal of the Postbaccalaureate Research Education Program (PREP) in Biomedical Sciences (BMS) at the Louisiana State University Health Sciences Center in New Orleans (LSUHSC-NO) is to enhance the diversity of the research workforce by increasing competitiveness for acceptance and completion of PhD and MD/PhD programs by underrepresented minorities (URM). LSUHSC-NO PREP will accept 39 recent URM baccalaureate science graduates over 5 yrs for intensive research and innovative academic training experi- ences to foster success in BMS doctoral degree programs. Over 300 URM science baccalaureates are award- ed annually to URM students by universities located within 100 miles of LSUHSC-NO representing 32% of all science degrees; however, URM constitute only 10% of enrolled PhD and MD/PhD students nationwide, and 12% at LSUHSC-NO. The PREP will enhance competitiveness for acceptance, retention, and completion of BMS PhD programs by the Scholars by providing 1) intensive research experiences with committed research faculty, and 2) complementary skills development during the 1-yr training. PREP training will focus on building solid foundations in research skills by providing concentrated education in scientific critical thinking, analysis of results, statistics, and writing; inventive and personalized test-taking skills to improve GRE scores and success in graduate courses; oral and poster scientific presentations; responsible and ethical conduct in research; and writing a resume, personal statement, and selecting and applying to graduate schools. Scholars will participate in works-in-progress, journal clubs, and workshops hosted by PREP faculty, visitors, and recruitment contacts; join graduate students in skills development programs; present their research at the annual PREP poster sym- posium and local and national scientific conferences; mentor summer research fellows; and assist in communi- ty science education programs. The PREP will provide forums for the Scholars to engage in research and skills acquisition and active demonstration of knowledge. Over 60 LSUHSC-NO active research faculty, committed to the PREP, have extensive experience in mentoring high school, undergraduate, medical, predoctoral, and postdoctoral students representing URM in the BMS through NIH T32, R25, R35, and other funding mecha- nisms. There are 8 active LSUHSC-NO summer programs which provide research experiences to 75 URM fel- lows annually from which future PREP Scholars will be prescreened and recruited. Scholar recruitment efforts will extend to 4 local historically black colleges and 2 state universities to develop a community-wide mecha- nism to support the URM BMS workforce. The program will be critically evaluated using formative and summa- tive methodologies and descriptive, quantitative, and qualitative statistics to document success. The overall goal is for PREP Scholars to have an enhanced competitiveness for acceptance into rigorous graduate pro- grams with the confidence and essential research skills required to earn a PhD or MD/PhD degree, establish rewarding and successful BMS research careers, and serve as role-models for future URM students. PROJECT NARRATIVE The goal of the LSUHSC-NO PREP is to prepare individuals from backgrounds underrepresented in the biomedical sciences, who have recently completed their baccalaureate science degrees, for successful enrollment, retention, and completion of a PhD or MD-PhD training program. We aim to enhance the diversity of the biomedical research workforce by preparing PREP Scholars for the rigors and challenges of a biomedical doctoral degree program so that they will successfully obtain a PhD degree or MD/PhD degree and contribute their expertise to the biomedical scientific community.",LSUHSC-New Orleans Postbaccalaureate Research Education Program in Biomedical Sciences,9566214,R25GM121189,"['Academic Training', 'Anxiety', 'Award', 'Bachelor&apos', 's Degree', 'Basic Science', 'Biomedical Research', 'Centers of Research Excellence', 'Cities', 'Clinical Sciences', 'Communities', 'Critical Thinking', 'Data Analyses', 'Degree program', 'Dentistry', 'Development', 'Development Plans', 'Doctor of Philosophy', 'Doctor&apos', 's Degree', 'Education', 'Educational workshop', 'Enrollment', 'Environment', 'Ethics', 'Exercise', 'Extramural Activities', 'Faculty', 'Fostering', 'Foundations', 'Funding', 'Funding Mechanisms', 'Future', 'Goals', 'Health Sciences', 'Historically Black Colleges and Universities', 'Individual', 'Journals', 'Knowledge', 'Laboratory Research', 'Learning', 'Louisiana', 'Machine Learning', 'Manuscripts', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Minority Enrollment', 'NCI Scholars Program', 'Oral', 'Population', 'Postdoctoral Fellow', 'Program Development', 'Public Health', 'Research', 'Research Ethics', 'Research Project Grants', 'Resources', 'Rewards', 'Schools', 'Science', 'Scientist', 'Solid', 'Statistical Methods', 'Structure', 'Students', 'Study Skills', 'Sum', 'Technical Expertise', 'Testing', 'Time Management', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Visit', 'Work', 'Writing', 'career', 'design', 'doctoral student', 'education research', 'experience', 'faculty research', 'graduate student', 'gulf coast', 'high school', 'improved', 'innovation', 'invention', 'medical schools', 'member', 'minority communities', 'novel', 'posters', 'pre-doctoral', 'programs', 'recruit', 'role model', 'science education', 'skill acquisition', 'skills', 'skills training', 'statistics', 'success', 'summer program', 'summer research', 'symposium', 'undergraduate student', 'underrepresented minority student', 'university student']",NIGMS,LSU HEALTH SCIENCES CENTER,R25,2018,235732,0.036005226631489105
"Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)? PROJECT SUMMARY The North Coast Conference on Precision Medicine is a national annual mid-sized conference series held in Cleveland, Ohio. The conference series aims to serve as a venue for the continuing education and exchange of scientific ideas related to the rapidly evolving and highly interdisciplinary landscape that is precision medicine research. The topics for each conference coincide with the national conversation and research agenda set by national research programs focused on precision medicine. The 2018 conference is a symposium that will focus on issues related to return of genomic results both in clinical and research settings with an emphasis on diverse populations. The conference will be organized as a traditional format with invited speakers from among national experts for topics ranging from issues returning research results to culturally diverse participants and family members, inclusion of diverse patient and participant populations in the Clinical Sequencing Evidence- Generating Research (CSER) consortium and the Trans-Omics for Precision Medicine (TOPMed) Program, pharmacogenomics-guided dosing and race/ethnicity, strategies used to return results, among others. 2019 and beyond conference topics are being considered from previous symposia attendees and trends in precision medicine research. Odd-numbered year conferences include a workshop component that has previously covered outcome and exposure variable extraction from electronic health records. Future workshop topics being considered include integration of multiple ‘omics, drug response in different populations, pharmacogenomics clinical implementation, precision medicine in cancer, data sharing and informed consent, and the use of apps for recruitment, diagnosis, follow-up, and treatment. Our second major objective of this conference series is the promotion of diversity in the biomedical workforce. It is well-known that the pipeline from training to full professor for women in biomedical research is leaky whereas the pipeline for under-represented minorities is practically non-existent. Drawing from national and local sources, we vet women and under-represented minorities for every invited speaker opportunity, thereby providing valuable career currency and networking opportunities. We will also encourage women and under-represented minorities, particularly at the trainee level, to attend and participate in this conference series to spur interest in pursuing precision medicine research as a career. Overall, the North Coast Conference on Precision Medicine series is a valuable addition to the national conference landscape, and with its unique location and low cost to participants, will serve as an important educational opportunity as precision medicine research accelerates in earnest. PROJECT NARRATIVE The North Coast Conference on Precision Medicine is a yearly fall conference series in Cleveland, Ohio designed as a continuing education forum in the burgeoning area of precision medicine research. The conference brings together national experts on a host of topics ranging from bioethics to bioinformatics to biomedical informatics to speak and lead workshops on timely challenges posed in translating complex genomic and health data into clinical practice. The conference series also serves to promote diversity in the biomedical workforce. This year’s symposium will focus issues related to return of genomic results in both clinical and research settings with an emphasis on diverse populations.",Sequencing and Genotyping in Diverse Populations:  Who Wants What Back (and When)?,9612854,R13HG010286,"['Academic Medical Centers', 'Acceleration', 'African American', 'Area', 'Back', 'Big Data', 'Bioethics', 'Bioinformatics', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Research', 'Complex', 'Computational Biology', 'Computer Simulation', 'Continuing Education', 'Custom', 'Data', 'Databases', 'Diagnosis', 'Dose', 'Educational workshop', 'Electronic Health Record', 'Ensure', 'Ethnic Origin', 'Family member', 'Funding', 'Future', 'Generations', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Health system', 'Healthcare Systems', 'Hospitals', 'Incidental Findings', 'Informed Consent', 'Institution', 'Knowledge', 'Lead', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mining', 'Names', 'Ohio', 'Outcome', 'PMI cohort', 'Participant', 'Pathogenicity', 'Patients', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Physicians', 'Population', 'Population Heterogeneity', 'Prevention', 'Process', 'Race', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Schedule', 'Science', 'Series', 'Source', 'Surveys', 'Technology', 'Time', 'Training', 'Trans-Omics for Precision Medicine', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Minority', 'United States', 'United States Centers for Medicare and Medicaid Services', 'Variant', 'Veterans', 'Woman', 'base', 'big biomedical data', 'biomedical informatics', 'career', 'clinical care', 'clinical implementation', 'clinical practice', 'clinical sequencing', 'clinically relevant', 'cost', 'cost effective', 'data sharing', 'design', 'falls', 'follow-up', 'forging', 'frontier', 'genome-wide', 'genomic data', 'health data', 'health disparity', 'health information technology', 'incentive program', 'individual patient', 'interest', 'medical specialties', 'multiple omics', 'patient population', 'point of care', 'posters', 'precision medicine', 'programs', 'recruit', 'response', 'science education', 'senior faculty', 'symposium', 'trend']",NHGRI,CASE WESTERN RESERVE UNIVERSITY,R13,2018,10000,0.005699283282037243
"UTMB Clinical and Translational Science Award UTMB's CTSA-linked KL2 Scholars Program addresses the significant need for developing future clinical and translational (C&T) investigators, with emphases on team-based research, leadership development, and mentorship training. In our new CTSA hub, we will build on our current CTSA's successes over the past 5½ years, with unique innovative integration of exceptional training approaches, including: 1) mentored career development within CTSA-supported multidisciplinary translational teams (MTTs); 2) an emphasis on individual development plans (IDPs) and pre-established C&T research competencies tailored to the needs of the individual scholar, but also emphasizing team-based competencies; 3) development of leadership competencies through participation in a new Leadership Development Academy; 4) an Academy of Research Mentors (ARM), based within our Institute for Translational Sciences (ITS), to foster mentoring and mentor training; 5) a linked Translational Research Scholars Program (TRSP), which provides an expanded peer group and a wider impact across the institution, with twice-monthly career development seminars and a focus on scholars' research; 6) development of entrepreneurial skills and leadership through participation in a UT System-funded Healthcare Entrepreneurship Program; and 7) collaboration and dissemination of program experience to other CTSA hubs in the Texas Regional CTSA Consortium, and the national CTSA Consortium. An important feature of our KL2 Scholars Program is its linked position within the continuum of career development, from graduate student training in our CTSA TL1 Training Core to the production of independently funded C&T faculty members. Our program is enhanced with by financial support from our Provost's office for scholar expenses, ITS education administrators, the ARM, and the Office of Faculty Affairs, which is focused on faculty development at UTMB. UTMB also ranks nationally in promoting diversity, which will enhance our recruitment of underrepresented minority scholars by the participation of faculty from our Hispanic Center of Excellence, and our Medical School Enrichment Program. Our KL2 Program is well-integrated with other institutional education activities, including our Human Pathophysiology and Translational Medicine graduate program, and courses targeted toward scientific writing, biostatistics, and study design. Early-career faculty as Phase 1 TRSP scholars can compete to become CTSA-supported KL2 Scholars, and with acquisition of their first mentored K-level grants (e.g., K08), advance to a Phase 2 TRSP Scholar, then focusing on the transition from mentored to independent grant funding. Upon acquisition of independent (e.g. R01) funding, scholars advance to become Phase 3 TRSP Scholars and Associate Members in the ARM, to facilitate their development of mentoring skills, and eventually to full ARM membership, with demonstrated success in C&T science mentoring. Our KL2 Scholars Program thus integrates novel team-based training, leadership, and mentoring approaches to foster the career development of future leaders in C&T research. n/a",UTMB Clinical and Translational Science Award,9479717,KL2TR001441,"['Academy', 'Address', 'Administrator', 'Biological', 'Biological Markers', 'Biometry', 'Biopsy', 'Body Surface Area', 'Burn injury', 'Characteristics', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical and Translational Science Awards', 'Collaborations', 'Competence', 'Data', 'Dependence', 'Development', 'Development Plans', 'Down-Regulation', 'Education', 'Enrollment', 'Entrepreneurship', 'Evolution', 'Expression Profiling', 'Faculty', 'Failure', 'Financial Support', 'Fostering', 'Freezing', 'Functional disorder', 'Funding', 'Future', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genomics', 'Grant', 'Healthcare', 'Hepatitis C virus', 'Hispanics', 'Human', 'Individual', 'Infection', 'Inflammation', 'Institutes', 'Institution', 'Interferons', 'Intervention', 'Leadership', 'Link', 'Liver Fibrosis', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Medicare', 'Medicare claim', 'Medicine', 'Mentors', 'Mentorship', 'MicroRNAs', 'Modeling', 'NCI Scholars Program', 'Participant', 'Pathway interactions', 'Patients', 'Peer Group', 'Phase', 'Physicians', 'Positioning Attribute', 'Process', 'Production', 'Protocols documentation', 'Regimen', 'Research', 'Research Design', 'Rice', 'Structure', 'System', 'TNFSF15 gene', 'Teacher Professional Development', 'Techniques', 'Testing', 'Texas', 'Time', 'Tissues', 'Training', 'Translational Research', 'Underrepresented Minority', 'Variant', 'Writing', 'base', 'career development', 'cohort', 'college', 'demographics', 'early-career faculty', 'experience', 'graduate student', 'innovation', 'leadership development', 'liver biopsy', 'medical schools', 'member', 'microbial', 'multidisciplinary', 'novel', 'outcome forecast', 'peripheral blood', 'predict clinical outcome', 'program dissemination', 'programs', 'recruit', 'response', 'science education', 'skills', 'student training', 'success', 'translational medicine', 'translational scientist']",NCATS,UNIVERSITY OF TEXAS MED BR GALVESTON,KL2,2018,423431,0.029434272522208087
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,9542295,U54EB020405,"['Accelerometer', 'Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Big Data to Knowledge', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Overweight', 'Pathology', 'Personal Satisfaction', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Walking', 'Work', 'base', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'health data', 'improved', 'improved outcome', 'industry partner', 'insight', 'massive open online courses', 'models and simulation', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'online resource', 'prevent', 'programs', 'public health relevance', 'reduce symptoms', 'role model', 'social', 'social model', 'societal costs', 'surgery outcome', 'tool', 'visiting scholar', 'wearable device']",NIBIB,STANFORD UNIVERSITY,U54,2018,955747,0.011286591842367941
"Mixed Reality System for STEM Education and the promotion of health-related careers Project Summary/Abstract Proposed is a system to combine and leverage the advantages of existing medical props with interactive media to provide engaging and cooperative group STEM learning experiences. Significance: The PowerPoint lecture style has become the standard method for teaching groups of students. Unfortunately, this style does not emphasize student-instructor or student-student instruction, and in fact seems to have made students even less engaged than before. Broad agreement exists in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning exercises. Despite their substantial benefits, physical props are fundamentally limited as they are primarily static (e.g. fixed coloration, disease depiction), their internal structures (with limited exceptions) often bear little resemblance to actual human anatomy, and they are passive objects. Hypothesis: A system which can provide more engaging interaction with physical props will be able to improve student retention and increase interest in STEM related subjects. Specific Aims: To prove the feasibility of the proposed system in Phase I IDL will 1) Determine stakeholder requirements through round table discussions; 2) Create prototype system hardware & software to augment learning with physical props; and 3) Validate the prototype system through a pilot study. The overall Phase I effort will demonstrate the ability of the proposed system to augment learning with physical props. In the Phase II effort IDL will ready the system for commercialization by 1) Developing production-quality software, hardware, and user interfaces; 2) Developing a set of comprehensive curricula for the system; and 3) Validating the system through human subject testing. Project Narrative Passive learning methods, i.e. PowerPoint lectures, have become the standard method for teaching groups of students topics including Anatomy and Physiology in spite of broad agreement in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning; however, these props are fundamentally limited.",Mixed Reality System for STEM Education and the promotion of health-related careers,9622753,R44GM130247,"['Agreement', 'Algorithmic Software', 'Anatomy', 'Biological', 'Biological Sciences', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Development', 'Disease', 'Disease Progression', 'Dissection', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Environment', 'Exercise', 'Hand', 'Health', 'Health Promotion and Education', 'Hour', 'Human', 'Hybrids', 'Image', 'Instruction', 'Intervention', 'Learning', 'Location', 'Manikins', 'Medical', 'Minnesota', 'Modeling', 'Participant', 'Phase', 'Physiological', 'Physiology', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Production', 'Role', 'Sampling', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Slide', 'Small Business Innovation Research Grant', 'Structure', 'Students', 'Support Groups', 'System', 'Teaching Method', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'Vision', 'animation', 'career', 'college', 'commercialization', 'design', 'digital media', 'experience', 'flexibility', 'guided inquiry', 'hands-on learning', 'human subject', 'improved', 'innovation', 'instructor', 'interactive tool', 'interest', 'learning strategy', 'lectures', 'mid-career faculty', 'pedagogy', 'prototype', 'retention rate', 'science education', 'software systems', 'tool']",NIGMS,"INNOVATIVE DESIGN LABS, INC.",R44,2018,224984,0.008275876977055667
"Environmental Health Research Experiences for Teachers in High-Poverty Schools: A Professional DevelopmentProgram Abstract The current project proposes an innovative professional development (PD) program in environmental health research experiences for science high-school teachers from schools with high poverty levels in North Carolina. In a collaborative effort, experts from the College of Education and scientists affiliated with the Center for Human Health and Environment (CHHE), and the Comparative Medicine Institute (CMI) at NC State University will provide teachers (N=40) with unique authentic lab experiences. The 8-week summer research PD program aims at enhancing teachers' environmental health literacy and research skills that will support novel science teaching strategies. The specific aims addressed by the program are the following: 1) to provide teachers with a practical understanding of the scientific method in mentored research projects examining links between environmental stressors and health; 2) to provide teachers with an understanding of core conceptual issues in toxicology; 3) to train teachers in ethical issues in scientific conduct, science communication, and public health; 4) to immerse teachers in authentic research lab experiences by using a cognitive apprenticeship model; and 5) to develop a comprehensive evaluation plan in order to assess the short- and long- term PD outcomes. In the proposed environmental health science (EHS) research PD program, teachers will be integrated into genuine research projects and attend lab meetings, gaining general knowledge of how research is conducted and specialized knowledge related to ongoing projects in their host lab. Additionally, teachers in the program will come together one day per week in a workshop environment, to share their diversity of research experiences and gain additional training in biological concepts and ethical issues related to environmental health sciences. Project Narrative Environmental health research experiences are often inaccessible to high-school teachers, particularly in high-poverty schools. Our PD program will provide teachers with scientific knowledge and resources to improve their classroom instruction by adopting a curriculum grounded in environmental health research. Further, teachers' newly acquired EHS knowledge and research skills have the potential to improve student science learning, and promote interest and readiness for STEM careers. By exposing students to novel instructional strategies, students will acquire not just STEM specialized knowledge, but develop STEM domain identification. This is particularly important for science, given the fact that students from high- poverty schools are economically disadvantaged and may comprise a large proportion of individuals from minority groups that are underrepresented in science.",Environmental Health Research Experiences for Teachers in High-Poverty Schools: A Professional DevelopmentProgram,9458539,R25ES028974,"['Address', 'Adopted', 'Area', 'Biological', 'Biological Models', 'Biomedical Research', 'Case Study', 'Cognitive', 'Communication', 'Communities', 'Data', 'Development', 'Dose', 'Economically Deprived Population', 'Education', 'Educational Activities', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Ensure', 'Environment', 'Environmental Health', 'Ethical Issues', 'Ethics', 'Evaluation', 'Experimental Designs', 'Exposure to', 'Faculty', 'Goals', 'Health', 'High School Faculty', 'Human', 'Individual', 'Institute of Medicine (U.S.)', 'Instruction', 'Interview', 'K-12 Faculty', 'Knowledge', 'Learning', 'Link', 'Mentors', 'Methods', 'Minority Groups', 'Modeling', 'North Carolina', 'Outcome', 'Participant', 'Poverty', 'Poverty Areas', 'Predisposition', 'Program Development', 'Program Evaluation', 'Public Health', 'Readiness', 'Research', 'Research Project Grants', 'Resources', 'STEM career', 'School Teachers', 'Schools', 'Science', 'Scientist', 'Students', 'Surveys', 'Teacher Professional Development', 'Teaching Method', 'Testing', 'Time', 'Toxicology', 'Training', 'Training Programs', 'Translating', 'Underrepresented Groups', 'Universities', 'Validity and Reliability', 'apprenticeship', 'base', 'college', 'comparative', 'deep learning', 'design', 'environmental stressor', 'experience', 'experimental study', 'exposure route', 'health literacy', 'health science research', 'high school program', 'improved', 'innovation', 'interest', 'laboratory experience', 'meetings', 'next generation', 'novel', 'outreach', 'pedagogical content', 'programs', 'response', 'science teacher', 'skills', 'socioeconomic disadvantage', 'socioeconomic disparity', 'stressor', 'summer research', 'teacher', 'tool']",NIEHS,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R25,2018,99506,0.024100816442846545
"Washington University School of Medicine Undiagnosed Diseases Network Clinical Site 1.0 PROJECT SUMMARY The scientific premise of this application is that the individualized translational research process of the Undiagnosed Diseases Network (UDN) developed during Phase I is scalable and that its impact on patients, families, and disease discovery can be advanced and sustained by addition of a Clinical Site at Washington University School of Medicine (WUSM). WUSM represents a large academic medical center that is fully integrated with world-renowned basic science capabilities and demonstrated expertise in a gene first approach for patients with undiagnosed diseases. The highly collaborative clinical and biomedical research culture at WUSM promotes interactions within and across Departments, with institutional genomic, clinical, computational, and model system experts, and with colleagues regionally, nationally, and internationally. These interactions support recruitment, selection, evaluation, diagnosis discovery, and follow up of pediatric and adult patients with undiagnosed diseases through both established networks and individual referrals. Building on this infrastructure, WUSM faculty and staff will advance the success of the UDN in diagnosing and managing disease in undiagnosed patients by, first, using, refining, and improving protocols designed during Phase I of the UDN for comprehensive, timely clinical evaluations of 30 undiagnosed patients annually. Secondly, we will collect, securely store, and share standardized, high-quality clinical and laboratory data including genotyping, phenotyping, and documentation of environmental exposures and promote an integrated and collaborative community across the UDN and among laboratory and clinical investigators focused on defining the pathophysiology, cell biologic, and molecular mechanisms that cause these difficult to diagnose diseases. Thirdly, the WUSM UDN Clinical Site will propose a bioinformatics plan for leveraging institutional infrastructure and expertise to develop innovative strategies to improve discovery of pathogenic variants. Fourthly, the assessment, dissemination, outreach, and training plan will accelerate assessment and dissemination of data, protocols, consent materials, and methods, availability of educational and outreach materials for participants, clinicians, and other researchers, engagement of underrepresented minorities, and training for students, fellows, staff, and faculty in collaboration with WUSM’s Clinical and Translational Science Award infrastructure. Finally, WUSM will make a clear institutional commitment to maintain its Clinical Site, to adapt UDN Phase I practices for sustainability, to contribute to formation of a sustainable national UDN resource, and to adapt to unique needs and unexpected circumstances that may arise once Common Fund support ends in fiscal year 2022. 2.0 PROJECT NARRATIVE Undiagnosed diseases in children and adults represent frustrating and costly challenges for patients, families, physicians, and society. Building on established institutional infrastructure similar to the Undiagnosed Diseases Network (UDN), Washington University School of Medicine (WUSM) will establish a UDN Clinical Site to improve the level of diagnosis and care for patients with undiagnosed diseases, facilitate research into the etiology of undiagnosed diseases, and promote an integrated and collaborative community across multiple UDN Clinical Sites, Sequencing Cores, Model Organisms Screening Centers, and among laboratory and clinical investigators. Specifically, the WUSM UDN Clinical Site will annually recruit, select, evaluate, and follow 30 participants with disorders in any clinical specialty, adult and pediatric, provide comprehensive clinical evaluations that require <5 days and follow up, and participate in all UDN protocols, data management and sharing, and sustainability planning.",Washington University School of Medicine Undiagnosed Diseases Network Clinical Site,9593059,U01HG010215,"['Academic Medical Centers', 'Accreditation', 'Adult', 'Animal Model', 'Basic Science', 'Bioinformatics', 'Biomedical Research', 'Businesses', 'Cells', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical and Translational Science Awards', 'Collaborations', 'Communities', 'Computer Simulation', 'Consent', 'DNA Sequencing Facility', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Management', 'Documentation', 'Environmental Exposure', 'Etiology', 'Evaluation', 'Expert Systems', 'Faculty', 'Family', 'Family Physicians', 'Functional disorder', 'Funding', 'Genes', 'Genomics', 'Genotype', 'Geographic Locations', 'Individual', 'Institutes', 'International', 'Laboratories', 'Methods', 'Molecular', 'Monitor', 'Network-based', 'Participant', 'Pathogenicity', 'Patient Care', 'Patients', 'Phase', 'Phase I Clinical Trials', 'Phenotype', 'Process', 'Protocols documentation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Review Committee', 'Secure', 'Societies', 'Standardization', 'Time', 'Training', 'Translational Research', 'Underrepresented Minority', 'Universities', 'Variant', 'Washington', 'clinical practice', 'clinical research site', 'cost', 'data management', 'deep learning', 'design', 'disease diagnosis', 'exome sequencing', 'experience', 'follow-up', 'genetic variant', 'genome sequencing', 'improved', 'innovation', 'medical schools', 'medical specialties', 'network models', 'operation', 'outreach', 'recruit', 'research clinical testing', 'screening', 'sequencing platform', 'student training', 'success', 'transcriptome sequencing']",NHGRI,WASHINGTON UNIVERSITY,U01,2018,750000,0.012077823451963388
"Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND) Project Summary/Abstract  This Phase III (P-III) COBRE project will extend the cores that have been successfully leveraged in our Phase I (P-I) and Phase II (P-II) COBRE projects and sustain these unique resources in New Mexico through the im- plementation of a business plan. Over the past eight years we have built up infrastructure and created a cutting edge brain imaging center, our P-II project is just over half-way through and is even more successful than our P- I was at this point in time. The Mind Research Network (MRN) houses an Elekta Neuromag 306-channel MEG System, a high density EEG lab, a 3T Siemens Trio MRI scanner, and a mobile 1.5T Siemens Avanto MRI scanner. Additional resources include a centralized neuroinformatics system, a strong IT management plan, and state-of-the-art image analysis expertise and tools. This P-III COBRE center will continue our momentum and move the cores we have developed into a position of long term sustainability. We will continue with the technical cores established during the P-II project including multimodal data acquisition (MDA), algorithm and data analy- sis (ADA), and biostatistics and neuro-informatics (BNI). These cores have begun to serve MRN and the greater community, as well as other institutions including extensive collaborations with IDeA funded projects in New Mexico and other states. We believe this P-III COBRE is extremely well-positioned to establish and sustain New Mexico as one of the premier brain imaging sites. We include an extensive pilot project program (PPP) that is built on the successful pilot programs implemented as part of the earlier COBRE phases. This includes an ex- tensive educational, mentoring, and faculty development program to carefully mentor and position faculty who use the cores to maximize their potential to successfully compete for external funding, thus fulfilling the ultimate goals of the COBRE program. 2 Narrative  This Phase III COBRE project is a natural extension of our Phase I and II COBRE projects which were cen- tered on mentoring individual researchers along with building the necessary infrastructure to support multimodal neuroimaging in mental illness. During this time, cutting-edge cores were developed that facilitated not only our local projects but also research at multiple institutions across New Mexico; the cores served as neuroimaging facilities and training centers for others to utilize. The Phase III project will ensure the sustainability of these cores as they transition to being fully funded by a broad cadre of users with various funding sources. We propose three technical cores including a multimodal data acquisition (MDA) core, an algorithm and data analysis (ADA) core, and a biostatistics and neuro-informatics (BNI) core. These cores have already shown their utility and have begun to be leveraged by users outside the COBRE. In addition, we propose a robust pilot project program (PPP) to continue to seed and enable new users of the cores to ultimately grow and sustain world class brain imaging research within our IDeA state, thus fulfilling the ultimate goals of the COBRE program. 1",Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND),9281577,P30GM122734,"['Algorithmic Analysis', 'Appointment', 'Area', 'Awareness', 'Biology', 'Biometry', 'Bipolar Depression', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Businesses', 'Centers of Research Excellence', 'Chemistry', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Core Facility', 'Data', 'Data Analyses', 'Department of Energy', 'Development', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Genetic', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institution', 'Interdisciplinary Study', 'Leadership', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Magnetoencephalography', 'Major Depressive Disorder', 'Mental Depression', 'Mental disorders', 'Mentors', 'Methods', 'Mind-Body Method', 'Mission', 'Multimodal Imaging', 'Neurobiology', 'Neurologic', 'Neurosciences', 'New Mexico', 'Paper', 'Patients', 'Peer Review', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Program Development', 'Psychiatry', 'Publications', 'Recording of previous events', 'Research', 'Research Domain Criteria', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Role', 'Schizophrenia', 'Seeds', 'Site', 'Structure', 'System', 'Teacher Professional Development', 'Time', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Vision', 'base', 'cohesion', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'deep learning', 'density', 'design', 'distinguished professor', 'improved', 'independent component analysis', 'meetings', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'neuropsychiatric disorder', 'programs', 'tool']",NIGMS,THE MIND RESEARCH NETWORK,P30,2018,1320387,0.00265890337490124
"Training a new generation of computational neuroscientists bridging neurobiology The Training Program in Computational Neuroscience (TPCN) will support integrated undergraduate and graduate training in computational neuroscience at New York University. The program will be hosted by the Center for Neural Science (CNS), with participation of faculty in the Departments of Psychology, Mathematics, and Computer Science, and the Institute of Neuroscience at the School of Medicine. The TPCN will fit well with NYU’s unique strengths and recent developments: (1) NYU is one of a few universities with a critical mass of computational neuroscientists. NYU has had a Sloan-Swartz Center for Theoretical Neuroscience since 1994. In the past three years alone, NYU has hired three computational neuroscientists. (2) CNS established an undergraduate major in neuroscience as early as 1992, and thus has a long track record in undergraduate education, it now has 136 students in the current academic year. (3) Recent faculty hiring in CNS, Psychology, and the School of Medicine has greatly expanded our teaching and research capabilities in the neuroscience of cognitive functions and their impairments associated with mental disorders. (3) As NYU is undertaking a merge of two historically separated neuroscience graduate programs (at CNS and the School of Medicine), this training grant will ensure that computational modeling, which has become indispensible in neuroscience, will be front-and-center in the integrated graduate program. (4) NYU is a major center of Artificial Intelligence and Data Science, with close links to Facebook’s AI Center and the Simons Center for Data Analysis. Our training faculty together with these connections will give our students ample opportunities to acquire machine learning techniques for data analysis and learn about brain-like AI algorithms. The proposed training program will support coherent undergraduate and graduate training in computational neuroscience at NYU. It will have several unique features: (1) Innovative mentorship methods: For example, (a) graduate trainees will mentor undergraduate trainees, (b) faculty will explicitly discuss human factors in academic practice; (c) there will be post-mortems after seminars by outside speakers. (2) Computational psychiatry: We propose new courses and research opportunities that are designed specifically to link cognitive function and the neurobiology of neural circuits. We propose innovative education in the nascent field of Computational Psychiatry, to bring theory and circuit modeling to clinical research in mental health. (3) Broad preparation: We aim to prepare trainees for jobs not only in academia, but also in medical and industry research. To achieve this, we will utilize our strength in machine learning and data science to broaden computational neuroscience training. The Program Directors have complementary strengths and will have complementary roles in the program. Wang will supervise graduate trainees and focus on training in mechanistic/circuit-level side of computational neuroscience as well as computational psychiatry. Ma will supervise undergraduate trainees and focus on the computational/behavioral side. This grant will support training of a new generation of graduate and undergraduate students in  computational neuroscience, which has become increasingly important to meet the challenges of  making discoveries with new data analysis tools and of understanding highly nonlinear complex  neural circuits. A salient component of our program is training in the nascent field  of   Computational  Psychiatry,  bridging  basic  neuroscience  and clinical research on mental  disorders. Therefore, the proposed program has the potential of making  a significant impact on  mental health.",Training a new generation of computational neuroscientists bridging neurobiology,9346652,R90DA043849,"['Academia', 'Algorithms', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Clinical Research', 'Computer Simulation', 'Data Analyses', 'Data Science', 'Development', 'Education', 'Educational process of instructing', 'Ensure', 'Faculty', 'Generations', 'Grant', 'Human', 'Impairment', 'Industry', 'Institutes', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurosciences', 'New York', 'Occupations', 'Preparation', 'Psychiatry', 'Psychology', 'Research', 'Role', 'Science', 'Side', 'Students', 'Supervision', 'Teacher Professional Development', 'Techniques', 'Training', 'Training Programs', 'Universities', 'cognitive function', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'design', 'innovation', 'mathematical sciences', 'medical schools', 'neural circuit', 'programs', 'relating to nervous system', 'theories', 'undergraduate education', 'undergraduate student']",NIDA,NEW YORK UNIVERSITY,R90,2017,204981,0.03594438421696144
"From genomics to natural language processing: A protected environment for research computing in the health science NIH S10 equipment proposal: From genomics to natural language processing:  A protected environment for research computing in the health sciences. Health sciences researchers are often required to manage, mine, and analyze restricted patient data (Protected Health Information, PHI) to facilitate and advance their research aims. They are often required to do this without access to central information technology expertise or resources to facilitate their research aims. These researchers are often left to their own devices to “solve” their research compute and data needs and are challenged due to lack of available resources, barriers from central IT, and/or lack of knowledge of available resources. A further challenge is that “small” data sets— data that researchers could formerly handle on office resources—have morphed and grown into the big data domain through the explosion of technical advances and significant expansion in various research directions. Examples include: genomics research, image analysis, simulation, natural language processing, and mining of EMRs. Therefore, the need exists to develop a framework for managing and processing this data securely and reliably. This S10 equipment proposal is to replace the “protected environment” (PE) prototype the University of Utah’s Center for High Performance Computing (CHPC) and Department of Biomedical Informatics built six years ago and has operated since. The PE consists of both high performance computing and virtual machine (VM) components and associated storage sufficient to manage, protect and analyze HIPAA protected health information. This environment has been very successful and has grown significantly in scope. CHPC isolated this protected environment in the secured University of Utah Downtown Data Center and setup a network protected logical partition that provided research groups specific access to individual data sets. As the environment and technology developed, CHPC added additional security features such as two-factor authentication for entry and audit/monitoring. Unfortunately, the prototype has reached the point where demand is surpassing capability and all the hardware is aged and off-warranty. To give an idea of users of the virtual machine farm component, the Biomedical Informatics Core (BMIC) REDCap (Research Electronic Data Capture) environment for data collection has over 2,500 users in 1,500 projects supporting over $25M in NIH funding at the University of Utah, including support for more than 25 active NIH R-01 grants. Moreover, the HIPAA compliant protected environment was a key factor that aided passing the recent University of Utah HIPAA audit. The “protected environment” also helped the University of Utah Health Sciences Center and the BMIC justify the NCATS Center Clinical and Translational Science award (1ULTR001067). NIH S10 equipment proposal: From genomics to natural language processing:  A protected environment for research computing in the health sciences. Project Narrative: The proposed “Protected Environment” instrument will provide research computing and data management capabilities for health sciences researchers to properly manage, secure, and analyze HIPAA regulated protected health information. The technology will not only support a large number of clinical trials, but also enable research in Human Genetics and Natural Language Processing of electronic health records.",From genomics to natural language processing: A protected environment for research computing in the health science,9274445,S10OD021644,"['Award', 'Big Data', 'Clinical Sciences', 'Data', 'Data Collection', 'Data Set', 'Devices', 'Environment', 'Equipment', 'Explosion', 'Farming environment', 'Funding', 'Genomics', 'Grant', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'High Performance Computing', 'Image Analysis', 'Individual', 'Information Technology', 'Knowledge', 'Left', 'Mining', 'Monitor', 'Natural Language Processing', 'Patients', 'Research', 'Research Personnel', 'Resources', 'Secure', 'Security', 'Technology', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Utah', 'aged', 'biomedical informatics', 'computerized data processing', 'electronic data', 'prototype', 'simulation', 'virtual']",OD,UNIVERSITY OF UTAH,S10,2017,493595,-0.011333111086462021
"Transforming Analytical Learning in the Era of Big Data ﻿    DESCRIPTION (provided by applicant): In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio) statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offer and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will draw from the expertise and experience of faculty from four different departments within four different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts, and Information Science in the School of Information. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high-dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and imaging. The diseases and conditions they study include obesity, cancer, diabetes, cardiovascular disease, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and response for our pilot offering in 2015 with 153 applications for 20 positions and a yield rate of 80% from the offers we extended. We plan to build on the success of this initial offering in the next three year funding cycle of this grant (2016-2018). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a no-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 30 undergraduates nationally and expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world. PUBLIC HEALTH RELEVANCE: We propose a six week long summer institute: ""Transforming Analytical Learning in the Era of Big Data"" to be held at the Department of Biostatistics, University of Michigan, Ann Arbor, with a group of approximately 30 undergraduates recruited nationally, from 2016-2018. We plan to expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Statistics, Computer Science and Engineering, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm.",Transforming Analytical Learning in the Era of Big Data,9325011,R25EB022363,"['Adverse drug effect', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Big Data', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Case Study', 'Code', 'Collection', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Engineering', 'Epigenetic Process', 'Faculty', 'Funding', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Image', 'Imagery', 'Information Sciences', 'Injury', 'Kidney Diseases', 'Learning', 'Literature', 'Machine Learning', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Positioning Attribute', 'Prevention', 'Problem Sets', 'Public Health Informatics', 'Public Health Schools', 'Recruitment Activity', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Social Behavior', 'Statistical Methods', 'Students', 'Talents', 'Techniques', 'Training', 'Universities', 'Work', 'base', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'design', 'experience', 'high dimensionality', 'instructor', 'interest', 'lectures', 'member', 'metabolomics', 'nervous system disorder', 'next generation', 'novel therapeutics', 'open source', 'personalized medicine', 'posters', 'programs', 'public health relevance', 'response', 'signal processing', 'skills', 'statistics', 'success', 'summer institute', 'symposium', 'tool', 'undergraduate student', 'wiki']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2017,161633,0.051481843489061756
"Adapting the Berkeley Big Data Analytics Stack to Genomics and Health Project Summary We propose building a computational platform based on the high performance Berkeley Big Data Analytics Stack (BDAS) to support a new ecosystem of Clinical Decision Support (CDS) applications. This platform will make it faster, easier, and less expensive to develop molecular Clinical Decision Support Systems. These systems require real-time queries of globally distributed data, efficient machine learning on large genomic datasets, and must be secure, fault-tolerant and scalable. BDAS and associated technologies are designed to help us meet these challenges and are therefore ideal building blocks to help us create our computational platform. To encourage the adoption of standards for the querying and sharing of large genomic datasets, we will adapt the BDAS stack to support the standards of the Global Alliance for Genomics and Health (GA4GH). Project Narrative Funding this work will help establish a production quality FOSS implementation of the important Global Alliance for Genomics and Health standards. Without such open-source implementations, a fragmented and proprietary platform ecosystem would slow down innovation as well as divert resources away from the practice of medicine.",Adapting the Berkeley Big Data Analytics Stack to Genomics and Health,9466681,R44GM119858,"['Adoption', 'Algorithms', 'Apache', 'Big Data', 'Big Data to Knowledge', 'Businesses', 'Capital', 'Clinical', 'Clinical Decision Support Systems', 'Cloud Computing', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Contractor', 'Data', 'Data Analytics', 'Data Set', 'Distributed Systems', 'Ecosystem', 'Ensure', 'Feedback', 'Funding', 'Genome', 'Genomics', 'Health', 'Individual', 'Industrialization', 'Industry', 'Ingestion', 'Institutes', 'International', 'Leadership', 'Letters', 'Machine Learning', 'Maintenance', 'Measures', 'Medicine', 'Molecular', 'Performance', 'Phase', 'Phenotype', 'Policies', 'Production', 'Provider', 'Publications', 'Resources', 'Running', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Software Tools', 'Source', 'System', 'Technology', 'Time', 'Training', 'Variant', 'Work', 'base', 'cloud platform', 'cluster computing', 'commercialization', 'design', 'distributed data', 'genomic data', 'health care delivery', 'individual patient', 'innovation', 'open source', 'operation', 'petabyte', 'precision medicine', 'symposium', 'web services', 'whole genome']",NIGMS,"CUROVERSE INNOVATIONS, INC.",R44,2017,1086725,0.013671574917505576
"INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE Project Summary  To understand the many disorders of the brain it is necessary to grapple with its complexity.  Increasingly large and complicated data sets are being collected, but the tools for analyzing and  modeling the data are not yet available. More researchers trained in computational neuroscience are  desperately needed. This project supports graduate and undergraduate training programs in  computational neuroscience (TPCN) at both Carnegie Mellon University (CMU) and the University of  Pittsburgh (Pitt), and a summer school in computational neuroscience for undergraduates, which are  available to students coming from colleges and universities throughout the United States.  The CMU-Pitt TPCN has 16 training faculty in computational neuroscience, 22 training faculty whose  laboratories are primarily experimental, and 20 training faculty whose laboratories are both  computational and experimental. At the graduate level the TPCN offers a PhD program in Neural  Computation (PNC) and joint PhD programs with CMU’s Department of Statistics (PNC-Stat) and its  Machine Learning Department (PNC- MLD), all set within a highly collegial, cross-disciplinary  environment of our Center for the Neural Basis of Cognition (CNBC), which is operated jointly by  CMU and Pitt. The CNBC was established in 1994 to foster interdisciplinary research on the neural  mechanisms of brain function, and now comprises 145 faculty having appointments in 22 departments.  At the undergraduate level a substantial pool of local students is supplemented during the summer  by a cohort of students from across the country. During this renewal funding period the project is  strengthening the role of statistics and machine learning throughout the training programs; (2) revising the summer undergraduate program by creating a didactic two-week “boot camp” at the  beginning, which includes a 20-lecture overview of computational neuroscience; (3) creating online  materials, in conjunction with the boot camp, that will serve not only our own students but also  the greater world of training in computational neuroscience; and (4) enhancing our minority  recruitment by (a) taking advantage of the boot camp and online materials, as well as making  promotional visits to targeted campuses, and (b) creating and running a one-year “bridge” program  to better prepare under-represented minorities for PhD programs.  TPCN trainees work in vertically integrated, cross-disciplinary research teams. Graduate students  take a year- long course in computational neuroscience that bridges modeling and modern statistical  machine learning approaches to neuroscience. To ensure their competency in core neuroscience  principles they also take courses in cognitive neuroscience, neurophysiology, and systems  neuroscience. They then pursue depth in a relevant quantitative discipline, such as computer  science, engineering, mathematics, or statistics. Graduate students have extended experience in at  least one experimental laboratory, and they take part in journal clubs and seminars within the  large Pittsburgh neuroscience community. Year-long undergraduates take courses in mathematics,  computer programming, statistics, and neuroscience; they take an additional course in neuroscience  or psychology and a course in computational neuroscience; and they complete a year-long research  project. In addition, they complete the TPCN summer program. Undergraduate trainees in the summer  program go through the boot camp on topics in computational neuroscience, including tutorials in  Matlab, statistical methods, fundamentals of differential equations, and ideas of neural coding;  they then complete a research project under careful guidance. All trainees will receive training in  responsible conduct of research. Across 5 years of funding, the TPCN supports 20 NRSA graduate  students, 10 non-NRSA graduate students, 30 undergraduate year-long fellows, and 60 undergraduate  summer fellows. Project Narrative  Research in neuroscience is crucial for attacking the causes of neurological and mental health  disorders. If the field of neuroscience is to continue its rapid advance, neuroscientists must use,  understand, and develop new technologies, acquire and analyze ever larger data sets, and grapple  more directly with the complexity of neurobiological systems. The primary goal of these training  programs will be to help train a new generation of interdisciplinary neuroscientists with strong  quantitative skills.",INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE,9349475,R90DA023426,"['Appointment', 'Brain', 'Brain Diseases', 'Code', 'Cognition', 'Communities', 'Competence', 'Country', 'Data Set', 'Differential Equation', 'Discipline', 'Doctor of Philosophy', 'Educational Status', 'Engineering', 'Ensure', 'Environment', 'Faculty', 'Fostering', 'Funding', 'Interdisciplinary Study', 'Joints', 'Journals', 'Laboratories', 'Machine Learning', 'Mathematics', 'Minority Recruitment', 'Modeling', 'Modernization', 'National Research Service Awards', 'Neurosciences', 'Psychology', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Running', 'Schools', 'Statistical Methods', 'Students', 'System', 'Teacher Professional Development', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States', 'Universities', 'Visit', 'Work', 'bridge program', 'cognitive neuroscience', 'cohort', 'college', 'computational neuroscience', 'computer program', 'computer science', 'data modeling', 'experience', 'graduate student', 'lectures', 'neuromechanism', 'neurophysiology', 'programs', 'relating to nervous system', 'responsible research conduct', 'statistics', 'summer program', 'tool', 'undergraduate student']",NIDA,CARNEGIE-MELLON UNIVERSITY,R90,2017,305372,0.03394526838430016
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,9371707,K99HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Databases', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'comparative effectiveness', 'computer science', 'data sharing', 'design', 'digital', 'effectiveness research', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'learning strategy', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'permissiveness', 'point of care', 'predictive modeling', 'privacy protection', 'programs', 'public trust', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",K99,2017,93824,0.004927709209659669
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9266344,U54AI117924,"['Address', 'Biological', 'Blood coagulation', 'Clinical', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'biomedical scientist', 'clinical investigation', 'clinical predictors', 'education research', 'graduate student', 'high dimensionality', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning', 'undergraduate student']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2017,229691,0.00016662745926958368
"HERCULES: Exposome Research Center PROJECT SUMMARY: HERCULES The vision of the HERCULES P30 is to demonstrably advance the role of environmental health sciences in clinical and public health settings using the platform of the exposome. Healthcare and biomedical research have become increasingly genome-centric. While much of this is due to the impressive achievements in genomics, which have consistently outpaced gains in environmental health, it is our contention that a more persuasive case needs to be made for environmental factors. Science and intuition support the idea that the environment plays just as large of a role as genetics for the majority of diseases. The exposome, which embraces a strategy and scale similar to genomic research, is poised to elevate the environment in discussions of health and disease. We will continue to grow and enhance the environmental health science research portfolio at Emory through cutting-edge technologies and innovative data solutions. We will build upon the superb relationships we have built with the local community and continue to push the mission of NIEHS on campus and across the scientific landscape. Based on the extraordinary progress over our first three years, we propose to retain our theme to use exposome-related concepts and approaches to improve human health. This simple and unifying vision will continue to stimulate discovery, promote collaboration, and enhance communication through the following Specific Aims: Specific Aim 1. To marshal physical and intellectual resources to support exposome-related approaches (high-resolution metabolomics, analytical chemistry, systems biology, machine learning, bioinformatics, high-throughput toxicology, and spatial and temporal statistical models) through cores, pilot funding, mentoring, and research forums. Specific Aim 2. To make major contributions towards exposome and environmental health science research. Specific Aim 3. To provide career development activities around innovative and emerging concepts and approaches related to the exposome. Specific Aim 4. To enhance and expand existing relationships with community partners to resolve environmental health issues in the community using exposome principles. Specific Aim 5. To provide infrastructure and resources to facilitate rapid translation of novel scientific findings into the development of prevention and treatment strategies in humans. Pursuit of HERCULES' aims will advance environmental health sciences within our institutions and in the scientific community. PROJECT NARRATIVE: HERCULES Human health and disease is dictated by a combination of genetic and environmental factors. The HERCULES Center is focused on providing a more comprehensive assessment of these environmental influences by utilizing exposome-based concepts and approaches.",HERCULES: Exposome Research Center,9270925,P30ES019776,"['Achievement', 'Analytical Chemistry', 'Award', 'Bioinformatics', 'Biomedical Research', 'Climate', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Community Outreach', 'Core Facility', 'Data', 'Data Science', 'Development', 'Discipline', 'Disease', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Care Research', 'Health Sciences', 'Human', 'Individual', 'Institution', 'Intuition', 'Leadership', 'Letters', 'Machine Learning', 'Marshal', 'Mentors', 'Mission', 'National Institute of Environmental Health Sciences', 'Phase', 'Play', 'Prevention strategy', 'Productivity', 'Public Health', 'Research', 'Research Activity', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Statistical Models', 'Strategic Planning', 'Systems Biology', 'Technology', 'Toxicology', 'Translations', 'Update', 'Vision', 'base', 'career development', 'catalyst', 'improved', 'innovation', 'metabolomics', 'novel', 'operation', 'ranpirnase', 'treatment strategy']",NIEHS,EMORY UNIVERSITY,P30,2017,1573499,0.01771188660310311
"HERCULES: Exposome Research Center PROJECT SUMMARY: HERCULES The vision of the HERCULES P30 is to demonstrably advance the role of environmental health sciences in clinical and public health settings using the platform of the exposome. Healthcare and biomedical research have become increasingly genome-centric. While much of this is due to the impressive achievements in genomics, which have consistently outpaced gains in environmental health, it is our contention that a more persuasive case needs to be made for environmental factors. Science and intuition support the idea that the environment plays just as large of a role as genetics for the majority of diseases. The exposome, which embraces a strategy and scale similar to genomic research, is poised to elevate the environment in discussions of health and disease. We will continue to grow and enhance the environmental health science research portfolio at Emory through cutting-edge technologies and innovative data solutions. We will build upon the superb relationships we have built with the local community and continue to push the mission of NIEHS on campus and across the scientific landscape. Based on the extraordinary progress over our first three years, we propose to retain our theme to use exposome-related concepts and approaches to improve human health. This simple and unifying vision will continue to stimulate discovery, promote collaboration, and enhance communication through the following Specific Aims: Specific Aim 1. To marshal physical and intellectual resources to support exposome-related approaches (high-resolution metabolomics, analytical chemistry, systems biology, machine learning, bioinformatics, high-throughput toxicology, and spatial and temporal statistical models) through cores, pilot funding, mentoring, and research forums. Specific Aim 2. To make major contributions towards exposome and environmental health science research. Specific Aim 3. To provide career development activities around innovative and emerging concepts and approaches related to the exposome. Specific Aim 4. To enhance and expand existing relationships with community partners to resolve environmental health issues in the community using exposome principles. Specific Aim 5. To provide infrastructure and resources to facilitate rapid translation of novel scientific findings into the development of prevention and treatment strategies in humans. Pursuit of HERCULES' aims will advance environmental health sciences within our institutions and in the scientific community. PROJECT NARRATIVE: HERCULES Human health and disease is dictated by a combination of genetic and environmental factors. The HERCULES Center is focused on providing a more comprehensive assessment of these environmental influences by utilizing exposome-based concepts and approaches.",HERCULES: Exposome Research Center,9565097,P30ES019776,"['Achievement', 'Analytical Chemistry', 'Award', 'Bioinformatics', 'Biomedical Research', 'Climate', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Community Outreach', 'Core Facility', 'Data', 'Data Science', 'Development', 'Discipline', 'Disease', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Care Research', 'Health Sciences', 'Human', 'Individual', 'Institution', 'Intuition', 'Leadership', 'Letters', 'Machine Learning', 'Marshal', 'Mentors', 'Mission', 'National Institute of Environmental Health Sciences', 'Phase', 'Play', 'Prevention strategy', 'Productivity', 'Public Health', 'Research', 'Research Activity', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Statistical Models', 'Strategic Planning', 'Systems Biology', 'Technology', 'Toxicology', 'Translations', 'Update', 'Vision', 'base', 'career development', 'catalyst', 'improved', 'innovation', 'metabolomics', 'novel', 'operation', 'ranpirnase', 'treatment strategy']",NIEHS,EMORY UNIVERSITY,P30,2017,93567,0.01771188660310311
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9383718,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Complex', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophageal', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'improved', 'in vivo', 'learning strategy', 'lymph nodes', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2017,359872,0.0064977420675960025
"The Big DIPA: Data Image Processing and Analysis ﻿    DESCRIPTION (provided by applicant): This proposal aims to establish a national short course in Big Data Image Processing & Analysis (BigDIPA) intended to increase the number and overall skills of competent research scientists now encountering large, complex image data sources derived from cutting edge biological/biomedical research approaches. Extraction of knowledge from these imaging sources requires specialized skills and an interdisciplinary mindset. Yet effective training opportunities of this sector of the ""Big Data"" science community are glaringly underappreciated and underserved compared to other big data fields such as omics. UC Irvine is ideally suited to host a short course to address this thematic training deficit on account of the synergistic colocalization between multiple facilities, renowned for development of numerous advanced imaging techniques, and the outstanding instructional environment provided by faculty with collaborative expertise in biological image processing and computer vision, bioinformatics and high performance computational approaches.  Specifically, our BigDIPA proposal assembles an interdisciplinary alliance of faculty experts that can leverage the preeminent imaging resource facilities, such as the Laboratory of Fluorescence Dynamics (LFD) and the Beckman Laser Institute, and fuse these to ongoing campus big data initiatives, e.g. UCI's Data Science Initiative, to create a top-rated training course designed for senior graduate students, postdoctoral researchers, faculty and industry scientists from diverse scientific disciplines who have nascent interests and needs to handle BIG DATA sources beyond their current level of competency.  The course theme is focused to utilize discreet examples drawn from the analysis of complex data acquired from different microscopy imaging modalities employed to investigate dynamics in cellular and tissue processes, including signal transduction networks, development, neuroscience and biomedical applications, and that hereto where hidden or inaccessible to standard methods of analysis. Participants will be guided along the complete acquisition- processing-analysis pipeline through exposure to a coherent progression of topics and issues typically encountered when handling BIG DATA. We believe this training approach will therefore be attractive to a broad and significant untapped pool of researchers from the biological disciplines, biomedical engineering, systems biology, math, biophysics, computer science, bioinformatics and statistics who possess some, but not all, of the requisite competencies to effectively traverse the BD2K landscape. We have designed the course such that skills and experience gained by trainees will be transferable to their own research interests.  The BigDIPA course format will combine didactic lectures on the theory and foundational frameworks that underpin each step, with practical instruction on implementation and hands-on tutorials in image acquisition, large data handling, basic scripting of computational tools, image processing on high performance computing architectures, as well as feature extraction, evaluation and visualization of results. The course is designed to offer an intense learning experience delivered in a compact time frame, and opportunities to foster interdisciplinary interactions through small team exercises. Participants will also be encouraged to take advantage of pre-courses - separate and distinct training opportunities not funded by this proposal - that will be coordinated to directly precede our course. This unique format provides multiple benefits: it provides an efficient mechanism to address individual participant training deficiencies to permit a more productive experience in the BigDIPA course, adds no-cost mutual benefits to independent but synergistic programs, and facilitates recruitment of applicants who frequently feel interested but intimidated due to a perceived lack of prior adequate training.  Beyond providing an intensive on-site training course, all course materials (lecture notes, video lectures and tutorials), tutorial exercises, open source software resources and sample datasets will be made freely available through on-line distribution to maximize outreach and encourage additional contributions of curated training resources solicited from the community. PUBLIC HEALTH RELEVANCE: We propose to train and expand the cadre of researchers capable of effectively using the deluge of complex BIG DATA being generated by advanced biomedical imaging approaches. These data sources represent a rich source of complex information relevant to many scientific areas of inquiry, and are informative at multiple scales ranging from fundamental biological processes at the cellular level to patient diagnostics for diseases such as cancer or neurological disorders.",The Big DIPA: Data Image Processing and Analysis,9295026,R25EB022366,"['Address', 'Architecture', 'Area', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biomedical Engineering', 'Biomedical Research', 'Biomedical Technology', 'Biophysics', 'Communities', 'Competence', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Development', 'Diagnostic', 'Discipline', 'Disease', 'Education', 'Educational Curriculum', 'Educational workshop', 'Environment', 'Evaluation', 'Exercise', 'Exposure to', 'Faculty', 'Fluorescence', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Information Sciences', 'Institutes', 'Instruction', 'Interdisciplinary Communication', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Methods', 'Modality', 'Modernization', 'NIH Program Announcements', 'National Institute of General Medical Sciences', 'Neurosciences', 'Participant', 'Patients', 'Performance', 'Problem Solving', 'Process', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Sampling', 'Schools', 'Scientist', 'Signal Transduction', 'Site', 'Software Tools', 'Source', 'Stream', 'Systems Biology', 'Talents', 'Time', 'Tissues', 'Training', 'United States National Institutes of Health', 'big biomedical data', 'bioimaging', 'biological systems', 'biomedical scientist', 'computer science', 'computerized tools', 'cost', 'course implementation', 'data acquisition', 'data format', 'demographics', 'design', 'experience', 'flexibility', 'graduate student', 'image processing', 'imaging approach', 'imaging modality', 'interdisciplinary collaboration', 'interest', 'learning materials', 'lecture notes', 'lectures', 'microscopic imaging', 'nervous system disorder', 'open source', 'outreach', 'programs', 'public health relevance', 'repository', 'skill acquisition', 'skills', 'statistics', 'theories', 'training opportunity']",NIBIB,UNIVERSITY OF CALIFORNIA-IRVINE,R25,2017,161997,0.023675917023469984
"Summer Institute in Neuroimaging and Data Science Project Summary/Abstract The study of the human brain with neuroimaging technologies is at the cusp of an exciting era of Big Data. Many data collection projects, such as the NIH-funded Human Connectome Project, have made large, high- quality datasets of human neuroimaging data freely available to researchers. These large data sets promise to provide important new insights about human brain structure and function, and to provide us the clues needed to address a variety of neurological and psychiatric disorders. However, neuroscience researchers still face substantial challenges in capitalizing on these data, because these Big Data require a different set of technical and theoretical tools than those that are required for analyzing traditional experimental data. These skills and ideas, collectively referred to as Data Science, include knowledge in computer science and software engineering, databases, machine learning and statistics, and data visualization.  The Summer Institute in Data Science for Neuroimaging will combine instruction by experts in data science methodology and by leading neuroimaging researchers that are applying data science to answer scientiﬁc ques- tions about the human brain. In addition to lectures on the theoretical background of data science methodology and its application to neuroimaging, the course will emphasize experiential hands-on training in problem-solving tutorials, as well as project-based learning, in which the students will create small projects based on openly available datasets. Summer Institute in Neuroimaging and Data Science: Project Narrative The Summer Institute in Neuroimaging and Data Science will provide training in modern data science tools and methods, such as programming, data management, machine learning and data visualization. Through lectures, hands-on training sessions and team projects, it will empower scientists from a variety of backgrounds in the use of these tools in research on the human brain and on neurological and psychiatric brain disorders.",Summer Institute in Neuroimaging and Data Science,9278954,R25MH112480,"['Address', 'Adopted', 'Big Data', 'Brain', 'Brain Diseases', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Data Set', 'Databases', 'Discipline', 'Face', 'Faculty', 'Fostering', 'Funding', 'Habits', 'Home environment', 'Human', 'Image', 'Institutes', 'Institution', 'Instruction', 'Internet', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mental disorders', 'Methodology', 'Methods', 'Modernization', 'Neurologic', 'Neurosciences', 'Participant', 'Positioning Attribute', 'Problem Solving', 'Psychology', 'Reproducibility', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Software Engineering', 'Software Tools', 'Structure', 'Students', 'Technology', 'Testing', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'career', 'computer science', 'connectome', 'data management', 'data visualization', 'design', 'e-science', 'experimental study', 'high dimensionality', 'insight', 'instructor', 'interdisciplinary collaboration', 'knowledge base', 'lectures', 'nervous system disorder', 'neurogenetics', 'neuroimaging', 'novel', 'open source', 'prediction algorithm', 'programs', 'project-based learning', 'skills', 'statistics', 'success', 'summer institute', 'theories', 'tool']",NIMH,UNIVERSITY OF WASHINGTON,R25,2017,205185,-0.006953217115588497
"QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine  The purpose of this proposal is to develop a combination of innovative statistical and data visualization approaches using patient-generated health data, including mobile health (mHealth) data from wearable devices and smartphones, and patient-reported outcomes, to improve outcomes for patients with Inflammatory Bowel Diseases (IBDs). This research will offer new insights into how to process and transform patient-generated health data into precise lifestyle recommendations to help achieve remission of symptoms. The specific aims of this research are: 1) To develop new preprocessing methods for publicly available, heterogeneous, time-varied mHealth data to develop a high quality mHealth dataset; 2) To develop and apply novel machine learning methods to obtain accurate predictions and formal statistical inference for the influence of lifestyle features on disease activity in IBDs; and 3) To design and develop innovative, interactive data visualization tools for knowledge discovery. The methods developed in the areas of preprocessing of mHealth data, calibration for mHealth devices, machine learning, and interactive data visualization will be broadly applicable to other mHealth data, chronic conditions beyond IBDs, and other fields in which the data streams are highly variable, intermittent, and periodic. This work is highly relevant to the mission of the NIH BD2K initiative which supports the development of innovative and transformative approaches and tools to accelerate the integration of Big Data and data science into biomedical research. This project will also enhance training in the development and use of methods for biomedical Big Data science and mentor the next generation of multidisciplinary scientists. The proposed research is relevant to public health by seeking to improve symptoms for patients with inflammatory bowel diseases, which are chronic, life-long conditions with waxing and waning symptoms. Developing novel statistical and visualization methods to provide a more nuanced understanding of the precise relationship between physical activity and sleep to disease activity is relevant to BD2K's mission.",QuBBD: Statistical & Visualization Methods for PGHD to Enable Precision Medicine ,9394127,R01EB025024,"['Adrenal Cortex Hormones', 'Adult', 'Adverse effects', 'Affect', 'Americas', 'Area', 'Behavior', 'Behavior Therapy', 'Big Data', 'Big Data to Knowledge', 'Biomedical Research', 'Calibration', 'Caring', 'Cellular Phone', 'Characteristics', 'Chronic', 'Crohn&apos', 's disease', 'Data', 'Data Science', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Outcome', 'Disease remission', 'Dose', 'Effectiveness', 'Flare', 'Foundations', 'Functional disorder', 'Funding', 'Health Care Research', 'Imagery', 'Immunosuppression', 'Individual', 'Inflammation', 'Inflammatory', 'Inflammatory Bowel Diseases', 'Institute of Medicine (U.S.)', 'Knowledge Discovery', 'Life', 'Life Style', 'Longitudinal Surveys', 'Longitudinal cohort study', 'Machine Learning', 'Mathematics', 'Measures', 'Mentors', 'Methods', 'Mission', 'Moderate Activity', 'Morbidity - disease rate', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Patient-Focused Outcomes', 'Patients', 'Periodicity', 'Phenotype', 'Physical activity', 'Precision therapeutics', 'Process', 'Public Health', 'Quality of life', 'Recommendation', 'Reporting', 'Research', 'Research Institute', 'Schools', 'Scientist', 'Sleep', 'Sleep disturbances', 'Stream', 'Symptoms', 'Therapeutic', 'Time', 'Training', 'Ulcerative Colitis', 'United States National Institutes of Health', 'Visualization software', 'Waxes', 'Work', 'base', 'big biomedical data', 'clinical remission', 'comparative effectiveness', 'cost', 'data visualization', 'design', 'disorder risk', 'effectiveness research', 'health care quality', 'health data', 'improved', 'improved outcome', 'individual patient', 'innovation', 'insight', 'large bowel Crohn&apos', 's disease', 'learning strategy', 'lifestyle factors', 'mHealth', 'member', 'multidisciplinary', 'next generation', 'novel', 'precision medicine', 'symptomatic improvement', 'tool']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2017,338637,-0.009421614212643953
"Boosting the Translational Impact of Scientific Competitions by Ensemble Learning ﻿    DESCRIPTION (provided by applicant): ""Big data"" such as those arising from sequencing, imaging, genomics and other emerging technologies are playing a critical role in modern biology and medicine. The generation of hypotheses about biological processes and disease mechanisms is now increasingly being driven by the production and analysis of large and complex datasets. Advanced computational methods have been developed for the robust analysis of these datasets, and the growth in number and sophistication of these methods has closely tracked the growth in volume and complexity of biomedical data. In such a crowded environment of diverse computational methods and data, it is difficult to judge how generalizable the performance of these methods is from one setting to another. Crowdsourcing-based scientific competitions, or challenges, have now become popular mechanisms for the rigorous, blinded and unbiased evaluation of the performance of these methods and the identification of best-performing methods for biomedical problems. However, despite the benefits of these challenges to the biomedical research enterprise, the impact of their findings has been remarkably limited in laboratory and clinical settings. This is likely due to two important aspects of current challenges: (i) their over-emphasis on identifying the ""best"" solutions rather than tryig to comprehensively assimilate the knowledge embedded in all the submitted solutions, and (ii) the absence of a stable channel of communication and collaboration between problem and solution providers due to a lack of sufficient incentives to do so. The aim of this project is to boost the translational impact of scientific challenges through a combination of novel machine learning methods, development of novel scalable software and unique collaborations with disease experts to ensure the effective translation of knowledge accrued in challenges to real clinical settings and practice. These novel methods and software are designed to effectively assimilate the knowledge embedded in all the submissions to challenges into ""ensemble"" solutions. In a first of its kind effort, the ensemble solutions derived from disease-focused challenges under the DREAM project will be brought directly to scientists and clinicians that are experts in these disease areas. Initial effort in this project will focus on active DREAM challenges aiming at the accurate prediction of drug response and clinical outcomes respectively in Rheumatoid Arthritis (RA) and Acute Myeloid Leukemia (AML). Both these diseases are difficult to treat and thus they pose major medical and public health concerns. In collaboration with RA and AML experts, the ensemble solutions learnt in these challenges will be validated in independent patient cohorts and carefully designed clinical studies. This second-level validation is essential to judge the clinical applicability of any method, but is rarely done As the methodology is general, similar efforts will be made for other diseases in later stages of the project. Overall, using a smart combination of crowdsourcing-based challenges and computational methods and software, we aim to demonstrate a unique pathway for studying and treating disease by truly leveraging the ""wisdom of the crowds"". PUBLIC HEALTH RELEVANCE: Crowdsourcing-based scientific competitions, or challenges, have become a popular mechanism to identify innovative solutions to complex biomedical problems. However, the collective effort of all the challenge participants has been under utilized, and the overall impact on actual clinical and laboratory practice has been remarkably limited. Using novel computational methods and novel ""big data""-friendly software implementation, we plan to demonstrate how biomedical challenges, combined with our approach, can influence clinical practice in Acute Myeloid Leukemia and Rheumatoid Arthritis, as well as rigorously validate our approach.",Boosting the Translational Impact of Scientific Competitions by Ensemble Learning,9251828,R01GM114434,"['Acute Myelocytic Leukemia', 'Address', 'Adopted', 'Advanced Development', 'Architecture', 'Area', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Blinded', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Crowding', 'Data', 'Data Set', 'Discipline', 'Disease', 'Emerging Technologies', 'Ensure', 'Environment', 'Evaluation', 'Explosion', 'Generations', 'Genomics', 'Genotype', 'Goals', 'Growth', 'Heterogeneity', 'High Performance Computing', 'Image', 'Incentives', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Mining', 'Modernization', 'Nature', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Problem Solving', 'Production', 'Provider', 'Public Health', 'Publications', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Running', 'Science', 'Scientist', 'Software Design', 'Source', 'Standardization', 'Synapses', 'System', 'Time', 'Translating', 'Translations', 'Validation', 'Variant', 'base', 'clinical application', 'clinical practice', 'cohort', 'computer science', 'crowdsourcing', 'design', 'innovation', 'interest', 'interoperability', 'knowledge translation', 'learning progression', 'method development', 'novel', 'open source', 'predictive modeling', 'prospective', 'public health relevance', 'response', 'stem', 'tool', 'translational impact']",NIGMS,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2017,428512,0.0020321311688748754
"Development of Tools for Evaluating the National Toxicology Program's Effectiveness  As part of its activities, the National Toxicology Program (NTP) at NIEHS conducts literature-based evaluations to identify the state of the science, evaluate hazards, and determine the effectiveness of NTP’s research. NTP lacks an intelligent automated approach to assist with this work. NIEHS has requested assistant from the Oak Ridge National Laboratory (ORNL), Department of Energy to assist with the research and development of publication and web mining tools for use in NTP’s evaluations. This assistance extends to the Division of Extramual Research and Training to automate the approach for capturing outcomes and impacts from NIEHS-funded research noted in scientific publications and grantees’ progress reports. n/a",Development of Tools for Evaluating the National Toxicology Program's Effectiveness ,9492481,ES16002001,"['Applications Grants', 'Computer software', 'Department of Energy', 'Effectiveness', 'Evaluation', 'Funding', 'Imagery', 'Internet', 'Laboratories', 'Literature', 'Machine Learning', 'Methodology', 'Methods', 'Mining', 'National Institute of Environmental Health Sciences', 'National Toxicology Program', 'Outcome', 'Program Effectiveness', 'Program Evaluation', 'Progress Reports', 'Publications', 'Research', 'Research Training', 'Science', 'Techniques', 'Work', 'base', 'hazard', 'learning strategy', 'research and development', 'tool', 'tool development']",NIEHS,NATIONAL INSTITUTE OF ENVIRONMENTAL HEALTH SCIENCES,Y01,2017,446000,0.0008977612463890295
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9248178,U24HG009446,"['ATAC-seq', 'Alleles', 'Alpha Cell', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Standardization', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data integration', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'member', 'mouse genome', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2017,2000000,-0.0029911983325882543
"NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR) DESCRIPTION (provided by applicant):  We propose to establish a NIDA Center of Excellence for Computational Drug Abuse Research (CDAR) between the University of Pittsburgh (Pitt) and (CMU), with the goal of advancing and ensuring the productive and broad usage of state-of-the-art computational technologies that will facilitate and enhance drug abuse (DA) research, both in the local (Pittsburgh) area and nationwide. To this end, we will develop/integrate tools for DA-domain-specific chemical-to-protein-to-genomics mapping using cheminformatics, computational biology and computational genomics methods by centralizing computational chemical genomics (or chemogenomics) resources while also making them available on a cloud server. The Center will foster collaboration and advance knowledge-based translational research and increase the effectiveness of ongoing funded research project (FRPs) via the following Research Support Cores: (1) The Computational Chemogenomics Core for DA (CC4DA) will help address polydrug addiction/polypharmacology by developing new chemogenomics tools and by compiling the data collected/generated, along with those from other Cores, into a DA knowledge-based chemogenomics (DA-KB) repository that will be made accessible to the DA community. (2) The Computational Biology Core (CB4DA) will focus on developing a resource for structure-based investigation of the interactions among substances of DA and their target proteins, in addition to assessing the drugability of receptors and transporters involved in DA and addiction. These activities will be complemented by quantitative systems pharmacology methods to enable a systems-level approach to DA research. (3) The Computational Genomics Core (CG4DA) will carry out genome-wide discovery of new DA targets, markers, and epigenetic influences using developed machine learning models and algorithms. (4) The Administrative Core will coordinate Center activities, provide management to oversee the CDAR activities in consultation with the Scientific Steering Committee (SSC) and an External Advisory Board (EAB), ensure the effective dissemination of software/data among the Cores and the FRPs, and establish mentoring mechanisms to train junior researchers. Overall, the Center will strive to achieve the long-term goal of translating advances in computational chemistry, biology and genomics toward the development of novel personalized DA therapeutics. We propose a Computational Drug Abuse Research (CDAR) Center, as a joint initiative between the  University of Pittsburgh and Carnegie Mellon University. The Center consist of three Cores (CC4DA, CB4DA  and CG4DA) that will leverage our expertise in computational chemogenomics, computational biology, and  computational genomics to facilitate basic and translational drug abuse and medication research.",NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR),9321115,P30DA035778,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cannabinoids', 'Categories', 'Cells', 'Chemicals', 'Clinical Trials Network', 'Cloud Computing', 'Cocaine', 'Collaborations', 'Communities', 'Complement', 'Computational Biology', 'Computer software', 'Consultations', 'Data', 'Databases', 'Development', 'Doctor of Philosophy', 'Drug Addiction', 'Drug Receptors', 'Drug abuse', 'Effectiveness', 'Endocytosis', 'Ensure', 'Environmental Risk Factor', 'Epigenetic Process', 'Feedback', 'Fostering', 'Funding', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Intervention', 'Investigation', 'Joints', 'Leadership', 'Link', 'Machine Learning', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'National Institute of Drug Abuse', 'Neuropharmacology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacology', 'Phenotype', 'Proteins', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Science', 'Signal Transduction', 'Software Tools', 'Source', 'Structure', 'Substance Use Disorder', 'System', 'Systems Biology', 'Technology', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Universities', 'addiction', 'algorithmic methodologies', 'base', 'biobehavior', 'cheminformatics', 'cloud based', 'cloud platform', 'computational chemistry', 'computer science', 'data mining', 'design', 'distinguished professor', 'dopamine transporter', 'drug abuse prevention', 'falls', 'genome-wide', 'genome-wide analysis', 'improved', 'insight', 'knowledge base', 'member', 'novel', 'novel therapeutics', 'operation', 'prevent', 'professor', 'repository', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P30,2017,1080816,-0.0033933146064795586
"Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!) PROJECT SUMMARY/ABSTRACT Our society faces significant challenges in providing quality health care that is accessible by each person and is sensitive to each person's individual lifestyle and individual health needs. Due to recent advances in sensing technologies that have improved in accuracy, increased in throughput, and reduced in cost, it has become relatively easy to gather high resolution behavioral and individualized health data at scale. The resulting big datasets can be analyzed to understand the link between behavior and health and to design healthy behavior interventions. In this emerging area, however, very few courses are currently available for teaching researchers and practitioners about the foundational principles and best practices behind collecting, storing, analyzing, and using behavior- based sensor data. Teaching these skills can help the next generation of students thrive in the increasingly digital world.  The goal of this application is to design online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to WSU faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.  This contribution is significant because not only large research groups but even individual investigators can create large data sets that provide valuable, in-the-moment information about human behavior. They need to be able to handle the challenges that arise when working with sensor- based behavior data. Because students will receive hands-on training with actual sensor datasets and analysis tools, they will know how to get the best results from available tools and will be able to interpret the significance of analysis results.  Our proposed online course program, called AHA!, builds on the investigators' extensive experience and ongoing collaboration at Washington State University on the development of smart home and mobile health app design, activity recognition, scalable biological data mining, and the use of these technologies for clinical applications. Our approach will be to design online course modules to train individuals in the analysis of behavior-based sensor data using clinical case studies (Aim 1). We will design an educational program that involves students from diverse backgrounds and that is findable, accessible, interoperable, and reusable (Aim 2). Finally, we will conduct a thorough evaluation to monitor success and incrementally improve the program (Aim 3). All of the materials will be designed for continued use beyond the funding period of the program. PROJECT NARRATIVE  This program focuses on the development and dissemination of online courses that train researchers and practitioners in sensor-based behavioral health. Specifically, we will offer training in responsible conduct, collection and understanding of behavioral sensor data, data exploration and statistical inference, scaling behavioral analysis to massive datasets, and introducing state of the art machine learning and activity learning techniques. The courses will be offered in person to Washington State University faculty and staff, offered with staff support through MOOCs, and available to the general public from our web page. Course material will be enhanced and driven by specific clinical case studies. Additionally, the courses will be supplemented with actual datasets that students can continue to use beyond the course.",Development of an Online Course Suite in Tools for Analysis of Sensor-Based Behavioral Health Data (AHA!),9313495,R25EB024327,"['Address', 'Aging', 'Area', 'Behavior', 'Behavior Therapy', 'Behavioral', 'Big Data', 'Biological', 'Case Study', 'Charge', 'Chronic Disease', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Data', 'Data Set', 'Development', 'Discipline', 'E-learning', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Evaluation', 'FAIR principles', 'Face', 'Faculty', 'Feedback', 'Foundations', 'Funding', 'General Population', 'Goals', 'Health', 'Home environment', 'Human', 'Immersion Investigative Technique', 'Individual', 'Interdisciplinary Study', 'Life Style', 'Link', 'Longevity', 'Machine Learning', 'Methods', 'Monitor', 'Performance', 'Persons', 'Precision Medicine Initiative', 'Pythons', 'Recruitment Activity', 'Rehabilitation Nursing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Site', 'Societies', 'Structure', 'Students', 'Suggestion', 'Techniques', 'Technology', 'Training', 'Universities', 'Washington', 'Work', 'base', 'behavior influence', 'behavioral health', 'biocomputing', 'career networking', 'clinical application', 'cognitive rehabilitation', 'cost', 'course development', 'course module', 'data mining', 'design', 'digital', 'experience', 'health care quality', 'health data', 'improved', 'innovation', 'learning materials', 'learning strategy', 'mHealth', 'next generation', 'online course', 'programs', 'responsible research conduct', 'scale up', 'sensor', 'skills', 'statistics', 'success', 'synergism', 'tool', 'web page']",NIBIB,WASHINGTON STATE UNIVERSITY,R25,2017,186245,0.022407389241209212
"Pilot for Creating Reproducible Workflows Using Docker Containers for NIH Commons DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the world, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research. PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.",Pilot for Creating Reproducible Workflows Using Docker Containers for NIH Commons,9275674,U54GM114838,"['Actinomyces Infections', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Docking', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Intuition', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Privatization', 'Property', 'Regulator Genes', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Work', 'analytical method', 'base', 'big biomedical data', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'community building', 'data mining', 'design', 'drug discovery', 'field study', 'gene interaction', 'genome-wide', 'genome-wide analysis', 'genomic data', 'hackathon', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'online resource', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'webinar', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2017,119777,0.020988399824739448
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the world, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research. PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",9301573,U54GM114838,"['Actinomyces Infections', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Intuition', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Privatization', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transact', 'Universities', 'Work', 'analytical method', 'base', 'big biomedical data', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'community building', 'data mining', 'design', 'drug discovery', 'field study', 'gene interaction', 'genome-wide', 'genome-wide analysis', 'genomic data', 'hackathon', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'online resource', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'webinar', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2017,216422,0.021971764662698356
"All of Us, Wisconsin Our application for OT-PM-16-003, “One in a Million – Precision Medicine Initiative Wisconsin” represents the collaborative efforts of three fully integrated regional healthcare systems to form a virtual state-wide integrated delivery network. The application originates at the Marshfield Clinic Health System (MCHS), one of the most productive and earliest adopters of what has become Precision Medicine. The work of the MCHS has been cited by NIH Director Dr. Francis Collins as a model for the Precision Medicine Initiative (PMI). To ensure comprehensive nearly state-wide coverage of participant health care, MCHS has partnered with the other academic integrated delivery networks in Wisconsin, (University of Wisconsin (UW) and Medical College of Wisconsin (MCW)), that together include 173 clinics, 13 hospitals, insurer partners and 5 Federally Qualified Health Centers (FQHCs). The Blood Center of Wisconsin (BCW) also partners to operate state-wide mobile units of staff and equipment for blood collection that may be purposed for this effort. Through an independent agreement with Aurora Health, the electronic health records of participants recruited by academic and FQHC sites will be made available, ensuring nearly complete coverage of health care records across an entire state, with special emphasis on those populations that are traditionally the most underserved and understudied. The academic sites and FQHC partners have a long history of research cooperation and robust community engagement demonstrated by Clinical and Translational Science Awards (CTSA) ties, the Wisconsin Genome Initiative, reciprocal IRB arrangements, multiple joint grants and other collaborative studies. We have pioneered and implemented data sharing platforms and have demonstrated their usefulness with numerous high impact publications over many years. All three academic centers are leaders in the details of community engagement, recruitment, tracking, return of results and data sharing across various platforms in national and international consortia using large cohorts (e.g., MCHS’s 20,000 participant Personalized Medicine Research Project). A major innovation of this application is that it aligns the major healthcare systems of an entire state to more fully capture each participant’s data wherever participants get their health care. Indeed, 80% of all health care in Wisconsin is captured by our footprint. The State-wide catchment area also includes the oldest, sickest and poorest regions in the US and represent rural and urban areas, including African Americans, Hispanics and Native Americans, all represented as community champions. Through the FQHC partners, the recruiting institutions will achieve the 40% African American, Hispanic and Native American participant rate, with long standing community engagement and history of successful recruitment, including Wisconsin’s 12 Native American Tribes. Lending active support are Community Champions and Community Advisory Boards. A second innovative approach will employ Machine Learning (ML) techniques to optimize recruitment and retention processes. Our scientists have long collaborated on efforts to enhance the breadth and reliability of information extracted from the electronic health record (EHR), using a range of data to identify elements including family pedigrees or the occurrence of clinical events that are susceptible to unreliable coding. These efforts employed state-of-the-art methods including random forests, support vector machines and statistical relational learning, among others. These advanced computational methods will be used to predict those who are most likely to participate and which methods of approach are most effective. A third innovative approach is the planned use of mobile recruitment labs, previously successful with the Survey of the Health of Wisconsin (SHOW). SHOW, began in 2008 provides a novel infrastructure for population health research recruitment, enabling engagement across the state, longitudinal follow-up of participants and community-specific studies. Key assets of SHOW are two mobile units staffed by research and healthcare professionals to facilitate on-site health studies in randomly selected or community-specific participants. SHOW is predicated on community engagement and the response rate has been outstanding (in one study more than 90% of ~4,000 participants consented to follow-up, DNA testing, or blood work). This is true across all racial/ethnic groups, including non-Hispanic Whites, African Americans, Hispanics and Native Americans. The fourth innovative approach is to work with our FQHC partners to recruit traditionally underserved populations. MCHS, UW and MCW will work with FQHC partners (Marshfield Family Health Center, Access Community Health Center, Milwaukee Health Services, Progressive Health Center and 16th Street Community Health Center). Importantly, we are ready to start. We have already informed and engaged our communities through press releases and newsletters. Processes are in place. Volunteers have already asked us to contact them. All the required personnel are trained and SOPs are in place to begin recruitment. We have a productive history of working with partners already funded for PMI cohort recruitment. For several years, we have worked closely (and published) with our colleagues at Northwestern and Columbia through the eMERGE Network and with the University of Pittsburgh through CTSA. Project Director Murray Brilliant has recently served as an advisor to the University of Arizona’s Precision Medicine Program. Thus, we are team-players who are ready, willing and able to be valuable collaborative partners in the effort to build a national engine to transform healthcare under PMI. n/a","All of Us, Wisconsin",9512099,OT2OD025286,"['African American', 'Agreement', 'Arizona', 'Award', 'Blood', 'Catchment Area', 'Clinic', 'Clinical', 'Clinical Sciences', 'Code', 'Collection', 'Communities', 'Community Health Centers', 'Computing Methodologies', 'Consent', 'DNA', 'Data', 'Electronic Health Record', 'Elements', 'Ensure', 'Equipment', 'Ethnic group', 'Event', 'Family', 'Family health status', 'Federally Qualified Health Center', 'Funding', 'Genome', 'Grant', 'Health', 'Health Professional', 'Health Services', 'Health Surveys', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hispanic Americans', 'Hospitals', 'Human Resources', 'Institution', 'Insurance Carriers', 'International', 'Joints', 'Learning', 'Machine Learning', 'Methods', 'Modeling', 'Native Americans', 'Newsletter', 'Not Hispanic or Latino', 'PMI cohort', 'Participant', 'Population', 'Precision Medicine Initiative', 'Press Releases', 'Process', 'Publications', 'Publishing', 'Recording of previous events', 'Records', 'Recruitment Activity', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Scientist', 'Site', 'Techniques', 'Testing', 'Training', 'Translational Research', 'Tribes', 'Underserved Population', 'United States National Institutes of Health', 'Universities', 'Wisconsin', 'Work', 'cohort', 'data sharing', 'follow-up', 'forest', 'genetic pedigree', 'innovation', 'medical schools', 'novel', 'personalized medicine', 'population health', 'precision medicine', 'programs', 'racial and ethnic', 'response', 'rural area', 'urban area', 'virtual', 'volunteer']",OD,MARSHFIELD CLINIC RESEARCH FOUNDATION,OT2,2017,5360833,-0.0009956681369843402
"CSHL Computational and Comparative Genomics Course The Cold Spring Harbor Laboratory proposes to continue a course entitled “Computational and Comparative Genomics”, to be held in the Fall of 2017 – 2019. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases that they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions. NARRATIVE The Computational & Comparative Genomics, a 9 day course, is designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.",CSHL Computational and Comparative Genomics Course,9357752,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'Course Content', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genome', 'Home environment', 'Institution', 'International', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Research Training', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Training Programs', 'Universities', 'Update', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'graduate student', 'instructor', 'interest', 'laboratory experience', 'lecturer', 'programs', 'promoter', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2017,62304,0.0003234322433067134
"Sci-Score, a tool to support rigor and transparency guidelines Project Summary While  standards  in  reporting  of  scientific  methods  are  absolutely  critical  to  producing  reproducible  science,  meeting  such  standards  is  difficult.  Checklists  and  instructions  are  tough  to  follow  often  resulting  in  low  and inconsistent  compliance.  Scientific  journals  and  societies  as  well  as  the  National  Institutes  of  Health  are  now actively proposing general guidelines to address reproducibility issues, particularly in the reporting of methods  (e.g.,  http://www.cell.com/star-­methods),  but  the  trickier  part  will  be  to  train  the  biomedical  community  to  use these standards to effectively improve how scientific methods are communicated. To support new standards in methods reporting, specifically the RRID standard for Rigor and Transparency of  Key Biological Resources, we propose to build Sci-­Score a text mining based tool suite to help authors meet the  standard.  Sci-­Score  will  provide  an  automated  check  on  compliance  with  the  RRID  standard  already  implemented by over 100 journals including Cell, Journal of Neuroscience, and eLife. The innovation behind Sci-­ score is the provision of a score, which can be obtained by individual investigators, which reflects a numerical  validation of the quality of their methods reporting. We posit that the score will serve as a tool that investigators  and journals can use to compete with themselves and each other, or in the very least allow them to see how  close they are to the average in meeting quality requirements.   Recently, our group has developed a text mining algorithm that has now been successfully been used to detect software tools and databases from the SciCrunch Registry in published papers. Digital tools are one of four resource types that the RRID standard identifies. We propose to extend this approach to the other types of entities: antibodies, cell lines and model organisms. Resource identification along with other quality metrics twill be used to train an algorithm to score the overall quality of the methods document. If successful, the tool could be used by editors, reviewers, and investigators to improve the number of RRIDs, therefore the quality of descriptors of key biological resources in published papers. This SBIR project will build a set of algorithms similar to the resource finding pipeline and develop it into an industrial robust and reconfigurable software system. Our Phase I specific aims include to 1) creating gold sets of data for each resource type and training a set of algorithms for each resource type; 2) designing and evaluating the scoring system; 3) designing and evaluating a report generating system based on the previous aims. In Phase II, we will develop a scalable backend infrastructure to serve the needs of scientific publishers and research community. Standards for scientific methods reporting are absolutely critical to producing reproducible science, but meeting  such standards is difficult. Checklists and instructions are tough to follow often resulting in low and inconsistent  compliance. To support new standards in methods reporting, specifically the RRID standard for Rigor and Transparency, we propose to build Sci-Score text mining based tool suite to help authors meet the standard. Sci-Score will provide an automated check on compliance with the RRID standard implemented by over 100 journals including Cell, Journal of Neuroscience, and eLife. Sci-Score will provide a score rating the quality of  methods reporting in submitted articles, which provides feedback to authors, reviewers and editors on how to improvecompliance with RRIDs and other standards. ","Sci-Score, a tool to support rigor and transparency guidelines",9345707,R43OD024432,"['Address', 'Agreement', 'Algorithms', 'Animal Model', 'Antibodies', 'Area', 'Big Data', 'Biological', 'California', 'Cell Line', 'Cell model', 'Cells', 'Communities', 'Data Set', 'Databases', 'Descriptor', 'Elements', 'Ensure', 'Evaluation', 'Feedback', 'Funding', 'Glare', 'Gold', 'Guidelines', 'Habits', 'Human', 'Individual', 'Industrialization', 'Instruction', 'Journals', 'Learning', 'Literature', 'Machine Learning', 'Manuscripts', 'Methods', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Neurosciences', 'Organism', 'Paper', 'Performance', 'Phase', 'Plagiarism', 'Process', 'Publications', 'Publishing', 'Readability', 'Reader', 'Reading', 'Reagent', 'Registries', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Running', 'Sales', 'Science', 'Scoring Method', 'Services', 'Small Business Innovation Research Grant', 'Societies', 'Software Tools', 'System', 'Technology', 'Text', 'To specify', 'Training', 'United States National Institutes of Health', 'Universities', 'Validation', 'Work', 'Writing', 'base', 'biological systems', 'computerized tools', 'design', 'digital', 'improved', 'innovation', 'interest', 'meetings', 'prototype', 'software systems', 'sound', 'text searching', 'tool', 'vigilance', 'web site']",OD,"SCICRUNCH, INC.",R43,2017,221865,-0.014923292902682983
"Heterogeneous and Robust Survival Analysis in Genomic Studies DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed. PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.",Heterogeneous and Robust Survival Analysis in Genomic Studies,9250803,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Methods', 'Modeling', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'experimental study', 'genomic data', 'hazard', 'high dimensionality', 'human genomics', 'improved', 'individual patient', 'loss of function', 'novel', 'patient biomarkers', 'personalized genomic medicine', 'predictive modeling', 'prevent', 'public health relevance', 'response', 'simulation', 'survival outcome', 'theories', 'treatment response', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2017,66026,-0.02459913618902947
"Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II Project Summary Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Clinical performance assessment emphasizes learner evaluation over learner development, lacks rigor and utility for developmental purposes, and clinical teachers have expressed particular difficulty with diagnosing reasoning deficits for remediation purposes. Further, medical students' diagnostic reasoning does not improve over the course of clinical training and senior medical students have highly variable diagnostic performance that is often rated below expectations according to theory-based and validated scoring criteria. Independent practice does not necessarily enhance the context for clinical reasoning; the majority of physicians' medical errors are thought to be diagnostic in nature. We propose to improve undergraduate medical education to minimize the time to clinical competency for first year residents through targeted diagnostic reasoning skill development that (1) integrates basic science and clinical instruction; (2) provides deliberate practice with structured, case-based learning opportunities; and (3) enables anytime/anywhere learning that fits with the demanding schedules of most medical students. Southern Illinois University School of Medicine (SIUSOM) is a recognized leader in using performance-based clinical competency exams to enhance reasoning skill acquisition among medical students. These exams feature clinical scenarios with standardized patients followed by diagnostic justification essays which require students to explicitly describe the thought process used to reach a final diagnosis. These essays are the most reliable method of assessing diagnostic strategies but are not in use in the majority of medical schools, though interest in improving diagnostic reasoning instruction and assessment during undergraduate medical education is widespread. Barriers to the widespread adoption of this approach are 1) the time-consuming need to hand score each essay; and 2) the difficulty in accurately and consistently identifying the causes of strategy failures. This project will develop an application to provide automated scoring of diagnostic justification essays, identification of the underlying causes of failure when students perform poorly, and feedback with instructional strategies for remediation specific to each deficit. We propose these specific aims: 1) Improve reliability of human scoring of DXJ essays. 2) Extend the automated scoring algorithms. 3) Automated reasoning failure categorization and remediation. 4) Complete the software development required for delivering the commercial product. 5) Evaluate predictive validity of automatically scored DXJ essays. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine. Project Narrative Today's clinical learning environments do not provide the level of deliberate practice, direct supervision, and rigorous assessment and feedback needed to develop diagnostic reasoning expertise. Better preparation during undergraduate medical education can shorten the time to competency of first year residents, improving patient outcomes. We propose to develop and test a technology-enabled, deliberate-practice approach to training diagnostic strategy that includes automated scoring of diagnostic justification essays, identification of specific diagnostic strategy failures and targeted remediation. The proposed product represents a significant shift in undergraduate medical training and through Phase III dissemination will address a critical gap between education and practice in academic medicine.","Advanced Assessment to Accelerate Diagnostic Skill Acquisition, Phase II",9339455,R42GM108104,"['Address', 'Adopted', 'Adoption', 'Algorithms', 'Basic Science', 'Caring', 'Case Based Learning', 'Case Study', 'Charge', 'Classification', 'Clinical', 'Clinical Competence', 'Community Health Education', 'Competence', 'Consult', 'Custom', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Education', 'Educational Technology', 'Educational process of instructing', 'Ensure', 'Environment', 'Equation', 'Evaluation', 'Faculty', 'Failure', 'Feedback', 'Future', 'Goals', 'Hand', 'Hospitals', 'Human', 'Illinois', 'Incubators', 'Instruction', 'Leadership', 'Learning', 'Letters', 'Machine Learning', 'Measures', 'Medical', 'Medical Education', 'Medical Errors', 'Medical Students', 'Medicine', 'Methods', 'Modeling', 'Nature', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern Recognition', 'Performance', 'Phase', 'Physicians', 'Preparation', 'Process', 'Recommendation', 'Role', 'Sales', 'Schedule', 'Semantics', 'Standardization', 'Structure', 'Students', 'Suggestion', 'Supervision', 'System', 'Taxonomy', 'Teaching Method', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validity and Reliability', 'Variant', 'base', 'educational atmosphere', 'essays', 'evidence base', 'expectation', 'improved', 'innovation', 'interest', 'medical schools', 'prototype', 'remediation', 'research and development', 'skill acquisition', 'skills', 'software development', 'teacher', 'theories', 'tool', 'undergraduate medical education', 'undergraduate student', 'virtual']",NIGMS,"PARALLEL CONSULTING, LLC",R42,2017,500000,0.0004131722057627061
"Training in lesion-symptom mapping for speech-language research ﻿    DESCRIPTION (provided by applicant): Training in lesion-symptom mapping for speech-language research Abstract: Researchers rely upon the lesion method to evaluate the speech-language status of stroke survivors and draw inferences about underlying brain function. This use of neuropsychology is highly valued in basic speech- language research because it can support causal inferences about brain structure/function relationships. Crucially, advances in analytic techniques and brain image computing are creating a new landscape for neuropsychological research. In this new landscape, the lesion method represents a form of big-data science that requires large sample sizes and complex image computing to implement lesion-symptom mapping (LSM) across the entire brain, without prior regions of interest. Expertise in these new techniques is becoming critical for high impact speech-language research. The career enhancement plan will provide the candidate with training in cutting-edge LSM. The candidate is an established speech-language investigator with a basic program of multidisciplinary research that includes populations with communication disorders due to stroke. The career enhancement will come at an ideal point, because it will build on the candidate's success in establishing an open-access research registry of stroke survivors (the Western Pennsylvania Patient Registry, WPPR), and current work to develop and validate collaborative videoconferencing for remote neuropsychological assessment. These efforts have created the recruitment pool and datasets that are needed for LSM. The career enhancement will provide the training needed to leverage these resources, thereby augmenting the candidate's program of research and career trajectory. The overarching objectives are to: (1) retool the skills of the candidate to infuse LSM into her program of speech-language research, (2) seed data sharing and data science partnerships to boost the candidate's leadership of WPPR as a national resource, and (3) advance understanding of LSM methods and the neural substrates for speech and language to improve the knowledge base of the candidate and other investigators. The candidate proposes a synergistic set of activities. Didactic activities will give training in machie learning and brain image computing, scholarly travel experiences will afford opportunities to network with speech-language researchers and data scientists whose work is relevant for LSM, and two research studies will provide a hands-on opportunity for the candidate to acquire, apply, and extend LSM methods under the guidance of a superb mentoring team. Study 1 will use univariate and multivariate LSM analysis to investigate the neural substrates of chronic Broca's aphasia and the factors that influence the reproducibility of LSM results. Study 2 will develop and evaluate a workflow for automated lesion segmentation, using a software platform (3D Slicer) that involves two NIH-supported data science centers. Overall, the career enhancement will retool the skills, research network, and knowledge base of an established investigator, allowing the candidate to significantly augment her program of speech-language research and advance the utility of WPPR as a national resource for speech-language research. PUBLIC HEALTH RELEVANCE: This use of neuropsychology is highly valued in basic speech-language research because it can support causal inferences about brain structure/function relationships. Crucially, advances in analytic techniques and brain image computing are creating a new landscape for neuropsychological research. This career enhancement will retool the skills, research network, and knowledge base of an established investigator, allowing the candidate to significantly augment her program of speech-language research and advance the utility of a Pittsburgh- based stroke research registry as a national resource.",Training in lesion-symptom mapping for speech-language research,9274245,K18DC014577,"['Adult', 'Aphasia', 'Big Data', 'Brain', 'Brain imaging', 'Broca Aphasia', 'Chronic', 'Collaborations', 'Communication impairment', 'Community Developments', 'Complex', 'Computer software', 'Data Science', 'Data Set', 'Educational workshop', 'Evaluation', 'Gold', 'Image', 'Interdisciplinary Study', 'Knowledge', 'Language', 'Language Disorders', 'Leadership', 'Learning', 'Lesion', 'Machine Learning', 'Manuals', 'Mentors', 'Methods', 'Modernization', 'Network-based', 'Neuropsychology', 'Participant', 'Pennsylvania', 'Population', 'Recruitment Activity', 'Registries', 'Reproducibility', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sample Size', 'Seeds', 'Speech', 'Stroke', 'Structure-Activity Relationship', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Tissues', 'Training', 'Travel', 'United States', 'United States National Institutes of Health', 'Videoconferencing', 'Work', 'base', 'career', 'data sharing', 'design', 'disability', 'experience', 'improved', 'interest', 'knowledge base', 'language processing', 'method development', 'named group', 'novel', 'patient registry', 'programs', 'public health relevance', 'relating to nervous system', 'research and development', 'research study', 'skills', 'speech processing', 'stroke survivor', 'success', 'theories', 'visiting scholar']",NIDCD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K18,2017,171562,-0.04215202261622723
"COINSTAC: decentralized, scalable analysis of loosely coupled data ﻿    DESCRIPTION (provided by applicant):     The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway5,10. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume11, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the dat as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community becomes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group2).    The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates  dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented storage vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and privacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix factorization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities. PUBLIC HEALTH RELEVANCE: Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don't have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this 'missing data' and allow for pooling of both open and 'closed' repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed computational solution for a large toolkit of widely used algorithms.","COINSTAC: decentralized, scalable analysis of loosely coupled data",9268713,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithmic Analysis', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Set', 'Data Sources', 'Decentralization', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Individual', 'Informatics', 'Institution', 'International', 'Knowledge', 'Language', 'Letters', 'Linear Models', 'Location', 'Logistics', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Privatization', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'base', 'commune', 'computer framework', 'computing resources', 'connectome', 'cost', 'data sharing', 'distributed data', 'flexibility', 'imaging genetics', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'open data', 'peer', 'public health relevance', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,THE MIND RESEARCH NETWORK,R01,2017,655080,0.01415621069844561
"Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership ﻿    DESCRIPTION (provided by applicant): The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The aims to achieve the goals are: 1) Implement an integrated didactic program to enhance student self-efficacy with computational and informatics tool development and use for interrogating and interpreting Big Data, including a two-semester bioinformatics course in Bioinformatics, informed by the expertise of UIUC KnowEnG BD2K Center faculty with additional Special Topics courses available remotely from UIUC. 2) Develop an integrated academic year (Fisk, or partners) and summer research program at the UIUC KnowEnG BD2K Center to assure student exposure to a participation in the life cycle of a `Big Data' research problem. 3) Implement a professional skills development program that assures successful transition of undergraduate participants to a Ph.D. (or MD/PhD Program) in Big Data- reliant biomedical research. 4) Launch a faculty development program in bioinformatics that leads to embracing Big Data problems in courses in multiple disciplines for impact on all Fisk undergraduate STEM majors. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fisk R25 mentors, of value for their broader education and research training goals at UIUC and Mayo. PUBLIC HEALTH RELEVANCE: The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fis R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.  ",Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership,9303203,R25MD010396,"['Address', 'Articulation', 'Base Pairing', 'Big Data', 'Big Data to Knowledge', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Career Choice', 'Cellular biology', 'Chemicals', 'Collaborations', 'Communication', 'Complement', 'Computers', 'Core Facility', 'Development Plans', 'Discipline', 'Doctor of Philosophy', 'Education Projects', 'Educational Curriculum', 'Educational workshop', 'Elements', 'Exposure to', 'Faculty', 'Faculty Workshop', 'Fostering', 'Funding', 'Genomics', 'Goals', 'Grant', 'Illinois', 'Informatics', 'Journals', 'Learning', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Manuscripts', 'Mathematics', 'Mentors', 'Molecular Biology', 'Oral', 'Participant', 'Program Development', 'Proteomics', 'Reading', 'Recruitment Activity', 'Research', 'Research Ethics', 'Research Personnel', 'Research Training', 'Role', 'STEM field', 'Science', 'Scientist', 'Self Efficacy', 'Students', 'Systems Biology', 'Teacher Professional Development', 'Technology', 'Time', 'Training', 'Training Programs', 'Training and Education', 'Underrepresented Minority', 'Universities', 'Work', 'Writing', 'base', 'career', 'computer science', 'data acquisition', 'data sharing', 'experience', 'faculty research', 'individualized medicine', 'innovation', 'minority scientist', 'posters', 'programs', 'public health relevance', 'responsible research conduct', 'skill acquisition', 'skills', 'summer research', 'tool', 'tool development', 'undergraduate research', 'undergraduate student']",NIMHD,FISK UNIVERSITY,R25,2017,216000,0.056210408849727125
"LSUHSC-New Orleans Postbaccalaureate Research Education Program in Biomedical Sciences PROJECT SUMMARY/ABSTRACT The overall goal of the Postbaccalaureate Research Education Program (PREP) in Biomedical Sciences (BMS) at the Louisiana State University Health Sciences Center in New Orleans (LSUHSC-NO) is to enhance the diversity of the research workforce by increasing competitiveness for acceptance and completion of PhD and MD/PhD programs by underrepresented minorities (URM). LSUHSC-NO PREP will accept 39 recent URM baccalaureate science graduates over 5 yrs for intensive research and innovative academic training experi- ences to foster success in BMS doctoral degree programs. Over 300 URM science baccalaureates are award- ed annually to URM students by universities located within 100 miles of LSUHSC-NO representing 32% of all science degrees; however, URM constitute only 10% of enrolled PhD and MD/PhD students nationwide, and 12% at LSUHSC-NO. The PREP will enhance competitiveness for acceptance, retention, and completion of BMS PhD programs by the Scholars by providing 1) intensive research experiences with committed research faculty, and 2) complementary skills development during the 1-yr training. PREP training will focus on building solid foundations in research skills by providing concentrated education in scientific critical thinking, analysis of results, statistics, and writing; inventive and personalized test-taking skills to improve GRE scores and success in graduate courses; oral and poster scientific presentations; responsible and ethical conduct in research; and writing a resume, personal statement, and selecting and applying to graduate schools. Scholars will participate in works-in-progress, journal clubs, and workshops hosted by PREP faculty, visitors, and recruitment contacts; join graduate students in skills development programs; present their research at the annual PREP poster sym- posium and local and national scientific conferences; mentor summer research fellows; and assist in communi- ty science education programs. The PREP will provide forums for the Scholars to engage in research and skills acquisition and active demonstration of knowledge. Over 60 LSUHSC-NO active research faculty, committed to the PREP, have extensive experience in mentoring high school, undergraduate, medical, predoctoral, and postdoctoral students representing URM in the BMS through NIH T32, R25, R35, and other funding mecha- nisms. There are 8 active LSUHSC-NO summer programs which provide research experiences to 75 URM fel- lows annually from which future PREP Scholars will be prescreened and recruited. Scholar recruitment efforts will extend to 4 local historically black colleges and 2 state universities to develop a community-wide mecha- nism to support the URM BMS workforce. The program will be critically evaluated using formative and summa- tive methodologies and descriptive, quantitative, and qualitative statistics to document success. The overall goal is for PREP Scholars to have an enhanced competitiveness for acceptance into rigorous graduate pro- grams with the confidence and essential research skills required to earn a PhD or MD/PhD degree, establish rewarding and successful BMS research careers, and serve as role-models for future URM students. PROJECT NARRATIVE The goal of the LSUHSC-NO PREP is to prepare individuals from backgrounds underrepresented in the biomedical sciences, who have recently completed their baccalaureate science degrees, for successful enrollment, retention, and completion of a PhD or MD-PhD training program. We aim to enhance the diversity of the biomedical research workforce by preparing PREP Scholars for the rigors and challenges of a biomedical doctoral degree program so that they will successfully obtain a PhD degree or MD/PhD degree and contribute their expertise to the biomedical scientific community.",LSUHSC-New Orleans Postbaccalaureate Research Education Program in Biomedical Sciences,9208463,R25GM121189,"['Academic Training', 'Anxiety', 'Award', 'Bachelor&apos', 's Degree', 'Basic Science', 'Biomedical Research', 'Centers of Research Excellence', 'Cities', 'Clinical Sciences', 'Communities', 'Critical Thinking', 'Data Analyses', 'Degree program', 'Dentistry', 'Development', 'Development Plans', 'Doctor of Philosophy', 'Doctor&apos', 's Degree', 'Education', 'Educational workshop', 'Enrollment', 'Environment', 'Ethics', 'Exercise', 'Extramural Activities', 'Faculty', 'Fostering', 'Foundations', 'Funding', 'Funding Mechanisms', 'Future', 'Goals', 'Health Sciences', 'Historically Black Colleges and Universities', 'Individual', 'Journals', 'Knowledge', 'Laboratory Research', 'Learning', 'Louisiana', 'Machine Learning', 'Manuscripts', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Minority Enrollment', 'NCI Scholars Program', 'Oral', 'Population', 'Postdoctoral Fellow', 'Program Development', 'Public Health', 'Recruitment Activity', 'Research', 'Research Ethics', 'Research Project Grants', 'Resources', 'Rewards', 'Schools', 'Science', 'Scientist', 'Solid', 'Statistical Methods', 'Structure', 'Students', 'Study Skills', 'Sum', 'Technical Expertise', 'Testing', 'Time Management', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Visit', 'Work', 'Writing', 'career', 'design', 'doctoral student', 'education research', 'experience', 'faculty research', 'graduate student', 'gulf coast', 'high school', 'improved', 'innovation', 'invention', 'medical schools', 'member', 'minority communities', 'novel', 'posters', 'pre-doctoral', 'programs', 'role model', 'science education', 'skill acquisition', 'skills', 'skills training', 'statistics', 'success', 'summer program', 'summer research', 'symposium', 'undergraduate student', 'underrepresented minority student', 'university student']",NIGMS,LSU HEALTH SCIENCES CENTER,R25,2017,255172,0.036005226631489105
"Semantic Data Lake for Biomedical Research Capitalizing on the transformative opportunities afforded by the extremely large and ever-growing volume, velocity, and variety of biomedical data being continuously produced is a major challenge. The development and increasingly widespread adoption of several new technologies, including next generation genetic sequencing, electronic health records and clinical trials systems, and research data warehouses means that we are in the midst of a veritable explosion in data production. This in turn results in the migration of the bottleneck in scientific productivity into data management and interpretation: tools are urgently needed to assist cancer researchers in the assembly, integration, transformation, and analysis of these Big Data sets. In this project, we propose to develop the Semantic Data Lake for Biomedical Research (SDL-BR) system, a cluster-computing software environment that enables rapid data ingestion, multifaceted data modeling, logical and semantic querying and data transformation, and intelligent resource discovery. SDL-BR is based on the idea of a data lake, a distributed store that does not make any assumptions about the structure of incoming data, and that delays modeling decisions until data is to be used. This project adds to the data lake paradigm methods for semantic data modeling, integration, and querying, and for resource discovery based on learned relationships between users and data resources. The SDL-BR System is a distributed computing software solution that enables research institutions to manage, integrate, and make available large institutional data sets to researchers, and that permits users to generate data models specific to particular applications. It uses state of the art cluster computing, Semantic Web, and machine learning technologies to provide for rapid data ingestion, semantic modeling and querying, and search and discovery of data resources through a sophisticated, Web-based user interface.",Semantic Data Lake for Biomedical Research,9443736,R44CA206782,"['Accelerometer', 'Acute', 'Address', 'Adoption', 'Area', 'Big Data', 'Biomedical Computing', 'Biomedical Research', 'Catalogs', 'Chronic Myeloid Leukemia', 'Clinical', 'Clinical Trials', 'Collection', 'Colorectal Cancer', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Discovery', 'Data Quality', 'Data Science', 'Data Set', 'Data Sources', 'Demographic Factors', 'Development', 'Electronic Health Record', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Evaluation', 'Explosion', 'Generations', 'Genetic', 'Genetic Markers', 'High-Throughput Nucleotide Sequencing', 'Income', 'Individual', 'Informatics', 'Ingestion', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Legal', 'Legal patent', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Non-Small-Cell Lung Carcinoma', 'Online Systems', 'Ontology', 'Phase', 'Policies', 'Precision therapeutics', 'Procedures', 'Process', 'Production', 'Productivity', 'Recommendation', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Security', 'Semantics', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Testing', 'Vocabulary', 'Work', 'base', 'cancer therapy', 'clinical data warehouse', 'cluster computing', 'computer based Semantic Analysis', 'cost effective', 'data access', 'data exchange', 'data integration', 'data management', 'data modeling', 'data resource', 'design', 'disease heterogeneity', 'experience', 'genetic information', 'handheld mobile device', 'indexing', 'individualized medicine', 'melanoma', 'migration', 'natural language', 'new technology', 'next generation', 'novel', 'precision medicine', 'prototype', 'success', 'systems research', 'targeted treatment', 'technology development', 'time use', 'tool']",NCI,"INFOTECH SOFT, INC.",R44,2017,50000,-0.013619005250789505
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,9333122,U54EB020405,"['Accelerometer', 'Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Big Data to Knowledge', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Walking', 'Work', 'base', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'health data', 'improved', 'improved outcome', 'industry partner', 'insight', 'massive open online courses', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'online resource', 'prevent', 'programs', 'public health relevance', 'reduce symptoms', 'role model', 'sensor', 'social', 'social model', 'tool', 'visiting scholar']",NIBIB,STANFORD UNIVERSITY,U54,2017,401742,0.011286591842367941
"Semantic Data Lake for Biomedical Research Capitalizing on the transformative opportunities afforded by the extremely large and ever-growing volume, velocity, and variety of biomedical data being continuously produced is a major challenge. The development and increasingly widespread adoption of several new technologies, including next generation genetic sequencing, electronic health records and clinical trials systems, and research data warehouses means that we are in the midst of a veritable explosion in data production. This in turn results in the migration of the bottleneck in scientific productivity into data management and interpretation: tools are urgently needed to assist cancer researchers in the assembly, integration, transformation, and analysis of these Big Data sets. In this project, we propose to develop the Semantic Data Lake for Biomedical Research (SDL-BR) system, a cluster-computing software environment that enables rapid data ingestion, multifaceted data modeling, logical and semantic querying and data transformation, and intelligent resource discovery. SDL-BR is based on the idea of a data lake, a distributed store that does not make any assumptions about the structure of incoming data, and that delays modeling decisions until data is to be used. This project adds to the data lake paradigm methods for semantic data modeling, integration, and querying, and for resource discovery based on learned relationships between users and data resources. The SDL-BR System is a distributed computing software solution that enables research institutions to manage, integrate, and make available large institutional data sets to researchers, and that permits users to generate data models specific to particular applications. It uses state of the art cluster computing, Semantic Web, and machine learning technologies to provide for rapid data ingestion, semantic modeling and querying, and search and discovery of data resources through a sophisticated, Web-based user interface.",Semantic Data Lake for Biomedical Research,9536289,R44CA206782,"['Accelerometer', 'Acute', 'Address', 'Adoption', 'Area', 'Big Data', 'Biomedical Computing', 'Biomedical Research', 'Catalogs', 'Chronic Myeloid Leukemia', 'Clinical', 'Clinical Trials', 'Collection', 'Colorectal Cancer', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Discovery', 'Data Quality', 'Data Science', 'Data Set', 'Data Sources', 'Demographic Factors', 'Development', 'Electronic Health Record', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Evaluation', 'Explosion', 'Generations', 'Genetic', 'Genetic Markers', 'High-Throughput Nucleotide Sequencing', 'Income', 'Individual', 'Informatics', 'Ingestion', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Legal', 'Legal patent', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Non-Small-Cell Lung Carcinoma', 'Online Systems', 'Ontology', 'Phase', 'Policies', 'Precision therapeutics', 'Procedures', 'Process', 'Production', 'Productivity', 'Recommendation', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Security', 'Semantics', 'Services', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Testing', 'Vocabulary', 'Work', 'base', 'cancer therapy', 'clinical data warehouse', 'cluster computing', 'computer based Semantic Analysis', 'cost effective', 'data access', 'data exchange', 'data integration', 'data management', 'data modeling', 'data resource', 'design', 'disease heterogeneity', 'experience', 'genetic information', 'handheld mobile device', 'indexing', 'individualized medicine', 'melanoma', 'migration', 'natural language', 'new technology', 'next generation', 'novel', 'precision medicine', 'prototype', 'success', 'systems research', 'targeted treatment', 'technology development', 'time use', 'tool']",NCI,"INFOTECH SOFT, INC.",R44,2017,589741,-0.013619005250789505
"UTMB Clinical and Translational Science Award UTMB's CTSA-linked KL2 Scholars Program addresses the significant need for developing future clinical and translational (C&T) investigators, with emphases on team-based research, leadership development, and mentorship training. In our new CTSA hub, we will build on our current CTSA's successes over the past 5½ years, with unique innovative integration of exceptional training approaches, including: 1) mentored career development within CTSA-supported multidisciplinary translational teams (MTTs); 2) an emphasis on individual development plans (IDPs) and pre-established C&T research competencies tailored to the needs of the individual scholar, but also emphasizing team-based competencies; 3) development of leadership competencies through participation in a new Leadership Development Academy; 4) an Academy of Research Mentors (ARM), based within our Institute for Translational Sciences (ITS), to foster mentoring and mentor training; 5) a linked Translational Research Scholars Program (TRSP), which provides an expanded peer group and a wider impact across the institution, with twice-monthly career development seminars and a focus on scholars' research; 6) development of entrepreneurial skills and leadership through participation in a UT System-funded Healthcare Entrepreneurship Program; and 7) collaboration and dissemination of program experience to other CTSA hubs in the Texas Regional CTSA Consortium, and the national CTSA Consortium. An important feature of our KL2 Scholars Program is its linked position within the continuum of career development, from graduate student training in our CTSA TL1 Training Core to the production of independently funded C&T faculty members. Our program is enhanced with by financial support from our Provost's office for scholar expenses, ITS education administrators, the ARM, and the Office of Faculty Affairs, which is focused on faculty development at UTMB. UTMB also ranks nationally in promoting diversity, which will enhance our recruitment of underrepresented minority scholars by the participation of faculty from our Hispanic Center of Excellence, and our Medical School Enrichment Program. Our KL2 Program is well-integrated with other institutional education activities, including our Human Pathophysiology and Translational Medicine graduate program, and courses targeted toward scientific writing, biostatistics, and study design. Early-career faculty as Phase 1 TRSP scholars can compete to become CTSA-supported KL2 Scholars, and with acquisition of their first mentored K-level grants (e.g., K08), advance to a Phase 2 TRSP Scholar, then focusing on the transition from mentored to independent grant funding. Upon acquisition of independent (e.g. R01) funding, scholars advance to become Phase 3 TRSP Scholars and Associate Members in the ARM, to facilitate their development of mentoring skills, and eventually to full ARM membership, with demonstrated success in C&T science mentoring. Our KL2 Scholars Program thus integrates novel team-based training, leadership, and mentoring approaches to foster the career development of future leaders in C&T research. n/a",UTMB Clinical and Translational Science Award,9270644,KL2TR001441,"['Academy', 'Address', 'Administrator', 'Award', 'Biological', 'Biological Markers', 'Biometry', 'Biopsy', 'Body Surface Area', 'Burn injury', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Competence', 'Data', 'Dependence', 'Development', 'Development Plans', 'Down-Regulation', 'Education', 'Enrollment', 'Entrepreneurship', 'Evolution', 'Faculty', 'Failure', 'Financial Support', 'Fostering', 'Freezing', 'Functional disorder', 'Funding', 'Future', 'Gene Expression', 'Genes', 'Genetic Transcription', 'Genomics', 'Grant', 'Healthcare', 'Hepatitis C', 'Hispanics', 'Human', 'Individual', 'Infection', 'Inflammation', 'Institutes', 'Institution', 'Interferons', 'Intervention', 'Leadership', 'Link', 'Liver Fibrosis', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Medicare', 'Medicare claim', 'Medicine', 'Mentors', 'Mentorship', 'MicroRNAs', 'Modeling', 'Molecular Profiling', 'NCI Scholars Program', 'Participant', 'Pathway interactions', 'Patients', 'Peer Group', 'Phase', 'Physicians', 'Positioning Attribute', 'Process', 'Production', 'Protocols documentation', 'Recruitment Activity', 'Regimen', 'Research', 'Research Design', 'Rice', 'Structure', 'System', 'TNFSF15 gene', 'Teacher Professional Development', 'Techniques', 'Testing', 'Texas', 'Time', 'Tissues', 'Training', 'Translational Research', 'Underrepresented Minority', 'Variant', 'Writing', 'base', 'career development', 'cohort', 'college', 'demographics', 'early-career faculty', 'experience', 'graduate student', 'innovation', 'leadership development', 'liver biopsy', 'medical schools', 'member', 'microbial', 'multidisciplinary', 'novel', 'outcome forecast', 'peripheral blood', 'predict clinical outcome', 'program dissemination', 'programs', 'response', 'science education', 'skills', 'student training', 'success', 'translational medicine', 'translational scientist']",NCATS,UNIVERSITY OF TEXAS MED BR GALVESTON,KL2,2017,313812,0.029434272522208087
"Center for Environmental Genetics This application requests a 5-year renewal of the Center for Environmental Genetics. The unified theme of  the proposal is to elucidate how gene and environment interaction through epigenetics influences disease  risks and health outcome. Ohioans are exposed to exceptionally bad air quality due to dated power plants  and the fact that it is situated in the nation's main artery of the north-south transportation route. These unique  geographical/economic features put the residents in the state at high risk of the following diseases: (a)  endocrine disruption and cancer; (b) immune and allergic diseases; (c) cardiovascular and lipid disorders;  and (d) neurology and behavior disorders. The CEG has 20-years' of accumulative success in environmental  health sciences (EHS) research, our aspiration is to help mitigate these environmental diseases, first in Ohio,  then extend our success to similar populations in the nation and around the globe. Here we propose to attain  our goal by (1) expanding EHS research human capital through the continued recruitment and support of  investigators of all levels to EHS research, (2) innovative ideas and collaborative work from new and  established investigators will be supported by the Pilot Project Program and Director's Fund, (3) junior  investigators will be mentored by a Career Development Program and strong mentor-mentee relationships;  (4) an Integrative Technology Support Core combined with a Bioinformatics Core will provide investigators  with leading-edge technologies and data analysis to attain a new level of system-biology approach to EHS;  (5) enhancement activities such as workshops, symposia and seminar series will be used to stimulate  collaboration and innovation; (6) an Integrative Health Sciences Facility Core will provide the toolbox for  translation of EHS to the clinical and human studies; and (7) a Community Outreach and Engagement Core  will serve to translate EHS to public health and health education for healthier living and disease prevention.  The center is led by an outstanding team of directors with visionary scientific and administrative experiences  and insights. The team will be assisted by Internal and External Advisory Boards to provide checks and  balances. CEG, through cooperation with other centers will strive to expand EHS capacity and beyond. Our environmental health center focuses on understanding how genes and environment affect our health,  serving the residents, communities of Ohio, the nation and the globe by generating knowledge that is  applicable to the general public and policymakers for healthier living.",Center for Environmental Genetics,9565110,P30ES006096,"['Acute', 'Affect', 'Air', 'Allergic Disease', 'Area', 'Arteries', 'Attention', 'Barker Hypothesis', 'Behavior Disorders', 'Biogenesis', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cells', 'Chronic', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Community Outreach', 'Complex', 'Core Facility', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Dose', 'Economics', 'Educational workshop', 'Endocrine disruption', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Epigenetic Process', 'Equilibrium', 'Equipment', 'Evolution', 'Exposure to', 'Funding', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Health', 'Health Sciences', 'Human', 'Human Genome Project', 'Immune System Diseases', 'Individual', 'Informatics', 'Integrative Medicine', 'Knowledge', 'Lead', 'Life', 'Life Style', 'Link', 'Machine Learning', 'Medicine', 'Mentors', 'Mission', 'Monozygotic twins', 'Nature', 'Neurology', 'Ohio', 'Organ', 'Outcome', 'Phenotype', 'Pilot Projects', 'Population', 'Power Plants', 'Predisposition', 'Program Development', 'Public Health', 'Public Health Education', 'Recruitment Activity', 'Request for Applications', 'Research', 'Research Personnel', 'Route', 'Series', 'Systems Biology', 'Technology', 'Time', 'Translating', 'Translations', 'Transportation', 'Update', 'Vision', 'Work', 'base', 'career development', 'clinical practice', 'disorder prevention', 'disorder risk', 'environmental agent', 'epigenome', 'experience', 'gene environment interaction', 'genome wide association study', 'high risk', 'human capital', 'innovation', 'insight', 'lipid disorder', 'malignant endocrine gland neoplasm', 'member', 'multidisciplinary', 'next generation sequencing', 'programs', 'response', 'success', 'symposium', 'translation to humans']",NIEHS,UNIVERSITY OF CINCINNATI,P30,2017,106418,0.009097293740215435
"Center for Environmental Genetics     DESCRIPTION (provided by applicant)        It is a priority of the CEG and the Career Development Program to identify and develop the careers of promising early stage investigators. To accomplish this goal, the overall objective of the career development program (CDP) is to recruit, enrich, encourage, and provide resources and mentoring activities to investigators at the graduate, postgraduate and early faculty levels with a particular emphasis on environmental health science. The CDP has forged new cross-disciplinary partnerships in areas applicable to environmental health science with basic, epidemiological, and/or clinical studies including studies in molecular genetics and environmental epidemiology and environmental toxicology.  To accomplish the overall objective, the CDP has developed a highly innovative approach with three specific.  Aim 1 is to attract, recruit and promote opportunities for junior faculty (within three years from initial appointment) towards development of an independent career interfacing between basic, translational or clinical investigations with application to environmental health science. The Next Generation Biomedical Investigator (NGBI) program is the principal mechanism for achieving this aim.  Aim 2 is to identify investigators with less experience (novice investigators) who are still in trainin with minimal experience but have an interest in examining the intricate role of environmental health science in health and disease. Recruits include physicians in their academic fellowship i.e. post residency, who are obtaining an MS or Ph.D, mentored postdoctoral Ph.D. fellows or advanced (third or fourth year) pre-doctoral research students. This aim is achieved by supplementing novice investigators' training with research resources, mentoring and career development opportunities through the New Investigator Scholar (NIS) pathway.  Aim 3 is to enrich training/scientific experiences, promote career opportunities and networking experiences, activities integrated with the Administrative and other CEG cores. The objective is to develop NGBIs and NISs and others new to environmental health science by enriching experiences as an investigator and eventually independent scientist. Thus, these aims are achieved through financial awards, mentorship, access to core resources and other career development activities.                  Our environmental health center focuses on understanding how genes and environment affect our health,  serving the residents, communities of Ohio, the nation and the globe by generating knowledge that is  applicable to the general public and policymakers for healthier living.",Center for Environmental Genetics,9253392,P30ES006096,"['Acute', 'Affect', 'Air', 'Allergic Disease', 'Area', 'Arteries', 'Attention', 'Barker Hypothesis', 'Behavior Disorders', 'Biogenesis', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cells', 'Chronic', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Community Outreach', 'Complex', 'Core Facility', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Dose', 'Economics', 'Educational workshop', 'Endocrine disruption', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Epigenetic Process', 'Equilibrium', 'Equipment', 'Evolution', 'Exposure to', 'Funding', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Health', 'Health Sciences', 'Human', 'Human Genome Project', 'Immune System Diseases', 'Individual', 'Informatics', 'Integrative Medicine', 'Knowledge', 'Lead', 'Life', 'Life Style', 'Link', 'Machine Learning', 'Medicine', 'Mentors', 'Mission', 'Monozygotic twins', 'Nature', 'Neurology', 'Ohio', 'Organ', 'Outcome', 'Phenotype', 'Pilot Projects', 'Population', 'Power Plants', 'Predisposition', 'Program Development', 'Public Health', 'Public Health Education', 'Recruitment Activity', 'Request for Applications', 'Research', 'Research Personnel', 'Route', 'Series', 'Systems Biology', 'Technology', 'Time', 'Translating', 'Translations', 'Transportation', 'Update', 'Vision', 'Work', 'base', 'career development', 'clinical practice', 'disorder prevention', 'disorder risk', 'environmental agent', 'epigenome', 'experience', 'gene environment interaction', 'genome wide association study', 'high risk', 'human capital', 'innovation', 'insight', 'lipid disorder', 'malignant endocrine gland neoplasm', 'member', 'multidisciplinary', 'next generation sequencing', 'programs', 'response', 'success', 'symposium', 'translation to humans']",NIEHS,UNIVERSITY OF CINCINNATI,P30,2017,1728654,0.01971467761630971
"Center for Environmental Genetics This application requests a 5-year renewal of the Center for Environmental Genetics. The unified theme of  the proposal is to elucidate how gene and environment interaction through epigenetics influences disease  risks and health outcome. Ohioans are exposed to exceptionally bad air quality due to dated power plants  and the fact that it is situated in the nation's main artery of the north-south transportation route. These unique  geographical/economic features put the residents in the state at high risk of the following diseases: (a)  endocrine disruption and cancer; (b) immune and allergic diseases; (c) cardiovascular and lipid disorders;  and (d) neurology and behavior disorders. The CEG has 20-years' of accumulative success in environmental  health sciences (EHS) research, our aspiration is to help mitigate these environmental diseases, first in Ohio,  then extend our success to similar populations in the nation and around the globe. Here we propose to attain  our goal by (1) expanding EHS research human capital through the continued recruitment and support of  investigators of all levels to EHS research, (2) innovative ideas and collaborative work from new and  established investigators will be supported by the Pilot Project Program and Director's Fund, (3) junior  investigators will be mentored by a Career Development Program and strong mentor-mentee relationships;  (4) an Integrative Technology Support Core combined with a Bioinformatics Core will provide investigators  with leading-edge technologies and data analysis to attain a new level of system-biology approach to EHS;  (5) enhancement activities such as workshops, symposia and seminar series will be used to stimulate  collaboration and innovation; (6) an Integrative Health Sciences Facility Core will provide the toolbox for  translation of EHS to the clinical and human studies; and (7) a Community Outreach and Engagement Core  will serve to translate EHS to public health and health education for healthier living and disease prevention.  The center is led by an outstanding team of directors with visionary scientific and administrative experiences  and insights. The team will be assisted by Internal and External Advisory Boards to provide checks and  balances. CEG, through cooperation with other centers will strive to expand EHS capacity and beyond. Our environmental health center focuses on understanding how genes and environment affect our health,  serving the residents, communities of Ohio, the nation and the globe by generating knowledge that is  applicable to the general public and policymakers for healthier living.",Center for Environmental Genetics,9565118,P30ES006096,"['Acute', 'Affect', 'Air', 'Allergic Disease', 'Area', 'Arteries', 'Attention', 'Barker Hypothesis', 'Behavior Disorders', 'Biogenesis', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cells', 'Chronic', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Community Outreach', 'Complex', 'Core Facility', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Dose', 'Economics', 'Educational workshop', 'Endocrine disruption', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Epigenetic Process', 'Equilibrium', 'Equipment', 'Evolution', 'Exposure to', 'Funding', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Health', 'Health Sciences', 'Human', 'Human Genome Project', 'Immune System Diseases', 'Individual', 'Informatics', 'Integrative Medicine', 'Knowledge', 'Lead', 'Life', 'Life Style', 'Link', 'Machine Learning', 'Medicine', 'Mentors', 'Mission', 'Monozygotic twins', 'Nature', 'Neurology', 'Ohio', 'Organ', 'Outcome', 'Phenotype', 'Pilot Projects', 'Population', 'Power Plants', 'Predisposition', 'Program Development', 'Public Health', 'Public Health Education', 'Recruitment Activity', 'Request for Applications', 'Research', 'Research Personnel', 'Route', 'Series', 'Systems Biology', 'Technology', 'Time', 'Translating', 'Translations', 'Transportation', 'Update', 'Vision', 'Work', 'base', 'career development', 'clinical practice', 'disorder prevention', 'disorder risk', 'environmental agent', 'epigenome', 'experience', 'gene environment interaction', 'genome wide association study', 'high risk', 'human capital', 'innovation', 'insight', 'lipid disorder', 'malignant endocrine gland neoplasm', 'member', 'multidisciplinary', 'next generation sequencing', 'programs', 'response', 'success', 'symposium', 'translation to humans']",NIEHS,UNIVERSITY OF CINCINNATI,P30,2017,52102,0.009097293740215435
"Center for Environmental Genetics This application requests a 5-year renewal of the Center for Environmental Genetics. The unified theme of  the proposal is to elucidate how gene and environment interaction through epigenetics influences disease  risks and health outcome. Ohioans are exposed to exceptionally bad air quality due to dated power plants  and the fact that it is situated in the nation's main artery of the north-south transportation route. These unique  geographical/economic features put the residents in the state at high risk of the following diseases: (a)  endocrine disruption and cancer; (b) immune and allergic diseases; (c) cardiovascular and lipid disorders;  and (d) neurology and behavior disorders. The CEG has 20-years' of accumulative success in environmental  health sciences (EHS) research, our aspiration is to help mitigate these environmental diseases, first in Ohio,  then extend our success to similar populations in the nation and around the globe. Here we propose to attain  our goal by (1) expanding EHS research human capital through the continued recruitment and support of  investigators of all levels to EHS research, (2) innovative ideas and collaborative work from new and  established investigators will be supported by the Pilot Project Program and Director's Fund, (3) junior  investigators will be mentored by a Career Development Program and strong mentor-mentee relationships;  (4) an Integrative Technology Support Core combined with a Bioinformatics Core will provide investigators  with leading-edge technologies and data analysis to attain a new level of system-biology approach to EHS;  (5) enhancement activities such as workshops, symposia and seminar series will be used to stimulate  collaboration and innovation; (6) an Integrative Health Sciences Facility Core will provide the toolbox for  translation of EHS to the clinical and human studies; and (7) a Community Outreach and Engagement Core  will serve to translate EHS to public health and health education for healthier living and disease prevention.  The center is led by an outstanding team of directors with visionary scientific and administrative experiences  and insights. The team will be assisted by Internal and External Advisory Boards to provide checks and  balances. CEG, through cooperation with other centers will strive to expand EHS capacity and beyond. Our environmental health center focuses on understanding how genes and environment affect our health,  serving the residents, communities of Ohio, the nation and the globe by generating knowledge that is  applicable to the general public and policymakers for healthier living.",Center for Environmental Genetics,9565126,P30ES006096,"['Acute', 'Affect', 'Air', 'Allergic Disease', 'Area', 'Arteries', 'Attention', 'Barker Hypothesis', 'Behavior Disorders', 'Biogenesis', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cells', 'Chronic', 'Clinical Data', 'Clinical Research', 'Collaborations', 'Communities', 'Community Outreach', 'Complex', 'Core Facility', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Dose', 'Economics', 'Educational workshop', 'Endocrine disruption', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Epigenetic Process', 'Equilibrium', 'Equipment', 'Evolution', 'Exposure to', 'Funding', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Geography', 'Goals', 'Health', 'Health Sciences', 'Human', 'Human Genome Project', 'Immune System Diseases', 'Individual', 'Informatics', 'Integrative Medicine', 'Knowledge', 'Lead', 'Life', 'Life Style', 'Link', 'Machine Learning', 'Medicine', 'Mentors', 'Mission', 'Monozygotic twins', 'Nature', 'Neurology', 'Ohio', 'Organ', 'Outcome', 'Phenotype', 'Pilot Projects', 'Population', 'Power Plants', 'Predisposition', 'Program Development', 'Public Health', 'Public Health Education', 'Recruitment Activity', 'Request for Applications', 'Research', 'Research Personnel', 'Route', 'Series', 'Systems Biology', 'Technology', 'Time', 'Translating', 'Translations', 'Transportation', 'Update', 'Vision', 'Work', 'base', 'career development', 'clinical practice', 'disorder prevention', 'disorder risk', 'environmental agent', 'epigenome', 'experience', 'gene environment interaction', 'genome wide association study', 'high risk', 'human capital', 'innovation', 'insight', 'lipid disorder', 'malignant endocrine gland neoplasm', 'member', 'multidisciplinary', 'next generation sequencing', 'programs', 'response', 'success', 'symposium', 'translation to humans']",NIEHS,UNIVERSITY OF CINCINNATI,P30,2017,39875,0.009097293740215435
"Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome Addiction is a highly complex disease with risk factors that include genetic variants and differences in development, sex, and environment. The long term potential of precision medicine to improve drug treatment and prevention depends on gaining a much better understanding how genetics, drugs, brain cells, and neuronal circuitry interact to influence behavior. There are serious technical barriers that prevent researchers and clinicians from incorporating more powerful computational and predictive methods in addiction research. The purpose of the NIDA P30 Core Center of Excellence in Omics, Systems Genetics, and the Addictome is to empower and train researchers supported by NIH, NIDA, NIAAA, and other federal and state institutions to use more quantitative and testable ways to analyze genetic, epigenetic, and the environmental factors that influence drug abuse risk and treatment. In the Transcriptome Informatics and Mechanisms research core we assemble and upgrade hundreds of large genome (DNA) and transcriptome (RNA) datasets for experimental rodent (rat) models of addiction. In the Systems Analytics and Modeling research core, we are using innovative systems genetics methods (gene mapping) to understand the linkage between DNA differences, environmental risks such as stress, and the differential risk of drug abuse and relapse. Our Pilot core is catalyzing new collaborations among young investigator in the field of addiction research. In sum the Center is a national resource for more reproducible research in addiction. We are centralizing, archiving, distributing, analyzing and integrating high quality data, metadata, using open software systems in collaboration with many other teams of researchers. Our goal is to help build toward an NIDA Addictome Portal that will include all genomic research relevant to addiction research. PROJECT NARRATIVE The NIDA Core Center of Excellence in Omics, Systems Genetics, and the Addictome (OSGA) provides genomic and computational support to a large number of research scientists working on mechanisms and treatment of addiction. The two main research cores of OSGA are providing support for transcriptome, epigenome, and metagenome studies of rat models of addiction at many levels of analysis. We are also creating open access tools and a powerful web portal to catalyze more effective and replicable use of massive datasets generated by programs in addiction biology and treatment.","Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome",9360448,P30DA044223,"['Archives', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Bioinformatics', 'Biological Assay', 'Biology', 'Biometry', 'Cells', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consult', 'DNA', 'DNA Sequence', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Interactions', 'Drug abuse', 'Educational workshop', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Epigenetic Process', 'Foundations', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Hybrids', 'Image', 'Imagery', 'Informatics', 'Institution', 'Joints', 'Leadership', 'Learning', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences Research', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Prevention', 'Proteome', 'Publications', 'Publishing', 'Quantitative Genetics', 'Quantitative Trait Loci', 'RNA', 'Rattus', 'Relapse', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Rodent', 'Role', 'Scientist', 'Site', 'Standardization', 'Statistical Models', 'Stress', 'Sum', 'System', 'Systems Analysis', 'Testing', 'Training', 'Translations', 'United States National Institutes of Health', 'Update', 'Variant', 'Work', 'addiction', 'base', 'behavior influence', 'brain cell', 'career', 'cohort', 'computerized tools', 'computing resources', 'data archive', 'data integration', 'data modeling', 'digital imaging', 'drug relapse', 'epigenome', 'experience', 'genetic analysis', 'genetic variant', 'genomic variation', 'graphical user interface', 'health record', 'high dimensionality', 'improved', 'innovation', 'insight', 'metagenome', 'mouse model', 'neuronal circuitry', 'novel', 'precision medicine', 'prevent', 'programs', 'ranpirnase', 'rat genome', 'repository', 'sex', 'single cell analysis', 'software systems', 'tool', 'transcriptome', 'transcriptomics', 'web portal']",NIDA,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,P30,2017,906404,-0.006378251379133539
"Multimodal Biomarkers in Frontotemporal Lobar Degeneration DESCRIPTION (provided by applicant): This K01 award will support my development as an independent investigator with a translational research program that specializes in the cognitive and biological basis of neurodegenerative diseases such as frontotemporal lobar degeneration (FTLD). Candidate: My research experience as a cognitive neuroscientist ideally positions me to achieve my career goal of becoming an independent investigator with expertise on the cognitive and biological basis of neurodegenerative disease. I have strong cognitive training with an M.Sc in Psycholinguistics and Ph.D in Psychology from the University of Edinburgh, where I was supported by an NRSA Individual Predoctoral Award. During my postdoctoral IGERT fellowship at the Institute for Research in Cognitive Science at the University of Pennsylvania, I was awarded an NRSA Individual Postdoctoral Fellowship Award to investigate the role of decision-making in language. In this research I have gained experience investigating neurodegenerative disease patients comparatively in order to obtain converging evidence to complement fMRI studies of healthy adults. I have become increasingly interested in translating my research to optimize the diagnosis and treatment of patients with neurodegenerative diseases. I was recently award the Society for the Neurobiology of Language Postdoctoral Merit Award in recognition of my novel research investigating how social limitations in patients contribute to difficulty in discourse. I have committed to four years of clinical research the NIH Loan Repayment Program, and I intend to commit to clinical research for the duration of my career. I have learned that cognitive and neuroimaging studies provide only one perspective on neurodegenerative diseases. In this proposal, I plan to gain the necessary expertise in biological aspects of FTLD and related conditions to complement my past experiences, and thus achieve my goal of becoming a multifaceted independent investigator with expertise in the cognitive and biological basis for neurodegenerative diseases. With the support of this K01, I will develop expertise to conduct investigations of cerebrospinal fluid (CSF), genetic, and neuropathological aspects of neurodegenerative diseases. I will ultimately integrate the biological expertise gained in this proposal with language studies from my cognitive neuroscience research in an effort to identify non-invasive biomarkers that can be used to screen patients for clinical trials and to measure the efficacy of disease-modifying agents. Environment: This award will be conducted at the Perelman School of Medicine at the University of Pennsylvania in the Department of Neurology, the Center for Neurodegenerative Disease Research (CNDR), and the Penn Bioinformatics Center where I have strong institutional support. The proposed institution is an exceptional environment that has expert centers for neuroimaging, cerebrospinal fluid biomarker analysis, a leading genetic research core, expert neuropathology, outstanding biostatisical support, and relevant clinical research laboratories. The University of Pennsylvania is unique in comparison to other institutions in the country because all of the above methods are available in one center. My mentor, Dr. Murray Grossman, and my co-mentor, Dr. John Trojanowksi, have international reputations for neurodegenerative disease research. My career development will also be supported by my co-mentor, Dr. Lyle Ungar, who has extensive expertise in statistical learning algorithms and in the analysis of proteomic and genomics datasets. Together, this mentorship team will facilitate my development as an independent investigator by providing access to existing and future collaborators, laboratory resources, and exceptional training environments. The CNDR is a world- leading center for neurodegenerative disease research with human and animal models of disease and exceptional translational science. Biofluid biomarker experience is extensive, and several national biofluid cores are centered at Penn (e.g. ADNI). There is a wealth of internationally-recognized neuroimaging expertise at the University of Pennsylvania in the Penn Imaging and Computer Science Laboratory, and I will benefit by integrating neuroimaging resources from these facilities with other modalities of biomarker research. Training: I will develop my expertise in the biological basis of neurodegenerative disease with the support of my mentor, Dr. Murray Grossman, and my co-mentors, Dr. John Trojanowski and Dr. Lyle Ungar. Specifically, with Dr. Trojanowksi I will engage in training related to biofluid and genetic biomarkers of FTLD. I will develop advanced neuroimaging skills and cutting-edge biostatistical methods with Dr. Ungar. Each of these training modalities will be supported by complementary formal coursework, participation in seminars, attendance of conferences, and regularly scheduled meetings with mentorship team. Research: FTLD is a neurodegenerative disease affecting approximately 15 out of 100,000 individuals. In recent years detailed neuropathological investigations at autopsy have demonstrated distinct sources of histopathological abnormalities in FTLD, including the presence of tau inclusions (FTLD-tau) and TDP-43 proteinopathies (FTLD-TDP). However, there are currently no in vivo methods for discriminating between FTLD-tau and FTLD-TDP. There is an urgent need to improve the in vivo diagnosis of FTLD to appropriately enter patients into emerging clinical trials, and to develop sensitive and specific endpoints in trials that can quantify response to these treatments. The overall research aim of this proposal is to develop multimodal methods to improve in vivo diagnosis of FTLD. PUBLIC HEALTH RELEVANCE: Frontotemporal lobar degeneration (FTLD) affects approximately 15 out of 100,000 adults. Detailed neuropathological investigations at autopsy have identified two distinct sources of histopathological changes that contribute to FTLD. However, there are currently no in vivo methods for diagnosing pathological subtypes of FTLD. There is an urgent need to identify in vivo diagnosis methods to facilitate the identification of appropriate patients to enter into emerging disease-modifying drug treatment trials. The overall aim of this project is to identify multimodal biomarkers of FTLD.",Multimodal Biomarkers in Frontotemporal Lobar Degeneration,9279038,K01AG043503,"['Address', 'Adult', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animal Disease Models', 'Animal Model', 'Area', 'Atrophic', 'Autopsy', 'Award', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biostatistical Methods', 'Cerebrospinal Fluid', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Cognitive', 'Cognitive Science', 'Comparative Study', 'Complement', 'Country', 'DNA Sequence Alteration', 'DNA-Binding Proteins', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Fellowship', 'Follow-Up Studies', 'Foundations', 'Frontotemporal Lobar Degenerations', 'Functional Magnetic Resonance Imaging', 'Future', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genomics', 'Goals', 'Gold', 'Human', 'Image', 'Individual', 'Institution', 'International', 'Investigation', 'Laboratories', 'Laboratory Research', 'Language', 'Machine Learning', 'Measures', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Microscopic', 'Modality', 'National Research Service Awards', 'Nerve Degeneration', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurology', 'Neurosciences Research', 'Pathologic', 'Pathology', 'Patient Monitoring', 'Patients', 'Pennsylvania', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Positioning Attribute', 'Primary Progressive Aphasia', 'Process', 'Proteomics', 'Proxy', 'Psycholinguistics', 'Psychology', 'Rare Diseases', 'Research', 'Research Institute', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Scientist', 'Semantics', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Societies', 'Source', 'Statistical Data Interpretation', 'Training', 'Transact', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Work', 'accurate diagnosis', 'behavioral variant frontotemporal dementia', 'candidate marker', 'career', 'career development', 'clinical phenotype', 'clinically relevant', 'cognitive neuroscience', 'cognitive training', 'cohort', 'comparative', 'computer science', 'diagnostic accuracy', 'experience', 'genome wide association study', 'gray matter', 'imaging study', 'improved', 'in vivo', 'individual patient', 'interest', 'longitudinal course', 'magnetic resonance imaging biomarker', 'medical schools', 'meetings', 'multimodality', 'neuroimaging', 'neuropathology', 'novel', 'pre-doctoral', 'prediction algorithm', 'programs', 'prospective', 'public health relevance', 'response', 'screening', 'skills', 'social', 'symposium', 'tau Proteins', 'tool', 'translational research program', 'treatment response', 'treatment trial', 'white matter']",NIA,UNIVERSITY OF PENNSYLVANIA,K01,2017,128358,-0.0025158587217945774
"Augmented Reality System for the Education of Clinical Caregivers of Older Adults Project Summary/Abstract The value of mannequin-based simulation is well recognized and is incorporated extensively into medical education. In general, their primary purpose is to simulate a physical ""patient"" on which to learn, demonstrate, and test skill without fear of harming patients prior to entering clinical environments. Despite their substantial benefits, they have several fundamental limitations. Proposed is a system to combine and leverage the advantages of both existing physical mannequin-based training and virtual media to support clinical learning using Augmented Reality (AR). This Phase I project will focus on creating and evaluating a proof of concept system. An engaging, interactive training course using the prototype system will be developed as a case study for clinical nursing training on pressure injuries – an oftentimes preventable injury that is attributed to tremendous human suffering and represents a significant cost burden on our health care system. The course will leverage existing mannequin-based training used at the UMN and be evaluated by both instructors and students at the School of Nursing. Project Narrative Over the past decade, medical simulation has been experiencing explosive growth and widespread adoption. There are now over 800 medical simulation centers in the US alone, located in medical schools, nursing schools, hospitals, military simulation centers, and schools of allied health professions. The global market for Mannequin-Based Simulation is projected to reach $1 Billion by 2020. It is hypothesized that the combination of existing physical mannequin-based training with virtual media will opens new possibilities for exploration and enhanced learning interactions for medical education.",Augmented Reality System for the Education of Clinical Caregivers of Older Adults,9409513,R43AG057257,"['Adoption', 'Algorithmic Software', 'Allied Health Profession', 'Anatomy', 'Augmented Reality', 'Caregivers', 'Case Study', 'Clinical', 'Clinical Nursing', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Development', 'Devices', 'Disease Progression', 'Dissection', 'Education', 'Educational Curriculum', 'Elderly', 'Environment', 'Fright', 'Growth', 'Healthcare Systems', 'Hospitals', 'Human', 'Hybrids', 'Image', 'Injury', 'Intervention', 'Lead', 'Learning', 'Location', 'Manikins', 'Medical', 'Medical Education', 'Military Personnel', 'Minnesota', 'Modeling', 'Movement', 'Nursing Schools', 'Patients', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Sampling', 'School Nursing', 'Schools', 'Scientist', 'Severity of illness', 'Skin', 'Small Business Innovation Research Grant', 'Structure', 'Students', 'Support Groups', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'Vision', 'Visual', 'animation', 'base', 'caregiver education', 'cost', 'design', 'experience', 'flexibility', 'human study', 'innovation', 'instructor', 'medical schools', 'pressure', 'professor', 'prototype', 'simulation', 'skills', 'teacher', 'virtual', 'virtual reality']",NIA,"INNOVATIVE DESIGN LABS, INC.",R43,2017,224952,-0.014313998283661923
"2018 International Conference on Health Policy Statistics International Conference on Health Policy Statistics (ICHPS) 2018  Specific Aims  The 12th International Conference on Health Policy Statistics (ICHPS), under the timely theme, “Health <-> Statistical Science <-> Care, Policy, Outcomes”, focuses on the interactive relationship between health services research and innovative statistical methodology. It falls within the category of “Research Design and Methodology” in the AHRQ program announcement. The primary sponsor is the Section on Health Policy Statistics of the American Statistical Association (ASA). The 12th ICHPS will be held January 10 to 12, 2018 in Charleston, South Carolina. Details for the last ICHPS conducted in 2015 attended by 246 participants, are available online at: http://www.amstat.org/meetings/ichps/2015/index.cfm.  The overarching aim of ICHPS is to create an educational and research forum for statisticians, econometricians, and other research methodologists working on cutting-edge and innovative approaches to exchange and to build upon ideas, and to foster the tradition of linking methodologists with policymakers and other stakeholders in the health services research and health policy arenas to add focus and perspective to the development of new methodological tools. Additional aims of ICHPS 2018 are to increase participation by students and junior investigators, as well as to increase local engagement.  The technical program for the upcoming ICHPS will examine a broad range of topics that fit very well with the goals of the Agency for Healthcare Research and Quality (AHRQ), consistent with previous ICHPS conferences supported by AHRQ. The invited sessions will be useful to promote improvements in the quality, safety, efficiency, and effectiveness of health care by developing, debating and disseminating state-of-the-art research methods. In line with ASA's increasing efforts to engage policy-makers and other stakeholders in health policy, ICHPS 2018 will focus on data-centric statistical methodology related to health services research, and health policy issues of national and international importance.  The invited program includes invited sessions, workshops, contributed talks and posters, in addition to a keynote and a plenary speaker. The confirmed keynote speaker is national expert Dr. Robert Califf, Professor of Medicine at Duke University and former Commissioner of the Food and Drug Administration. The confirmed plenary speaker is Dr. Suchi Saria, Assistant Professor, Department of Computer Science, Johns Hopkins University, a machine learning expert working on the use of data-driven technology to improve healthcare. Sessions will cover key methodological areas including: causal inference, health disparities research, propensity scores, analysis of complex survey data, heterogeneous treatment effects and individualized treatments, longitudinal modeling, meta-analysis and evidence synthesis, novel trial designs, real-world data, and patient-reported outcomes. Most importantly, the ICHPS program is focused on addressing key health care policy research priorities. Applied topics that have been focal points at recent ICHPS meetings on comparative effectiveness research include examining evidence-based care, patient-reported outcomes analyses, and personalized medicine.  The program will also include roundtable discussions to provide research training and career development for new and current health policy and health services researchers in methods, resources and applications at the forefront of health policy research. Plans for dissemination include pursuing a special issue in Springer's, Health Services and Outcomes Research Methodology for conference proceedings, as was done for 2015 ICHPS (http://link.springer.com/article/10.1007/s10742-016-0165-5). In addition, we will publish articles on emerging topics and themes, and interviews with award winners in magazines and social media. The 13th International Conference on Health Policy Statistics (ICHPS), under the broad and timely theme, “Health <-> Statistical Science <-> Care, Policy, Outcomes,” is a scientific conference that focuses on the interplay between health services research and statistical methodology. Its specific aim is to create an educational and research forum for statisticians, econometricians, psychometricians, and other experts in research methodology to exchange and build upon ideas, discuss research needs, and develop solutions to methodological challenges.",2018 International Conference on Health Policy Statistics,9479456,R13HS025884,[' '],AHRQ,AMERICAN STATISTICAL ASSOCIATION,R13,2017,30000,-0.0035802489006244572
"Training a new generation of computational neuroscientists bridging neurobiology The  Training  Program  in  Computational  Neuroscience  (TPCN)  will  support  integrated   undergraduate  and graduate training in computational neuroscience at New York University. The program will be hosted  by the Center for Neural Science (CNS), with participation of faculty in the Departments of  Psychology, Mathematics, and Computer Science, and the Institute of Neuroscience at the School of  Medicine. The TPCN will fit well with NYU’s unique strengths and recent developments: (1) NYU is  one of a few universities with a critical mass of computational neuroscientists. NYU has had a  Sloan-Swartz Center for Theoretical Neuroscience since 1994. In the past three years alone, NYU has  hired three computational neuroscientists. (2) CNS  established an undergraduate major in  neuroscience as early as 1992, and thus has a long track record in undergraduate education, it now  has 136 students in the current academic year. (3) Recent faculty hiring in CNS, Psychology, and  the School of Medicine has greatly expanded our teaching and research capabilities in the  neuroscience of cognitive functions and their impairments associated with mental disorders. (3) As  NYU is undertaking a merge of two historically separated neuroscience graduate programs (at CNS   and  the  School  of  Medicine),  this training grant will ensure that computational modeling,  which has become indispensible in neuroscience, will be front-and-center in the integrated graduate  program. (4) NYU is a major center of Artificial Intelligence and Data Science, with close links to  Facebook’s AI Center and the Simons Center for Data Analysis. Our training faculty together with  these connections will give our students ample opportunities to acquire machine learning techniques  for data analysis and learn about brain-like AI algorithms. The proposed  training  program will support coherent undergraduate  and  graduate  training  in   computational neuroscience at NYU. It will have several unique features: (1) Innovative mentorship  methods: For example, (a) graduate trainees will mentor undergraduate trainees, (b) faculty will explicitly discuss human  factors in academic practice; (c) there will be post-mortems after seminars by outside speakers.  (2) Computational psychiatry: We propose new courses and research opportunities that are designed  specifically to link cognitive function and the neurobiology of neural circuits. We propose  innovative education in the nascent field of Computational Psychiatry, to bring theory and circuit  modeling to clinical research in mental health. (3) Broad preparation: We aim to prepare trainees  for jobs not only in academia, but  also  in  medical  and  industry research. To achieve this, we  will utilize our strength in machine learning and data science to broaden computational  neuroscience training. The Program Directors have complementary strengths and will have  complementary roles in the program. Wang will supervise graduate trainees and focus on training in  mechanistic/circuit-level side of computational neuroscience as well as computational psychiatry.  Ma will supervise undergraduate trainees and focus on the computational/behavioral side. This grant will support training of a new generation of graduate and undergraduate students in  computational neuroscience, which has become increasingly important to meet the challenges of  making discoveries with new data analysis tools and of understanding highly nonlinear complex  neural circuits. A salient component of our program is training in the nascent field  of   Computational  Psychiatry,  bridging  basic  neuroscience  and clinical research on mental  disorders. Therefore, the proposed program has the potential of making  a significant impact on  mental health.",Training a new generation of computational neuroscientists bridging neurobiology,9316750,R90DA043849,"['Academia', 'Algorithms', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Clinical Research', 'Computer Simulation', 'Data Analyses', 'Data Science', 'Development', 'Education', 'Educational process of instructing', 'Ensure', 'Faculty', 'Generations', 'Grant', 'Human', 'Impairment', 'Industry', 'Institutes', 'Learning', 'Link', 'Machine Learning', 'Mathematics', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurosciences', 'New York', 'Occupations', 'Preparation', 'Psychiatry', 'Psychology', 'Research', 'Role', 'Science', 'Side', 'Students', 'Teacher Professional Development', 'Techniques', 'Training', 'Training Programs', 'Universities', 'cognitive function', 'computational neuroscience', 'computer science', 'design', 'innovation', 'medical schools', 'neural circuit', 'programs', 'relating to nervous system', 'theories', 'undergraduate education']",NIDA,NEW YORK UNIVERSITY,R90,2016,204981,0.03594438421696144
"Administrative Supplement Request for Transforming Analytical Learning in the Era of Big Data ﻿    DESCRIPTION (provided by applicant): In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio) statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offer and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will draw from the expertise and experience of faculty from four different departments within four different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts, and Information Science in the School of Information. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high-dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and imaging. The diseases and conditions they study include obesity, cancer, diabetes, cardiovascular disease, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and response for our pilot offering in 2015 with 153 applications for 20 positions and a yield rate of 80% from the offers we extended. We plan to build on the success of this initial offering in the next three year funding cycle of this grant (2016-2018). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a no-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 30 undergraduates nationally and expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world. PUBLIC HEALTH RELEVANCE: We propose a six week long summer institute: ""Transforming Analytical Learning in the Era of Big Data"" to be held at the Department of Biostatistics, University of Michigan, Ann Arbor, with a group of approximately 30 undergraduates recruited nationally, from 2016-2018. We plan to expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Statistics, Computer Science and Engineering, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm.",Administrative Supplement Request for Transforming Analytical Learning in the Era of Big Data,9243811,R25EB022363,"['Administrative Supplement', 'Adverse drug effect', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Behavioral Sciences', 'Big Data', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Case Study', 'Code', 'Collection', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Engineering', 'Epigenetic Process', 'Faculty', 'Funding', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Health', 'Image', 'Imagery', 'Information Sciences', 'Injury', 'Kidney Diseases', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Positioning Attribute', 'Prevention', 'Problem Sets', 'Public Health Informatics', 'Public Health Schools', 'Recruitment Activity', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Statistical Methods', 'Students', 'Talents', 'Techniques', 'Training', 'Universities', 'Work', 'base', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'design', 'experience', 'instructor', 'interest', 'lectures', 'meetings', 'member', 'metabolomics', 'nervous system disorder', 'next generation', 'novel therapeutics', 'open source', 'personalized medicine', 'posters', 'programs', 'response', 'signal processing', 'skills', 'statistics', 'success', 'summer institute', 'symposium', 'tool', 'undergraduate student', 'wiki']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2016,159359,0.05148517713393987
"Transforming Analytical Learning in the Era of Big Data ﻿    DESCRIPTION (provided by applicant): In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio) statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offer and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will draw from the expertise and experience of faculty from four different departments within four different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts, and Information Science in the School of Information. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high-dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and imaging. The diseases and conditions they study include obesity, cancer, diabetes, cardiovascular disease, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and response for our pilot offering in 2015 with 153 applications for 20 positions and a yield rate of 80% from the offers we extended. We plan to build on the success of this initial offering in the next three year funding cycle of this grant (2016-2018). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a no-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 30 undergraduates nationally and expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world. PUBLIC HEALTH RELEVANCE: We propose a six week long summer institute: ""Transforming Analytical Learning in the Era of Big Data"" to be held at the Department of Biostatistics, University of Michigan, Ann Arbor, with a group of approximately 30 undergraduates recruited nationally, from 2016-2018. We plan to expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Statistics, Computer Science and Engineering, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm.",Transforming Analytical Learning in the Era of Big Data,9149238,R25EB022363,"['Adverse drug effect', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Behavioral Sciences', 'Big Data', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Case Study', 'Code', 'Collection', 'Computing Methodologies', 'Data', 'Data Science', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Engineering', 'Epigenetic Process', 'Faculty', 'Funding', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Health', 'Image', 'Imagery', 'Information Sciences', 'Injury', 'Kidney Diseases', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Positioning Attribute', 'Prevention', 'Problem Sets', 'Public Health Informatics', 'Public Health Schools', 'Recruitment Activity', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Statistical Methods', 'Students', 'Talents', 'Techniques', 'Training', 'Universities', 'Work', 'base', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'design', 'experience', 'instructor', 'interest', 'lectures', 'meetings', 'member', 'metabolomics', 'nervous system disorder', 'next generation', 'novel therapeutics', 'open source', 'personalized medicine', 'posters', 'programs', 'response', 'signal processing', 'skills', 'statistics', 'success', 'summer institute', 'symposium', 'tool', 'undergraduate student', 'wiki']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2016,160479,0.051481843489061756
"Analytical Approaches to Massive Data Computation with Applications to Genomics DESCRIPTION (provided by applicant): We propose to design and test mathematically well founded algorithmic and statistical tectonics for analyzing large scale, heterogeneous and noisy data. We focus on fully analytical evaluation of algorithms' performance and rigorous statistical guarantees on the analysis results. This project will leverage on the PIs' recent work on cancer genomics data analysis and rigorous data mining techniques. Those works were driven by specific applications, while in the current project we aim at developing general principles and techniques that will apply to a broad sets of applications. The proposed research is transformative in its emphasis on rigorous analytical evaluation of algorithms' performance and statistical measures of output uncertainty, in contrast to the primarily heuristic approaches currently used in data ming and machine learning. While we cannot expect full mathematical analysis of all data mining and machine learning techniques, any progress in that direction will have significant contribution to the reliability and scientific impact of this discipline. While ou work is motivated by molecular biology data, we expect the techniques to be useful for other scientific communities with massive multi-variate data analysis challenges. Molecular biology provides an excellent source of data for testing advance data analysis techniques: specifically, DNA/RNA sequence data repositories are growing at a super-exponential rate. The data is typically large and noisy, and it includes both genotype and phenotype features that permit experimental validation of the analysis. One such data repository is The Cancer Genome Atlas (TCGA), which we will use for initial testing of the proposed approaches. RELEVANCE (See instructions): This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas. This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas.",Analytical Approaches to Massive Data Computation with Applications to Genomics,9015770,R01CA180776,"['Advocate', 'Algorithms', 'Area', 'Big Data', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Discipline', 'Effectiveness', 'Evaluation', 'Evidence Based Medicine', 'Genomics', 'Genotype', 'Health', 'Human Genome', 'Instruction', 'Machine Learning', 'Measures', 'Molecular Biology', 'Output', 'Performance', 'Phenotype', 'RNA Sequences', 'Research', 'Social Policies', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Uncertainty', 'Validation', 'Work', 'base', 'cancer genome', 'cancer genomics', 'data mining', 'design', 'genomic data', 'heuristics', 'mathematical analysis']",NCI,BROWN UNIVERSITY,R01,2016,71329,-0.008706530664271022
"INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE Project Summary  To understand the many disorders of the brain it is necessary to grapple with its complexity.  Increasingly large and complicated data sets are being collected, but the tools for analyzing and  modeling the data are not yet available. More researchers trained in computational neuroscience are  desperately needed. This project supports graduate and undergraduate training programs in  computational neuroscience (TPCN) at both Carnegie Mellon University (CMU) and the University of  Pittsburgh (Pitt), and a summer school in computational neuroscience for undergraduates, which are  available to students coming from colleges and universities throughout the United States.  The CMU-Pitt TPCN has 16 training faculty in computational neuroscience, 22 training faculty whose  laboratories are primarily experimental, and 20 training faculty whose laboratories are both  computational and experimental. At the graduate level the TPCN offers a PhD program in Neural  Computation (PNC) and joint PhD programs with CMU’s Department of Statistics (PNC-Stat) and its  Machine Learning Department (PNC- MLD), all set within a highly collegial, cross-disciplinary  environment of our Center for the Neural Basis of Cognition (CNBC), which is operated jointly by  CMU and Pitt. The CNBC was established in 1994 to foster interdisciplinary research on the neural  mechanisms of brain function, and now comprises 145 faculty having appointments in 22 departments.  At the undergraduate level a substantial pool of local students is supplemented during the summer  by a cohort of students from across the country. During this renewal funding period the project is  strengthening the role of statistics and machine learning throughout the training programs; (2) revising the summer undergraduate program by creating a didactic two-week “boot camp” at the  beginning, which includes a 20-lecture overview of computational neuroscience; (3) creating online  materials, in conjunction with the boot camp, that will serve not only our own students but also  the greater world of training in computational neuroscience; and (4) enhancing our minority  recruitment by (a) taking advantage of the boot camp and online materials, as well as making  promotional visits to targeted campuses, and (b) creating and running a one-year “bridge” program  to better prepare under-represented minorities for PhD programs.  TPCN trainees work in vertically integrated, cross-disciplinary research teams. Graduate students  take a year- long course in computational neuroscience that bridges modeling and modern statistical  machine learning approaches to neuroscience. To ensure their competency in core neuroscience  principles they also take courses in cognitive neuroscience, neurophysiology, and systems  neuroscience. They then pursue depth in a relevant quantitative discipline, such as computer  science, engineering, mathematics, or statistics. Graduate students have extended experience in at  least one experimental laboratory, and they take part in journal clubs and seminars within the  large Pittsburgh neuroscience community. Year-long undergraduates take courses in mathematics,  computer programming, statistics, and neuroscience; they take an additional course in neuroscience  or psychology and a course in computational neuroscience; and they complete a year-long research  project. In addition, they complete the TPCN summer program. Undergraduate trainees in the summer  program go through the boot camp on topics in computational neuroscience, including tutorials in  Matlab, statistical methods, fundamentals of differential equations, and ideas of neural coding;  they then complete a research project under careful guidance. All trainees will receive training in  responsible conduct of research. Across 5 years of funding, the TPCN supports 20 NRSA graduate  students, 10 non-NRSA graduate students, 30 undergraduate year-long fellows, and 60 undergraduate  summer fellows. Project Narrative  Research in neuroscience is crucial for attacking the causes of neurological and mental health  disorders. If the field of neuroscience is to continue its rapid advance, neuroscientists must use,  understand, and develop new technologies, acquire and analyze ever larger data sets, and grapple  more directly with the complexity of neurobiological systems. The primary goal of these training  programs will be to help train a new generation of interdisciplinary neuroscientists with strong  quantitative skills.",INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE,9322706,R90DA023426,"['Appointment', 'Brain', 'Brain Diseases', 'Camping', 'Code', 'Cognition', 'Communities', 'Country', 'Data Set', 'Differential Equation', 'Discipline', 'Doctor of Philosophy', 'Engineering', 'Ensure', 'Environment', 'Faculty', 'Fostering', 'Funding', 'Interdisciplinary Study', 'Joints', 'Journals', 'Laboratories', 'Machine Learning', 'Mathematics', 'Minority Recruitment', 'Modeling', 'National Research Service Awards', 'Neurosciences', 'Psychology', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Running', 'Schools', 'Statistical Methods', 'Students', 'System', 'Teacher Professional Development', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States', 'Universities', 'Visit', 'Work', 'base', 'bridge program', 'cognitive neuroscience', 'cohort', 'college', 'computational neuroscience', 'computer program', 'computer science', 'data modeling', 'experience', 'graduate student', 'lectures', 'neuromechanism', 'neurophysiology', 'programs', 'relating to nervous system', 'responsible research conduct', 'statistics', 'summer program', 'tool']",NIDA,CARNEGIE-MELLON UNIVERSITY,R90,2016,316840,0.03394526838430016
"Summer Institute for Statistics of Big Data DESCRIPTION:  Funding is sought for the Summer Institute for Statistics of Big Data (SISBID) at the University of Washington. This program will provide workshops on the statistical and computational skills needed to access, process, manage, and analyze large biomedical data sets. It will be co-directed by Ali Shojaie and Daniela Witten, faculty in the Department of Biostatistics at University of Washington.  The SISBID program will consist of five 2.5-day in-person courses, or modules, taught at the University of Washington each July. An individual participant can register for whichever set of modules he or she chooses. The five modules are as follows: (1) Accessing Biomedical Big Data; (2) Data Visualization; (3) Supervised Methods for Statistical Machine Learning; (4) Unsupervised Methods for Statistical Machine Learning; (5) Reproducible Research for Biomedical Big Data. Each module will consist of a combination of formal lectures and hands-on computing labs. Participants will work together in teams in order to apply the skills that they develop in each module to important problems drawn from relevant case studies.  The primary audience for SISBID will consist of biomedical scientists who would like to develop the statistical and computational training needed to make use of Biomedical Big Data. The secondary audience will consist of individuals with stronger statistical or computational backgrounds but little exposure to biology, who will learn how to apply their skills to problems associated with Biomedical Big Data. Participants will include advanced undergraduates, graduate students, post-doctoral fellows, and researchers, and will be drawn from industry, government, and academia. In order to ensure that all participants are able to fully engage in the program, participants will be expected to already have some prior background in R programming and statistical inference, which can be obtained by taking two free online courses before the program begins.  Each of the five modules will be co-taught by two instructors. The ten instructors will be drawn from top universities and research centers across the U.S., such as the University of Washington, Rice University, University of Iowa, Johns Hopkins University, MD Anderson Cancer Research Center, Fred Hutchinson Cancer Research Center, and University of North Carolina. They have been selected based on research expertise and excellence in teaching.  Lecture videos and slides will be made freely available online so that individuals who are unable to attend SISBID in person can still benefit from the program.  This proposal specifically requests funds for 55 student / postdoctoral fellow travel scholarships per year, 130 student / postdoctoral fellow registration scholarships per year, instructor travel and stipends, teaching assistant stipends, and PI salary support. PUBLIC HEALTH RELEVANCE:   In recent years, the biomedical sciences have been inundated by Big Data, such as DNA sequence data and electronic medical records. In principle, it should be possible to use such data for a variety of tasks, such as predicting an individual's risk of developing diabetes or cancer, and tailoring therapies to an individual should he or she become ill. The Summer Institute for Statistics of Big Data will provide biomedical researchers with the computational and statistical training needed in order to take advantage of Big Data, so that they can more effectively use it to understand human diseases and to improve human health.",Summer Institute for Statistics of Big Data,9063061,R25EB020380,"['Academia', 'Applied Skills', 'Area', 'Big Data', 'Biology', 'Biomedical Research', 'Biometry', 'Cancer Center', 'Case Study', 'Collection', 'Computer software', 'Computerized Medical Record', 'DNA Sequence', 'Data', 'Data Set', 'Diabetes Mellitus', 'Educational process of instructing', 'Educational workshop', 'Ensure', 'Environment', 'Exposure to', 'Faculty', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Government', 'Health', 'Human', 'Hybrids', 'Imagery', 'Individual', 'Industry', 'Institutes', 'Iowa', 'Knowledge', 'Learning', 'Learning Module', 'Machine Learning', 'Malignant Neoplasms', 'NCI Center for Cancer Research', 'North Carolina', 'Participant', 'Persons', 'Postdoctoral Fellow', 'Process', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rice', 'Risk', 'Running', 'Scholarship', 'Science', 'Slide', 'Statistical Computing', 'Statistical Methods', 'Students', 'Training', 'Training Activity', 'Training Programs', 'Travel', 'United States', 'Universities', 'Videotape', 'Wages', 'Washington', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'data visualization', 'graduate student', 'human disease', 'improved', 'instructor', 'learning materials', 'lectures', 'massive open online courses', 'member', 'online course', 'open source', 'programs', 'skills', 'statistics', 'summer institute', 'teacher', 'teaching assistant', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R25,2016,159605,0.03365752280156542
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,9056632,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'education research', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2016,73173,0.00016662745926958368
"The Center for Predictive Computational Phenotyping-1 Overall DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application. PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.",The Center for Predictive Computational Phenotyping-1 Overall,9270103,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'education research', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2016,43143,0.00016662745926958368
"Reactome: An Open Knowledgebase of Human Pathways DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community. RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.",Reactome: An Open Knowledgebase of Human Pathways,9005867,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablet Computer', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'mobile computing', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2016,1271107,-0.009336077991975673
"The Big DIPA: Data Image Processing and Analysis ﻿    DESCRIPTION (provided by applicant): This proposal aims to establish a national short course in Big Data Image Processing & Analysis (BigDIPA) intended to increase the number and overall skills of competent research scientists now encountering large, complex image data sources derived from cutting edge biological/biomedical research approaches. Extraction of knowledge from these imaging sources requires specialized skills and an interdisciplinary mindset. Yet effective training opportunities of this sector of the ""Big Data"" science community are glaringly underappreciated and underserved compared to other big data fields such as omics. UC Irvine is ideally suited to host a short course to address this thematic training deficit on account of the synergistic colocalization between multiple facilities, renowned for development of numerous advanced imaging techniques, and the outstanding instructional environment provided by faculty with collaborative expertise in biological image processing and computer vision, bioinformatics and high performance computational approaches.  Specifically, our BigDIPA proposal assembles an interdisciplinary alliance of faculty experts that can leverage the preeminent imaging resource facilities, such as the Laboratory of Fluorescence Dynamics (LFD) and the Beckman Laser Institute, and fuse these to ongoing campus big data initiatives, e.g. UCI's Data Science Initiative, to create a top-rated training course designed for senior graduate students, postdoctoral researchers, faculty and industry scientists from diverse scientific disciplines who have nascent interests and needs to handle BIG DATA sources beyond their current level of competency.  The course theme is focused to utilize discreet examples drawn from the analysis of complex data acquired from different microscopy imaging modalities employed to investigate dynamics in cellular and tissue processes, including signal transduction networks, development, neuroscience and biomedical applications, and that hereto where hidden or inaccessible to standard methods of analysis. Participants will be guided along the complete acquisition- processing-analysis pipeline through exposure to a coherent progression of topics and issues typically encountered when handling BIG DATA. We believe this training approach will therefore be attractive to a broad and significant untapped pool of researchers from the biological disciplines, biomedical engineering, systems biology, math, biophysics, computer science, bioinformatics and statistics who possess some, but not all, of the requisite competencies to effectively traverse the BD2K landscape. We have designed the course such that skills and experience gained by trainees will be transferable to their own research interests.  The BigDIPA course format will combine didactic lectures on the theory and foundational frameworks that underpin each step, with practical instruction on implementation and hands-on tutorials in image acquisition, large data handling, basic scripting of computational tools, image processing on high performance computing architectures, as well as feature extraction, evaluation and visualization of results. The course is designed to offer an intense learning experience delivered in a compact time frame, and opportunities to foster interdisciplinary interactions through small team exercises. Participants will also be encouraged to take advantage of pre-courses - separate and distinct training opportunities not funded by this proposal - that will be coordinated to directly precede our course. This unique format provides multiple benefits: it provides an efficient mechanism to address individual participant training deficiencies to permit a more productive experience in the BigDIPA course, adds no-cost mutual benefits to independent but synergistic programs, and facilitates recruitment of applicants who frequently feel interested but intimidated due to a perceived lack of prior adequate training.  Beyond providing an intensive on-site training course, all course materials (lecture notes, video lectures and tutorials), tutorial exercises, open source software resources and sample datasets will be made freely available through on-line distribution to maximize outreach and encourage additional contributions of curated training resources solicited from the community. PUBLIC HEALTH RELEVANCE: We propose to train and expand the cadre of researchers capable of effectively using the deluge of complex BIG DATA being generated by advanced biomedical imaging approaches. These data sources represent a rich source of complex information relevant to many scientific areas of inquiry, and are informative at multiple scales ranging from fundamental biological processes at the cellular level to patient diagnostics for diseases such as cancer or neurological disorders.",The Big DIPA: Data Image Processing and Analysis,9150564,R25EB022366,"['Accounting', 'Address', 'Architecture', 'Area', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biomedical Engineering', 'Biomedical Research', 'Biomedical Technology', 'Biophysics', 'Cell physiology', 'Communities', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Development', 'Diagnostic', 'Discipline', 'Disease', 'Educational Curriculum', 'Educational workshop', 'Environment', 'Evaluation', 'Exercise', 'Exposure to', 'Faculty', 'Fluorescence', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Information Sciences', 'Institutes', 'Instruction', 'Interdisciplinary Communication', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Methods', 'Modality', 'NIH Program Announcements', 'National Institute of General Medical Sciences', 'Neurosciences', 'Participant', 'Patients', 'Performance', 'Problem Solving', 'Process', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Sampling', 'Schools', 'Scientist', 'Senior Scientist', 'Signal Transduction', 'Site', 'Skills Development', 'Software Tools', 'Source', 'Staging', 'Stream', 'Systems Biology', 'TNFRSF5 gene', 'Time', 'Training', 'United States National Institutes of Health', 'Work', 'bioimaging', 'biological systems', 'biomedical scientist', 'computer science', 'computerized tools', 'cost', 'course implementation', 'data acquisition', 'data format', 'demographics', 'design', 'education research', 'experience', 'flexibility', 'graduate student', 'image processing', 'imaging modality', 'interdisciplinary collaboration', 'interest', 'learning materials', 'lecture notes', 'lectures', 'meetings', 'microscopic imaging', 'nervous system disorder', 'open source', 'outreach', 'programs', 'repository', 'skill acquisition', 'skills', 'statistics', 'theories', 'tissue processing', 'training opportunity']",NIBIB,UNIVERSITY OF CALIFORNIA-IRVINE,R25,2016,161997,0.023675917023469984
"EDAC: ENCODE Data Analysis Center DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health. RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,9268117,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost effectiveness', 'cost efficient', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'genomic data', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2016,1378926,0.004088077486549261
"Boosting the Translational Impact of Scientific Competitions by Ensemble Learning ﻿    DESCRIPTION (provided by applicant): ""Big data"" such as those arising from sequencing, imaging, genomics and other emerging technologies are playing a critical role in modern biology and medicine. The generation of hypotheses about biological processes and disease mechanisms is now increasingly being driven by the production and analysis of large and complex datasets. Advanced computational methods have been developed for the robust analysis of these datasets, and the growth in number and sophistication of these methods has closely tracked the growth in volume and complexity of biomedical data. In such a crowded environment of diverse computational methods and data, it is difficult to judge how generalizable the performance of these methods is from one setting to another. Crowdsourcing-based scientific competitions, or challenges, have now become popular mechanisms for the rigorous, blinded and unbiased evaluation of the performance of these methods and the identification of best-performing methods for biomedical problems. However, despite the benefits of these challenges to the biomedical research enterprise, the impact of their findings has been remarkably limited in laboratory and clinical settings. This is likely due to two important aspects of current challenges: (i) their over-emphasis on identifying the ""best"" solutions rather than tryig to comprehensively assimilate the knowledge embedded in all the submitted solutions, and (ii) the absence of a stable channel of communication and collaboration between problem and solution providers due to a lack of sufficient incentives to do so. The aim of this project is to boost the translational impact of scientific challenges through a combination of novel machine learning methods, development of novel scalable software and unique collaborations with disease experts to ensure the effective translation of knowledge accrued in challenges to real clinical settings and practice. These novel methods and software are designed to effectively assimilate the knowledge embedded in all the submissions to challenges into ""ensemble"" solutions. In a first of its kind effort, the ensemble solutions derived from disease-focused challenges under the DREAM project will be brought directly to scientists and clinicians that are experts in these disease areas. Initial effort in this project will focus on active DREAM challenges aiming at the accurate prediction of drug response and clinical outcomes respectively in Rheumatoid Arthritis (RA) and Acute Myeloid Leukemia (AML). Both these diseases are difficult to treat and thus they pose major medical and public health concerns. In collaboration with RA and AML experts, the ensemble solutions learnt in these challenges will be validated in independent patient cohorts and carefully designed clinical studies. This second-level validation is essential to judge the clinical applicability of any method, but is rarely done As the methodology is general, similar efforts will be made for other diseases in later stages of the project. Overall, using a smart combination of crowdsourcing-based challenges and computational methods and software, we aim to demonstrate a unique pathway for studying and treating disease by truly leveraging the ""wisdom of the crowds"". PUBLIC HEALTH RELEVANCE: Crowdsourcing-based scientific competitions, or challenges, have become a popular mechanism to identify innovative solutions to complex biomedical problems. However, the collective effort of all the challenge participants has been under utilized, and the overall impact on actual clinical and laboratory practice has been remarkably limited. Using novel computational methods and novel ""big data""-friendly software implementation, we plan to demonstrate how biomedical challenges, combined with our approach, can influence clinical practice in Acute Myeloid Leukemia and Rheumatoid Arthritis, as well as rigorously validate our approach.",Boosting the Translational Impact of Scientific Competitions by Ensemble Learning,9049511,R01GM114434,"['Acute Myelocytic Leukemia', 'Address', 'Adopted', 'Advanced Development', 'Architecture', 'Area', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Blinded', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Crowding', 'Data', 'Data Set', 'Discipline', 'Disease', 'Emerging Technologies', 'Ensure', 'Environment', 'Evaluation', 'Explosion', 'Generations', 'Genomics', 'Genotype', 'Goals', 'Growth', 'Health', 'Heterogeneity', 'High Performance Computing', 'Image', 'Incentives', 'Knowledge', 'Laboratories', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Mining', 'Nature', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Problem Solving', 'Production', 'Provider', 'Public Health', 'Publications', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Running', 'Science', 'Scientist', 'Software Design', 'Source', 'Staging', 'Synapses', 'System', 'Time', 'Translating', 'Translations', 'Validation', 'Variant', 'base', 'clinical application', 'clinical practice', 'cohort', 'computer science', 'crowdsourcing', 'design', 'innovation', 'interest', 'knowledge translation', 'learning progression', 'learning strategy', 'meetings', 'method development', 'novel', 'open source', 'predictive modeling', 'prospective', 'response', 'stem', 'tool']",NIGMS,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2016,428512,0.0020321311688748754
"NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR) DESCRIPTION (provided by applicant):  We propose to establish a NIDA Center of Excellence for Computational Drug Abuse Research (CDAR) between the University of Pittsburgh (Pitt) and (CMU), with the goal of advancing and ensuring the productive and broad usage of state-of-the-art computational technologies that will facilitate and enhance drug abuse (DA) research, both in the local (Pittsburgh) area and nationwide. To this end, we will develop/integrate tools for DA-domain-specific chemical-to-protein-to-genomics mapping using cheminformatics, computational biology and computational genomics methods by centralizing computational chemical genomics (or chemogenomics) resources while also making them available on a cloud server. The Center will foster collaboration and advance knowledge-based translational research and increase the effectiveness of ongoing funded research project (FRPs) via the following Research Support Cores: (1) The Computational Chemogenomics Core for DA (CC4DA) will help address polydrug addiction/polypharmacology by developing new chemogenomics tools and by compiling the data collected/generated, along with those from other Cores, into a DA knowledge-based chemogenomics (DA-KB) repository that will be made accessible to the DA community. (2) The Computational Biology Core (CB4DA) will focus on developing a resource for structure-based investigation of the interactions among substances of DA and their target proteins, in addition to assessing the drugability of receptors and transporters involved in DA and addiction. These activities will be complemented by quantitative systems pharmacology methods to enable a systems-level approach to DA research. (3) The Computational Genomics Core (CG4DA) will carry out genome-wide discovery of new DA targets, markers, and epigenetic influences using developed machine learning models and algorithms. (4) The Administrative Core will coordinate Center activities, provide management to oversee the CDAR activities in consultation with the Scientific Steering Committee (SSC) and an External Advisory Board (EAB), ensure the effective dissemination of software/data among the Cores and the FRPs, and establish mentoring mechanisms to train junior researchers. Overall, the Center will strive to achieve the long-term goal of translating advances in computational chemistry, biology and genomics toward the development of novel personalized DA therapeutics. We propose a Computational Drug Abuse Research (CDAR) Center, as a joint initiative between the  University of Pittsburgh and Carnegie Mellon University. The Center consist of three Cores (CC4DA, CB4DA  and CG4DA) that will leverage our expertise in computational chemogenomics, computational biology, and  computational genomics to facilitate basic and translational drug abuse and medication research.",NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR),9118144,P30DA035778,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cannabinoids', 'Categories', 'Cells', 'Chemicals', 'Clinical Trials Network', 'Cloud Computing', 'Cocaine', 'Collaborations', 'Communities', 'Complement', 'Computational Biology', 'Computer software', 'Consultations', 'Data', 'Databases', 'Development', 'Doctor of Philosophy', 'Drug abuse', 'Effectiveness', 'Endocytosis', 'Ensure', 'Environmental Risk Factor', 'Feedback', 'Fostering', 'Funding', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Intervention', 'Investigation', 'Joints', 'Leadership', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'National Institute of Drug Abuse', 'Neuropharmacology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacology', 'Phenotype', 'Proteins', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Science', 'Signal Transduction', 'Software Tools', 'Structure', 'Substance Use Disorder', 'System', 'Systems Biology', 'Technology', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Universities', 'addiction', 'base', 'biobehavior', 'cheminformatics', 'cloud based', 'cloud platform', 'computational chemistry', 'computer science', 'data mining', 'design', 'distinguished professor', 'dopamine transporter', 'drug abuse prevention', 'epigenetic marker', 'falls', 'genome-wide', 'improved', 'insight', 'knowledge base', 'member', 'novel', 'operation', 'predictive modeling', 'prevent', 'professor', 'receptor', 'repository', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P30,2016,1070007,-0.0033933146064795586
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL     DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the worid, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research.         PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.            ","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",9096856,U54GM114838,"['Actinomyces Infections', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Work', 'analytical method', 'base', 'big biomedical data', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'community building', 'data mining', 'design', 'drug discovery', 'field study', 'gene interaction', 'genome sequencing', 'genome-wide', 'genomic data', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2016,2201640,0.02251461771438208
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL     DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the worid, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research.         PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.            ","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",9288931,U54GM114838,"['Actinomyces Infections', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Analytics', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Work', 'analytical method', 'base', 'big biomedical data', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'community building', 'data mining', 'design', 'drug discovery', 'field study', 'gene interaction', 'genome sequencing', 'genome-wide', 'genomic data', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2016,224176,0.02251461771438208
"Big Data Coursework for Computational Medicine DESCRIPTION:  As the era of ""Big Data"" is dawning on biomedical research, multiple types of biomedical data, including phenotypic, molecular (including -omics), clinical, imaging, behavioral, and environmental data is being generated on an unprecedented scale with high volume, variety and velocity. These datasets are increasingly large and complex, challenging our current abilities for data representation, integration and analysis for improving outcomes and reducing healthcare costs. It is well-recognized that the greatest challenge to leveraging the significant potentials of Big Data is in educating and recruiting future computational and data scientists who have the background, training and experience to master fundamental opportunities in biomedical sciences. This demands interdisciplinary education and hands-on practicum training on understanding the application, analysis, limitations, and value of the Big Data. To bridge this knowledge gap for the U.S. biomedical workforce, we propose to develop a research educational program-Big Data Coursework for Computational Medicine (BDC4CM)-that will instruct students, fellows and scientists in the use of specific new methods and tools fo Big Data by providing tailored, in-depth instruction, hands-on laboratory modules, and case studies on Big Data access, integration, processing and analysis. Offered by highly interdisciplinary and experienced faculty from Mayo Clinic and the University of Minnesota, this program will provide a short- term training opportunity on Big Data methods and approaches for: 1) data and knowledge representation standards; 2) information extraction and natural language processing; 3) visualization analytics; 4) data mining and predictive modeling; 5) privacy and ethics; and 6) applications in comparative effectiveness research and population health research and improvement. Our primary educational goal is to prepare the next generation of innovators and visionaries in the emerging, multidimensional field of Big Data Science in healthcare, as well as to develop a future workforce that fulfills industry needs and increases U.S. competitiveness in healthcare technologies and applications. PUBLIC HEALTH RELEVANCE:   The postdoctoral Big Data Coursework for Computational Medicine (BDC4CM) program seeks to provide short-term education and hands-on practicum training in utilization of biomedical Big Data. BDC4CM will address a major need for the U.S. biomedical workforce to develop and enhance existing skills in application, analysis, limitations, and value of the Big Data.",Big Data Coursework for Computational Medicine,9129718,R25EB020381,"['Academic Medical Centers', 'Address', 'Advisory Committees', 'Area', 'Behavioral', 'Big Data', 'Bioethics', 'Biological Sciences', 'Biomedical Research', 'Case Study', 'Clinic', 'Clinical', 'Collection', 'Committee Members', 'Complex', 'Computational Biology', 'Data', 'Data Reporting', 'Data Science', 'Data Set', 'Development', 'Development Plans', 'Discipline', 'Doctor of Medicine', 'Doctor of Philosophy', 'Education', 'Effectiveness', 'Engineering', 'Ethics', 'Evaluation', 'Faculty', 'Feedback', 'Future', 'Goals', 'Grant', 'Health', 'Health Care Costs', 'Health Services Research', 'Healthcare', 'Image', 'Imagery', 'Industry', 'Informatics', 'Instruction', 'Interdisciplinary Education', 'Interview', 'Knowledge', 'Laws', 'Learning', 'Mathematics', 'Measures', 'Medicine', 'Mentorship', 'Methods', 'Minnesota', 'Molecular', 'Monitor', 'Natural Language Processing', 'Patient-Focused Outcomes', 'Peer Review', 'Performance', 'Positioning Attribute', 'Postdoctoral Fellow', 'Privacy', 'Process', 'Program Reviews', 'Public Health', 'Publications', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Students', 'Surveys', 'Technology', 'Training', 'Training Activity', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'base', 'big biomedical data', 'biomedical informatics', 'career', 'career development', 'collaborative environment', 'comparative effectiveness', 'computer science', 'data access', 'data mining', 'education research', 'effectiveness research', 'experience', 'faculty mentor', 'improved', 'improved outcome', 'information organization', 'instrument', 'laboratory experience', 'laboratory module', 'meetings', 'multidisciplinary', 'new technology', 'next generation', 'population health', 'predictive modeling', 'programs', 'skills', 'statistics', 'student training', 'success', 'tool', 'training opportunity', 'working group']",NIBIB,WEILL MEDICAL COLL OF CORNELL UNIV,R25,2016,150010,0.02260126790253118
"Big Data Coursework for Computational Medicine DESCRIPTION:  As the era of ""Big Data"" is dawning on biomedical research, multiple types of biomedical data, including phenotypic, molecular (including -omics), clinical, imaging, behavioral, and environmental data is being generated on an unprecedented scale with high volume, variety and velocity. These datasets are increasingly large and complex, challenging our current abilities for data representation, integration and analysis for improving outcomes and reducing healthcare costs. It is well-recognized that the greatest challenge to leveraging the significant potentials of Big Data is in educating and recruiting future computational and data scientists who have the background, training and experience to master fundamental opportunities in biomedical sciences. This demands interdisciplinary education and hands-on practicum training on understanding the application, analysis, limitations, and value of the Big Data. To bridge this knowledge gap for the U.S. biomedical workforce, we propose to develop a research educational program-Big Data Coursework for Computational Medicine (BDC4CM)-that will instruct students, fellows and scientists in the use of specific new methods and tools fo Big Data by providing tailored, in-depth instruction, hands-on laboratory modules, and case studies on Big Data access, integration, processing and analysis. Offered by highly interdisciplinary and experienced faculty from Mayo Clinic and the University of Minnesota, this program will provide a short- term training opportunity on Big Data methods and approaches for: 1) data and knowledge representation standards; 2) information extraction and natural language processing; 3) visualization analytics; 4) data mining and predictive modeling; 5) privacy and ethics; and 6) applications in comparative effectiveness research and population health research and improvement. Our primary educational goal is to prepare the next generation of innovators and visionaries in the emerging, multidimensional field of Big Data Science in healthcare, as well as to develop a future workforce that fulfills industry needs and increases U.S. competitiveness in healthcare technologies and applications. PUBLIC HEALTH RELEVANCE:   The postdoctoral Big Data Coursework for Computational Medicine (BDC4CM) program seeks to provide short-term education and hands-on practicum training in utilization of biomedical Big Data. BDC4CM will address a major need for the U.S. biomedical workforce to develop and enhance existing skills in application, analysis, limitations, and value of the Big Data.",Big Data Coursework for Computational Medicine,9242970,R25EB020381,"['Academic Medical Centers', 'Address', 'Advisory Committees', 'Area', 'Behavioral', 'Big Data', 'Bioethics', 'Biological Sciences', 'Biomedical Research', 'Case Study', 'Clinic', 'Clinical', 'Collection', 'Committee Members', 'Complex', 'Computational Biology', 'Data', 'Data Reporting', 'Data Science', 'Data Set', 'Development', 'Development Plans', 'Discipline', 'Doctor of Medicine', 'Doctor of Philosophy', 'Education', 'Effectiveness', 'Engineering', 'Ethics', 'Evaluation', 'Faculty', 'Feedback', 'Future', 'Goals', 'Grant', 'Health', 'Health Care Costs', 'Health Services Research', 'Healthcare', 'Image', 'Imagery', 'Industry', 'Informatics', 'Instruction', 'Interdisciplinary Education', 'Interview', 'Knowledge', 'Laws', 'Learning', 'Mathematics', 'Measures', 'Medicine', 'Mentorship', 'Methods', 'Minnesota', 'Molecular', 'Monitor', 'Natural Language Processing', 'Patient-Focused Outcomes', 'Peer Review', 'Performance', 'Positioning Attribute', 'Postdoctoral Fellow', 'Privacy', 'Process', 'Program Reviews', 'Public Health', 'Publications', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Students', 'Surveys', 'Technology', 'Training', 'Training Activity', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'base', 'big biomedical data', 'biomedical informatics', 'career', 'career development', 'collaborative environment', 'comparative effectiveness', 'computer science', 'data access', 'data mining', 'education research', 'effectiveness research', 'experience', 'faculty mentor', 'improved', 'improved outcome', 'information organization', 'instrument', 'laboratory experience', 'laboratory module', 'meetings', 'multidisciplinary', 'new technology', 'next generation', 'population health', 'predictive modeling', 'programs', 'skills', 'statistics', 'student training', 'success', 'tool', 'training opportunity', 'working group']",NIBIB,WEILL MEDICAL COLL OF CORNELL UNIV,R25,2016,68279,0.02260126790253118
"Heterogeneous and Robust Survival Analysis in Genomic Studies DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed. PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.",Heterogeneous and Robust Survival Analysis in Genomic Studies,9041640,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Methods', 'Modeling', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'genomic data', 'hazard', 'human genomics', 'improved', 'individual patient', 'loss of function', 'novel', 'patient biomarkers', 'personalized genomic medicine', 'prevent', 'public health relevance', 'research study', 'response', 'simulation', 'survival outcome', 'theories', 'treatment response', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2016,255295,-0.02459913618902947
"An Open Source Precision Medicine Platform for Cloud Operating Systems ﻿    DESCRIPTION (provided by applicant):  Rapid improvements in DNA sequencing and synthesis have the potential to usher in a new era of precision medicine. To realize this vision, however, we must re-imagine the computational and storage infrastructure used to manage and extract actionable results from the massive data sets made possible by widely available advances in DNA sequencing and synthetic biology. In conjunction with the Global Alliance for Genomics and Health (GA4GH), we propose to build the Arvados platform so that a new ecosystem of clinical decision support applications will be able to navigate petabytes of global biomedical data and search millions of genomes in real-time (seconds). Our team has a proven track record of commercial success and high impact scientific research. Commercialization of this free and open-source software (FOSS) platform, which will be greatly accelerated by this grant, will permit organizations to seamlessly span on-premise & hosted cloud- operating systems and vastly simplify data-management & computation, all while facilitating compliance with institutional policies and regulatory requirements.         PUBLIC HEALTH RELEVANCE:  The delivery of healthcare based on molecular data specific to an individual patient (i.e. precision medicine) will require the creation of a new ecosystem of Clinical Decision Support (CDS) applications. This work will provide a platform that will make the development of such applications faster, easier, and less expensive.        ",An Open Source Precision Medicine Platform for Cloud Operating Systems,9140741,R44GM109737,"['Address', 'Adopted', 'Big Data', 'Bioinformatics', 'Businesses', 'Capital', 'Clinical', 'Clinical Decision Support Systems', 'Collaborations', 'Communities', 'Computer software', 'Contractor', 'DNA Sequence', 'DNA biosynthesis', 'Data', 'Data Set', 'Databases', 'Development', 'Distributed Systems', 'Ecosystem', 'Feedback', 'Fostering', 'Funding', 'Galaxy', 'Genome', 'Genomics', 'Grant', 'Health', 'Healthcare', 'Human', 'Industry', 'Information Technology', 'Institutional Policy', 'International', 'Internet', 'Language', 'Length', 'Letters', 'Machine Learning', 'Maintenance', 'Manuscripts', 'Measures', 'Medicine', 'Memory', 'Molecular', 'Operating System', 'Phase', 'Policies', 'Production', 'Publications', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resources', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Source Code', 'System', 'Technology', 'Time', 'Training Support', 'Vision', 'Work', 'base', 'big biomedical data', 'cloud platform', 'commercialization', 'data management', 'genome sequencing', 'genomic data', 'health care delivery', 'individual patient', 'meetings', 'new technology', 'next generation sequencing', 'open source', 'operation', 'petabyte', 'portability', 'precision medicine', 'public health relevance', 'repository', 'screening', 'success', 'symposium', 'synthetic biology', 'terabyte', 'web services', 'whole genome']",NIGMS,"CUROVERSE, INC.",R44,2016,985339,-0.004668983443718892
"COINSTAC: decentralized, scalable analysis of loosely coupled data ﻿    DESCRIPTION (provided by applicant):     The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway5,10. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume11, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the dat as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community becomes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group2).    The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates  dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented storage vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and privacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix factorization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities. PUBLIC HEALTH RELEVANCE: Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don't have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this 'missing data' and allow for pooling of both open and 'closed' repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed computational solution for a large toolkit of widely used algorithms.","COINSTAC: decentralized, scalable analysis of loosely coupled data",9100683,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Left', 'Letters', 'Linear Models', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'base', 'computing resources', 'connectome', 'cost', 'data sharing', 'distributed data', 'flexibility', 'imaging genetics', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'open data', 'peer', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,THE MIND RESEARCH NETWORK,R01,2016,680020,0.01415621069844561
"CSHL Computational and Comparative Genomics Course DESCRIPTION (provided by applicant): The Cold Spring Harbor Laboratory proposes to continue a course entitled ""Computational and Comparative Genomics"", to be held in the fall of 2014 - 2016. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions. PUBLIC HEALTH RELEVANCE: The Computational & Comparative Genomics is a 6 day course designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.",CSHL Computational and Comparative Genomics Course,9097763,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'Course Content', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Educational process of instructing', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomics', 'Health', 'Home environment', 'Institution', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Peptide Sequence Determination', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Universities', 'Update', 'base', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'genome sequencing', 'graduate student', 'instructor', 'interest', 'laboratory experience', 'lecturer', 'meetings', 'programs', 'promoter', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2016,52816,0.0005109701189417029
"Training in lesion-symptom mapping for speech-language research ﻿    DESCRIPTION (provided by applicant): Training in lesion-symptom mapping for speech-language research Abstract: Researchers rely upon the lesion method to evaluate the speech-language status of stroke survivors and draw inferences about underlying brain function. This use of neuropsychology is highly valued in basic speech- language research because it can support causal inferences about brain structure/function relationships. Crucially, advances in analytic techniques and brain image computing are creating a new landscape for neuropsychological research. In this new landscape, the lesion method represents a form of big-data science that requires large sample sizes and complex image computing to implement lesion-symptom mapping (LSM) across the entire brain, without prior regions of interest. Expertise in these new techniques is becoming critical for high impact speech-language research. The career enhancement plan will provide the candidate with training in cutting-edge LSM. The candidate is an established speech-language investigator with a basic program of multidisciplinary research that includes populations with communication disorders due to stroke. The career enhancement will come at an ideal point, because it will build on the candidate's success in establishing an open-access research registry of stroke survivors (the Western Pennsylvania Patient Registry, WPPR), and current work to develop and validate collaborative videoconferencing for remote neuropsychological assessment. These efforts have created the recruitment pool and datasets that are needed for LSM. The career enhancement will provide the training needed to leverage these resources, thereby augmenting the candidate's program of research and career trajectory. The overarching objectives are to: (1) retool the skills of the candidate to infuse LSM into her program of speech-language research, (2) seed data sharing and data science partnerships to boost the candidate's leadership of WPPR as a national resource, and (3) advance understanding of LSM methods and the neural substrates for speech and language to improve the knowledge base of the candidate and other investigators. The candidate proposes a synergistic set of activities. Didactic activities will give training in machie learning and brain image computing, scholarly travel experiences will afford opportunities to network with speech-language researchers and data scientists whose work is relevant for LSM, and two research studies will provide a hands-on opportunity for the candidate to acquire, apply, and extend LSM methods under the guidance of a superb mentoring team. Study 1 will use univariate and multivariate LSM analysis to investigate the neural substrates of chronic Broca's aphasia and the factors that influence the reproducibility of LSM results. Study 2 will develop and evaluate a workflow for automated lesion segmentation, using a software platform (3D Slicer) that involves two NIH-supported data science centers. Overall, the career enhancement will retool the skills, research network, and knowledge base of an established investigator, allowing the candidate to significantly augment her program of speech-language research and advance the utility of WPPR as a national resource for speech-language research. PUBLIC HEALTH RELEVANCE: This use of neuropsychology is highly valued in basic speech-language research because it can support causal inferences about brain structure/function relationships. Crucially, advances in analytic techniques and brain image computing are creating a new landscape for neuropsychological research. This career enhancement will retool the skills, research network, and knowledge base of an established investigator, allowing the candidate to significantly augment her program of speech-language research and advance the utility of a Pittsburgh- based stroke research registry as a national resource.",Training in lesion-symptom mapping for speech-language research,9040405,K18DC014577,"['Adult', 'Aphasia', 'Big Data', 'Brain', 'Brain imaging', 'Broca Aphasia', 'Chronic', 'Collaborations', 'Communication impairment', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Educational workshop', 'Evaluation', 'Gold', 'Health', 'Image', 'Interdisciplinary Study', 'K-Series Research Career Programs', 'Knowledge', 'Language', 'Language Disorders', 'Leadership', 'Learning', 'Lesion', 'Machine Learning', 'Manuals', 'Maps', 'Mentors', 'Methods', 'Neuropsychology', 'Participant', 'Pennsylvania', 'Population', 'Registries', 'Reproducibility', 'Research', 'Research Activity', 'Research Methodology', 'Research Personnel', 'Resources', 'Sample Size', 'Seeds', 'Slice', 'Speech', 'Stroke', 'Structure-Activity Relationship', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Tissues', 'Training', 'Travel', 'United States', 'United States National Institutes of Health', 'Videoconferences', 'Videoconferencing', 'Visit', 'Work', 'abstracting', 'base', 'career', 'data sharing', 'design', 'disability', 'experience', 'improved', 'interest', 'knowledge base', 'language processing', 'method development', 'named group', 'neuropsychological', 'novel', 'patient registry', 'programs', 'relating to nervous system', 'research and development', 'research study', 'skills', 'speech processing', 'stroke survivor', 'success', 'theories']",NIDCD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K18,2016,167875,-0.04215202261622723
"Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership ﻿    DESCRIPTION (provided by applicant): The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The aims to achieve the goals are: 1) Implement an integrated didactic program to enhance student self-efficacy with computational and informatics tool development and use for interrogating and interpreting Big Data, including a two-semester bioinformatics course in Bioinformatics, informed by the expertise of UIUC KnowEnG BD2K Center faculty with additional Special Topics courses available remotely from UIUC. 2) Develop an integrated academic year (Fisk, or partners) and summer research program at the UIUC KnowEnG BD2K Center to assure student exposure to a participation in the life cycle of a `Big Data' research problem. 3) Implement a professional skills development program that assures successful transition of undergraduate participants to a Ph.D. (or MD/PhD Program) in Big Data- reliant biomedical research. 4) Launch a faculty development program in bioinformatics that leads to embracing Big Data problems in courses in multiple disciplines for impact on all Fisk undergraduate STEM majors. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fisk R25 mentors, of value for their broader education and research training goals at UIUC and Mayo. PUBLIC HEALTH RELEVANCE: The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fis R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.  ",Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership,9150655,R25MD010396,"['Address', 'Base Pairing', 'Big Data', 'Big Data to Knowledge', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Career Choice', 'Cellular biology', 'Chemicals', 'Collaborations', 'Communication', 'Complement', 'Computers', 'Core Facility', 'Data Analyses', 'Development Plans', 'Discipline', 'Diving', 'Doctor of Philosophy', 'Education Projects', 'Educational Curriculum', 'Educational workshop', 'Elements', 'Exposure to', 'Faculty', 'Faculty Workshop', 'Fostering', 'Funding', 'Genomics', 'Goals', 'Grant', 'Health', 'Illinois', 'Informatics', 'Joints', 'Journals', 'Learning', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Manuscripts', 'Mathematics', 'Mentors', 'Molecular Biology', 'Oral', 'Participant', 'Proteomics', 'Reading', 'Recruitment Activity', 'Research', 'Research Ethics', 'Research Personnel', 'Research Training', 'Role', 'STEM field', 'Science', 'Scientist', 'Self Efficacy', 'Skills Development', 'Students', 'System', 'Teacher Professional Development', 'Technology', 'Time', 'Training', 'Training Programs', 'Underrepresented Minority', 'Universities', 'Work', 'Writing', 'base', 'career', 'computer science', 'data acquisition', 'data sharing', 'education research', 'experience', 'faculty research', 'individualized medicine', 'innovation', 'minority scientist', 'posters', 'programs', 'responsible research conduct', 'skill acquisition', 'skills', 'summer research', 'tool', 'tool development', 'undergraduate research']",NIMHD,FISK UNIVERSITY,R25,2016,204941,0.056210408849727125
"Semantic Data Lake for Biomedical Research Capitalizing on the transformative opportunities afforded by the extremely large and ever-growing volume, velocity, and variety of biomedical data being continuously produced is a major challenge. The development and increasingly widespread adoption of several new technologies, including next generation genetic sequencing, electronic health records and clinical trials systems, and research data warehouses means that we are in the midst of a veritable explosion in data production. This in turn results in the migration of the bottleneck in scientific productivity into data management and interpretation: tools are urgently needed to assist cancer researchers in the assembly, integration, transformation, and analysis of these Big Data sets. In this project, we propose to develop the Semantic Data Lake for Biomedical Research (SDL-BR) system, a cluster-computing software environment that enables rapid data ingestion, multifaceted data modeling, logical and semantic querying and data transformation, and intelligent resource discovery. SDL-BR is based on the idea of a data lake, a distributed store that does not make any assumptions about the structure of incoming data, and that delays modeling decisions until data is to be used. This project adds to the data lake paradigm methods for semantic data modeling, integration, and querying, and for resource discovery based on learned relationships between users and data resources. The SDL-BR System is a distributed computing software solution that enables research institutions to manage, integrate, and make available large institutional data sets to researchers, and that permits users to generate data models specific to particular applications. It uses state of the art cluster computing, Semantic Web, and machine learning technologies to provide for rapid data ingestion, semantic modeling and querying, and search and discovery of data resources through a sophisticated, Web-based user interface.",Semantic Data Lake for Biomedical Research,9200905,R44CA206782,"['Accelerometer', 'Acute', 'Address', 'Adoption', 'Area', 'Big Data', 'Biomedical Computing', 'Biomedical Research', 'Cataloging', 'Catalogs', 'Chronic Myeloid Leukemia', 'Clinical', 'Clinical Trials', 'Collection', 'Colorectal Cancer', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Discovery', 'Data Quality', 'Data Science', 'Data Set', 'Data Sources', 'Databases', 'Decision Modeling', 'Demographic Factors', 'Development', 'Electronic Health Record', 'Ensure', 'Environment', 'Evaluation', 'Explosion', 'Generations', 'Genetic', 'Genetic Markers', 'High-Throughput Nucleotide Sequencing', 'Immigration', 'Individual', 'Informatics', 'Ingestion', 'Institution', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Legal', 'Legal patent', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Non-Small-Cell Lung Carcinoma', 'Online Systems', 'Ontology', 'Phase', 'Policies', 'Precision therapeutics', 'Procedures', 'Process', 'Production', 'Productivity', 'Recommendation', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Retrieval', 'Risk', 'Secure', 'Security', 'Semantics', 'Services', 'Source', 'Specific qualifier value', 'Staging', 'Structure', 'System', 'Technology', 'Testing', 'Vocabulary', 'Work', 'base', 'cancer therapy', 'cluster computing', 'computer based Semantic Analysis', 'cost effective', 'data access', 'data exchange', 'data integration', 'data management', 'data modeling', 'design', 'disease heterogeneity', 'experience', 'genetic information', 'handheld mobile device', 'indexing', 'individualized medicine', 'melanoma', 'natural language', 'new technology', 'next generation', 'novel', 'precision medicine', 'prototype', 'success', 'systems research', 'targeted treatment', 'technology development', 'time use', 'tool']",NCI,"INFOTECH SOFT, INC.",R44,2016,221175,-0.013619005250789505
"Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems DESCRIPTION (provided by applicant): Abstract Biomedical science, higher education, software and technology are simultaneously undergoing tectonic shifts. The amazing pace of software and technological development are driving equally amazing advances in the ability to acquire massive data sets in the biomedical sciences. These new Big Biomedical data sets come in the form of complex measurements, such as that of the brain, genome, proteome and human biome or massive databases, such as with electronic health records. Big Data issues, such as reproducibility of processing, measurement and analysis techniques, are increasingly complex, and crucial. Across all domains there is a knowledge gap of researchers to analyze and interpret these new data sets and the current higher education model cannot meet the insatiable demand for this training. We propose to make substantial progress on these issues in two domains. Specifically, we propose to use Massive Open Online Courses (MOOCs) to create two series, one in neuroimaging and one in genomics. These series will allow for flexible, student paced, low cost scalable training for tens of thousands of students. Along with these series, we propose the creation of modular Big Data biostatistical content that can be used by students as well as teachers. This effort will be parallel to work on an intelligent tutoring syste called swirl. This application proposes to use swirl to create rich, gamified learning environments for students. All of the material created from this grant will be open access and free. PUBLIC HEALTH RELEVANCE:  Project narrative: We propose two Massive Open Online Course series in neuroimaging and genomic Big Data analysis as well as the creation of modular Big Data statistics content and content creation for an intelligent tutoring system.","Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems",9061684,R25EB020378,"['Adopted', 'Amaze', 'Area', 'Attention', 'Automobile Driving', 'Big Data', 'Biological', 'Biology', 'Brain', 'Clinical Trials', 'Communities', 'Complex', 'Computer software', 'Cost Analysis', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Science', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Discipline', 'Drops', 'Education', 'Educational Curriculum', 'Educational Models', 'Educational process of instructing', 'Electronic Health Record', 'Enrollment', 'Environment', 'Generations', 'Genes', 'Genome', 'Genomics', 'Grant', 'Head', 'Health', 'Human', 'Image', 'Knowledge', 'Laboratories', 'Learning Module', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medicine', 'Modeling', 'Molecular Biology', 'Molecular Medicine', 'Multivariate Analysis', 'Persons', 'Population', 'Principal Investigator', 'Problem Sets', 'Proteome', 'Public Health', 'Public Health Nurses', 'Public Health Nursing', 'Race', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Series', 'Services', 'Statistical Data Interpretation', 'Stream', 'Students', 'System', 'Systems Biology', 'Teacher Professional Development', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Touch sensation', 'Training', 'Training Activity', 'Training Programs', 'Universities', 'Work', 'abstracting', 'big biomedical data', 'contrast enhanced', 'cost', 'course module', 'density', 'educational atmosphere', 'flexibility', 'hands-on learning', 'higher education', 'instructor', 'learning materials', 'lectures', 'massive open online courses', 'meetings', 'multidisciplinary', 'neuroimaging', 'new technology', 'novel strategies', 'open source', 'operation', 'process repeatability', 'programs', 'research study', 'skills', 'statistics', 'teacher', 'tutoring']",NIBIB,JOHNS HOPKINS UNIVERSITY,R25,2016,209444,0.030873475160192447
"UTMB Clinical and Translational Science Award UTMB's CTSA-linked KL2 Scholars Program addresses the significant need for developing future clinical and translational (C&T) investigators, with emphases on team-based research, leadership development, and mentorship training. In our new CTSA hub, we will build on our current CTSA's successes over the past 5½ years, with unique innovative integration of exceptional training approaches, including: 1) mentored career development within CTSA-supported multidisciplinary translational teams (MTTs); 2) an emphasis on individual development plans (IDPs) and pre-established C&T research competencies tailored to the needs of the individual scholar, but also emphasizing team-based competencies; 3) development of leadership competencies through participation in a new Leadership Development Academy; 4) an Academy of Research Mentors (ARM), based within our Institute for Translational Sciences (ITS), to foster mentoring and mentor training; 5) a linked Translational Research Scholars Program (TRSP), which provides an expanded peer group and a wider impact across the institution, with twice-monthly career development seminars and a focus on scholars' research; 6) development of entrepreneurial skills and leadership through participation in a UT System-funded Healthcare Entrepreneurship Program; and 7) collaboration and dissemination of program experience to other CTSA hubs in the Texas Regional CTSA Consortium, and the national CTSA Consortium. An important feature of our KL2 Scholars Program is its linked position within the continuum of career development, from graduate student training in our CTSA TL1 Training Core to the production of independently funded C&T faculty members. Our program is enhanced with by financial support from our Provost's office for scholar expenses, ITS education administrators, the ARM, and the Office of Faculty Affairs, which is focused on faculty development at UTMB. UTMB also ranks nationally in promoting diversity, which will enhance our recruitment of underrepresented minority scholars by the participation of faculty from our Hispanic Center of Excellence, and our Medical School Enrichment Program. Our KL2 Program is well-integrated with other institutional education activities, including our Human Pathophysiology and Translational Medicine graduate program, and courses targeted toward scientific writing, biostatistics, and study design. Early-career faculty as Phase 1 TRSP scholars can compete to become CTSA-supported KL2 Scholars, and with acquisition of their first mentored K-level grants (e.g., K08), advance to a Phase 2 TRSP Scholar, then focusing on the transition from mentored to independent grant funding. Upon acquisition of independent (e.g. R01) funding, scholars advance to become Phase 3 TRSP Scholars and Associate Members in the ARM, to facilitate their development of mentoring skills, and eventually to full ARM membership, with demonstrated success in C&T science mentoring. Our KL2 Scholars Program thus integrates novel team-based training, leadership, and mentoring approaches to foster the career development of future leaders in C&T research. n/a",UTMB Clinical and Translational Science Award,9128789,KL2TR001441,"['Academy', 'Address', 'Administrator', 'Award', 'Biological', 'Biological Markers', 'Biometry', 'Biopsy', 'Body Surface Area', 'Burn injury', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Collaborations', 'Data', 'Dependence', 'Development', 'Development Plans', 'Down-Regulation', 'Education', 'Enrollment', 'Entrepreneurship', 'Evolution', 'Faculty', 'Financial Support', 'Fostering', 'Freezing', 'Functional disorder', 'Funding', 'Future', 'Gene Expression', 'Genes', 'Genomics', 'Grant', 'Healthcare', 'Hepatitis C virus', 'Hispanics', 'Human', 'Individual', 'Infection', 'Inflammation', 'Institutes', 'Institution', 'Interferons', 'Intervention', 'Lead', 'Leadership', 'Link', 'Liver Fibrosis', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Medicare', 'Medicare claim', 'Medicine', 'Mentors', 'Mentorship', 'MicroRNAs', 'Modeling', 'Molecular Profiling', 'NCI Scholars Program', 'Organ failure', 'Participant', 'Pathway interactions', 'Patients', 'Peer Group', 'Phase', 'Physicians', 'Positioning Attribute', 'Process', 'Production', 'Protocols documentation', 'Regimen', 'Research', 'Research Design', 'Research Personnel', 'Rice', 'Structure', 'System', 'TNFSF15 gene', 'Teacher Professional Development', 'Techniques', 'Testing', 'Texas', 'Time', 'Tissues', 'Training', 'Translational Research', 'Underrepresented Minority', 'Variant', 'Writing', 'base', 'career development', 'cohort', 'college', 'demographics', 'early-career faculty', 'experience', 'graduate student', 'innovation', 'leadership development', 'liver biopsy', 'medical schools', 'member', 'microbial', 'multidisciplinary', 'novel', 'outcome forecast', 'peripheral blood', 'predict clinical outcome', 'program dissemination', 'programs', 'response', 'science education', 'skills', 'student training', 'success', 'translational medicine']",NCATS,UNIVERSITY OF TEXAS MED BR GALVESTON,KL2,2016,423432,0.029434272522208087
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,9103879,U54EB020405,"['Accelerometer', 'Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Big Data to Knowledge', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Science', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Mental Depression', 'Methods', 'Mission', 'Modality', 'Modeling', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Walking', 'Work', 'base', 'big biomedical data', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'experience', 'flexibility', 'health data', 'improved', 'improved outcome', 'industry partner', 'insight', 'massive open online courses', 'models and simulation', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'prevent', 'programs', 'public health relevance', 'reduce symptoms', 'role model', 'sensor', 'social', 'social model', 'tool', 'visiting scholar']",NIBIB,STANFORD UNIVERSITY,U54,2016,401742,0.011286591842367941
"Center for Environmental Genetics     DESCRIPTION (provided by applicant)        It is a priority of the CEG and the Career Development Program to identify and develop the careers of promising early stage investigators. To accomplish this goal, the overall objective of the career development program (CDP) is to recruit, enrich, encourage, and provide resources and mentoring activities to investigators at the graduate, postgraduate and early faculty levels with a particular emphasis on environmental health science. The CDP has forged new cross-disciplinary partnerships in areas applicable to environmental health science with basic, epidemiological, and/or clinical studies including studies in molecular genetics and environmental epidemiology and environmental toxicology.  To accomplish the overall objective, the CDP has developed a highly innovative approach with three specific.  Aim 1 is to attract, recruit and promote opportunities for junior faculty (within three years from initial appointment) towards development of an independent career interfacing between basic, translational or clinical investigations with application to environmental health science. The Next Generation Biomedical Investigator (NGBI) program is the principal mechanism for achieving this aim.  Aim 2 is to identify investigators with less experience (novice investigators) who are still in trainin with minimal experience but have an interest in examining the intricate role of environmental health science in health and disease. Recruits include physicians in their academic fellowship i.e. post residency, who are obtaining an MS or Ph.D, mentored postdoctoral Ph.D. fellows or advanced (third or fourth year) pre-doctoral research students. This aim is achieved by supplementing novice investigators' training with research resources, mentoring and career development opportunities through the New Investigator Scholar (NIS) pathway.  Aim 3 is to enrich training/scientific experiences, promote career opportunities and networking experiences, activities integrated with the Administrative and other CEG cores. The objective is to develop NGBIs and NISs and others new to environmental health science by enriching experiences as an investigator and eventually independent scientist. Thus, these aims are achieved through financial awards, mentorship, access to core resources and other career development activities.                  Our environmental health center focuses on understanding how genes and environment affect our health,  serving the residents, communities of Ohio, the nation and the globe by generating knowledge that is  applicable to the general public and policymakers for healthier living.",Center for Environmental Genetics,9044557,P30ES006096,"['Acute', 'Affect', 'Air', 'Allergic Disease', 'Area', 'Arteries', 'Attention', 'Barker Hypothesis', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cells', 'Chronic', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Community Outreach', 'Complex', 'Core Facility', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Dose', 'Economics', 'Educational workshop', 'Endocrine disruption', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Epigenetic Process', 'Equilibrium', 'Equipment', 'Evolution', 'Exposure to', 'Funding', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Health', 'Health Sciences', 'Health education', 'Human', 'Human Genome Project', 'Immune System Diseases', 'Individual', 'Informatics', 'Integrative Medicine', 'Knowledge', 'Lead', 'Life', 'Life Style', 'Link', 'Machine Learning', 'Medicine', 'Mentors', 'Mission', 'Monozygotic twins', 'Nature', 'Neurology', 'Ohio', 'Organ', 'Outcome', 'Phenotype', 'Pilot Projects', 'Population', 'Power Plants', 'Predisposition', 'Public Health', 'Request for Applications', 'Research Personnel', 'Route', 'Series', 'Staging', 'Systems Biology', 'Technology', 'Time', 'Translating', 'Translations', 'Transportation', 'Update', 'Vision', 'Work', 'base', 'career development', 'clinical practice', 'disorder prevention', 'disorder risk', 'environmental agent', 'epigenome', 'experience', 'gene environment interaction', 'genome wide association study', 'health science research', 'high risk', 'human capital', 'innovation', 'insight', 'lipid disorder', 'malignant endocrine gland neoplasm', 'member', 'multidisciplinary', 'next generation sequencing', 'programs', 'response', 'success', 'symposium']",NIEHS,UNIVERSITY OF CINCINNATI,P30,2016,1729509,0.01971467761630971
"The q-bio Summer School DESCRIPTION (provided by applicant): The purpose of the Annual q-bio Summer School, founded in 2007 in Los Alamos, NM, is to advance predictive modeling of cellular regulatory systems by providing trtaining in mathematical, statistical, and computational techniques that are important in systems and synthetic biology. A secondary goal is to advance the careers of researchers new to quantitative biology. The school consists of courses in six subjects: 1) stochastic gene regulation, 2) cell signaling, 3) biomolecular simulations, 4) viral dynamics, 5) synthetic biology, and 6) computational neuroscience. Demand for training in quantitative biology is increasing rapidly-the number of qualified summer school applicants increased from fewer than 40 in 2010 to over 170 in 2012. In response to this demand, we expanded the school in 2012 to accommodate more students. The school now takes place at two campuses, in Santa Fe, NM (courses 1-4) and in San Diego, CA (courses 5-6). Approximately 30 students attend at each campus and are diverse in terms of educational background (mathematics, engineering, physical sciences, and biology), career level (~75% are graduate students, ~20% are postdocs, and ~5% are more advanced), and demographics (gender, race, ethnicity, and worldwide geographical origin). Students attend all core lectures in the courses offered at their campus, as well as specialized course-specific lectures, student get-to-know-me talks, and other talks (e.g., talks focused on career skills), and participate in hands-on computer labs and mentored projects. After two intensive weeks, all students gather in Santa Fe for a 2-day q- bio Student Symposium, which features student projects reports, student poster presentations, and external invited speakers. All students then attend the 4-day q-bio Conference, an international conference attended by >200 researchers. All q-bio Summer School participants can expect the following: a) broad exposure to mathematical/statistical/computational tools used in quantitative biology, b) in-depth training in techniques of special interest (i.e., in one of the six course subjects) through course-specific lectures, computer labs, and mentored projects; c) multiple opportunities to practice scientific communication through talks and poster presentations; d) exposure to cutting-edge research, and e) extensive networking opportunities with peers and thought leaders. Lecturers and speakers include more than 50 different researchers active in quantitative biology, including very distinguished scientists. For example, in 2013, confirmed lecturers include six academicians. By the time the students attend the q-bio Conference, they are equipped with a powerful social network that facilitates interactions, idea exchange, and initiation of collaborative research. The long-term goal of the school is to change the way biological research is conducted, making biology a more quantitative field, like physics and chemistry. In this effort, the organizers are supported by significant goodwill from the international quantitative biology community and a number of local institutions, including two national centers for systems biology. However, to maintain and improve the school, additional financial support is required. PUBLIC HEALTH RELEVANCE: Many future biomedical and biotechnological advances in synthetic and systems biology will require investigators who have the ability to carefully integrate quantitative experimentation with mathematical, statistical and computational modeling. The goal of the q-bio Summer School is to prepare a new generation of quantitative biologists who are adept at modeling and/or working with modelers to advance our predictive understanding of cellular regulatory systems. The complexity and importance of these systems, which govern cellular activities and fates, provides motivation for developing a scientific and engineering workforce equipped to deal with the complexity.",The q-bio Summer School,9002062,R25GM105608,"['Behavior', 'Bioinformatics', 'Biological', 'Biology', 'Career Choice', 'Career Mobility', 'Cell model', 'Cell physiology', 'Cells', 'Chemistry', 'Communication', 'Communities', 'Complex', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Cues', 'Data', 'Education', 'Educational Background', 'Educational Curriculum', 'Educational workshop', 'Engineering', 'Ethnic Origin', 'Event', 'Exposure to', 'Financial Support', 'Funding', 'Future', 'Gender', 'Gene Expression Regulation', 'Generations', 'Goals', 'Health', 'Heterogeneity', 'Immune system', 'Individual', 'Institution', 'International', 'Internet', 'Machine Learning', 'Mathematics', 'Mentors', 'Minority-Serving Institution', 'Modeling', 'Molecular', 'Motivation', 'National Institute of General Medical Sciences', 'Neurons', 'Occupations', 'Participant', 'Physics', 'Population', 'Postdoctoral Fellow', 'Professional Competence', 'Qualifying', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Scientist', 'Series', 'Signal Transduction', 'Social Network', 'Statistical Data Interpretation', 'Statistical Models', 'Students', 'Synthetic Genes', 'System', 'Systems Biology', 'Techniques', 'Time', 'Training', 'Underrepresented Groups', 'United States National Institutes of Health', 'Viral', 'Woman', 'Work', 'biochemical model', 'biological research', 'career', 'career development', 'computational neuroscience', 'computerized tools', 'demographics', 'graduate student', 'improved', 'interest', 'learning materials', 'lecture notes', 'lecturer', 'lectures', 'mathematical model', 'member', 'model design', 'multidisciplinary', 'peer', 'physical science', 'posters', 'predictive modeling', 'programs', 'research study', 'response', 'simulation', 'skills', 'statistics', 'symposium', 'synthetic biology', 'tool']",NIGMS,"NEW MEXICO CONSORTIUM, INC.",R25,2016,168780,0.03609728491431856
"Multimodal Biomarkers in Frontotemporal Lobar Degeneration DESCRIPTION (provided by applicant): This K01 award will support my development as an independent investigator with a translational research program that specializes in the cognitive and biological basis of neurodegenerative diseases such as frontotemporal lobar degeneration (FTLD). Candidate: My research experience as a cognitive neuroscientist ideally positions me to achieve my career goal of becoming an independent investigator with expertise on the cognitive and biological basis of neurodegenerative disease. I have strong cognitive training with an M.Sc in Psycholinguistics and Ph.D in Psychology from the University of Edinburgh, where I was supported by an NRSA Individual Predoctoral Award. During my postdoctoral IGERT fellowship at the Institute for Research in Cognitive Science at the University of Pennsylvania, I was awarded an NRSA Individual Postdoctoral Fellowship Award to investigate the role of decision-making in language. In this research I have gained experience investigating neurodegenerative disease patients comparatively in order to obtain converging evidence to complement fMRI studies of healthy adults. I have become increasingly interested in translating my research to optimize the diagnosis and treatment of patients with neurodegenerative diseases. I was recently award the Society for the Neurobiology of Language Postdoctoral Merit Award in recognition of my novel research investigating how social limitations in patients contribute to difficulty in discourse. I have committed to four years of clinical research the NIH Loan Repayment Program, and I intend to commit to clinical research for the duration of my career. I have learned that cognitive and neuroimaging studies provide only one perspective on neurodegenerative diseases. In this proposal, I plan to gain the necessary expertise in biological aspects of FTLD and related conditions to complement my past experiences, and thus achieve my goal of becoming a multifaceted independent investigator with expertise in the cognitive and biological basis for neurodegenerative diseases. With the support of this K01, I will develop expertise to conduct investigations of cerebrospinal fluid (CSF), genetic, and neuropathological aspects of neurodegenerative diseases. I will ultimately integrate the biological expertise gained in this proposal with language studies from my cognitive neuroscience research in an effort to identify non-invasive biomarkers that can be used to screen patients for clinical trials and to measure the efficacy of disease-modifying agents. Environment: This award will be conducted at the Perelman School of Medicine at the University of Pennsylvania in the Department of Neurology, the Center for Neurodegenerative Disease Research (CNDR), and the Penn Bioinformatics Center where I have strong institutional support. The proposed institution is an exceptional environment that has expert centers for neuroimaging, cerebrospinal fluid biomarker analysis, a leading genetic research core, expert neuropathology, outstanding biostatisical support, and relevant clinical research laboratories. The University of Pennsylvania is unique in comparison to other institutions in the country because all of the above methods are available in one center. My mentor, Dr. Murray Grossman, and my co-mentor, Dr. John Trojanowksi, have international reputations for neurodegenerative disease research. My career development will also be supported by my co-mentor, Dr. Lyle Ungar, who has extensive expertise in statistical learning algorithms and in the analysis of proteomic and genomics datasets. Together, this mentorship team will facilitate my development as an independent investigator by providing access to existing and future collaborators, laboratory resources, and exceptional training environments. The CNDR is a world- leading center for neurodegenerative disease research with human and animal models of disease and exceptional translational science. Biofluid biomarker experience is extensive, and several national biofluid cores are centered at Penn (e.g. ADNI). There is a wealth of internationally-recognized neuroimaging expertise at the University of Pennsylvania in the Penn Imaging and Computer Science Laboratory, and I will benefit by integrating neuroimaging resources from these facilities with other modalities of biomarker research. Training: I will develop my expertise in the biological basis of neurodegenerative disease with the support of my mentor, Dr. Murray Grossman, and my co-mentors, Dr. John Trojanowski and Dr. Lyle Ungar. Specifically, with Dr. Trojanowksi I will engage in training related to biofluid and genetic biomarkers of FTLD. I will develop advanced neuroimaging skills and cutting-edge biostatistical methods with Dr. Ungar. Each of these training modalities will be supported by complementary formal coursework, participation in seminars, attendance of conferences, and regularly scheduled meetings with mentorship team. Research: FTLD is a neurodegenerative disease affecting approximately 15 out of 100,000 individuals. In recent years detailed neuropathological investigations at autopsy have demonstrated distinct sources of histopathological abnormalities in FTLD, including the presence of tau inclusions (FTLD-tau) and TDP-43 proteinopathies (FTLD-TDP). However, there are currently no in vivo methods for discriminating between FTLD-tau and FTLD-TDP. There is an urgent need to improve the in vivo diagnosis of FTLD to appropriately enter patients into emerging clinical trials, and to develop sensitive and specific endpoints in trials that can quantify response to these treatments. The overall research aim of this proposal is to develop multimodal methods to improve in vivo diagnosis of FTLD. PUBLIC HEALTH RELEVANCE: Frontotemporal lobar degeneration (FTLD) affects approximately 15 out of 100,000 adults. Detailed neuropathological investigations at autopsy have identified two distinct sources of histopathological changes that contribute to FTLD. However, there are currently no in vivo methods for diagnosing pathological subtypes of FTLD. There is an urgent need to identify in vivo diagnosis methods to facilitate the identification of appropriate patients to enter into emerging disease-modifying drug treatment trials. The overall aim of this project is to identify multimodal biomarkers of FTLD.",Multimodal Biomarkers in Frontotemporal Lobar Degeneration,9068732,K01AG043503,"['Address', 'Adult', 'Affect', 'Algorithms', 'Animal Disease Models', 'Animal Model', 'Area', 'Atrophic', 'Autopsy', 'Award', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biostatistical Methods', 'Cerebrospinal Fluid', 'Clinical Research', 'Clinical Trials', 'Cognitive', 'Cognitive Science', 'Comparative Study', 'Complement', 'Country', 'DNA Sequence Alteration', 'DNA-Binding Proteins', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Doctor of Philosophy', 'Environment', 'Fellowship', 'Foundations', 'Frontotemporal Lobar Degenerations', 'Functional Magnetic Resonance Imaging', 'Future', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genomics', 'Goals', 'Gold', 'Human', 'Image', 'Individual', 'Institution', 'International', 'Investigation', 'Laboratories', 'Language', 'Learning', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Microscopic', 'Modality', 'National Research Service Awards', 'Nerve Degeneration', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurology', 'Neurosciences Research', 'Pathology', 'Patient Monitoring', 'Patients', 'Pennsylvania', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Positioning Attribute', 'Primary Progressive Aphasia', 'Process', 'Proteomics', 'Proxy', 'Psycholinguistics', 'Psychology', 'Rare Diseases', 'Research', 'Research Institute', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Scientist', 'Semantics', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Societies', 'Source', 'Training', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Work', 'accurate diagnosis', 'base', 'behavioral variant frontotemporal dementia', 'candidate marker', 'career', 'career development', 'clinical phenotype', 'cognitive neuroscience', 'cognitive training', 'cohort', 'computer science', 'diagnostic accuracy', 'experience', 'follow-up', 'genome wide association study', 'gray matter', 'improved', 'in vivo', 'individual patient', 'interest', 'longitudinal course', 'medical schools', 'meetings', 'neuroimaging', 'neuropathology', 'novel', 'pre-doctoral', 'prediction algorithm', 'programs', 'public health relevance', 'response', 'screening', 'skills', 'social', 'symposium', 'tau Proteins', 'tool', 'treatment response', 'treatment trial', 'white matter']",NIA,UNIVERSITY OF PENNSYLVANIA,K01,2016,128358,-0.0025158587217945774
"Transforming Analytical Learning in the Era of Big Data ﻿    DESCRIPTION (provided by applicant): In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio) statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offer and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will draw from the expertise and experience of faculty from four different departments within four different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts, and Information Science in the School of Information. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high-dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and imaging. The diseases and conditions they study include obesity, cancer, diabetes, cardiovascular disease, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and response for our pilot offering in 2015 with 153 applications for 20 positions and a yield rate of 80% from the offers we extended. We plan to build on the success of this initial offering in the next three year funding cycle of this grant (2016-2018). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a no-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 30 undergraduates nationally and expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world.         PUBLIC HEALTH RELEVANCE: We propose a six week long summer institute: ""Transforming Analytical Learning in the Era of Big Data"" to be held at the Department of Biostatistics, University of Michigan, Ann Arbor, with a group of approximately 30 undergraduates recruited nationally, from 2016-2018. We plan to expose them to diverse techniques, skills and problems in the field of Big Data. They will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Statistics, Computer Science and Engineering, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by UM researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm.            ",Transforming Analytical Learning in the Era of Big Data,9044118,R25EB022363,"['Adverse drug effect', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Behavioral Sciences', 'Big Data', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Case Study', 'Code', 'Collection', 'Computing Methodologies', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Engineering', 'Epigenetic Process', 'Faculty', 'Funding', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Image', 'Imagery', 'Information Sciences', 'Injury', 'Institutes', 'Kidney Diseases', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Prevention', 'Public Health Informatics', 'Public Health Schools', 'Recruitment Activity', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Statistical Methods', 'Students', 'Talents', 'Techniques', 'Training', 'Universities', 'Work', 'base', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'design', 'experience', 'graduate student', 'instructor', 'interest', 'lectures', 'meetings', 'member', 'metabolomics', 'nervous system disorder', 'next generation', 'open source', 'personalized medicine', 'posters', 'programs', 'public health relevance', 'response', 'signal processing', 'skills', 'statistics', 'success', 'symposium', 'tool', 'undergraduate student', 'wiki']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2015,159359,0.051481843489061756
"Analytical Approaches to Massive Data Computation with Applications to Genomics DESCRIPTION (provided by applicant): We propose to design and test mathematically well founded algorithmic and statistical tectonics for analyzing large scale, heterogeneous and noisy data. We focus on fully analytical evaluation of algorithms' performance and rigorous statistical guarantees on the analysis results. This project will leverage on the PIs' recent work on cancer genomics data analysis and rigorous data mining techniques. Those works were driven by specific applications, while in the current project we aim at developing general principles and techniques that will apply to a broad sets of applications. The proposed research is transformative in its emphasis on rigorous analytical evaluation of algorithms' performance and statistical measures of output uncertainty, in contrast to the primarily heuristic approaches currently used in data ming and machine learning. While we cannot expect full mathematical analysis of all data mining and machine learning techniques, any progress in that direction will have significant contribution to the reliability and scientific impact of this discipline. While ou work is motivated by molecular biology data, we expect the techniques to be useful for other scientific communities with massive multi-variate data analysis challenges. Molecular biology provides an excellent source of data for testing advance data analysis techniques: specifically, DNA/RNA sequence data repositories are growing at a super-exponential rate. The data is typically large and noisy, and it includes both genotype and phenotype features that permit experimental validation of the analysis. One such data repository is The Cancer Genome Atlas (TCGA), which we will use for initial testing of the proposed approaches. RELEVANCE (See instructions): This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas. This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas.",Analytical Approaches to Massive Data Computation with Applications to Genomics,8825472,R01CA180776,"['Advocate', 'Algorithms', 'Area', 'Big Data', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Discipline', 'Effectiveness', 'Evaluation', 'Evidence Based Medicine', 'Genomics', 'Genotype', 'Health', 'Human Genome', 'Instruction', 'Machine Learning', 'Measures', 'Molecular Biology', 'Output', 'Performance', 'Phenotype', 'RNA Sequences', 'Research', 'Social Policies', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Uncertainty', 'Validation', 'Work', 'base', 'cancer genome', 'cancer genomics', 'data mining', 'design', 'heuristics', 'mathematical analysis', 'transcriptome sequencing']",NCI,BROWN UNIVERSITY,R01,2015,71329,-0.008706530664271022
"Summer Institute for Statistics of Big Data DESCRIPTION:  Funding is sought for the Summer Institute for Statistics of Big Data (SISBID) at the University of Washington. This program will provide workshops on the statistical and computational skills needed to access, process, manage, and analyze large biomedical data sets. It will be co-directed by Ali Shojaie and Daniela Witten, faculty in the Department of Biostatistics at University of Washington.  The SISBID program will consist of five 2.5-day in-person courses, or modules, taught at the University of Washington each July. An individual participant can register for whichever set of modules he or she chooses. The five modules are as follows: (1) Accessing Biomedical Big Data; (2) Data Visualization; (3) Supervised Methods for Statistical Machine Learning; (4) Unsupervised Methods for Statistical Machine Learning; (5) Reproducible Research for Biomedical Big Data. Each module will consist of a combination of formal lectures and hands-on computing labs. Participants will work together in teams in order to apply the skills that they develop in each module to important problems drawn from relevant case studies.  The primary audience for SISBID will consist of biomedical scientists who would like to develop the statistical and computational training needed to make use of Biomedical Big Data. The secondary audience will consist of individuals with stronger statistical or computational backgrounds but little exposure to biology, who will learn how to apply their skills to problems associated with Biomedical Big Data. Participants will include advanced undergraduates, graduate students, post-doctoral fellows, and researchers, and will be drawn from industry, government, and academia. In order to ensure that all participants are able to fully engage in the program, participants will be expected to already have some prior background in R programming and statistical inference, which can be obtained by taking two free online courses before the program begins.  Each of the five modules will be co-taught by two instructors. The ten instructors will be drawn from top universities and research centers across the U.S., such as the University of Washington, Rice University, University of Iowa, Johns Hopkins University, MD Anderson Cancer Research Center, Fred Hutchinson Cancer Research Center, and University of North Carolina. They have been selected based on research expertise and excellence in teaching.  Lecture videos and slides will be made freely available online so that individuals who are unable to attend SISBID in person can still benefit from the program.  This proposal specifically requests funds for 55 student / postdoctoral fellow travel scholarships per year, 130 student / postdoctoral fellow registration scholarships per year, instructor travel and stipends, teaching assistant stipends, and PI salary support. PUBLIC HEALTH RELEVANCE:   In recent years, the biomedical sciences have been inundated by Big Data, such as DNA sequence data and electronic medical records. In principle, it should be possible to use such data for a variety of tasks, such as predicting an individual's risk of developing diabetes or cancer, and tailoring therapies to an individual should he or she become ill. The Summer Institute for Statistics of Big Data will provide biomedical researchers with the computational and statistical training needed in order to take advantage of Big Data, so that they can more effectively use it to understand human diseases and to improve human health.",Summer Institute for Statistics of Big Data,8935790,R25EB020380,"['Academia', 'Area', 'Big Data', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Biometry', 'Cancer Center', 'Case Study', 'Collection', 'Computer software', 'Computerized Medical Record', 'DNA Sequence', 'Data', 'Data Set', 'Diabetes Mellitus', 'Educational process of instructing', 'Educational workshop', 'Ensure', 'Environment', 'Exposure to', 'Faculty', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Government', 'Health', 'Human', 'Hybrids', 'Imagery', 'Individual', 'Industry', 'Institutes', 'Iowa', 'Knowledge', 'Learning', 'Learning Module', 'Machine Learning', 'Malignant Neoplasms', 'NCI Center for Cancer Research', 'North Carolina', 'Participant', 'Persons', 'Postdoctoral Fellow', 'Process', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rice', 'Risk', 'Running', 'Scholarship', 'Science', 'Slide', 'Statistical Computing', 'Statistical Methods', 'Students', 'Training', 'Training Activity', 'Training Programs', 'Travel', 'United States', 'Universities', 'Videotape', 'Wages', 'Washington', 'Work', 'base', 'biomedical scientist', 'data visualization', 'graduate student', 'human disease', 'improved', 'instructor', 'lectures', 'member', 'open source', 'programs', 'skills', 'statistics', 'teacher', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R25,2015,159605,0.03365752280156542
"Informatics Tools for High-Throughput Sequences Data Analysis DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK. The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.",Informatics Tools for High-Throughput Sequences Data Analysis,8788050,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'insertion/deletion mutation', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2015,967608,-0.019689335143351923
"The Big DIPA: Data Image Processing and Analysis ﻿    DESCRIPTION (provided by applicant): This proposal aims to establish a national short course in Big Data Image Processing & Analysis (BigDIPA) intended to increase the number and overall skills of competent research scientists now encountering large, complex image data sources derived from cutting edge biological/biomedical research approaches. Extraction of knowledge from these imaging sources requires specialized skills and an interdisciplinary mindset. Yet effective training opportunities of this sector of the ""Big Data"" science community are glaringly underappreciated and underserved compared to other big data fields such as omics. UC Irvine is ideally suited to host a short course to address this thematic training deficit on account of the synergistic colocalization between multiple facilities, renowned for development of numerous advanced imaging techniques, and the outstanding instructional environment provided by faculty with collaborative expertise in biological image processing and computer vision, bioinformatics and high performance computational approaches.  Specifically, our BigDIPA proposal assembles an interdisciplinary alliance of faculty experts that can leverage the preeminent imaging resource facilities, such as the Laboratory of Fluorescence Dynamics (LFD) and the Beckman Laser Institute, and fuse these to ongoing campus big data initiatives, e.g. UCI's Data Science Initiative, to create a top-rated training course designed for senior graduate students, postdoctoral researchers, faculty and industry scientists from diverse scientific disciplines who have nascent interests and needs to handle BIG DATA sources beyond their current level of competency.  The course theme is focused to utilize discreet examples drawn from the analysis of complex data acquired from different microscopy imaging modalities employed to investigate dynamics in cellular and tissue processes, including signal transduction networks, development, neuroscience and biomedical applications, and that hereto where hidden or inaccessible to standard methods of analysis. Participants will be guided along the complete acquisition- processing-analysis pipeline through exposure to a coherent progression of topics and issues typically encountered when handling BIG DATA. We believe this training approach will therefore be attractive to a broad and significant untapped pool of researchers from the biological disciplines, biomedical engineering, systems biology, math, biophysics, computer science, bioinformatics and statistics who possess some, but not all, of the requisite competencies to effectively traverse the BD2K landscape. We have designed the course such that skills and experience gained by trainees will be transferable to their own research interests.  The BigDIPA course format will combine didactic lectures on the theory and foundational frameworks that underpin each step, with practical instruction on implementation and hands-on tutorials in image acquisition, large data handling, basic scripting of computational tools, image processing on high performance computing architectures, as well as feature extraction, evaluation and visualization of results. The course is designed to offer an intense learning experience delivered in a compact time frame, and opportunities to foster interdisciplinary interactions through small team exercises. Participants will also be encouraged to take advantage of pre-courses - separate and distinct training opportunities not funded by this proposal - that will be coordinated to directly precede our course. This unique format provides multiple benefits: it provides an efficient mechanism to address individual participant training deficiencies to permit a more productive experience in the BigDIPA course, adds no-cost mutual benefits to independent but synergistic programs, and facilitates recruitment of applicants who frequently feel interested but intimidated due to a perceived lack of prior adequate training.  Beyond providing an intensive on-site training course, all course materials (lecture notes, video lectures and tutorials), tutorial exercises, open source software resources and sample datasets will be made freely available through on-line distribution to maximize outreach and encourage additional contributions of curated training resources solicited from the community.         PUBLIC HEALTH RELEVANCE: We propose to train and expand the cadre of researchers capable of effectively using the deluge of complex BIG DATA being generated by advanced biomedical imaging approaches. These data sources represent a rich source of complex information relevant to many scientific areas of inquiry, and are informative at multiple scales ranging from fundamental biological processes at the cellular level to patient diagnostics for diseases such as cancer or neurological disorders.            ",The Big DIPA: Data Image Processing and Analysis,9044533,R25EB022366,"['Accounting', 'Address', 'Architecture', 'Area', 'Big Data', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biomedical Engineering', 'Biomedical Research', 'Biomedical Technology', 'Biophysics', 'Cell physiology', 'Communities', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Set', 'Data Sources', 'Development', 'Diagnostic', 'Discipline', 'Disease', 'Education', 'Educational Curriculum', 'Educational workshop', 'Environment', 'Evaluation', 'Exercise', 'Exposure to', 'Faculty', 'Fluorescence', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Industry', 'Information Sciences', 'Institutes', 'Instruction', 'Interdisciplinary Communication', 'Knowledge', 'Knowledge Extraction', 'Laboratories', 'Lasers', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Methods', 'Microscopy', 'Modality', 'NIH Program Announcements', 'National Institute of General Medical Sciences', 'Neurosciences', 'Participant', 'Patients', 'Performance', 'Problem Solving', 'Process', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Sampling', 'Schools', 'Science', 'Scientist', 'Senior Scientist', 'Signal Transduction', 'Site', 'Software Tools', 'Source', 'Staging', 'Stream', 'Systems Biology', 'TNFRSF5 gene', 'Time', 'Training', 'United States National Institutes of Health', 'Work', 'bioimaging', 'biological systems', 'biomedical scientist', 'citizen science', 'computer science', 'computerized tools', 'cost', 'data acquisition', 'data format', 'demographics', 'design', 'experience', 'flexibility', 'graduate student', 'image processing', 'imaging modality', 'interdisciplinary collaboration', 'interest', 'lecture notes', 'lectures', 'meetings', 'nervous system disorder', 'open source', 'outreach', 'programs', 'public health relevance', 'repository', 'skills', 'statistics', 'theories', 'tissue processing']",NIBIB,UNIVERSITY OF CALIFORNIA-IRVINE,R25,2015,161997,0.023675917023469984
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,8935748,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Research', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Scientist', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'clinical investigation', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2015,73173,0.00016662745926958368
"Reactome: An Open Knowledgebase of Human Pathways DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community. RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.",Reactome: An Open Knowledgebase of Human Pathways,8840984,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablet Computer', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2015,1243799,-0.009336077991975673
"Developing Cloud-based tools for Big Neural Data DESCRIPTION (provided by applicant): Big data has the potential to dramatically advance the electrophysiology biodata sciences in similar ways that it has transformed Genetics. Differences between these two areas dictate separate approaches to apply Big Data tools, and methods in order to provide successful assets to the research community. For one, neural datasets are very heterogeneous by nature. The data is difficult to interpret without knowing specifics about the data acquisition protocol, the experimental paradigm and the physiological state of the recorded subject. Many neural datasets are complemented with complex meta-data sets, which should be an integral component in any effort to integrate and share these data with other researchers. The goal of this project is to develop novel, generalizable Big Data tools to facilitate cloud-base analysis of complex multi-scale neural data. Epilepsy research will be used as a specific use case to guide the development of the tools. A cohort of established senior investigators performing epilepsy research will use and validate these tools in their laboratories. Epilepsy research is currently limited by its narrow focus on single models (animal or human) in individual centers and laboratories. Just as Genetics was revolutionized through Big Data techniques, so too can Epilepsy research be transformed through novel approaches to standardize, share, and mine data across groups of investigators. Over the past several years I have co-developed a NINDS funded cloud-based data platform, ://ieeg.org, giving me a central role in developing Big Data solutions for neural data, such as customized data sharing, large-scale cloud-based data analysis, and search and interrogation techniques for complex data and metadata. My scientific objectives for this project are: (1) to develop generalizable tools to curate, analyze, and interrogate multi-scale neural data, and (2) to create a platform that will galvanize a research community focused on sharing data, and methods to advance Big Data research in the basic and translational neurosciences. Equally important to this proposal, I present a training plan to prepare me for an academic career focused on Big Data in the neurosciences. This plan supplements my background in bioengineering and statistical modeling of neural data with broader data-science expertise in data integration and machine learning, and deeper domain knowledge of the clinical neurosciences. I have assembled a group of collaborators, basic investigators and clinician scientists, who will use the tools developed in this project to analyze and validate their data and methods. I will use the results of this project as the foundation for a R01 Grant application, in which I will expand the developed platform and tools to target other research domains (TBI, Emergency Care, Cardiac), as well as integrate other data-modalities such as Imaging, and Genomics. OMB No. 0925-0001/0002 (Rev. 08/12 Approved Through 8/31/2015) Page Continuation Format Page PUBLIC HEALTH RELEVANCE: The goal of this proposal is to advance Big Data research in the neurosciences by developing tools and techniques to interrogate electrophysiology data sets from animal models of human neurological disorders. Development of these tools requires close collaboration between domain experts in Neuroscience, Machine Learning, Statistics and Computer Science. When developed, this platform and these tools will allow investigators to share, collaborate, annotate, standardize and analyze large, complex, multiscale data sets that are a crucial first step in advancing this field.",Developing Cloud-based tools for Big Neural Data,8935817,K01ES025436,"['Animal Model', 'Applications Grants', 'Area', 'Big Data', 'Biomedical Engineering', 'Cardiac', 'Clinical', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Electrophysiology (science)', 'Emergency Care', 'Epilepsy', 'Evaluation', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Image', 'Incentives', 'Individual', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Metadata', 'Methods', 'Mining', 'Modality', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Neurosciences', 'Organism', 'Performance', 'Physiological', 'Process', 'Protocols documentation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Science', 'Scientist', 'Series', 'Solutions', 'Standardization', 'Statistical Models', 'Techniques', 'Time', 'Training', 'base', 'career', 'cloud based', 'cohort', 'comparative', 'computer science', 'data acquisition', 'data integration', 'data management', 'data mining', 'data sharing', 'improved', 'nervous system disorder', 'novel', 'novel strategies', 'relating to nervous system', 'statistics', 'tool', 'tool development', 'translational neuroscience']",NIEHS,UNIVERSITY OF PENNSYLVANIA,K01,2015,192201,-0.006606162014265987
"EDAC: ENCODE Data Analysis Center DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health. RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8889700,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2015,2005492,0.004088077486549261
"Boosting the Translational Impact of Scientific Competitions by Ensemble Learning ﻿    DESCRIPTION (provided by applicant): ""Big data"" such as those arising from sequencing, imaging, genomics and other emerging technologies are playing a critical role in modern biology and medicine. The generation of hypotheses about biological processes and disease mechanisms is now increasingly being driven by the production and analysis of large and complex datasets. Advanced computational methods have been developed for the robust analysis of these datasets, and the growth in number and sophistication of these methods has closely tracked the growth in volume and complexity of biomedical data. In such a crowded environment of diverse computational methods and data, it is difficult to judge how generalizable the performance of these methods is from one setting to another. Crowdsourcing-based scientific competitions, or challenges, have now become popular mechanisms for the rigorous, blinded and unbiased evaluation of the performance of these methods and the identification of best-performing methods for biomedical problems. However, despite the benefits of these challenges to the biomedical research enterprise, the impact of their findings has been remarkably limited in laboratory and clinical settings. This is likely due to two important aspects of current challenges: (i) their over-emphasis on identifying the ""best"" solutions rather than tryig to comprehensively assimilate the knowledge embedded in all the submitted solutions, and (ii) the absence of a stable channel of communication and collaboration between problem and solution providers due to a lack of sufficient incentives to do so. The aim of this project is to boost the translational impact of scientific challenges through a combination of novel machine learning methods, development of novel scalable software and unique collaborations with disease experts to ensure the effective translation of knowledge accrued in challenges to real clinical settings and practice. These novel methods and software are designed to effectively assimilate the knowledge embedded in all the submissions to challenges into ""ensemble"" solutions. In a first of its kind effort, the ensemble solutions derived from disease-focused challenges under the DREAM project will be brought directly to scientists and clinicians that are experts in these disease areas. Initial effort in this project will focus on active DREAM challenges aiming at the accurate prediction of drug response and clinical outcomes respectively in Rheumatoid Arthritis (RA) and Acute Myeloid Leukemia (AML). Both these diseases are difficult to treat and thus they pose major medical and public health concerns. In collaboration with RA and AML experts, the ensemble solutions learnt in these challenges will be validated in independent patient cohorts and carefully designed clinical studies. This second-level validation is essential to judge the clinical applicability of any method, but is rarely done As the methodology is general, similar efforts will be made for other diseases in later stages of the project. Overall, using a smart combination of crowdsourcing-based challenges and computational methods and software, we aim to demonstrate a unique pathway for studying and treating disease by truly leveraging the ""wisdom of the crowds"".         PUBLIC HEALTH RELEVANCE: Crowdsourcing-based scientific competitions, or challenges, have become a popular mechanism to identify innovative solutions to complex biomedical problems. However, the collective effort of all the challenge participants has been under utilized, and the overall impact on actual clinical and laboratory practice has been remarkably limited. Using novel computational methods and novel ""big data""-friendly software implementation, we plan to demonstrate how biomedical challenges, combined with our approach, can influence clinical practice in Acute Myeloid Leukemia and Rheumatoid Arthritis, as well as rigorously validate our approach.                 ",Boosting the Translational Impact of Scientific Competitions by Ensemble Learning,8864679,R01GM114434,"['Acute Myelocytic Leukemia', 'Address', 'Adopted', 'Advanced Development', 'Architecture', 'Area', 'Big Data', 'Biological', 'Biological Process', 'Biology', 'Biomedical Research', 'Blinded', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Research', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Crowding', 'Data', 'Data Set', 'Discipline', 'Disease', 'Emerging Technologies', 'Ensure', 'Environment', 'Evaluation', 'Explosion', 'Generations', 'Genomics', 'Genotype', 'Goals', 'Growth', 'Heterogeneity', 'High Performance Computing', 'Image', 'Incentives', 'Knowledge', 'Laboratories', 'Learning', 'Life', 'Machine Learning', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Mining', 'Nature', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Play', 'Problem Solving', 'Production', 'Provider', 'Public Health', 'Publications', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Running', 'Science', 'Scientist', 'Software Design', 'Solutions', 'Source', 'Staging', 'Synapses', 'System', 'Time', 'Translating', 'Translations', 'Validation', 'Variant', 'base', 'clinical application', 'clinical practice', 'cohort', 'computer science', 'design', 'innovation', 'interest', 'knowledge translation', 'meetings', 'method development', 'novel', 'open source', 'predictive modeling', 'prospective', 'public health relevance', 'response', 'stem', 'tool']",NIGMS,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2015,445887,0.0020321311688748754
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the worid, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research. PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",9147033,U54GM114838,"['Actinobacteria class', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Health', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Work', 'analytical method', 'base', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'data mining', 'design', 'drug discovery', 'gene interaction', 'genome sequencing', 'genome-wide', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'programs', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2015,489338,0.02251461771438208
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL     DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the worid, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research.         PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.            ","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",8935854,U54GM114838,"['Actinobacteria class', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Work', 'analytical method', 'base', 'biomedical scientist', 'cancer therapy', 'clinical care', 'collaborative environment', 'data mining', 'design', 'drug discovery', 'gene interaction', 'genome sequencing', 'genome-wide', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2015,2116462,0.02251461771438208
"NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR) DESCRIPTION (provided by applicant):  We propose to establish a NIDA Center of Excellence for Computational Drug Abuse Research (CDAR) between the University of Pittsburgh (Pitt) and (CMU), with the goal of advancing and ensuring the productive and broad usage of state-of-the-art computational technologies that will facilitate and enhance drug abuse (DA) research, both in the local (Pittsburgh) area and nationwide. To this end, we will develop/integrate tools for DA-domain-specific chemical-to-protein-to-genomics mapping using cheminformatics, computational biology and computational genomics methods by centralizing computational chemical genomics (or chemogenomics) resources while also making them available on a cloud server. The Center will foster collaboration and advance knowledge-based translational research and increase the effectiveness of ongoing funded research project (FRPs) via the following Research Support Cores: (1) The Computational Chemogenomics Core for DA (CC4DA) will help address polydrug addiction/polypharmacology by developing new chemogenomics tools and by compiling the data collected/generated, along with those from other Cores, into a DA knowledge-based chemogenomics (DA-KB) repository that will be made accessible to the DA community. (2) The Computational Biology Core (CB4DA) will focus on developing a resource for structure-based investigation of the interactions among substances of DA and their target proteins, in addition to assessing the drugability of receptors and transporters involved in DA and addiction. These activities will be complemented by quantitative systems pharmacology methods to enable a systems-level approach to DA research. (3) The Computational Genomics Core (CG4DA) will carry out genome-wide discovery of new DA targets, markers, and epigenetic influences using developed machine learning models and algorithms. (4) The Administrative Core will coordinate Center activities, provide management to oversee the CDAR activities in consultation with the Scientific Steering Committee (SSC) and an External Advisory Board (EAB), ensure the effective dissemination of software/data among the Cores and the FRPs, and establish mentoring mechanisms to train junior researchers. Overall, the Center will strive to achieve the long-term goal of translating advances in computational chemistry, biology and genomics toward the development of novel personalized DA therapeutics. We propose a Computational Drug Abuse Research (CDAR) Center, as a joint initiative between the  University of Pittsburgh and Carnegie Mellon University. The Center consist of three Cores (CC4DA, CB4DA  and CG4DA) that will leverage our expertise in computational chemogenomics, computational biology, and  computational genomics to facilitate basic and translational drug abuse and medication research.",NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR),8896676,P30DA035778,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cannabinoids', 'Categories', 'Cells', 'Chemicals', 'Clinical Trials Network', 'Cloud Computing', 'Cocaine', 'Collaborations', 'Communities', 'Complement', 'Computational Biology', 'Computer software', 'Consultations', 'Data', 'Databases', 'Development', 'Doctor of Philosophy', 'Drug abuse', 'Effectiveness', 'Endocytosis', 'Ensure', 'Environmental Risk Factor', 'Feedback', 'Fostering', 'Funding', 'Genetic', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Intervention', 'Investigation', 'Joints', 'Leadership', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'National Institute of Drug Abuse', 'Neuropharmacology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacology', 'Phenotype', 'Proteins', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Science', 'Signal Transduction', 'Software Tools', 'Structure', 'Substance Use Disorder', 'System', 'Systems Biology', 'Technology', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Universities', 'addiction', 'base', 'biobehavior', 'cheminformatics', 'cloud based', 'computational chemistry', 'computer science', 'data mining', 'design', 'dopamine transporter', 'drug abuse prevention', 'epigenetic marker', 'falls', 'genome-wide', 'improved', 'insight', 'knowledge base', 'member', 'novel', 'operation', 'predictive modeling', 'prevent', 'professor', 'receptor', 'repository', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P30,2015,1064603,-0.0033933146064795586
"Protect Privacy of Healthcare Data in the Cloud DESCRIPTION (provided by applicant): Cloud computing is gain popularity due to its cost-effective storage and computation. There are few studies on how to leverage cloud computing resources to facilitate healthcare research in a privacy preserving manner. This project proposes an advanced framework that combines rigorous privacy protection and encryption techniques to facilitate healthcare data sharing in the cloud environment. Comparing to traditional centralized data anonymization, we are facing major challenges such as lack of global knowledge and the difficulty to enforce consistency. We adopt differential privacy as our privacy criteria and will leverage homomorphic encryption and Yao's garbled circuit protocol to build secure yet scalable information exchange to overcome the barrier. Project narrative Sustainability and privacy are critical concerns in handling large and growing healthcare data. New challenges emerge as new paradigms like cloud computing become popular for cost-effective storage and computation. This project will develop an advanced framework to combine rigorous privacy protection and encryption techniques to facilitate healthcare data sharing in the cloud environment.",Protect Privacy of Healthcare Data in the Cloud,8925916,R21LM012060,"['Adopted', 'Algorithms', 'Cloud Computing', 'Communities', 'Data', 'Data Analyses', 'Data Set', 'Environment', 'Goals', 'Health Services Research', 'Healthcare', 'Individual', 'Institution', 'Intuition', 'Knowledge', 'Laplacian', 'Machine Learning', 'Modeling', 'Privacy', 'Protocols documentation', 'Provider', 'Records', 'Research Infrastructure', 'Research Personnel', 'Secure', 'Security', 'Services', 'Societies', 'Techniques', 'Technology', 'Trust', 'Work', 'base', 'computing resources', 'cost', 'cost effective', 'data sharing', 'encryption', 'light weight', 'novel', 'predictive modeling', 'privacy protection', 'research study', 'tool']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2015,192613,0.0026778198262177562
"Big Data Coursework for Computational Medicine DESCRIPTION:  As the era of ""Big Data"" is dawning on biomedical research, multiple types of biomedical data, including phenotypic, molecular (including -omics), clinical, imaging, behavioral, and environmental data is being generated on an unprecedented scale with high volume, variety and velocity. These datasets are increasingly large and complex, challenging our current abilities for data representation, integration and analysis for improving outcomes and reducing healthcare costs. It is well-recognized that the greatest challenge to leveraging the significant potentials of Big Data is in educating and recruiting future computational and data scientists who have the background, training and experience to master fundamental opportunities in biomedical sciences. This demands interdisciplinary education and hands-on practicum training on understanding the application, analysis, limitations, and value of the Big Data. To bridge this knowledge gap for the U.S. biomedical workforce, we propose to develop a research educational program-Big Data Coursework for Computational Medicine (BDC4CM)-that will instruct students, fellows and scientists in the use of specific new methods and tools fo Big Data by providing tailored, in-depth instruction, hands-on laboratory modules, and case studies on Big Data access, integration, processing and analysis. Offered by highly interdisciplinary and experienced faculty from Mayo Clinic and the University of Minnesota, this program will provide a short- term training opportunity on Big Data methods and approaches for: 1) data and knowledge representation standards; 2) information extraction and natural language processing; 3) visualization analytics; 4) data mining and predictive modeling; 5) privacy and ethics; and 6) applications in comparative effectiveness research and population health research and improvement. Our primary educational goal is to prepare the next generation of innovators and visionaries in the emerging, multidimensional field of Big Data Science in healthcare, as well as to develop a future workforce that fulfills industry needs and increases U.S. competitiveness in healthcare technologies and applications. PUBLIC HEALTH RELEVANCE:   The postdoctoral Big Data Coursework for Computational Medicine (BDC4CM) program seeks to provide short-term education and hands-on practicum training in utilization of biomedical Big Data. BDC4CM will address a major need for the U.S. biomedical workforce to develop and enhance existing skills in application, analysis, limitations, and value of the Big Data.",Big Data Coursework for Computational Medicine,8935791,R25EB020381,"['Academic Medical Centers', 'Address', 'Advisory Committees', 'Area', 'Behavioral', 'Big Data', 'Bioethics', 'Biological Sciences', 'Biomedical Research', 'Case Study', 'Clinic', 'Clinical', 'Collection', 'Committee Members', 'Complex', 'Computational Biology', 'Data', 'Data Reporting', 'Data Set', 'Development', 'Development Plans', 'Discipline', 'Doctor of Medicine', 'Doctor of Philosophy', 'Education', 'Effectiveness', 'Engineering', 'Ethics', 'Evaluation', 'Faculty', 'Feedback', 'Future', 'Goals', 'Grant', 'Health', 'Health Care Costs', 'Health Services Research', 'Healthcare', 'Image', 'Imagery', 'Industry', 'Informatics', 'Instruction', 'Interdisciplinary Education', 'Interview', 'Knowledge', 'Laboratories', 'Laws', 'Learning', 'Mathematics', 'Measures', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Minnesota', 'Molecular', 'Monitor', 'Natural Language Processing', 'Outcome', 'Patients', 'Peer Review', 'Performance', 'Positioning Attribute', 'Postdoctoral Fellow', 'Privacy', 'Process', 'Program Reviews', 'Public Health', 'Publications', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Students', 'Surveys', 'Technology', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'career', 'career development', 'collaborative environment', 'comparative effectiveness', 'computer science', 'data mining', 'effectiveness research', 'experience', 'improved', 'information organization', 'instrument', 'meetings', 'multidisciplinary', 'new technology', 'next generation', 'population health', 'predictive modeling', 'programs', 'skills', 'statistics', 'success', 'tool', 'working group']",NIBIB,MAYO CLINIC ROCHESTER,R25,2015,22575,0.02260126790253118
"Heterogeneous and Robust Survival Analysis in Genomic Studies DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed. PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.",Heterogeneous and Robust Survival Analysis in Genomic Studies,8858662,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Human', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Methods', 'Modeling', 'Outcome', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'hazard', 'improved', 'loss of function', 'novel', 'personalized genomic medicine', 'prevent', 'public health relevance', 'research study', 'response', 'simulation', 'theories', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2015,248912,-0.02459913618902947
"Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership ﻿    DESCRIPTION (provided by applicant): The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The aims to achieve the goals are: 1) Implement an integrated didactic program to enhance student self-efficacy with computational and informatics tool development and use for interrogating and interpreting Big Data, including a two-semester bioinformatics course in Bioinformatics, informed by the expertise of UIUC KnowEnG BD2K Center faculty with additional Special Topics courses available remotely from UIUC. 2) Develop an integrated academic year (Fisk, or partners) and summer research program at the UIUC KnowEnG BD2K Center to assure student exposure to a participation in the life cycle of a `Big Data' research problem. 3) Implement a professional skills development program that assures successful transition of undergraduate participants to a Ph.D. (or MD/PhD Program) in Big Data- reliant biomedical research. 4) Launch a faculty development program in bioinformatics that leads to embracing Big Data problems in courses in multiple disciplines for impact on all Fisk undergraduate STEM majors. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fisk R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.   PUBLIC HEALTH RELEVANCE: The overall goal of the proposed Fisk- UIUC KnowEnG R25 program is to recruit and retain a cadre of under-represented minority scientists prepared to compete for PhD training in biomedical research with already acquired confidence in the use of Big Data. The proposed partnership with the KnowEnG BD2K Center at UIUC will permit curricular enhancements and summer research opportunities for Fisk trainees while, at the same time, reciprocally training natural scientists and mathematics majors in complementary computer and informatics sciences and providing computer science and mathematics undergraduates with essential systems, molecular and cell biology/biochemistry background at Fisk University to provide context for cutting edge genomics, proteomics, and individualized medicine research reliant on Big Data. In addition to curricular and research training program elements, Fisk students will have remote access to seminar courses to increase efficacy in communicating BD2K-based technologies and their applications. Didactic work and undergraduate research experiences will be complemented by an individualized student development plan for honing professional skills, deep understanding of the responsible conduct of research, and wrap-around mentoring to assure subsequent successful entry into competitive BD2K aligned PhD-granting programs. UIUC-hosted summer workshops for faculty will increase confidence in use of Big Data tools, leading to innovations in STEM courses that embrace Big Data, impacting all Fisk STEM undergraduates. Research collaborations between Fisk and BD2K partner faculty also will be fostered. The proposed program will increase both didactic and research experiences in Big Data for Fisk University undergraduates while preparing them for successful entry into PhD-granting programs in related disciplines at research intensive universities. Our KnowEnG partnership also will increase Fisk faculty capacity in Big Data use and foster faculty research collaborations, thus introducing Big Data into course-embedded research, impacting all Fisk University STEM Majors. Reciprocally, our KnowEnG UIUC faculty partners will enrich their holistic mentoring skills of URM trainees based on interactions with Fis R25 mentors, of value for their broader education and research training goals at UIUC and Mayo.  ",Fisk University/UIUC-Mayo KnowENG BD2K Center R25 Partnership,9049946,R25MD010396,"['Address', 'Base Pairing', 'Big Data', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Cellular biology', 'Chemicals', 'Collaborations', 'Communication', 'Complement', 'Computers', 'Core Facility', 'Development', 'Development Plans', 'Discipline', 'Diving', 'Doctor of Philosophy', 'Education', 'Education Projects', 'Educational Curriculum', 'Educational workshop', 'Elements', 'Exposure to', 'Faculty', 'Faculty Workshop', 'Fostering', 'Funding', 'Genomics', 'Goals', 'Grant', 'Health', 'Illinois', 'Informatics', 'Joints', 'Journals', 'Learning', 'Life Cycle Stages', 'Literature', 'Machine Learning', 'Manuscripts', 'Mathematics', 'Mentors', 'Minority', 'Molecular Biology', 'Oral', 'Participant', 'Pathway interactions', 'Program Development', 'Proteomics', 'Reading', 'Recruitment Activity', 'Research', 'Research Ethics', 'Research Personnel', 'Research Training', 'Role', 'STEM field', 'Science', 'Scientist', 'Self Efficacy', 'Students', 'System', 'Technology', 'Time', 'Training', 'Training Programs', 'Underrepresented Minority', 'Universities', 'Work', 'Writing', 'base', 'career', 'computer science', 'data acquisition', 'data sharing', 'experience', 'individualized medicine', 'innovation', 'posters', 'programs', 'responsible research conduct', 'skills', 'tool', 'tool development', 'undergraduate research']",NIMHD,FISK UNIVERSITY,R25,2015,168294,0.056210408849727125
"Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems DESCRIPTION (provided by applicant): Abstract Biomedical science, higher education, software and technology are simultaneously undergoing tectonic shifts. The amazing pace of software and technological development are driving equally amazing advances in the ability to acquire massive data sets in the biomedical sciences. These new Big Biomedical data sets come in the form of complex measurements, such as that of the brain, genome, proteome and human biome or massive databases, such as with electronic health records. Big Data issues, such as reproducibility of processing, measurement and analysis techniques, are increasingly complex, and crucial. Across all domains there is a knowledge gap of researchers to analyze and interpret these new data sets and the current higher education model cannot meet the insatiable demand for this training. We propose to make substantial progress on these issues in two domains. Specifically, we propose to use Massive Open Online Courses (MOOCs) to create two series, one in neuroimaging and one in genomics. These series will allow for flexible, student paced, low cost scalable training for tens of thousands of students. Along with these series, we propose the creation of modular Big Data biostatistical content that can be used by students as well as teachers. This effort will be parallel to work on an intelligent tutoring syste called swirl. This application proposes to use swirl to create rich, gamified learning environments for students. All of the material created from this grant will be open access and free. PUBLIC HEALTH RELEVANCE:  Project narrative: We propose two Massive Open Online Course series in neuroimaging and genomic Big Data analysis as well as the creation of modular Big Data statistics content and content creation for an intelligent tutoring system.","Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems",8935788,R25EB020378,"['Adopted', 'Amaze', 'Area', 'Attention', 'Automobile Driving', 'Big Data', 'Biological', 'Biology', 'Brain', 'Clinical Trials', 'Communities', 'Complex', 'Computer software', 'Cost Analysis', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Discipline', 'Drops', 'Education', 'Educational Curriculum', 'Educational Models', 'Educational process of instructing', 'Electronic Health Record', 'Enrollment', 'Environment', 'Generations', 'Genes', 'Genome', 'Genomics', 'Grant', 'Head', 'Health', 'Human', 'Image', 'Knowledge', 'Laboratories', 'Learning', 'Learning Module', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medicine', 'Modeling', 'Molecular Biology', 'Molecular Medicine', 'Multivariate Analysis', 'Persons', 'Population', 'Principal Investigator', 'Proteome', 'Public Health', 'Public Health Nurses', 'Public Health Nursing', 'Race', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Series', 'Services', 'Solutions', 'Stream', 'Students', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Touch sensation', 'Training', 'Training Programs', 'Universities', 'Work', 'abstracting', 'contrast enhanced', 'cost', 'density', 'flexibility', 'instructor', 'lectures', 'meetings', 'multidisciplinary', 'neuroimaging', 'new technology', 'novel strategies', 'open source', 'operation', 'process repeatability', 'programs', 'research study', 'skills', 'statistics', 'teacher']",NIBIB,JOHNS HOPKINS UNIVERSITY,R25,2015,212771,0.030873475160192447
"COINSTAC: decentralized, scalable analysis of loosely coupled data ﻿    DESCRIPTION (provided by applicant):     The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway5,10. However, there is a significant gap in existing strategies which focus on anonymized, post-hoc sharing of either 1) full raw or preprocessed data [in the case of open studies] or 2) manually computed summary measures [such as hippocampal volume11, in the case of closed (or not yet shared) studies] which we propose to address. Current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the dat as well as for the individual requesting the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions). This needs to change, so that the scientific community becomes a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see recent overview on this from our group2).    The large amount of existing data requires an approach that can analyze data in a distributed way while also leaving control of the source data with the individual investigator; this motivates  dynamic, decentralized way of approaching large scale analyses. We are proposing a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). The system will provide an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data can be avoided, while the strength of large-scale analyses can be retained. To achieve this, in Aim 1, the uniform data interfaces that we propose will make it easy to share and cooperate. Robust and novel quality assurance and replicability tools will also be incorporated. Collaboration and data sharing will be done through forming temporary (need and project-based) virtual clusters of studies performing automatically generated local computation on their respective data and aggregating statistics in global inference procedures. The communal organization will provide a continuous stream of large scale projects that can be formed and completed without the need of creating new rigid organizations or project-oriented storage vaults. In Aim 2, we develop, evaluate, and incorporate privacy-preserving algorithms to ensure that the data used are not re-identifiable even with multiple re-uses. We also will develop advanced distributed and privacy preserving approaches for several key multivariate families of algorithms (general linear model, matrix factorization [e.g. independent component analysis], classification) to estimate intrinsic networks and perform data fusion. Finally, in Aim 3, we will demonstrate the utility of this approach in a proof of concept study through distributed analyses of substance abuse datasets across national and international venues with multiple imaging modalities.         PUBLIC HEALTH RELEVANCE: Hundreds of millions of dollars have been spent to collect human neuroimaging data for clinical and research purposes, many of which don't have data sharing agreements or collect sensitive data which are not easily shared, such as genetics. Opportunities for large scale aggregated analyses to infer health-relevant facts create new challenges in protecting the privacy of individuals' data. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a good solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we are proposing will capture this 'missing data' and allow for pooling of both open and 'closed' repositories by developing privacy preserving versions of widely-used algorithms and incorporating within an easy-to-use platform which enables distributed computation. In addition, COINSTAC will accelerate research on both open and closed data by offering a distributed computational solution for a large toolkit of widely used algorithms.                ","COINSTAC: decentralized, scalable analysis of loosely coupled data",8975906,R01DA040487,"['AODD relapse', 'Accounting', 'Address', 'Agreement', 'Alcohol or Other Drugs use', 'Algorithms', 'Attention', 'Brain imaging', 'Classification', 'Clinical Research', 'Collaborations', 'Communities', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Ensure', 'Family', 'Functional Magnetic Resonance Imaging', 'Funding', 'Genetic', 'Genetic Markers', 'Health', 'Hippocampus (Brain)', 'Human', 'Image', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Left', 'Letters', 'Linear Models', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Methods', 'Movement', 'Paper', 'Plant Roots', 'Poaceae', 'Population', 'Privacy', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Site', 'Solutions', 'Stream', 'Substance abuse problem', 'System', 'Testing', 'Time', 'United States National Institutes of Health', 'base', 'computing resources', 'cost', 'data sharing', 'distributed data', 'flexibility', 'imaging modality', 'independent component analysis', 'neuroimaging', 'novel', 'peer', 'public health relevance', 'quality assurance', 'repository', 'statistics', 'tool', 'virtual']",NIDA,THE MIND RESEARCH NETWORK,R01,2015,727692,0.01415621069844561
"CSHL Computational and Comparative Genomics Course DESCRIPTION (provided by applicant): The Cold Spring Harbor Laboratory proposes to continue a course entitled ""Computational and Comparative Genomics"", to be held in the fall of 2014 - 2016. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions. PUBLIC HEALTH RELEVANCE: The Computational & Comparative Genomics is a 6 day course designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.",CSHL Computational and Comparative Genomics Course,8898177,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomics', 'Health', 'Home environment', 'Institution', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Peptide Sequence Determination', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Universities', 'Update', 'base', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'genome sequencing', 'graduate student', 'instructor', 'interest', 'lecturer', 'meetings', 'programs', 'promoter', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2015,52816,0.0005109701189417029
"UTMB Clinical and Translational Science Award UTMB's CTSA-linked KL2 Scholars Program addresses the significant need for developing future clinical and translational (C&T) investigators, with emphases on team-based research, leadership development, and mentorship training. In our new CTSA hub, we will build on our current CTSA's successes over the past 5½ years, with unique innovative integration of exceptional training approaches, including: 1) mentored career development within CTSA-supported multidisciplinary translational teams (MTTs); 2) an emphasis on individual development plans (IDPs) and pre-established C&T research competencies tailored to the needs of the individual scholar, but also emphasizing team-based competencies; 3) development of leadership competencies through participation in a new Leadership Development Academy; 4) an Academy of Research Mentors (ARM), based within our Institute for Translational Sciences (ITS), to foster mentoring and mentor training; 5) a linked Translational Research Scholars Program (TRSP), which provides an expanded peer group and a wider impact across the institution, with twice-monthly career development seminars and a focus on scholars' research; 6) development of entrepreneurial skills and leadership through participation in a UT System-funded Healthcare Entrepreneurship Program; and 7) collaboration and dissemination of program experience to other CTSA hubs in the Texas Regional CTSA Consortium, and the national CTSA Consortium. An important feature of our KL2 Scholars Program is its linked position within the continuum of career development, from graduate student training in our CTSA TL1 Training Core to the production of independently funded C&T faculty members. Our program is enhanced with by financial support from our Provost's office for scholar expenses, ITS education administrators, the ARM, and the Office of Faculty Affairs, which is focused on faculty development at UTMB. UTMB also ranks nationally in promoting diversity, which will enhance our recruitment of underrepresented minority scholars by the participation of faculty from our Hispanic Center of Excellence, and our Medical School Enrichment Program. Our KL2 Program is well-integrated with other institutional education activities, including our Human Pathophysiology and Translational Medicine graduate program, and courses targeted toward scientific writing, biostatistics, and study design. Early-career faculty as Phase 1 TRSP scholars can compete to become CTSA-supported KL2 Scholars, and with acquisition of their first mentored K-level grants (e.g., K08), advance to a Phase 2 TRSP Scholar, then focusing on the transition from mentored to independent grant funding. Upon acquisition of independent (e.g. R01) funding, scholars advance to become Phase 3 TRSP Scholars and Associate Members in the ARM, to facilitate their development of mentoring skills, and eventually to full ARM membership, with demonstrated success in C&T science mentoring. Our KL2 Scholars Program thus integrates novel team-based training, leadership, and mentoring approaches to foster the career development of future leaders in C&T research. n/a",UTMB Clinical and Translational Science Award,9085705,KL2TR001441,"['Academy', 'Address', 'Administrator', 'Award', 'Biological', 'Biological Markers', 'Biometry', 'Biopsy', 'Body Surface Area', 'Burn injury', 'Characteristics', 'Clinical', 'Clinical Sciences', 'Collaborations', 'Data', 'Dependence', 'Development', 'Development Plans', 'Down-Regulation', 'Education', 'Enrollment', 'Entrepreneurship', 'Evolution', 'Faculty', 'Financial Support', 'Fostering', 'Freezing', 'Functional disorder', 'Funding', 'Future', 'Gene Expression', 'Genes', 'Genomics', 'Grant', 'Healthcare', 'Hepatitis C virus', 'Hispanics', 'Human', 'Individual', 'Infection', 'Inflammation', 'Institutes', 'Institution', 'Interferons', 'Intervention', 'Lead', 'Leadership', 'Link', 'Liver Fibrosis', 'Longitudinal Studies', 'Machine Learning', 'Measures', 'Medicare', 'Medicare claim', 'Medicine', 'Mentors', 'Mentorship', 'MicroRNAs', 'Modeling', 'Molecular Profiling', 'NCI Scholars Program', 'Organ failure', 'Outcome', 'Participant', 'Pathway interactions', 'Patients', 'Peer Group', 'Phase', 'Physicians', 'Positioning Attribute', 'Process', 'Production', 'Protocols documentation', 'Regimen', 'Research', 'Research Design', 'Research Personnel', 'Rice', 'Structure', 'System', 'Techniques', 'Testing', 'Texas', 'Time', 'Tissues', 'Training', 'Translational Research', 'Underrepresented Minority', 'Variant', 'Writing', 'base', 'career', 'career development', 'clinical predictors', 'cohort', 'college', 'demographics', 'experience', 'graduate student', 'innovation', 'liver biopsy', 'medical schools', 'member', 'microbial', 'multidisciplinary', 'novel', 'outcome forecast', 'peripheral blood', 'programs', 'response', 'science education', 'skills', 'success', 'translational medicine']",NCATS,UNIVERSITY OF TEXAS MED BR GALVESTON,KL2,2015,388145,0.029434272522208087
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,8935802,U54EB020405,"['Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cellular Phone', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Outcome', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Science', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Visit', 'Walking', 'Work', 'base', 'biomechanical model', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'health data', 'improved', 'industry partner', 'insight', 'models and simulation', 'motor impairment', 'next generation', 'novel', 'novel strategies', 'prevent', 'programs', 'public health relevance', 'role model', 'sensor', 'social', 'social model', 'tool']",NIBIB,STANFORD UNIVERSITY,U54,2015,401742,0.011286591842367941
"The q-bio Summer School DESCRIPTION (provided by applicant): The purpose of the Annual q-bio Summer School, founded in 2007 in Los Alamos, NM, is to advance predictive modeling of cellular regulatory systems by providing trtaining in mathematical, statistical, and computational techniques that are important in systems and synthetic biology. A secondary goal is to advance the careers of researchers new to quantitative biology. The school consists of courses in six subjects: 1) stochastic gene regulation, 2) cell signaling, 3) biomolecular simulations, 4) viral dynamics, 5) synthetic biology, and 6) computational neuroscience. Demand for training in quantitative biology is increasing rapidly-the number of qualified summer school applicants increased from fewer than 40 in 2010 to over 170 in 2012. In response to this demand, we expanded the school in 2012 to accommodate more students. The school now takes place at two campuses, in Santa Fe, NM (courses 1-4) and in San Diego, CA (courses 5-6). Approximately 30 students attend at each campus and are diverse in terms of educational background (mathematics, engineering, physical sciences, and biology), career level (~75% are graduate students, ~20% are postdocs, and ~5% are more advanced), and demographics (gender, race, ethnicity, and worldwide geographical origin). Students attend all core lectures in the courses offered at their campus, as well as specialized course-specific lectures, student get-to-know-me talks, and other talks (e.g., talks focused on career skills), and participate in hands-on computer labs and mentored projects. After two intensive weeks, all students gather in Santa Fe for a 2-day q- bio Student Symposium, which features student projects reports, student poster presentations, and external invited speakers. All students then attend the 4-day q-bio Conference, an international conference attended by >200 researchers. All q-bio Summer School participants can expect the following: a) broad exposure to mathematical/statistical/computational tools used in quantitative biology, b) in-depth training in techniques of special interest (i.e., in one of the six course subjects) through course-specific lectures, computer labs, and mentored projects; c) multiple opportunities to practice scientific communication through talks and poster presentations; d) exposure to cutting-edge research, and e) extensive networking opportunities with peers and thought leaders. Lecturers and speakers include more than 50 different researchers active in quantitative biology, including very distinguished scientists. For example, in 2013, confirmed lecturers include six academicians. By the time the students attend the q-bio Conference, they are equipped with a powerful social network that facilitates interactions, idea exchange, and initiation of collaborative research. The long-term goal of the school is to change the way biological research is conducted, making biology a more quantitative field, like physics and chemistry. In this effort, the organizers are supported by significant goodwill from the international quantitative biology community and a number of local institutions, including two national centers for systems biology. However, to maintain and improve the school, additional financial support is required. PUBLIC HEALTH RELEVANCE: Many future biomedical and biotechnological advances in synthetic and systems biology will require investigators who have the ability to carefully integrate quantitative experimentation with mathematical, statistical and computational modeling. The goal of the q-bio Summer School is to prepare a new generation of quantitative biologists who are adept at modeling and/or working with modelers to advance our predictive understanding of cellular regulatory systems. The complexity and importance of these systems, which govern cellular activities and fates, provides motivation for developing a scientific and engineering workforce equipped to deal with the complexity.",The q-bio Summer School,8802880,R25GM105608,"['Behavior', 'Bioinformatics', 'Biological', 'Biology', 'Career Choice', 'Cell model', 'Cell physiology', 'Cells', 'Chemistry', 'Communication', 'Communities', 'Complex', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Cues', 'Data', 'Education', 'Educational Background', 'Educational Curriculum', 'Educational workshop', 'Engineering', 'Ethnic Origin', 'Event', 'Exposure to', 'Financial Support', 'Funding', 'Future', 'Gender', 'Gene Expression Regulation', 'Generations', 'Goals', 'Health', 'Heterogeneity', 'Immune system', 'Individual', 'Institution', 'International', 'Internet', 'Machine Learning', 'Mathematics', 'Mentors', 'Minority-Serving Institution', 'Modeling', 'Molecular', 'Motivation', 'National Institute of General Medical Sciences', 'Neurons', 'Occupations', 'Participant', 'Physics', 'Population', 'Postdoctoral Fellow', 'Qualifying', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Scientist', 'Series', 'Signal Transduction', 'Social Network', 'Statistical Data Interpretation', 'Statistical Models', 'Students', 'Synthetic Genes', 'System', 'Systems Biology', 'Techniques', 'Time', 'Training', 'Underrepresented Minority', 'United States National Institutes of Health', 'Viral', 'Woman', 'Work', 'biochemical model', 'biological research', 'career', 'career development', 'computational neuroscience', 'computerized tools', 'demographics', 'graduate student', 'improved', 'interest', 'lecture notes', 'lecturer', 'lectures', 'mathematical model', 'member', 'model design', 'multidisciplinary', 'peer', 'physical science', 'posters', 'predictive modeling', 'programs', 'research study', 'response', 'simulation', 'skills', 'statistics', 'symposium', 'synthetic biology', 'tool']",NIGMS,"NEW MEXICO CONSORTIUM, INC.",R25,2015,169997,0.03609728491431856
"Center for Environmental Genetics     DESCRIPTION (provided by applicant)        It is a priority of the CEG and the Career Development Program to identify and develop the careers of promising early stage investigators. To accomplish this goal, the overall objective of the career development program (CDP) is to recruit, enrich, encourage, and provide resources and mentoring activities to investigators at the graduate, postgraduate and early faculty levels with a particular emphasis on environmental health science. The CDP has forged new cross-disciplinary partnerships in areas applicable to environmental health science with basic, epidemiological, and/or clinical studies including studies in molecular genetics and environmental epidemiology and environmental toxicology.  To accomplish the overall objective, the CDP has developed a highly innovative approach with three specific.  Aim 1 is to attract, recruit and promote opportunities for junior faculty (within three years from initial appointment) towards development of an independent career interfacing between basic, translational or clinical investigations with application to environmental health science. The Next Generation Biomedical Investigator (NGBI) program is the principal mechanism for achieving this aim.  Aim 2 is to identify investigators with less experience (novice investigators) who are still in trainin with minimal experience but have an interest in examining the intricate role of environmental health science in health and disease. Recruits include physicians in their academic fellowship i.e. post residency, who are obtaining an MS or Ph.D, mentored postdoctoral Ph.D. fellows or advanced (third or fourth year) pre-doctoral research students. This aim is achieved by supplementing novice investigators' training with research resources, mentoring and career development opportunities through the New Investigator Scholar (NIS) pathway.  Aim 3 is to enrich training/scientific experiences, promote career opportunities and networking experiences, activities integrated with the Administrative and other CEG cores. The objective is to develop NGBIs and NISs and others new to environmental health science by enriching experiences as an investigator and eventually independent scientist. Thus, these aims are achieved through financial awards, mentorship, access to core resources and other career development activities.                  Our environmental health center focuses on understanding how genes and environment affect our health,  serving the residents, communities of Ohio, the nation and the globe by generating knowledge that is  applicable to the general public and policymakers for healthier living.",Center for Environmental Genetics,8832593,P30ES006096,"['Acute', 'Affect', 'Air', 'Allergic Disease', 'Area', 'Arteries', 'Attention', 'Barker Hypothesis', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cells', 'Chronic', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Community Outreach', 'Complex', 'Core Facility', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Dose', 'Economics', 'Educational workshop', 'Endocrine disruption', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Epigenetic Process', 'Equilibrium', 'Equipment', 'Evolution', 'Exposure to', 'Funding', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Health', 'Health Sciences', 'Health education', 'Human', 'Human Genome Project', 'Immune System Diseases', 'Individual', 'Informatics', 'Knowledge', 'Lead', 'Life', 'Life Style', 'Link', 'Machine Learning', 'Medicine', 'Mentors', 'Mission', 'Monozygotic twins', 'Nature', 'Neurology', 'Ohio', 'Organ', 'Outcome', 'Phenotype', 'Pilot Projects', 'Population', 'Power Plants', 'Predisposition', 'Public Health', 'Request for Applications', 'Research Personnel', 'Route', 'Series', 'Staging', 'Systems Biology', 'Technology', 'Time', 'Translating', 'Translations', 'Transportation', 'Update', 'Vision', 'Work', 'base', 'career development', 'clinical practice', 'disorder prevention', 'disorder risk', 'environmental agent', 'epigenome', 'experience', 'gene environment interaction', 'genome wide association study', 'health science research', 'high risk', 'human capital', 'innovation', 'insight', 'lipid disorder', 'malignant endocrine gland neoplasm', 'member', 'multidisciplinary', 'next generation sequencing', 'programs', 'response', 'success', 'symposium']",NIEHS,UNIVERSITY OF CINCINNATI,P30,2015,1735289,0.01971467761630971
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8840551,R01CA180777,"['Bees', 'Big Data', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'genetic variant', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2015,219004,-0.02176600342251595
"Multimodal Biomarkers in Frontotemporal Lobar Degeneration DESCRIPTION (provided by applicant): This K01 award will support my development as an independent investigator with a translational research program that specializes in the cognitive and biological basis of neurodegenerative diseases such as frontotemporal lobar degeneration (FTLD). Candidate: My research experience as a cognitive neuroscientist ideally positions me to achieve my career goal of becoming an independent investigator with expertise on the cognitive and biological basis of neurodegenerative disease. I have strong cognitive training with an M.Sc in Psycholinguistics and Ph.D in Psychology from the University of Edinburgh, where I was supported by an NRSA Individual Predoctoral Award. During my postdoctoral IGERT fellowship at the Institute for Research in Cognitive Science at the University of Pennsylvania, I was awarded an NRSA Individual Postdoctoral Fellowship Award to investigate the role of decision-making in language. In this research I have gained experience investigating neurodegenerative disease patients comparatively in order to obtain converging evidence to complement fMRI studies of healthy adults. I have become increasingly interested in translating my research to optimize the diagnosis and treatment of patients with neurodegenerative diseases. I was recently award the Society for the Neurobiology of Language Postdoctoral Merit Award in recognition of my novel research investigating how social limitations in patients contribute to difficulty in discourse. I have committed to four years of clinical research the NIH Loan Repayment Program, and I intend to commit to clinical research for the duration of my career. I have learned that cognitive and neuroimaging studies provide only one perspective on neurodegenerative diseases. In this proposal, I plan to gain the necessary expertise in biological aspects of FTLD and related conditions to complement my past experiences, and thus achieve my goal of becoming a multifaceted independent investigator with expertise in the cognitive and biological basis for neurodegenerative diseases. With the support of this K01, I will develop expertise to conduct investigations of cerebrospinal fluid (CSF), genetic, and neuropathological aspects of neurodegenerative diseases. I will ultimately integrate the biological expertise gained in this proposal with language studies from my cognitive neuroscience research in an effort to identify non-invasive biomarkers that can be used to screen patients for clinical trials and to measure the efficacy of disease-modifying agents. Environment: This award will be conducted at the Perelman School of Medicine at the University of Pennsylvania in the Department of Neurology, the Center for Neurodegenerative Disease Research (CNDR), and the Penn Bioinformatics Center where I have strong institutional support. The proposed institution is an exceptional environment that has expert centers for neuroimaging, cerebrospinal fluid biomarker analysis, a leading genetic research core, expert neuropathology, outstanding biostatisical support, and relevant clinical research laboratories. The University of Pennsylvania is unique in comparison to other institutions in the country because all of the above methods are available in one center. My mentor, Dr. Murray Grossman, and my co-mentor, Dr. John Trojanowksi, have international reputations for neurodegenerative disease research. My career development will also be supported by my co-mentor, Dr. Lyle Ungar, who has extensive expertise in statistical learning algorithms and in the analysis of proteomic and genomics datasets. Together, this mentorship team will facilitate my development as an independent investigator by providing access to existing and future collaborators, laboratory resources, and exceptional training environments. The CNDR is a world- leading center for neurodegenerative disease research with human and animal models of disease and exceptional translational science. Biofluid biomarker experience is extensive, and several national biofluid cores are centered at Penn (e.g. ADNI). There is a wealth of internationally-recognized neuroimaging expertise at the University of Pennsylvania in the Penn Imaging and Computer Science Laboratory, and I will benefit by integrating neuroimaging resources from these facilities with other modalities of biomarker research. Training: I will develop my expertise in the biological basis of neurodegenerative disease with the support of my mentor, Dr. Murray Grossman, and my co-mentors, Dr. John Trojanowski and Dr. Lyle Ungar. Specifically, with Dr. Trojanowksi I will engage in training related to biofluid and genetic biomarkers of FTLD. I will develop advanced neuroimaging skills and cutting-edge biostatistical methods with Dr. Ungar. Each of these training modalities will be supported by complementary formal coursework, participation in seminars, attendance of conferences, and regularly scheduled meetings with mentorship team. Research: FTLD is a neurodegenerative disease affecting approximately 15 out of 100,000 individuals. In recent years detailed neuropathological investigations at autopsy have demonstrated distinct sources of histopathological abnormalities in FTLD, including the presence of tau inclusions (FTLD-tau) and TDP-43 proteinopathies (FTLD-TDP). However, there are currently no in vivo methods for discriminating between FTLD-tau and FTLD-TDP. There is an urgent need to improve the in vivo diagnosis of FTLD to appropriately enter patients into emerging clinical trials, and to develop sensitive and specific endpoints in trials that can quantify response to these treatments. The overall research aim of this proposal is to develop multimodal methods to improve in vivo diagnosis of FTLD. PUBLIC HEALTH RELEVANCE: Frontotemporal lobar degeneration (FTLD) affects approximately 15 out of 100,000 adults. Detailed neuropathological investigations at autopsy have identified two distinct sources of histopathological changes that contribute to FTLD. However, there are currently no in vivo methods for diagnosing pathological subtypes of FTLD. There is an urgent need to identify in vivo diagnosis methods to facilitate the identification of appropriate patients to enter into emerging disease-modifying drug treatment trials. The overall aim of this project is to identify multimodal biomarkers of FTLD.",Multimodal Biomarkers in Frontotemporal Lobar Degeneration,8849803,K01AG043503,"['Address', 'Adult', 'Affect', 'Algorithms', 'Animal Disease Models', 'Animal Model', 'Area', 'Atrophic', 'Autopsy', 'Award', 'Behavioral', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biostatistical Methods', 'Cerebrospinal Fluid', 'Clinical Research', 'Clinical Trials', 'Cognitive', 'Cognitive Science', 'Comparative Study', 'Complement', 'Country', 'DNA Sequence Alteration', 'DNA-Binding Proteins', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Doctor of Philosophy', 'Environment', 'Fellowship', 'Foundations', 'Frontotemporal Dementia', 'Frontotemporal Lobar Degenerations', 'Functional Magnetic Resonance Imaging', 'Future', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genomics', 'Goals', 'Gold', 'Human', 'Image', 'Individual', 'Institution', 'International', 'Investigation', 'Laboratories', 'Language', 'Learning', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Microscopic', 'Modality', 'National Research Service Awards', 'Nerve Degeneration', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurology', 'Neurosciences Research', 'Pathology', 'Patient Monitoring', 'Patients', 'Pennsylvania', 'Pharmaceutical Preparations', 'Phenotype', 'Positioning Attribute', 'Primary Progressive Aphasia', 'Process', 'Proteomics', 'Proxy', 'Psycholinguistics', 'Psychology', 'Rare Diseases', 'Research', 'Research Institute', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Scientist', 'Semantics', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Societies', 'Source', 'Training', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Work', 'accurate diagnosis', 'base', 'career', 'career development', 'clinical phenotype', 'cognitive neuroscience', 'cognitive training', 'cohort', 'computer science', 'diagnostic accuracy', 'experience', 'follow-up', 'genome wide association study', 'gray matter', 'improved', 'in vivo', 'interest', 'longitudinal course', 'medical schools', 'meetings', 'neuroimaging', 'neuropathology', 'novel', 'pre-doctoral', 'programs', 'public health relevance', 'response', 'screening', 'skills', 'social', 'symposium', 'tau Proteins', 'tool', 'treatment trial', 'white matter']",NIA,UNIVERSITY OF PENNSYLVANIA,K01,2015,128358,-0.0025158587217945774
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,8836569,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,2687363,-0.008235334019173857
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,9132876,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,413294,-0.008235334019173857
"Genomic Database for the Yeast Saccharomyces DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements. Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,",Genomic Database for the Yeast Saccharomyces,9133491,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2015,115911,-0.008235334019173857
"Big Data Coursework for Computational Medicine No abstract available PUBLIC HEALTH RELEVANCE:   The postdoctoral Big Data Coursework for Computational Medicine (BDC4CM) program seeks to provide short-term education and hands-on practicum training in utilization of biomedical Big Data. BDC4CM will address a major need for the U.S. biomedical workforce to develop and enhance existing skills in application, analysis, limitations, and value of the Big Data.",Big Data Coursework for Computational Medicine,9171678,R25EB020381,"['Academic Medical Centers', 'Address', 'Advisory Committees', 'Area', 'Behavioral', 'Big Data', 'Bioethics', 'Biological Sciences', 'Biomedical Research', 'Case Study', 'Clinic', 'Clinical', 'Collection', 'Committee Members', 'Complex', 'Computational Biology', 'Data', 'Data Reporting', 'Data Set', 'Development', 'Development Plans', 'Discipline', 'Doctor of Medicine', 'Doctor of Philosophy', 'Education', 'Effectiveness', 'Engineering', 'Ethics', 'Evaluation', 'Faculty', 'Feedback', 'Future', 'Goals', 'Grant', 'Health', 'Health Care Costs', 'Health Services Research', 'Healthcare', 'Image', 'Imagery', 'Industry', 'Informatics', 'Instruction', 'Interdisciplinary Education', 'Interview', 'Knowledge', 'Laboratories', 'Laws', 'Learning', 'Mathematics', 'Measures', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Minnesota', 'Molecular', 'Monitor', 'Natural Language Processing', 'Outcome', 'Patients', 'Peer Review', 'Performance', 'Positioning Attribute', 'Postdoctoral Fellow', 'Privacy', 'Process', 'Program Reviews', 'Public Health', 'Publications', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Students', 'Surveys', 'Technology', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'career', 'career development', 'collaborative environment', 'comparative effectiveness', 'computer science', 'data mining', 'effectiveness research', 'experience', 'improved', 'information organization', 'instrument', 'meetings', 'multidisciplinary', 'new technology', 'next generation', 'population health', 'predictive modeling', 'programs', 'skills', 'statistics', 'success', 'tool', 'working group']",NIBIB,WEILL MEDICAL COLL OF CORNELL UNIV,R25,2015,128308,0.025119756663402944
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8683213,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2014,221252,-0.02041698702624387
"Analytical Approaches to Massive Data Computation with Applications to Genomics DESCRIPTION (provided by applicant): We propose to design and test mathematically well founded algorithmic and statistical tectonics for analyzing large scale, heterogeneous and noisy data. We focus on fully analytical evaluation of algorithms' performance and rigorous statistical guarantees on the analysis results. This project will leverage on the PIs' recent work on cancer genomics data analysis and rigorous data mining techniques. Those works were driven by specific applications, while in the current project we aim at developing general principles and techniques that will apply to a broad sets of applications. The proposed research is transformative in its emphasis on rigorous analytical evaluation of algorithms' performance and statistical measures of output uncertainty, in contrast to the primarily heuristic approaches currently used in data ming and machine learning. While we cannot expect full mathematical analysis of all data mining and machine learning techniques, any progress in that direction will have significant contribution to the reliability and scientific impact of this discipline. While ou work is motivated by molecular biology data, we expect the techniques to be useful for other scientific communities with massive multi-variate data analysis challenges. Molecular biology provides an excellent source of data for testing advance data analysis techniques: specifically, DNA/RNA sequence data repositories are growing at a super-exponential rate. The data is typically large and noisy, and it includes both genotype and phenotype features that permit experimental validation of the analysis. One such data repository is The Cancer Genome Atlas (TCGA), which we will use for initial testing of the proposed approaches. This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas.",Analytical Approaches to Massive Data Computation with Applications to Genomics,8685211,R01CA180776,"['Advocate', 'Algorithms', 'Area', 'Big Data', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Discipline', 'Effectiveness', 'Evaluation', 'Evidence Based Medicine', 'Genomics', 'Genotype', 'Health', 'Human Genome', 'Machine Learning', 'Measures', 'Molecular Biology', 'Output', 'Performance', 'Phenotype', 'RNA Sequences', 'Research', 'Social Policies', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Uncertainty', 'Validation', 'Work', 'base', 'cancer genome', 'cancer genomics', 'data mining', 'design', 'heuristics', 'mathematical analysis']",NCI,BROWN UNIVERSITY,R01,2014,69189,-0.007738444638250912
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.        The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8601147,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'High-Throughput Nucleotide Sequencing', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2014,989800,-0.019689335143351923
"Summer Institute for Statistics of Big Data     DESCRIPTION:  Funding is sought for the Summer Institute for Statistics of Big Data (SISBID) at the University of Washington. This program will provide workshops on the statistical and computational skills needed to access, process, manage, and analyze large biomedical data sets. It will be co-directed by Ali Shojaie and Daniela Witten, faculty in the Department of Biostatistics at University of Washington.  The SISBID program will consist of five 2.5-day in-person courses, or modules, taught at the University of Washington each July. An individual participant can register for whichever set of modules he or she chooses. The five modules are as follows: (1) Accessing Biomedical Big Data; (2) Data Visualization; (3) Supervised Methods for Statistical Machine Learning; (4) Unsupervised Methods for Statistical Machine Learning; (5) Reproducible Research for Biomedical Big Data. Each module will consist of a combination of formal lectures and hands-on computing labs. Participants will work together in teams in order to apply the skills that they develop in each module to important problems drawn from relevant case studies.  The primary audience for SISBID will consist of biomedical scientists who would like to develop the statistical and computational training needed to make use of Biomedical Big Data. The secondary audience will consist of individuals with stronger statistical or computational backgrounds but little exposure to biology, who will learn how to apply their skills to problems associated with Biomedical Big Data. Participants will include advanced undergraduates, graduate students, post-doctoral fellows, and researchers, and will be drawn from industry, government, and academia. In order to ensure that all participants are able to fully engage in the program, participants will be expected to already have some prior background in R programming and statistical inference, which can be obtained by taking two free online courses before the program begins.  Each of the five modules will be co-taught by two instructors. The ten instructors will be drawn from top universities and research centers across the U.S., such as the University of Washington, Rice University, University of Iowa, Johns Hopkins University, MD Anderson Cancer Research Center, Fred Hutchinson Cancer Research Center, and University of North Carolina. They have been selected based on research expertise and excellence in teaching.  Lecture videos and slides will be made freely available online so that individuals who are unable to attend SISBID in person can still benefit from the program.  This proposal specifically requests funds for 55 student / postdoctoral fellow travel scholarships per year, 130 student / postdoctoral fellow registration scholarships per year, instructor travel and stipends, teaching assistant stipends, and PI salary support.         PUBLIC HEALTH RELEVANCE:   In recent years, the biomedical sciences have been inundated by Big Data, such as DNA sequence data and electronic medical records. In principle, it should be possible to use such data for a variety of tasks, such as predicting an individual's risk of developing diabetes or cancer, and tailoring therapies to an individual should he or she become ill. The Summer Institute for Statistics of Big Data will provide biomedical researchers with the computational and statistical training needed in order to take advantage of Big Data, so that they can more effectively use it to understand human diseases and to improve human health.            ",Summer Institute for Statistics of Big Data,8829422,R25EB020380,"['Academia', 'Area', 'Big Data', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Biometry', 'Cancer Center', 'Case Study', 'Collection', 'Computer software', 'Computerized Medical Record', 'DNA Sequence', 'Data', 'Data Set', 'Diabetes Mellitus', 'Educational process of instructing', 'Educational workshop', 'Ensure', 'Environment', 'Exposure to', 'Faculty', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Government', 'Health', 'Human', 'Hybrids', 'Imagery', 'Individual', 'Industry', 'Institutes', 'Iowa', 'Knowledge', 'Learning', 'Learning Module', 'Machine Learning', 'Malignant Neoplasms', 'NCI Center for Cancer Research', 'North Carolina', 'Participant', 'Persons', 'Postdoctoral Fellow', 'Process', 'Records', 'Research', 'Research Personnel', 'Resources', 'Rice', 'Risk', 'Running', 'Scholarship', 'Science', 'Slide', 'Statistical Computing', 'Statistical Methods', 'Students', 'Training', 'Training Activity', 'Training Programs', 'Travel', 'United States', 'Universities', 'Videotape', 'Wages', 'Washington', 'Work', 'base', 'biomedical scientist', 'graduate student', 'human disease', 'improved', 'instructor', 'lectures', 'member', 'open source', 'programs', 'public health relevance', 'skills', 'statistics', 'teacher', 'web site']",NIBIB,UNIVERSITY OF WASHINGTON,R25,2014,160523,0.03365752280156542
"GPU COMPUTING RESOURCE TO ENABLE INNOVATION IN IMAGING AND NETWORK BIOLOGY     DESCRIPTION:  Many complex diseases such as cancer, cardiovascular disorders, and schizophrenia may be understood as failures in the functioning of nested hierarchies of biomolecular and cellular networks. These nested hierarchies control a range of processes including the differentiation and migration of cells, remodeling of extracellular matrices and tissues, and information encoding in neuronal subsystems. Washington University has established expertise in cutting edge imaging, molecular biology and genomic technologies synergistic with computational approaches such as machine learning and unraveling the principles of hierarchical organization and dynamics of complex systems. This collective expertise is being leveraged to develop new drugs, improve our ability to interpret sophisticated imaging data, understand how populations of neurons act collectively to accomplish complex tasks, and model the onset and progression of complex diseases as dynamical rewiring of hierarchical, multi-scale networks. Biological network analyses provide a rich set of tools for organizing and interpreting the vast quantities of data produced by state-of-the-art experimental protocols. The rapid advancement of computationally intensive research in these areas is outstripping the capabilities of CPU-based high performance computing (HPC) systems. This application would support the acquisition and integration of a large-scale IBM high performance cluster of Graphics Processor Units (GPUs) to be added as an upgrade to the existing IBM-designed Heterogeneous High Performance Computing environment to form a state-of-the-art hybrid computing capability. Such a resource is essential to match the growing need for high performance computing at Washington University and to support state of the art research software applications that are optimized for GPU computing. The acquisition and integration of a high performance GPU cluster will solve critical computing challenges that exist within Washington University's growing NIH research portfolio. The proposed state-of-the-art hybrid GPU/CPU computing capabilities will be deployed within the framework of a stable, productive and rapidly growing resource center. The addition of high-capacity GPU computing capabilities will allow critical calculation to be performed in hours instead of days and enable substantial increases in productivity for existing projects covering a broad range of application areas as well as enabling new research directions.             n/a",GPU COMPUTING RESOURCE TO ENABLE INNOVATION IN IMAGING AND NETWORK BIOLOGY,8640341,S10OD018091,"['Area', 'Biological', 'Biology', 'Cardiovascular Diseases', 'Complex', 'Computer Systems', 'Computer software', 'Data', 'Disease', 'Environment', 'Extracellular Matrix', 'Failure', 'Genomics', 'High Performance Computing', 'Hour', 'Hybrids', 'Image', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular Biology', 'Neurons', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Productivity', 'Protocols documentation', 'Research', 'Resources', 'Schizophrenia', 'System', 'Technology', 'Tissues', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'cell motility', 'computing resources', 'design', 'improved', 'innovation', 'tool']",OD,WASHINGTON UNIVERSITY,S10,2014,597700,0.004310836973267447
"The Center for Predictive Computational Phenotyping-1 Overall     DESCRIPTION (provided by applicant):  The biomedical sciences are being radically transformed by advances in our ability to monitor, record, store and integrate information characterizing human biology and health at scales that range from individual molecules to large populations of subjects. This wealth of information has the potential to substantially advance both our understanding of human biology and our ability to improve human health. Perhaps the most central and general approach for exploiting biomedical data is to use methods from machine learning and statistical modeling to infer predictive models. Such models take as input observable data representing some object of interest, and produce as output a prediction about a particular, unobservable property of the object. This approach has proven to be of high value for a wide range of biomedical tasks, but numerous significant challenges remain to be solved in order for the full potential of predictive modeling to be realized.  To address these challenges, we propose to establish The Center for Predictive Computational Phenotyping (CPCP). Our proposed center will focus on a broad range of problems that can be cast as computational phenotyping. Although some phenotypes are easily measured and interpreted, and are available in an accessible format, a wide range of scientifically and clinically important phenotypes do not satisfy these criteria. In such cases, computational phenotyping methods are required either to (i) extract a relevant  phenotype from a complex data source or collection of heterogeneous data sources, (ii) predict clinically  important phenotypes before they are exhibited, or (iii) do both in the same application.         PUBLIC HEALTH RELEVANCE:  We will develop innovative new approaches and tools that are able to discover, and make crucial inferences with large data sets that include molecular profiles, medical images, electronic health records, population-level data, and various combinations of these and other data types. These approaches will significantly advance the state of the art in wide range of biological and clinical investigations, such as predicting which patients are most at risk for breast cancer, heart attacks and severe blood clots.            ",The Center for Predictive Computational Phenotyping-1 Overall,8774800,U54AI117924,"['Address', 'Arts', 'Biological', 'Blood coagulation', 'Clinical Trials', 'Complex', 'Computational algorithm', 'Computer software', 'Computing Methodologies', 'Data', 'Data Collection', 'Data Set', 'Data Sources', 'Diagnosis', 'Disease', 'Education', 'Electronic Health Record', 'Environment', 'Exhibits', 'General Population', 'Generations', 'Genomics', 'Genotype', 'Greek', 'Health', 'Human', 'Human Biology', 'Individual', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular Profiling', 'Monitor', 'Myocardial Infarction', 'Organism', 'Output', 'Patients', 'Phenotype', 'Population', 'Postdoctoral Fellow', 'Property', 'Regulatory Element', 'Research', 'Resources', 'Risk', 'Risk Assessment', 'Sampling', 'Science', 'Scientist', 'Statistical Algorithm', 'Statistical Models', 'Time', 'Training Activity', 'graduate student', 'improved', 'innovation', 'interest', 'malignant breast neoplasm', 'novel strategies', 'outcome forecast', 'predictive modeling', 'public health relevance', 'success', 'tool', 'treatment planning']",NIAID,UNIVERSITY OF WISCONSIN-MADISON,U54,2014,73173,0.00016662745926958368
"Reactome: An Open Knowledgebase of Human Pathways     DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community.          RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                ",Reactome: An Open Knowledgebase of Human Pathways,8661774,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'MicroRNAs', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablet Computer', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2014,1248956,-0.009336077991975673
"Developing Cloud-based tools for Big Neural Data     DESCRIPTION (provided by applicant): Big data has the potential to dramatically advance the electrophysiology biodata sciences in similar ways that it has transformed Genetics. Differences between these two areas dictate separate approaches to apply Big Data tools, and methods in order to provide successful assets to the research community. For one, neural datasets are very heterogeneous by nature. The data is difficult to interpret without knowing specifics about the data acquisition protocol, the experimental paradigm and the physiological state of the recorded subject. Many neural datasets are complemented with complex meta-data sets, which should be an integral component in any effort to integrate and share these data with other researchers. The goal of this project is to develop novel, generalizable Big Data tools to facilitate cloud-base analysis of complex multi-scale neural data. Epilepsy research will be used as a specific use case to guide the development of the tools. A cohort of established senior investigators performing epilepsy research will use and validate these tools in their laboratories. Epilepsy research is currently limited by its narrow focus on single models (animal or human) in individual centers and laboratories. Just as Genetics was revolutionized through Big Data techniques, so too can Epilepsy research be transformed through novel approaches to standardize, share, and mine data across groups of investigators. Over the past several years I have co-developed a NINDS funded cloud-based data platform, ://ieeg.org, giving me a central role in developing Big Data solutions for neural data, such as customized data sharing, large-scale cloud-based data analysis, and search and interrogation techniques for complex data and metadata. My scientific objectives for this project are: (1) to develop generalizable tools to curate, analyze, and interrogate multi-scale neural data, and (2) to create a platform that will galvanize a research community focused on sharing data, and methods to advance Big Data research in the basic and translational neurosciences. Equally important to this proposal, I present a training plan to prepare me for an academic career focused on Big Data in the neurosciences. This plan supplements my background in bioengineering and statistical modeling of neural data with broader data-science expertise in data integration and machine learning, and deeper domain knowledge of the clinical neurosciences. I have assembled a group of collaborators, basic investigators and clinician scientists, who will use the tools developed in this project to analyze and validate their data and methods. I will use the results of this project as the foundation for a R01 Grant application, in which I will expand the developed platform and tools to target other research domains (TBI, Emergency Care, Cardiac), as well as integrate other data-modalities such as Imaging, and Genomics. OMB No. 0925-0001/0002 (Rev. 08/12 Approved Through 8/31/2015) Page Continuation Format Page         PUBLIC HEALTH RELEVANCE: The goal of this proposal is to advance Big Data research in the neurosciences by developing tools and techniques to interrogate electrophysiology data sets from animal models of human neurological disorders. Development of these tools requires close collaboration between domain experts in Neuroscience, Machine Learning, Statistics and Computer Science. When developed, this platform and these tools will allow investigators to share, collaborate, annotate, standardize and analyze large, complex, multiscale data sets that are a crucial first step in advancing this field.            ",Developing Cloud-based tools for Big Neural Data,8830141,K01ES025436,"['Animal Model', 'Applications Grants', 'Area', 'Big Data', 'Biomedical Engineering', 'Cardiac', 'Clinical', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Computational Technique', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Electrophysiology (science)', 'Emergency Care', 'Epilepsy', 'Evaluation', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Genetic', 'Genomics', 'Goals', 'Health', 'Human', 'Image', 'Incentives', 'Individual', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Metadata', 'Methods', 'Mining', 'Modality', 'National Institute of Neurological Disorders and Stroke', 'Nature', 'Neurosciences', 'Organism', 'Performance', 'Physiological', 'Process', 'Protocols documentation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Science', 'Scientist', 'Series', 'Solutions', 'Standardization', 'Statistical Models', 'Techniques', 'Time', 'Training', 'base', 'career', 'cloud based', 'cohort', 'comparative', 'computer science', 'data acquisition', 'data integration', 'data management', 'data mining', 'data sharing', 'improved', 'nervous system disorder', 'novel', 'novel strategies', 'relating to nervous system', 'statistics', 'tool', 'tool development', 'translational neuroscience']",NIEHS,UNIVERSITY OF PENNSYLVANIA,K01,2014,192201,-0.006606162014265987
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8725717,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2014,2015775,0.004088077486549261
"Protect Privacy of Healthcare Data in the Cloud     DESCRIPTION (provided by applicant): Cloud computing is gain popularity due to its cost-effective storage and computation. There are few studies on how to leverage cloud computing resources to facilitate healthcare research in a privacy preserving manner. This project proposes an advanced framework that combines rigorous privacy protection and encryption techniques to facilitate healthcare data sharing in the cloud environment. Comparing to traditional centralized data anonymization, we are facing major challenges such as lack of global knowledge and the difficulty to enforce consistency. We adopt differential privacy as our privacy criteria and will leverage homomorphic encryption and Yao's garbled circuit protocol to build secure yet scalable information exchange to overcome the barrier.             Project narrative Sustainability and privacy are critical concerns in handling large and growing healthcare data. New challenges emerge as new paradigms like cloud computing become popular for cost-effective storage and computation. This project will develop an advanced framework to combine rigorous privacy protection and encryption techniques to facilitate healthcare data sharing in the cloud environment.",Protect Privacy of Healthcare Data in the Cloud,8810023,R21LM012060,"['Adopted', 'Algorithms', 'Cloud Computing', 'Communities', 'Data', 'Data Analyses', 'Data Set', 'Environment', 'Goals', 'Health Services Research', 'Healthcare', 'Individual', 'Institution', 'Intuition', 'Knowledge', 'Machine Learning', 'Modeling', 'Privacy', 'Protocols documentation', 'Provider', 'Records', 'Research Infrastructure', 'Research Personnel', 'Secure', 'Security', 'Services', 'Societies', 'Techniques', 'Technology', 'Trust', 'Work', 'base', 'computing resources', 'cost', 'cost effective', 'data sharing', 'encryption', 'light weight', 'novel', 'predictive modeling', 'research study', 'tool']",NLM,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R21,2014,183155,0.0026778198262177562
"KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL     DESCRIPTION (provided by applicant): The primary goal of the proposed Center of Excellence is to build a powerful and scalable Knowledge Engine for Genomics, KnowEnG. KnowEnG will transform the way biomedical researchers analyze their genome-wide data by integrating multiple analytical methods derived from the most advanced data mining and machine learning research to use the full breadth of existing knowledge about the relationships between genes as background, and providing an intuitive and professionally designed user interface. In order to achieve these goals, the project includes the following components: (1) gathering and integrating existing knowledgebases documenting connections between genes and their functions into a single Knowledge Network; (2) developing computational methods for analyzing genome-wide user datasets in the context of this pre-existing knowledge; (3) implementing these methods into scalable software components that can be deployed in a public or private cloud; (4) designing and implementing a Web-based user interface, based on the HUBZero toolkit, that enables the interactive analysis of user-supplied datasets in a graphics-driven and intuitive fashion; (5) thoroughly testing the functionality and usefulness of the KnowEnG environment in three large scale projects in the clinical sciences (pharmacogenomics of breast cancer), behavioral sciences (identification of gene regulatory modules underlying behavioral patterns) and drug discovery (genome-based prediction of the capacity of microorganisms to synthesize novel biologically active compounds). The KnowEng environment will be deployed in a cloud infrastructure and fully available to the community, as will be the software developed by the Center. The proposed Center is a collaboration between the University of Illinois (UIUC), a recognized world leader in computational science and engineering, and the Mayo Clinic, one of the leading clinical care and research organizations in the worid, and will be based at the UIUC Institute for Genomic Biology, which has state-of-the-art facilities and a nationally recognized program of multidisciplinary team-based genomic research.         PUBLIC HEALTH RELEVANCE: Physicians and biologists are now routinely producing very large, genome-wide datasets. These data need to be analyzed in the context of an even larger corpus of publically available data, in a manner that is approachable to non-specialist doctors and scientists. The proposed Center will leverage the latest computational techniques used to mine corporate or Internet data to enable the intuitive analysis and exploration of biomedical Big Data.            ","KnowEng, a Scalable Knowledge Engine for Large-Scale Genomic Data-OVERALL",8774407,U54GM114838,"['Actinobacteria class', 'Algorithms', 'Antibiotics', 'Bacterial Genome', 'Behavioral', 'Behavioral Sciences', 'Big Data', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Brain', 'Businesses', 'Clinic', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Cloud Computing', 'Code', 'Collaborations', 'Communities', 'Complex', 'Computational Science', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Country', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Educational workshop', 'Engineering', 'Ensure', 'Environment', 'Ethics', 'Fostering', 'Future', 'Gene Expression', 'Generations', 'Genes', 'Genetic Determinism', 'Genome', 'Genomics', 'Goals', 'Illinois', 'Imagery', 'Institutes', 'Internet', 'Knowledge', 'Lead', 'Learning', 'Legal', 'Link', 'Machine Learning', 'Metabolic Pathway', 'Methods', 'Mining', 'Modality', 'Molecular Profiling', 'Online Systems', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Privacy', 'Property', 'Regulator Genes', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Social Network', 'Stimulus', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Work', 'analytical method', 'base', 'biomedical scientist', 'cancer therapy', 'clinical care', 'data mining', 'design', 'drug discovery', 'gene interaction', 'genome sequencing', 'genome-wide', 'innovation', 'knowledge base', 'malignant breast neoplasm', 'member', 'microorganism', 'multidisciplinary', 'next generation', 'novel', 'programs', 'public health relevance', 'research and development', 'response', 'social', 'software development', 'transcriptomics', 'working group']",NIGMS,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,U54,2014,1623265,0.02251461771438208
"NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR) DESCRIPTION (provided by applicant):  We propose to establish a NIDA Center of Excellence for Computational Drug Abuse Research (CDAR) between the University of Pittsburgh (Pitt) and (CMU), with the goal of advancing and ensuring the productive and broad usage of state-of-the-art computational technologies that will facilitate and enhance drug abuse (DA) research, both in the local (Pittsburgh) area and nationwide. To this end, we will develop/integrate tools for DA-domain-specific chemical-to-protein-to-genomics mapping using cheminformatics, computational biology and computational genomics methods by centralizing computational chemical genomics (or chemogenomics) resources while also making them available on a cloud server. The Center will foster collaboration and advance knowledge-based translational research and increase the effectiveness of ongoing funded research project (FRPs) via the following Research Support Cores: (1) The Computational Chemogenomics Core for DA (CC4DA) will help address polydrug addiction/polypharmacology by developing new chemogenomics tools and by compiling the data collected/generated, along with those from other Cores, into a DA knowledge-based chemogenomics (DA-KB) repository that will be made accessible to the DA community. (2) The Computational Biology Core (CB4DA) will focus on developing a resource for structure-based investigation of the interactions among substances of DA and their target proteins, in addition to assessing the drugability of receptors and transporters involved in DA and addiction. These activities will be complemented by quantitative systems pharmacology methods to enable a systems-level approach to DA research. (3) The Computational Genomics Core (CG4DA) will carry out genome-wide discovery of new DA targets, markers, and epigenetic influences using developed machine learning models and algorithms. (4) The Administrative Core will coordinate Center activities, provide management to oversee the CDAR activities in consultation with the Scientific Steering Committee (SSC) and an External Advisory Board (EAB), ensure the effective dissemination of software/data among the Cores and the FRPs, and establish mentoring mechanisms to train junior researchers. Overall, the Center will strive to achieve the long-term goal of translating advances in computational chemistry, biology and genomics toward the development of novel personalized DA therapeutics. We propose a Computational Drug Abuse Research (CDAR) Center, as a joint initiative between the  University of Pittsburgh and Carnegie Mellon University. The Center consist of three Cores (CC4DA, CB4DA  and CG4DA) that will leverage our expertise in computational chemogenomics, computational biology, and  computational genomics to facilitate basic and translational drug abuse and medication research.",NIDA Center of Excellence OF Computational Drug Abuse Research (CDAR),8743368,P30DA035778,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cannabinoids', 'Categories', 'Cells', 'Chemicals', 'Clinical Trials Network', 'Cloud Computing', 'Cocaine', 'Collaborations', 'Communities', 'Complement', 'Computational Biology', 'Computer software', 'Consultations', 'Data', 'Databases', 'Development', 'Doctor of Philosophy', 'Drug abuse', 'Effectiveness', 'Endocytosis', 'Ensure', 'Environmental Risk Factor', 'Feedback', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Intervention', 'Investigation', 'Joints', 'Leadership', 'Link', 'Machine Learning', 'Maps', 'Mentors', 'Methods', 'Modeling', 'Molecular', 'N-Methyl-D-Aspartate Receptors', 'National Institute of Drug Abuse', 'Neuropharmacology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Pharmacology', 'Phenotype', 'Proteins', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Support', 'Resources', 'Science', 'Signal Transduction', 'Software Tools', 'Structure', 'Substance Use Disorder', 'System', 'Systems Biology', 'Technology', 'Therapeutic', 'Training', 'Translating', 'Translational Research', 'Universities', 'addiction', 'base', 'biobehavior', 'cheminformatics', 'cloud based', 'computational chemistry', 'computer science', 'data mining', 'design', 'dopamine transporter', 'drug abuse prevention', 'epigenetic marker', 'falls', 'genome-wide', 'improved', 'insight', 'knowledge base', 'member', 'novel', 'operation', 'predictive modeling', 'prevent', 'professor', 'receptor', 'repository', 'tool']",NIDA,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P30,2014,1094316,-0.0033933146064795586
"Building an open-source cloud-based computational platform to improve data access   We propose to develop a novel, cost-effective, cloud-based data and analytics platform that will provide efficient data storage solutions and enhanced analytics, annotation and reporting capabilities for supporting and accelerating clinical and molecular research in the treatment of substance use disorders (SUD). This open source platform, which leverages existing BioDX technology, will provide a centralized, multi-user environment that enables and encourages collaborative research and information dissemination among team members.  One of the unmet infrastructural challenges of modern molecular research is the availability of computational platforms that allow the management of large databases, easy access to data, the availability of powerful customizable tools for data mining, analysis and visualization, and integration of different data sources to allow successful analysis of complex data problems. Such problems are commonplace in high- throughput molecular research. This proposal aims to fill this gap by developing a robust platform that integrates state-of-the-art open-source technologies for data storage, data access, data mining and analysis, annotation, visualization and reporting.  We previously developed a cloud-based BioDatomics platform for Next Generation Sequencing (NGS), BioDX, which has been successful and has been used commercially by several clients. This proposal aims to develop a new platform leveraging our experience with the BioDX platform that integrates: data storage and real-time data querying using Cloudera Impala; powerful and customizable analytics tools using R and its derivative Bioconductor suite of programs for bioinformatics; annotation integration and reporting which is an existing feature of BioDX; and a visual programming interface that will simplify and enhance the development and maintenance of reproducible analytics workflows. We believe this powerful integrated data platform, if successful, will enable real-time collaboration, dramatically reduce data repository costs, and increase the efficiency and efficacy of data analyses for translating experimental data into actionable research products.  We are committed to analyzing stakeholder needs and optimizing hardware, software and information technology systems to meet their demands. This platform will enhance stakeholder capabilities for developing, implementing and testing various models for substance addiction, risky behavior, discovery of molecular targets for treatment, genomic profiling of patients and other relevant scientific questions. Users will have access to modern statistical, machine learning, data mining and visualization tools.  The initial phase of work will involve development of the platform, optimizing performance on the cloud and testing the integration of new technology. BioDatomics is committed to funding the next phase of work which will include usability testing and finalizing a commercial product, following which full commercialization will proceed. Preliminary commercialization plans have demonstrated that the project has the capacity to generate a million dollars in revenue during the first full year after commercial release.  The ultimate beneficiaries of this platform will be government agencies, academic researchers and pharmaceutical companies pursuing collaborative projects to discover treatments for substance abuse disorders. This open source platform will enable significant savings to the end users in terms of data storage and analytic capabilities, and promises to have a major impact in increasing the success of molecular, clinical and translational research for substance abuse disorders. PUBLIC HEALTH RELEVANCE: One of the unmet infrastructural challenges of modern molecular research is the availability of computational platforms that allow the management of large databases, easy access to data, the availability of powerful customizable tools for data mining, analysis and visualization, and integration of different data sources to allow successful analysis of complex data problems. Such problems are commonplace in high- throughput molecular research. We propose to develop a novel, cost-effective, cloud-based data and analytics platform that will provide efficient data storage solutions and enhanced analytics, annotation and reporting capabilities for supporting and accelerating clinical and molecular research in the treatment of substance use disorders (SUD). This open source platform, which leverages existing BioDX technology, will provide a centralized, multi-user environment that enables and encourages collaborative research and information dissemination among team members. This platform will enhance stakeholder capabilities for developing, implementing and testing various models for substance addiction, risky behavior, discovery of molecular targets for treatment, genomic profiling of patients and other relevant scientific questions. Users will have access to modern statistical, machine learning, data mining and visualization tools. The ultimate beneficiaries of this platform will be government agencies, academic researchers and pharmaceutical companies pursuing collaborative projects to discover treatments for substance abuse disorders. This platform will enable significant savings to the end users in terms of data storage and analytic capabilities, and promises to have a major impact in increasing the success of molecular, clinical and translational research for substance abuse disorders.            ",Building an open-source cloud-based computational platform to improve data access,8647860,R43DA036970,"['Academia', 'Apache Indians', 'Bioconductor', 'Bioinformatics', 'Biological', 'Businesses', 'Centers for Disease Control and Prevention (U.S.)', 'Client', 'Clinical', 'Clinical Research', 'Collaborations', 'Commit', 'Complex', 'Computer software', 'Cost Savings', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Data Storage and Retrieval', 'Databases', 'Development', 'Disease', 'Distributed Databases', 'Drug Industry', 'Environment', 'Expenditure', 'Funding', 'Genomics', 'Government Agencies', 'Growth', 'Imagery', 'Industry', 'Information Dissemination', 'Information Systems', 'Java', 'Language', 'Licensing', 'Link', 'Machine Learning', 'Maintenance', 'Marketing', 'Messenger RNA', 'Modeling', 'Molecular', 'Molecular Target', 'Mutation', 'Online Systems', 'Patients', 'Performance', 'Pharmacologic Substance', 'Phase', 'Programming Languages', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk Behaviors', 'Savings', 'Services', 'Software Engineering', 'Software Tools', 'Solutions', 'Speed', 'Statistical Data Interpretation', 'Statistical Models', 'Substance Addiction', 'Substance Use Disorder', 'Substance abuse problem', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'Visual', 'Work', 'base', 'beneficiary', 'cloud based', 'commercialization', 'computer infrastructure', 'cost', 'cost effective', 'data mining', 'drug discovery', 'experience', 'improved', 'mathematical model', 'meetings', 'member', 'models and simulation', 'new technology', 'next generation sequencing', 'novel', 'open source', 'programs', 'public health relevance', 'substance abuse treatment', 'success', 'tool', 'usability', 'user-friendly']",NIDA,"BIODATOMICS, LLC",R43,2014,195584,-0.007691162944239177
"Big Data Coursework for Computational Medicine     DESCRIPTION:  As the era of ""Big Data"" is dawning on biomedical research, multiple types of biomedical data, including phenotypic, molecular (including -omics), clinical, imaging, behavioral, and environmental data is being generated on an unprecedented scale with high volume, variety and velocity. These datasets are increasingly large and complex, challenging our current abilities for data representation, integration and analysis for improving outcomes and reducing healthcare costs. It is well-recognized that the greatest challenge to leveraging the significant potentials of Big Data is in educating and recruiting future computational and data scientists who have the background, training and experience to master fundamental opportunities in biomedical sciences. This demands interdisciplinary education and hands-on practicum training on understanding the application, analysis, limitations, and value of the Big Data. To bridge this knowledge gap for the U.S. biomedical workforce, we propose to develop a research educational program-Big Data Coursework for Computational Medicine (BDC4CM)-that will instruct students, fellows and scientists in the use of specific new methods and tools fo Big Data by providing tailored, in-depth instruction, hands-on laboratory modules, and case studies on Big Data access, integration, processing and analysis. Offered by highly interdisciplinary and experienced faculty from Mayo Clinic and the University of Minnesota, this program will provide a short- term training opportunity on Big Data methods and approaches for: 1) data and knowledge representation standards; 2) information extraction and natural language processing; 3) visualization analytics; 4) data mining and predictive modeling; 5) privacy and ethics; and 6) applications in comparative effectiveness research and population health research and improvement. Our primary educational goal is to prepare the next generation of innovators and visionaries in the emerging, multidimensional field of Big Data Science in healthcare, as well as to develop a future workforce that fulfills industry needs and increases U.S. competitiveness in healthcare technologies and applications.         PUBLIC HEALTH RELEVANCE:   The postdoctoral Big Data Coursework for Computational Medicine (BDC4CM) program seeks to provide short-term education and hands-on practicum training in utilization of biomedical Big Data. BDC4CM will address a major need for the U.S. biomedical workforce to develop and enhance existing skills in application, analysis, limitations, and value of the Big Data.            ",Big Data Coursework for Computational Medicine,8827881,R25EB020381,"['Academic Medical Centers', 'Address', 'Advisory Committees', 'Area', 'Behavioral', 'Big Data', 'Bioethics', 'Biological Sciences', 'Biomedical Research', 'Case Study', 'Clinic', 'Clinical', 'Collection', 'Committee Members', 'Complex', 'Computational Biology', 'Data', 'Data Reporting', 'Data Set', 'Development', 'Development Plans', 'Discipline', 'Doctor of Medicine', 'Doctor of Philosophy', 'Education', 'Effectiveness', 'Engineering', 'Environment', 'Ethics', 'Evaluation', 'Faculty', 'Feedback', 'Future', 'Goals', 'Grant', 'Health Care Costs', 'Health Services Research', 'Healthcare', 'Image', 'Imagery', 'Industry', 'Informatics', 'Instruction', 'Interdisciplinary Education', 'Interview', 'Knowledge', 'Laboratories', 'Laws', 'Learning', 'Mathematics', 'Measures', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Metric', 'Minnesota', 'Molecular', 'Monitor', 'Natural Language Processing', 'Outcome', 'Patients', 'Peer Review', 'Performance', 'Positioning Attribute', 'Postdoctoral Fellow', 'Privacy', 'Process', 'Program Reviews', 'Public Health', 'Publications', 'Recruitment Activity', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Students', 'Surveys', 'Technology', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'career', 'career development', 'comparative effectiveness', 'computer science', 'data mining', 'effectiveness research', 'experience', 'improved', 'information organization', 'instrument', 'meetings', 'multidisciplinary', 'new technology', 'next generation', 'population health', 'predictive modeling', 'programs', 'public health relevance', 'skills', 'statistics', 'success', 'tool', 'working group']",NIBIB,MAYO CLINIC ROCHESTER,R25,2014,153437,0.02260126790253118
"Heterogeneous and Robust Survival Analysis in Genomic Studies     DESCRIPTION (provided by applicant): The long-term objective of this project is to develop powerful and computationally-efficient statistical methods for statistical modeling of high-dimensional genomic data motivated by important biological problems and experiments. The specific aims of the current project include developing novel survival analysis methods to model the heterogeneity in both patients and biomarkers in genomic studies and developing robust survival analysis methods to analyze high-dimensional genomic data. The proposed methods hinge on a novel integration of methods in high-dimensional data analysis, theory in statistical learning and methods in human genomics. The project will also investigate the robustness, power and efficiencies of these methods and compare them with existing methods. Results from applying the methods to studies of ovarian cancer, lung cancer, brain cancer will help ensure that maximal information is obtained from the high-throughput experiments conducted by our collaborators as well as data that are publicly available. Software will be made available through Bioconductor to ensure that the scientific community benefits from the methods developed.         PUBLIC HEALTH RELEVANCE:     NARRATIVE The last decade of advanced laboratory techniques has had a profound impact on genomic research, however, the development of corresponding statistical methods to analyze the data has not been in the same pace. This project aims to develop, evaluate, and disseminate powerful and computationally-efficient statistical methods to model the heterogeneity in both patients and biomarkers in genomic studies. We believe our proposed methods can help scientific community turn valuable high-throughput measurements into meaningful results.            ",Heterogeneous and Robust Survival Analysis in Genomic Studies,8696520,R01HG007377,"['Address', 'Affect', 'Bioconductor', 'Biological', 'Biological Markers', 'Categories', 'Cause of Death', 'Clinical Treatment', 'Communities', 'Computer software', 'Cox Proportional Hazards Models', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Ensure', 'Failure', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Heterogeneity', 'Human', 'Individual', 'Laboratories', 'Lead', 'Long-Term Effects', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Malignant neoplasm of ovary', 'Measurement', 'Medicine', 'Methods', 'Modeling', 'Outcome', 'Patients', 'Phenotype', 'Population', 'Quality of life', 'Research', 'Statistical Methods', 'Statistical Models', 'Survival Analysis', 'Techniques', 'Time', 'base', 'clinical application', 'hazard', 'improved', 'loss of function', 'novel', 'prevent', 'public health relevance', 'research study', 'response', 'simulation', 'theories', 'treatment strategy']",NHGRI,UNIVERSITY OF WISCONSIN-MADISON,R01,2014,255295,-0.02459913618902947
"Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems     DESCRIPTION (provided by applicant): Abstract Biomedical science, higher education, software and technology are simultaneously undergoing tectonic shifts. The amazing pace of software and technological development are driving equally amazing advances in the ability to acquire massive data sets in the biomedical sciences. These new Big Biomedical data sets come in the form of complex measurements, such as that of the brain, genome, proteome and human biome or massive databases, such as with electronic health records. Big Data issues, such as reproducibility of processing, measurement and analysis techniques, are increasingly complex, and crucial. Across all domains there is a knowledge gap of researchers to analyze and interpret these new data sets and the current higher education model cannot meet the insatiable demand for this training. We propose to make substantial progress on these issues in two domains. Specifically, we propose to use Massive Open Online Courses (MOOCs) to create two series, one in neuroimaging and one in genomics. These series will allow for flexible, student paced, low cost scalable training for tens of thousands of students. Along with these series, we propose the creation of modular Big Data biostatistical content that can be used by students as well as teachers. This effort will be parallel to work on an intelligent tutoring syste called swirl. This application proposes to use swirl to create rich, gamified learning environments for students. All of the material created from this grant will be open access and free.         PUBLIC HEALTH RELEVANCE:  Project narrative: We propose two Massive Open Online Course series in neuroimaging and genomic Big Data analysis as well as the creation of modular Big Data statistics content and content creation for an intelligent tutoring system.            ","Big Data education for the masses: MOOCs, modules, & intelligent tutoring systems",8829370,R25EB020378,"['Adopted', 'Amaze', 'Area', 'Attention', 'Automobile Driving', 'Big Data', 'Biological', 'Biology', 'Brain', 'Clinical Trials', 'Communities', 'Complex', 'Computer software', 'Cost Analysis', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Discipline', 'Drops', 'Education', 'Educational Curriculum', 'Educational Models', 'Educational process of instructing', 'Electronic Health Record', 'Enrollment', 'Environment', 'Generations', 'Genes', 'Genome', 'Genomics', 'Grant', 'Head', 'Human', 'Image', 'Knowledge', 'Laboratories', 'Learning', 'Learning Module', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medicine', 'Modeling', 'Molecular Biology', 'Molecular Medicine', 'Multivariate Analysis', 'Persons', 'Population', 'Principal Investigator', 'Proteome', 'Public Health', 'Public Health Nurses', 'Public Health Nursing', 'Race', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Series', 'Services', 'Solutions', 'Stream', 'Students', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Touch sensation', 'Training', 'Training Programs', 'Universities', 'Work', 'abstracting', 'cost', 'density', 'flexibility', 'instructor', 'lectures', 'meetings', 'multidisciplinary', 'neuroimaging', 'new technology', 'novel strategies', 'open source', 'operation', 'process repeatability', 'programs', 'public health relevance', 'research study', 'skills', 'statistics', 'teacher']",NIBIB,JOHNS HOPKINS UNIVERSITY,R25,2014,216000,0.030873475160192447
"CSHL Computational and Comparative Genomics Course     DESCRIPTION (provided by applicant): The Cold Spring Harbor Laboratory proposes to continue a course entitled ""Computational and Comparative Genomics"", to be held in the fall of 2014 - 2016. The Computational and Comparative Genomics course provides experimental biologists with backgrounds in molecular biology, genetics, and biochemistry with the theoretical background and practical experience necessary to use and evaluate computational approaches to genome annotation and analysis, including protein sequence database searching, multiple sequence alignment, identification of promoters and other genetic regulatory elements, and the integration of sequence information into broader models of biological function. The course also provides computer scientists and mathematicians with an introduction to the algorithms, computational methods, and biological problems that are addressed in biological sequence analysis and computational biology. For post-doctoral fellows, and junior and senior investigators who are interested in changing their research direction towards computational biology, the course provides an introduction to computational biology methods and a survey of future directions. Over a seven day period, the students receive a strong grounding in the both the biological and computer science foundations for genome analysis and practical computer laboratory experience on challenging problems. The course is taught by internationally recognized leaders in the field, who provide hands-on demonstrations of the programs and biological databases they have developed. At the end of the course, students can not only use effectively currently available tools in biological sequence analysis, they can also evaluate critically new computational approaches by considering alternative methods and interpretations, and appreciate the strengths and limitations of computational methods for answering broad biological questions.         PUBLIC HEALTH RELEVANCE: The Computational & Comparative Genomics is a 6 day course designed to meet the continuing need for training in computational biology, statistics, and computer science for molecular biologists and geneticists with backgrounds in experimental biology. In addition, the course presents problems in biological sequence analysis and biological databases to biologists and computer scientists. The course covers research topics and state-of-the-art techniques that, while essential to interpret genome sequence and large-scale functional analysis data from a perspective that balances the theoretical foundations of the approaches and their experimental and analytical limitations.                 ",CSHL Computational and Comparative Genomics Course,8737540,R25HG007819,"['Address', 'Algorithms', 'Amino Acid Sequence', 'Amino Acid Sequence Databases', 'Area', 'Biochemistry', 'Bioinformatics', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological databases', 'Biology', 'Computational Biology', 'Computers', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Analyses', 'Databases', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Equilibrium', 'Faculty', 'Foundations', 'Future', 'Genes', 'Genetic', 'Genomics', 'Home environment', 'Institution', 'Laboratories', 'Laboratory Study', 'Machine Learning', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Nucleic Acid Regulatory Sequences', 'Other Genetics', 'Peptide Sequence Determination', 'Postdoctoral Fellow', 'Publishing', 'Research', 'Research Personnel', 'Scientist', 'Sequence Alignment', 'Sequence Analysis', 'Statistical Algorithm', 'Students', 'Surveys', 'Techniques', 'Training', 'Universities', 'Update', 'base', 'comparative genomics', 'computer science', 'design', 'experience', 'falls', 'genome analysis', 'genome annotation', 'genome database', 'genome sequencing', 'graduate student', 'instructor', 'interest', 'lecturer', 'meetings', 'programs', 'promoter', 'public health relevance', 'statistics', 'tool']",NHGRI,COLD SPRING HARBOR LABORATORY,R25,2014,52816,0.0005109701189417029
"Mobility Data Integration to Insight     DESCRIPTION (provided by applicant): Mobility is essential for human health. Regular physical activity helps prevent heart disease and stroke, relieves symptoms of depression, and promotes weight loss. Unfortunately, many conditions, such as cerebral palsy, osteoarthritis, and obesity, limit mobility at an enormous personal and societal cost. While vast amounts of data are available from hundreds of research labs and millions of smartphones, there is a dearth of methods for analyzing this massive, heterogeneous dataset.  We propose to establish the National Center for Mobility Data Integration to Insight (the Mobilize Center) to overcome the data science challenges facing mobility big data and biomedical big data in general. Our preliminary work identified four bottlenecks in data science, which drive four Data Science Research Cores.  The Cores include Biomechanical Modeling, Statistical Learning, Behavioral and Social Modeling, and Integrative Modeling and Prediction. Our Cores will produce novel methods to integrate diverse modeling modalities and gain insight from noisy, sparse, heterogeneous, and time-varying big data. Our data-sharing consortia, with clinical, research, and industry partners, will provide mobility data for over ten million people.  Three Driving Biomedical Problems will focus and validate our data science research.  The Mobilize Center will disseminate our novel data science tools to thousands of researchers and create a sustainable data-sharing consortium. We will train tens of thousands of scientists to use data science methods in biomedicine through our in-person and online educational programs. We will establish a cohesive, vibrant, and sustainable National Center through the leadership of an experienced executive team and will help unify the BD2K consortia through our Biomedical Computation Review publication and the Simtk.org resource portal.  The Mobilize Center will lay the groundwork for the next generation of data science systems and revolutionize diagnosis and treatment for millions of people affected by limited mobility.         PUBLIC HEALTH RELEVANCE:  Regular physical activity is essential for human health, yet a broad range of conditions impair mobility. This project will transform human movement research by developing tools for data analysis and creating software that will advance research to prevent, diagnose, and reduce impairments that limit human movement.            ",Mobility Data Integration to Insight,8775015,U54EB020405,"['Affect', 'Area', 'Automobile Driving', 'Behavioral', 'Behavioral Model', 'Big Data', 'Biomechanics', 'Biomedical Computing', 'Biomedical Research', 'Body Weight decreased', 'Cerebral Palsy', 'Child', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Degenerative polyarthritis', 'Diabetes Mellitus', 'Diagnosis', 'Educational workshop', 'Elderly', 'Ethics', 'Exercise', 'Fellowship', 'Fostering', 'Gait', 'Health', 'Heart Diseases', 'Human', 'Impairment', 'Individual', 'Injury', 'Joints', 'Leadership', 'Limb structure', 'Machine Learning', 'Medical center', 'Methods', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Movement', 'NCI Scholars Program', 'Nature', 'Obesity', 'Operative Surgical Procedures', 'Outcome', 'Overweight', 'Pathology', 'Persons', 'Physical activity', 'Prevention', 'Problem Solving', 'Public Health', 'Publications', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Running', 'Science', 'Scientist', 'Stroke', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Visit', 'Walking', 'Work', 'base', 'clinical decision-making', 'cognitive function', 'cohesion', 'cost', 'data integration', 'data modeling', 'data sharing', 'depressive symptoms', 'experience', 'flexibility', 'improved', 'industry partner', 'insight', 'models and simulation', 'next generation', 'novel', 'novel strategies', 'prevent', 'programs', 'public health relevance', 'role model', 'sensor', 'social', 'social model', 'tool']",NIBIB,STANFORD UNIVERSITY,U54,2014,209258,0.011286591842367941
"Center for Environmental Genetics     DESCRIPTION (provided by applicant)        It is a priority of the CEG and the Career Development Program to identify and develop the careers of promising early stage investigators. To accomplish this goal, the overall objective of the career development program (CDP) is to recruit, enrich, encourage, and provide resources and mentoring activities to investigators at the graduate, postgraduate and early faculty levels with a particular emphasis on environmental health science. The CDP has forged new cross-disciplinary partnerships in areas applicable to environmental health science with basic, epidemiological, and/or clinical studies including studies in molecular genetics and environmental epidemiology and environmental toxicology.  To accomplish the overall objective, the CDP has developed a highly innovative approach with three specific.  Aim 1 is to attract, recruit and promote opportunities for junior faculty (within three years from initial appointment) towards development of an independent career interfacing between basic, translational or clinical investigations with application to environmental health science. The Next Generation Biomedical Investigator (NGBI) program is the principal mechanism for achieving this aim.  Aim 2 is to identify investigators with less experience (novice investigators) who are still in trainin with minimal experience but have an interest in examining the intricate role of environmental health science in health and disease. Recruits include physicians in their academic fellowship i.e. post residency, who are obtaining an MS or Ph.D, mentored postdoctoral Ph.D. fellows or advanced (third or fourth year) pre-doctoral research students. This aim is achieved by supplementing novice investigators' training with research resources, mentoring and career development opportunities through the New Investigator Scholar (NIS) pathway.  Aim 3 is to enrich training/scientific experiences, promote career opportunities and networking experiences, activities integrated with the Administrative and other CEG cores. The objective is to develop NGBIs and NISs and others new to environmental health science by enriching experiences as an investigator and eventually independent scientist. Thus, these aims are achieved through financial awards, mentorship, access to core resources and other career development activities.                  Our environmental health center focuses on understanding how genes and environment affect our health,  serving the residents, communities of Ohio, the nation and the globe by generating knowledge that is  applicable to the general public and policymakers for healthier living.",Center for Environmental Genetics,8670743,P30ES006096,"['Acute', 'Affect', 'Air', 'Allergic Disease', 'Area', 'Arteries', 'Attention', 'Barker Hypothesis', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cells', 'Chronic', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Community Outreach', 'Complex', 'Core Facility', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Dose', 'Economics', 'Educational workshop', 'Endocrine disruption', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Epigenetic Process', 'Equilibrium', 'Equipment', 'Evolution', 'Exposure to', 'Funding', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Health', 'Health Sciences', 'Health education', 'Human', 'Human Genome Project', 'Immune System Diseases', 'Individual', 'Informatics', 'Knowledge', 'Lead', 'Life', 'Life Style', 'Link', 'Machine Learning', 'Medicine', 'Mentors', 'Mission', 'Monozygotic twins', 'Nature', 'Neurology', 'Ohio', 'Organ', 'Outcome', 'Phenotype', 'Pilot Projects', 'Population', 'Power Plants', 'Predisposition', 'Public Health', 'Request for Applications', 'Research Personnel', 'Route', 'Series', 'Staging', 'Systems Biology', 'Technology', 'Time', 'Translating', 'Translations', 'Transportation', 'Update', 'Vision', 'Work', 'base', 'career development', 'clinical practice', 'disorder prevention', 'disorder risk', 'environmental agent', 'epigenome', 'experience', 'gene environment interaction', 'genome wide association study', 'health science research', 'high risk', 'human capital', 'innovation', 'insight', 'lipid disorder', 'malignant endocrine gland neoplasm', 'member', 'multidisciplinary', 'programs', 'response', 'success', 'symposium']",NIEHS,UNIVERSITY OF CINCINNATI,P30,2014,1739696,0.01971467761630971
"The q-bio Summer School     DESCRIPTION (provided by applicant): The purpose of the Annual q-bio Summer School, founded in 2007 in Los Alamos, NM, is to advance predictive modeling of cellular regulatory systems by providing trtaining in mathematical, statistical, and computational techniques that are important in systems and synthetic biology. A secondary goal is to advance the careers of researchers new to quantitative biology. The school consists of courses in six subjects: 1) stochastic gene regulation, 2) cell signaling, 3) biomolecular simulations, 4) viral dynamics, 5) synthetic biology, and 6) computational neuroscience. Demand for training in quantitative biology is increasing rapidly-the number of qualified summer school applicants increased from fewer than 40 in 2010 to over 170 in 2012. In response to this demand, we expanded the school in 2012 to accommodate more students. The school now takes place at two campuses, in Santa Fe, NM (courses 1-4) and in San Diego, CA (courses 5-6). Approximately 30 students attend at each campus and are diverse in terms of educational background (mathematics, engineering, physical sciences, and biology), career level (~75% are graduate students, ~20% are postdocs, and ~5% are more advanced), and demographics (gender, race, ethnicity, and worldwide geographical origin). Students attend all core lectures in the courses offered at their campus, as well as specialized course-specific lectures, student get-to-know-me talks, and other talks (e.g., talks focused on career skills), and participate in hands-on computer labs and mentored projects. After two intensive weeks, all students gather in Santa Fe for a 2-day q- bio Student Symposium, which features student projects reports, student poster presentations, and external invited speakers. All students then attend the 4-day q-bio Conference, an international conference attended by >200 researchers. All q-bio Summer School participants can expect the following: a) broad exposure to mathematical/statistical/computational tools used in quantitative biology, b) in-depth training in techniques of special interest (i.e., in one of the six course subjects) through course-specific lectures, computer labs, and mentored projects; c) multiple opportunities to practice scientific communication through talks and poster presentations; d) exposure to cutting-edge research, and e) extensive networking opportunities with peers and thought leaders. Lecturers and speakers include more than 50 different researchers active in quantitative biology, including very distinguished scientists. For example, in 2013, confirmed lecturers include six academicians. By the time the students attend the q-bio Conference, they are equipped with a powerful social network that facilitates interactions, idea exchange, and initiation of collaborative research. The long-term goal of the school is to change the way biological research is conducted, making biology a more quantitative field, like physics and chemistry. In this effort, the organizers are supported by significant goodwill from the international quantitative biology community and a number of local institutions, including two national centers for systems biology. However, to maintain and improve the school, additional financial support is required.         PUBLIC HEALTH RELEVANCE: Many future biomedical and biotechnological advances in synthetic and systems biology will require investigators who have the ability to carefully integrate quantitative experimentation with mathematical, statistical and computational modeling. The goal of the q-bio Summer School is to prepare a new generation of quantitative biologists who are adept at modeling and/or working with modelers to advance our predictive understanding of cellular regulatory systems. The complexity and importance of these systems, which govern cellular activities and fates, provides motivation for developing a scientific and engineering workforce equipped to deal with the complexity.            ",The q-bio Summer School,8643269,R25GM105608,"['Behavior', 'Bioinformatics', 'Biological', 'Biology', 'Career Choice', 'Cell model', 'Cell physiology', 'Cells', 'Chemistry', 'Communication', 'Communities', 'Complex', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Cues', 'Data', 'Education', 'Educational Background', 'Educational Curriculum', 'Educational workshop', 'Engineering', 'Ethnic Origin', 'Event', 'Exposure to', 'Financial Support', 'Funding', 'Future', 'Gender', 'Gene Expression Regulation', 'Generations', 'Goals', 'Heterogeneity', 'Immune system', 'Individual', 'Institution', 'International', 'Internet', 'Machine Learning', 'Mathematics', 'Mentors', 'Minority-Serving Institution', 'Modeling', 'Molecular', 'Motivation', 'National Institute of General Medical Sciences', 'Neurons', 'Occupations', 'Participant', 'Physics', 'Population', 'Postdoctoral Fellow', 'Qualifying', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Scientist', 'Series', 'Signal Transduction', 'Social Network', 'Statistical Data Interpretation', 'Statistical Models', 'Students', 'Synthetic Genes', 'System', 'Systems Biology', 'Techniques', 'Time', 'Training', 'Underrepresented Minority', 'United States National Institutes of Health', 'Viral', 'Woman', 'Work', 'biochemical model', 'biological research', 'career', 'career development', 'computational neuroscience', 'computerized tools', 'demographics', 'graduate student', 'improved', 'interest', 'lecture notes', 'lecturer', 'lectures', 'mathematical model', 'member', 'model design', 'multidisciplinary', 'peer', 'physical science', 'posters', 'predictive modeling', 'programs', 'public health relevance', 'research study', 'response', 'simulation', 'skills', 'statistics', 'symposium', 'synthetic biology', 'tool']",NIGMS,"NEW MEXICO CONSORTIUM, INC.",R25,2014,171217,0.03609728491431856
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8642168,R01CA180777,"['Bees', 'Big Data', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2014,207764,-0.02176600342251595
"Multimodal Biomarkers in Frontotemporal Lobar Degeneration DESCRIPTION (provided by applicant): This K01 award will support my development as an independent investigator with a translational research program that specializes in the cognitive and biological basis of neurodegenerative diseases such as frontotemporal lobar degeneration (FTLD). Candidate: My research experience as a cognitive neuroscientist ideally positions me to achieve my career goal of becoming an independent investigator with expertise on the cognitive and biological basis of neurodegenerative disease. I have strong cognitive training with an M.Sc in Psycholinguistics and Ph.D in Psychology from the University of Edinburgh, where I was supported by an NRSA Individual Predoctoral Award. During my postdoctoral IGERT fellowship at the Institute for Research in Cognitive Science at the University of Pennsylvania, I was awarded an NRSA Individual Postdoctoral Fellowship Award to investigate the role of decision-making in language. In this research I have gained experience investigating neurodegenerative disease patients comparatively in order to obtain converging evidence to complement fMRI studies of healthy adults. I have become increasingly interested in translating my research to optimize the diagnosis and treatment of patients with neurodegenerative diseases. I was recently award the Society for the Neurobiology of Language Postdoctoral Merit Award in recognition of my novel research investigating how social limitations in patients contribute to difficulty in discourse. I have committed to four years of clinical research the NIH Loan Repayment Program, and I intend to commit to clinical research for the duration of my career. I have learned that cognitive and neuroimaging studies provide only one perspective on neurodegenerative diseases. In this proposal, I plan to gain the necessary expertise in biological aspects of FTLD and related conditions to complement my past experiences, and thus achieve my goal of becoming a multifaceted independent investigator with expertise in the cognitive and biological basis for neurodegenerative diseases. With the support of this K01, I will develop expertise to conduct investigations of cerebrospinal fluid (CSF), genetic, and neuropathological aspects of neurodegenerative diseases. I will ultimately integrate the biological expertise gained in this proposal with language studies from my cognitive neuroscience research in an effort to identify non-invasive biomarkers that can be used to screen patients for clinical trials and to measure the efficacy of disease-modifying agents. Environment: This award will be conducted at the Perelman School of Medicine at the University of Pennsylvania in the Department of Neurology, the Center for Neurodegenerative Disease Research (CNDR), and the Penn Bioinformatics Center where I have strong institutional support. The proposed institution is an exceptional environment that has expert centers for neuroimaging, cerebrospinal fluid biomarker analysis, a leading genetic research core, expert neuropathology, outstanding biostatisical support, and relevant clinical research laboratories. The University of Pennsylvania is unique in comparison to other institutions in the country because all of the above methods are available in one center. My mentor, Dr. Murray Grossman, and my co-mentor, Dr. John Trojanowksi, have international reputations for neurodegenerative disease research. My career development will also be supported by my co-mentor, Dr. Lyle Ungar, who has extensive expertise in statistical learning algorithms and in the analysis of proteomic and genomics datasets. Together, this mentorship team will facilitate my development as an independent investigator by providing access to existing and future collaborators, laboratory resources, and exceptional training environments. The CNDR is a world- leading center for neurodegenerative disease research with human and animal models of disease and exceptional translational science. Biofluid biomarker experience is extensive, and several national biofluid cores are centered at Penn (e.g. ADNI). There is a wealth of internationally-recognized neuroimaging expertise at the University of Pennsylvania in the Penn Imaging and Computer Science Laboratory, and I will benefit by integrating neuroimaging resources from these facilities with other modalities of biomarker research. Training: I will develop my expertise in the biological basis of neurodegenerative disease with the support of my mentor, Dr. Murray Grossman, and my co-mentors, Dr. John Trojanowski and Dr. Lyle Ungar. Specifically, with Dr. Trojanowksi I will engage in training related to biofluid and genetic biomarkers of FTLD. I will develop advanced neuroimaging skills and cutting-edge biostatistical methods with Dr. Ungar. Each of these training modalities will be supported by complementary formal coursework, participation in seminars, attendance of conferences, and regularly scheduled meetings with mentorship team. Research: FTLD is a neurodegenerative disease affecting approximately 15 out of 100,000 individuals. In recent years detailed neuropathological investigations at autopsy have demonstrated distinct sources of histopathological abnormalities in FTLD, including the presence of tau inclusions (FTLD-tau) and TDP-43 proteinopathies (FTLD-TDP). However, there are currently no in vivo methods for discriminating between FTLD-tau and FTLD-TDP. There is an urgent need to improve the in vivo diagnosis of FTLD to appropriately enter patients into emerging clinical trials, and to develop sensitive and specific endpoints in trials that can quantify response to these treatments. The overall research aim of this proposal is to develop multimodal methods to improve in vivo diagnosis of FTLD. PUBLIC HEALTH RELEVANCE: Frontotemporal lobar degeneration (FTLD) affects approximately 15 out of 100,000 adults. Detailed neuropathological investigations at autopsy have identified two distinct sources of histopathological changes that contribute to FTLD. However, there are currently no in vivo methods for diagnosing pathological subtypes of FTLD. There is an urgent need to identify in vivo diagnosis methods to facilitate the identification of appropriate patients to enter into emerging disease-modifying drug treatment trials. The overall aim of this project is to identify multimodal biomarkers of FTLD.",Multimodal Biomarkers in Frontotemporal Lobar Degeneration,8707928,K01AG043503,"['Address', 'Adult', 'Affect', 'Algorithms', 'Animal Disease Models', 'Animal Model', 'Area', 'Atrophic', 'Autopsy', 'Award', 'Behavioral', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biostatistical Methods', 'Cerebrospinal Fluid', 'Clinical Research', 'Clinical Trials', 'Cognitive', 'Cognitive Science', 'Commit', 'Comparative Study', 'Complement', 'Country', 'DNA-Binding Proteins', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Doctor of Philosophy', 'Environment', 'Fellowship', 'Foundations', 'Frontotemporal Dementia', 'Frontotemporal Lobar Degenerations', 'Functional Magnetic Resonance Imaging', 'Future', 'Gene Mutation', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genomics', 'Goals', 'Gold', 'Human', 'Image', 'Individual', 'Institution', 'International', 'Investigation', 'Laboratories', 'Language', 'Learning', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Microscopic', 'Modality', 'National Research Service Awards', 'Nerve Degeneration', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurology', 'Neurosciences Research', 'Pathology', 'Patient Monitoring', 'Patients', 'Pennsylvania', 'Pharmaceutical Preparations', 'Phenotype', 'Positioning Attribute', 'Primary Progressive Aphasia', 'Process', 'Proteomics', 'Proxy', 'Psycholinguistics', 'Psychology', 'Rare Diseases', 'Research', 'Research Institute', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Scientist', 'Semantics', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Societies', 'Source', 'Training', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Work', 'base', 'career', 'career development', 'clinical phenotype', 'cognitive neuroscience', 'cognitive training', 'cohort', 'computer science', 'diagnostic accuracy', 'experience', 'follow-up', 'genome wide association study', 'gray matter', 'improved', 'in vivo', 'interest', 'longitudinal course', 'medical schools', 'meetings', 'neuroimaging', 'neuropathology', 'novel', 'pre-doctoral', 'programs', 'public health relevance', 'response', 'screening', 'skills', 'social', 'symposium', 'tau Proteins', 'tool', 'treatment trial', 'white matter']",NIA,UNIVERSITY OF PENNSYLVANIA,K01,2014,128358,-0.0025158587217945774
"Computer-based simulation Pediatric disaster Triage Training for Emergency Medica  ABSTRACT Children are not small adults. Nowhere is this understanding more critical than in the aftermath of a disaster event, when the strained resources of healthcare providers must be directed where they can do the most good in the least time. Frontline responders are unfortunately rarely trained in the principles and practice of pediatric disaster triage and often do not understand the special pediatric needs and considerations they must take into account when acting decisively and quickly to direct actions in a stressful situation that is often chaotic and always taxing. Researchers at Yale University School of Medicine (YSM) have developed a live simulation training protocol on pediatric disaster triage that has been shown to be effective but also relatively expensive, resource-intensive and therefore difficult to disseminate widely. The Yale New Haven Health System Center for Healthcare Solutions (YNHHS-CHS) has taken up this challenge, proposing to use YNHHS-CHS expertise with online training solutions and web development to create and implement a computer-based simulation that will build on the live simulation model and carry the research into a new medium that will be more cost-effective and able to more broadly engage and educate greater numbers of emergency medical service providers (EMSPs). YNHHS-CHS specialists with design and training skills will use the expertise of YSM pediatric emergency medicine specialists Mark Cicero, MD, who developed the live simulation training, and Marc Auerbach, MD, and the YNHHS-CHS network of emergency management contacts to engage EMSPs in this learning process. The computer- based simulation training will be delivered to 600 EMSPs in southern New England (Connecticut, Rhode Island and Massachusetts) and evaluated for future broader dissemination. Multiple retention evaluations, scenario-based and decision-tree driven, will be conducted: immediately at the end of the online training and at three- and six-month intervals post-training to determine the value of the training in delivering information and fostering the ability to apply it in simulated scenarios. A 10% random sampling of participants will also take an in-person live simulation retention evaluation to further assess and demonstrate the usefulness of the training. The project objective is to achieve a success rate of >80% of learners performing pediatric disaster triage with accuracy that is >/=90%. PUBLIC HEALTH RELEVANCE: Emergency planners often focus on large-scale disaster events, but smaller-scale local events are far more common and together have a much greater impact on the health and well-being of communities - particularly events involving children, such as bus accidents or school-related crises. Children are often present at a disaster site and sorting out their needs and requirements can be a significant challenge to emergency medical service providers. This project brings together Yale School of Medicine pediatric emergency medicine specialists and Yale New Haven Health System Center for Healthcare Solutions instructional design and emergency management experts who are committed to developing a training that delivers the greatest possible efficiency and effectiveness with the greatest possibl accuracy in making choices and directing appropriate healthcare resources to improve disaster event outcomes and mitigate negative consequences for children, disasters' most vulnerable and often least understood victims.            ",Computer-based simulation Pediatric disaster Triage Training for Emergency Medica,8664515,R18HS022837,[' '],AHRQ,YALE UNIVERSITY,R18,2014,720455,-0.01793445047201983
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8640966,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2014,2699376,-0.008235334019173857
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.         PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8518436,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'epigenome', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation sequencing', 'novel', 'open source', 'public health relevance', 'tool', 'transcription factor', 'transcriptome sequencing', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2013,220626,-0.02041698702624387
"Analytical Approaches to Massive Data Computation with Applications to Genomics     DESCRIPTION (provided by applicant): We propose to design and test mathematically well founded algorithmic and statistical tectonics for analyzing large scale, heterogeneous and noisy data. We focus on fully analytical evaluation of algorithms' performance and rigorous statistical guarantees on the analysis results. This project will leverage on the PIs' recent work on cancer genomics data analysis and rigorous data mining techniques. Those works were driven by specific applications, while in the current project we aim at developing general principles and techniques that will apply to a broad sets of applications. The proposed research is transformative in its emphasis on rigorous analytical evaluation of algorithms' performance and statistical measures of output uncertainty, in contrast to the primarily heuristic approaches currently used in data ming and machine learning. While we cannot expect full mathematical analysis of all data mining and machine learning techniques, any progress in that direction will have significant contribution to the reliability and scientific impact of this discipline. While ou work is motivated by molecular biology data, we expect the techniques to be useful for other scientific communities with massive multi-variate data analysis challenges. Molecular biology provides an excellent source of data for testing advance data analysis techniques: specifically, DNA/RNA sequence data repositories are growing at a super-exponential rate. The data is typically large and noisy, and it includes both genotype and phenotype features that permit experimental validation of the analysis. One such data repository is The Cancer Genome Atlas (TCGA), which we will use for initial testing of the proposed approaches. RELEVANCE (See instructions): This project will advocate a responsible approach to data analysis, based on well-founded mathematical and Statistical concepts. Such an approach enhances the effectiveness of evidence based medicine and other policy and social applications of big data analysis. The proposed work will be tested on human and cancer genome data, contributing to health IT, one of the National Priority Domain Areas.              n/a",Analytical Approaches to Massive Data Computation with Applications to Genomics,8599823,R01CA180776,"['Advocate', 'Algorithms', 'Area', 'Communities', 'DNA', 'Data', 'Data Analyses', 'Data Sources', 'Databases', 'Discipline', 'Effectiveness', 'Evaluation', 'Evidence Based Medicine', 'Genomics', 'Genotype', 'Health', 'Human Genome', 'Instruction', 'Machine Learning', 'Measures', 'Molecular Biology', 'Output', 'Performance', 'Phenotype', 'RNA Sequences', 'Research', 'Social Policies', 'Techniques', 'Testing', 'The Cancer Genome Atlas', 'Uncertainty', 'Validation', 'Work', 'base', 'cancer genome', 'cancer genomics', 'data mining', 'design', 'heuristics']",NCI,BROWN UNIVERSITY,R01,2013,71329,-0.007757924547400531
"Brain Science Computer Cluster     DESCRIPTION (provided by applicant): Computational requirements of contemporary brain science research often exceed financial and resource management limits of individual investigator laboratories. Many contemporary neuroscience research projects require analysis of large data sets with advanced statistical methods and anatomical reconstruction techniques. These methods require high speed computational and graphics engines operating in a multiple processor environments equipped with large capacity, high-speed storage devices. A limitation in the Brown brain science effort at understanding neural processing is the lack of a readily accessible high-speed computational resource. A central computational resource based on a unified cluster of contemporary Linux CPUs and GPUs will serve the computational needs of a core group of brain science investigators at Brown without compromising individual access common to stand-alone workstations. The requested computer cluster has system software that automatically balances CPU and GPU usage, thereby ensuring maximum access to the computational resource for all users. Intensive 3D graphics are off-loaded either to GPUs or to client workstations, thereby further reducing the central computational load. Commercial or open-source software with an open operating environment will be used for analysis using standard and novel statistical and machine learning approaches to assess significance of large data sets. This proposal details the architecture and benefits of a contemporary computational resource for the major and minor users, and more generally the Brown brain science community. The resource was designed to fill immediate and near-term computational and storage needs of a core group of Brown brain scientists. The system can be readily expansion as needs, either computational, storage, or new users, arise. Expansion of the existing core investigators group can occur easily since the computational power or storage capacity of the system can be readily enhanced at relatively low cost. The flexible nature of the system will serve a variety of research needs of the Brown brain science community. The computational resource is expected to bring together researchers at Brown working on the common problem of neural processing.             n/a",Brain Science Computer Cluster,8447697,S10OD016366,"['Architecture', 'Brain', 'Client', 'Communities', 'Computer software', 'Data Set', 'Devices', 'Ensure', 'Environment', 'Equilibrium', 'Individual', 'Laboratories', 'Linux', 'Machine Learning', 'Methods', 'Minor', 'Nature', 'Neurosciences Research', 'Process', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Scientist', 'Speed', 'Statistical Methods', 'System', 'Techniques', 'Work', 'base', 'computer cluster', 'computing resources', 'cost', 'design', 'flexibility', 'novel', 'open source', 'reconstruction', 'relating to nervous system', 'software systems']",OD,BROWN UNIVERSITY,S10,2013,599598,-0.008257637182575953
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.        The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8416349,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Targeting', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'genome analysis', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2013,964551,-0.019689335143351923
"Reactome: An Open Knowledgebase of Human Pathways     DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community.          RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                ",Reactome: An Open Knowledgebase of Human Pathways,8473164,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Computers', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablets', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2013,1216983,-0.009336077991975673
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8722983,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2013,115680,0.004088077486549261
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8548395,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2013,1871839,0.004088077486549261
"The q-bio Summer School     DESCRIPTION (provided by applicant): The purpose of the Annual q-bio Summer School, founded in 2007 in Los Alamos, NM, is to advance predictive modeling of cellular regulatory systems by providing trtaining in mathematical, statistical, and computational techniques that are important in systems and synthetic biology. A secondary goal is to advance the careers of researchers new to quantitative biology. The school consists of courses in six subjects: 1) stochastic gene regulation, 2) cell signaling, 3) biomolecular simulations, 4) viral dynamics, 5) synthetic biology, and 6) computational neuroscience. Demand for training in quantitative biology is increasing rapidly-the number of qualified summer school applicants increased from fewer than 40 in 2010 to over 170 in 2012. In response to this demand, we expanded the school in 2012 to accommodate more students. The school now takes place at two campuses, in Santa Fe, NM (courses 1-4) and in San Diego, CA (courses 5-6). Approximately 30 students attend at each campus and are diverse in terms of educational background (mathematics, engineering, physical sciences, and biology), career level (~75% are graduate students, ~20% are postdocs, and ~5% are more advanced), and demographics (gender, race, ethnicity, and worldwide geographical origin). Students attend all core lectures in the courses offered at their campus, as well as specialized course-specific lectures, student get-to-know-me talks, and other talks (e.g., talks focused on career skills), and participate in hands-on computer labs and mentored projects. After two intensive weeks, all students gather in Santa Fe for a 2-day q- bio Student Symposium, which features student projects reports, student poster presentations, and external invited speakers. All students then attend the 4-day q-bio Conference, an international conference attended by >200 researchers. All q-bio Summer School participants can expect the following: a) broad exposure to mathematical/statistical/computational tools used in quantitative biology, b) in-depth training in techniques of special interest (i.e., in one of the six course subjects) through course-specific lectures, computer labs, and mentored projects; c) multiple opportunities to practice scientific communication through talks and poster presentations; d) exposure to cutting-edge research, and e) extensive networking opportunities with peers and thought leaders. Lecturers and speakers include more than 50 different researchers active in quantitative biology, including very distinguished scientists. For example, in 2013, confirmed lecturers include six academicians. By the time the students attend the q-bio Conference, they are equipped with a powerful social network that facilitates interactions, idea exchange, and initiation of collaborative research. The long-term goal of the school is to change the way biological research is conducted, making biology a more quantitative field, like physics and chemistry. In this effort, the organizers are supported by significant goodwill from the international quantitative biology community and a number of local institutions, including two national centers for systems biology. However, to maintain and improve the school, additional financial support is required.         PUBLIC HEALTH RELEVANCE: Many future biomedical and biotechnological advances in synthetic and systems biology will require investigators who have the ability to carefully integrate quantitative experimentation with mathematical, statistical and computational modeling. The goal of the q-bio Summer School is to prepare a new generation of quantitative biologists who are adept at modeling and/or working with modelers to advance our predictive understanding of cellular regulatory systems. The complexity and importance of these systems, which govern cellular activities and fates, provides motivation for developing a scientific and engineering workforce equipped to deal with the complexity.            ",The q-bio Summer School,8475276,R25GM105608,"['Behavior', 'Bioinformatics', 'Biological', 'Biology', 'Career Choice', 'Cell model', 'Cell physiology', 'Cells', 'Chemistry', 'Communication', 'Communities', 'Complex', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Cues', 'Data', 'Education', 'Educational Background', 'Educational Curriculum', 'Educational workshop', 'Engineering', 'Ethnic Origin', 'Event', 'Exposure to', 'Financial Support', 'Funding', 'Future', 'Gender', 'Gene Expression Regulation', 'Generations', 'Goals', 'Heterogeneity', 'Immune system', 'Individual', 'Institution', 'International', 'Internet', 'Machine Learning', 'Mathematics', 'Mentors', 'Minority-Serving Institution', 'Modeling', 'Molecular', 'Motivation', 'National Institute of General Medical Sciences', 'Neurons', 'Occupations', 'Participant', 'Physics', 'Population', 'Postdoctoral Fellow', 'Qualifying', 'Race', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Schools', 'Scientist', 'Series', 'Signal Transduction', 'Social Network', 'Statistical Data Interpretation', 'Statistical Models', 'Students', 'Synthetic Genes', 'System', 'Systems Biology', 'Techniques', 'Time', 'Training', 'United States National Institutes of Health', 'Viral', 'Woman', 'Work', 'biochemical model', 'biological research', 'career', 'career development', 'computational neuroscience', 'computerized tools', 'demographics', 'graduate student', 'improved', 'interest', 'lecture notes', 'lecturer', 'lectures', 'mathematical model', 'member', 'model design', 'multidisciplinary', 'peer', 'physical science', 'posters', 'predictive modeling', 'programs', 'public health relevance', 'research study', 'response', 'simulation', 'skills', 'statistics', 'symposium', 'synthetic biology', 'tool']",NIGMS,"NEW MEXICO CONSORTIUM, INC.",R25,2013,174626,0.03609728491431856
"Center for Environmental Genetics     DESCRIPTION (provided by applicant)        It is a priority of the CEG and the Career Development Program to identify and develop the careers of promising early stage investigators. To accomplish this goal, the overall objective of the career development program (CDP) is to recruit, enrich, encourage, and provide resources and mentoring activities to investigators at the graduate, postgraduate and early faculty levels with a particular emphasis on environmental health science. The CDP has forged new cross-disciplinary partnerships in areas applicable to environmental health science with basic, epidemiological, and/or clinical studies including studies in molecular genetics and environmental epidemiology and environmental toxicology.  To accomplish the overall objective, the CDP has developed a highly innovative approach with three specific.  Aim 1 is to attract, recruit and promote opportunities for junior faculty (within three years from initial appointment) towards development of an independent career interfacing between basic, translational or clinical investigations with application to environmental health science. The Next Generation Biomedical Investigator (NGBI) program is the principal mechanism for achieving this aim.  Aim 2 is to identify investigators with less experience (novice investigators) who are still in trainin with minimal experience but have an interest in examining the intricate role of environmental health science in health and disease. Recruits include physicians in their academic fellowship i.e. post residency, who are obtaining an MS or Ph.D, mentored postdoctoral Ph.D. fellows or advanced (third or fourth year) pre-doctoral research students. This aim is achieved by supplementing novice investigators' training with research resources, mentoring and career development opportunities through the New Investigator Scholar (NIS) pathway.  Aim 3 is to enrich training/scientific experiences, promote career opportunities and networking experiences, activities integrated with the Administrative and other CEG cores. The objective is to develop NGBIs and NISs and others new to environmental health science by enriching experiences as an investigator and eventually independent scientist. Thus, these aims are achieved through financial awards, mentorship, access to core resources and other career development activities.                  Our environmental health center focuses on understanding how genes and environment affect our health,  serving the residents, communities of Ohio, the nation and the globe by generating knowledge that is  applicable to the general public and policymakers for healthier living.",Center for Environmental Genetics,8734521,P30ES006096,"['Acute', 'Affect', 'Allergic Disease', 'Appointment', 'Area', 'Attention', 'Award', 'Barker Hypothesis', 'Behavior Disorders', 'Biological', 'Cardiovascular Diseases', 'Cells', 'Chronic', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Doctor of Philosophy', 'Dose', 'Endocrine disruption', 'Environment', 'Environmental Epidemiology', 'Environmental Health', 'Environmental Risk Factor', 'Epidemiology', 'Epigenetic Process', 'Equipment', 'Evolution', 'Exposure to', 'Faculty', 'Fellowship', 'Funding', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Health', 'Human', 'Human Genome Project', 'Immune System Diseases', 'Individual', 'Informatics', 'Knowledge', 'Lead', 'Life', 'Life Style', 'Link', 'Machine Learning', 'Medicine', 'Mentors', 'Mentorship', 'Mission', 'Molecular Genetics', 'Monozygotic twins', 'Nature', 'Neurology', 'Ohio', 'Organ', 'Outcome', 'Pathway interactions', 'Phenotype', 'Physicians', 'Population', 'Predisposition', 'Recruitment Activity', 'Research', 'Research Personnel', 'Residencies', 'Resources', 'Role', 'Scientist', 'Staging', 'Students', 'Systems Biology', 'Time', 'Training', 'Translations', 'Update', 'Vision', 'base', 'career', 'career development', 'clinical practice', 'disorder risk', 'environmental agent', 'environmental toxicology', 'epigenome', 'experience', 'forging', 'gene environment interaction', 'genome wide association study', 'innovation', 'interest', 'investigator training', 'lipid disorder', 'malignant endocrine gland neoplasm', 'member', 'multidisciplinary', 'next generation', 'pre-doctoral', 'programs', 'response']",NIEHS,UNIVERSITY OF CINCINNATI,P30,2013,16830,0.01971467761630971
"Center for Environmental Genetics     DESCRIPTION (provided by applicant)        It is a priority of the CEG and the Career Development Program to identify and develop the careers of promising early stage investigators. To accomplish this goal, the overall objective of the career development program (CDP) is to recruit, enrich, encourage, and provide resources and mentoring activities to investigators at the graduate, postgraduate and early faculty levels with a particular emphasis on environmental health science. The CDP has forged new cross-disciplinary partnerships in areas applicable to environmental health science with basic, epidemiological, and/or clinical studies including studies in molecular genetics and environmental epidemiology and environmental toxicology.  To accomplish the overall objective, the CDP has developed a highly innovative approach with three specific.  Aim 1 is to attract, recruit and promote opportunities for junior faculty (within three years from initial appointment) towards development of an independent career interfacing between basic, translational or clinical investigations with application to environmental health science. The Next Generation Biomedical Investigator (NGBI) program is the principal mechanism for achieving this aim.  Aim 2 is to identify investigators with less experience (novice investigators) who are still in trainin with minimal experience but have an interest in examining the intricate role of environmental health science in health and disease. Recruits include physicians in their academic fellowship i.e. post residency, who are obtaining an MS or Ph.D, mentored postdoctoral Ph.D. fellows or advanced (third or fourth year) pre-doctoral research students. This aim is achieved by supplementing novice investigators' training with research resources, mentoring and career development opportunities through the New Investigator Scholar (NIS) pathway.  Aim 3 is to enrich training/scientific experiences, promote career opportunities and networking experiences, activities integrated with the Administrative and other CEG cores. The objective is to develop NGBIs and NISs and others new to environmental health science by enriching experiences as an investigator and eventually independent scientist. Thus, these aims are achieved through financial awards, mentorship, access to core resources and other career development activities.                  Our environmental health center focuses on understanding how genes and environment affect our health,  serving the residents, communities of Ohio, the nation and the globe by generating knowledge that is  applicable to the general public and policymakers for healthier living.",Center for Environmental Genetics,8725319,P30ES006096,"['Acute', 'Affect', 'Allergic Disease', 'Appointment', 'Area', 'Attention', 'Award', 'Barker Hypothesis', 'Behavior Disorders', 'Biological', 'Cardiovascular Diseases', 'Cells', 'Chronic', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Doctor of Philosophy', 'Dose', 'Endocrine disruption', 'Environment', 'Environmental Epidemiology', 'Environmental Health', 'Environmental Risk Factor', 'Epidemiology', 'Epigenetic Process', 'Equipment', 'Evolution', 'Exposure to', 'Faculty', 'Fellowship', 'Funding', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Health', 'Human', 'Human Genome Project', 'Immune System Diseases', 'Individual', 'Informatics', 'Knowledge', 'Lead', 'Life', 'Life Style', 'Link', 'Machine Learning', 'Medicine', 'Mentors', 'Mentorship', 'Mission', 'Molecular Genetics', 'Monozygotic twins', 'Nature', 'Neurology', 'Ohio', 'Organ', 'Outcome', 'Pathway interactions', 'Phenotype', 'Physicians', 'Population', 'Predisposition', 'Recruitment Activity', 'Research', 'Research Personnel', 'Residencies', 'Resources', 'Role', 'Scientist', 'Staging', 'Students', 'Systems Biology', 'Time', 'Training', 'Translations', 'Update', 'Vision', 'base', 'career', 'career development', 'clinical practice', 'disorder risk', 'environmental agent', 'environmental toxicology', 'epigenome', 'experience', 'forging', 'gene environment interaction', 'genome wide association study', 'innovation', 'interest', 'investigator training', 'lipid disorder', 'malignant endocrine gland neoplasm', 'member', 'multidisciplinary', 'next generation', 'pre-doctoral', 'programs', 'response']",NIEHS,UNIVERSITY OF CINCINNATI,P30,2013,47910,0.01971467761630971
"Center for Environmental Genetics     DESCRIPTION (provided by applicant)        It is a priority of the CEG and the Career Development Program to identify and develop the careers of promising early stage investigators. To accomplish this goal, the overall objective of the career development program (CDP) is to recruit, enrich, encourage, and provide resources and mentoring activities to investigators at the graduate, postgraduate and early faculty levels with a particular emphasis on environmental health science. The CDP has forged new cross-disciplinary partnerships in areas applicable to environmental health science with basic, epidemiological, and/or clinical studies including studies in molecular genetics and environmental epidemiology and environmental toxicology.  To accomplish the overall objective, the CDP has developed a highly innovative approach with three specific.  Aim 1 is to attract, recruit and promote opportunities for junior faculty (within three years from initial appointment) towards development of an independent career interfacing between basic, translational or clinical investigations with application to environmental health science. The Next Generation Biomedical Investigator (NGBI) program is the principal mechanism for achieving this aim.  Aim 2 is to identify investigators with less experience (novice investigators) who are still in trainin with minimal experience but have an interest in examining the intricate role of environmental health science in health and disease. Recruits include physicians in their academic fellowship i.e. post residency, who are obtaining an MS or Ph.D, mentored postdoctoral Ph.D. fellows or advanced (third or fourth year) pre-doctoral research students. This aim is achieved by supplementing novice investigators' training with research resources, mentoring and career development opportunities through the New Investigator Scholar (NIS) pathway.  Aim 3 is to enrich training/scientific experiences, promote career opportunities and networking experiences, activities integrated with the Administrative and other CEG cores. The objective is to develop NGBIs and NISs and others new to environmental health science by enriching experiences as an investigator and eventually independent scientist. Thus, these aims are achieved through financial awards, mentorship, access to core resources and other career development activities.                  Our environmental health center focuses on understanding how genes and environment affect our health,  serving the residents, communities of Ohio, the nation and the globe by generating knowledge that is  applicable to the general public and policymakers for healthier living.",Center for Environmental Genetics,8426878,P30ES006096,"['Acute', 'Affect', 'Air', 'Allergic Disease', 'Area', 'Arteries', 'Attention', 'Barker Hypothesis', 'Behavior Disorders', 'Bioinformatics', 'Biological', 'Cardiovascular Diseases', 'Cells', 'Chronic', 'Clinical', 'Clinical Data', 'Collaborations', 'Communities', 'Community Outreach', 'Complex', 'Core Facility', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Dose', 'Economics', 'Educational workshop', 'Endocrine disruption', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Epigenetic Process', 'Equilibrium', 'Equipment', 'Evolution', 'Exposure to', 'Funding', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Goals', 'Health', 'Health Sciences', 'Health education', 'Human', 'Human Genome Project', 'Immune System Diseases', 'Individual', 'Informatics', 'Knowledge', 'Lead', 'Life', 'Life Style', 'Link', 'Machine Learning', 'Medicine', 'Mentors', 'Mission', 'Monozygotic twins', 'Nature', 'Neurology', 'Ohio', 'Organ', 'Outcome', 'Phenotype', 'Pilot Projects', 'Population', 'Power Plants', 'Predisposition', 'Public Health', 'Request for Applications', 'Research Personnel', 'Route', 'Series', 'Staging', 'Systems Biology', 'Technology', 'Time', 'Translating', 'Translations', 'Transportation', 'Update', 'Vision', 'Work', 'base', 'career development', 'clinical practice', 'disorder prevention', 'disorder risk', 'environmental agent', 'epigenome', 'experience', 'gene environment interaction', 'genome wide association study', 'health science research', 'high risk', 'human capital', 'innovation', 'insight', 'lipid disorder', 'malignant endocrine gland neoplasm', 'member', 'multidisciplinary', 'programs', 'response', 'success', 'symposium']",NIEHS,UNIVERSITY OF CINCINNATI,P30,2013,1743768,0.01971467761630971
"BIGDATA: DA: Interpreting massive genomic data sets via summarization Genomic data is big and getting ever bigger, but current analysis methods will not scale to the analysis of thousands or millions of genomes. Consequently, a critical technical challenge is to develop new methods that can analyze these enormous data sets. In this proposal, we describe a new computational framework for drawing inferences from massive genomic data sets. Our approach leverages submodular summarization methods that have been developed for analyzing text corpora. We will apply these methods to five big data problems in genomics: 1) identifying functional elements characteristic o f a given human cell type; 2) identifying genomic features associated with a particular subclass of cancer; 3-4) identifying genomic variants representative of ancestrally or phenotypically defined human populations; and 5) finding a set of microbial genes that characterize a given site on the human body. This project will advance discovery and understanding on two fronts. First, we will develop novel methods for summarizing genomic, epigenomic and metagenomic data sets. Indeed, to our knowledge, this grant proposes the first application of summarization methods to genomic data of any kind. The proposed research will significantly advance our ability to apply submodularity to these summarization tasks, particularly with respect to identifying and creating a library of distance functions that have bee validated with respect to the five tasks outlined in the proposal. Second, we will apply our novel methods to problems of profound importance. Indeed, significant progress toward any one of our five tasks would represent an important advance in our scientific understanding of human history, biology or disease. The impact of this project will grow as the big data problem grows, even after the project is complete. The results of this project, both the software that we develop and the summaries that we produce, will be useful for answering a wide array of questions in any field that must cope with big data. Rapid advances in DNA sequencing technology have led to an explosion of genomic data. This data contains valuable knowledge about human biology and human disease, but few existing computational methods are designed to scale to the joint analysis of tens of thousands of human genomes. This proposal adapts and extends recent advances from the field of natural language processing to characterize cancer subtvoesdiscover ofinetic variants associated with disease and characterize human microbial populations.",BIGDATA: DA: Interpreting massive genomic data sets via summarization,8599826,R01CA180777,"['Bees', 'Biology', 'Characteristics', 'Computing Methodologies', 'DNA Sequence', 'Data', 'Data Set', 'Disease', 'Elements', 'Explosion', 'Genes', 'Genome', 'Genomics', 'Grant', 'Human', 'Human Biology', 'Human Genome', 'Human body', 'Joints', 'Knowledge', 'Libraries', 'Malignant Neoplasms', 'Metagenomics', 'Methods', 'Natural Language Processing', 'Population', 'Recording of previous events', 'Research', 'Site', 'Technology', 'Text', 'Variant', 'cell type', 'computer framework', 'coping', 'design', 'epigenomics', 'human disease', 'microbial', 'novel', 'software development']",NCI,UNIVERSITY OF WASHINGTON,R01,2013,214832,-0.02176600342251595
"Multimodal Biomarkers in Frontotemporal Lobar Degeneration DESCRIPTION (provided by applicant): This K01 award will support my development as an independent investigator with a translational research program that specializes in the cognitive and biological basis of neurodegenerative diseases such as frontotemporal lobar degeneration (FTLD). Candidate: My research experience as a cognitive neuroscientist ideally positions me to achieve my career goal of becoming an independent investigator with expertise on the cognitive and biological basis of neurodegenerative disease. I have strong cognitive training with an M.Sc in Psycholinguistics and Ph.D in Psychology from the University of Edinburgh, where I was supported by an NRSA Individual Predoctoral Award. During my postdoctoral IGERT fellowship at the Institute for Research in Cognitive Science at the University of Pennsylvania, I was awarded an NRSA Individual Postdoctoral Fellowship Award to investigate the role of decision-making in language. In this research I have gained experience investigating neurodegenerative disease patients comparatively in order to obtain converging evidence to complement fMRI studies of healthy adults. I have become increasingly interested in translating my research to optimize the diagnosis and treatment of patients with neurodegenerative diseases. I was recently award the Society for the Neurobiology of Language Postdoctoral Merit Award in recognition of my novel research investigating how social limitations in patients contribute to difficulty in discourse. I have committed to four years of clinical research the NIH Loan Repayment Program, and I intend to commit to clinical research for the duration of my career. I have learned that cognitive and neuroimaging studies provide only one perspective on neurodegenerative diseases. In this proposal, I plan to gain the necessary expertise in biological aspects of FTLD and related conditions to complement my past experiences, and thus achieve my goal of becoming a multifaceted independent investigator with expertise in the cognitive and biological basis for neurodegenerative diseases. With the support of this K01, I will develop expertise to conduct investigations of cerebrospinal fluid (CSF), genetic, and neuropathological aspects of neurodegenerative diseases. I will ultimately integrate the biological expertise gained in this proposal with language studies from my cognitive neuroscience research in an effort to identify non-invasive biomarkers that can be used to screen patients for clinical trials and to measure the efficacy of disease-modifying agents. Environment: This award will be conducted at the Perelman School of Medicine at the University of Pennsylvania in the Department of Neurology, the Center for Neurodegenerative Disease Research (CNDR), and the Penn Bioinformatics Center where I have strong institutional support. The proposed institution is an exceptional environment that has expert centers for neuroimaging, cerebrospinal fluid biomarker analysis, a leading genetic research core, expert neuropathology, outstanding biostatisical support, and relevant clinical research laboratories. The University of Pennsylvania is unique in comparison to other institutions in the country because all of the above methods are available in one center. My mentor, Dr. Murray Grossman, and my co-mentor, Dr. John Trojanowksi, have international reputations for neurodegenerative disease research. My career development will also be supported by my co-mentor, Dr. Lyle Ungar, who has extensive expertise in statistical learning algorithms and in the analysis of proteomic and genomics datasets. Together, this mentorship team will facilitate my development as an independent investigator by providing access to existing and future collaborators, laboratory resources, and exceptional training environments. The CNDR is a world- leading center for neurodegenerative disease research with human and animal models of disease and exceptional translational science. Biofluid biomarker experience is extensive, and several national biofluid cores are centered at Penn (e.g. ADNI). There is a wealth of internationally-recognized neuroimaging expertise at the University of Pennsylvania in the Penn Imaging and Computer Science Laboratory, and I will benefit by integrating neuroimaging resources from these facilities with other modalities of biomarker research. Training: I will develop my expertise in the biological basis of neurodegenerative disease with the support of my mentor, Dr. Murray Grossman, and my co-mentors, Dr. John Trojanowski and Dr. Lyle Ungar. Specifically, with Dr. Trojanowksi I will engage in training related to biofluid and genetic biomarkers of FTLD. I will develop advanced neuroimaging skills and cutting-edge biostatistical methods with Dr. Ungar. Each of these training modalities will be supported by complementary formal coursework, participation in seminars, attendance of conferences, and regularly scheduled meetings with mentorship team. Research: FTLD is a neurodegenerative disease affecting approximately 15 out of 100,000 individuals. In recent years detailed neuropathological investigations at autopsy have demonstrated distinct sources of histopathological abnormalities in FTLD, including the presence of tau inclusions (FTLD-tau) and TDP-43 proteinopathies (FTLD-TDP). However, there are currently no in vivo methods for discriminating between FTLD-tau and FTLD-TDP. There is an urgent need to improve the in vivo diagnosis of FTLD to appropriately enter patients into emerging clinical trials, and to develop sensitive and specific endpoints in trials that can quantify response to these treatments. The overall research aim of this proposal is to develop multimodal methods to improve in vivo diagnosis of FTLD. PUBLIC HEALTH RELEVANCE: Frontotemporal lobar degeneration (FTLD) affects approximately 15 out of 100,000 adults. Detailed neuropathological investigations at autopsy have identified two distinct sources of histopathological changes that contribute to FTLD. However, there are currently no in vivo methods for diagnosing pathological subtypes of FTLD. There is an urgent need to identify in vivo diagnosis methods to facilitate the identification of appropriate patients to enter into emerging disease-modifying drug treatment trials. The overall aim of this project is to identify multimodal biomarkers of FTLD.",Multimodal Biomarkers in Frontotemporal Lobar Degeneration,8581245,K01AG043503,"['Address', 'Adult', 'Affect', 'Algorithms', 'Animal Disease Models', 'Animal Model', 'Area', 'Atrophic', 'Autopsy', 'Award', 'Behavioral', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biostatistical Methods', 'Cerebrospinal Fluid', 'Clinical Research', 'Clinical Trials', 'Cognitive', 'Cognitive Science', 'Commit', 'Comparative Study', 'Complement', 'Country', 'DNA-Binding Proteins', 'Data Set', 'Decision Making', 'Development', 'Diagnosis', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Doctor of Philosophy', 'Environment', 'Fellowship', 'Foundations', 'Frontotemporal Dementia', 'Frontotemporal Lobar Degenerations', 'Functional Magnetic Resonance Imaging', 'Future', 'Gene Mutation', 'Genetic', 'Genetic Markers', 'Genetic Research', 'Genomics', 'Goals', 'Gold', 'Human', 'Image', 'Individual', 'Institution', 'International', 'Investigation', 'Laboratories', 'Language', 'Learning', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Methods', 'Microscopic', 'Modality', 'National Research Service Awards', 'Nerve Degeneration', 'Neurobiology', 'Neurodegenerative Disorders', 'Neurology', 'Neurosciences Research', 'Pathology', 'Patient Monitoring', 'Patients', 'Pennsylvania', 'Pharmaceutical Preparations', 'Phenotype', 'Positioning Attribute', 'Primary Progressive Aphasia', 'Process', 'Proteomics', 'Proxy', 'Psycholinguistics', 'Psychology', 'Rare Diseases', 'Research', 'Research Institute', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Scientist', 'Semantics', 'Sensitivity and Specificity', 'Single Nucleotide Polymorphism', 'Societies', 'Source', 'Training', 'Translating', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Work', 'base', 'career', 'career development', 'clinical phenotype', 'cognitive neuroscience', 'cognitive training', 'cohort', 'computer science', 'diagnostic accuracy', 'experience', 'follow-up', 'genome wide association study', 'gray matter', 'improved', 'in vivo', 'interest', 'longitudinal course', 'medical schools', 'meetings', 'neuroimaging', 'neuropathology', 'novel', 'pre-doctoral', 'programs', 'public health relevance', 'response', 'screening', 'skills', 'social', 'symposium', 'tau Proteins', 'tool', 'treatment trial', 'white matter']",NIA,UNIVERSITY OF PENNSYLVANIA,K01,2013,128358,-0.0025158587217945774
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8447583,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'screening', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2013,2703817,-0.008235334019173857
"Data Management and Coordinating Center (DMCC) This application seeks funding for the Data Management and Coordinating Center (DMCC) (formerly known as Data Technology Coordinating Center, DTCC) for the Rare Diseases Clinical Research Network (RDCRN). The applicant, Dr. Krischer, has served as the Principal Investigator for the DTCC for the last 5 years and seeks to renew the cooperative agreement for the DMCC which supports the Rare Diseases Clinical Research Network (RDCRN). The DMCC propose to extend the systems, processes, and procedures developed successfully over the last grant cycle to accommodate the 3000 subjects enrolled on 32 current studies, contingent upon the successful re-competition of their associated clinical research consortia, addition of new studies reflecting the growth of the network, accommodation of federated databases, work with consortia that have pre-existing infrastructure (registries, patient databases, etc.) and registries, provide a user friendly website for web-based recruitment which receives over 3.4 million hits per year at present and a 4000+ member contact registry enhanced for subjects seeking enrollment on clinical trials. We will continue development of new technologies to support scalability and generalizability and tools for cross-disease data mining. Our international clinical information network is secure providing coordinated data management services for collection, storage and analysis of diverse data types from multiple diseases and geographically disparate locations and a portal for the general public and larger community of clinical investigators. The proposed DMCC will facilitate clinical research in rare diseases by providing a test-bed for distributed  clinical data management that incorporates novel approaches and technologies for data management, data  mining, and data sharing across rare diseases, data types, and platforms; and access to information related  to rare diseases for basic and clinical researchers, academic and practicing physicians, patients, and the lay public.",Data Management and Coordinating Center (DMCC),8545224,U54NS064808,"['Access to Information', 'Accountability', 'Address', 'Adherence', 'Administrator', 'Adverse event', 'Agreement', 'Algorithms', 'Architecture', 'Archives', 'Area', 'Automatic Data Processing', 'Beds', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Bite', 'Businesses', 'Cancer Patient', 'Case Report Form', 'Cellular Phone', 'Characteristics', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Management', 'Clinical Protocols', 'Clinical Research', 'Clinical Research Associate', 'Clinical Research Protocols', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Data Monitoring Committees', 'Code', 'Collaborations', 'Collection', 'Committee Members', 'Common Data Element', 'Common Terminology Criteria for Adverse Events', 'Communication', 'Communities', 'Computer Architectures', 'Computer Security', 'Computer software', 'Computers', 'Confidentiality', 'Consent Forms', 'Cost Savings', 'Custom', 'Cystic Fibrosis', 'Data', 'Data Analyses', 'Data Base Management', 'Data Collection', 'Data Element', 'Data Protection', 'Data Quality', 'Data Reporting', 'Data Security', 'Data Set', 'Databases', 'Decision Trees', 'Descriptor', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Directories', 'Disasters', 'Disease', 'Documentation', 'Drops', 'Drug Monitoring', 'Electronic Mail', 'Electronics', 'Eligibility Determination', 'Engineering', 'Enrollment', 'Ensure', 'Environment', 'Epidemiology', 'Etiology', 'Evaluation', 'Event', 'Exclusion Criteria', 'Expert Systems', 'Extensible Markup Language', 'Faculty', 'Family', 'Feedback', 'Flare', 'Foundations', 'Freezing', 'Frequencies', 'Funding', 'Future', 'General Population', 'Generations', 'Generic Drugs', 'Genetic', 'Genetic Transcription', 'Genus - Lotus', 'Grant', 'Graph', 'Grouping', 'Growth', 'Guidelines', 'Hand', 'Health', 'Human Resources', 'Image', 'Individual', 'Industry', 'Informatics', 'Information Networks', 'Information Systems', 'Informed Consent', 'Institution', 'Institutional Review Boards', 'Insulin-Dependent Diabetes Mellitus', 'International', 'Internet', 'Interview', 'Label', 'Laboratories', 'Laboratory Research', 'Language', 'Laws', 'Lead', 'Learning', 'Letters', 'Libraries', 'Life', 'Link', 'Location', 'Logic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mails', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Medical History', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Monitoring Clinical Trials', 'Nature', 'Neurofibromatoses', 'Notification', 'Online Systems', 'Optics', 'Outcome Study', 'Pamphlets', 'Paralysed', 'Participant', 'Pathologic', 'Pathology', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Physical environment', 'Physicians', 'Pilot Projects', 'Policies', 'Population', 'Population Study', 'Positron-Emission Tomography', 'Prevention strategy', 'Principal Investigator', 'Printing', 'Privacy', 'Procedures', 'Process', 'Production', 'Programming Languages', 'Proteomics', 'Protocol Compliance', 'Protocols documentation', 'Publications', 'Published Directory', 'Publishing', 'Qualifying', 'Quality Control', 'Quality of life', 'Radiology Specialty', 'Randomized', 'Rare Diseases', 'Reader', 'Recording of previous events', 'Records', 'Recovery', 'Recruitment Activity', 'Registries', 'Regulation', 'Relative (related person)', 'Reporting', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Subjects', 'Resolution', 'Resources', 'Risk', 'Role', 'SNOMED Clinical Terms', 'Sampling', 'Scanning', 'Schedule', 'Scientist', 'Secure', 'Security', 'Selection Bias', 'Self Assessment', 'Services', 'Side', 'Single-Gene Defect', 'Site', 'Site Visit', 'Source', 'Specific qualifier value', 'Specimen', 'Stream', 'Structure', 'Support Groups', 'Support System', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Translations', 'Trees', 'U-Series Cooperative Agreements', 'United States National Institutes of Health', 'Update', 'Validation', 'Variant', 'Videoconferences', 'Videoconferencing', 'Visit', 'Visual', 'Voice', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical research site', 'cluster computing', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'data mining', 'data modeling', 'data sharing', 'database design', 'database structure', 'demographics', 'design', 'distributed data', 'electronic data', 'eligible participant', 'experience', 'federal policy', 'federated computing', 'firewall', 'follow-up', 'forest', 'graphical user interface', 'improved', 'information display', 'interest', 'meetings', 'member', 'new technology', 'novel strategies', 'operation', 'optical character recognition', 'patient advocacy group', 'patient registry', 'predictive modeling', 'professor', 'programs', 'prospective', 'protocol development', 'quality assurance', 'radiologist', 'remediation', 'repository', 'research study', 'response', 'sample collection', 'software development', 'statistics', 'success', 'symposium', 'technology development', 'therapeutic development', 'tool', 'trafficking', 'user-friendly', 'vector', 'volunteer', 'web interface', 'web page', 'web services', 'web site', 'working group']",NINDS,UNIVERSITY OF SOUTH FLORIDA,U54,2013,4024095,0.012825176746584501
"Data Management and Coordinating Center (DMCC) This application seeks funding for the Data Management and Coordinating Center (DMCC) (formerly known  as Data Technology Coordinating Center, DTCC) for the Rare Diseases Clinical Research Network  (RDCRN). The applicant, Dr. Krischer, has served as the Principal Investigator for the DTCC for the last 5  years and seeks to renew the cooperative agreement for the DMCC which supports the Rare Diseases  Clinical Research Network (RDCRN). The DMCC propose to extend the systems, processes, and  procedures developed successfully over the last grant cycle to accommodate the 3000 subjects enrolled on  32 current studies, contingent upon the successful re-competition of their associated clinical research  consortia, addition of new studies reflecting the growth of the network, accommodation of federated  databases, work with consortia that have pre-existing infrastructure (registries, patient databases, etc.) and  registries, provide a user friendly website for web-based recruitment which receives over 3.4 million hits per  year at present and a 4000+ member contact registry enhanced for subjects seeking enrollment on clinical  trials. We will continue development of new technologies to support scalability and generalizability and tools  for cross-disease data mining. Our international clinical information network is secure providing coordinated  data management services for collection, storage and analysis of diverse data types from multiple diseases  and geographically disparate locations and a portal for the general public and larger community of clinical  investigators. The proposed DMCC will facilitate clinical research in rare diseases by providing a test-bed for distributed  clinical data management that incorporates novel approaches and technologies for data management, data  mining, and data sharing across rare diseases, data types, and platforms; and access to information related  to rare diseases for basic and clinical researchers, academic and practicing physicians, patients, and the lay public.",Data Management and Coordinating Center (DMCC),8734648,U54NS064808,"['Access to Information', 'Accountability', 'Address', 'Adherence', 'Administrator', 'Adverse event', 'Agreement', 'Algorithms', 'Architecture', 'Archives', 'Area', 'Automatic Data Processing', 'Beds', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Bite', 'Businesses', 'Cancer Patient', 'Case Report Form', 'Cellular Phone', 'Characteristics', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Management', 'Clinical Protocols', 'Clinical Research', 'Clinical Research Associate', 'Clinical Research Protocols', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Data Monitoring Committees', 'Code', 'Collaborations', 'Collection', 'Committee Members', 'Common Data Element', 'Common Terminology Criteria for Adverse Events', 'Communication', 'Communities', 'Computer Architectures', 'Computer Security', 'Computer software', 'Computers', 'Confidentiality', 'Consent Forms', 'Cost Savings', 'Custom', 'Cystic Fibrosis', 'Data', 'Data Analyses', 'Data Base Management', 'Data Collection', 'Data Element', 'Data Protection', 'Data Quality', 'Data Reporting', 'Data Security', 'Data Set', 'Databases', 'Decision Trees', 'Descriptor', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Directories', 'Disasters', 'Disease', 'Documentation', 'Drops', 'Drug Monitoring', 'Electronic Mail', 'Electronics', 'Eligibility Determination', 'Engineering', 'Enrollment', 'Ensure', 'Environment', 'Epidemiology', 'Etiology', 'Evaluation', 'Event', 'Exclusion Criteria', 'Expert Systems', 'Extensible Markup Language', 'Faculty', 'Family', 'Feedback', 'Flare', 'Foundations', 'Freezing', 'Frequencies', 'Funding', 'Future', 'General Population', 'Generations', 'Generic Drugs', 'Genetic', 'Genetic Transcription', 'Genus - Lotus', 'Grant', 'Graph', 'Grouping', 'Growth', 'Guidelines', 'Hand', 'Health', 'Human Resources', 'Image', 'Individual', 'Industry', 'Informatics', 'Information Networks', 'Information Systems', 'Informed Consent', 'Institution', 'Institutional Review Boards', 'Insulin-Dependent Diabetes Mellitus', 'International', 'Internet', 'Interview', 'Label', 'Laboratories', 'Laboratory Research', 'Language', 'Laws', 'Lead', 'Learning', 'Letters', 'Libraries', 'Life', 'Link', 'Location', 'Logic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mails', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Medical History', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Monitoring Clinical Trials', 'Nature', 'Neurofibromatoses', 'Notification', 'Online Systems', 'Optics', 'Outcome Study', 'Pamphlets', 'Paralysed', 'Participant', 'Pathologic', 'Pathology', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Physical environment', 'Physicians', 'Pilot Projects', 'Policies', 'Population', 'Population Study', 'Positron-Emission Tomography', 'Prevention strategy', 'Principal Investigator', 'Printing', 'Privacy', 'Procedures', 'Process', 'Production', 'Programming Languages', 'Proteomics', 'Protocol Compliance', 'Protocols documentation', 'Publications', 'Published Directory', 'Publishing', 'Qualifying', 'Quality Control', 'Quality of life', 'Radiology Specialty', 'Randomized', 'Rare Diseases', 'Reader', 'Recording of previous events', 'Records', 'Recovery', 'Recruitment Activity', 'Registries', 'Regulation', 'Relative (related person)', 'Reporting', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Subjects', 'Resolution', 'Resources', 'Risk', 'Role', 'SNOMED Clinical Terms', 'Sampling', 'Scanning', 'Schedule', 'Scientist', 'Secure', 'Security', 'Selection Bias', 'Self Assessment', 'Services', 'Side', 'Single-Gene Defect', 'Site', 'Site Visit', 'Source', 'Specific qualifier value', 'Specimen', 'Stream', 'Structure', 'Support Groups', 'Support System', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Translations', 'Trees', 'U-Series Cooperative Agreements', 'United States National Institutes of Health', 'Update', 'Validation', 'Variant', 'Videoconferences', 'Videoconferencing', 'Visit', 'Visual', 'Voice', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical research site', 'cluster computing', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'data mining', 'data modeling', 'data sharing', 'database design', 'database structure', 'demographics', 'design', 'distributed data', 'electronic data', 'eligible participant', 'experience', 'federal policy', 'federated computing', 'firewall', 'follow-up', 'forest', 'graphical user interface', 'improved', 'information display', 'interest', 'meetings', 'member', 'new technology', 'novel strategies', 'operation', 'optical character recognition', 'patient advocacy group', 'patient registry', 'predictive modeling', 'professor', 'programs', 'prospective', 'protocol development', 'quality assurance', 'radiologist', 'remediation', 'repository', 'research study', 'response', 'sample collection', 'software development', 'statistics', 'success', 'symposium', 'technology development', 'therapeutic development', 'tool', 'trafficking', 'user-friendly', 'vector', 'volunteer', 'web interface', 'web page', 'web services', 'web site', 'working group']",NINDS,UNIVERSITY OF SOUTH FLORIDA,U54,2013,304154,0.012825176746584501
"Machine learning methods to increase genomic accessibility by next-gen sequencing     DESCRIPTION (provided by applicant): DNA sequencing has become an indispensable tool in many areas of biology and medicine. Recent techno- logical breakthroughs in next-generation sequencing (NGS) have made it possible to sequence billions of bases quickly and cheaply. A number of NGS-based tools have been created, including ChIP-seq, RNA-seq, Methyl- seq and exon/whole-genome sequencing, enabling a fundamentally new way of studying diseases, genomes and epigenomes. The widespread use of NGS-based methods calls for better and more efficient tools for the analysis and interpretation of the NGS high-throughput data. Although a number of computational tools have been devel- oped, they are insufficient in mapping and studying genome features located within repeat, duplicated and other so-called unmappable regions of genomes. In this project, computational algorithms and software that expand genomic accessibility of NGS to these previously understudied regions will be developed.  The algorithms will begin with a new way of mapping raw reads from NGS to the reference genome, followed by a machine learning method to resolve ambiguously mapped reads, and will be integrated into a comprehen- sive analysis pipeline for ChIP-seq. More specifically, the three aims of the research are to develop: (1) Data structures and efficient algorithms for read mapping to rapidly identify all mapping locations. Unlike existing methods, the focus of this research is to rapidly identify all candidate locations of each read, instead of one or only a few locations. (2) Machine learning algorithms for read analysis to resolve ambiguously mapped reads for both ChIP-seq analysis and genetic variation detection. This work will develop probabilistic models to resolve ambiguously mapped reads by pooling information from the entire collection of reads. (3) A comprehensive ChIP- seq analysis pipeline to systematically study genomic features located within unmappable regions of genomes. These algorithms will be tested and refined using both publicly available data and data from established wet-lab collaborators.  In addition to discovering new genomic features located within repeat, duplicated or other previously unac- cessible regions, this work will provide the NGS community with (a) a faster and more accurate tool for mapping short sequence reads, (b) a general methodology for expanding genomic accessibility of NGS, and (c) a versatile, modular, open-source toolbox of algorithms for NGS data analysis, (d) a comprehensive analysis of protein-DNA interactions in repeat regions in all publicly available ChIP-seq datasets.  This work is a close collaboration between computer scientists and web-lab biologists who are developing NGS assays to study biomedical problems. In particular, we will collaborate with Timothy Osborne of Sanford- Burnham Medical Research Institute to study regulators involved in cholesterol and fatty acid metabolism, with Kyoko Yokomori of UC Irvine to study Cohesin, Nipbl and their roles in Cornelia de Lange syndrome, and Ken Cho of UC Irvine to study the roles of FoxH1 and Schnurri in development and growth control.        PUBLIC HEALTH RELEVANCE: DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.              DNA-sequencing has become an indispensable tool for basic biomedical research as well as for discovering new treatments and helping biomedical researchers understand disease mechanisms. Next-generation sequencing, which enables rapid generation of billions of bases at relatively low cost, poses a significant computational challenge on how to analyze the large amount of sequence data efficiently and accurately. The goal of this research is to develop open-source software to improve both the efficiency and accuracy of the next-generation sequencing analysis tools, and thereby allowing biomedical researchers to take full advantage of next-generation sequencing to study biology and disease.            ",Machine learning methods to increase genomic accessibility by next-gen sequencing,8350385,R01HG006870,"['Algorithms', 'Anus', 'Area', 'Base Sequence', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Research', 'Bruck-de Lange syndrome', 'ChIP-seq', 'Cholesterol', 'Chromatin', 'Collaborations', 'Collection', 'Communities', 'Computational algorithm', 'Computer software', 'Computers', 'DNA Sequence', 'DNA-Protein Interaction', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Disease', 'Exons', 'Facioscapulohumeral', 'Foundations', 'Generations', 'Genetic Variation', 'Genome', 'Genomics', 'Goals', 'Growth and Development function', 'Internet', 'Location', 'Machine Learning', 'Maps', 'Medical Research', 'Medicine', 'Methodology', 'Methods', 'Muscular Dystrophies', 'Procedures', 'Publishing', 'RNA', 'Reading', 'Research', 'Research Institute', 'Research Personnel', 'Role', 'Scientist', 'Sequence Analysis', 'Software Engineering', 'Speed', 'Statistical Models', 'Structure', 'Testing', 'Uncertainty', 'Work', 'base', 'cohesin', 'computerized tools', 'cost', 'fatty acid metabolism', 'functional genomics', 'genome sequencing', 'genome-wide', 'improved', 'insertion/deletion mutation', 'next generation', 'novel', 'open source', 'tool', 'transcription factor', 'xenopus development']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2012,220000,-0.015242536936925087
"ISMB 2012 Conference Support for Students & Young Scientists     DESCRIPTION (provided by applicant): The 2012 Intelligent Systems for Molecular Biology (ISMB) conference in will be held in Long Beach, California, with 1,500-1,700 attendees, including 33-38% students/post doctoral researchers. ISMB brings together graduate students, post doctoral researchers, faculty, research staff and senior scientists of many different nationalities, all of whom are studying or working in computer science, molecular biology, mathematics or statistics. The conference brings biologists and computational scientists together to focus on research centered on actual biological problems rather than simply theoretical calculations. The combined focus on ""intelligent systems"" and actual biological data makes ISMB a highly relevant meeting, and many years of producing the event has resulted in a professionally organized and respected annual conference. The ISMB conference presents the latest research methods and results developed through the application of computer programming to the study of biological sciences, including advances in sequencing genomes that may lead to a better understanding of how, for instance, cells interact for the treatment of diseases such as cancer. Presentations may describe methods and advances associated with the analysis of existing biological literature, including benchmarking experiments, to create a better public understanding of scientific research reports. Overall, ISMB serves to educate attendees on the latest developments that will further drive the research methods and results of the field of computational biology. Students and scientists are able to return to their labs to appy what they have learned as they advance their own research efforts or begin investigating new areas they were exposed to as a result of attending ISMB. The scientific program for each ISMB meeting includes parallel presentation tracks of original research papers, highlights of recently published papers, special sessions focused on emerging topics, technology demos, late breaking research and poster presentations, an art in science exhibition, tutorial workshops, special interest group meetings and a student symposium organized by and for students. For ISMB 2011, 258 original research papers were submitted and 48 selected for the Proceedings Track, while 88 previously published papers were submitted and 38 selected for the Highlights Track. In all, over 225 talks were presented during the course of the 2011 conference, and similar numbers are anticipated for 2012. In all cases, submissions are rigorously reviewed, typically by three members of each track's committee before approval by the track chair, insuring the highest possible quality of work is presented. The specific areas represented in the conference vary each year depending on the areas that researchers find most interesting and innovative, and therefore submit as papers and proposals. This proposal seeks funding to assist students and junior researchers in attending the conference, thus exposing them to the latest research of their own areas as well as areas that may be new to them.        PUBLIC HEALTH RELEVANCE: Bioinformatics is well established as an essential tool for understanding biological systems, largely driven by genomic sequence efforts due to the usefulness of genomic data in the quest to develop new and improved treatments for and prevention of disease is highly dependent on one's ability to electronically access and manipulate it. The Intelligent Systems for Molecular Biology (ISMB) conference series directly addresses these questions by showcasing the latest advances in the field and exposing what's on the horizon of future discoveries, but is distinguished from many other events in computational biology or artificial intelligence by an insistence that the researchers work with real molecular biology data, not theoretical or toy examples. Although the cultures of computer science and biology are so disparate, ISMB bridges this cultural gap by providing a forum among biological conferences that features technical advances as they occur, which otherwise may be shunned until a firm experimental result is published.              Bioinformatics is well established as an essential tool for understanding biological systems, largely driven by genomic sequence efforts due to the usefulness of genomic data in the quest to develop new and improved treatments for and prevention of disease is highly dependent on one's ability to electronically access and manipulate it. The Intelligent Systems for Molecular Biology (ISMB) conference series directly addresses these questions by showcasing the latest advances in the field and exposing what's on the horizon of future discoveries, but is distinguished from many other events in computational biology or artificial intelligence by an insistence that the researchers work with real molecular biology data, not theoretical or toy examples. Although the cultures of computer science and biology are so disparate, ISMB bridges this cultural gap by providing a forum among biological conferences that features technical advances as they occur, which otherwise may be shunned until a firm experimental result is published.            ",ISMB 2012 Conference Support for Students & Young Scientists,8317817,R13GM101868,"['Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Arts', 'Benchmarking', 'Binding', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Biology', 'California', 'Cells', 'Computational Biology', 'Computational Technique', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Educational workshop', 'Elements', 'Event', 'Evolution', 'Expert Systems', 'Faculty', 'Feedback', 'Financial Support', 'Funding', 'Future', 'Genomics', 'Graph', 'Group Meetings', 'Home environment', 'Human', 'International', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Limited Stage', 'Linguistics', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Metabolic Pathway', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Structure', 'Nationalities', 'Oral', 'Paper', 'Participant', 'Pattern Recognition', 'Peer Review', 'Phylogenetic Analysis', 'Postdoctoral Fellow', 'Published Comment', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Robotics', 'Science', 'Scientist', 'Senior Scientist', 'Sequence Analysis', 'Series', 'Specialist', 'Speed', 'Students', 'System', 'Technology', 'Time', 'Toy', 'Training', 'Validation', 'Work', 'biological systems', 'career', 'computer program', 'computer science', 'disorder prevention', 'exhibitions', 'experience', 'genome sequencing', 'graduate student', 'improved', 'information organization', 'innovation', 'interest', 'lectures', 'medical specialties', 'meetings', 'member', 'multidisciplinary', 'next generation', 'novel', 'parallel computing', 'posters', 'practical application', 'programs', 'research study', 'role model', 'satisfaction', 'skills', 'special interest group', 'statistics', 'symposium', 'tool']",NIGMS,INTERNATIONAL SOCIETY/COMP BIOLOGY,R13,2012,25000,0.019710018609179356
"Informatics Tools for High-Throughput Sequences Data Analysis    DESCRIPTION (provided by applicant): The Genome Analysis Toolkit (GATK) is a suite of best-in-class, widely-used, well-supported, open-source tools for processing and analysis of next-generation DNA sequencing (NGS) data. These tools currently  include a multiple sequence realigner, a covariate-correcting base quality score recalibrator, multi-sample  SNP, INDEL, and CNV genotypers, machine learning algorithms for false positive identification, variant  evaluation modules, somatic SNP and indel callers, and hundreds of other tools. Underlying all of these tools is our structured programming framework (GATK-Engine) that uses the functional programming philosophy of MapReduce to make writing feature-rich, efficient and robust analysis tools easy. By centralizing common data management infrastructure, all GATK-based tools benefit from the engine's correctness, CPU and memory efficiency, as well as automatic distributed and shared memory parallelization, essential capabilities given the massive and growing size of NGS datasets. The GATK currently supports all of the major sequencing technologies including lllumina. Life Sciences 454, and ABI SOLID, from hybrid capture of exomes to 1000s of low-pass samples in the 1000 Genomes Project. Our emphasis on technology-agnostic processing tools has helped to popularize the now standard SAM/BAM and VCFs formats for representing NGS data and variation calls, respectively. In this RFA we propose to  continue to develop the GATK-Engine and data processing tools to (1) achieve complete and accurate  variation discovery and genotyping for all major sequencing study designs and NGS technologies (2)  optimize the GATK-Engine and pipelining infrastructure to operate efficiently on distributed data sets at the  scale of tens of thousands of samples (3) extend the GATK data processing tools to support the upcoming  sequencing technologies of Complete Genomics, lon Torrent, and Pacific Biosciences as well as we do  current technologies, (4) expand significantly our educational and support structures to ensure that the longtail  of future NGS users can benefit from the best-practice data processing and analysis tools in the GATK.      PUBLIC HEALTH RELEVANCE: The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.              The proposed project aims to continue to develop the Genome Analysis Toolkit (GATK), a suite of widely used and mission-critical tools for analyzing the next-generation DNA sequencing data. With this grant we will improve these tools, make them more robust, and extend them to new sequencing technologies. This is essential to realize the potential of DNA sequencing to understand human history, diversity, and to discover  new loci associated with human disease, leading to new biologic hypotheses and new drug targets.            ",Informatics Tools for High-Throughput Sequences Data Analysis,8237596,U01HG006569,"['Algorithms', 'Biological Sciences', 'Communities', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Set', 'Documentation', 'Drug Delivery Systems', 'Ensure', 'Evaluation', 'Experimental Designs', 'Floods', 'Future', 'Genome', 'Genomics', 'Genotype', 'Grant', 'Human', 'Hybrids', 'Informatics', 'Machine Learning', 'Medical Genetics', 'Memory', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Philosophy', 'Process', 'Recording of previous events', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'SNP genotyping', 'Sampling', 'Site', 'Structure', 'Techniques', 'Technology', 'Variant', 'Work', 'Writing', 'base', 'cancer genetics', 'computerized data processing', 'data management', 'distributed data', 'distributed memory', 'exome', 'human disease', 'improved', 'next generation', 'novel', 'open source', 'programs', 'shared memory', 'tool']",NHGRI,"BROAD INSTITUTE, INC.",U01,2012,1010000,-0.03200769879398626
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8494858,U01HG004695,"['Address', 'Algorithms', 'Area', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Hypersensitivity', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'RNA', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2012,371054,0.0159003669394999
"Reactome: An Open Knowledgebase of Human Pathways     DESCRIPTION (provided by applicant): We seek renewal of the core operating funding for the Reactome Knowledgebase of Human Biological Pathways and Processes. Reactome is a curated knowledgebase available online as an open access resource that can be freely used and redistributed by all members of the biological research community. It is used by geneticists, genomics researchers, clinical researchers and molecular biologists to interpret the results of high-throughput experimental studies, by bioinformaticians seeking to develop novel algorithms for mining knowledge from genomics studies, and by systems biologists building predictive models of normal and abnormal pathways.  Our curational system draws heavily on the expertise of independent investigators within the community who author precise machine-readable descriptions of human biological pathways under the guidance of a staff of dedicated curators. Each pathway is extensively checked and peer-reviewed prior to publication to ensure its factual accuracy and compliance with the data model. A system of evidence tracking ensures that all assertions are backed up by the primary literature, and that human molecular events inferred from orthologous ones in animal models have an auditable inference chain. Curated pathways described by Reactome currently cover roughly one quarter of the translated portion of the genome. We also offer a network of ""functional interactions"" (FIs) predicted by a conservative machine-learning approach, that covers an additional quarter of the translated genome, for a combined coverage of roughly 50% of the known genome.  Over the next five years, we seek to (1) increase the number of curated proteins and other functional entities to at least 10,500; (2) to supplement normal pathways with variant reactions for 1200 genes representing disease states; (3) increase the size of the Reactome Fl network to 15,000 molecules; and (4) enhance the web site and other resources to meet the needs of a growing and diverse user community.        PUBLIC HEALTH RELEVANCE: RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                  RELEVANCE (See instructions):  Reactome represents one of a very small number of fully open access curated pathway databases. Its contents have contributed both directly and indirectly to large numbers of basic and translational research studies, and it supports a broad, diverse and engaged user community. As such it represents a key and irreplaceable community resource for genomics, genetics, systems biology, and translational researchers.                ",Reactome: An Open Knowledgebase of Human Pathways,8268588,U41HG003751,"['Algorithms', 'Animal Model', 'Back', 'Basic Science', 'Behavior', 'Biological', 'Clinical', 'Communities', 'Computer software', 'Computers', 'Databases', 'Disease', 'Disease Pathway', 'Ensure', 'Event', 'Funding', 'Generations', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Health', 'Human', 'Image', 'Instruction', 'Internet', 'Knowledge', 'Link', 'Lipids', 'Literature', 'Logic', 'Machine Learning', 'Maps', 'Mining', 'Molecular', 'Online Systems', 'Pathway interactions', 'Peer Review', 'Process', 'Protein Isoforms', 'Proteins', 'Publications', 'Reaction', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Software Tools', 'System', 'Systems Biology', 'Tablets', 'Time', 'Translating', 'Translational Research', 'Variant', 'Visual', 'base', 'biological research', 'data exchange', 'data modeling', 'improved', 'knowledge base', 'meetings', 'member', 'novel', 'predictive modeling', 'research study', 'small molecule', 'touchscreen', 'transcription factor', 'usability', 'web services', 'web site']",NHGRI,ONTARIO INSTITUTE FOR CANCER RESEARCH,U41,2012,1300000,-0.0015930295027058693
"EDAC: ENCODE Data Analysis Center     DESCRIPTION (provided by applicant): The objective of the Encyclopedia of DNA Elements (ENCODE) Project is to provide a complete inventory of all functional elements in the human genome using high-throughput experiments as well as computational methods. This proposal aims to create the ENCODE Data Analysis Center (EDAC, or the DAC), consisting of a multi-disciplinary group of leading scientists who will respond to directions from the Analysis Working Group (AWG) of ENCODE and thus integrate data generated by all groups in the ENCODE Consortium in an unbiased manner. These analyses will substantially augment the value of the ENCODE data by integrating diverse data types. The DAC members are leaders in their respective fields of bioinformatics, computational machine learning, algorithm development, and statistical theory and application to genomic data (Zhiping Weng, Manolis Kellis, Mark Gerstein, Mark Daly, Roderic Guigo, Shirley Liu, Rafael Irizarry, and William Noble). They have a strong track record of delivering collaborative analysis in the context of the ENCODE and modENCODE Projects, in which this group of researchers was responsible for the much of the analyses and the majority of the figures and tables in the ENCODE and modENCODE papers. The proposed DAC will pursue goals summarized as the following seven aims: Aim 1. To work with the AWG to define and prioritize integrative analyses of ENCODE data; Aim 2.To provide shared computational guidelines and infrastructure for data processing, common analysis tasks, and data exchange; Aim 3. To facilitate and carry out data integration for element-specific analyses; Aim 4.To facilitate and carry out exploratory data analyses across elements; Aim 5.To facilitate and carry out comparative analyses across human, mouse, fly, and worm; Aim 6.To facilitate integration with the genome-wide association studies community and disease datasets; and Aim 7.To facilitate writing Consortium papers and assist evaluating ENCODE data.         RELEVANCE: The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome. This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting this human genome and using it to understand human biology and improve human health.             RELEVANCE (See instructions):  The Encyclopedia of DNA Elements (ENCODE) Project is a coordinated effort to apply high-throughput, cost-efficient approaches to generate a comprehensive catalog of functional elements in the human genome.  This proposal establishes a data analysis center to support, facilitate, and enhance integrative analyses of the ENCODE Consortium, with the ultimate goal of facilitating the scientific and medical communities in interpreting the human genome and using it to understand human biology and improve human health",EDAC: ENCODE Data Analysis Center,8402447,U41HG007000,"['Address', 'Algorithms', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biological Sciences', 'Cataloging', 'Catalogs', 'Communities', 'Complement', 'Computing Methodologies', 'DNA', 'Data', 'Data Analyses', 'Data Collection', 'Data Element', 'Data Set', 'Development', 'Disease', 'Elements', 'Equipment and supply inventories', 'Freezing', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Indium', 'Instruction', 'Invertebrates', 'Investigation', 'Machine Learning', 'Manuscripts', 'Medical', 'Mus', 'National Human Genome Research Institute', 'Organism', 'Paper', 'Publishing', 'Records', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Scientist', 'Vertebral column', 'Vertebrates', 'Work', 'Writing', 'comparative', 'computerized data processing', 'cost', 'cost effectiveness', 'data exchange', 'data integration', 'fly', 'foot', 'genome wide association study', 'genome-wide', 'human disease', 'improved', 'insight', 'member', 'novel', 'research study', 'symposium', 'task analysis', 'theories', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U41,2012,2460045,0.004088077486549261
"Pattern Discovery for comparative epigenomics    DESCRIPTION (provided by applicant): We propose a training program that will prepare an effective independent investigator in computational genomics. The candidate has a PhD in biology from the University of Cambridge and will extend his skills in both computational and wet-lab methods through a two-year program of organized mentorship and training, and a structured five-year research program.  This program will promote the command of machine learning as applied to functional genomics data. Dr. William Noble will mentor the candidate's scientific development. Dr. Noble is a recognized leader in computational biology and machine learning. He holds a dual appointment as Associate Professor in Genome Sciences and Com- puter Science and Engineering, and has trained numerous postdoctoral fellows and graduate students. Dr. Jeff Bilmes, Associate Professor of Electrical Engineering, will contribute to the mentoring effort, and a committee of experienced genome and computational biologists will advise on science and the candidate's career goals.  Research will focus on the analysis of multiple tracks of data from high-throughput sequencing assays, such as the ChIP-seq data produced by the ENCODE Project. These experiments allow us to obtain a more complete picture of the structure of human chromatin, revealing the behavior of transcription factors, the organization of epigenetic modifications, and the locations of accessible DNA across the entire genome at up to single-base resolution. A current challenge is to discover joint patterns across multiple tracks of these functional genomics results simultaneously. This project will (1) develop computational methods for identifying such patterns, providing new ways of finding both well-understood genomic features and novel functional elements, (2) apply those methods to characterize the similarities and differences among different biological samples, establishing a better understanding of chromatin, the bounds of its variation, and its role in human disease, and (3) validate computational findings with laboratory experiments. The project will use a dynamic Bayesian network (DBN), a type of probabilistic graphical model, to represent the statistical dependencies between observed data, such as sequencing tag density, on an inferred hidden state sequence.  The Department of Genome Sciences of the University Of Washington School Of Medicine provides an ideal setting for training a new independent investigator with an extensive program of formal and informal education for postdoctoral scientists, opportunities for collaboration with researchers with expertise in diverse areas, and modern computational and laboratory resources. This environment maximizes the potential for the candidate to obtain the training and perform the research necessary to establish himself as a skilled investigator with an independent research program.         The major outcome of this work will be a trained scientist with the skills to run an independent research pro- gram integrating computational methods and genome biology. Additionally, the research will result in improved methodology and software resources for analyzing functional genomics data, and a better understanding of how chromatin state affects molecular biology and human disease.            ",Pattern Discovery for comparative epigenomics,8331495,K99HG006259,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Appointment', 'Area', 'Base Pairing', 'Behavior', 'Biological', 'Biological Assay', 'Biology', 'Cell physiology', 'Cells', 'Censuses', 'Chromatin', 'Chromatin Structure', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Methylation', 'DNA Sequence', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Data Sources', 'Deoxyribonucleases', 'Dependency', 'Development', 'Digestion', 'Disease', 'Doctor of Philosophy', 'Education', 'Electrical Engineering', 'Elements', 'Engineering', 'Enhancers', 'Environment', 'Epigenetic Process', 'Event', 'Exposure to', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Histocompatibility Testing', 'Human', 'Individual', 'Joints', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Molecular Biology', 'Molecular and Cellular Biology', 'Outcome', 'Pattern', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Probability', 'Qualifying', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Running', 'Sampling', 'Schools', 'Science', 'Scientist', 'Seeds', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'Techniques', 'Time', 'Training', 'Training Programs', 'Transfection', 'Transgenic Mice', 'Universities', 'Variant', 'Washington', 'Work', 'base', 'career', 'cell type', 'chromatin immunoprecipitation', 'clinically relevant', 'comparative', 'computer based statistical methods', 'computer science', 'cytokine', 'density', 'disorder control', 'empowered', 'epigenomics', 'experience', 'follow-up', 'functional genomics', 'genome-wide', 'graduate student', 'histone modification', 'human disease', 'human tissue', 'improved', 'network models', 'new technology', 'novel', 'professor', 'programs', 'promoter', 'research study', 'skills', 'speech processing', 'transcription factor']",NHGRI,UNIVERSITY OF WASHINGTON,K99,2012,103535,0.0004950074205160224
"Research Education in Statistical Genetics of Substance Abuse This application seeks support from the National Institute on Drug Abuse R25 mechanism for pre-doctoral and postdoctoral research positions at the Virginia Institute for Psychiatric and Behavioral Genetics (VIPBG) at Virginia Commonwealth University (VCU). The overall goal of this research education program is to provide an environment that encourages the development and application of statistical genetics at the highest levels. To accomplish this goal, a research education program in statistical genetics will been developed to foster interdisciplinary research, a key tenet of the NIDA mission, and which we believe is essential to conducting research in this field. Two areas of research focus are identified: Advanced Genetic Epidemiology and Statistical Molecular Genetics. These areas are synergistic and address a diverse variety of statistical methods, both those in current use and those under development. The research education program consists of pre-doctoral and postdoctoral components. Pre-doctoral participants will pursue degrees in either Human and Molecular Genetics or Biostatistics. This component is designed to recruit, at the earliest time in their careers, potential future investigators to research in statistical genetics focused on substance use, abuse and dependence (SUAD). The aim is to create a cohort of PhD graduates who are have been extensively exposed to, and begun to publish research in, this area at the outset of their research training. The postdoctoral component recognizes that many promising young researchers have training in areas relevant to, but not focused on, the statistical genetics of substance use and abuse. This flexible 2-3 year postdoctoral training component will help guide young investigators to this field of study and will provide them with integrated and focused training that will enable them to pursue careers in statistical genetics of SUAD. Research education is intended for individuals with training in mathematics, statistics, biostatistics, genetics, psychology or pharmacology and to those who have completed their clinical requirements for the MD degree. The goal of the postdoctoral component is to educate independent investigators who will contribute to the efforts to identify and characterize the genetic and environmental determinants of SUAD; they are expected to do so at VCU and at other institutions nationwide. To accomplish the overall program goal we will: i) Offer and carefully monitor a multidisciplinary integrated research training program with a range of research opportunities; ii) Meet the needs for training in emerging research areas in SUAD; iii) Provide training to researchers from diverse academic and ethnic backgrounds and intensive mentoring; iv) Provide a specialized curriculum that will merge strengths in SUAD research at our institution; and v) Disseminate course materials, developed software, user guides and example scripts to the wider community by teaching workshops and establishing a website with web casts, pod casts and script libraries. This project seeks support from the NIDA R25 research education program in statistical genetics of substance abuse. Two predoctoral and three postdoctoral participants will pursue individualized courses of training in statistical genetics, and participate in active research projects in the Virginia Institute for Psychiatric and Behavioral Genetics at Virginia Commonwealth University.",Research Education in Statistical Genetics of Substance Abuse,8305142,R25DA026119,"['Addictive Behavior', 'Address', 'Adolescent', 'Alcohol or Other Drugs use', 'Alcohols', 'Animal Model', 'Area', 'Behavioral', 'Behavioral Genetics', 'Biometry', 'Clinical', 'Commit', 'Communities', 'Comorbidity', 'Computer Simulation', 'Computer software', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Dependence', 'Development', 'Doctor of Philosophy', 'Education', 'Education Projects', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Epidemiologist', 'Exposure to', 'Faculty', 'Fostering', 'Foundations', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Polymorphism', 'Genetic Programming', 'Genetic Research', 'Genetics and Medicine', 'Genome Scan', 'Genotype', 'Goals', 'Grant', 'Health', 'Human', 'Human Genetics', 'Individual', 'Institutes', 'Institution', 'Interdisciplinary Study', 'Internet', 'Knowledge', 'Libraries', 'Machine Learning', 'Mathematics', 'Measurable', 'Mentors', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Mus', 'National Institute of Drug Abuse', 'O-(glucuronic acid 2-sulfate)-(1--4)-O-(2,5)-anhydromannitol 6-sulfate', 'Participant', 'Pattern', 'Pharmaceutical Preparations', 'Pharmacology', 'Pharmacology and Toxicology', 'Phenotype', 'Positioning Attribute', 'Postdoctoral Fellow', 'Predisposing Factor', 'Prevention', 'Psychiatry', 'Psychology', 'Psychometrics', 'Publishing', 'Queensland', 'Recruitment Activity', 'Relative (related person)', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Sampling', 'Scientist', 'Series', 'Statistical Methods', 'Statistical Models', 'Structure', 'Students', 'Substance abuse problem', 'Time', 'Training', 'Training Programs', 'Twin Multiple Birth', 'Universities', 'Virginia', 'Work', 'Writing', 'addiction', 'base', 'career', 'career development', 'cohort', 'computer science', 'design', 'experience', 'field study', 'flexibility', 'genetic epidemiology', 'genome wide association study', 'human subject', 'medical specialties', 'meetings', 'model development', 'multidisciplinary', 'novel', 'population based', 'post-doctoral training', 'pre-doctoral', 'professor', 'programs', 'psychogenetics', 'software development', 'statistics', 'tool', 'web site']",NIDA,VIRGINIA COMMONWEALTH UNIVERSITY,R25,2012,379949,-0.011505874025794116
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.         Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8337800,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Screening procedure', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2012,2751015,-0.008235334019173857
"Data Management and Coordinating Center (DMCC) This application seeks funding for the Data Management and Coordinating Center (DMCC) (formerly known as Data Technology Coordinating Center, DTCC) for the Rare Diseases Clinical Research Network (RDCRN). The applicant, Dr. Krischer, has served as the Principal Investigator for the DTCC for the last 5 years and seeks to renew the cooperative agreement for the DMCC which supports the Rare Diseases Clinical Research Network (RDCRN). The DMCC propose to extend the systems, processes, and procedures developed successfully over the last grant cycle to accommodate the 3000 subjects enrolled on 32 current studies, contingent upon the successful re-competition of their associated clinical research consortia, addition of new studies reflecting the growth of the network, accommodation of federated databases, work with consortia that have pre-existing infrastructure (registries, patient databases, etc.) and registries, provide a user friendly website for web-based recruitment which receives over 3.4 million hits per year at present and a 4000+ member contact registry enhanced for subjects seeking enrollment on clinical trials. We will continue development of new technologies to support scalability and generalizability and tools for cross-disease data mining. Our international clinical information network is secure providing coordinated data management services for collection, storage and analysis of diverse data types from multiple diseases and geographically disparate locations and a portal for the general public and larger community of clinical investigators. The proposed DMCC will facilitate clinical research in rare diseases by providing a test-bed for distributed  clinical data management that incorporates novel approaches and technologies for data management, data  mining, and data sharing across rare diseases, data types, and platforms; and access to information related  to rare diseases for basic and clinical researchers, academic and practicing physicians, patients, and the lay public.",Data Management and Coordinating Center (DMCC),8330246,U54NS064808,"['Access to Information', 'Accountability', 'Address', 'Adherence', 'Administrator', 'Adverse event', 'Agreement', 'Algorithms', 'Architecture', 'Archives', 'Area', 'Automatic Data Processing', 'Beds', 'Biological', 'Biological Markers', 'Biological Neural Networks', 'Bite', 'Businesses', 'Cancer Patient', 'Case Report Form', 'Cellular Phone', 'Characteristics', 'Classification', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Management', 'Clinical Protocols', 'Clinical Research', 'Clinical Research Associate', 'Clinical Research Protocols', 'Clinical Trials', 'Clinical Trials Cooperative Group', 'Clinical Trials Data Monitoring Committees', 'Code', 'Collaborations', 'Collection', 'Committee Members', 'Common Data Element', 'Common Terminology Criteria for Adverse Events', 'Communication', 'Communities', 'Computer Architectures', 'Computer Security', 'Computer software', 'Computers', 'Confidentiality', 'Consent Forms', 'Cost Savings', 'Custom', 'Cystic Fibrosis', 'Data', 'Data Analyses', 'Data Base Management', 'Data Collection', 'Data Element', 'Data Protection', 'Data Quality', 'Data Reporting', 'Data Security', 'Data Set', 'Databases', 'Decision Trees', 'Descriptor', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Directories', 'Disasters', 'Disease', 'Documentation', 'Drops', 'Drug Monitoring', 'Electronic Mail', 'Electronics', 'Eligibility Determination', 'Engineering', 'Enrollment', 'Ensure', 'Environment', 'Epidemiology', 'Etiology', 'Evaluation', 'Event', 'Exclusion Criteria', 'Expert Systems', 'Extensible Markup Language', 'Faculty', 'Family', 'Feedback', 'Flare', 'Foundations', 'Freezing', 'Frequencies', 'Funding', 'Future', 'General Population', 'Generations', 'Generic Drugs', 'Genetic', 'Genetic Transcription', 'Genus - Lotus', 'Grant', 'Graph', 'Grouping', 'Growth', 'Guidelines', 'Hand', 'Health', 'Human Resources', 'Image', 'Individual', 'Industry', 'Informatics', 'Information Networks', 'Information Systems', 'Informed Consent', 'Institution', 'Institutional Review Boards', 'Insulin-Dependent Diabetes Mellitus', 'International', 'Internet', 'Interview', 'Label', 'Laboratories', 'Laboratory Research', 'Language', 'Laws', 'Lead', 'Learning', 'Letters', 'Libraries', 'Life', 'Link', 'Location', 'Logic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mails', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Medical History', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Monitoring Clinical Trials', 'Nature', 'Neurofibromatoses', 'Notification', 'Online Systems', 'Optics', 'Outcome Study', 'Pamphlets', 'Paralysed', 'Participant', 'Pathologic', 'Pathology', 'Patient Outcomes Assessments', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Pharmacy facility', 'Phase', 'Physical environment', 'Physicians', 'Pilot Projects', 'Policies', 'Population', 'Population Study', 'Positron-Emission Tomography', 'Prevention strategy', 'Principal Investigator', 'Printing', 'Privacy', 'Procedures', 'Process', 'Production', 'Programming Languages', 'Proteomics', 'Protocol Compliance', 'Protocols documentation', 'Publications', 'Published Directory', 'Publishing', 'Qualifying', 'Quality Control', 'Quality of life', 'Radiology Specialty', 'Randomized', 'Rare Diseases', 'Reader', 'Recording of previous events', 'Records', 'Recovery', 'Recruitment Activity', 'Registries', 'Regulation', 'Relative (related person)', 'Reporting', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Subjects', 'Resolution', 'Resources', 'Risk', 'Role', 'SNOMED Clinical Terms', 'Sampling', 'Scanning', 'Schedule', 'Scientist', 'Secure', 'Security', 'Selection Bias', 'Self Assessment', 'Services', 'Side', 'Single-Gene Defect', 'Site', 'Site Visit', 'Source', 'Specific qualifier value', 'Specimen', 'Stream', 'Structure', 'Support Groups', 'Support System', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Translations', 'Trees', 'U-Series Cooperative Agreements', 'United States National Institutes of Health', 'Update', 'Validation', 'Variant', 'Videoconferences', 'Videoconferencing', 'Visit', 'Visual', 'Voice', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical research site', 'cluster computing', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'data mining', 'data modeling', 'data sharing', 'database design', 'database structure', 'demographics', 'design', 'distributed data', 'electronic data', 'eligible participant', 'experience', 'federal policy', 'federated computing', 'firewall', 'follow-up', 'forest', 'graphical user interface', 'improved', 'information display', 'interest', 'meetings', 'member', 'new technology', 'novel strategies', 'operation', 'optical character recognition', 'patient advocacy group', 'patient registry', 'predictive modeling', 'professor', 'programs', 'prospective', 'protocol development', 'quality assurance', 'radiologist', 'remediation', 'repository', 'research study', 'response', 'sample collection', 'software development', 'statistics', 'success', 'symposium', 'technology development', 'therapeutic development', 'tool', 'trafficking', 'user-friendly', 'vector', 'volunteer', 'web interface', 'web page', 'web services', 'web site', 'working group']",NINDS,UNIVERSITY OF SOUTH FLORIDA,U54,2012,2827142,0.012825176746584501
"CASE STUDIES IN BAYESIAN STATISTICS AND MACHINE LEARNING    DESCRIPTION (provided by applicant): Case Studies in Bayesian Statistics and Machine Learning I continues in the tradition of the Case Studies in Bayesian Statistics series. The original series of workshops were held in odd years at Carnegie Mellon University in the early fall. The first edition of the new workshop will be held at Carnegie Mellon University on October 14-15, 2011. The highest level goal of the workshop series is to generate and present successful solutions to difficult substantive problems in a wide variety of areas. The specific objectives of the workshop are to 1. Present and discuss solutions to challenging scientific problems that illustrate the potential for statistical machine learning approaches in substantive research; 2. Present an opportunity for statisticians and computer scientists to present applications-oriented research  that changes the way that data are analyzed in scientific fields; 3. Stimulate discussion of the challenges of the analysis of high-dimensional and complex datasets in a scientifically useful manner; 4. Encourage young researchers, including graduate students, to present their applied work; 5. Provide a small meeting atmosphere to facilitate the interaction of young researchers with senior colleagues; 6. Expose young researchers to important challenges and opportunities in collaborative research; 7. Include as participants women, under-represented minorities and persons with disabilities who might benefit from the small workshop environment; 8. Encourage dissemination of the findings presented at the workshop via well-documented and peer- reviewed journal articles.      PUBLIC HEALTH RELEVANCE: Bayesian and statistical machine learning approaches are essential for the analysis of data in the health sciences, particularly in complex diseases like cancer. The proposed workshop will highlight interesting applications of Bayesian and statistical machine learning, particularly in bioinformatics and imaging, which are relevant to cancer research and provide a venue for important collaboration amongst junior and senior researchers in statistics, computer science, and other disciplines.           Bayesian and statistical machine learning approaches are essential for the analysis of data in the health sciences, particularly in complex diseases like cancer. The proposed workshop will highlight interesting applications of Bayesian and statistical machine learning, particularly in bioinformatics and imaging, which are relevant to cancer research and provide a venue for important collaboration amongst junior and senior researchers in statistics, computer science, and other disciplines.         ",CASE STUDIES IN BAYESIAN STATISTICS AND MACHINE LEARNING,8203089,R13CA144626,"['Area', 'Bioinformatics', 'Case Study', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Data Analyses', 'Data Set', 'Disabled Persons', 'Discipline', 'Disease', 'Educational workshop', 'Environment', 'Fostering', 'Goals', 'Hand', 'Health Sciences', 'Image', 'Institutes', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'National Human Genome Research Institute', 'Participant', 'Peer Review', 'Research', 'Research Personnel', 'Scientist', 'Series', 'Solutions', 'Underrepresented Minority', 'Universities', 'Woman', 'Work', 'anticancer research', 'computer science', 'data modeling', 'falls', 'graduate student', 'interest', 'journal article', 'meetings', 'peer', 'planetary Atmosphere', 'statistics', 'symposium']",NCI,CARNEGIE-MELLON UNIVERSITY,R13,2011,7500,-0.0035762761271989026
"Intelligent Control Approach to Anemia Management    DESCRIPTION (provided by applicant):   Management of anemia due to end-stage renal disease is a multifactorial decision process involving administration of recombinant human erythropoietin (rHuEPO) and iron, as well as assessment of other factors influencing the progress of the disease. This application aims at improving the cost-effectiveness of this process through the use of state-of-the-art numerical tools from control engineering and machine learning. The specific aims are the collection of anemia management data and development of new guidelines for period of measuring hemoglobin levels if necessary, development of individualized, computer-assisted approach to rHuEPO dosing based on modern control engineering and machine learning approach, evaluation of the developed tools through numeric simulation and assessment of the potential improvements in therapy and projected savings in rHuEPO utilization. The final aim is to provide a physical implementation and to perform a clinical evaluation of the developed methodology. The applicant, Dr. Adam E. Gaweda, is an Instructor of Medicine in the Department of Medicine, Division of Nephrology at the University of Louisville. His original training is in the field of electrical engineering (M.Eng.) and computer science (Ph.D.). The applicant plans to develop as an independent and well established researcher in the field of biomedical engineering with focus on translation of state-of-the-art technology to heath care. To achieve this goal the applicant will enroll into the Clinical Research, Epidemiology and Statistics Training (CREST) Program at the University of Louisville, School of Public Health and Information Sciences       n/a",Intelligent Control Approach to Anemia Management,8062287,K25DK072085,"['Adverse event', 'Algorithms', 'Anemia', 'Anti-Arrhythmia Agents', 'Artificial Intelligence', 'Biological Models', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Collection', 'Comorbidity', 'Complex', 'Computer Assisted', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Controlled Clinical Trials', 'Data', 'Decision Support Systems', 'Development', 'Dialysis procedure', 'Disease', 'Doctor of Philosophy', 'Dose', 'Drug Prescriptions', 'Effectiveness', 'Electrical Engineering', 'End stage renal failure', 'Engineering', 'Enrollment', 'Epidemiology', 'Erythropoietin', 'Evaluation', 'Feedback', 'Frequencies', 'Funding', 'Goals', 'Guidelines', 'Health Sciences', 'Hemodialysis', 'Hemoglobin', 'Hemoglobin concentration result', 'Human', 'Individual', 'Information Sciences', 'Insulin', 'Iron', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Nephrology', 'Outcome', 'Patient Monitoring', 'Patients', 'Pharmaceutical Preparations', 'Physiological', 'Population', 'Process', 'Protocols documentation', 'Research', 'Research Personnel', 'Safety', 'Sampling', 'Savings', 'Schools', 'Techniques', 'Technology', 'Testing', 'Training', 'Training Programs', 'Translations', 'Universities', 'Veterans', 'Waran', 'Work', 'base', 'clinical practice', 'computer science', 'cost effectiveness', 'data management', 'experience', 'improved', 'insight', 'instructor', 'mathematical algorithm', 'novel', 'patient population', 'primary outcome', 'programs', 'recombinant human erythropoietin', 'research clinical testing', 'response', 'simulation', 'statistics', 'theories', 'tool']",NIDDK,UNIVERSITY OF LOUISVILLE,K25,2011,140381,0.01586836812124561
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.           Project Narrative The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.",Scalable Learning with Ensemble Techniques and Parallel Computing,8045486,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Biological Sciences', 'Biomedical Research', 'Classification', 'Communication', 'Communities', 'Community Financing', 'Companions', 'Complex', 'Computer software', 'Consult', 'Crowding', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Health', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Performance', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Randomized', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Validation', 'Voting', 'Work', 'base', 'computer cluster', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'new technology', 'next generation', 'parallel computing', 'programs', 'prototype', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSILICOS,R44,2011,374673,0.00546911570959752
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8107695,U01HG004695,"['Address', 'Algorithms', 'Area', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Hypersensitivity', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'RNA', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2011,108418,0.0159003669394999
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,8062031,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Dimensions', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Health', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'innate immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2011,359403,-0.002842712170123793
"Pattern Discovery for comparative epigenomics    DESCRIPTION (provided by applicant): We propose a training program that will prepare an effective independent investigator in computational genomics. The candidate has a PhD in biology from the University of Cambridge and will extend his skills in both computational and wet-lab methods through a two-year program of organized mentorship and training, and a structured five-year research program.  This program will promote the command of machine learning as applied to functional genomics data. Dr. William Noble will mentor the candidate's scientific development. Dr. Noble is a recognized leader in computational biology and machine learning. He holds a dual appointment as Associate Professor in Genome Sciences and Com- puter Science and Engineering, and has trained numerous postdoctoral fellows and graduate students. Dr. Jeff Bilmes, Associate Professor of Electrical Engineering, will contribute to the mentoring effort, and a committee of experienced genome and computational biologists will advise on science and the candidate's career goals.  Research will focus on the analysis of multiple tracks of data from high-throughput sequencing assays, such as the ChIP-seq data produced by the ENCODE Project. These experiments allow us to obtain a more complete picture of the structure of human chromatin, revealing the behavior of transcription factors, the organization of epigenetic modifications, and the locations of accessible DNA across the entire genome at up to single-base resolution. A current challenge is to discover joint patterns across multiple tracks of these functional genomics results simultaneously. This project will (1) develop computational methods for identifying such patterns, providing new ways of finding both well-understood genomic features and novel functional elements, (2) apply those methods to characterize the similarities and differences among different biological samples, establishing a better understanding of chromatin, the bounds of its variation, and its role in human disease, and (3) validate computational findings with laboratory experiments. The project will use a dynamic Bayesian network (DBN), a type of probabilistic graphical model, to represent the statistical dependencies between observed data, such as sequencing tag density, on an inferred hidden state sequence.  The Department of Genome Sciences of the University Of Washington School Of Medicine provides an ideal setting for training a new independent investigator with an extensive program of formal and informal education for postdoctoral scientists, opportunities for collaboration with researchers with expertise in diverse areas, and modern computational and laboratory resources. This environment maximizes the potential for the candidate to obtain the training and perform the research necessary to establish himself as a skilled investigator with an independent research program.       PUBLIC HEALTH RELEVANCE: The major outcome of this work will be a trained scientist with the skills to run an independent research pro- gram integrating computational methods and genome biology. Additionally, the research will result in improved methodology and software resources for analyzing functional genomics data, and a better understanding of how chromatin state affects molecular biology and human disease.              The major outcome of this work will be a trained scientist with the skills to run an independent research pro- gram integrating computational methods and genome biology. Additionally, the research will result in improved methodology and software resources for analyzing functional genomics data, and a better understanding of how chromatin state affects molecular biology and human disease.            ",Pattern Discovery for comparative epigenomics,8164533,K99HG006259,"['Accounting', 'Address', 'Affect', 'Algorithms', 'Appointment', 'Area', 'Base Pairing', 'Behavior', 'Biological', 'Biological Assay', 'Biology', 'Cell physiology', 'Cells', 'Censuses', 'Chromatin', 'Chromatin Structure', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'DNA', 'DNA Methylation', 'DNA Sequence', 'DNA-Binding Proteins', 'Data', 'Data Set', 'Data Sources', 'Deoxyribonucleases', 'Dependency', 'Development', 'Digestion', 'Disease', 'Doctor of Philosophy', 'Education', 'Electrical Engineering', 'Elements', 'Engineering', 'Enhancers', 'Environment', 'Epigenetic Process', 'Event', 'Exposure to', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Histocompatibility Testing', 'Human', 'Individual', 'Joints', 'Knowledge', 'Laboratories', 'Lead', 'Learning', 'Length', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modeling', 'Modification', 'Molecular Biology', 'Molecular and Cellular Biology', 'Outcome', 'Pattern', 'Phase', 'Phenotype', 'Postdoctoral Fellow', 'Probability', 'Qualifying', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Running', 'Sampling', 'Schools', 'Science', 'Scientist', 'Seeds', 'Signal Transduction', 'Signaling Molecule', 'Structure', 'Techniques', 'Time', 'Training', 'Training Programs', 'Transfection', 'Transgenic Mice', 'Universities', 'Variant', 'Washington', 'Work', 'base', 'career', 'cell type', 'chromatin immunoprecipitation', 'clinically relevant', 'comparative', 'computer based statistical methods', 'computer science', 'cytokine', 'density', 'disorder control', 'empowered', 'epigenomics', 'experience', 'follow-up', 'functional genomics', 'genome-wide', 'graduate student', 'histone modification', 'human disease', 'human tissue', 'improved', 'network models', 'new technology', 'novel', 'professor', 'programs', 'promoter', 'research study', 'skills', 'speech processing', 'transcription factor']",NHGRI,UNIVERSITY OF WASHINGTON,K99,2011,102709,-0.0032500677702027763
"ISMB 2011 Conference Support for Students & Young Scientists    DESCRIPTION (provided by applicant): ISMB 2011 Conference Travel Support for Students and Young Scientists.  The Intelligent Systems for Molecular Biology (ISMB) conference in 2011 will be held in Vienna, Austria, as a conference of approximately 1,500-1,700 attendees, including 33-38% students/post doctoral researchers. ISMB brings together graduate students, post doctoral researchers, faculty, research staff and senior scientists of many different nationalities, all of whom are studying or working in computer science, molecular biology, mathematics and/or statistics. The conference brings biologists and computational scientists together to focus on research centered on actual biological problems rather than simply theoretical calculations. The combined focus on ""intelligent systems"" and actual biological data makes ISMB a highly relevant meeting, and many years of producing the event has resulted in a well organized, well attended, and respected annual conference. The ISMB conference presents the latest research methods and results developed through the application of computer programming to the study of biological sciences, including advances in sequencing genomes that may lead to a better understanding of how, for instance, cells interact for the treatment of diseases such as cancer. Additionally, presentations may describe methods and advances associated with the analysis of existing biological literature, including benchmarking experiments, to create a better public understanding of scientific research reports. Overall, ISMB serves to educate attendees on the latest developments that will further drive the research methods and results of the field of computational biology. Students and scientists are able to return to their labs to apply what they have learned as they advance their own research efforts. The scientific program for each ISMB meeting comprises parallel presentation tracks of original research papers, highlights of recently published research, topically focused special sessions on emerging topics, technology demos, tutorial workshops, special interest group meetings and a student symposium organized by and for students. As an example, for ISMB 2010, 234 original research papers were submitted and 48 selected for the Proceedings Track; 126 published papers were submitted and 42 selected for the Highlights Track; nine proposals were submitted and four selected for presentation along with two invited for the Special Sessions Track. In all, well over 200 talks were presented during the course of the 2010 conference, and similar numbers are anticipated for 2011. In all cases, submissions are rigorously reviewed, typically by three members of each track's committee before approval by the track chair, insuring the highest possible quality of work is presented. The specific areas represented in the conference vary each year depending on the areas that researchers find most interesting and innovative, and therefore submit as papers and proposals. This proposal seeks funding to assist students and junior researchers in attending the conference, thus exposing them to the latest research of their own areas as well as areas that may be new to them.      PUBLIC HEALTH RELEVANCE: Relevance Bioinformatics is well established as an essential tool for understanding biological systems. The widespread recognition of bioinformatics has been largely driven by genomic sequence efforts, because laboratory scientists recognize that the usefulness of genomic data in the quest to develop new and improved treatments for and prevention of disease is highly dependent on one's ability to electronically access and manipulate it. Biologists are routinely integrating computational tools into their research programs and creating large predictive models based on information found in databases and other electronic resources. The Intelligent Systems for Molecular Biology (ISMB) conference series directly addresses these questions by showcasing the latest advances in the field, as well as exposing what's on the horizon of future discoveries.           Relevance Bioinformatics is well established as an essential tool for understanding biological systems. The widespread recognition of bioinformatics has been largely driven by genomic sequence efforts, because laboratory scientists recognize that the usefulness of genomic data in the quest to develop new and improved treatments for and prevention of disease is highly dependent on one's ability to electronically access and manipulate it. Biologists are routinely integrating computational tools into their research programs and creating large predictive models based on information found in databases and other electronic resources. The Intelligent Systems for Molecular Biology (ISMB) conference series directly addresses these questions by showcasing the latest advances in the field, as well as exposing what's on the horizon of future discoveries.         ",ISMB 2011 Conference Support for Students & Young Scientists,8121309,R13GM097938,"['Address', 'Algorithms', 'Area', 'Austria', 'Benchmarking', 'Binding', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Cells', 'Computational Biology', 'Computational Technique', 'Computer software', 'Computers', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Educational workshop', 'Electronics', 'Elements', 'Event', 'Evolution', 'Expert Systems', 'Faculty', 'Feedback', 'Financial Support', 'Funding', 'Future', 'Genomics', 'Graph', 'Group Meetings', 'Human', 'Industry', 'International', 'Knowledge', 'Laboratory Scientists', 'Lead', 'Learning', 'Limited Stage', 'Linguistics', 'Literature', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Metabolic Pathway', 'Methods', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Structure', 'Nationalities', 'Oral', 'Paper', 'Participant', 'Pattern Recognition', 'Peer Review', 'Phylogenetic Analysis', 'Postdoctoral Fellow', 'Published Comment', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Robotics', 'Role', 'Science', 'Scientist', 'Senior Scientist', 'Sequence Analysis', 'Series', 'Speed', 'Students', 'System', 'Technology', 'Time', 'Training', 'Travel', 'Validation', 'Vendor', 'Work', 'base', 'biological systems', 'career', 'computer program', 'computer science', 'computerized tools', 'cost', 'disorder prevention', 'exhibitions', 'experience', 'genome sequencing', 'graduate student', 'improved', 'information organization', 'innovation', 'interest', 'lectures', 'meetings', 'member', 'multidisciplinary', 'next generation', 'novel', 'parallel computing', 'posters', 'practical application', 'predictive modeling', 'programs', 'research study', 'role model', 'satisfaction', 'skills', 'special interest group', 'statistics', 'symposium', 'tool']",NIGMS,INTERNATIONAL SOCIETY/COMP BIOLOGY,R13,2011,20000,0.020571293846788855
"Genomic Database for the Yeast Saccharomyces    DESCRIPTION (provided by applicant): The goal of the Saccharomyces Genome Database (SGD) is to continue the development and implementation of a comprehensive resource containing curated information about the genome and its elements of the budding yeast, Saccharomyces cerevisiae. SGD will continue to annotate the genome, assimilate new data, include genomic information from other fungal species, and incorporate formalized and controlled vocabularies to represent biological concepts. We will continue to maintain and broaden relationships with the greater scientific community and make technical improvements through the development of tools and the use of third party tools that will allow us to better serve our users. The database and its associated resources will always remain publicly available without restriction from www.yeastgenome.org.  SGD will continue to provide the S. cerevisiae genome and its gene products culled from the published literature. New user interfaces and analysis resources will be developed for existing information as well as for new types of data, such as results from large scale genomic/proteomic analysis. These improvements will be developed using publicly available tools such as those available from the GMOD project. Query tools will be more enhanced to instantly direct users to the appropriate pages.  SGD has evolved into a substantial service organization, and will maintain its service to the scientific community, reaching out to all yeast researchers as well as scientists outside the fungal community to serve those who have a need for information about budding yeast genes, their products, and their functions. SGD will continue existing services while working to simplify the use and maintenance of our hardware and software environment through the application of new technologies. We will continue to collaborate with the yeast biology community to keep the database accurate and current, and to maintain consensus and order in the naming of genes and other generic elements.      PUBLIC HEALTH RELEVANCE:  Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,            Saccharomyces cerevisiae is a model forth understanding of chromosome maintenance, the cell cycle and cellular biology. S. cerevisiae is used for the development of new genomic and proteomic technologies. S. cerevisiae is the most well studied eukaryofic genome and the experimental literature for this yeast contains these results. The SGD provides a comprehensive resource that facilitates experimentation in other systems,         ",Genomic Database for the Yeast Saccharomyces,8242999,U41HG001315,"['Adopted', 'Affect', 'Architecture', 'Bioinformatics', 'Biological', 'Biology', 'Cell Cycle', 'Cells', 'Cellular biology', 'Chromatin', 'Chromosomes', 'Collaborations', 'Communities', 'Complex', 'Computer Analysis', 'Computer software', 'Consensus', 'Controlled Vocabulary', 'Data', 'Data Display', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Elements', 'Enhancers', 'Environment', 'Generic Drugs', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Individual', 'Industry', 'Internet', 'Knowledge', 'Laboratories', 'Learning', 'Link', 'Literature', 'Location', 'Maintenance', 'Manuals', 'Maps', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'Nomenclature', 'Phenotype', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Provider', 'Publishing', 'Regulatory Element', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Saccharomycetales', 'Scientist', 'Screening procedure', 'Secure', 'Services', 'Solutions', 'Source', 'System', 'Techniques', 'Technology', 'Universities', 'Untranslated Regions', 'Update', 'Variant', 'Work', 'Yeasts', 'abstracting', 'base', 'data mining', 'design', 'genome database', 'genome sequencing', 'human disease', 'improved', 'model organisms databases', 'mutant', 'new technology', 'promoter', 'tool', 'tool development', 'usability', 'web page']",NHGRI,STANFORD UNIVERSITY,U41,2011,2416667,-0.011782805631306915
"COMPUTATIONAL THINKING-Novel Machine Learning Approaches for Automati In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems.  To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING-Novel Machine Learning Approaches for Automati,8173654,76201000029C,"['Caring', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Complement', 'Computers', 'Contracts', 'Data', 'Databases', 'Decision Making', 'Electronic Health Record', 'Face', 'Family', 'Funding', 'Goals', 'Health Care Costs', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Memory', 'Patients', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Solutions', 'Speed', 'System', 'Thinking', 'biomedical scientist', 'data mining', 'flexibility', 'innovation', 'novel', 'novel strategies', 'rapid growth']",NLM,NORTHEASTERN UNIVERSITY,N03,2010,377968,0.010170809706158124
"COMPUTATIONAL THINKING - Combining multiple types of reasoning to infer plausible In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING - Combining multiple types of reasoning to infer plausible,8170612,76201000023C,"['Caring', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Face', 'Family', 'Funding', 'Goals', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Medical Informatics', 'Patients', 'Population', 'Process', 'Research', 'Research Personnel', 'Research Project Grants', 'System', 'Thinking', 'biomedical scientist', 'flexibility', 'innovation', 'novel strategies', 'prototype', 'rapid growth']",NLM,"CYCORP, INC.",N03,2010,377967,0.007055446634306322
"COMPUTATIONAL THINKING-Casual Inference on Narrative and Structured Temporal Dat  In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING-Casual Inference on Narrative and Structured Temporal Dat ,8172635,76201000024C,"['Caring', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Computers', 'Contracts', 'Data', 'Databases', 'Decision Making', 'Disease', 'Electronic Health Record', 'Face', 'Family', 'Funding', 'Human', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Patients', 'Population', 'Research', 'Research Personnel', 'Research Project Grants', 'Statistical Methods', 'Structure', 'System', 'Text', 'Thinking', 'biomedical scientist', 'clinical care', 'flexibility', 'innovation', 'novel strategies', 'rapid growth']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,N03,2010,373073,0.0055185504147254845
"COMPUTATIONAL THINKING-Automated Reasoning for Application of Clinical In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING-Automated Reasoning for Application of Clinical,8173644,76201000025C,"['Caring', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Computer Simulation', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Development', 'Face', 'Family', 'Funding', 'Goals', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Patient Care', 'Patients', 'Research', 'Research Personnel', 'Research Project Grants', 'System', 'Thinking', 'biomedical scientist', 'clinical application', 'evidence based guidelines', 'flexibility', 'improved', 'innovation', 'novel strategies', 'rapid growth']",NLM,STANFORD UNIVERSITY,N03,2010,378000,0.007909567975194516
"COMPUTATIONAL THINKING-Developing an Intelligent and Socially Oriented Search Que In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING-Developing an Intelligent and Socially Oriented Search Que,8173663,76201000032C,"['Caring', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Communities', 'Competence', 'Complement', 'Computers', 'Contracts', 'Data', 'Databases', 'Decision Making', 'Electronic Health Record', 'Face', 'Family', 'Funding', 'Goals', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Memory', 'Patients', 'Research', 'Research Personnel', 'Research Project Grants', 'Solutions', 'Speed', 'System', 'Thinking', 'biomedical scientist', 'flexibility', 'innovation', 'novel strategies', 'rapid growth', 'social']",NLM,UNIVERSITY OF MICHIGAN AT ANN ARBOR,N03,2010,301251,0.008797915895545934
"COMPUTATIONAL THINKING-Computational Thinking to Support Clinicians and Biomedica In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING-Computational Thinking to Support Clinicians and Biomedica,8173959,76201000034C,"['Caring', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Complement', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Face', 'Family', 'Funding', 'Goals', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Memory', 'Patients', 'Research', 'Research Personnel', 'Research Project Grants', 'Solutions', 'Speed', 'System', 'Thinking', 'biomedical scientist', 'clinical decision-making', 'flexibility', 'innovation', 'novel strategies', 'rapid growth']",NLM,"SAMSUNG SDS AMERICA, INC.",N03,2010,377925,0.010273103373475166
"COMPUTATIONAL THINKING-Computational Abduction for Molecular Biology In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING-Computational Abduction for Molecular Biology,8173956,76201000033C,"['Biology', 'Caring', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Complement', 'Computer software', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Face', 'Family', 'Funding', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Memory', 'Molecular Biology', 'Patients', 'Research', 'Research Personnel', 'Research Project Grants', 'Solutions', 'Speed', 'System', 'Thinking', 'biomedical scientist', 'data modeling', 'flexibility', 'innovation', 'novel strategies', 'open source', 'prototype', 'rapid growth']",NLM,UNIVERSITY OF COLORADO DENVER,N03,2010,377982,0.010107331555551451
"COMPUTTIONAL THINKING-An Evidence-Based, Open-Database Approach to Diagnostic Dec In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a","COMPUTTIONAL THINKING-An Evidence-Based, Open-Database Approach to Diagnostic Dec",8173645,76201000026C,"['Caring', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Complement', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Face', 'Family', 'Funding', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Memory', 'Patients', 'Population', 'Prevention', 'Research', 'Research Personnel', 'Research Project Grants', 'Solutions', 'Speed', 'System', 'Thinking', 'biomedical scientist', 'cost effectiveness', 'design', 'evidence base', 'flexibility', 'improved', 'innovation', 'novel strategies', 'rapid growth']",NLM,"SIMULCONSULT, INC.",N03,2010,377991,0.0087092077409402
"COMPUTATIONAL THINKING-Visual Clinical Problem Threading for Case Summarization In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING-Visual Clinical Problem Threading for Case Summarization,8173653,76201000028C,"['Age', 'Caring', 'Chronic Disease', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Complement', 'Complex', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Disease Management', 'Face', 'Family', 'Funding', 'Human', 'Imagery', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Machine Learning', 'Medical', 'Memory', 'Methods', 'Patients', 'Population', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Solutions', 'Speed', 'System', 'Thinking', 'Visual', 'biomedical scientist', 'design', 'flexibility', 'innovation', 'novel strategies', 'rapid growth']",NLM,"RUTGERS, THE STATE UNIV OF N.J.",N03,2010,300216,0.010276905153954739
"COMPUTATIONAL THINKING-Evidence-Based Expert Systems to Assist in Treatment of De In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING-Evidence-Based Expert Systems to Assist in Treatment of De,8173961,76201000035C,"['Caring', 'Childhood', 'Clinical', 'Cognition', 'Cognitive', 'Collaborations', 'Competence', 'Complement', 'Computers', 'Contracts', 'Databases', 'Decision Making', 'Development', 'Disease', 'Expert Systems', 'Face', 'Family', 'Funding', 'Goals', 'Human', 'Individual', 'Information Management', 'Intelligence', 'Knowledge', 'Lead', 'Machine Learning', 'Medical', 'Memory', 'Mental Depression', 'Outcome', 'Patients', 'Probability', 'Research', 'Research Personnel', 'Research Project Grants', 'Solutions', 'Speed', 'System', 'Thinking', 'biomedical scientist', 'evidence base', 'flexibility', 'health application', 'innovation', 'novel strategies', 'rapid growth', 'tool', 'treatment planning']",NLM,SRI INTERNATIONAL,N03,2010,377997,0.00920257574424465
"Intelligent Control Approach to Anemia Management    DESCRIPTION (provided by applicant):   Management of anemia due to end-stage renal disease is a multifactorial decision process involving administration of recombinant human erythropoietin (rHuEPO) and iron, as well as assessment of other factors influencing the progress of the disease. This application aims at improving the cost-effectiveness of this process through the use of state-of-the-art numerical tools from control engineering and machine learning. The specific aims are the collection of anemia management data and development of new guidelines for period of measuring hemoglobin levels if necessary, development of individualized, computer-assisted approach to rHuEPO dosing based on modern control engineering and machine learning approach, evaluation of the developed tools through numeric simulation and assessment of the potential improvements in therapy and projected savings in rHuEPO utilization. The final aim is to provide a physical implementation and to perform a clinical evaluation of the developed methodology. The applicant, Dr. Adam E. Gaweda, is an Instructor of Medicine in the Department of Medicine, Division of Nephrology at the University of Louisville. His original training is in the field of electrical engineering (M.Eng.) and computer science (Ph.D.). The applicant plans to develop as an independent and well established researcher in the field of biomedical engineering with focus on translation of state-of-the-art technology to heath care. To achieve this goal the applicant will enroll into the Clinical Research, Epidemiology and Statistics Training (CREST) Program at the University of Louisville, School of Public Health and Information Sciences       n/a",Intelligent Control Approach to Anemia Management,7802898,K25DK072085,"['Adverse event', 'Algorithms', 'Anemia', 'Anti-Arrhythmia Agents', 'Artificial Intelligence', 'Arts', 'Biological Models', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Collection', 'Comorbidity', 'Complex', 'Computer Assisted', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Controlled Clinical Trials', 'Data', 'Decision Support Systems', 'Development', 'Dialysis procedure', 'Disease', 'Doctor of Philosophy', 'Dose', 'Drug Prescriptions', 'Effectiveness', 'Electrical Engineering', 'End stage renal failure', 'Engineering', 'Enrollment', 'Epidemiology', 'Erythropoietin', 'Evaluation', 'Feedback', 'Frequencies', 'Funding', 'Goals', 'Guidelines', 'Hemodialysis', 'Hemoglobin', 'Hemoglobin concentration result', 'Human', 'Individual', 'Information Sciences', 'Insulin', 'Iron', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Nephrology', 'Outcome', 'Patient Monitoring', 'Patients', 'Pharmaceutical Preparations', 'Physiological', 'Population', 'Process', 'Protocols documentation', 'Public Health Schools', 'Research', 'Research Personnel', 'Safety', 'Sampling', 'Savings', 'Techniques', 'Technology', 'Testing', 'Training', 'Training Programs', 'Translations', 'Universities', 'Veterans', 'Waran', 'Work', 'base', 'clinical practice', 'computer science', 'cost effectiveness', 'data management', 'experience', 'improved', 'insight', 'instructor', 'mathematical algorithm', 'novel', 'patient population', 'primary outcome', 'programs', 'recombinant human erythropoietin', 'research clinical testing', 'response', 'simulation', 'statistics', 'theories', 'tool']",NIDDK,UNIVERSITY OF LOUISVILLE,K25,2010,136911,0.01586836812124561
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,8013208,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Arts', 'Biological Sciences', 'Biomedical Research', 'Cations', 'Classification', 'Communication', 'Communities', 'Companions', 'Complex', 'Computer software', 'Consult', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Imagery', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Performance', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Randomized', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Voting', 'Work', 'base', 'computer cluster', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'next generation', 'parallel computing', 'programs', 'prototype', 'public health relevance', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSILICOS,R44,2010,376899,0.005901800275242617
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,7913074,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,1248287,0.0159003669394999
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8121894,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,300000,0.0159003669394999
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8144973,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,113520,0.0159003669394999
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,8147585,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2010,151816,0.0159003669394999
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,8068069,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'innate immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'public health relevance', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2010,51400,-0.002842712170123793
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,7828142,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'innate immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'public health relevance', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2010,338802,-0.002842712170123793
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),8110238,U54CA121852,"['Address', 'Algorithms', 'Area', 'Binding', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Databases', 'Development', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Genes', 'Genetic Engineering', 'Genomics', 'Internet', 'Investigation', 'Literature', 'Machine Learning', 'Maps', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Research Personnel', 'Resources', 'Signal Pathway', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'base', 'biomedical ontology', 'computer framework', 'data mining', 'design', 'genome-wide', 'graphical user interface', 'knowledge base', 'multidisciplinary', 'natural language', 'novel', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2010,29814,-0.0545935827789462
"COMPUTATIONAL THINKING-Computational Abduction for Molecular Biology In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING-Computational Abduction for Molecular Biology,8173647,76201000027C,[' '],NLM,STANFORD UNIVERSITY,N03,2010,378000,0.010107331555551451
"COMPUTATIONAL THINKING-Text Mining of clinical narratives: In biomedicine, clinicians and researchers now face formidable challenges in information management, innovation, and decision-making in an era which is seeing extraordinarily rapid growth of knowledge, distributed among a host of databases, and on a scale far larger than can be mastered by an individual. The remarkable speed, memory capacity, and symbol-manipulating power of computers, if properly harnessed, can complement human cognitive strengths so as to enable efficient use of all of the knowledge relevant to solution of clinical and scientific problems. To invigorate research in the arena of computation and cognition, a number of fresh concepts have arisen in recent years: computational intelligence, machine learning, intelligence amplifying systems, flexible competence, human-computer collaboration, and computational thinking. As part of its ¿Medical Advanced Research Projects Initiative,¿ the NLM is funding novel approaches to computational thinking, in order to evaluate the feasibility of using innovative computational approaches to enhance the ability of clinicians and biomedical scientists to solve one or more significant cognitive tasks and bring improvements in medical care to patient, families and the public. n/a",COMPUTATIONAL THINKING-Text Mining of clinical narratives:,8173660,76201000031C,[' '],NLM,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,N03,2010,336943,0.008007831114711182
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7754089,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2010,2037327,-0.0016564585999463526
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,8115481,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'intelligence genetics', 'novel', 'operation', 'programs', 'resistant strain', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2010,99989,-0.012681918769059624
"Enhancing 3dsvm to improve its interoperability and dissemination    DESCRIPTION (provided by applicant): This research plan outlines crucial software enhancements to a program called 3dsvm, which is a command line program and graphical user interface (gui) plugin for AFNI (Cox, 1996). 3dsvm performs support vector machine (SVM) analysis on fMRI data, which constitutes one important approach to performing multivariate supervised learning of neuroimaging data. 3dsvm originally provided the ability to analyze fMRI data as described in (LaConte et al., 2005). Since its first distribution as a part of AFNI, it has been steadily extended to provide new functionality including regression and non-linear kernels, as well as multiclass classification capabilities. In addition to its integration into AFNI, features that make 3dsvm particularly well suited for fMRI analysis are that it is easy to spatially mask voxels (to include/exclude them in the SVM analysis) as well as to flexibly select subsets of a dataset to use as training or testing samples. It has been used to generate results for our own work and for collaborative efforts and has been cited as a resource by others (Mur et al. 2009; Hanke et al. 2009). Despite many positive aspects of 3dsvm, the priorities of PAR-07-417 address a genuine need that this software project has - the ability to focus on improvements that will increase its dissemination and interoperability. A major motivation for PAR-07-417 is to facilitate the improved interface, characterization, and documentation to enhance the extent of sharing and to provide the groundwork for future extensions. Our aims are well aligned with this program announcement. Further, there is a growing need in the neuroimaging community for tools such as 3dsvm. Since 3dsvm is not a new project, is tightly integrated into the software environment of AFNI, and can be further integrated to enable better functionality to support needs as diverse as NIfTI format capabilities to rtFMRI, this proposed project will help to further the NIH Blueprint for Neuroscience Research by supporting its need for wide-spread adoption of high-quality neuroimaging tools.      PUBLIC HEALTH RELEVANCE: This proposal focuses on improving, characterizing, and documenting an existing neuroinformatics software tool. The project described will help to further the NIH Blueprint for Neuroscience Research by supporting its need for wide-spread adoption of high-quality neuroimaging tools.           NARRATIVE This proposal focuses on improving, characterizing, and documenting an existing neuroinformatics software tool. The project described will help to further the NIH Blueprint for Neuroscience Research by supporting its need for wide-spread adoption of high-quality neuroimaging tools.",Enhancing 3dsvm to improve its interoperability and dissemination,8278135,R03EB012464,[' '],NIBIB,VIRGINIA POLYTECHNIC INST AND ST UNIV,R03,2010,156500,0.004549704943915272
"Informatics Core for the Collaborative Initiative on Fetal Alcohol Spectrum disor    DESCRIPTION (provided by applicant): The Informatics Core is part of the Consortium for the ""Collaborative Initiative on Fetal Alcohol Spectrum Disorders"" (CIFASD). The theme of this collaborative initiative is a cross-cultural assessment of ""fetal alcohol spectrum disorder"" (FASD). The CIFASD will coordinate basic, behavioral, and clinical investigators in a multidisciplinary research project to better inform approaches aimed at developing effective intervention and treatment approaches for FASD. It will involve the input and contributions from basic researchers, behavioral scientists, and clinical investigators with the willingness to utilize novel and cutting-edge techniques so as not to simply replicate previous or ongoing work, but rather to try and move it forward in a rigorous fashion. The Informatics Core will develop and maintain the CIFASD Data Repository, which will be used to collect, maintain and distribute data generated by the various participants in the consortium. The Informatics Core will be responsible for working with the other consortium participants to define a Data Dictionary to be used in standardizing data collection, enabling the transfer of data to and from the CIFASD Data Repository, consulting on how to establish local data management systems, providing both software tools and consulting to consortium participants, and producing status reports about the progress of the various projects within the consortium. The Informatics Core draws on a wealth of resources, experience, and expertise at Indiana University in information technology infrastructure and data management, The CIFASD Data Repository will be developed on Indiana University's state-of-the-art central supercomputing facilities, taking advantage of Indiana University's strong commitment to institutional computational resources. Resources that will be used to implement the CIFASD Data Repository include multiple supercomputers, an array of readily available database and statistical software, and a high- speed, secure, robust data archiving system capable of storing duplicate copies in multiple physical locations separated by more than fifty miles. The Informatics Core will use these extraordinary computational resources to provide a single, highly secure location for consortium participants to obtain the cross-cultural data that will enable the CIFASD to meet its goals of developing novel techniques for intervention and treatment of FASD.           n/a",Informatics Core for the Collaborative Initiative on Fetal Alcohol Spectrum disor,7900050,U24AA014818,"['Address', 'Adolescent', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Archives', 'Arts', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cells', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Collaborations', 'Computer Systems', 'Computer software', 'Consult', 'Data', 'Data Analyses', 'Data Collection', 'Data Storage and Retrieval', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Dictionary', 'Dietary Intervention', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early treatment', 'Elements', 'Emotional', 'Ethanol', 'Ethnic group', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Indiana', 'Individual', 'Infant', 'Informal Social Control', 'Informatics', 'Information Technology', 'Interdisciplinary Study', 'Internet', 'Intervention', 'Knowledge', 'Label', 'Language', 'Language Development', 'Life', 'Location', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Mission', 'Modeling', 'Moscow', 'Mothers', 'Mus', 'Names', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'New Mexico', 'Outcome', 'Participant', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Rattus', 'Recording of previous events', 'Reporting', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Schools', 'Scientist', 'Secure', 'Sensitivity and Specificity', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Software Tools', 'Specificity', 'Speed', 'Structure', 'Sum', 'Supercomputing', 'Supplementation', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Three-Dimensional Image', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Universities', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'brain behavior', 'brain morphology', 'cognitive control', 'computing resources', 'critical period', 'data exchange', 'data integration', 'data management', 'data sharing', 'distributed data', 'drinking', 'effective intervention', 'experience', 'fetal', 'flexibility', 'follow-up', 'imaging modality', 'improved', 'in utero', 'infancy', 'literacy', 'meetings', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'offspring', 'prenatal', 'prospective', 'quality assurance', 'reconstruction', 'repository', 'social', 'supercomputer', 'three dimensional structure', 'willingness']",NIAAA,INDIANA UNIVERSITY BLOOMINGTON,U24,2010,192573,-0.031595395854301905
"Data Management and Coordinating Center (DMCC) This application seeks funding for the Data Management and Coordinating Center (DMCC) (formerly known as Data Technology Coordinating Center, DTCC) for the Rare Diseases Clinical Research Network (RDCRN). The applicant, Dr. Krischer, has served as the Principal Investigator for the DTCC for the last 5 years and seeks to renew the cooperative agreement for the DMCC which supports the Rare Diseases Clinical Research Network (RDCRN). The DMCC propose to extend the systems, processes, and procedures developed successfully over the last grant cycle to accommodate the 3000 subjects enrolled on 32 current studies, contingent upon the successful re-competition of their associated clinical research consortia, addition of new studies reflecting the growth of the network, accommodation of federated databases, work with consortia that have pre-existing infrastructure (registries, patient databases, etc.) and registries, provide a user friendly website for web-based recruitment which receives over 3.4 million hits per year at present and a 4000+ member contact registry enhanced for subjects seeking enrollment on clinical trials. We will continue development of new technologies to support scalability and generalizability and tools for cross-disease data mining. Our international clinical information network is secure providing coordinated data management services for collection, storage and analysis of diverse data types from multiple diseases and geographically disparate locations and a portal for the general public and larger community of clinical investigators. The proposed DMCC will facilitate clinical research in rare diseases by providing a test-bed for distributed  clinical data management that incorporates novel approaches and technologies for data management, data  mining, and data sharing across rare diseases, data types, and platforms; and access to information related  to rare diseases for basic and clinical researchers, academic and practicing physicians, patients, and the lay public.",Data Management and Coordinating Center (DMCC),8150047,U54NS064808,"['Address', 'Adherence', 'Algorithms', 'Architecture', 'Archives', 'Area', 'Automatic Data Processing', 'Beds', 'Biological', 'Bite', 'Cancer Patient', 'Case Report Form', 'Cellular Phone', 'Characteristics', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Research Associate', 'Clinical Research Protocols', 'Clinical Trials Cooperative Group', 'Collaborations', 'Collection', 'Committee Members', 'Common Data Element', 'Common Terminology Criteria for Adverse Events', 'Computer software', 'Custom', 'Cystic Fibrosis', 'Data', 'Data Analyses', 'Data Collection', 'Data Element', 'Data Quality', 'Data Reporting', 'Data Set', 'Databases', 'Decision Trees', 'Descriptor', 'Development', 'Diagnosis', 'Diagnostic radiologic examination', 'Disasters', 'Disease', 'Electronic Mail', 'Electronics', 'Eligibility Determination', 'Engineering', 'Enrollment', 'Ensure', 'Environment', 'Epidemiology', 'Etiology', 'Evaluation', 'Event', 'Exclusion Criteria', 'Expert Systems', 'Extensible Markup Language', 'Faculty', 'Family history of', 'Feedback', 'Flare', 'Foundations', 'Freezing', 'Frequencies', 'Funding', 'Future', 'Genetic', 'Genetic Transcription', 'Genus - Lotus', 'Grant', 'Grouping', 'Growth', 'Guidelines', 'Hand', 'Health', 'Image', 'Individual', 'Industry', 'Information Networks', 'Information Systems', 'Informed Consent', 'Institution', 'Insulin-Dependent Diabetes Mellitus', 'International', 'Internet', 'Interview', 'Label', 'Laboratories', 'Laboratory Research', 'Language', 'Laws', 'Lead', 'Learning', 'Letters', 'Libraries', 'Life', 'Link', 'Location', 'Logic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mails', 'Manuals', 'Maps', 'Mechanics', 'Medical', 'Medical History', 'Methodology', 'Methods', 'Monitor', 'Monitoring Clinical Trials', 'Nature', 'Neurofibromatoses', 'Notification', 'Online Systems', 'Optics', 'Outcome Study', 'Pamphlets', 'Paralysed', 'Pathologic', 'Pathology', 'Patient Outcomes Assessments', 'Patients', 'Persons', 'Pharmacy facility', 'Phase', 'Physical environment', 'Physicians', 'Pilot Projects', 'Policies', 'Positron-Emission Tomography', 'Principal Investigator', 'Printing', 'Procedures', 'Process', 'Production', 'Programming Languages', 'Protocol Compliance', 'Protocols documentation', 'Publications', 'Published Directory', 'Publishing', 'Qualifying', 'Quality Control', 'Quality of life', 'Radiology Specialty', 'Randomized', 'Reader', 'Records', 'Recovery', 'Recruitment Activity', 'Registries', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Resources', 'Risk', 'Role', 'SNOMED Clinical Terms', 'Scanning', 'Scientist', 'Security', 'Selection Bias', 'Self Assessment', 'Services', 'Side', 'Single-Gene Defect', 'Site', 'Site Visit', 'Source', 'Specific qualifier value', 'Specimen', 'Stream', 'Support Groups', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Translations', 'Trees', 'U-Series Cooperative Agreements', 'United States National Institutes of Health', 'Update', 'Validation', 'Variant', 'Videoconferences', 'Videoconferencing', 'Visit', 'Visual', 'Voice', 'Work', 'X-Ray Computed Tomography', 'base', 'computerized data processing', 'data management', 'data mining', 'electronic data', 'follow-up', 'improved', 'interest', 'meetings', 'patient advocacy group', 'programs', 'quality assurance', 'radiologist', 'sample collection', 'statistics', 'tool', 'web site', 'working group']",NINDS,UNIVERSITY OF SOUTH FLORIDA,U54,2010,959195,0.012825176746584501
"National Center: Multiscale Analysis of Genomic and Cellular Networks (MAGNet) A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.   n/a",National Center: Multiscale Analysis of Genomic and Cellular Networks (MAGNet),8012947,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2010,3757192,-0.053710166863221775
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.      CRITQUE 1:      The Bioconductor project began in 2001. In 2002 it was awarded a BISTI grant for three years 2003-2006). During this time the project has expanded and provided support for a world wide community of researchers. This is a proposal for continued development for Bioconductor, which is a set of statistical programs which are specifically tailored to the computatational biology community. Bioconductor is composed of over 130 R packages that have been contributed by a large number of developers. The software packages range from state of the art statistical methods which typically are used in microarray analysis, to annotation tools, to plotting functions, GUIs, to sequence alignment and data management packages. Contributions to and usage of Bioconductor is growing rapidly and the applicants are requesting support to continue its development as well as general logistical support for software distribution and quality assurance. The proposal includes a research component for Bioconductor which will involve the development of analysis techniques. This will include optimization of the R statistical analyses, statistical processing of Affymetrix data, analysis of SNP data, improved standards, data storage, retreivals from NCBI, sequence management, machine learning, web services and distributed computing.      SCIENTIFIC MERIT   The applicants address many issues that are crucial to the success of a large open source project with multiple contributors. Examples of training, scientific publication, documentation and resource development run throughout the proposal. Many tangible examples were given on the usage of the system by the scientific community.        EXPERIMENTAL DESIGN   This is a description of their management workflow for the project which does a good job of demonstrating the technical excellence brought to the project by this group. 1) Build annotation packages every three months, Integrate changes in annotation source data structure into annotation package building code. 2) Maintain project website, mailing lists, source control archive. Organize web resources for short course and conferences. 3) Improve existing software. 4) Sustain automated nightly builds. Work with developers whose packages fail to pass QA. 5) Resolve cross-platform issues. 6) Review new submissions. Answer questions on the mailing lists. 7) Use software engineering best practices. Develop unit testing strategies. Design appropriate classes and methods for new data types. Refactor existing code for better interoperability and extensibility. 8) Develop and organize training materials and documentation.      Extensive detail on testing, build procedures, interoperability, quality assurance and project management is given elsewhere in the document. They clearly have dealt with many issues necessary for a project of this size. They state that one of the biggest cost items is support of this package to run on multiple platforms. They point out that many contributors focus on a single platform, much of their work is track down cross-platform bugs. This is time well-spent, given the platforms used are in sync with the needs of the greater bioinformatics community.        ORIGINALITY   While a high degree of originality is not a particularly critical element of open source software development project, there are certainly areas in the proposal that are unique. Most importantly, it is safe to say that there is not another project which has this blend of statistical analysis systems specifically tailored to a important research bioinformatics area that can be deployed on a number of different computer environments.      INVESTIGATOR AND CO-INVESTIGATORS   Dr. Gentleman is the founder and leader of the Bioconductor project. Dr. Gentlemen was an Associate Professor in the Department of Biostatistics, Harvard School of Public Health and Department of Biostatistics and Computational Biology, Dana Farber Cancer Institute. In 2004 he became Program Head, Computational Biology, at the Fred Hutchinson Cancer Research Center in Seattle. He has on the order of ten publications relating to Bioconductor or related statistical analysis. He implemented the original versions of the R programming language jointly with another co-founder. He is PI or Investigator of a number of research grants, at least two are directly related to this work. He and other members of the proposal have taught a number of courses and given lectures on Bioconductor, the amount of these courses certainly indicate significant dedication to the project.  A review of the PI and Co-PI activities related to this project are shown on Table 3 on page 42 of the application. The roles and time allocations assigned to each participant appear to be reasonable.  Dr. Gentleman will serve as project leader and will manage the programmers, coordinating the project, and investigating new computational methods and approaches.  Dr. Vincent Carey, as co Principal Investigator has 20% time allocated for the project.  In 2005 he became Associate Professor of Medicine (Biostatistics). Carey is a senior member of the Bioconductor development core. He will improve interoperability to allow Bioconductor reuse of external modules in Java, Perl and other languages as well as strengthen interfaces between high throughput experimental workflows and machine learning tools, and ontology capture.  An administrative assistant will assist Dr. Carey with administrative requirements, including call coordination, manuscript preparation and distribution, scheduling and budget management.  Dr. Rafael Irizarry as co-PI will spend 30% effort on the project.  Dr. Irizarry has four years experience developing methods for microarray data analysis and in the Department of Biostatistics serving as faculty liaison to the Johns Hopkins Medical Institution's Microarray Core.  He will supervize all efforts to support preprocessing on all platforms and support for microarray related consortiums such as the ERCC, GEO, and ArrayExpress.      Programmers will be responsible for the project website, managing email lists, maintaining training materials, upgrading software, refactoring and other code enhancements, managing the svn archive, and Bioconductor releases. They will handle checking all submitted packages, developing unit tests, and simplifying downloads, nightly build procedures, cross-platform issues, data technologies as well as integrating resources found in other languages (e.g. large C libraries of routines for string handling, machine learning and so on). Programmers have familiarity with R packages and systems for database management and for parallel and distributed computing. They will be responsible for managing the annotation data including package building and liaising with organism specific and other data providers.      SIGNIFICANCE   Given the scope of the proposal, and the size of the Bioconductor project in general the request for the above resources is appropriate. There is an excellent mix of grounded project management along with development of newer state of the art techniques that will benifit many members of the bioinformatics community. There is a high probability that funding this project will help to maintain and advance this important community resource.      ENVIRONMENT   The computer infrastructure, and the local departments of the PI and Co-PIs, as well as the work with the larger scientific community are all excellent environments to support this project.      IN SUMMARY   This is a terrific resource.  It is a well managed large open source project with very well crafted QA testing, documentation and training.  Continuation of this is a three year project. Beyond that period, a statement of long term stated goals is needed. The PI should articulate the strategic goals, as well as their research motivation and translate that into an action plan. They should also use that context to describe how they would go about choosing packages that are put into the Bioconductor system; Table 3 only listed the names of the packages made by the applicants, it could have gone further to give the reader more information for choosing packages.  A simple example would have been if they stated in the document: ""Given our assessment of the microarray state of the art, we ultimately aim to overlay annotation data, ontological information, and other forms of meta data onto a statistical framework for expression data."" The resulting research plan would then justify a five year project, but it was not strong enough in this application.       It should be noted that many of the benificiaries to this system are not just users that download the system.  In many cases a centralized informatics service downloads their system and then performs analysis for other members of the campus or the wider www community. While that type of ""success measure"" is hard to assess, more effort in this area in subsequent proposals would be helpful.           n/a",Bioconductor: an open computing resource for genomics,7910730,P41HG004059,[' '],NHGRI,FRED HUTCHINSON CANCER RESEARCH CENTER,P41,2010,1093220,-0.00027839569859696475
"Intelligent Control Approach to Anemia Management    DESCRIPTION (provided by applicant):   Management of anemia due to end-stage renal disease is a multifactorial decision process involving administration of recombinant human erythropoietin (rHuEPO) and iron, as well as assessment of other factors influencing the progress of the disease. This application aims at improving the cost-effectiveness of this process through the use of state-of-the-art numerical tools from control engineering and machine learning. The specific aims are the collection of anemia management data and development of new guidelines for period of measuring hemoglobin levels if necessary, development of individualized, computer-assisted approach to rHuEPO dosing based on modern control engineering and machine learning approach, evaluation of the developed tools through numeric simulation and assessment of the potential improvements in therapy and projected savings in rHuEPO utilization. The final aim is to provide a physical implementation and to perform a clinical evaluation of the developed methodology. The applicant, Dr. Adam E. Gaweda, is an Instructor of Medicine in the Department of Medicine, Division of Nephrology at the University of Louisville. His original training is in the field of electrical engineering (M.Eng.) and computer science (Ph.D.). The applicant plans to develop as an independent and well established researcher in the field of biomedical engineering with focus on translation of state-of-the-art technology to heath care. To achieve this goal the applicant will enroll into the Clinical Research, Epidemiology and Statistics Training (CREST) Program at the University of Louisville, School of Public Health and Information Sciences       n/a",Intelligent Control Approach to Anemia Management,7597080,K25DK072085,"['Adverse event', 'Algorithms', 'Anemia', 'Anti-Arrhythmia Agents', 'Artificial Intelligence', 'Arts', 'Biological Models', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Collection', 'Complex', 'Computer Assisted', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Controlled Clinical Trials', 'Data', 'Decision Support Systems', 'Development', 'Dialysis procedure', 'Disease', 'Doctor of Philosophy', 'Dose', 'Drug Prescriptions', 'Effectiveness', 'Electrical Engineering', 'End stage renal failure', 'Engineering', 'Enrollment', 'Epidemiology', 'Erythropoietin', 'Evaluation', 'Feedback', 'Frequencies', 'Funding', 'Goals', 'Guidelines', 'Hemodialysis', 'Hemoglobin', 'Hemoglobin concentration result', 'Human', 'Individual', 'Information Sciences', 'Insulin', 'Iron', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Nephrology', 'Outcome', 'Patient Monitoring', 'Patients', 'Pharmaceutical Preparations', 'Physiological', 'Population', 'Process', 'Protocols documentation', 'Public Health Schools', 'Research', 'Research Personnel', 'Safety', 'Sampling', 'Savings', 'Techniques', 'Technology', 'Testing', 'Training', 'Training Programs', 'Translations', 'Universities', 'Veterans', 'Waran', 'Work', 'base', 'clinical practice', 'computer science', 'cost effectiveness', 'data management', 'experience', 'improved', 'insight', 'instructor', 'mathematical algorithm', 'novel', 'patient population', 'primary outcome', 'programs', 'recombinant human erythropoietin', 'research clinical testing', 'response', 'simulation', 'statistics', 'theories', 'tool']",NIDDK,UNIVERSITY OF LOUISVILLE,K25,2009,138161,0.01586836812124561
"Intelligent Control Approach to Anemia Management    DESCRIPTION (provided by applicant):   Management of anemia due to end-stage renal disease is a multifactorial decision process involving administration of recombinant human erythropoietin (rHuEPO) and iron, as well as assessment of other factors influencing the progress of the disease. This application aims at improving the cost-effectiveness of this process through the use of state-of-the-art numerical tools from control engineering and machine learning. The specific aims are the collection of anemia management data and development of new guidelines for period of measuring hemoglobin levels if necessary, development of individualized, computer-assisted approach to rHuEPO dosing based on modern control engineering and machine learning approach, evaluation of the developed tools through numeric simulation and assessment of the potential improvements in therapy and projected savings in rHuEPO utilization. The final aim is to provide a physical implementation and to perform a clinical evaluation of the developed methodology. The applicant, Dr. Adam E. Gaweda, is an Instructor of Medicine in the Department of Medicine, Division of Nephrology at the University of Louisville. His original training is in the field of electrical engineering (M.Eng.) and computer science (Ph.D.). The applicant plans to develop as an independent and well established researcher in the field of biomedical engineering with focus on translation of state-of-the-art technology to heath care. To achieve this goal the applicant will enroll into the Clinical Research, Epidemiology and Statistics Training (CREST) Program at the University of Louisville, School of Public Health and Information Sciences       n/a",Intelligent Control Approach to Anemia Management,7920591,K25DK072085,"['Adverse event', 'Algorithms', 'Anemia', 'Anti-Arrhythmia Agents', 'Artificial Intelligence', 'Arts', 'Biological Models', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Collection', 'Complex', 'Computer Assisted', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Controlled Clinical Trials', 'Data', 'Decision Support Systems', 'Development', 'Dialysis procedure', 'Disease', 'Doctor of Philosophy', 'Dose', 'Drug Prescriptions', 'Effectiveness', 'Electrical Engineering', 'End stage renal failure', 'Engineering', 'Enrollment', 'Epidemiology', 'Erythropoietin', 'Evaluation', 'Feedback', 'Frequencies', 'Funding', 'Goals', 'Guidelines', 'Hemodialysis', 'Hemoglobin', 'Hemoglobin concentration result', 'Human', 'Individual', 'Information Sciences', 'Insulin', 'Iron', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Nephrology', 'Outcome', 'Patient Monitoring', 'Patients', 'Pharmaceutical Preparations', 'Physiological', 'Population', 'Process', 'Protocols documentation', 'Public Health Schools', 'Research', 'Research Personnel', 'Safety', 'Sampling', 'Savings', 'Techniques', 'Technology', 'Testing', 'Training', 'Training Programs', 'Translations', 'Universities', 'Veterans', 'Waran', 'Work', 'base', 'clinical practice', 'computer science', 'cost effectiveness', 'data management', 'experience', 'improved', 'insight', 'instructor', 'mathematical algorithm', 'novel', 'patient population', 'primary outcome', 'programs', 'recombinant human erythropoietin', 'research clinical testing', 'response', 'simulation', 'statistics', 'theories', 'tool']",NIDDK,UNIVERSITY OF LOUISVILLE,K25,2009,54000,0.01586836812124561
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,7622614,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'flexibility', 'foot', 'genome-wide', 'insight', 'meetings', 'member', 'novel', 'quality assurance', 'scale up', 'symposium', 'theories', 'tool', 'working group']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2009,1224323,0.0159003669394999
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,7577491,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Patients', 'Play', 'Population', 'Process', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'longitudinal analysis', 'particle', 'public health relevance', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2009,342223,-0.002842712170123793
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7914681,U54CA121852,"['Address', 'Algorithms', 'Area', 'Binding', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Databases', 'Development', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Genes', 'Genetic Engineering', 'Genomics', 'Internet', 'Investigation', 'Literature', 'Machine Learning', 'Maps', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Research Personnel', 'Resources', 'Signal Pathway', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'base', 'biomedical ontology', 'computer framework', 'data mining', 'design', 'genome-wide', 'graphical user interface', 'knowledge base', 'multidisciplinary', 'natural language', 'novel', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2009,116802,-0.0545935827789462
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7582301,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2009,2057843,-0.0016564585999463526
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,7652508,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Operative Surgical Procedures', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'intelligence genetics', 'novel', 'programs', 'resistant strain', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2009,363929,-0.012681918769059624
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.      CRITQUE 1:      The Bioconductor project began in 2001. In 2002 it was awarded a BISTI grant for three years 2003-2006). During this time the project has expanded and provided support for a world wide community of researchers. This is a proposal for continued development for Bioconductor, which is a set of statistical programs which are specifically tailored to the computatational biology community. Bioconductor is composed of over 130 R packages that have been contributed by a large number of developers. The software packages range from state of the art statistical methods which typically are used in microarray analysis, to annotation tools, to plotting functions, GUIs, to sequence alignment and data management packages. Contributions to and usage of Bioconductor is growing rapidly and the applicants are requesting support to continue its development as well as general logistical support for software distribution and quality assurance. The proposal includes a research component for Bioconductor which will involve the development of analysis techniques. This will include optimization of the R statistical analyses, statistical processing of Affymetrix data, analysis of SNP data, improved standards, data storage, retreivals from NCBI, sequence management, machine learning, web services and distributed computing.      SCIENTIFIC MERIT   The applicants address many issues that are crucial to the success of a large open source project with multiple contributors. Examples of training, scientific publication, documentation and resource development run throughout the proposal. Many tangible examples were given on the usage of the system by the scientific community.        EXPERIMENTAL DESIGN   This is a description of their management workflow for the project which does a good job of demonstrating the technical excellence brought to the project by this group. 1) Build annotation packages every three months, Integrate changes in annotation source data structure into annotation package building code. 2) Maintain project website, mailing lists, source control archive. Organize web resources for short course and conferences. 3) Improve existing software. 4) Sustain automated nightly builds. Work with developers whose packages fail to pass QA. 5) Resolve cross-platform issues. 6) Review new submissions. Answer questions on the mailing lists. 7) Use software engineering best practices. Develop unit testing strategies. Design appropriate classes and methods for new data types. Refactor existing code for better interoperability and extensibility. 8) Develop and organize training materials and documentation.      Extensive detail on testing, build procedures, interoperability, quality assurance and project management is given elsewhere in the document. They clearly have dealt with many issues necessary for a project of this size. They state that one of the biggest cost items is support of this package to run on multiple platforms. They point out that many contributors focus on a single platform, much of their work is track down cross-platform bugs. This is time well-spent, given the platforms used are in sync with the needs of the greater bioinformatics community.        ORIGINALITY   While a high degree of originality is not a particularly critical element of open source software development project, there are certainly areas in the proposal that are unique. Most importantly, it is safe to say that there is not another project which has this blend of statistical analysis systems specifically tailored to a important research bioinformatics area that can be deployed on a number of different computer environments.      INVESTIGATOR AND CO-INVESTIGATORS   Dr. Gentleman is the founder and leader of the Bioconductor project. Dr. Gentlemen was an Associate Professor in the Department of Biostatistics, Harvard School of Public Health and Department of Biostatistics and Computational Biology, Dana Farber Cancer Institute. In 2004 he became Program Head, Computational Biology, at the Fred Hutchinson Cancer Research Center in Seattle. He has on the order of ten publications relating to Bioconductor or related statistical analysis. He implemented the original versions of the R programming language jointly with another co-founder. He is PI or Investigator of a number of research grants, at least two are directly related to this work. He and other members of the proposal have taught a number of courses and given lectures on Bioconductor, the amount of these courses certainly indicate significant dedication to the project.  A review of the PI and Co-PI activities related to this project are shown on Table 3 on page 42 of the application. The roles and time allocations assigned to each participant appear to be reasonable.  Dr. Gentleman will serve as project leader and will manage the programmers, coordinating the project, and investigating new computational methods and approaches.  Dr. Vincent Carey, as co Principal Investigator has 20% time allocated for the project.  In 2005 he became Associate Professor of Medicine (Biostatistics). Carey is a senior member of the Bioconductor development core. He will improve interoperability to allow Bioconductor reuse of external modules in Java, Perl and other languages as well as strengthen interfaces between high throughput experimental workflows and machine learning tools, and ontology capture.  An administrative assistant will assist Dr. Carey with administrative requirements, including call coordination, manuscript preparation and distribution, scheduling and budget management.  Dr. Rafael Irizarry as co-PI will spend 30% effort on the project.  Dr. Irizarry has four years experience developing methods for microarray data analysis and in the Department of Biostatistics serving as faculty liaison to the Johns Hopkins Medical Institution's Microarray Core.  He will supervize all efforts to support preprocessing on all platforms and support for microarray related consortiums such as the ERCC, GEO, and ArrayExpress.      Programmers will be responsible for the project website, managing email lists, maintaining training materials, upgrading software, refactoring and other code enhancements, managing the svn archive, and Bioconductor releases. They will handle checking all submitted packages, developing unit tests, and simplifying downloads, nightly build procedures, cross-platform issues, data technologies as well as integrating resources found in other languages (e.g. large C libraries of routines for string handling, machine learning and so on). Programmers have familiarity with R packages and systems for database management and for parallel and distributed computing. They will be responsible for managing the annotation data including package building and liaising with organism specific and other data providers.      SIGNIFICANCE   Given the scope of the proposal, and the size of the Bioconductor project in general the request for the above resources is appropriate. There is an excellent mix of grounded project management along with development of newer state of the art techniques that will benifit many members of the bioinformatics community. There is a high probability that funding this project will help to maintain and advance this important community resource.      ENVIRONMENT   The computer infrastructure, and the local departments of the PI and Co-PIs, as well as the work with the larger scientific community are all excellent environments to support this project.      IN SUMMARY   This is a terrific resource.  It is a well managed large open source project with very well crafted QA testing, documentation and training.  Continuation of this is a three year project. Beyond that period, a statement of long term stated goals is needed. The PI should articulate the strategic goals, as well as their research motivation and translate that into an action plan. They should also use that context to describe how they would go about choosing packages that are put into the Bioconductor system; Table 3 only listed the names of the packages made by the applicants, it could have gone further to give the reader more information for choosing packages.  A simple example would have been if they stated in the document: ""Given our assessment of the microarray state of the art, we ultimately aim to overlay annotation data, ontological information, and other forms of meta data onto a statistical framework for expression data."" The resulting research plan would then justify a five year project, but it was not strong enough in this application.       It should be noted that many of the benificiaries to this system are not just users that download the system.  In many cases a centralized informatics service downloads their system and then performs analysis for other members of the campus or the wider www community. While that type of ""success measure"" is hard to assess, more effort in this area in subsequent proposals would be helpful.           n/a",Bioconductor: an open computing resource for genomics,7669241,P41HG004059,"['Address', 'Archives', 'Area', 'Arts', 'Award', 'Bioconductor', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Budgets', 'Building Codes', 'Code', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Database Management Systems', 'Dedications', 'Development', 'Discipline', 'Documentation', 'Educational process of instructing', 'Electronic Mail', 'Elements', 'Environment', 'Evolution', 'Experimental Designs', 'Faculty', 'Familiarity', 'FarGo', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Goals', 'Grant', 'Head', 'Human Genome', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Internet', 'Investigation', 'Java', 'Knowledge', 'Language', 'Libraries', 'Machine Learning', 'Mails', 'Manuscripts', 'Measures', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Microarray Analysis', 'Motivation', 'Names', 'Nature', 'Occupations', 'Ontology', 'Operative Surgical Procedures', 'Organism', 'Participant', 'Policies', 'Preparation', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Program Development', 'Programming Languages', 'Provider', 'Public Health Schools', 'Publications', 'Reader', 'Request for Proposals', 'Research', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Role', 'Running', 'Schedule', 'Scientist', 'Sequence Alignment', 'Services', 'Software Design', 'Software Engineering', 'Solutions', 'Source', 'Statistical Methods', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'cluster computing', 'computer infrastructure', 'computing resources', 'cost', 'cost effective', 'data management', 'data structure', 'design', 'experience', 'falls', 'improved', 'innovation', 'interoperability', 'lectures', 'meetings', 'member', 'model development', 'open source', 'originality', 'professor', 'programs', 'quality assurance', 'research study', 'software development', 'success', 'symposium', 'tool', 'tool development', 'web site', 'web-accessible']",NHGRI,FRED HUTCHINSON CANCER RESEARCH CENTER,P41,2009,829379,-0.00027839569859696475
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.      CRITQUE 1:      The Bioconductor project began in 2001. In 2002 it was awarded a BISTI grant for three years 2003-2006). During this time the project has expanded and provided support for a world wide community of researchers. This is a proposal for continued development for Bioconductor, which is a set of statistical programs which are specifically tailored to the computatational biology community. Bioconductor is composed of over 130 R packages that have been contributed by a large number of developers. The software packages range from state of the art statistical methods which typically are used in microarray analysis, to annotation tools, to plotting functions, GUIs, to sequence alignment and data management packages. Contributions to and usage of Bioconductor is growing rapidly and the applicants are requesting support to continue its development as well as general logistical support for software distribution and quality assurance. The proposal includes a research component for Bioconductor which will involve the development of analysis techniques. This will include optimization of the R statistical analyses, statistical processing of Affymetrix data, analysis of SNP data, improved standards, data storage, retreivals from NCBI, sequence management, machine learning, web services and distributed computing.      SCIENTIFIC MERIT   The applicants address many issues that are crucial to the success of a large open source project with multiple contributors. Examples of training, scientific publication, documentation and resource development run throughout the proposal. Many tangible examples were given on the usage of the system by the scientific community.        EXPERIMENTAL DESIGN   This is a description of their management workflow for the project which does a good job of demonstrating the technical excellence brought to the project by this group. 1) Build annotation packages every three months, Integrate changes in annotation source data structure into annotation package building code. 2) Maintain project website, mailing lists, source control archive. Organize web resources for short course and conferences. 3) Improve existing software. 4) Sustain automated nightly builds. Work with developers whose packages fail to pass QA. 5) Resolve cross-platform issues. 6) Review new submissions. Answer questions on the mailing lists. 7) Use software engineering best practices. Develop unit testing strategies. Design appropriate classes and methods for new data types. Refactor existing code for better interoperability and extensibility. 8) Develop and organize training materials and documentation.      Extensive detail on testing, build procedures, interoperability, quality assurance and project management is given elsewhere in the document. They clearly have dealt with many issues necessary for a project of this size. They state that one of the biggest cost items is support of this package to run on multiple platforms. They point out that many contributors focus on a single platform, much of their work is track down cross-platform bugs. This is time well-spent, given the platforms used are in sync with the needs of the greater bioinformatics community.        ORIGINALITY   While a high degree of originality is not a particularly critical element of open source software development project, there are certainly areas in the proposal that are unique. Most importantly, it is safe to say that there is not another project which has this blend of statistical analysis systems specifically tailored to a important research bioinformatics area that can be deployed on a number of different computer environments.      INVESTIGATOR AND CO-INVESTIGATORS   Dr. Gentleman is the founder and leader of the Bioconductor project. Dr. Gentlemen was an Associate Professor in the Department of Biostatistics, Harvard School of Public Health and Department of Biostatistics and Computational Biology, Dana Farber Cancer Institute. In 2004 he became Program Head, Computational Biology, at the Fred Hutchinson Cancer Research Center in Seattle. He has on the order of ten publications relating to Bioconductor or related statistical analysis. He implemented the original versions of the R programming language jointly with another co-founder. He is PI or Investigator of a number of research grants, at least two are directly related to this work. He and other members of the proposal have taught a number of courses and given lectures on Bioconductor, the amount of these courses certainly indicate significant dedication to the project.  A review of the PI and Co-PI activities related to this project are shown on Table 3 on page 42 of the application. The roles and time allocations assigned to each participant appear to be reasonable.  Dr. Gentleman will serve as project leader and will manage the programmers, coordinating the project, and investigating new computational methods and approaches.  Dr. Vincent Carey, as co Principal Investigator has 20% time allocated for the project.  In 2005 he became Associate Professor of Medicine (Biostatistics). Carey is a senior member of the Bioconductor development core. He will improve interoperability to allow Bioconductor reuse of external modules in Java, Perl and other languages as well as strengthen interfaces between high throughput experimental workflows and machine learning tools, and ontology capture.  An administrative assistant will assist Dr. Carey with administrative requirements, including call coordination, manuscript preparation and distribution, scheduling and budget management.  Dr. Rafael Irizarry as co-PI will spend 30% effort on the project.  Dr. Irizarry has four years experience developing methods for microarray data analysis and in the Department of Biostatistics serving as faculty liaison to the Johns Hopkins Medical Institution's Microarray Core.  He will supervize all efforts to support preprocessing on all platforms and support for microarray related consortiums such as the ERCC, GEO, and ArrayExpress.      Programmers will be responsible for the project website, managing email lists, maintaining training materials, upgrading software, refactoring and other code enhancements, managing the svn archive, and Bioconductor releases. They will handle checking all submitted packages, developing unit tests, and simplifying downloads, nightly build procedures, cross-platform issues, data technologies as well as integrating resources found in other languages (e.g. large C libraries of routines for string handling, machine learning and so on). Programmers have familiarity with R packages and systems for database management and for parallel and distributed computing. They will be responsible for managing the annotation data including package building and liaising with organism specific and other data providers.      SIGNIFICANCE   Given the scope of the proposal, and the size of the Bioconductor project in general the request for the above resources is appropriate. There is an excellent mix of grounded project management along with development of newer state of the art techniques that will benifit many members of the bioinformatics community. There is a high probability that funding this project will help to maintain and advance this important community resource.      ENVIRONMENT   The computer infrastructure, and the local departments of the PI and Co-PIs, as well as the work with the larger scientific community are all excellent environments to support this project.      IN SUMMARY   This is a terrific resource.  It is a well managed large open source project with very well crafted QA testing, documentation and training.  Continuation of this is a three year project. Beyond that period, a statement of long term stated goals is needed. The PI should articulate the strategic goals, as well as their research motivation and translate that into an action plan. They should also use that context to describe how they would go about choosing packages that are put into the Bioconductor system; Table 3 only listed the names of the packages made by the applicants, it could have gone further to give the reader more information for choosing packages.  A simple example would have been if they stated in the document: ""Given our assessment of the microarray state of the art, we ultimately aim to overlay annotation data, ontological information, and other forms of meta data onto a statistical framework for expression data."" The resulting research plan would then justify a five year project, but it was not strong enough in this application.       It should be noted that many of the benificiaries to this system are not just users that download the system.  In many cases a centralized informatics service downloads their system and then performs analysis for other members of the campus or the wider www community. While that type of ""success measure"" is hard to assess, more effort in this area in subsequent proposals would be helpful.           n/a",Bioconductor: an open computing resource for genomics,7921192,P41HG004059,"['Address', 'Archives', 'Area', 'Arts', 'Award', 'Bioconductor', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Budgets', 'Building Codes', 'Code', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Database Management Systems', 'Dedications', 'Development', 'Discipline', 'Documentation', 'Educational process of instructing', 'Electronic Mail', 'Elements', 'Environment', 'Evolution', 'Experimental Designs', 'Faculty', 'Familiarity', 'FarGo', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Goals', 'Grant', 'Head', 'Human Genome', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Internet', 'Investigation', 'Java', 'Knowledge', 'Language', 'Libraries', 'Machine Learning', 'Mails', 'Manuscripts', 'Measures', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Microarray Analysis', 'Motivation', 'Names', 'Nature', 'Occupations', 'Ontology', 'Operative Surgical Procedures', 'Organism', 'Participant', 'Policies', 'Preparation', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Program Development', 'Programming Languages', 'Provider', 'Public Health Schools', 'Publications', 'Reader', 'Request for Proposals', 'Research', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Role', 'Running', 'Schedule', 'Scientist', 'Sequence Alignment', 'Services', 'Software Design', 'Software Engineering', 'Solutions', 'Source', 'Statistical Methods', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'cluster computing', 'computer infrastructure', 'computing resources', 'cost', 'cost effective', 'data management', 'data structure', 'design', 'experience', 'falls', 'improved', 'innovation', 'interoperability', 'lectures', 'meetings', 'member', 'model development', 'open source', 'originality', 'professor', 'programs', 'quality assurance', 'research study', 'software development', 'success', 'symposium', 'tool', 'tool development', 'web site', 'web-accessible']",NHGRI,FRED HUTCHINSON CANCER RESEARCH CENTER,P41,2009,250001,-0.00027839569859696475
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7663288,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Computer Systems Development', 'Computer software', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Source', 'Structure', 'System', 'Systems Integration', 'Technology', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'meetings', 'models and simulation', 'open source', 'outreach', 'protein complex', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2009,437938,-0.01902794185524723
"Optimal Micro-Data Switching: An Enhanced Framework and Decision Tool for Confid    DESCRIPTION (provided by applicant): The objective of this project is the development of an innovative technique to avoid disclosure of confidential data in public use tabular data. Our proposed technique, called Optimal Data Switching (OS), overcomes the limitations and disadvantages found in currently deployed disclosure limitation methods. Statistical databases for public use pose a critical problem of identifying how to make the data available for analysis without disclosing information that would infringe on privacy, violate confidentiality, or endanger national security. Organizations in both the public and private sectors have a major stake in this confidentiality protection problem, given the fact that access to data is essential for advancing research and formulating policy. Yet, the possibility of extracting certain sensitive elements of information from the data can jeopardize the welfare of these organizations and potentially, in some instances, the welfare of the society in which they operate. The challenge is, therefore, to represent the data in a form that permits accurate analysis for supporting research, decision-making and policy initiatives, while preventing an unscrupulous or ill-intentioned party from exploiting the data for harmful consequences. Our goal is to build on the latest advances in optimization, to which the OptTek Systems, Inc. (OptTek) research team has made pioneering contributions, to provide a framework based on optimal data switching, enabling the Centers for Disease Control and Prevention (CDC) and other organizations to effectively meet the challenge of confidentiality protection. The framework we propose is structured to be easy to use in a wide array of application settings and diverse user environments, from client-server to web-based, regardless of whether the micro-data is continuous, ordinal, binary, or any combination of these types. The successful development of such a framework, and the computer-based method for implementing it, is badly needed and will be of value to many types of organizations, not only in the public sector but also in the private sector, for whom the incentive to publish data is both economic as well as scientific. Examples in the public sector are evident, where organizations like CDC and the U.S. Census Bureau exist for the purpose of collecting, analyzing and publishing data for analysis by other parties. Numerous examples are also encountered in the private sector, notably in banking and financial services, healthcare (including drug companies and medical research institutions), market research, oil exploration, computational biology, renewable and sustainable energy, retail sales, product development, and a wide variety of other areas. PUBLIC HEALTH RELEVANCE: In the process of accumulating and disseminating public health data for reporting purposes, various uses, and statistical analysis, we must guarantee that individual records describing each person or establishment are protected. Organizations in both the public and private sectors have a major stake in this confidentiality protection problem, given the fact that access to data is essential for advancing research and formulating policy. This project proposes the development of a robust methodology and practical framework to deliver an efficient and effective tool to protect the confidentiality in published tabular data.                      n/a",Optimal Micro-Data Switching: An Enhanced Framework and Decision Tool for Confid,7790821,R43MH086138,"['Accounting', 'American', 'Area', 'Cells', 'Censuses', 'Centers for Disease Control and Prevention (U.S.)', 'Client', 'Computational Biology', 'Confidentiality', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Disadvantaged', 'Disclosure', 'Economics', 'Elements', 'Ensure', 'Environment', 'Goals', 'Health Personnel', 'Healthcare', 'Incentives', 'Individual', 'Inferior', 'Institution', 'Machine Learning', 'Market Research', 'Medical Research', 'Methodology', 'Methods', 'National Security', 'Oils', 'Online Systems', 'Persons', 'Pharmaceutical Preparations', 'Policies', 'Policy Making', 'Privacy', 'Private Sector', 'Problem Solving', 'Process', 'Property', 'Provider', 'Public Health', 'Public Sector', 'Publishing', 'Records', 'Research', 'Research Methodology', 'Research Support', 'Respondent', 'Sales', 'Services', 'Social Welfare', 'Societies', 'Solutions', 'Structure', 'System', 'Techniques', 'Time', 'United States National Institutes of Health', 'base', 'computer framework', 'data mining', 'flexibility', 'innovation', 'interest', 'meetings', 'prevent', 'product development', 'public health relevance', 'tool']",NIMH,"OPTTEK SYSTEMS, INC.",R43,2009,4047,0.003010230559371265
"Integration and Visualization of Diverse Biological Data DESCRIPTION (provided by applicant): Currently a gap exists between the explosion of high-throughput data generation in molecular biology and the relatively slower growth of reliable functional information extracted from the data. This gap is largely due to the lack of specificity necessary for accurate gene function prediction in the currently available large-scale experimental technologies for rapid protein function assessment. Bioinformatics methods that integrate diverse data sources in their analysis achieve higher accuracy and thus alleviate this lack of specificity, but there's a paucity of generalizable, efficient, and accurate methods for data integration. In addition, no efficient methods exist to effectively display diverse genomic data, even though visualization has been very valuable for analysis of data from large scale technologies such as gene expression microarrays. The long-term goal of this proposal is to develop an accurate and generalizable bioinformatics framework for integrated analysis and visualization of heterogeneous biological data.      We propose to address the data integration problem with a Bayesian network approach and effective visualization methods. We have shown the efficacy of this method in a proof-of-principle system that increased the accuracy of gene function prediction for Saccharomyces cerevisiae compared to individual data sources. Building on our previous work, we present a two-part plan to improve and expand our system and to develop novel visualization methods for genomic data based on the scalable display technology. First, we will investigate the computational and theoretical issues behind accurate integration, analysis and effective visualization of heterogeneous high-throughput data. Then, leveraging our existing system and algorithmic improvements developed in the first part of the project, we will design and implement a full-scale data integration and function prediction system for Saccharomyces cerevisiae that will be incorporated with the Saccharomyces Genome Database (SGD), a model organism database for yeast.      The proposed system would provide highly accurate automatic function prediction that can accelerate genomic functional annotation through targeted experimental testing. Furthermore, our system will perform general integration and will offer researchers a unified view of the diverse high-throughput data through effective integration and visualization tools, thereby facilitating hypothesis generation and data analysis. Our scalable visualization methods will enable teams of researchers to examine biological data interactively and thus support the highly collaborative nature of genomic research. In addition to contributing to S. cerevisiae genomics, the technology for efficient and accurate heterogeneous data integration and visualization developed as a result of this proposal will form a basis for systems that address the same set of issues for other organisms, including the human. n/a",Integration and Visualization of Diverse Biological Data,7595813,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Collaborations', 'Communities', 'Computer software', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Effectiveness', 'Evaluation', 'Expert Systems', 'Explosion', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grouping', 'Growth', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Institutes', 'Investigation', 'Knock-out', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Machine Learning', 'Magic', 'Methods', 'Molecular Biology', 'Monitor', 'Nature', 'Online Systems', 'Organism', 'Phenotype', 'Probability', 'Process', 'Protein-Protein Interaction Map', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Scientist', 'Side', 'Source', 'Specificity', 'Staining method', 'Stains', 'Structure', 'System', 'Systems Biology', 'Technology', 'Test Result', 'Testing', 'Two-Hybrid System Techniques', 'Universities', 'Visualization software', 'Work', 'Yeasts', 'base', 'biological systems', 'comparative', 'computer based statistical methods', 'data integration', 'design', 'flexibility', 'functional genomics', 'gene function', 'genome database', 'high throughput analysis', 'improved', 'model organisms databases', 'novel', 'parallel computing', 'programs', 'protein function', 'prototype', 'research study', 'software development', 'tandem mass spectrometry', 'tool', 'ultra high resolution', 'web interface', 'web site']",NIGMS,PRINCETON UNIVERSITY,R01,2009,243004,-0.012639332862314704
"Informatics Core for the Collaborative Initiative on Fetal Alcohol Spectrum disor    DESCRIPTION (provided by applicant): The Informatics Core is part of the Consortium for the ""Collaborative Initiative on Fetal Alcohol Spectrum Disorders"" (CIFASD). The theme of this collaborative initiative is a cross-cultural assessment of ""fetal alcohol spectrum disorder"" (FASD). The CIFASD will coordinate basic, behavioral, and clinical investigators in a multidisciplinary research project to better inform approaches aimed at developing effective intervention and treatment approaches for FASD. It will involve the input and contributions from basic researchers, behavioral scientists, and clinical investigators with the willingness to utilize novel and cutting-edge techniques so as not to simply replicate previous or ongoing work, but rather to try and move it forward in a rigorous fashion. The Informatics Core will develop and maintain the CIFASD Data Repository, which will be used to collect, maintain and distribute data generated by the various participants in the consortium. The Informatics Core will be responsible for working with the other consortium participants to define a Data Dictionary to be used in standardizing data collection, enabling the transfer of data to and from the CIFASD Data Repository, consulting on how to establish local data management systems, providing both software tools and consulting to consortium participants, and producing status reports about the progress of the various projects within the consortium. The Informatics Core draws on a wealth of resources, experience, and expertise at Indiana University in information technology infrastructure and data management, The CIFASD Data Repository will be developed on Indiana University's state-of-the-art central supercomputing facilities, taking advantage of Indiana University's strong commitment to institutional computational resources. Resources that will be used to implement the CIFASD Data Repository include multiple supercomputers, an array of readily available database and statistical software, and a high- speed, secure, robust data archiving system capable of storing duplicate copies in multiple physical locations separated by more than fifty miles. The Informatics Core will use these extraordinary computational resources to provide a single, highly secure location for consortium participants to obtain the cross-cultural data that will enable the CIFASD to meet its goals of developing novel techniques for intervention and treatment of FASD.           n/a",Informatics Core for the Collaborative Initiative on Fetal Alcohol Spectrum disor,7668731,U24AA014818,"['Address', 'Adolescent', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Archives', 'Arts', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cells', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Collaborations', 'Computer Systems', 'Computer software', 'Consult', 'Data', 'Data Analyses', 'Data Collection', 'Data Storage and Retrieval', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Dictionary', 'Dietary Intervention', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early treatment', 'Elements', 'Emotional', 'Ethanol', 'Ethnic group', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Indiana', 'Individual', 'Infant', 'Informal Social Control', 'Informatics', 'Information Technology', 'Interdisciplinary Study', 'Internet', 'Intervention', 'Knowledge', 'Label', 'Language', 'Language Development', 'Life', 'Location', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Mission', 'Modeling', 'Moscow', 'Mothers', 'Mus', 'Names', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'New Mexico', 'Outcome', 'Participant', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Rattus', 'Recording of previous events', 'Reporting', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Schools', 'Scientist', 'Secure', 'Sensitivity and Specificity', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Software Tools', 'Specificity', 'Speed', 'Structure', 'Sum', 'Supercomputing', 'Supplementation', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Three-Dimensional Image', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Universities', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'brain behavior', 'brain morphology', 'cognitive control', 'computing resources', 'critical period', 'data exchange', 'data integration', 'data management', 'data sharing', 'distributed data', 'drinking', 'effective intervention', 'experience', 'fetal', 'flexibility', 'follow-up', 'imaging modality', 'improved', 'in utero', 'infancy', 'literacy', 'meetings', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'offspring', 'prenatal', 'prospective', 'quality assurance', 'reconstruction', 'repository', 'social', 'supercomputer', 'three dimensional structure', 'willingness']",NIAAA,INDIANA UNIVERSITY BLOOMINGTON,U24,2009,185188,-0.031595395854301905
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7676864,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2009,3464579,-0.0545935827789462
"Novel TIRF microscopy analyzing trafficking & signaling at the cell cortex In 3-month paid research experiences, over two summers, 4  talented undergraduate engineering and computer science students will be recruited to contribute in a substantial way to the progress of sub-aims of my parent New Innovator (DP2) Award;  the DP2's main specific aims are to develop novel microscopes (Aim 1) and analytical tools (Aim 2) to study membrane trafficking at the cell cortex (Aim 3).  Specifically, students will work on one of two projects: i)  Design and construct and improve electronic circuits to control the galvometric XY mirror on our multi-angle FRAP/TIRFM (Aim 1B) and/or new auto-sensing calibration devices (Aim 2) or ii) Develop models or software to visualize and track vesicles in 3D by multi-angle TIRFM (Aim 2 ). Their advances will directly benefits goals of the DP2 and the new electronics and software's performance will be benchmarked and iteratively improved. Training and oversight will come from the PI and the DP2-supported senior scientist, Dr. Polejaev.  Students will benefit from the infrastructure of the Yale 'CINEMA' lab imaging center, which is under the PI's directorship.         Two outstanding US engineering students have already been identified, Noah Pestana and Isaac Anderson, both of whom have expressed a high interest in participating this summer on projects (i) and (ii), respectively. In the second summer, a particular emphasis will be made to recruit minority undergraduate students through the Yale 'STARS' program for minorities.   All proposed activity are within the scope of the parent DP2 and capitalizes on early successes and will accelerate the tempo of two of the approved specific aims. Consistent with the recovery act's goal, this funding will provide full-time summer employment for 4 undergraduate students and accelerate scientific achievement of the parent DP2 award.  n/a",Novel TIRF microscopy analyzing trafficking & signaling at the cell cortex,7892704,DP2OD002980,"['1-Phosphatidylinositol 3-Kinase', 'Abbreviations', 'Accounting', 'Acoustics', 'Address', 'Adipocytes', 'Affect', 'Algorithms', 'Area', 'Arts', 'Attenuated', 'Automobile Driving', 'Award', 'Back', 'Binding', 'Biochemical', 'Biochemistry', 'Biological', 'Biology', 'Boxing', 'Buffers', 'Caliber', 'Calibration', 'Cell Line', 'Cell membrane', 'Cell surface', 'Cells', 'Cellular biology', 'Clathrin', 'Cluster Analysis', 'Collaborations', 'Collection', 'Collimator', 'Color', 'Coma', 'Communities', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computers', 'Conflict (Psychology)', 'Confocal Microscopy', 'Coupled', 'Coupling', 'Cues', 'Cytoskeleton', 'Data', 'Data Set', 'Defect', 'Development', 'Diabetes Mellitus', 'Diffusion', 'Dimensions', 'Dimerization', 'Disadvantaged', 'Discipline', 'Docking', 'Down-Regulation', 'Drops', 'Dyes', 'Employee Strikes', 'Endocytosis', 'Engineering', 'Ensure', 'Environment', 'Event', 'Exocytosis', 'Eye', 'Face', 'Feedback', 'Fiber', 'Figs - dietary', 'Flare', 'Fluorescein-5-isothiocyanate', 'Fluorescence', 'Fluorescence Microscopy', 'Fluorescence Recovery After Photobleaching', 'Fluorescent Dyes', 'Functional disorder', 'Funding', 'Genetic Screening', 'Germany', 'Glass', 'Glucose Transporter', 'Glycerol', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Insulin', 'Interdisciplinary Study', 'Investments', 'Joints', 'Kinetics', 'Knowledge', 'Label', 'Laboratories', 'Lasers', 'Learning', 'Legal patent', 'Length', 'Life', 'Light', 'Lighting', 'Link', 'Lipids', 'Location', 'Macromolecular Complexes', 'Malignant Neoplasms', 'Maps', 'Masks', 'Measures', 'Mediating', 'Membrane', 'Membrane Microdomains', 'Membrane Protein Traffic', 'Methodology', 'Methods', 'Microscope', 'Microscopy', 'Microtubules', 'Modeling', 'Molecular', 'Monitor', 'Morphologic artifacts', 'Motivation', 'Motor', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Optics', 'Organelles', 'PTEN gene', 'Paper', 'Parasites', 'Pathway interactions', 'Penetration', 'Performance', 'Phosphatidylinositols', 'Phosphotransferases', 'Photobleaching', 'Physiologic pulse', 'Planet Mars', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Private Sector', 'Probability', 'Process', 'Proteins', 'Publications', 'Pupil', 'Quantum Dots', 'RNA Interference', 'Radial', 'Randomized', 'Reagent', 'Recruitment Activity', 'Refractive Indices', 'Regulation', 'Relative (related person)', 'Reporter', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seminal', 'Series', 'Side', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Simulate', 'Site', 'Small Interfering RNA', 'Solid', 'Solutions', 'Sorting - Cell Movement', 'Source', 'Spain', 'Spatial Distribution', 'Specific qualifier value', 'Specimen', 'Speed', 'Spottings', 'Structure', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Thick', 'Time', 'Total Internal Reflection Fluorescent', 'Touch sensation', 'Training', 'Transfection', 'Tubulin', 'Vesicle', 'Visual', 'Wolves', 'Work', 'analytical method', 'basal insulin', 'base', 'blood glucose regulation', 'cell cortex', 'cell motility', 'cell type', 'cellular imaging', 'density', 'design', 'extracellular', 'flexibility', 'flotillin', 'fluorescence imaging', 'fluorescence microscope', 'fluorophore', 'handbook', 'holistic approach', 'image processing', 'improved', 'innovation', 'insight', 'instrument', 'instrumentation', 'insulin signaling', 'interest', 'lens', 'medical schools', 'meetings', 'micromanipulator', 'migration', 'millisecond', 'nanometer', 'novel', 'object shape', 'photoactivation', 'prototype', 'receptor', 'research study', 'response', 'scaffold', 'simulation', 'single molecule', 'success', 'tool', 'trafficking', 'trans-Golgi Network', 'trend', 'user-friendly', 'virtual']",OD,YALE UNIVERSITY,DP2,2009,50463,0.011083419762410401
"Intelligent Control Approach to Anemia Management    DESCRIPTION (provided by applicant):   Management of anemia due to end-stage renal disease is a multifactorial decision process involving administration of recombinant human erythropoietin (rHuEPO) and iron, as well as assessment of other factors influencing the progress of the disease. This application aims at improving the cost-effectiveness of this process through the use of state-of-the-art numerical tools from control engineering and machine learning. The specific aims are the collection of anemia management data and development of new guidelines for period of measuring hemoglobin levels if necessary, development of individualized, computer-assisted approach to rHuEPO dosing based on modern control engineering and machine learning approach, evaluation of the developed tools through numeric simulation and assessment of the potential improvements in therapy and projected savings in rHuEPO utilization. The final aim is to provide a physical implementation and to perform a clinical evaluation of the developed methodology. The applicant, Dr. Adam E. Gaweda, is an Instructor of Medicine in the Department of Medicine, Division of Nephrology at the University of Louisville. His original training is in the field of electrical engineering (M.Eng.) and computer science (Ph.D.). The applicant plans to develop as an independent and well established researcher in the field of biomedical engineering with focus on translation of state-of-the-art technology to heath care. To achieve this goal the applicant will enroll into the Clinical Research, Epidemiology and Statistics Training (CREST) Program at the University of Louisville, School of Public Health and Information Sciences       n/a",Intelligent Control Approach to Anemia Management,7364629,K25DK072085,"['Adverse event', 'Algorithms', 'Anemia', 'Anti-Arrhythmia Agents', 'Artificial Intelligence', 'Arts', 'Biological Models', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Collection', 'Complex', 'Computer Assisted', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Controlled Clinical Trials', 'Data', 'Decision Support Systems', 'Development', 'Dialysis procedure', 'Disease', 'Doctor of Philosophy', 'Dose', 'Drug Prescriptions', 'Effectiveness', 'Electrical Engineering', 'End stage renal failure', 'Engineering', 'Enrollment', 'Epidemiology', 'Erythropoietin', 'Evaluation', 'Feedback', 'Frequencies', 'Funding', 'Goals', 'Guidelines', 'Hemodialysis', 'Hemoglobin', 'Hemoglobin concentration result', 'Human', 'Individual', 'Information Sciences', 'Insulin', 'Iron', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Nephrology', 'Outcome', 'Patient Monitoring', 'Patients', 'Pharmaceutical Preparations', 'Physical Dialysis', 'Physiological', 'Population', 'Process', 'Protocols documentation', 'Public Health Schools', 'Range', 'Research', 'Research Personnel', 'Safety', 'Sampling', 'Savings', 'Standards of Weights and Measures', 'Techniques', 'Technology', 'Testing', 'Training', 'Training Programs', 'Translations', 'Universities', 'Veterans', 'Waran', 'Work', 'base', 'computer science', 'cost effectiveness', 'data management', 'desire', 'experience', 'improved', 'insight', 'instructor', 'mathematical algorithm', 'novel', 'prescription document', 'prescription procedure', 'programs', 'recombinant human erythropoietin', 'research clinical testing', 'response', 'simulation', 'statistics', 'theories', 'tool']",NIDDK,UNIVERSITY OF LOUISVILLE,K25,2008,134890,0.01586836812124561
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,7433144,R44GM083965,"['Adoption', 'Algorithms', 'Architecture', 'Arts', 'Biological Sciences', 'Biomedical Research', 'Cations', 'Class', 'Classification', 'Communication', 'Communities', 'Companions', 'Complex', 'Computer software', 'Computers', 'Consult', 'Data', 'Data Set', 'Databases', 'Detection', 'Diagnosis', 'Disease', 'Effectiveness', 'Emerging Technologies', 'Ensure', 'Fostering', 'Foundations', 'Future', 'Generations', 'Goals', 'Graph', 'Grouping', 'Imagery', 'Knowledge', 'Language', 'Learning', 'Libraries', 'Machine Learning', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Numbers', 'Performance', 'Personal Satisfaction', 'Phase', 'Prevention', 'Problem Solving', 'Program Development', 'Public Health', 'Randomized', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Running', 'Scheme', 'Simulate', 'Software Design', 'Software Tools', 'Speed', 'Structure', 'Techniques', 'Technology', 'Testing', 'Today', 'Training', 'Voting', 'Work', 'base', 'computerized tools', 'data mining', 'design', 'forest', 'improved', 'innovation', 'next generation', 'parallel computing', 'programs', 'prototype', 'research and development', 'response', 'software development', 'sound', 'statistics', 'theories', 'tool']",NIGMS,INSIGHTFUL CORPORATION,R44,2008,25548,0.005901800275242617
"EDAC: ENCODE Data Analysis Center    DESCRIPTION (provided by applicant):   The ENCODE Data Analysis Center (EDAC) proposal aims to provide a flexible analysis resource for the ENCODE project. The ENCODE project is a large multi center project which aims to define all the functional elements in the human genome. This will be achieved using many different experimental techniques coupled with numerous computational techniques. A critical part in delivering this set of functional elements is the integration of data from multiple sources. The ED AC proposal aims to provide this integration. As proscribed by the RFA for this proposal, the precise prioritization for the EDAC's work will be set by an external group, the Analysis Working Group (AWG). Based on previous experience, these analysis methods will require a variety of techniques. We expect to have to apply sophisticated statistical models to the integration of the data, in particular mitigating the problems of the extensive heterogeneity and correlation of variables on the human genome. We have statistical experts who can use the large size of the human genome, coupled with a limited number of sensible assumptions to produce statistical techniques which are robust to this considerable heterogeneity. We also expect to apply machine learning techniques to build integration methods combining datasets. These included Bayesian based inference methods and the robust computer science technique of Support Vector Machines. Each of these methods have performed well in the ENCODE pilot project and we expect them to be even more useful in the full ENCODE project. We will also provide quality assurance and summary metrics of genome-wide multiple alignments. This area has a number of complex statistical, algorithmic and engineering issues, which we will solve using state of the art techniques. Overall we aim to provide deep integration of the ENCODE data, under the direction of the AWG and in tight collaboration with the other members of the ENCODE consortium.           n/a",EDAC: ENCODE Data Analysis Center,7499147,U01HG004695,"['Address', 'Algorithms', 'Area', 'Arts', 'Be++ element', 'Behavior', 'Beryllium', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Collaborations', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Depth', 'Development', 'Educational workshop', 'Engineering', 'Equipment and supply inventories', 'Freezing', 'Gene Expression Regulation', 'Genome', 'Genomics', 'Goals', 'Heterogeneity', 'Human Genome', 'Indium', 'Link', 'Machine Learning', 'Manuscripts', 'Maps', 'Methods', 'Metric', 'Nature', 'Numbers', 'Phase', 'Pilot Projects', 'Publications', 'Records', 'Reporting', 'Research Personnel', 'Resources', 'Scientist', 'Source', 'Statistical Models', 'Structure', 'Techniques', 'Telephone', 'Transcript', 'Vertebral column', 'Work', 'base', 'computer science', 'data integration', 'experience', 'experimental analysis', 'foot', 'insight', 'member', 'novel', 'quality assurance', 'scale up', 'size', 'symposium', 'theories', 'tool']",NHGRI,EUROPEAN MOLECULAR BIOLOGY LABORATORY,U01,2008,1200000,0.0159003669394999
"The Statistical and Computational Analysis of Flow Cytometry Data    DESCRIPTION (provided by applicant):  Flow cytometry is a data-rich technology that plays a critical role in basic research and clinical therapy for a variety of human diseases. Recent technological developments have greatly increased the areas of application and data throughput, and corresponding innovative analysis methods are needed. In order to be able to take advantage of these new capabilities researchers need access to high quality analysis tools that will help to identify subpopulations of cells with particular characteristics. The methods we are proposing include advanced methods for machine learning and visualization. We will apply our methods to a number of different scenarios such as the analysis of longitudinal data, and the analysis of data arising from clinical studies. PUBLIC HEALTH RELEVANCE: The aims of this project are to provide statistical and computational methods for the analysis of flow cytometry data. The impact of these tools will be to provide better, more reliable, tools for the analysis of flow cytometry data. The domain of application spans all diseases, but current applications are focused on HIV disease and cancer.          n/a",The Statistical and Computational Analysis of Flow Cytometry Data,7431959,R01EB008400,"['AIDS/HIV problem', 'Address', 'Antibodies', 'Antigens', 'Area', 'Basic Science', 'Biological', 'Cancer Vaccines', 'Cations', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Computer Analysis', 'Computer software', 'Computing Methodologies', 'Condition', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Development', 'Disease', 'Ensure', 'Event', 'Flow Cytometry', 'Future', 'Genomics', 'HIV', 'Hypersensitivity', 'Imagery', 'Immune response', 'Immunity', 'Intervention', 'Lasers', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical', 'Methods', 'Names', 'Noise', 'Numbers', 'Patients', 'Play', 'Population', 'Process', 'Public Health', 'Rate', 'Reagent', 'Research Infrastructure', 'Research Personnel', 'Role', 'Rosa', 'Sampling', 'Shapes', 'Software Tools', 'Staining method', 'Stains', 'Statistical Methods', 'Surface', 'Technology', 'Transplantation', 'Vaccine Research', 'Variant', 'Work', 'graft vs host disease', 'human disease', 'immune function', 'innovation', 'instrument', 'instrumentation', 'leukemia/lymphoma', 'particle', 'size', 'sound', 'tool']",NIBIB,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2008,376423,-0.002842712170123793
"Nation Center: Multi-Scale Study- Cellular Networks(RMI) A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genomewide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 1 investigators to combine molecular interaction clues from Core 2 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions. n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7674889,U54CA121852,"['Address', 'Algorithms', 'Area', 'Automobile Driving', 'Binding', 'Bioinformatics', 'Biological', 'Biological Process', 'Biomedical Research', 'Cell Adhesion', 'Cell physiology', 'Cells', 'Communities', 'Complex', 'Computational Science', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'DNA-Protein Interaction', 'Databases', 'Development', 'Dissection', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Genes', 'Genetic Engineering', 'Genomics', 'Individual', 'Internet', 'Investigation', 'Knowledge', 'Language', 'Literature', 'Machine Learning', 'Maps', 'Medical', 'Methodology', 'Molecular', 'Molecular Analysis', 'Ontology', 'Organism', 'Physics', 'Process', 'Published Comment', 'Range', 'Regulation', 'Research', 'Research Personnel', 'Resources', 'Science', 'Signal Pathway', 'Skeleton', 'Source', 'Structure', 'Techniques', 'Testing', 'Tissues', 'Training', 'Transcriptional Activation', 'Work', 'base', 'computer framework', 'data mining', 'design', 'graphical user interface', 'improved', 'innovation', 'knowledge base', 'multidisciplinary', 'novel', 'response', 'software systems', 'structural biology', 'tool', 'usability']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2008,113826,-0.05483851868158673
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7367958,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'Work', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2008,2037396,-0.0016564585999463526
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,7495734,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease Resistance', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Numbers', 'Operative Surgical Procedures', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Range', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'novel', 'programs', 'size', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA-IRVINE,R01,2008,353327,-0.012681918769059624
"Neuroimaging Neuroinformatics Training Program    DESCRIPTION (provided by applicant): This proposal is in response to PAR-03-034 ""Neuroinformatics Institutional Mentored Research Scientist Development Award (K12)."" The overarching goal of this application is to provide an excellent postdoctoral training program in neuroimaging neuroinformatics that capitalizes on the many strengths of the existing neuroscientists, informatics and imaging resources that our combined resources represent. Our proposed Neuroimaging Neuroinformatics Training Program (NNTP) is based upon a number of important strategic alliances. The first cornerstone of this effort is the existing HBP grants held by Dr. Anders Dale (R01 NS39581: Cortical-Surface-Based Brain Imaging) and Dr. David Kennedy (R01 NS34189: Anatomic Morphologic Analysis of MR Brain Images). These efforts span a wealth of technological developments, research and clinical application areas in the rapidly developing area of quantitative morphometric image analysis. A second and vital cornerstone is our association with the Harvard-MIT Division of Health Sciences and Technology (HST) Biomedical Informatics Program. This existing pre- and post-graduate academic program, within a world class biomedical engineering department, is an ideal setting for the development of a coordinated training effort in Neuroinformatics. The established track record in training skilled scientists in areas of informatics will prove invaluable in this new initiative. The third cornerstone is the combined clinical research opportunities afforded by the Harvard-wide biomedical imaging resources. These include the MGH/MIT/HST Athinoula A. Martinos Center for Biomedical Imaging, the Harvard Neuroimaging Center, the Surgical Planning Lab at Brigham and Women's Hospital, the Brain Morphology BIRN (Biomedical Informatics Research Network) and the MIT Artificial Intelligence Laboratory. Together, these active and vibrant programs provide for the best possible training opportunities in imaging science, computer science, clinical application areas, and cognitive neuroscience. A substantial and successful pool of internationally renowned mentors have agreed to participate in this program, and the combined resources provide the best possible exposure to all neuroimaging procedures and insure the capability to draw the highest caliber trainees. A plan for recruiting, selecting and monitoring trainees is proposed. This program will be an asset to the Neuroinformatics initiatives of the Human Brain Project by helping to prepare future scientists with advanced neuroinformatics skills         n/a",Neuroimaging Neuroinformatics Training Program,7371085,K12MH069281,"['Anatomy', 'Area', 'Artificial Intelligence', 'Base of the Brain', 'Biomedical Engineering', 'Biomedical Informatics Research Network', 'Brain', 'Brain imaging', 'Caliber', 'Class', 'Clinical', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Development', 'Discipline', 'Educational Activities', 'Exposure to', 'Foundations', 'Functional disorder', 'Future', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Laboratories', 'Mentored Research Scientist Development Award', 'Mentors', 'Methodology', 'Monitor', 'Neurosciences', 'Numbers', 'Operative Surgical Procedures', 'Physicians', 'Procedures', 'Program Development', 'Psyche structure', 'Range', 'Rate', 'Recruitment Activity', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'SECTM1 gene', 'Science', 'Scientist', 'Surface', 'Techniques', 'Technology', 'Training', 'Training Programs', 'Woman', 'base', 'bioimaging', 'biomedical informatics', 'brain morphology', 'career', 'cationic antimicrobial protein CAP 37', 'clinical application', 'cognitive neuroscience', 'computer science', 'imaging informatics', 'multidisciplinary', 'nervous system disorder', 'neuroimaging', 'neuroinformatics', 'post-doctoral training', 'programs', 'research and development', 'response', 'skills']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,K12,2008,462488,9.683510653424107e-05
"Interactive Learning Modules for Writing Grant Proposals DESCRIPTION (provided by applicant):  The overall objective of this application is to continue our challenge to empower faculty at institutions with high minority enrollment to develop and submit competitive research proposals. Building on our past experience, the competing renewal has three facets which will take place concurrently: 1) up-dating current modules (14) and the development, testing, and evaluation of two new internet course modules; 2) recruitment and training of participants through 5 workshops at remote sites and subsequent participation in the web-based course; 3) continuing evaluation of the training modules for the purpose of technological and content versions. Significant changes from the original program include moving the pre-course conference off-site to maximize the number of faculty participating from contiguous institutions and the introduction of machine language technology to aid in the editing and packaging of participants' grant writing efforts. At the conclusion of the initiative, each participant should be both motivated and empowered to submit a competitive proposal. Thus, our continuing partnership with NIGMS should improve the skills and abilities of researchers/grant writers at minority institutions, increase the number of minorities engaged in biomedical research, and strengthen minority institution's overall research environment. n/a",Interactive Learning Modules for Writing Grant Proposals,7459910,U13GM058252,"['Advisory Committees', 'Applications Grants', 'Biomedical Research', 'Computer Retrieval of Information on Scientific Projects Database', 'Computer software', 'Databases', 'Development', 'Educational workshop', 'Enrollment', 'Environment', 'Evaluation', 'Faculty', 'Feedback', 'Funding', 'Future', 'Goals', 'Grant', 'Grant Review Process', 'Institution', 'Internet', 'Language', 'Learning', 'Machine Learning', 'Mentors', 'Minority', 'National Institute of General Medical Sciences', 'Numbers', 'Online Systems', 'Participant', 'Peer Review', 'Progress Reports', 'Purpose', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Rest', 'Role', 'Scientist', 'Services', 'Site', 'Study Section', 'System', 'Technology', 'Time', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Work', 'Writing', 'base', 'evaluation/testing', 'experience', 'follow-up', 'impression', 'improved', 'member', 'novel strategies', 'programs', 'skills', 'symposium', 'training project']",NIGMS,UNIVERSITY OF KENTUCKY,U13,2008,118789,0.012082297239496529
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7457647,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Condition', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Facility Construction Funding Category', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Numbers', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Score', 'Software Tools', 'Source', 'Structure', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'models and simulation', 'open source', 'outreach', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2008,437938,-0.01902794185524723
"Optimal Micro-Data Switching: An Enhanced Framework and Decision Tool for Confid    DESCRIPTION (provided by applicant): The objective of this project is the development of an innovative technique to avoid disclosure of confidential data in public use tabular data. Our proposed technique, called Optimal Data Switching (OS), overcomes the limitations and disadvantages found in currently deployed disclosure limitation methods. Statistical databases for public use pose a critical problem of identifying how to make the data available for analysis without disclosing information that would infringe on privacy, violate confidentiality, or endanger national security. Organizations in both the public and private sectors have a major stake in this confidentiality protection problem, given the fact that access to data is essential for advancing research and formulating policy. Yet, the possibility of extracting certain sensitive elements of information from the data can jeopardize the welfare of these organizations and potentially, in some instances, the welfare of the society in which they operate. The challenge is, therefore, to represent the data in a form that permits accurate analysis for supporting research, decision-making and policy initiatives, while preventing an unscrupulous or ill-intentioned party from exploiting the data for harmful consequences. Our goal is to build on the latest advances in optimization, to which the OptTek Systems, Inc. (OptTek) research team has made pioneering contributions, to provide a framework based on optimal data switching, enabling the Centers for Disease Control and Prevention (CDC) and other organizations to effectively meet the challenge of confidentiality protection. The framework we propose is structured to be easy to use in a wide array of application settings and diverse user environments, from client-server to web-based, regardless of whether the micro-data is continuous, ordinal, binary, or any combination of these types. The successful development of such a framework, and the computer-based method for implementing it, is badly needed and will be of value to many types of organizations, not only in the public sector but also in the private sector, for whom the incentive to publish data is both economic as well as scientific. Examples in the public sector are evident, where organizations like CDC and the U.S. Census Bureau exist for the purpose of collecting, analyzing and publishing data for analysis by other parties. Numerous examples are also encountered in the private sector, notably in banking and financial services, healthcare (including drug companies and medical research institutions), market research, oil exploration, computational biology, renewable and sustainable energy, retail sales, product development, and a wide variety of other areas. PUBLIC HEALTH RELEVANCE: In the process of accumulating and disseminating public health data for reporting purposes, various uses, and statistical analysis, we must guarantee that individual records describing each person or establishment are protected. Organizations in both the public and private sectors have a major stake in this confidentiality protection problem, given the fact that access to data is essential for advancing research and formulating policy. This project proposes the development of a robust methodology and practical framework to deliver an efficient and effective tool to protect the confidentiality in published tabular data.                      n/a",Optimal Micro-Data Switching: An Enhanced Framework and Decision Tool for Confid,7535414,R43MH086138,"['Accounting', 'American', 'Area', 'Cells', 'Censuses', 'Centers for Disease Control and Prevention (U.S.)', 'Client', 'Computational Biology', 'Confidentiality', 'Data', 'Data Analyses', 'Data Reporting', 'Data Set', 'Databases', 'Decision Analysis', 'Decision Making', 'Development', 'Disadvantaged', 'Disclosure', 'Economics', 'Elements', 'Ensure', 'Environment', 'Goals', 'Health Personnel', 'Healthcare', 'Incentives', 'Individual', 'Inferior', 'Institution', 'Machine Learning', 'Market Research', 'Medical Research', 'Methodology', 'Methods', 'National Security', 'Oils', 'Online Systems', 'Persons', 'Pharmaceutical Preparations', 'Policies', 'Policy Making', 'Privacy', 'Private Sector', 'Problem Solving', 'Process', 'Property', 'Provider', 'Public Health', 'Public Sector', 'Publishing', 'Purpose', 'Records', 'Research', 'Research Methodology', 'Respondent', 'Sales', 'Services', 'Social Welfare', 'Societies', 'Solutions', 'Structure', 'Support of Research', 'System', 'Techniques', 'Time', 'United States National Institutes of Health', 'base', 'computer framework', 'data mining', 'desire', 'innovation', 'interest', 'prevent', 'tool']",NIMH,"OPTTEK SYSTEMS, INC.",R43,2008,99843,0.003010230559371265
"Integration and Visualization of Diverse Biological Data DESCRIPTION (provided by applicant): Currently a gap exists between the explosion of high-throughput data generation in molecular biology and the relatively slower growth of reliable functional information extracted from the data. This gap is largely due to the lack of specificity necessary for accurate gene function prediction in the currently available large-scale experimental technologies for rapid protein function assessment. Bioinformatics methods that integrate diverse data sources in their analysis achieve higher accuracy and thus alleviate this lack of specificity, but there's a paucity of generalizable, efficient, and accurate methods for data integration. In addition, no efficient methods exist to effectively display diverse genomic data, even though visualization has been very valuable for analysis of data from large scale technologies such as gene expression microarrays. The long-term goal of this proposal is to develop an accurate and generalizable bioinformatics framework for integrated analysis and visualization of heterogeneous biological data.      We propose to address the data integration problem with a Bayesian network approach and effective visualization methods. We have shown the efficacy of this method in a proof-of-principle system that increased the accuracy of gene function prediction for Saccharomyces cerevisiae compared to individual data sources. Building on our previous work, we present a two-part plan to improve and expand our system and to develop novel visualization methods for genomic data based on the scalable display technology. First, we will investigate the computational and theoretical issues behind accurate integration, analysis and effective visualization of heterogeneous high-throughput data. Then, leveraging our existing system and algorithmic improvements developed in the first part of the project, we will design and implement a full-scale data integration and function prediction system for Saccharomyces cerevisiae that will be incorporated with the Saccharomyces Genome Database (SGD), a model organism database for yeast.      The proposed system would provide highly accurate automatic function prediction that can accelerate genomic functional annotation through targeted experimental testing. Furthermore, our system will perform general integration and will offer researchers a unified view of the diverse high-throughput data through effective integration and visualization tools, thereby facilitating hypothesis generation and data analysis. Our scalable visualization methods will enable teams of researchers to examine biological data interactively and thus support the highly collaborative nature of genomic research. In addition to contributing to S. cerevisiae genomics, the technology for efficient and accurate heterogeneous data integration and visualization developed as a result of this proposal will form a basis for systems that address the same set of issues for other organisms, including the human. n/a",Integration and Visualization of Diverse Biological Data,7404447,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Collaborations', 'Communities', 'Compatible', 'Computer software', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Depth', 'Development', 'Effectiveness', 'Evaluation', 'Expert Systems', 'Explosion', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grouping', 'Growth', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Information Systems', 'Institutes', 'Investigation', 'Knock-out', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Machine Learning', 'Magic', 'Methods', 'Molecular Biology', 'Monitor', 'Nature', 'Online Systems', 'Organism', 'Phenotype', 'Pliability', 'Probability', 'Process', 'Protein-Protein Interaction Map', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Scientist', 'Side', 'Source', 'Specificity', 'Staining method', 'Stains', 'Structure', 'System', 'Systems Biology', 'Technology', 'Test Result', 'Testing', 'Two-Hybrid System Techniques', 'Universities', 'Visualization software', 'Work', 'Yeasts', 'base', 'comparative', 'computer based statistical methods', 'concept', 'data integration', 'design', 'functional genomics', 'gene function', 'genome database', 'high throughput analysis', 'improved', 'model organisms databases', 'novel', 'parallel computing', 'programs', 'protein function', 'prototype', 'research study', 'software development', 'tandem mass spectrometry', 'tool', 'ultra high resolution', 'web interface']",NIGMS,PRINCETON UNIVERSITY,R01,2008,243004,-0.012639332862314704
"Scalable Learning with Ensemble Techniques and Parallel Computing    DESCRIPTION (provided by applicant): The ability to conduct basic and applied biomedical research is becoming increasingly dependent on data produced by new and emerging technologies. This data has an unprecedented amount of detail and volume. Researchers are therefore dependent on computing and computational tools to be able to visualize, analyze, model, and interpret these large and complex sets of data. Tools for disease detection, diagnosis, treatment, and prevention are common goals of many, if not all, biomedical research programs. Sound analytical and statistical theory and methodology for class pre- diction and class discovery lay the foundation for building these tools, of which the machine learning techniques of classification (supervised learning) and clustering (unsupervised learning) are crucial. Our goal is to produce software for analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies. Ensemble techniques are recent advances in machine learning theory and methodology leading to great improvements in accuracy and stability in data set analysis and interpretation. The results from a committee of primary machine learners (classifiers or clusterers) that have been trained on different instance or feature subsets are combined through techniques such as voting. The high prediction accuracy of classifier ensembles (such as boosting, bagging, and random forests) has generated much excitement in the statistics and machine learning communities. Recent research extends the ensemble methodology to clustering, where class information is unavailable, also yielding superior performance in terms of accuracy and stability. In theory, most ensemble techniques are inherently parallel. However, existing implementations are generally serial and assume the data set is memory resident. Therefore current software will not scale to the large data sets produced in today's biomedical research. We propose to take two approaches to scale ensemble techniques to large data sets: data partitioning approaches and parallel computing. The focus of Phase I will be to prototype scalable classifier ensembles using parallel architectures. We intend to: establish the parallel computing infrastructures; produce a preliminary architecture and software design; investigate a wide range of ensemble generation schemes using data partitioning strategies; and implement scalable bagging and random forests based on the preliminary design. The focus of Phase II will be to complete the software architecture and implement the scalable classifier ensembles and scalable clusterer ensembles within this framework. We intend to: complete research and development of classifier ensembles; extend the classification framework to clusterer ensembles; research and develop a unified interface for building ensembles with differing generation mechanisms and combination strategies; and evaluate the effectiveness of the software on simulated and real data. PUBLIC HEALTH RELEVANCE: The common goals to many, if not all, biomedical research programs are the development of tools for disease detection, diagnosis, treatment, and prevention. These programs often rely on new types of data that have an unprecedented amount of detail and volume. Our goal is to produce software for the analysis and interpretation of large data sets using ensemble machine learning techniques and parallel computing technologies to enable researchers who are dependent on computational tools to have the ability to visualize, analyze, model, and interpret these large and complex sets of data.          n/a",Scalable Learning with Ensemble Techniques and Parallel Computing,7748401,R44GM083965,"['Learning', 'Techniques', 'parallel computing']",NIGMS,INSILICOS,R44,2008,143361,0.005901800275242617
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.       n/a",Bioconductor: an open computing resource for genomics,7495201,P41HG004059,"['Address', 'Archives', 'Area', 'Arts', 'Award', 'Bioconductor', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Budgets', 'Building Codes', 'Class', 'Code', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Data Sources', 'Data Storage and Retrieval', 'Database Management Systems', 'Dedications', 'Development', 'Discipline', 'Documentation', 'Educational process of instructing', 'Electronic Mail', 'Elements', 'Environment', 'Evolution', 'Experimental Designs', 'Faculty', 'Familiarity', 'FarGo', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Goals', 'Grant', 'Head', 'Human Genome', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Internet', 'Investigation', 'Java', 'Knowledge', 'Language', 'Libraries', 'Machine Learning', 'Mails', 'Manuscripts', 'Measures', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Microarray Analysis', 'Motivation', 'Names', 'Nature', 'Numbers', 'Occupations', 'Ontology', 'Operative Surgical Procedures', 'Organism', 'Participant', 'Policies', 'Preparation', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Program Development', 'Programming Languages', 'Provider', 'Public Health Schools', 'Publications', 'Range', 'Reader', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Role', 'Running', 'Schedule', 'Scientist', 'Sequence Alignment', 'Services', 'Software Design', 'Software Engineering', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Statistical Methods', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'cluster computing', 'computing resources', 'cost', 'cost effective', 'data management', 'data structure', 'design', 'experience', 'falls', 'improved', 'innovation', 'interoperability', 'lectures', 'member', 'model development', 'open source', 'originality', 'professor', 'programs', 'quality assurance', 'research study', 'size', 'software development', 'success', 'symposium', 'tool', 'tool development', 'web-accessible']",NHGRI,FRED HUTCHINSON CANCER RESEARCH CENTER,P41,2008,805222,0.0047721682324904854
"Informatics Core for the Collaborative Initiative on Fetal Alcohol Spectrum disor    DESCRIPTION (provided by applicant): The Informatics Core is part of the Consortium for the ""Collaborative Initiative on Fetal Alcohol Spectrum Disorders"" (CIFASD). The theme of this collaborative initiative is a cross-cultural assessment of ""fetal alcohol spectrum disorder"" (FASD). The CIFASD will coordinate basic, behavioral, and clinical investigators in a multidisciplinary research project to better inform approaches aimed at developing effective intervention and treatment approaches for FASD. It will involve the input and contributions from basic researchers, behavioral scientists, and clinical investigators with the willingness to utilize novel and cutting-edge techniques so as not to simply replicate previous or ongoing work, but rather to try and move it forward in a rigorous fashion. The Informatics Core will develop and maintain the CIFASD Data Repository, which will be used to collect, maintain and distribute data generated by the various participants in the consortium. The Informatics Core will be responsible for working with the other consortium participants to define a Data Dictionary to be used in standardizing data collection, enabling the transfer of data to and from the CIFASD Data Repository, consulting on how to establish local data management systems, providing both software tools and consulting to consortium participants, and producing status reports about the progress of the various projects within the consortium. The Informatics Core draws on a wealth of resources, experience, and expertise at Indiana University in information technology infrastructure and data management, The CIFASD Data Repository will be developed on Indiana University's state-of-the-art central supercomputing facilities, taking advantage of Indiana University's strong commitment to institutional computational resources. Resources that will be used to implement the CIFASD Data Repository include multiple supercomputers, an array of readily available database and statistical software, and a high- speed, secure, robust data archiving system capable of storing duplicate copies in multiple physical locations separated by more than fifty miles. The Informatics Core will use these extraordinary computational resources to provide a single, highly secure location for consortium participants to obtain the cross-cultural data that will enable the CIFASD to meet its goals of developing novel techniques for intervention and treatment of FASD.           n/a",Informatics Core for the Collaborative Initiative on Fetal Alcohol Spectrum disor,7502758,U24AA014818,"['Address', 'Adolescent', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Archives', 'Arts', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cells', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Collaborations', 'Computer software', 'Condition', 'Consult', 'Data', 'Data Analyses', 'Data Collection', 'Data Storage and Retrieval', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Dictionary', 'Dietary Intervention', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Elements', 'Emotional', 'Ethanol', 'Ethnic group', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Indiana', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Information Storage', 'Information Technology', 'Interdisciplinary Study', 'Internet', 'Intervention', 'Knowledge', 'Label', 'Language', 'Language Development', 'Life', 'Location', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Mission', 'Modeling', 'Moscow', 'Mothers', 'Mus', 'Names', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'New Mexico', 'Outcome', 'Participant', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Principal Investigator', 'Range', 'Rattus', 'Recording of previous events', 'Reporting', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Schools', 'Scientist', 'Secure', 'Sensitivity and Specificity', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Software Tools', 'Specificity', 'Speed', 'Structure', 'Sum', 'Supercomputing', 'Supplementation', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Universities', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'brain behavior', 'brain morphology', 'cognitive control', 'critical developmental period', 'data integration', 'data management', 'distributed data', 'drinking', 'experience', 'fetal', 'follow-up', 'improved', 'in utero', 'infancy', 'literacy', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'prenatal', 'programs', 'prospective', 'quality assurance', 'reconstruction', 'repository', 'social', 'supercomputer', 'three dimensional structure', 'transmission process', 'willingness']",NIAAA,INDIANA UNIVERSITY BLOOMINGTON,U24,2008,186589,-0.031595395854301905
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7502135,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2008,3570137,-0.0545935827789462
"WormBase: a core data resource for C elegans and other nematodes    DESCRIPTION (provided by applicant):  Caenorhabditis elegans is a major model system for basic biological and biomedical research and the first animal for which there is a complete description of its genome, anatomy and development, and some information about each of its ~22,000 genes. Five years of funding is requested to maintain and expand WormBase, a Model Organism Database (MOD), with complete coverage of core genomic, genetic, anatomical and functional information about this and other nematodes. Such a database is necessary to allow the entire biomedical research community to make full use of nematode genomic sequences. The two top priorities will be intensive data curation and user interface improvement. WormBase will include up-to-date annotation of the genomic data, the current genetic and physical maps and many experimental data such as genome-scale datasets connected to the function and interactions of cells and genes, as well as development, physiology and behavior. Direct access to the sources of biological material, such as the strain collection of the Caenorhabditis Genetics Center and direct links to data sets maintained by others will be provided. Data will be recovered from the existing resources, from direct contribution of the individual laboratories, and from the literature. While WormBase will act as a central forum through which every laboratory will be able to contribute constructively to the global effort to fully comprehend this metazoan organism, WormBase professional curators will ensure detailed attribution of data sources and check consistency and integrity. To facilitate communication, WormBase will use technology, terminology and style concordant with other databases wherever possible. WormBase will maintain ontologies for nematode anatomy and phenotypes. WormBase will be Web-based and easy to use. Multiple relational databases will be used for data management; the object-based Acedb database system will be used for integration, and this integrated database plus ""slave"" relational databases will be used to drive the website. Coordination of the project and the main curation site will be at Caltech under the supervision of a C. elegans biologist. Curation and annotation of genomic sequence will take place at the centers - the Sanger Institute and Washington University - that generated the entire genome sequence. Oxford University will maintain genetic nomenclature.  Nematodes (roundworms) are major parasites of humans, livestock and crops, and extension of WormBase to broader coverage of nematode genomics will facilitate research into the diagnosis and treatment of nematode-based disease. Studies of C. elegans have informed us of basic principles of normal development and the molecular basis of aging, cancer, nicotine addiction, as well as a variety of fundamental biological processes such as cell migration, cell differentiation and cell death.              n/a",WormBase: a core data resource for C elegans and other nematodes,7502984,P41HG002223,"['Ablation', 'Age', 'Agriculture', 'Alleles', 'Anatomy', 'Animals', 'Antibodies', 'Architecture', 'Base Sequence', 'Behavior', 'Binding Sites', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biomedical Research', 'Caenorhabditis', 'Caenorhabditis elegans', 'Cell Communication', 'Cell Death', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Chromosome Mapping', 'Code', 'Collection', 'Communication', 'Communities', 'Comparative Anatomy', 'Compatible', 'DNA Sequence', 'Data', 'Data Set', 'Data Sources', 'Databases', 'Depth', 'Detection', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Ensure', 'Expressed Sequence Tags', 'Funding', 'Gene Expression Regulation', 'Gene Proteins', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Processes', 'Genetic Recombination', 'Genetic Variation', 'Genome', 'Genomics', 'Human', 'Hybrids', 'Imagery', 'Individual', 'Institutes', 'Internet', 'Knock-out', 'Knowledge', 'Laboratories', 'Link', 'Literature', 'Livestock', 'Longevity', 'Malignant Neoplasms', 'Maps', 'Medical', 'Metabolic', 'Methods', 'Molecular', 'Molecular Genetics', 'Mutation', 'Names', 'Natural Language Processing', 'Nature', 'Nematoda', 'Nicotine Dependence', 'Nomenclature', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Parasites', 'Parasitic nematode', 'Pathway interactions', 'Phenotype', 'Physical Chromosome Mapping', 'Physiology', 'Pliability', 'Process', 'Proteins', 'Proteomics', 'RNA Interference', 'Reagent', 'Regulation', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Secure', 'Site', 'Slave', 'Source', 'Subcellular Anatomy', 'Supervision', 'System', 'Techniques', 'Technology', 'Terminology', 'Tertiary Protein Structure', 'Transcript', 'Transgenes', 'Transgenic Organisms', 'Universities', 'Variant', 'Washington', 'Yeasts', 'base', 'cell motility', 'chromatin immunoprecipitation', 'comparative', 'comparative genomic hybridization', 'data integration', 'data management', 'data modeling', 'design', 'experience', 'functional genomics', 'gene function', 'genetic analysis', 'genome sequencing', 'improved', 'interoperability', 'member', 'migration', 'model organisms databases', 'programs', 'research study', 'small molecule', 'tool', 'transcription factor', 'usability', 'web interface', 'yeast two hybrid system']",NHGRI,CALIFORNIA INSTITUTE OF TECHNOLOGY,P41,2008,2750000,-0.05382190262330293
"MUSC Minority Student Development Program    DESCRIPTION (provided by applicant):  The goals of this program are to: 1) increase the number of underrepresented minority (URM) students choosing a research career in the biomedical sciences, 2) enhance the quantity and quality of URM students enrolled in the doctoral program in the College of Graduate Studies, 3) prepare them for a successful career in biomedical sciences, 4) provide structured activities that enhance the interaction of minority and majority students and 5) increase the number of URMs in the Summer Undergraduate Research Program (SURP). To accomplish these goals a Minority Recruitment Committee will be developed to assist in recruiting URMs. An MUSC ""Science Day"" will be implemented to expose minority students to the excitement of biomedical science research. Undergraduate science advisors will nominate potential URM Ph.D. applicants who will attend ""Science Day"" with a parent and the advisor. The SURP will be expanded by five students, designated as E.E. Just Scholars. These SURP participants will interact with minority graduate students via a Big Brother/Sister program. A summer pre-matriculation course to review basic biochemical and molecular concepts will be available for all new students. All students will participate in a ""Diversity in Science"" course that will foster the interaction of minority and majority students that focuses on issues related to minorities in biomedical science. URM graduate students will serve as Graduate Student Ambassadors to HBCUs and present seminars to undergraduates. Funds will be provided for URM graduate students to present their research at a national meeting. A Mentoring Committee will be developed to 1) monitor and advise URM doctoral students through the graduate training program, 2) assist with career development and 3) organize the content of the ""Diversity in Science"" course as well as career workshops. Internal and External Advisory Committees will provide oversight for the program. These programmatic elements will increase the number of minority students participating in biomedical science research and prepare them for a successful career.         n/a",MUSC Minority Student Development Program,7383798,R25GM072643,"['5-(4-hydroxy-3-methoxyphenyl)-5-phenylhydantoin', 'Academia', 'Accounting', 'Achievement', 'Address', 'Admission activity', 'Advisory Committees', 'Affect', 'African American', 'Aging', 'Agonist', 'Alcohols', 'Alzheimer&apos', 's Disease', 'Amino Acids', 'Animals', 'Appendix', 'Applied Research', 'Area', 'Award', 'Back', 'Bacteriorhodopsins', 'Baltimore', 'Belief', 'Biochemical', 'Biochemistry', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Blood Vessels', 'Bradykinin', 'Brain', 'Brothers', 'Budgets', 'Businesses', 'CXCL1 gene', 'Calcium', 'Cancer Biology', 'Cancer Center', 'Cancer Education Grant Program', 'Cardiac', 'Cardiovascular Physiology', 'Cardiovascular system', 'Cell physiology', 'Cells', 'Cellular Structures', 'Cellular biology', 'Ceramides', 'Cessation of life', 'Chemicals', 'Chemistry', 'Chicago', 'Cities', 'Class', 'Classification', 'Cocaine', 'Collaborations', 'Commit', 'Committee Members', 'Communities', 'Complex', 'Contracts', 'Counseling', 'County', 'Cyclic AMP', 'Data', 'Daughter', 'Decision Making', 'Development', 'Development Plans', 'Disease', 'Doctor of Philosophy', 'Doctor of Public Health', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Endotoxins', 'Enrollment', 'Ensure', 'Environment', 'Enzymatic Biochemistry', 'Enzymes', 'Equilibrium', 'Evaluation', 'Event', 'Exhibits', 'Explosion', 'Exposure to', 'Extramural Activities', 'Faculty', 'Failure', 'Fatty Acids', 'Fees', 'Fellowship', 'Flax', 'Florida', 'Fostering', 'Foundations', 'Friends', 'Friendships', 'Funding', 'Funding Mechanisms', 'Future', 'G-Protein-Coupled Receptors', 'GTP-Binding Proteins', 'Genes', 'Genetic', 'Genetic Programming', 'Genetic Transcription', 'Geographic Locations', 'Goals', 'Graduate Education', 'Grant', 'Health Occupations', 'Health Professional', 'Health Services Research', 'Heart Hypertrophy', 'Heroin', 'Historically Black Colleges and Universities', 'Home Page', 'Home environment', 'Hour', 'Human', 'Hypoxia', 'Indiana', 'Individual', 'Industry', 'Information Resources', 'Institutes', 'Institution', 'Insulin Resistance', 'Insulin-Like Growth Factor Receptor', 'Insulin-Like Growth-Factor-Binding Proteins', 'Intellectual Property', 'Internal Medicine', 'International', 'Internet', 'Interview', 'Investigation', 'Journals', 'Laboratories', 'Laboratory Research', 'Lead', 'Leadership', 'Learning', 'Legal patent', 'Letters', 'Life', 'Ligands', 'Lipid Biochemistry', 'Lipids', 'Machine Learning', 'Mails', 'Malignant Neoplasms', 'Marines', 'Maryland', 'Mass Spectrum Analysis', 'Mediating', 'Medical', 'Medical center', 'Meiosis', 'Membrane', 'Membrane Transport Proteins', 'Mentors', 'Metabolism', 'Methods', 'Microfluidics', 'Minority', 'Mission', 'Mitosis', 'Modality', 'Modems', 'Modification', 'Molecular', 'Molecular and Cellular Biology', 'Monitor', 'Multiple Sclerosis', 'Myelin', 'NMR Spectroscopy', 'National Cancer Institute', 'National Institute of General Medical Sciences', 'Natural regeneration', 'Nervous system structure', 'Neurobiology', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Neurosciences', 'Neurosciences Research', 'Newsletter', 'Nucleic Acids', 'Numbers', 'Occupations', 'Oral', 'Organic Chemistry', 'Other Minority', 'Outcome', 'Oxygen', 'Parents', 'Parkinson Disease', 'Participant', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatrics', 'Pennsylvania', 'Performance', 'Pharmacologic Substance', 'Pharmacology', 'Phase', 'Phospholipids', 'Phosphotransferases', 'Physics', 'Play', 'Policies', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Program Development', 'Progress Reports', 'Proteins', 'Proteomics', 'Published Comment', 'Purpose', 'Qualifying', 'Range', 'Recommendation', 'Recording of previous events', 'Recruitment Activity', 'Regulation', 'Reporting', 'Research', 'Research Ethics', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Residencies', 'Resolution', 'Resources', 'Restaurants', 'Rhodopsin', 'Role', 'Rotation', 'Schedule', 'Scholarship', 'Schools', 'Science', 'Scientist', 'Score', 'Series', 'Serotonin', 'Services', 'Shock', 'Signal Pathway', 'Signal Transduction', 'Sister', 'Site', 'Site Visit', 'Solid', 'Son', 'South Carolina', 'Sphingolipids', 'Staging', 'Stem cells', 'Strategic Planning', 'Stress', 'Structure', 'Structure-Activity Relationship', 'Students', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Telephone', 'Testing', 'Text', 'Therapeutic', 'Thinking', 'Thromboxane A2', 'Time', 'Toxicology', 'Training', 'Training Programs', 'Translational Research', 'Translations', 'Transportation', 'Travel', 'Underrepresented Minority', 'United States', 'United States National Institutes of Health', 'Universities', 'Vision', 'Visit', 'Vocational Guidance', 'Week', 'Wolves', 'Work', 'Writing', 'X-Ray Crystallography', 'addiction', 'aging brain', 'angiogenesis', 'anticancer research', 'base', 'body system', 'brain behavior', 'cancer therapy', 'career', 'cell growth', 'cell injury', 'cell motility', 'chemical bond', 'college', 'complement C2a', 'concept', 'cooking', 'cost', 'day', 'design', 'drug of abuse', 'expectation', 'experience', 'falls', 'fascinate', 'follow-up', 'frontier', 'gamma-Aminobutyric Acid', 'gene function', 'genome sequencing', 'high school', 'improved', 'innovation', 'insight', 'instructor', 'interest', 'journal article', 'lectures', 'lipid metabolism', 'member', 'minority health', 'myelination', 'nervous system disorder', 'novel', 'novel strategies', 'numb protein', 'patient oriented', 'posters', 'pre-clinical', 'professor', 'programs', 'protein protein interaction', 'protein structure function', 'receptor', 'receptor coupling', 'research facility', 'response', 'role model', 'science education', 'skills', 'social', 'soft drink', 'structural biology', 'success', 'symposium', 'technology development', 'theories', 'tool', 'transmission process', 'tumorigenesis', 'two-dimensional', 'tyrosine receptor', 'university student']",NIGMS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R25,2008,99916,0.036079643068903565
"MUSC Minority Student Development Program    DESCRIPTION (provided by applicant):  The goals of this program are to: 1) increase the number of underrepresented minority (URM) students choosing a research career in the biomedical sciences, 2) enhance the quantity and quality of URM students enrolled in the doctoral program in the College of Graduate Studies, 3) prepare them for a successful career in biomedical sciences, 4) provide structured activities that enhance the interaction of minority and majority students and 5) increase the number of URMs in the Summer Undergraduate Research Program (SURP). To accomplish these goals a Minority Recruitment Committee will be developed to assist in recruiting URMs. An MUSC ""Science Day"" will be implemented to expose minority students to the excitement of biomedical science research. Undergraduate science advisors will nominate potential URM Ph.D. applicants who will attend ""Science Day"" with a parent and the advisor. The SURP will be expanded by five students, designated as E.E. Just Scholars. These SURP participants will interact with minority graduate students via a Big Brother/Sister program. A summer pre-matriculation course to review basic biochemical and molecular concepts will be available for all new students. All students will participate in a ""Diversity in Science"" course that will foster the interaction of minority and majority students that focuses on issues related to minorities in biomedical science. URM graduate students will serve as Graduate Student Ambassadors to HBCUs and present seminars to undergraduates. Funds will be provided for URM graduate students to present their research at a national meeting. A Mentoring Committee will be developed to 1) monitor and advise URM doctoral students through the graduate training program, 2) assist with career development and 3) organize the content of the ""Diversity in Science"" course as well as career workshops. Internal and External Advisory Committees will provide oversight for the program. These programmatic elements will increase the number of minority students participating in biomedical science research and prepare them for a successful career.         n/a",MUSC Minority Student Development Program,7644195,R25GM072643,"['5-(4-hydroxy-3-methoxyphenyl)-5-phenylhydantoin', 'Academia', 'Accounting', 'Achievement', 'Address', 'Admission activity', 'Advisory Committees', 'Affect', 'African American', 'Aging', 'Agonist', 'Alcohols', 'Alzheimer&apos', 's Disease', 'Amino Acids', 'Animals', 'Appendix', 'Applied Research', 'Area', 'Award', 'Back', 'Bacteriorhodopsins', 'Baltimore', 'Belief', 'Biochemical', 'Biochemistry', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Blood Vessels', 'Bradykinin', 'Brain', 'Brothers', 'Budgets', 'Businesses', 'CXCL1 gene', 'Calcium', 'Cancer Biology', 'Cancer Center', 'Cancer Education Grant Program', 'Cardiac', 'Cardiovascular Physiology', 'Cardiovascular system', 'Cell physiology', 'Cells', 'Cellular Structures', 'Cellular biology', 'Ceramides', 'Cessation of life', 'Chemicals', 'Chemistry', 'Chicago', 'Cities', 'Class', 'Classification', 'Cocaine', 'Collaborations', 'Commit', 'Committee Members', 'Communities', 'Complex', 'Contracts', 'Counseling', 'County', 'Cyclic AMP', 'Data', 'Daughter', 'Decision Making', 'Development', 'Development Plans', 'Disease', 'Doctor of Philosophy', 'Doctor of Public Health', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Endotoxins', 'Enrollment', 'Ensure', 'Environment', 'Enzymatic Biochemistry', 'Enzymes', 'Equilibrium', 'Evaluation', 'Event', 'Exhibits', 'Explosion', 'Exposure to', 'Extramural Activities', 'Faculty', 'Failure', 'Fatty Acids', 'Fees', 'Fellowship', 'Flax', 'Florida', 'Fostering', 'Foundations', 'Friends', 'Friendships', 'Funding', 'Funding Mechanisms', 'Future', 'G-Protein-Coupled Receptors', 'GTP-Binding Proteins', 'Genes', 'Genetic', 'Genetic Programming', 'Genetic Transcription', 'Geographic Locations', 'Goals', 'Graduate Education', 'Grant', 'Health Occupations', 'Health Professional', 'Health Services Research', 'Heart Hypertrophy', 'Heroin', 'Historically Black Colleges and Universities', 'Home Page', 'Home environment', 'Hour', 'Human', 'Hypoxia', 'Indiana', 'Individual', 'Industry', 'Information Resources', 'Institutes', 'Institution', 'Insulin Resistance', 'Insulin-Like Growth Factor Receptor', 'Insulin-Like Growth-Factor-Binding Proteins', 'Intellectual Property', 'Internal Medicine', 'International', 'Internet', 'Interview', 'Investigation', 'Journals', 'Laboratories', 'Laboratory Research', 'Lead', 'Leadership', 'Learning', 'Legal patent', 'Letters', 'Life', 'Ligands', 'Lipid Biochemistry', 'Lipids', 'Machine Learning', 'Mails', 'Malignant Neoplasms', 'Marines', 'Maryland', 'Mass Spectrum Analysis', 'Mediating', 'Medical', 'Medical center', 'Meiosis', 'Membrane', 'Membrane Transport Proteins', 'Mentors', 'Metabolism', 'Methods', 'Microfluidics', 'Minority', 'Mission', 'Mitosis', 'Modality', 'Modems', 'Modification', 'Molecular', 'Molecular and Cellular Biology', 'Monitor', 'Multiple Sclerosis', 'Myelin', 'NMR Spectroscopy', 'National Cancer Institute', 'National Institute of General Medical Sciences', 'Natural regeneration', 'Nervous system structure', 'Neurobiology', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Neurosciences', 'Neurosciences Research', 'Newsletter', 'Nucleic Acids', 'Numbers', 'Occupations', 'Oral', 'Organic Chemistry', 'Other Minority', 'Outcome', 'Oxygen', 'Parents', 'Parkinson Disease', 'Participant', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatrics', 'Pennsylvania', 'Performance', 'Pharmacologic Substance', 'Pharmacology', 'Phase', 'Phospholipids', 'Phosphotransferases', 'Physics', 'Play', 'Policies', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Program Development', 'Progress Reports', 'Proteins', 'Proteomics', 'Published Comment', 'Purpose', 'Qualifying', 'Range', 'Recommendation', 'Recording of previous events', 'Recruitment Activity', 'Regulation', 'Reporting', 'Research', 'Research Ethics', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Residencies', 'Resolution', 'Resources', 'Restaurants', 'Rhodopsin', 'Role', 'Rotation', 'Schedule', 'Scholarship', 'Schools', 'Science', 'Scientist', 'Score', 'Series', 'Serotonin', 'Services', 'Shock', 'Signal Pathway', 'Signal Transduction', 'Sister', 'Site', 'Site Visit', 'Solid', 'Son', 'South Carolina', 'Sphingolipids', 'Staging', 'Stem cells', 'Strategic Planning', 'Stress', 'Structure', 'Structure-Activity Relationship', 'Students', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Telephone', 'Testing', 'Text', 'Therapeutic', 'Thinking', 'Thromboxane A2', 'Time', 'Toxicology', 'Training', 'Training Programs', 'Translational Research', 'Translations', 'Transportation', 'Travel', 'Underrepresented Minority', 'United States', 'United States National Institutes of Health', 'Universities', 'Vision', 'Visit', 'Vocational Guidance', 'Week', 'Wolves', 'Work', 'Writing', 'X-Ray Crystallography', 'addiction', 'aging brain', 'angiogenesis', 'anticancer research', 'base', 'body system', 'brain behavior', 'cancer therapy', 'career', 'cell growth', 'cell injury', 'cell motility', 'chemical bond', 'college', 'complement C2a', 'concept', 'cooking', 'cost', 'day', 'design', 'drug of abuse', 'expectation', 'experience', 'falls', 'fascinate', 'follow-up', 'frontier', 'gamma-Aminobutyric Acid', 'gene function', 'genome sequencing', 'high school', 'improved', 'innovation', 'insight', 'instructor', 'interest', 'journal article', 'lectures', 'lipid metabolism', 'member', 'minority health', 'myelination', 'nervous system disorder', 'novel', 'novel strategies', 'numb protein', 'patient oriented', 'posters', 'pre-clinical', 'professor', 'programs', 'protein protein interaction', 'protein structure function', 'receptor', 'receptor coupling', 'research facility', 'response', 'role model', 'science education', 'skills', 'social', 'soft drink', 'structural biology', 'success', 'symposium', 'technology development', 'theories', 'tool', 'transmission process', 'tumorigenesis', 'two-dimensional', 'tyrosine receptor', 'university student']",NIGMS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R25,2008,95384,0.036079643068903565
"MBRS IMSD Program at the University of Kansas    DESCRIPTION (provided by applicant):  Within the three short years since the University of Kansas (KU) IMSD program began, twelve minority students, including six American Indians, will have applied to graduate school. This is a continuation proposal to allow us to build on these successes. KU IMSD works in concert with other NIH funded programs (Bridge, RISE, IRACDA) and takes full advantage of the juxtaposition of a Research I Institution (KU) and one of the largest tribal colleges (Haskell Indian Nations University). KU IMSD consists of four components: 1) providing research experiences to American Indian and other minority students, with a particular a focus on recruiting Haskell students from the Bridge or RISE program; 2) enhancing and modifying the curriculum; 3) offering an interdisciplinary seminar series and 4) providing financial aid and mentoring. The undergraduate research experience takes a broad, interdisciplinary approach to placing students into one of 77 possible KU labs and includes opportunities for students to share their research results at local and national meetings. The program will also support several American Indian graduate students who have obtained BA's from Haskell. IMSD supported curricular enhancements that have shown remarkable results over the past three years will be continued for gatekeeper courses in biology, chemistry and math. In biology alone, the average grade point average of American Indian students who completed the introductory biology course has increased from 0.86 to 2.94 over the past six years. An integrative seminar series will bring together students from the IMSD, Bridge, and RISE programs to foster community and learning. Support from KU IMSD for undergraduate researchers will be a cornerstone in providing financial support along with KU scholarships targeted for American Indian students. Mentoring will be provided from faculty (research advisors), the IMSD Program Coordinator (individual and group meetings) and peers (other IMSD students). Evaluation and tracking procedures will allow for regular adjustment of activities during the course of the program and assessment of whether goals have been met. If funded for another four years, the KU/Haskell collaboration provides the opportunity to significantly impact the number of American Indian scientists in this country.         n/a",MBRS IMSD Program at the University of Kansas,7389728,R25GM062232,"['Address', 'Administrative Personnel', 'Administrator', 'Adopted', 'Advertising', 'Alaska', 'Algorithms', 'American Indians', 'Appendix', 'Area', 'Arrhythmia', 'Artificial Intelligence', 'Arts', 'Attention', 'Authorization documentation', 'Behavior', 'Behavioral Sciences', 'Biodiversity', 'Biogenesis', 'Bioinformatics', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Books', 'Bovine Spongiform Encephalopathy', 'Budgets', 'Calculi', 'Cells', 'Chaos Theory', 'Characteristics', 'Charge', 'Chemistry', 'Cities', 'Class', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Computers', 'Conservatism', 'Country', 'Coupled', 'DNA', 'DNA Structure', 'Daily', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Depth', 'Development', 'Discipline', 'Disease', 'Distant', 'Doctor of Philosophy', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Engineering', 'Enrollment', 'Environment', 'Equilibrium', 'Ethics', 'Evaluation', 'Event', 'Exercise', 'Exposure to', 'Faculty', 'Family', 'Feedback', 'Feeling', 'Fees', 'Film', 'Financial Support', 'Fostering', 'Foundations', 'Friends', 'Funding', 'Future', 'GYPA gene', 'Gatekeeping', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Glycophorin A', 'Goals', 'Grant', 'Graph', 'Group Meetings', 'Growth', 'Habits', 'Hand', 'Health', 'Health Sciences', 'Heart', 'Helix (Snails)', 'Home environment', 'Hour', 'Housing', 'Human', 'Human Resources', 'Humanities', 'Indigenous', 'Individual', 'Informatics', 'Information Systems', 'Institutes', 'Institution', 'Internet', 'Internships', 'Invasive', 'Journals', 'Judgment', 'Kansas', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Light', 'Link', 'Literature', 'Malignant Neoplasms', 'Mathematics', 'Medical', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Minority', 'Minority Groups', 'Modeling', 'Modems', 'Modification', 'Molecular Biology', 'Molecular and Cellular Biology', 'Monitor', 'Motivation', 'Museums', 'Music', 'Mutation', 'National Institute of General Medical Sciences', 'Natural History', 'Newsletter', 'Numbers', 'Oklahoma', 'Oral', 'Oral cavity', 'Organic Chemistry', 'Other Minority', 'Outcome', 'Pamphlets', 'Paper', 'Parents', 'Participant', 'Performance', 'Personality', 'Pharmaceutical Chemistry', 'Placement', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Poverty', 'Preparation', 'Principal Investigator', 'Problem Solving', 'Procedures', 'Process', 'Productivity', 'Program Development', 'Progress Reports', 'Proteins', 'Published Comment', 'Purpose', 'Qualifying', 'Quantum Mechanics', 'RNA', 'Race', 'Radio', 'Range', 'Reading', 'Recommendation', 'Records', 'Recruitment Activity', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Review Committee', 'Rewards', 'Schedule', 'Scholarship', 'Schools', 'Science', 'Scientist', 'Selection Criteria', 'Series', 'Services', 'Shock', 'Site', 'Slide', 'Snow', 'Social Functioning', 'Source', 'Sports', 'Standards of Weights and Measures', 'Students', 'Supervision', 'Support Groups', 'Surveys', 'Techniques', 'Technology', 'Text', 'Textbooks', 'Thinking', 'Time', 'Time Management', 'Today', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Update', 'Ursidae Family', 'Visit', 'Visualization software', 'Wages', 'Week', 'Work', 'Writing', 'abstracting', 'aging nutrition', 'analytical method', 'base', 'biomedical scientist', 'career', 'cohort', 'college', 'computer generated', 'computer science', 'concept', 'cost', 'court', 'data acquisition', 'day', 'digital', 'ear helix', 'expectation', 'experience', 'falls', 'follow-up', 'gene therapy', 'high school', 'i(19)', 'image visualization', 'improved', 'instructor', 'interdisciplinary approach', 'interest', 'lectures', 'member', 'novel', 'peer', 'posters', 'preference', 'professor', 'programs', 'protein structure', 'role model', 'satisfaction', 'size', 'skills', 'success', 'symposium', 'theories', 'tool', 'tribal college']",NIGMS,UNIVERSITY OF KANSAS LAWRENCE,R25,2008,373102,0.03807424098289514
"Semantics and Services enabled Problem Solving Environment for Trypanosoma cruzi    DESCRIPTION (provided by applicant): The study of complex biological systems increasingly depends on vast amounts of dynamic information from diverse sources. The scientific analysis of the parasite Trypanosoma cruzi (T.cruzi), the principal causative agent of human Chagas disease, is the driving biological application of this proposal. Approximately 18 million people, predominantly in Latin America, are infected with the T.cruzi parasite. As many as 40 percent of these are predicted eventually to suffer from Chagas disease, which is the leading cause of heart disease and sudden death in middle-aged adults in the region. Research on T. cruzi is therefore an important human disease related effort. It has reached a critical juncture with the quantities of experimental data being generated by labs around the world, due in large part to the publication of the T.cruzi genome in 2005. Although this research has the potential to improve human health significantly, the data being generated exist in independent heterogeneous databases with poor integration and accessibility. The scientific objectives of this research proposal are to develop and deploy a novel ontology-driven semantic problem-solving environment (PSE) for T.cruzi. This is in collaboration with the National Center for Biomedical Ontologies (NCBO) and will leverage its resources to achieve the objectives of this proposal as well as effectively to disseminate results to the broader life science community, including researchers in human pathogens. The PSE allows the dynamic integration of local and public data to answer biological questions at multiple levels of granularity. The PSE will utilize state-of- the-art semantic technologies for effective querying of multiple databases and, just as important, feature an intuitive and comprehensive set of interfaces for usability and easy adoption by biologists. Included in the multimodal datasets will be the genomic data and the associated bioinformatics predictions, functional information from metabolic pathways, experimental data from mass spectrometry and microarray experiments, and textual information from Pubmed. Researchers will be able to use and contribute to a rigorously curated T.cruzi knowledge base that will make it reusable and extensible. The resources developed as part of this proposal will be also useful to researchers in T.cruzi related kinetoplastids, Trypanosoma brucei and Leishmania major (among other pathogenic organisms), which use similar research protocols and face similar informatics challenges. PUBLIC HEALTH RELEVANCE: The scientific objective of this proposal is to develop and deploy a novel ontology-driven semantic problem-solving environment (PSE) for Trypanosoma cruzi, a parasite that infects approximately 18 million people, predominantly in Latin America. As many as 40 percent of those infected are predicted to eventually suffer from Chagas disease, the leading cause of heart disease and sudden death in middle-aged adults in the region. Facilitating T.cruzi research through the PSE, with the aim of identifying vaccine, diagnostic, and therapeutic targets, is an important human disease related endeavor.          n/a",Semantics and Services enabled Problem Solving Environment for Trypanosoma cruzi,7428761,R01HL087795,"['Acquired Immunodeficiency Syndrome', 'Address', 'Adherence', 'Adopted', 'Adoption', 'Adult', 'Algorithms', 'Anatomy', 'Animal Model', 'Anti-Retroviral Agents', 'Architecture', 'Archives', 'Area', 'Arts', 'Automobile Driving', 'Beds', 'Behavior', 'Bioinformatics', 'Biological', 'Biological Sciences', 'Biomedical Computing', 'Biomedical Research', 'Body of uterus', 'Buffaloes', 'California', 'Caring', 'Chagas Disease', 'Childhood', 'Chronic', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Computers', 'Controlled Vocabulary', 'DNA', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Doctor of Public Health', 'Drops', 'Drosophila genus', 'Educational Activities', 'Educational workshop', 'Electronics', 'Enrollment', 'Ensure', 'Environment', 'Evaluation', 'Evolution', 'Face', 'Feedback', 'Foundations', 'Future', 'Gene Mutation', 'Generations', 'Generic Drugs', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Geographic Locations', 'Goals', 'HIV', 'HIV Infections', 'Health', 'Heart Diseases', 'Homologous Gene', 'Human', 'Human Resources', 'Imagery', 'Immunologic Deficiency Syndromes', 'Immunology', 'Individual', 'Infection', 'Informatics', 'Information Management', 'Information Resources', 'Information Services', 'Information Technology', 'International', 'Internet', 'Interruption', 'Knowledge', 'Laboratories', 'Laboratory Organism', 'Language', 'Latin America', 'Lead', 'Learning', 'Leishmania major', 'Libraries', 'Link', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Medical Informatics', 'Medicine', 'Metabolic Pathway', 'Metadata', 'Methodology', 'Methods', 'Mind', 'Mining', 'Modeling', 'Mutation', 'Natural Language Processing', 'Nature', 'Online Mendelian Inheritance In Man', 'Online Systems', 'Ontology', 'Operative Surgical Procedures', 'Oregon', 'Organism', 'Orthologous Gene', 'Outcome', 'Parasites', 'Pathogenesis', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Philosophy', 'Physiology', 'Prevention strategy', 'Principal Investigator', 'Problem Solving', 'Process', 'Proteomics', 'Protocols documentation', 'PubMed', 'Public Health', 'Publications', 'Publishing', 'Purpose', 'Randomized Clinical Trials', 'Range', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'San Francisco', 'Science', 'Scientist', 'Semantics', 'Services', 'Site', 'Software Tools', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Structure', 'Study models', 'Sudden Death', 'Sum', 'System', 'TAF8 gene', 'Talents', 'Techniques', 'Technology', 'Terminology', 'Testing', 'Thinking', 'Training', 'Treatment Protocols', 'Trypanosoma brucei brucei', 'Trypanosoma cruzi', 'USA Georgia', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Universities', 'Update', 'Vaccines', 'Vertical Disease Transmission', 'Victoria Austrailia', 'Virtual Library', 'Virus', 'Western Asia Georgia', 'Work', 'Zebrafish', 'abstracting', 'base', 'biocomputing', 'biomedical scientist', 'college', 'computer based Semantic Analysis', 'computer science', 'concept', 'data integration', 'design', 'desire', 'fundamental research', 'human disease', 'improved', 'indexing', 'innovative technologies', 'knowledge base', 'member', 'metabolomics', 'middle age', 'novel', 'novel strategies', 'open source', 'outreach', 'pandemic disease', 'pathogen', 'prevent', 'programs', 'protein protein interaction', 'repository', 'research and development', 'research study', 'syntax', 'theories', 'therapeutic target', 'tool', 'usability']",NHLBI,WRIGHT STATE UNIVERSITY,R01,2008,393930,-0.02911994653968643
"Intelligent Control Approach to Anemia Management    DESCRIPTION (provided by applicant):   Management of anemia due to end-stage renal disease is a multifactorial decision process involving administration of recombinant human erythropoietin (rHuEPO) and iron, as well as assessment of other factors influencing the progress of the disease. This application aims at improving the cost-effectiveness of this process through the use of state-of-the-art numerical tools from control engineering and machine learning. The specific aims are the collection of anemia management data and development of new guidelines for period of measuring hemoglobin levels if necessary, development of individualized, computer-assisted approach to rHuEPO dosing based on modern control engineering and machine learning approach, evaluation of the developed tools through numeric simulation and assessment of the potential improvements in therapy and projected savings in rHuEPO utilization. The final aim is to provide a physical implementation and to perform a clinical evaluation of the developed methodology. The applicant, Dr. Adam E. Gaweda, is an Instructor of Medicine in the Department of Medicine, Division of Nephrology at the University of Louisville. His original training is in the field of electrical engineering (M.Eng.) and computer science (Ph.D.). The applicant plans to develop as an independent and well established researcher in the field of biomedical engineering with focus on translation of state-of-the-art technology to heath care. To achieve this goal the applicant will enroll into the Clinical Research, Epidemiology and Statistics Training (CREST) Program at the University of Louisville, School of Public Health and Information Sciences       n/a",Intelligent Control Approach to Anemia Management,7209599,K25DK072085,"['Adverse event', 'Algorithms', 'Anemia', 'Anti-Arrhythmia Agents', 'Artificial Intelligence', 'Arts', 'Biological Models', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood', 'Blood Vessels', 'Caring', 'Chronic', 'Clinical', 'Clinical Research', 'Collection', 'Complex', 'Computer Assisted', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Controlled Clinical Trials', 'Data', 'Decision Support Systems', 'Development', 'Dialysis procedure', 'Disease', 'Doctor of Philosophy', 'Dose', 'Drug Prescriptions', 'Effectiveness', 'Electrical Engineering', 'End stage renal failure', 'Engineering', 'Enrollment', 'Epidemiology', 'Erythropoietin', 'Evaluation', 'Feedback', 'Frequencies', 'Funding', 'Goals', 'Guidelines', 'Hemodialysis', 'Hemoglobin', 'Hemoglobin concentration result', 'Human', 'Individual', 'Information Sciences', 'Insulin', 'Iron', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Morbidity - disease rate', 'Nephrology', 'Outcome', 'Patient Monitoring', 'Patients', 'Pharmaceutical Preparations', 'Physical Dialysis', 'Physiological', 'Population', 'Process', 'Protocols documentation', 'Public Health Schools', 'Range', 'Research', 'Research Personnel', 'Safety', 'Sampling', 'Savings', 'Standards of Weights and Measures', 'Techniques', 'Technology', 'Testing', 'Training', 'Training Programs', 'Translations', 'Universities', 'Veterans', 'Waran', 'Work', 'base', 'computer science', 'cost effectiveness', 'data management', 'desire', 'experience', 'improved', 'insight', 'instructor', 'mathematical algorithm', 'novel', 'prescription document', 'prescription procedure', 'programs', 'recombinant human erythropoietin', 'research clinical testing', 'response', 'simulation', 'statistics', 'theories', 'tool']",NIDDK,UNIVERSITY OF LOUISVILLE,K25,2007,112534,0.01586836812124561
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7246847,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'Work', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2007,2183988,-0.0016564585999463526
"Efficient software and algorithms for analyzing markers data on general pedigree    DESCRIPTION (provided by applicant): Our long-term objective is to develop an efficient, extensible, modular, and accessible software toolbox that facilitates statistical methods for analyzing complex pedigrees. The toolbox will consist of novel algorithms that extend state of the art algorithms from graph theory, statistics, artificial intelligence, and genetics. This tool will enhance capabilities to analyze genetic components of inherited diseases. The specific aim of this project is to develop an extensible software system for efficiently computing pedigree likelihood for complex diseases in the presence of multiple polymorphic markers, and SNP markers, in fully general pedigrees taking into account qualitative (discrete) and quantitative traits and a variety of disease models. Our experience shows that by building on top of the insight gained within the last decade from the study of computational probability, in particular, from the theory of probabilistic networks, we can construct a software system whose functionality, speed, and extensibility is unmatched by current linkage software. We plan to integrate these new methods into an existing linkage analysis software, called superlink, which is already gaining momentum for analyzing large pedigrees. We will also continue to work with several participating genetic units in research hospitals and improve the software quality and reliability as we proceed with algorithmic improvements. In this project we will develop novel algorithms for more efficient likelihood calculations and more efficient maximization algorithms for the most general pedigrees. These algorithms will remove redundancy due to determinism, use cashing of partial results effectively, and determine close-to-optimal order of operations taking into account these enhancements. Time-space trade-offs will be computed that allow to use memory space in the most effective way, and to automatically determine on which portions of a complex pedigree exact computations are infeasible. In such cases, a combination of exact computations with intelligent use of approximation techniques, such as variational methods and sampling, will be employed. In particular we will focus on advancing sampling schemes such as MCMC used in the Morgan program and integrating it with exact computation. A serious effort will be devoted for quality control, interface design, and integration with complementing available software with the active help of current users of Superlink and Morgan. PUBLIC SUMMARY: The availability of extensive DMA measurements and new computational techniques provides the opportunity to decipher genetic components of inherited diseases. The main aim of this project is to deliver a fully tested and extremely strong software package to deliver the best computational techniques to genetics researchers.          n/a",Efficient software and algorithms for analyzing markers data on general pedigree,7318595,R01HG004175,"['Accounting', 'Address', 'Algorithms', 'Animals', 'Artificial Intelligence', 'Arts', 'Breeding', 'Complement', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Disease', 'Disease Resistance', 'Disease model', 'Genes', 'Genetic', 'Genetic Counseling', 'Graph', 'Hospitals', 'Human', 'Inherited', 'Measurement', 'Memory', 'Methods', 'Numbers', 'Operative Surgical Procedures', 'Polymorphic Microsatellite Marker', 'Probability', 'Quality Control', 'Range', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scheme', 'Single Nucleotide Polymorphism', 'Speed', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Work', 'base', 'computer studies', 'design', 'experience', 'genetic analysis', 'genetic linkage analysis', 'genetic pedigree', 'improved', 'insight', 'novel', 'programs', 'size', 'software systems', 'statistics', 'theories', 'tool', 'trait']",NHGRI,UNIVERSITY OF CALIFORNIA IRVINE,R01,2007,372000,-0.012681918769059624
"Bioconductor: an open computing resource for genomics    DESCRIPTION (provided by applicant): The Bioconductor project provides an open resource for the development and distribution of innovative reliable software for computational biology and bioinformatics. The range of available software is broad and rapidly growing as are both the user community and the developer community. The project maintains a web portal for delivering software and documentation to end users as well as an active mailing list. Additional services for developers include a software archive, mailing list and assistance and advice program development and design      We propose an active development strategy designed to meet new challenges while simultaneously providing user and developer support for existing tools and methods. In particular we emphasize a design strategy that accommodates the imperfect, yet evolving nature of biological knowledge and the relatively rapid development of new experimental technologies. Software solutions must be able to rapidly adapt and to facilitate new problems when they arise.      CRITQUE 1:      The Bioconductor project began in 2001. In 2002 it was awarded a BISTI grant for three years 2003-2006). During this time the project has expanded and provided support for a world wide community of researchers. This is a proposal for continued development for Bioconductor, which is a set of statistical programs which are specifically tailored to the computatational biology community. Bioconductor is composed of over 130 R packages that have been contributed by a large number of developers. The software packages range from state of the art statistical methods which typically are used in microarray analysis, to annotation tools, to plotting functions, GUIs, to sequence alignment and data management packages. Contributions to and usage of Bioconductor is growing rapidly and the applicants are requesting support to continue its development as well as general logistical support for software distribution and quality assurance. The proposal includes a research component for Bioconductor which will involve the development of analysis techniques. This will include optimization of the R statistical analyses, statistical processing of Affymetrix data, analysis of SNP data, improved standards, data storage, retreivals from NCBI, sequence management, machine learning, web services and distributed computing.      SCIENTIFIC MERIT   The applicants address many issues that are crucial to the success of a large open source project with multiple contributors. Examples of training, scientific publication, documentation and resource development run throughout the proposal. Many tangible examples were given on the usage of the system by the scientific community.        EXPERIMENTAL DESIGN   This is a description of their management workflow for the project which does a good job of demonstrating the technical excellence brought to the project by this group. 1) Build annotation packages every three months, Integrate changes in annotation source data structure into annotation package building code. 2) Maintain project website, mailing lists, source control archive. Organize web resources for short course and conferences. 3) Improve existing software. 4) Sustain automated nightly builds. Work with developers whose packages fail to pass QA. 5) Resolve cross-platform issues. 6) Review new submissions. Answer questions on the mailing lists. 7) Use software engineering best practices. Develop unit testing strategies. Design appropriate classes and methods for new data types. Refactor existing code for better interoperability and extensibility. 8) Develop and organize training materials and documentation.      Extensive detail on testing, build procedures, interoperability, quality assurance and project management is given elsewhere in the document. They clearly have dealt with many issues necessary for a project of this size. They state that one of the biggest cost items is support of this package to run on multiple platforms. They point out that many contributors focus on a single platform, much of their work is track down cross-platform bugs. This is time well-spent, given the platforms used are in sync with the needs of the greater bioinformatics community.        ORIGINALITY   While a high degree of originality is not a particularly critical element of open source software development project, there are certainly areas in the proposal that are unique. Most importantly, it is safe to say that there is not another project which has this blend of statistical analysis systems specifically tailored to a important research bioinformatics area that can be deployed on a number of different computer environments.      INVESTIGATOR AND CO-INVESTIGATORS   Dr. Gentleman is the founder and leader of the Bioconductor project. Dr. Gentlemen was an Associate Professor in the Department of Biostatistics, Harvard School of Public Health and Department of Biostatistics and Computational Biology, Dana Farber Cancer Institute. In 2004 he became Program Head, Computational Biology, at the Fred Hutchinson Cancer Research Center in Seattle. He has on the order of ten publications relating to Bioconductor or related statistical analysis. He implemented the original versions of the R programming language jointly with another co-founder. He is PI or Investigator of a number of research grants, at least two are directly related to this work. He and other members of the proposal have taught a number of courses and given lectures on Bioconductor, the amount of these courses certainly indicate significant dedication to the project.  A review of the PI and Co-PI activities related to this project are shown on Table 3 on page 42 of the application. The roles and time allocations assigned to each participant appear to be reasonable.  Dr. Gentleman will serve as project leader and will manage the programmers, coordinating the project, and investigating new computational methods and approaches.  Dr. Vincent Carey, as co Principal Investigator has 20% time allocated for the project.  In 2005 he became Associate Professor of Medicine (Biostatistics). Carey is a senior member of the Bioconductor development core. He will improve interoperability to allow Bioconductor reuse of external modules in Java, Perl and other languages as well as strengthen interfaces between high throughput experimental workflows and machine learning tools, and ontology capture.  An administrative assistant will assist Dr. Carey with administrative requirements, including call coordination, manuscript preparation and distribution, scheduling and budget management.  Dr. Rafael Irizarry as co-PI will spend 30% effort on the project.  Dr. Irizarry has four years experience developing methods for microarray data analysis and in the Department of Biostatistics serving as faculty liaison to the Johns Hopkins Medical Institution's Microarray Core.  He will supervize all efforts to support preprocessing on all platforms and support for microarray related consortiums such as the ERCC, GEO, and ArrayExpress.      Programmers will be responsible for the project website, managing email lists, maintaining training materials, upgrading software, refactoring and other code enhancements, managing the svn archive, and Bioconductor releases. They will handle checking all submitted packages, developing unit tests, and simplifying downloads, nightly build procedures, cross-platform issues, data technologies as well as integrating resources found in other languages (e.g. large C libraries of routines for string handling, machine learning and so on). Programmers have familiarity with R packages and systems for database management and for parallel and distributed computing. They will be responsible for managing the annotation data including package building and liaising with organism specific and other data providers.      SIGNIFICANCE   Given the scope of the proposal, and the size of the Bioconductor project in general the request for the above resources is appropriate. There is an excellent mix of grounded project management along with development of newer state of the art techniques that will benifit many members of the bioinformatics community. There is a high probability that funding this project will help to maintain and advance this important community resource.      ENVIRONMENT   The computer infrastructure, and the local departments of the PI and Co-PIs, as well as the work with the larger scientific community are all excellent environments to support this project.      IN SUMMARY   This is a terrific resource.  It is a well managed large open source project with very well crafted QA testing, documentation and training.  Continuation of this is a three year project. Beyond that period, a statement of long term stated goals is needed. The PI should articulate the strategic goals, as well as their research motivation and translate that into an action plan. They should also use that context to describe how they would go about choosing packages that are put into the Bioconductor system; Table 3 only listed the names of the packages made by the applicants, it could have gone further to give the reader more information for choosing packages.  A simple example would have been if they stated in the document: ""Given our assessment of the microarray state of the art, we ultimately aim to overlay annotation data, ontological information, and other forms of meta data onto a statistical framework for expression data."" The resulting research plan would then justify a five year project, but it was not strong enough in this application.       It should be noted that many of the benificiaries to this system are not just users that download the system.  In many cases a centralized informatics service downloads their system and then performs analysis for other members of the campus or the wider www community. While that type of ""success measure"" is hard to assess, more effort in this area in subsequent proposals would be helpful.           n/a",Bioconductor: an open computing resource for genomics,7293650,P41HG004059,"['Address', 'Archives', 'Area', 'Arts', 'Award', 'Bioconductor', 'Bioinformatics', 'Biological', 'Biology', 'Biometry', 'Budgets', 'Building Codes', 'Class', 'Code', 'Communities', 'Complex', 'Computational Biology', 'Computer Simulation', 'Computer software', 'Computers', 'Computing Methodologies', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Data Sources', 'Data Storage and Retrieval', 'Database Management Systems', 'Dedications', 'Development', 'Discipline', 'Documentation', 'Educational process of instructing', 'Electronic Mail', 'Elements', 'Environment', 'Evolution', 'Experimental Designs', 'Faculty', 'Familiarity', 'FarGo', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Genomics', 'Goals', 'Grant', 'Head', 'Human Genome', 'Human Resources', 'Individual', 'Informatics', 'Institution', 'Internet', 'Investigation', 'Java', 'Knowledge', 'Language', 'Libraries', 'Machine Learning', 'Mails', 'Manuscripts', 'Measures', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Microarray Analysis', 'Motivation', 'Names', 'Nature', 'Numbers', 'Occupations', 'Ontology', 'Operative Surgical Procedures', 'Organism', 'Participant', 'Policies', 'Preparation', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Program Development', 'Programming Languages', 'Provider', 'Public Health Schools', 'Publications', 'Range', 'Reader', 'Request for Proposals', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resource Development', 'Resources', 'Role', 'Running', 'Schedule', 'Scientist', 'Sequence Alignment', 'Services', 'Software Design', 'Software Engineering', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Statistical Methods', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translating', 'Work', 'cluster computing', 'computing resources', 'cost', 'cost effective', 'data management', 'data structure', 'design', 'experience', 'falls', 'improved', 'innovation', 'interoperability', 'lectures', 'member', 'model development', 'open source', 'originality', 'professor', 'programs', 'quality assurance', 'research study', 'size', 'software development', 'success', 'symposium', 'tool', 'tool development', 'web-accessible']",NHGRI,FRED HUTCHINSON CAN RES CTR,P41,2007,796910,-0.00027839569859696475
"Neuroimaging Neuroinformatics Training Program    DESCRIPTION (provided by applicant): This proposal is in response to PAR-03-034 ""Neuroinformatics Institutional Mentored Research Scientist Development Award (K12)."" The overarching goal of this application is to provide an excellent postdoctoral training program in neuroimaging neuroinformatics that capitalizes on the many strengths of the existing neuroscientists, informatics and imaging resources that our combined resources represent. Our proposed Neuroimaging Neuroinformatics Training Program (NNTP) is based upon a number of important strategic alliances. The first cornerstone of this effort is the existing HBP grants held by Dr. Anders Dale (R01 NS39581: Cortical-Surface-Based Brain Imaging) and Dr. David Kennedy (R01 NS34189: Anatomic Morphologic Analysis of MR Brain Images). These efforts span a wealth of technological developments, research and clinical application areas in the rapidly developing area of quantitative morphometric image analysis. A second and vital cornerstone is our association with the Harvard-MIT Division of Health Sciences and Technology (HST) Biomedical Informatics Program. This existing pre- and post-graduate academic program, within a world class biomedical engineering department, is an ideal setting for the development of a coordinated training effort in Neuroinformatics. The established track record in training skilled scientists in areas of informatics will prove invaluable in this new initiative. The third cornerstone is the combined clinical research opportunities afforded by the Harvard-wide biomedical imaging resources. These include the MGH/MIT/HST Athinoula A. Martinos Center for Biomedical Imaging, the Harvard Neuroimaging Center, the Surgical Planning Lab at Brigham and Women's Hospital, the Brain Morphology BIRN (Biomedical Informatics Research Network) and the MIT Artificial Intelligence Laboratory. Together, these active and vibrant programs provide for the best possible training opportunities in imaging science, computer science, clinical application areas, and cognitive neuroscience. A substantial and successful pool of internationally renowned mentors have agreed to participate in this program, and the combined resources provide the best possible exposure to all neuroimaging procedures and insure the capability to draw the highest caliber trainees. A plan for recruiting, selecting and monitoring trainees is proposed. This program will be an asset to the Neuroinformatics initiatives of the Human Brain Project by helping to prepare future scientists with advanced neuroinformatics skills         n/a",Neuroimaging Neuroinformatics Training Program,7189144,K12MH069281,"['Anatomy', 'Area', 'Artificial Intelligence', 'Base of the Brain', 'Biomedical Engineering', 'Biomedical Informatics Research Network', 'Brain', 'Brain imaging', 'Caliber', 'Class', 'Clinical', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Development', 'Discipline', 'Educational Activities', 'Exposure to', 'Foundations', 'Functional disorder', 'Future', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Informatics', 'Laboratories', 'Mentored Research Scientist Development Award', 'Mentors', 'Methodology', 'Monitor', 'Neurosciences', 'Numbers', 'Operative Surgical Procedures', 'Physicians', 'Procedures', 'Program Development', 'Psyche structure', 'Range', 'Rate', 'Recruitment Activity', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'SECTM1 gene', 'Science', 'Scientist', 'Surface', 'Techniques', 'Technology', 'Training', 'Training Programs', 'Woman', 'base', 'bioimaging', 'biomedical informatics', 'brain morphology', 'career', 'cationic antimicrobial protein CAP 37', 'clinical application', 'cognitive neuroscience', 'computer science', 'imaging informatics', 'multidisciplinary', 'nervous system disorder', 'neuroimaging', 'neuroinformatics', 'post-doctoral training', 'programs', 'research and development', 'response', 'skills']",NIMH,MASSACHUSETTS GENERAL HOSP,K12,2007,450967,9.683510653424107e-05
"Interactive Learning Modules for Writing Grant Proposals DESCRIPTION (provided by applicant):  The overall objective of this application is to continue our challenge to empower faculty at institutions with high minority enrollment to develop and submit competitive research proposals. Building on our past experience, the competing renewal has three facets which will take place concurrently: 1) up-dating current modules (14) and the development, testing, and evaluation of two new internet course modules; 2) recruitment and training of participants through 5 workshops at remote sites and subsequent participation in the web-based course; 3) continuing evaluation of the training modules for the purpose of technological and content versions. Significant changes from the original program include moving the pre-course conference off-site to maximize the number of faculty participating from contiguous institutions and the introduction of machine language technology to aid in the editing and packaging of participants' grant writing efforts. At the conclusion of the initiative, each participant should be both motivated and empowered to submit a competitive proposal. Thus, our continuing partnership with NIGMS should improve the skills and abilities of researchers/grant writers at minority institutions, increase the number of minorities engaged in biomedical research, and strengthen minority institution's overall research environment. n/a",Interactive Learning Modules for Writing Grant Proposals,7252088,U13GM058252,"['Advisory Committees', 'Applications Grants', 'Biomedical Research', 'Computer Retrieval of Information on Scientific Projects Database', 'Computer software', 'Databases', 'Development', 'Educational workshop', 'Enrollment', 'Environment', 'Evaluation', 'Faculty', 'Feedback', 'Funding', 'Future', 'Goals', 'Grant', 'Grant Review Process', 'Institution', 'Internet', 'Language', 'Learning', 'Machine Learning', 'Mentors', 'Minority', 'National Institute of General Medical Sciences', 'Numbers', 'Online Systems', 'Participant', 'Peer Review', 'Progress Reports', 'Purpose', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Rest', 'Role', 'Scientist', 'Services', 'Site', 'Study Section', 'System', 'Technology', 'Time', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Work', 'Writing', 'base', 'evaluation/testing', 'experience', 'follow-up', 'impression', 'improved', 'member', 'novel strategies', 'programs', 'skills', 'symposium', 'training project']",NIGMS,UNIVERSITY OF KENTUCKY,U13,2007,276104,0.012082297239496529
"Visant-Predictome: A System for Integration, Mining Visualization and Analysis    DESCRIPTION (provided by applicant): Recent and continuing technological advances are producing large amounts of disparate data about cell structure, function and activity. This is driving the development of tools for storing, mining, analyzing, visualizing and integrating data. This proposal describes the VisANT system: a tool for visual data mining that operates on a local database which includes results from our lab, as well as automatically updated proteomics data from web accessible databases such as MIPS and BIND. In addition to accessing its own database, a name normalization table (i.e. a dictionary of identifiers), permits the system to seamlessly retrieve sequence, disease and other data from sources such as GenBank and OMIM. The visualization tool is able to reversibly group related sets of nodes, and display and duplicate their internal structure, providing an approach to hierarchical representation and modeling. We propose to build further on these unique features by including capabilities for mining and representing chemical reactions, orthologous networks, combinatorially regulated transcriptional networks, splice variants and functional hierarchies. Software is open source, and the system also allows users to exchange and integrate the networks that they discover with those of others.           n/a","Visant-Predictome: A System for Integration, Mining Visualization and Analysis",7287965,R01RR022971,"['Address', 'Archives', 'Automobile Driving', 'Bayesian Method', 'Binding', 'Binding Sites', 'Biological', 'Cell physiology', 'Cellular Structures', 'Chemicals', 'Communication', 'Communities', 'Complex', 'Computer Systems Development', 'Computer software', 'Condition', 'Data', 'Data Sources', 'Databases', 'Dependence', 'Dependency', 'Development', 'Dictionary', 'Disease', 'Educational workshop', 'Electronic Mail', 'Facility Construction Funding Category', 'Genbank', 'Genes', 'Goals', 'Imagery', 'Information Systems', 'Link', 'Machine Learning', 'Maintenance', 'Methods', 'Mining', 'Modeling', 'Names', 'Network-based', 'Numbers', 'Online Mendelian Inheritance In Man', 'Phylogenetic Analysis', 'Proteomics', 'RNA Splicing', 'Reaction', 'Reporting', 'Score', 'Software Tools', 'Source', 'Structure', 'System', 'Systems Integration', 'Techniques', 'Technology', 'Tertiary Protein Structure', 'Update', 'Ursidae Family', 'Variant', 'Visual', 'Weight', 'base', 'chemical reaction', 'data mining', 'improved', 'models and simulation', 'open source', 'outreach', 'protein protein interaction', 'software development', 'statistics', 'tool', 'tool development', 'web-accessible', 'wiki']",NCRR,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R01,2007,446875,-0.01902794185524723
"Integration and Visualization of Diverse Biological Data DESCRIPTION (provided by applicant): Currently a gap exists between the explosion of high-throughput data generation in molecular biology and the relatively slower growth of reliable functional information extracted from the data. This gap is largely due to the lack of specificity necessary for accurate gene function prediction in the currently available large-scale experimental technologies for rapid protein function assessment. Bioinformatics methods that integrate diverse data sources in their analysis achieve higher accuracy and thus alleviate this lack of specificity, but there's a paucity of generalizable, efficient, and accurate methods for data integration. In addition, no efficient methods exist to effectively display diverse genomic data, even though visualization has been very valuable for analysis of data from large scale technologies such as gene expression microarrays. The long-term goal of this proposal is to develop an accurate and generalizable bioinformatics framework for integrated analysis and visualization of heterogeneous biological data.      We propose to address the data integration problem with a Bayesian network approach and effective visualization methods. We have shown the efficacy of this method in a proof-of-principle system that increased the accuracy of gene function prediction for Saccharomyces cerevisiae compared to individual data sources. Building on our previous work, we present a two-part plan to improve and expand our system and to develop novel visualization methods for genomic data based on the scalable display technology. First, we will investigate the computational and theoretical issues behind accurate integration, analysis and effective visualization of heterogeneous high-throughput data. Then, leveraging our existing system and algorithmic improvements developed in the first part of the project, we will design and implement a full-scale data integration and function prediction system for Saccharomyces cerevisiae that will be incorporated with the Saccharomyces Genome Database (SGD), a model organism database for yeast.      The proposed system would provide highly accurate automatic function prediction that can accelerate genomic functional annotation through targeted experimental testing. Furthermore, our system will perform general integration and will offer researchers a unified view of the diverse high-throughput data through effective integration and visualization tools, thereby facilitating hypothesis generation and data analysis. Our scalable visualization methods will enable teams of researchers to examine biological data interactively and thus support the highly collaborative nature of genomic research. In addition to contributing to S. cerevisiae genomics, the technology for efficient and accurate heterogeneous data integration and visualization developed as a result of this proposal will form a basis for systems that address the same set of issues for other organisms, including the human. n/a",Integration and Visualization of Diverse Biological Data,7214148,R01GM071966,"['Address', 'Algorithms', 'Binding', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Collaborations', 'Communities', 'Compatible', 'Computer software', 'Consultations', 'Data', 'Data Analyses', 'Data Set', 'Data Sources', 'Databases', 'Depth', 'Development', 'Effectiveness', 'Evaluation', 'Expert Systems', 'Explosion', 'Gene Expression', 'Generations', 'Genes', 'Genome', 'Genomics', 'Goals', 'Grouping', 'Growth', 'Human', 'Human Genome', 'Imagery', 'Individual', 'Information Systems', 'Institutes', 'Investigation', 'Knock-out', 'Knowledge', 'Laboratories', 'Learning', 'Literature', 'Machine Learning', 'Magic', 'Methods', 'Molecular Biology', 'Monitor', 'Nature', 'Online Systems', 'Organism', 'Phenotype', 'Pliability', 'Probability', 'Process', 'Protein-Protein Interaction Map', 'Proteomics', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Scientist', 'Side', 'Source', 'Specificity', 'Staining method', 'Stains', 'Structure', 'System', 'Systems Biology', 'Technology', 'Test Result', 'Testing', 'Two-Hybrid System Techniques', 'Universities', 'Visualization software', 'Work', 'Yeasts', 'base', 'comparative', 'computer based statistical methods', 'concept', 'data integration', 'design', 'functional genomics', 'gene function', 'genome database', 'high throughput analysis', 'improved', 'model organisms databases', 'novel', 'parallel computing', 'programs', 'protein function', 'prototype', 'research study', 'software development', 'tandem mass spectrometry', 'tool', 'ultra high resolution', 'web interface']",NIGMS,PRINCETON UNIVERSITY,R01,2007,240927,-0.012639332862314704
"CENTER OF EXCELLENCE IN PUBLIC HEALTH INFORMATICS The University of Washington proposes to establish the Center of Excellence in Public Health Informatics: Improving the Public's Health through Information Integration. Partners include the Washington Department of Health, Kitsap County Health District, the Public Health Informatics Institute, and Inland Northwest Health Services. This Center will focus on three research topics: Project 1 (Surveillance Integration and Decision Support) will develop public health surveillance methodswithin the emerging health information infrastructure. We will: 1) develop methods by which regional health information organizations can enhance public health surveillance; 2) develop and evaluate a probabilistic decision support system classifier for disease surveillance; and 3) investigate the usability of a web survey-assessment system for population tracking and disease reporting. Project 2 (Customizable Knowledge Management Repository System for Prevention: Design, Development, and Evaluation) will develop an interactive digital knowledge management system to support the collection, management, and retrieval of public health documents, data,  earning objects, and tools. The focus will be the development of tools, including concept mapping services that will provide rapid access to answers from a variety of key resources, including the ""gray literature"". The system will focus on the application of natural language processing and information visualization techniques. Components will include a knowledge repository system, integrative web services and a role-based user  nterface to support access to information resources for enhanced decision-making by practitioners. The ong-term goal is to create an environment in which practitioners can pose questions in ""plain English"" and receive answers to their questions rather than simply a list of possible places to look for answers. Project 3  Supporting Integration: Work Process, Change Management and System Modeling) will: 1) refine and validate an integrated model of public health information technologywork; 2) provide a Change Management Toolkit to support public health agencies in making changes to current practice called for by the integrated model; and 3) build a Virtual Public Health Information Technology Environment to serve as a testbed and to explore informatics challenges. These projects are supported by three cores: Administration Core (Core A), Epidemiology and Biostatistics Science Core (Core B), and Technology and Design Science Core (Core C). n/a",CENTER OF EXCELLENCE IN PUBLIC HEALTH INFORMATICS,7284424,P01HK000027,[' '],ODCDC,UNIVERSITY OF WASHINGTON,P01,2007,1889501,-0.0008623821844570437
"Informatics Core for the Collaborative Initiative on Fetal Alcohol Spectrum disor    DESCRIPTION (provided by applicant): The Informatics Core is part of the Consortium for the ""Collaborative Initiative on Fetal Alcohol Spectrum Disorders"" (CIFASD). The theme of this collaborative initiative is a cross-cultural assessment of ""fetal alcohol spectrum disorder"" (FASD). The CIFASD will coordinate basic, behavioral, and clinical investigators in a multidisciplinary research project to better inform approaches aimed at developing effective intervention and treatment approaches for FASD. It will involve the input and contributions from basic researchers, behavioral scientists, and clinical investigators with the willingness to utilize novel and cutting-edge techniques so as not to simply replicate previous or ongoing work, but rather to try and move it forward in a rigorous fashion. The Informatics Core will develop and maintain the CIFASD Data Repository, which will be used to collect, maintain and distribute data generated by the various participants in the consortium. The Informatics Core will be responsible for working with the other consortium participants to define a Data Dictionary to be used in standardizing data collection, enabling the transfer of data to and from the CIFASD Data Repository, consulting on how to establish local data management systems, providing both software tools and consulting to consortium participants, and producing status reports about the progress of the various projects within the consortium. The Informatics Core draws on a wealth of resources, experience, and expertise at Indiana University in information technology infrastructure and data management, The CIFASD Data Repository will be developed on Indiana University's state-of-the-art central supercomputing facilities, taking advantage of Indiana University's strong commitment to institutional computational resources. Resources that will be used to implement the CIFASD Data Repository include multiple supercomputers, an array of readily available database and statistical software, and a high- speed, secure, robust data archiving system capable of storing duplicate copies in multiple physical locations separated by more than fifty miles. The Informatics Core will use these extraordinary computational resources to provide a single, highly secure location for consortium participants to obtain the cross-cultural data that will enable the CIFASD to meet its goals of developing novel techniques for intervention and treatment of FASD.           n/a",Informatics Core for the Collaborative Initiative on Fetal Alcohol Spectrum disor,7343355,U24AA014818,"['Address', 'Adolescent', 'Affect', 'Africa', 'Alcohol consumption', 'Alcohol-Related Neurodevelopmental Disorder', 'Alcohols', 'Animal Model', 'Animals', 'Archives', 'Arts', 'Basic Science', 'Behavioral', 'Binding Sites', 'Biology', 'Brain', 'Brain imaging', 'Cells', 'Characteristics', 'Child', 'Choline', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Collaborations', 'Computer software', 'Condition', 'Consult', 'Data', 'Data Analyses', 'Data Collection', 'Data Storage and Retrieval', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Dictionary', 'Dietary Intervention', 'Drug Design', 'Dysmorphology', 'Early Diagnosis', 'Early Intervention', 'Elements', 'Emotional', 'Ethanol', 'Ethnic group', 'Face', 'Fetal Alcohol Exposure', 'Fetal Alcohol Spectrum Disorder', 'Fetal Alcohol Syndrome', 'Frequencies', 'Future', 'Genetic Polymorphism', 'Goals', 'Human', 'Image', 'Image Analysis', 'Indiana', 'Individual', 'Infant', 'Infant Development', 'Informal Social Control', 'Informatics', 'Information Storage', 'Information Technology', 'Interdisciplinary Study', 'Internet', 'Intervention', 'Knowledge', 'Label', 'Language', 'Language Development', 'Life', 'Location', 'Los Angeles', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Methods', 'Mission', 'Modeling', 'Moscow', 'Mothers', 'Mus', 'Names', 'Neonatal', 'Neural Cell Adhesion Molecule L1', 'Neurobiology', 'New Mexico', 'Outcome', 'Participant', 'Pattern', 'Performance', 'Phenotype', 'Pilot Projects', 'Play', 'Population', 'Pregnancy', 'Principal Investigator', 'Range', 'Rattus', 'Recording of previous events', 'Reporting', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Schools', 'Scientist', 'Secure', 'Sensitivity and Specificity', 'Sheep', 'Signal Pathway', 'Signal Transduction', 'Site', 'Software Tools', 'Specificity', 'Speed', 'Structure', 'Sum', 'Supercomputing', 'Supplementation', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Toddler', 'Ukraine', 'Ultrasonography', 'Universities', 'Woman', 'Work', 'alcohol exposure', 'alcohol sensitivity', 'analog', 'brain behavior', 'brain morphology', 'cognitive control', 'critical developmental period', 'data integration', 'data management', 'distributed data', 'drinking', 'experience', 'fetal', 'follow-up', 'improved', 'in utero', 'infancy', 'literacy', 'mouse model', 'multidisciplinary', 'neurobehavioral', 'northern plains', 'novel', 'prenatal', 'programs', 'prospective', 'quality assurance', 'reconstruction', 'repository', 'social', 'supercomputer', 'three dimensional structure', 'transmission process', 'willingness']",NIAAA,INDIANA UNIVERSITY BLOOMINGTON,U24,2007,178873,-0.031595395854301905
"National Center: Multi-Scale Study of Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",National Center: Multi-Scale Study of Cellular Networks(RMI),7286779,U54CA121852,[' '],NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2007,3638557,-0.0545935827789462
"MUSC Minority Student Development Program    DESCRIPTION (provided by applicant):  The goals of this program are to: 1) increase the number of underrepresented minority (URM) students choosing a research career in the biomedical sciences, 2) enhance the quantity and quality of URM students enrolled in the doctoral program in the College of Graduate Studies, 3) prepare them for a successful career in biomedical sciences, 4) provide structured activities that enhance the interaction of minority and majority students and 5) increase the number of URMs in the Summer Undergraduate Research Program (SURP). To accomplish these goals a Minority Recruitment Committee will be developed to assist in recruiting URMs. An MUSC ""Science Day"" will be implemented to expose minority students to the excitement of biomedical science research. Undergraduate science advisors will nominate potential URM Ph.D. applicants who will attend ""Science Day"" with a parent and the advisor. The SURP will be expanded by five students, designated as E.E. Just Scholars. These SURP participants will interact with minority graduate students via a Big Brother/Sister program. A summer pre-matriculation course to review basic biochemical and molecular concepts will be available for all new students. All students will participate in a ""Diversity in Science"" course that will foster the interaction of minority and majority students that focuses on issues related to minorities in biomedical science. URM graduate students will serve as Graduate Student Ambassadors to HBCUs and present seminars to undergraduates. Funds will be provided for URM graduate students to present their research at a national meeting. A Mentoring Committee will be developed to 1) monitor and advise URM doctoral students through the graduate training program, 2) assist with career development and 3) organize the content of the ""Diversity in Science"" course as well as career workshops. Internal and External Advisory Committees will provide oversight for the program. These programmatic elements will increase the number of minority students participating in biomedical science research and prepare them for a successful career.         n/a",MUSC Minority Student Development Program,7188026,R25GM072643,"['5-(4-hydroxy-3-methoxyphenyl)-5-phenylhydantoin', 'Academia', 'Accounting', 'Achievement', 'Address', 'Admission activity', 'Advisory Committees', 'Affect', 'African American', 'Aging', 'Agonist', 'Alcohols', 'Alzheimer&apos', 's Disease', 'Amino Acids', 'Animals', 'Appendix', 'Applied Research', 'Area', 'Award', 'Back', 'Bacteriorhodopsins', 'Baltimore', 'Belief', 'Biochemical', 'Biochemistry', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Blood Vessels', 'Bradykinin', 'Brain', 'Brothers', 'Budgets', 'Businesses', 'CXCL1 gene', 'Calcium', 'Cancer Biology', 'Cancer Center', 'Cancer Education Grant Program', 'Cardiac', 'Cardiovascular Physiology', 'Cardiovascular system', 'Cell physiology', 'Cells', 'Cellular Structures', 'Cellular biology', 'Ceramides', 'Cessation of life', 'Chemicals', 'Chemistry', 'Chicago', 'Cities', 'Class', 'Classification', 'Cocaine', 'Collaborations', 'Commit', 'Committee Members', 'Communities', 'Complex', 'Contracts', 'Counseling', 'County', 'Cyclic AMP', 'Data', 'Daughter', 'Decision Making', 'Development', 'Development Plans', 'Disease', 'Doctor of Philosophy', 'Doctor of Public Health', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Endotoxins', 'Enrollment', 'Ensure', 'Environment', 'Enzymatic Biochemistry', 'Enzymes', 'Equilibrium', 'Evaluation', 'Event', 'Exhibits', 'Explosion', 'Exposure to', 'Extramural Activities', 'Faculty', 'Failure', 'Fatty Acids', 'Fees', 'Fellowship', 'Flax', 'Florida', 'Fostering', 'Foundations', 'Friends', 'Friendships', 'Funding', 'Funding Mechanisms', 'Future', 'G-Protein-Coupled Receptors', 'GTP-Binding Proteins', 'Genes', 'Genetic', 'Genetic Programming', 'Genetic Transcription', 'Geographic Locations', 'Goals', 'Graduate Education', 'Grant', 'Health Occupations', 'Health Professional', 'Health Services Research', 'Heart Hypertrophy', 'Heroin', 'Historically Black Colleges and Universities', 'Home Page', 'Home environment', 'Hour', 'Human', 'Hypoxia', 'Indiana', 'Individual', 'Industry', 'Information Resources', 'Institutes', 'Institution', 'Insulin Resistance', 'Insulin-Like Growth Factor Receptor', 'Insulin-Like Growth-Factor-Binding Proteins', 'Intellectual Property', 'Internal Medicine', 'International', 'Internet', 'Interview', 'Investigation', 'Journals', 'Laboratories', 'Laboratory Research', 'Lead', 'Leadership', 'Learning', 'Legal patent', 'Letters', 'Life', 'Ligands', 'Lipid Biochemistry', 'Lipids', 'Machine Learning', 'Mails', 'Malignant Neoplasms', 'Marines', 'Maryland', 'Mass Spectrum Analysis', 'Mediating', 'Medical', 'Medical center', 'Meiosis', 'Membrane', 'Membrane Transport Proteins', 'Mentors', 'Metabolism', 'Methods', 'Microfluidics', 'Minority', 'Mission', 'Mitosis', 'Modality', 'Modems', 'Modification', 'Molecular', 'Molecular and Cellular Biology', 'Monitor', 'Multiple Sclerosis', 'Myelin', 'NMR Spectroscopy', 'National Cancer Institute', 'National Institute of General Medical Sciences', 'Natural regeneration', 'Nervous system structure', 'Neurobiology', 'Neurodegenerative Disorders', 'Neuronal Plasticity', 'Neurosciences', 'Neurosciences Research', 'Newsletter', 'Nucleic Acids', 'Numbers', 'Occupations', 'Oral', 'Organic Chemistry', 'Other Minority', 'Outcome', 'Oxygen', 'Parents', 'Parkinson Disease', 'Participant', 'Pathologic', 'Pathway Analysis', 'Pathway interactions', 'Pediatrics', 'Pennsylvania', 'Performance', 'Pharmacologic Substance', 'Pharmacology', 'Phase', 'Phospholipids', 'Phosphotransferases', 'Physics', 'Play', 'Policies', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Program Development', 'Progress Reports', 'Proteins', 'Proteomics', 'Published Comment', 'Purpose', 'Qualifying', 'Range', 'Recommendation', 'Recording of previous events', 'Recruitment Activity', 'Regulation', 'Reporting', 'Research', 'Research Ethics', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Residencies', 'Resolution', 'Resources', 'Restaurants', 'Rhodopsin', 'Role', 'Rotation', 'Schedule', 'Scholarship', 'Schools', 'Science', 'Scientist', 'Score', 'Series', 'Serotonin', 'Services', 'Shock', 'Signal Pathway', 'Signal Transduction', 'Sister', 'Site', 'Site Visit', 'Solid', 'Son', 'South Carolina', 'Sphingolipids', 'Staging', 'Stem cells', 'Strategic Planning', 'Stress', 'Structure', 'Structure-Activity Relationship', 'Students', 'Surveys', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Telephone', 'Testing', 'Text', 'Therapeutic', 'Thinking', 'Thromboxane A2', 'Time', 'Toxicology', 'Training', 'Training Programs', 'Translational Research', 'Translations', 'Transportation', 'Travel', 'Underrepresented Minority', 'United States', 'United States National Institutes of Health', 'Universities', 'Vision', 'Visit', 'Vocational Guidance', 'Week', 'Wolves', 'Work', 'Writing', 'X-Ray Crystallography', 'addiction', 'aging brain', 'angiogenesis', 'anticancer research', 'base', 'body system', 'brain behavior', 'cancer therapy', 'career', 'cell growth', 'cell injury', 'cell motility', 'chemical bond', 'college', 'complement C2a', 'concept', 'cooking', 'cost', 'day', 'design', 'drug of abuse', 'expectation', 'experience', 'falls', 'fascinate', 'follow-up', 'frontier', 'gamma-Aminobutyric Acid', 'gene function', 'genome sequencing', 'high school', 'improved', 'innovation', 'insight', 'instructor', 'interest', 'journal article', 'lectures', 'lipid metabolism', 'member', 'minority health', 'myelination', 'nervous system disorder', 'novel', 'novel strategies', 'numb protein', 'patient oriented', 'posters', 'pre-clinical', 'professor', 'programs', 'protein protein interaction', 'protein structure function', 'receptor', 'receptor coupling', 'research facility', 'response', 'role model', 'science education', 'skills', 'social', 'soft drink', 'structural biology', 'success', 'symposium', 'technology development', 'theories', 'tool', 'transmission process', 'tumorigenesis', 'two-dimensional', 'tyrosine receptor', 'university student']",NIGMS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,R25,2007,217360,0.036079643068903565
"MBRS IMSD Program at the University of Kansas    DESCRIPTION (provided by applicant):  Within the three short years since the University of Kansas (KU) IMSD program began, twelve minority students, including six American Indians, will have applied to graduate school. This is a continuation proposal to allow us to build on these successes. KU IMSD works in concert with other NIH funded programs (Bridge, RISE, IRACDA) and takes full advantage of the juxtaposition of a Research I Institution (KU) and one of the largest tribal colleges (Haskell Indian Nations University). KU IMSD consists of four components: 1) providing research experiences to American Indian and other minority students, with a particular a focus on recruiting Haskell students from the Bridge or RISE program; 2) enhancing and modifying the curriculum; 3) offering an interdisciplinary seminar series and 4) providing financial aid and mentoring. The undergraduate research experience takes a broad, interdisciplinary approach to placing students into one of 77 possible KU labs and includes opportunities for students to share their research results at local and national meetings. The program will also support several American Indian graduate students who have obtained BA's from Haskell. IMSD supported curricular enhancements that have shown remarkable results over the past three years will be continued for gatekeeper courses in biology, chemistry and math. In biology alone, the average grade point average of American Indian students who completed the introductory biology course has increased from 0.86 to 2.94 over the past six years. An integrative seminar series will bring together students from the IMSD, Bridge, and RISE programs to foster community and learning. Support from KU IMSD for undergraduate researchers will be a cornerstone in providing financial support along with KU scholarships targeted for American Indian students. Mentoring will be provided from faculty (research advisors), the IMSD Program Coordinator (individual and group meetings) and peers (other IMSD students). Evaluation and tracking procedures will allow for regular adjustment of activities during the course of the program and assessment of whether goals have been met. If funded for another four years, the KU/Haskell collaboration provides the opportunity to significantly impact the number of American Indian scientists in this country.         n/a",MBRS IMSD Program at the University of Kansas,7209749,R25GM062232,"['Address', 'Administrative Personnel', 'Administrator', 'Adopted', 'Advertising', 'Alaska', 'Algorithms', 'American Indians', 'Appendix', 'Area', 'Arrhythmia', 'Artificial Intelligence', 'Arts', 'Attention', 'Authorization documentation', 'Behavior', 'Behavioral Sciences', 'Biodiversity', 'Biogenesis', 'Bioinformatics', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Books', 'Bovine Spongiform Encephalopathy', 'Budgets', 'Calculi', 'Cells', 'Chaos Theory', 'Characteristics', 'Charge', 'Chemistry', 'Cities', 'Class', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer software', 'Computers', 'Conservatism', 'Country', 'Coupled', 'DNA', 'DNA Structure', 'Daily', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Depth', 'Development', 'Discipline', 'Disease', 'Distant', 'Doctor of Philosophy', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Elements', 'Engineering', 'Enrollment', 'Environment', 'Equilibrium', 'Ethics', 'Evaluation', 'Event', 'Exercise', 'Exposure to', 'Faculty', 'Family', 'Feedback', 'Feeling', 'Fees', 'Film', 'Financial Support', 'Fostering', 'Foundations', 'Friends', 'Funding', 'Future', 'GYPA gene', 'Gatekeeping', 'Gene Structure', 'Genes', 'Genetic', 'Genetic Programming', 'Geographic Information Systems', 'Glycophorin A', 'Goals', 'Grant', 'Graph', 'Group Meetings', 'Growth', 'Habits', 'Hand', 'Health', 'Health Sciences', 'Heart', 'Helix (Snails)', 'Home environment', 'Hour', 'Housing', 'Human', 'Human Resources', 'Humanities', 'Indigenous', 'Individual', 'Informatics', 'Information Systems', 'Institutes', 'Institution', 'Internet', 'Internships', 'Invasive', 'Journals', 'Judgment', 'Kansas', 'Knowledge', 'Laboratories', 'Language', 'Lead', 'Learning', 'Letters', 'Life', 'Light', 'Link', 'Literature', 'Malignant Neoplasms', 'Mathematics', 'Medical', 'Medical center', 'Medicine', 'Mentors', 'Methods', 'Minority', 'Minority Groups', 'Modeling', 'Modems', 'Modification', 'Molecular Biology', 'Molecular and Cellular Biology', 'Monitor', 'Motivation', 'Museums', 'Music', 'Mutation', 'National Institute of General Medical Sciences', 'Natural History', 'Newsletter', 'Numbers', 'Oklahoma', 'Oral', 'Oral cavity', 'Organic Chemistry', 'Other Minority', 'Outcome', 'Pamphlets', 'Paper', 'Parents', 'Participant', 'Performance', 'Personality', 'Pharmaceutical Chemistry', 'Placement', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Poverty', 'Preparation', 'Principal Investigator', 'Problem Solving', 'Procedures', 'Process', 'Productivity', 'Program Development', 'Progress Reports', 'Proteins', 'Published Comment', 'Purpose', 'Qualifying', 'Quantum Mechanics', 'RNA', 'Race', 'Radio', 'Range', 'Reading', 'Recommendation', 'Records', 'Recruitment Activity', 'Regulation', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Review Committee', 'Rewards', 'Schedule', 'Scholarship', 'Schools', 'Science', 'Scientist', 'Selection Criteria', 'Series', 'Services', 'Shock', 'Site', 'Slide', 'Snow', 'Social Functioning', 'Source', 'Sports', 'Standards of Weights and Measures', 'Students', 'Supervision', 'Support Groups', 'Surveys', 'Techniques', 'Technology', 'Text', 'Textbooks', 'Thinking', 'Time', 'Time Management', 'Today', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Update', 'Ursidae Family', 'Visit', 'Visualization software', 'Wages', 'Week', 'Work', 'Writing', 'abstracting', 'aging nutrition', 'analytical method', 'base', 'biomedical scientist', 'career', 'cohort', 'college', 'computer generated', 'computer science', 'concept', 'cost', 'court', 'data acquisition', 'day', 'digital', 'ear helix', 'expectation', 'experience', 'falls', 'follow-up', 'gene therapy', 'high school', 'i(19)', 'image visualization', 'improved', 'instructor', 'interdisciplinary approach', 'interest', 'lectures', 'member', 'novel', 'peer', 'posters', 'preference', 'professor', 'programs', 'protein structure', 'role model', 'satisfaction', 'size', 'skills', 'success', 'symposium', 'theories', 'tool', 'tribal college']",NIGMS,UNIVERSITY OF KANSAS LAWRENCE,R25,2007,430160,0.03807424098289514
"REU in Functional Genomics and Cell Biology DESCRIPTION (provided by applicant):  We propose to establish a summer program for undergraduates with non-biological sciences backgrounds that will provide cross-discipline training and experiences in combining the physical sciences backgrounds of the participants with concepts and approaches of functional genomics and cell biology to address biomedical research problems. The intended impact of our program is to encourage participating students to pursue graduate education in biomedical sciences, followed by careers in biomedical research.       Six students will be selected each year to pursue 10-week research experiences in one of eleven laboratories at the University of Cincinnati College of Medicine and Cincinnati Children's Hospital Medical Center. Instruction in functional genomics and cell biology will be provided through workshops and a series of seminars. Students will work as a group on a cross-discipline case study in wound-healing. In addition, students will receive instruction in research ethics, scientific writing, and career opportunities in biomedical sciences. At the conclusion of the summer, students will present their work at a poster session and receive evaluations. Students will be encouraged to publish their results in the Journal of the Ohio Association of Science.  To build community among these students, they will participate in a series of social and cultural events.   Formative evaluations will be used to alter and fine-tune the Program, and summative evaluations will be carried out at the conclusion of each summer and again, as the participants graduate from their undergraduate institutions, to measure the long-term impact of the Program on the participating students. n/a",REU in Functional Genomics and Cell Biology,7226706,R25GM072834,"['Academia', 'Academy', 'Accounting', 'Address', 'Adenocarcinoma Cell', 'Adhesions', 'Adhesives', 'Admission activity', 'Affect', 'African American', 'Aging', 'Algorithms', 'Androgens', 'Animals', 'Apoptosis', 'Area', 'Association of American Medical Colleges', 'Attitude', 'Authorship', 'Autoimmunity', 'Award', 'Back', 'Base Sequence', 'Basic Science', 'Belief', 'Biohazardous Substance', 'Bioinformatics', 'Biological', 'Biological Models', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Engineering', 'Biomedical Research', 'Bioterrorism', 'CCL7 gene', 'California', 'Camptothecin', 'Canada', 'Cardiac Myocytes', 'Career Choice', 'Case Study', 'Cell Adhesion', 'Cell Count', 'Cell Cycle', 'Cell Cycle Progression', 'Cell Death', 'Cell Line', 'Cell Polarity', 'Cell Proliferation', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular biology', 'Cessation of life', 'Chicago', 'Childhood', 'Cities', 'Class', 'Collagen', 'Color', 'Commit', 'Communication', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Computers', 'Computing Methodologies', 'Confocal Microscopy', 'Conserved Sequence', 'Consult', 'Contact Info', 'Country', 'Cues', 'Cyclin D1', 'Cytoplasm', 'DNA', 'DNA Damage', 'DNA Fingerprinting', 'DNA Fragmentation', 'DNA biosynthesis', 'DNA-Protein Interaction', 'Data', 'Data Sources', 'Decompression Sickness', 'Dependence', 'Development', 'Developmental Biology', 'Discipline', 'Discipline of obstetrics', 'Disease', 'District of Columbia', 'Doctor of Philosophy', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Educational workshop', 'Effectiveness', 'Electronic Mail', 'Electronics', 'Elements', 'Embryonic Development', 'Engineering', 'Enrollment', 'Environment', 'Environmental Health', 'Epidemiology', 'Epithelial Cells', 'Ethical Issues', 'Ethics', 'Evaluation', 'Event', 'Evolution', 'Exhibits', 'Extracellular Matrix', 'Extracellular Matrix Proteins', 'Eye', 'Eye Color', 'Faculty', 'Family', 'Fees', 'Fluorescence Microscopy', 'Forensic Medicine', 'Foxes', 'Fraud', 'Freedom', 'Functional RNA', 'Funding', 'Future', 'G1 Phase', 'Gel', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Transcription', 'Genetic Variation', 'Genome', 'Genomics', 'Germ Cells', 'Goals', 'Government', 'Graduate Education', 'Graph', 'Growth', 'Growth Factor', 'Guidelines', 'Guilt', 'Gynecology', 'Hand', 'Head', 'Healed', 'Heart', 'Historically Black Colleges and Universities', 'Holidays', 'Home environment', 'Homeostasis', 'Hour', 'Housing', 'Human', 'Image', 'Image Analysis', 'Implant', 'In Vitro', 'Indium', 'Individual', 'Informatics', 'Injury', 'Injury to Kidney', 'Institute of Medicine (U.S.)', 'Institution', 'Instruction', 'Integrins', 'Interdisciplinary Study', 'Internet', 'Interview', 'Investigation', 'Ireland', 'Jordan', 'Journals', 'Kentucky', 'Kidney', 'Knock-out', 'Knowledge', 'Label', 'Laboratories', 'Laboratory Research', 'Laminin', 'Lead', 'Learning', 'Letters', 'Life', 'Life Cycle Stages', 'Localized', 'Logistics', 'Lung', 'MDCK cell', 'Machine Learning', 'Mails', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Mammalian Cell', 'Manuscripts', 'Measures', 'Mechanics', 'Mediating', 'Medical center', 'Medicine', 'Meniscus structure of joint', 'Mentors', 'Mesenchymal Stem Cells', 'Methodology', 'Methods', 'Microscopy', 'Minority', 'Minority Groups', 'Mitochondria', 'Mitochondrial DNA', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Movement', 'Mus', 'Muscle Cells', 'Muscle Fibers', 'Music', 'Myosin Light Chain Kinase', 'Natural regeneration', 'Nature', 'Nerve Degeneration', 'Neurobiology', 'Neurons', 'Newborn Respiratory Distress Syndrome', 'Norovirus', 'Nuclear', 'Nucleic Acid Regulatory Sequences', 'Nucleic Acids', 'Numbers', 'Object Attachment', 'Ohio', 'Online Systems', 'Operative Surgical Procedures', 'Organism', 'Orthologous Gene', 'Ownership', 'Pamphlets', 'Participant', 'Pathogenesis', 'Pathologic', 'Pattern Recognition', 'Pediatric Hospitals', 'Performance', 'Personal Satisfaction', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Philosophy', 'Phosphorylation', 'Plagiarism', 'Play', 'Pneumocystis', 'Pneumocystis carinii', 'Population', 'Population Theory', 'Post-Translational Protein Processing', 'Postdoctoral Fellow', 'Predisposition', 'Premature Infant', 'Preparation', 'Printing', 'Prize', 'Procedures', 'Process', 'Program Evaluation', 'Prostate Adenocarcinoma', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Public Sector', 'Publications', 'Published Comment', 'Publishing', 'Pulmonary Surfactant-Associated Protein A', 'RNA Polymerase II', 'RNA Splicing', 'Race Relations', 'Radiation', 'Radioactive', 'Radioactivity', 'Railroads', 'Range', 'Rate', 'Rattus', 'Reading', 'Reagent', 'Recommendation', 'Records', 'Recruitment Activity', 'Regulation', 'Regulatory Element', 'Relative (related person)', 'Relaxation', 'Research', 'Research Activity', 'Research Ethics', 'Research Personnel', 'Research Project Grants', 'Resistance', 'Resources', 'Rewards', 'Rights', 'Risk', 'Role', 'Running', 'Safety', 'Schedule', 'Scholarship', 'Schools', 'Science', 'Scientist', 'Self Assessment', 'Series', 'Services', 'Side', 'Signal Pathway', 'Signal Transduction', 'Signal Transduction Pathway', 'Site', 'Skeletal Muscle', 'Software Tools', 'Standards of Weights and Measures', 'Stimulus', 'Stress', 'Structure', 'Students', 'Suggestion', 'Surveys', 'Susceptibility Gene', 'System', 'T-Lymphocyte', 'Techniques', 'Technology', 'Telephone', 'Tendon structure', 'Tennessee', 'Testing', 'Therapeutic', 'Time', 'Tissue Engineering', 'Tissues', 'Topoisomerase-I Inhibitor', 'Touch sensation', 'Training', 'Training Activity', 'Training Programs', 'Transcript', 'Transgenic Organisms', 'Transplantation', 'Travel', 'Tubular formation', 'Tumor Suppressor Proteins', 'Underrepresented Minority', 'United States National Academy of Sciences', 'United States National Institutes of Health', 'Universities', 'Update', 'Variant', 'Viral Proteins', 'Visit', 'Week', 'Wisconsin', 'Work', 'Wound Healing', 'Writing', 'Yugoslavia', 'abstracting', 'achilles tendon', 'adult stem cell', 'austin', 'base', 'biological adaptation to stress', 'biological research', 'career', 'cell growth', 'college', 'concept', 'cost', 'day', 'dentate gyrus', 'design', 'endonuclease', 'endonuclease G', 'expectation', 'experience', 'follow-up', 'functional genomics', 'handbook', 'healing', 'high school', 'human disease', 'human subject', 'improved', 'in vivo', 'indexing', 'information gathering', 'insight', 'instructor', 'interdisciplinary approach', 'interest', 'lectures', 'lung development', 'member', 'metaplastic cell transformation', 'morris water maze', 'new technology', 'news', 'notch protein', 'novel', 'novel strategies', 'object recognition', 'physical science', 'population migration', 'posters', 'preconditioning', 'prevent', 'professor', 'programs', 'protein folding', 'protein protein interaction', 'protein structure', 'protein structure function', 'renal artery', 'repaired', 'research and development', 'research study', 'response', 'retinoblastoma tumor suppressor', 'rhoA GTP-Binding Protein', 'role model', 'satisfaction', 'science education', 'simulation', 'skills', 'social', 'stem cell therapy', 'success', 'surfactant', 'symposium', 'teacher', 'theories', 'tissue processing', 'tool', 'transcription factor', 'transmission process']",NIGMS,UNIVERSITY OF CINCINNATI,R25,2007,66454,0.03059010627773542
"AMAUTA HEALTH INFORMATICS RESEARCH AND TRAINING PROGRAM DESCRIPTION (provided by applicant):     The proposed training program in Informatics for Global Health will consist of several activities carried out over a five year period 1) two short courses for 30-50 participants in basic informatics to be held in Peru 2) short term skills based training in informatics in Seattle with emphasis on genomics and resource access skills building 3) long term training in Informatics at the post doctoral or Masters of Science level through the Biomedical and Health Informatics program at the School of Medicine. Six scholars will be trained in addition to the short course participants. Four scholars now engaged in research will receive focused, skills building technical training and six scholars will be recruited and enrolled for longer term (2-3 year) post doctoral or Masters of Science training at the University of Washington. It is envisioned that this training program will foster the development of the capacity of UPCH to continue its role as a leading biomedical research institution and also to create a home to health informatics research activity in Peru. n/a",AMAUTA HEALTH INFORMATICS RESEARCH AND TRAINING PROGRAM,7249492,D43TW007551,"['1 year old', 'AIDS prevention', 'AIDS/HIV problem', 'Academic Detailing', 'Academic Medical Centers', 'Achievement', 'Acquired Immunodeficiency Syndrome', 'Acyclovir', 'Address', 'Admission activity', 'Adopted', 'Adult', 'Advisory Committees', 'Aeromonas', 'Affect', 'Age', 'Age Reporting', 'Agreement', 'AlamarBlue', 'Algorithms', 'Alleles', 'Am 80', 'Amauta', 'American', 'Americas', 'Amino Acid Sequence', 'Aminoglycosides', 'Anal Sex', 'Anogenital venereal warts', 'Anti-Retroviral Agents', 'Antibiotic susceptibility', 'Antigens', 'Antimicrobial susceptibility', 'Antitubercular Agents', 'Appendix', 'Appointment', 'Area', 'Artificial Intelligence', 'Arts', 'Asia', 'Aspirate substance', 'Australia', 'Automation', 'Award', 'Bacillus (bacterium)', 'Back', 'Bacteria', 'Bacterial Infections', 'Bacterial Vaginosis', 'Baseline Surveys', 'Basic Science', 'Behavior', 'Behavior Control', 'Behavior Therapy', 'Behavioral Research', 'Biochemical', 'Bioinformatics', 'Biological', 'Biological Assay', 'Biology', 'Biomedical Engineering', 'Biomedical Research', 'Biometry', 'Biotechnology', 'Bioterrorism', 'Birth', 'Bisexual', 'Blinded', 'Blood Tests', 'Bolivia', 'Books', 'Businesses', 'CD4 Lymphocyte Count', 'Calmette-Guerin Bacillus', 'Campylobacter', 'Canada', 'Candida', 'Caring', 'Case-Control Studies', 'Cataloging', 'Catalogs', 'Categories', 'Cause of Death', 'Cell physiology', 'Cells', 'Centers for Disease Control and Prevention (U.S.)', 'Certification', 'Cervical', 'Characteristics', 'Chest', 'Child', 'Child health care', 'Childhood', 'Chlamydia', 'Chlamydia Infections', 'Chromosome Mapping', 'Chronic', 'Ciprofloxacin', 'Cities', 'Class', 'Classification', 'Client', 'Climate', 'Clinic', 'Clinical', 'Clinical Informatics', 'Clinical Medicine', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Clinical trial protocol document', 'Code', 'Cohort Studies', 'Collaborations', 'Collection', 'Color', 'Commit', 'Committee Membership', 'Communicable Diseases', 'Communication', 'Communities', 'Community Medicine', 'Competence', 'Complex', 'Computer Assisted', 'Computer software', 'Computerized Medical Record', 'Computers', 'Congenital Syphilis', 'Consultations', 'Contact Tracing', 'Costa Rica', 'Coughing', 'Counseling', 'Country', 'County', 'Coupled', 'Critiques', 'Cross-Sectional Studies', 'Cryptosporidium', 'DNA', 'DNA Microarray Chip', 'DNA Microarray format', 'DNA amplification', 'Daily', 'Data', 'Data Collection', 'Data Sources', 'Databases', 'Decision Analysis', 'Decision Making', 'Decision Support Systems', 'Dental Schools', 'Depth', 'Detection', 'Developed Countries', 'Developing Countries', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Diagnostic tests', 'Diarrhea', 'Dimensions', 'Discipline', 'Discipline of Nursing', 'Disease', 'Disease remission', 'Distance Education', 'Distance Learning', 'Doctor of Philosophy', 'Dose', 'Drug Formulations', 'Drug usage', 'Early Diagnosis', 'Ecology', 'Economics', 'Education', 'Educational Curriculum', 'Educational Intervention', 'Educational Status', 'Educational process of instructing', 'Effectiveness', 'Electronic Mail', 'Electronics', 'Elements', 'Emergency Situation', 'Engineering', 'English Language', 'Enrollment', 'Ensure', 'Environment', 'Environmental Health', 'Epidemiologist', 'Epidemiology', 'Ethambutol', 'Ethics', 'Etiology', 'Evaluation', 'Event', 'Evolution', 'Expert Systems', 'Exposure to', 'Face', 'Faculty', 'Familiarity', 'Family', 'Feedback', 'Fellowship', 'Fellowship Program', 'Female', 'Female Condoms', 'Fertility Rates', 'Fever', 'Figs - dietary', 'Financial Support', 'Floor', 'Focus Groups', 'Fostering', 'Foundations', 'Fred Hutchinson Cancer Research Center', 'Funding', 'Future', 'Gene Conversion', 'Gene Expression', 'General Population', 'Generations', 'Genes', 'Genetic', 'Genetic Markers', 'Genetic Recombination', 'Genetic screening method', 'Genome', 'Genomics', 'Genus Mycobacterium', 'Geographic Information Systems', 'Geography', 'Giardia lamblia', 'Globus Pallidus', 'Glues', 'Goals', 'Gonorrhea', 'Government', 'Grant', 'Grenada', 'Guanosine Diphosphate', 'Guidelines', 'HIV', 'HIV Infections', 'HIV Seropositivity', 'HIV prevention trials network', 'HIV vaccine', 'HIV-1', 'HIV-2 vaccine', 'Hand', 'Head', 'Health', 'Health Information System', 'Health Personnel', 'Health Policy', 'Health Professional', 'Health Science Library', 'Health Sciences', 'Health Services', 'Health Services Research', 'Health Status', 'Health care facility', 'Health education', 'Healthcare', 'Heterogeneity', 'Heterosexuals', 'High Prevalence', 'Hispanics', 'Home Page', 'Home environment', 'Hospital Administration', 'Hospital Information Systems', 'Hospitalization', 'Hospitals', 'Hour', 'Housing', 'Human', 'Human Herpesvirus 2', 'Human Papilloma Virus Vaccine', 'Human Papillomavirus', 'Human Resources', 'Human immunodeficiency virus test', 'Human papillomavirus 16', 'Hybrids', 'Hyphae', 'IL2 gene', 'Image', 'Immersion Investigative Technique', 'Immune', 'Incidence', 'Individual', 'Induration', 'Infant', 'Infection', 'Infection Control', 'Informatics', 'Information Centers', 'Information Management', 'Information Networks', 'Information Resources', 'Information Sciences', 'Information Systems', 'Institutes', 'Institution', 'Instruction', 'Interdisciplinary Study', 'Interleukin-2', 'Internal Medicine', 'International', 'International AIDS', 'International Classification of Diseases', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Internet', 'Intervention', 'Intervention Trial', 'Interview', 'Isoniazid resistance', 'Japan', 'Job Description', 'Journals', 'Kenya', 'Knowledge', 'Knowledge acquisition', 'Laboratories', 'Laboratory Finding', 'Laboratory Research', 'Lamivudine/Zidovudine', 'Language', 'Latin America', 'Laws', 'Lead', 'Leadership', 'Learning', 'Left', 'Leishmaniasis', 'Lesion', 'Librarians', 'Libraries', 'Library Science', 'Licensing', 'Life', 'Life Expectancy', 'Light', 'Link', 'Linux', 'Literature', 'Local Area Networks', 'Location', 'London', 'Low income', 'Lung diseases', 'MEDLINE', 'Machine Learning', 'Malaria', 'Manuscripts', 'Maps', 'Marketing', 'Master of Science', 'Master&apos', 's Degree', 'Measures', 'Mediating', 'Mediation', 'Medical', 'Medical Education', 'Medical Informatics', 'Medical Libraries', 'Medical Research', 'Medical Students', 'Medical Surveillance', 'Medical Technology', 'Medical center', 'Medicine', 'Mentors', 'Mentorship', 'Methods', 'Metronidazole', 'Microbiology', 'Mining', 'Minority', 'Mission', 'Modeling', 'Modification', 'Molecular', 'Monitor', 'Montenegro', 'Mothers', 'Motivation', 'Multi-Drug Resistance', 'Multidrug-Resistant Tuberculosis', 'Mutation', 'Mycobacterium tuberculosis', 'N.I.H. Research Support', 'Names', 'Nature', 'Needs Assessment', 'Neighborhoods', 'Neisseria', 'Neonatology', 'Nested Case-Control Study', 'Nested PCR', 'Network-based', 'Nevirapine', 'Nuclear Energy', 'Nucleic Acids', 'Numbers', 'Nurses', 'Nursing Faculty', 'Nursing Schools', 'Occupational', 'Occupations', 'Online Systems', 'Ontology', 'Operating System', 'Oral', 'Outcome', 'Outcome Measure', 'Oxidation-Reduction', 'Oxidative Stress', 'Pacific Northwest', 'Pan American Health Organization', 'Paper', 'Parasites', 'Parasitic infection', 'Parasitology', 'Participant', 'Pathogenesis', 'Pathologist', 'Pathology', 'Pathway interactions', 'Patient Education', 'Patient currently pregnant', 'Patients', 'Pattern', 'Pediatrics', 'Peer Review', 'Pelvic Examination', 'Pelvic Inflammatory Disease', 'Peptide Sequence Determination', 'Performance', 'Perinatal', 'Peripheral Blood Mononuclear Cell', 'Peroxidase', 'Peroxidases', 'Personal Satisfaction', 'Persons', 'Peru', 'Pharmaceutical Preparations', 'Pharmacists', 'Pharmacologic Substance', 'Pharmacy Schools', 'Pharmacy facility', 'Phase', 'Phenotype', 'Philosophy', 'Physicians', 'Physics', 'Pilot Projects', 'Placebos', 'Placement', 'Plasma', 'Play', 'Pliability', 'Policies', 'Polymerase Chain Reaction', 'Population', 'Positioning Attribute', 'Postdoctoral Fellow', 'Practice Management', 'Pre-Post Tests', 'Predictive Value', 'Predisposition', 'Pregnancy', 'Pregnant Women', 'Prenatal care', 'Preparation', 'Prevalence', 'Prevention', 'Prevention strategy', 'Preventive', 'Primary Health Care', 'Principal Investigator', 'Printing', 'Private Practice', 'Prize', 'Problem Solving', 'Procedures', 'Process', 'Production', 'Professional counselor', 'Program Development', 'Program Evaluation', 'Programmed Learning', 'Progress Reports', 'Prophylactic treatment', 'Proteins', 'Proteomics', 'Protocols documentation', 'Protozoa', 'Provider', 'Province', 'Psychological reinforcement', 'Public Health', 'Public Health Administration', 'Public Health Education', 'Public Health Informatics', 'Public Health Practice', 'Public Health Schools', 'Public Hospitals', 'Public Policy', 'Publications', 'Publishing', 'Pulmonary Tuberculosis', 'Purpose', 'Pyrazinamide', 'Qualifying', 'Qualitative Methods', 'Questionnaires', 'Radiation', 'Radiation Oncology', 'Radiation therapy', 'Randomized', 'Randomized Controlled Clinical Trials', 'Randomized Controlled Trials', 'Range', 'Rate', 'Reaction', 'Readiness', 'Recommendation', 'Recording of previous events', 'Recruitment Activity', 'Recurrence', 'Regulation', 'Regulatory Element', 'Relative (related person)', 'Reporting', 'Representations, Knowledge (Computer)', 'Reproductive Tract Infections', 'Research', 'Research Activity', 'Research Design', 'Research Ethics Committees', 'Research Infrastructure', 'Research Institute', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Research Training', 'Resistance', 'Resources', 'Restriction fragment length polymorphism', 'Retrieval', 'Review Literature', 'Rheumatology', 'Rifampin', 'Risk', 'Risk Behaviors', 'Risk Factors', 'Robotics', 'Role', 'Rotavirus', 'Route', 'Running', 'Rural', 'Rural Health', 'Rural Population', 'Safe Sex', 'Salmonella', 'Sampling', 'Scholarship', 'School Nursing', 'Schools', 'Science', 'Scientist', 'Score', 'Screening procedure', 'Second Pregnancy Trimester', 'Secure', 'Security', 'Seeds', 'Senegal', 'Sentinel', 'Sentinel Surveillance', 'Sequence Alignment', 'Sequence Analysis', 'Series', 'Seroepidemiologic Studies', 'Serological', 'Seroprevalences', 'Services', 'Sex Behavior', 'Sexual Partners', 'Sexually Transmitted Diseases', 'Side', 'Signs and Symptoms', 'Simulate', 'Singapore', 'Sister', 'Site', 'Social Development', 'Social Psychology', 'Software Engineering', 'Software Tools', 'Solid', 'Solutions', 'Source', 'Specificity', 'Specimen', 'Spectinomycin', 'Speed', 'Sputum', 'Staining method', 'Stains', 'Standards of Weights and Measures', 'Stomach', 'Streptomycin', 'Structure', 'Students', 'Supplementation', 'Support System', 'Surrogate Markers', 'Surveillance Program', 'Surveys', 'Swab', 'Switzerland', 'Symptoms', 'Syndrome', 'Syphilis', 'System', 'T-Lymphocyte', 'TAF8 gene', 'Taiwan', 'Tanzania', 'Teaching Materials', 'Techniques', 'Technology', 'Teleconferences', 'Telemedicine', 'Television', 'Test Result', 'Testing', 'Textbooks', 'Therapeutic', 'Thinking', 'Time', 'TimeLine', 'Title', 'Touch sensation', 'Trainers Training', 'Training', 'Training Activity', 'Training Programs', 'Training and Infrastructure', 'Treatment Efficacy', 'Treponema pallidum', 'Triad Acrylic Resin', 'Trichomonas Infections', 'Tropical Disease', 'Trust', 'Tuberculin', 'Tuberculosis', 'U-Series Cooperative Agreements', 'USAID', 'Ulcer', 'Underemployment', 'United States', 'United States Dept. of Health and Human Services', 'United States National Institutes of Health', 'Universities', 'Unmarried', 'Update', 'Urban Population', 'Urethritis', 'Vaccination', 'Vaccines', 'Vagina', 'Variant', 'Venezuela', 'Vertebral column', 'Vibrio', 'Videoconferences', 'Videoconferencing', 'Virulence', 'Virulence Factors', 'Vision', 'Visit', 'Visual', 'Voice', 'Walking', 'Washington', 'Week', 'Western Europe', 'Wing', 'Wolves', 'Woman', 'Work', 'Workplace', 'World Health Organization', 'Writing', 'Zidovudine', 'Zinc', 'abstracting', 'base', 'behavior change', 'biomedical informatics', 'blood filter', 'cancer therapy', 'career', 'case control', 'case-based', 'catalase', 'clinically relevant', 'cohort', 'college', 'computer center', 'computer science', 'computing resources', 'concept', 'condoms', 'contextual factors', 'coping', 'cost', 'cytokine', 'data integration', 'data management', 'data mining', 'database design', 'day', 'design', 'desire', 'digital', 'epidemiology study', 'evaluation/testing', 'expectation', 'experience', 'falls', 'fetal', 'fly', 'follow-up', 'forging', 'genital herpes', 'genome sequencing', 'global environment', 'health administration', 'health application', 'high risk behavior', 'human subject', 'image processing', 'imaging informatics', 'immunopathology', 'improved', 'informatics training', 'information gathering', 'information organization', 'innovation', 'insight', 'instrumentation', 'interest', 'international center', 'isoniazid', 'knowledge base', 'laboratory facility', 'lectures', 'macrophage', 'male', 'mathematical model', 'medical schools', 'member', 'men', 'microbial', 'mortality', 'mouse Gdi2 protein', 'mycobacterial', 'neglect', 'nevirapine resistance', 'new growth', 'next generation', 'older patient', 'older women', 'oncology', 'open source', 'outreach', 'pathogen', 'pediatric AIDS', 'pediatrician', 'peer', 'point of care', 'prenatal', 'prevent', 'professor', 'programs', 'prospective', 'prototype', 'recombinase', 'rectal', 'research and development', 'research study', 'response', 'satisfaction', 'sex', 'size', 'skills', 'skills training', 'software development', 'sound', 'statistics', 'success', 'symposium', 'syndromic surveillance', 'teacher', 'tool', 'tool development', 'trafficking', 'transcription factor', 'transmission process', 'treatment planning', 'trend', 'tumor', 'web based interface', 'wide area network', 'willingness', 'young adult']",FIC,UNIVERSITY OF WASHINGTON,D43,2007,73250,0.010499614971559918
"Collaborative Brain Mapping: Tools for Sharing    DESCRIPTION (provided by applicant): Sharing data between research centers is increasingly important for contemporary brain imaging studies because they involve large numbers of subjects and complex analysis protocols that require highly specialized expertise. Our long-term objective is to facilitate brain-imaging research by enabling remote researchers to pool data between institutions and to analyze data using the appropriate algorithms executing on distributed resources. There are a number of difficult data management and technology challenges that have limited the success of data sharing environments. Rather than attempt to develop a comprehensive and general solution, we propose to develop a set of open, interoperable, and portable software tools that address critical issues currently limiting efforts to share and analyze brain-imaging data. Building upon years of providing brain-mapping expertise to collaborators, we propose to solve problems that we repeatedly encounter and that currently limit progress in brain imaging research. We propose to develop validated tools that enable collaborators to remotely access a variety of data analysis methods and databases. We will create web-based tools to perform multi-institutional studies, and provide access to complex data processing protocols executing on distributed computing resources. There are three specific aims. 1) Enable the web based acquisition and management of data utilizing an access control system that includes consideration of subject consent limits and investigator imposed conditions to facilitate data pooling for multi-institutional studies. This system will convert data files between different formats and schemas so that data can be used consistently between analysis programs and databases. It will also anonymize images and metadata according to institution-specific protocols. 2) Develop a system that is aware of data type and provenance so that it may act intelligently to arbitrate between different analysis programs. This system will capture the expertise of experienced lab personnel in the usage of various tools and assist new users in designing appropriate analytic strategies. 3) Create meta-algorithms that improve the robustness of techniques for neuroimaging analysis by intelligently combining the results from multiple algorithms. The proposed approach will provide a set of tools that address significant problems in data sharing and utilization. The resulting information technology will be scalable and applicable to other scientific data sharing problems.         n/a",Collaborative Brain Mapping: Tools for Sharing,7109207,R01MH071940,"['Internet', 'artificial intelligence', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain mapping', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'confidentiality', 'data management', 'information dissemination', 'information systems', 'mathematics']",NIMH,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2006,649537,-0.003489575315525928
"CREATION AND APPLICATION OF A DIABETES KNOWLEDGE BASE CREATION AND APPLICATION OF A DIABETES KNOWLEDGE BASE   The applicant is an Instructor in Pediatrics at Harvard Medical School and an associate in bioinformatics and pediatric endocrinology at Children's Hospital, Boston. The applicant completed an NLM-funded fellowship in informatics and received a Masters Degree in Medical Informatics from MIT. Since completing his fellowship less than two years ago, he has first-authored six publications, co-authored eight publications, senior authored two publications, and co-authored a book on microarray analysis. The applicant plans to pursue a career in basic research in diabetes genomics and bioinformatics, with a joint appointment in both an academic pediatric endocrinology department and a medical informatics program. The mentor is Dr. Isaac Kohane, director of the Children's Hospital Informatics Program with a staff of 20 including 10 faculty and extensive computational resources, funded through several NIH grants.       The past 10 years have led to a variety of measurements tools in molecular biology that are near comprehensive in nature. For example, RNA expression detection microarrays can provide systematic quantitative information on the expression of over 40,000 unique RNAs within cells. Yet microarrays are just one of at least 30 large-scale measurement or experimental modalities available to investigators in molecular biology. We see scientific value in being able to integrate multiple large-scale data sets from all biological modalities to address biomedical questions that could otherwise not be answered. We recognize that the full agenda of working out the details for all possible inferential processes between all near-comprehensive modalities is too large. The goal of this project is to serve as a model automated system for gathering data related to particular experimental characteristic and perform inferential operators on these data. For this application, we are focusing on a pragmatic subset. Specifically, we propose intersecting near comprehensive data sets by phenotype, and intersecting lists of significant and related genes within these data sets in an automated manner.      The central hypothesis for this application is that integrating large-scale data sets across measurement  modalities is a synergistic process to create new knowledge and testable hypothesis in the area of diabetes, and inferential processes involving intersection across genes can be automated. n/a",CREATION AND APPLICATION OF A DIABETES KNOWLEDGE BASE,7007706,K22LM008261,"['RNA interference', 'adipocytes', 'artificial intelligence', 'automated data processing', 'cell differentiation', 'clinical research', 'computer system design /evaluation', 'diabetes mellitus genetics', 'human data', 'information systems', 'insulin sensitivity /resistance', 'noninsulin dependent diabetes mellitus', 'obesity', 'phenotype', 'quantitative trait loci', 'vocabulary', 'weight gain']",NLM,STANFORD UNIVERSITY,K22,2006,153843,-0.007616459135716249
"10th International Fragile X Conference    DESCRIPTION (Provided by the Applicant):  10th International Fragile X Conference: The National Fragile X Foundation's 10th International Fragile X Conference in Atlanta, Georgia, at the OMNI Hotel - CNN Center, July 19-23, 2006, will bring together the world's leading researchers in molecular biology and genetics as well as leading clinicians and treatment specialists, selected by its Scientific and Clinical Advisory Committee, with hundreds of parents, extended family members and students engaged in research training. Both scientific and family-friendly sessions covering the three conditions resulting from the fragile X gene mutation will be addressed: fragile X syndrome; fragile X associated tremor ataxia syndrome; fragile X related premature ovarian failure. Keynote presentations, breakout session lectures, research abstract sessions, panels and posters will present the latest knowledge regarding the underlying mechanisms for the fragile X related conditions, plus evidence-based medical, therapeutic and educational interventions. The conference will benefit multiple disciplines including those engaged in clinical practice, epidemiology and delivery system organization. The National Fragile X Foundation will publish and disseminate the results in conference proceedings as well as other formats and utilize the recommendations as the basis for advancing the research and treatment fields.    n/a",10th International Fragile X Conference,7166760,R13HS016448,"['fragile X syndromes', 'meeting /conference /symposium', 'travel']",AHRQ,NATIONAL FRAGILE X FOUNDATION,R13,2006,25000,0.0016003023255425069
"Neuroimaging Neuroinformatics Training Program    DESCRIPTION (provided by applicant): This proposal is in response to PAR-03-034 ""Neuroinformatics Institutional Mentored Research Scientist Development Award (K12)."" The overarching goal of this application is to provide an excellent postdoctoral training program in neuroimaging neuroinformatics that capitalizes on the many strengths of the existing neuroscientists, informatics and imaging resources that our combined resources represent. Our proposed Neuroimaging Neuroinformatics Training Program (NNTP) is based upon a number of important strategic alliances. The first cornerstone of this effort is the existing HBP grants held by Dr. Anders Dale (R01 NS39581: Cortical-Surface-Based Brain Imaging) and Dr. David Kennedy (R01 NS34189: Anatomic Morphologic Analysis of MR Brain Images). These efforts span a wealth of technological developments, research and clinical application areas in the rapidly developing area of quantitative morphometric image analysis. A second and vital cornerstone is our association with the Harvard-MIT Division of Health Sciences and Technology (HST) Biomedical Informatics Program. This existing pre- and post-graduate academic program, within a world class biomedical engineering department, is an ideal setting for the development of a coordinated training effort in Neuroinformatics. The established track record in training skilled scientists in areas of informatics will prove invaluable in this new initiative. The third cornerstone is the combined clinical research opportunities afforded by the Harvard-wide biomedical imaging resources. These include the MGH/MIT/HST Athinoula A. Martinos Center for Biomedical Imaging, the Harvard Neuroimaging Center, the Surgical Planning Lab at Brigham and Women's Hospital, the Brain Morphology BIRN (Biomedical Informatics Research Network) and the MIT Artificial Intelligence Laboratory. Together, these active and vibrant programs provide for the best possible training opportunities in imaging science, computer science, clinical application areas, and cognitive neuroscience. A substantial and successful pool of internationally renowned mentors have agreed to participate in this program, and the combined resources provide the best possible exposure to all neuroimaging procedures and insure the capability to draw the highest caliber trainees. A plan for recruiting, selecting and monitoring trainees is proposed. This program will be an asset to the Neuroinformatics initiatives of the Human Brain Project by helping to prepare future scientists with advanced neuroinformatics skills         n/a",Neuroimaging Neuroinformatics Training Program,7056141,K12MH069281,"['bioimaging /biomedical imaging', 'bioinformatics', 'brain imaging /visualization /scanning', 'brain morphology', 'career', 'image processing', 'morphometry', 'neuroimaging', 'neurosciences', 'training']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,K12,2006,439784,9.683510653424107e-05
"The RPI Exploratory Center for Cheminformatics (RMI) The purpose of this Exploratory Center for Cheminformatics Research (ECCR) P20 planning grant is to develop a mechanism for bringing together and stimulating collaborative pilot projects among a constantly-evolving nucleus of experts in Cheminformatics-related fields ranging from methods of encoding and capturing molecular information, to machine learning and data mining techniques, to predictive model development, validation, interpretation and utilization. In addition to these research efforts, the Center will bring together a set of domain specialists and application scientists who will serve as both data generators and end users of the knowledge provided by the molecular property models and modeling methods developed during the course of the grant. This group will also test the new Cheminformatics software that will constitute a tangible, deliverable product from this work. Ten application project modules that exemplify possible interactions between various groups and areas of expertise within the Center are presented as part of this proposal. The unifying vision behind the proposed Center is that much of what is done in each of the subdisciplines represented here can be expressed in a Cheminformatics context: The many diverse project areas can be grouped into one or more overlapping categories: ""Data Generators"" (those who use either theoretical or experimental methods for creating or extracting knowledge), ""Machine Learning and Datamining"" groups (who perform model validation, feature selection, pattern recognition, generation of potentials of mean force and knowledge-based potential work), as well as ""Property-Prediction"" groups (who perform chemically-aware model building, molecular property descriptor generation, Quantitative Structure-Property Relationship modeling, validation, and interpretation), and ""Application"" groups who utilize the information made available using the new tools and methods that are developed as part of the Center. It is our strong belief that these areas of expertise can be brought together within this Planning Grant proposal to generate something larger than the sum of the parts. The Exploratory Center will seed new interdisciplinary projects and train graduate students in these areas.   Relevance: Advances in the generation, mining and analysis of chemical information is crucial to the development of new drug therapies, and to modern methods of bioinformatics and molecular medicine. n/a",The RPI Exploratory Center for Cheminformatics (RMI),7125575,P20HG003899,"['Internet', 'NIH Roadmap Initiative tag', 'bioinformatics', 'chemical models', 'cheminformatics', 'computer program /software', 'computers', 'data collection methodology /evaluation', 'data management', 'information retrieval', 'interdisciplinary collaboration', 'model design /development', 'molecular biology']",NHGRI,RENSSELAER POLYTECHNIC INSTITUTE,P20,2006,377226,0.011565251647832713
"NEW DRUG TARGETS FOR APOPTOSIS DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",NEW DRUG TARGETS FOR APOPTOSIS,7284550,P01CA017094,"['antineoplastics', 'biomedical facility', 'chemosensitizing agent', 'clinical research', 'drug design /synthesis /production', 'drug resistance', 'drug screening /evaluation', 'neoplasm /cancer chemotherapy']",NCI,UNIVERSITY OF ARIZONA,P01,2006,498959,-0.004638645201995156
"24th ANNUAL SYMPOSIUM ON NONHUMAN PRIMATE MODELS FOR AIDS    DESCRIPTION (provided by applicant):    This conference grant (R13) application requests funds to partially cover the cost of planning, organizing, publicizing and hosting the 24th Annual Symposium on Nonhuman Primate Models for AIDS. The symposium will be held October 4-7, 2006, at the Omni Hotel at CNN Center in downtown Atlanta, Georgia, and will be hosted by the Yerkes National Primate Research Center, Emory University. This meeting is the premier forum for the presentation and exchange of the most recent scientific advances in AIDS research utilizing the nonhuman primate model. The latest findings in primate pathogenesis, immunology, genomics, virology, vaccines and therapeutics will be presented. It is anticipated more than 300 scientists from the United States and other countries will attend. The symposium will encompass five half-day scientific sessions and an evening poster session. The scientific sessions will be: Virology, Pathogenesis, Immunology, Vaccines and Therapeutics/Genomics. Each session will have an invited Chair, a scientific leader in the field, who will give a 30-minute state-of-the-field presentation to open the session, and a Co-Chair from the Scientific Committee, who will moderate the session and entertain questions. In addition, there will be an invited keynote speaker and a banquet speaker, who will address scientific approaches and concerns regarding the global AIDS crisis and related issues of public health. A Scientific Program Committee consisting of eight-ten members drawn from the Yerkes/Emory community and other institutions will review abstracts and assign oral or poster presentations for each of the scientific sessions. Committee members will include leaders in the field from a variety of scientific disciplines. Criteria for selection of oral presentations will include relevance of the topic as well as originality and quality of the information contained in the abstract. Those giving talks will be invited to submit their presentations in manuscript form for publication in the Journal of Medical Primatology. A poster session will include meritorious presentations that cannot be accommodated in one of the platform sessions. A local Organizing Committee will handle arrangements and logistics for the symposium. Feedback from the participants will be obtained through written questionnaires or oral comments to members of the organizing committee. This format has been successfully followed using NCRR support for the previous Annual symposium.           n/a",24th ANNUAL SYMPOSIUM ON NONHUMAN PRIMATE MODELS FOR AIDS,7114527,R13RR022961,"['AIDS', 'Primates', 'disease /disorder model', 'meeting /conference /symposium', 'travel']",NCRR,EMORY UNIVERSITY,R13,2006,63089,0.0009768506844091561
"Nation Center: Multi-Scale Study- Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7126050,U54CA121852,"['NIH Roadmap Initiative tag', 'bioinformatics', 'cell biology', 'computational biology', 'cooperative study', 'genome']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2006,3747227,-0.05462354393207588
"Accessible Artificial Intelligence Tutoring Software DESCRIPTION (provided by applicant): Quantum has successfully developed, tested and brought to the classroom the first artificial intelligence (Al) tutoring systems in chemistry education. This work successfully addressed several longstanding, clearly articulated needs for improved interactive educational software. A leading distributor for the U.S. and Canada, Science Kit & Boreal Laboratories, as well as prominent textbook publisher, Holt, Rinehart and Winston, have entered into long-term contracts with Quantum, resulting in rapid dissemination to an established end user base. The aim of this Phase I SBIR proposal is to bring the full power and benefits of this cutting-edge new educational technology to students who are blind and visually impaired. There is a considerable need for improved educational software for science education in general, but the problem of quality educational software materials for the blind is known to be particularly acute. Certain unique attributes of the Quantum Al Tutors make them potentially very well suited for full accessibility to the blind using Internet-capable screen reader technology. The potential technological innovation here is the development of advanced Al tutoring technology that has accessibility built into its framework design. If successful, an immediate outcome will be the first Al tutoring systems that are accessible to blind students, delivered through the Internet. A formulation of an Al tutoring methodology with accessibility inherent to the design will have broad implications for the prospect of developing sophisticated accessible educational software in all content areas, beyond chemistry. This project can only be accomplished by working intimately with experts in education for the blind, and Quantum has arranged a number of important partnerships in this respect, for research as well as commercialization of the resulting technology, including: the National Federation of the Blind, the American Printing House for the Blind, Pearson Learning Group, Bartimaeus Group and Henter Mathematics. n/a",Accessible Artificial Intelligence Tutoring Software,6880607,R43EY016251,"['Internet', 'artificial intelligence', 'blind aid', 'chemistry', 'computer assisted instruction', 'computer human interaction', 'computer program /software', 'educational resource design /development', 'science education', 'technology /technique development']",NEI,"QUANTUM SIMULATIONS, INC.",R43,2005,100721,0.0037766985875692127
"BioMediator: Biologic Data Integration& Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration& Analysis System,6946761,R01HG002288,"['artificial intelligence', 'bioengineering /biomedical engineering', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'information retrieval', 'molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2005,100000,0.0035528400301554235
"Linking Information, Families and Technology (LIFT) DESCRIPTION (provided by applicant): KIT Solutions, a private firm specializing in developing intelligent, Knowledge-based Information Technology (KIT) solutions for the field of health and human services will partner with the University of Pittsburgh, Office of Child Development (OCD) to develop a Web-based, interactive software application of a Family Support Management Information System (FS MIS) for nationwide dissemination. This innovation is called Linking Information, Families and Technology (LIFT).  Family support centers, like other human service programs and agencies across the country, are being required to implement best practices and document the impact of their services to funders, policy makers, and the community. However, most family centers do not have a state-of-the-art web-based information system available to them that integrates best practice, expert knowledge, and daily management functions. The proposed LIFT system will address these critical needs and has great potential for nationwide commercial distribution. The combination of KIT'S proven record of developing knowledge based information technology and OCD's over 20 years of research and practice in family support services will greatly enhances the chance of success for this business venture. In Phase I of the project, we will produce prototype software demonstrating the benefit, usability, and feasibility of a web-based, interactive, intelligent system for use by family support centers across the nation. The extent of which LIFT enables family center staff to build skill, capacity, access information and expert knowledge, to enhance their work will be the focus of this phase. In Phase II, we will fully develop the prototype LIFT to a commercial grade web application for nationwide dissemination and further validate the commercial potential and impact of LIFT, using a quasiexperimental design, which will involve a large number of users across multiple sites. In Phase III, we will seek private funding for marketing the system to the national market. We intend to use the Microsoft.Net Platform and follow XML web service concepts to develop the proposed innovation. Collection of a subscription fee will be used to support the maintenance and future development of the system. n/a","Linking Information, Families and Technology (LIFT)",6990440,R43HD049229,"['Internet', 'artificial intelligence', 'behavioral /social science research tag', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'family', 'focus groups', 'human subject', 'information dissemination', 'social service']",NICHD,"KIT SOLUTIONS, INC.",R43,2005,104545,0.0005781334876224874
"Shifting Conceptions of Human Identity DESCRIPTION (provided by applicant):  . One of the most important questions raised by the ongoing achievements of the Human Genome Project is how this new biological knowledge - and the powers it confers - will affect our identity and self-understanding as human beings. This book project focuses on one key aspect of this complex issue: exploring the extent to which human identity can be reconciled with deliberate design or partial redesign. The author proposes to shed new light on this question by comparing the debates surrounding two areas of scientific innovation that are not normally associated with each other, but that are in fact deeply related: the enterprise of human genetic intervention and the enterprise of building intelligent machines. Both these enterprises entail ""pushing the limits"" of traditional concepts of what it means to be human; and both ultimately confront their makers with the same core ""family"" of questions: What are the defining features of human personhood? To what extent can those features be modified or extended, before human personhood begins to break down? Can some (or all) of those features find embodiment in an entity other than a human being? These kinds of questions are no longer the sole province of science fiction writers, but have been taken up with increasing seriousness by mainstream scientists and technologists, as well as by a wide array of ""science watchers"" in academia, legislative circles, and the news media.   . Through documentary research and interviews, this project aims to deepen our understanding of the history and sociology of the debates surrounding these powerful new technologies, electro-mechanical and biological, that are perceived as destabilizing human identity. The intended audience for the book is a broad one: scientists and technological practitioners interested in the social and cultural reception of their research; legislators and other policymakers with a stake in the governance of science; general educated readers who are concerned about the role of science and technology in shaping our collective future. n/a",Shifting Conceptions of Human Identity,6915830,R03HG003298,"['adult human (21+)', 'artificial intelligence', 'behavioral /social science research tag', 'biotechnology', 'books', 'clinical research', 'ethics', 'genetic manipulation', 'history of life science', 'human subject', 'identity', 'interview', 'robotics', 'self concept', 'sociology /anthropology']",NHGRI,VANDERBILT UNIVERSITY,R03,2005,75833,-0.0056928710204626485
"Collaborative Brain Mapping: Tools for Sharing    DESCRIPTION (provided by applicant): Sharing data between research centers is increasingly important for contemporary brain imaging studies because they involve large numbers of subjects and complex analysis protocols that require highly specialized expertise. Our long-term objective is to facilitate brain-imaging research by enabling remote researchers to pool data between institutions and to analyze data using the appropriate algorithms executing on distributed resources. There are a number of difficult data management and technology challenges that have limited the success of data sharing environments. Rather than attempt to develop a comprehensive and general solution, we propose to develop a set of open, interoperable, and portable software tools that address critical issues currently limiting efforts to share and analyze brain-imaging data. Building upon years of providing brain-mapping expertise to collaborators, we propose to solve problems that we repeatedly encounter and that currently limit progress in brain imaging research. We propose to develop validated tools that enable collaborators to remotely access a variety of data analysis methods and databases. We will create web-based tools to perform multi-institutional studies, and provide access to complex data processing protocols executing on distributed computing resources. There are three specific aims. 1) Enable the web based acquisition and management of data utilizing an access control system that includes consideration of subject consent limits and investigator imposed conditions to facilitate data pooling for multi-institutional studies. This system will convert data files between different formats and schemas so that data can be used consistently between analysis programs and databases. It will also anonymize images and metadata according to institution-specific protocols. 2) Develop a system that is aware of data type and provenance so that it may act intelligently to arbitrate between different analysis programs. This system will capture the expertise of experienced lab personnel in the usage of various tools and assist new users in designing appropriate analytic strategies. 3) Create meta-algorithms that improve the robustness of techniques for neuroimaging analysis by intelligently combining the results from multiple algorithms. The proposed approach will provide a set of tools that address significant problems in data sharing and utilization. The resulting information technology will be scalable and applicable to other scientific data sharing problems.         n/a",Collaborative Brain Mapping: Tools for Sharing,6953037,R01MH071940,"['Internet', 'artificial intelligence', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain mapping', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'confidentiality', 'data management', 'information dissemination', 'information systems', 'mathematics']",NIMH,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2005,647432,-0.003489575315525928
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6923756,R01GM061372,"['Internet', 'artificial intelligence', 'automated data processing', 'biological signal transduction', 'biomedical automation', 'computer system design /evaluation', 'functional /structural genomics', 'high throughput technology', 'intermolecular interaction', 'method development', 'molecular biology information system', 'statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2005,395905,-0.009354626012519334
"Development of Bioinformatic Tools for Virtual Cloning  DESCRIPTION (provided by applicant): The elaboration of the sequences of the human genome and those of many cellular and viral parasites has given us an unprecedented opportunity to address the causes and treatment of every major human disease. It has also resulted in the formation of an entirely new field, bioinformatics, which promises to manage and analyze the vast amount of data being generated. Bioinformatics needs to supply tools for data analysis and tools for experimental design. Most of the scientific and corporate resources being expended in bioinformatics are being spent on data analysis tools. While these are essential, we should not neglect the opportunity to accelerate the progress of actual experimental biology. Essentially every experiment in biology now begins with cloning one or more pieces of DNA. Commercial software that facilitates virtual DNA cloning does exist, but it lacks any automation features and depends on primitive and/or fragmentary gene and vector databases. It is inadequate in planning the hundreds or thousands of clones necessary to address questions posed by the proteomics initiatives, because the lack of knowledge integration. In Phase I of this SBIR grant, we have built and tested a virtual cloning expert system, along with a very useful gene database and a uniquely annotated vector database that serve as a knowledge base for automated DNA manipulations. A collection of automated cloning modules and databases is now functional. In Phase II we will complete the virtual cloning expert system and develop a flexible platform for automated experimental design, data management and analysis. We will also construct a user database, improve the user interface and establish security protocols. The results will be a complete program suite as a stable and marketable product. n/a",Development of Bioinformatic Tools for Virtual Cloning,6908174,R44HG003506,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'computer assisted sequence analysis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'experimental designs', 'expression cloning', 'genetic library', 'high throughput technology', 'molecular biology information system', 'molecular cloning']",NHGRI,"VIRMATICS, LLC",R44,2005,375000,-0.011386790933521827
"CREATION AND APPLICATION OF A DIABETES KNOWLEDGE BASE CREATION AND APPLICATION OF A DIABETES KNOWLEDGE BASE   The applicant is an Instructor in Pediatrics at Harvard Medical School and an associate in bioinformatics and pediatric endocrinology at Children's Hospital, Boston. The applicant completed an NLM-funded fellowship in informatics and received a Masters Degree in Medical Informatics from MIT. Since completing his fellowship less than two years ago, he has first-authored six publications, co-authored eight publications, senior authored two publications, and co-authored a book on microarray analysis. The applicant plans to pursue a career in basic research in diabetes genomics and bioinformatics, with a joint appointment in both an academic pediatric endocrinology department and a medical informatics program. The mentor is Dr. Isaac Kohane, director of the Children's Hospital Informatics Program with a staff of 20 including 10 faculty and extensive computational resources, funded through several NIH grants.       The past 10 years have led to a variety of measurements tools in molecular biology that are near comprehensive in nature. For example, RNA expression detection microarrays can provide systematic quantitative information on the expression of over 40,000 unique RNAs within cells. Yet microarrays are just one of at least 30 large-scale measurement or experimental modalities available to investigators in molecular biology. We see scientific value in being able to integrate multiple large-scale data sets from all biological modalities to address biomedical questions that could otherwise not be answered. We recognize that the full agenda of working out the details for all possible inferential processes between all near-comprehensive modalities is too large. The goal of this project is to serve as a model automated system for gathering data related to particular experimental characteristic and perform inferential operators on these data. For this application, we are focusing on a pragmatic subset. Specifically, we propose intersecting near comprehensive data sets by phenotype, and intersecting lists of significant and related genes within these data sets in an automated manner.      The central hypothesis for this application is that integrating large-scale data sets across measurement  modalities is a synergistic process to create new knowledge and testable hypothesis in the area of diabetes, and inferential processes involving intersection across genes can be automated. n/a",CREATION AND APPLICATION OF A DIABETES KNOWLEDGE BASE,7125331,K22LM008261,"['RNA interference', 'adipocytes', 'artificial intelligence', 'automated data processing', 'cell differentiation', 'clinical research', 'computer system design /evaluation', 'diabetes mellitus genetics', 'human data', 'information systems', 'insulin sensitivity /resistance', 'noninsulin dependent diabetes mellitus', 'obesity', 'phenotype', 'quantitative trait loci', 'vocabulary', 'weight gain']",NLM,STANFORD UNIVERSITY,K22,2005,152083,-0.007616459135716249
"Computational Approaches to Disease Causes and Treatment DESCRIPTION (provided by applicant): The State University of New York at Buffalo has assembled a multi-disciplinary team of investigators to plan and establish a National Program of Excellence in Biomedical Computing. The overall theme of the center is ""Novel Data Mining Algorithms for Applications in Genomics"" with a focus on the development of novel techniques for storing, managing, analyzing, modeling and visualizing multi-dimensional data sets. We intend to provide the expertise and infrastructure that will merge the research activities of computational and biomedical scientists. The focus of the proposed research is the study of common diseases, such as cancer, multiple sclerosis and coronary artery disease in which the underlying causes are multi-factorial. In this new paradigm, we will use advanced computational techniques and approaches to convert raw genomic data into knowledge that will advance the understanding of these common diseases and potentially identify new modalities of treatment. The Center will play a critical role in fostering multidisciplinary collaborations between faculty from the Departments of Computer Science and Engineering, Biology, Chemistry, Pharmaceutical Science and various departments in the School of Medicine and Biomedical Sciences. By co-locating biomedical and computer scientists, common understanding of research approaches will result in the development of computational tools that will meet the real-life needs of the biomedical researchers to help advance their projects. The Center will provide a broad range of educational and training activities for individuals who wish to pursue a career focusing on computational biology and bioinformatics. The focus of the education program will be the interdisciplinary training of computer science and engineering students who wish to pursue research in functional genomics and other biomedical areas, and the cross training of biomedically oriented students in topics with more of a computing orientation. We have identified three development projects that provide unique scientific opportunities to integrate the expertise of mathematicians, statisticians, and computer scientists with medical scientists, and to investigate novel computational approaches. These computational related projects are: 1. Data integration and data mining of clinical data and genomic data to advance clinical and epidemiological genetics as well as drug effect studies; 2. Pharmacodynamic analysis of drug-responsive gene expression changes; and 3. Chemi-genetic approaches to mapping regulatory pathways. These research projects will be supported by three core resources: genomics core, computational core, and clinical core. The common nature of these applications is that they all generate multidimensional data sets with numerical, functional or symbolic attributes. The management, retrieval and visualization of these data sets and analyses is likely to prove to be a rate limiting factor for new biomedical discoveries and the development of techniques for the effective analyses of genomic datasets is a critical step for the medical applications of bioinformatics. n/a",Computational Approaches to Disease Causes and Treatment,6931476,P20GM067650,"['animal tissue', 'artificial intelligence', 'bioinformatics', 'computational biology', 'computer data analysis', 'computer human interaction', 'computer simulation', 'computer system design /evaluation', 'data management', 'disease /disorder etiology', 'epidemiology', 'functional /structural genomics', 'gene expression', 'human subject', 'interdisciplinary collaboration', 'mathematical model', 'pharmacokinetics', 'science education', 'statistics /biometry', 'technology /technique development', 'therapy', 'training']",NIGMS,STATE UNIVERSITY OF NEW YORK AT BUFFALO,P20,2005,392500,0.01827216833899577
"Middle School Life Science-Education Partnership-PhaseII    DESCRIPTION (provided by applicant):    Precollege science education, particularly middle school where students first encounter courses dedicated to the sciences, has lacked the attention of the scientific and education communities. As a result, many middle level teachers are marginally prepared to teach contemporary science, the development of effective curricular materials has lagged, and schools devote inadequate resources and support to science. In the prior Phase I grant, experiment modules have been designed by scientists that address the core content of middle school Life Science. They utilize live (aquatic) organisms in the class room to stimulate inquiry into the properties of living organisms and make connections with related environmental health problems to link student learning with the world around them. Human environmental health was chosen as the biomedical context because it strongly relates to the macroscopic world in which middle school students live and provides age-appropriate learning opportunities for students as they begin to understand organisms and their underlying structures and mechanisms. During Phase II our specific objectives are 1. To infuse middle school Life Science education with attractive experiment modules that stress student inquiry. 2. To mount a comprehensive dissemination program with school systems that work with large numbers of minorities and students from families with lower socioeconomic status. 3. To utilize a 'train the trainer' method for lead teachers to achieve wide dissemination of the modules that involves close collaboration between scientists and educators and the lead teachers. 4. To provide teachers with full support to implement and sustain the modules through a science resource center. 5. To continue the development of the content of the modules. 6. To obtain a thorough formative and summative evaluation of the effectiveness of the curriculum modules and the entire mechanism for their delivery. 7. To establish a robust program to sustain the module dissemination to teachers after the completion of the grant.         n/a",Middle School Life Science-Education Partnership-PhaseII,6857683,R25RR014267,"['DVD /CD ROM', 'artificial intelligence', 'curriculum', 'education evaluation /planning', 'educational resource design /development', 'ethnic group', 'female', 'learning', 'meeting /conference /symposium', 'minority health professional', 'science education', 'secondary schools', 'social support network', 'teacher', 'university student', 'videotape /videodisc']",NCRR,UNIVERSITY OF WISCONSIN MILWAUKEE,R25,2005,268813,0.03414160648645688
"The RPI Exploratory Center for Cheminformatics(RMI) The purpose of this Exploratory Center for Cheminformatics Research (ECCR) P20 planning grant is to develop a mechanism for bringing together and stimulating collaborative pilot projects among a constantly-evolving nucleus of experts in Cheminformatics-related fields ranging from methods of encoding and capturing molecular information, to machine learning and data mining techniques, to predictive model development, validation, interpretation and utilization. In addition to these research efforts, the Center will bring together a set of domain specialists and application scientists who will serve as both data generators and end users of the knowledge provided by the molecular property models and modeling methods developed during the course of the grant. This group will also test the new Cheminformatics software that will constitute a tangible, deliverable product from this work. Ten application project modules that exemplify possible interactions between various groups and areas of expertise within the Center are presented as part of this proposal. The unifying vision behind the proposed Center is that much of what is done in each of the subdisciplines represented here can be expressed in a Cheminformatics context: The many diverse project areas can be grouped into one or more overlapping categories: ""Data Generators"" (those who use either theoretical or experimental methods for creating or extracting knowledge), ""Machine Learning and Datamining"" groups (who perform model validation, feature selection, pattern recognition, generation of potentials of mean force and knowledge-based potential work), as well as ""Property-Prediction"" groups (who perform chemically-aware model building, molecular property descriptor generation, Quantitative Structure-Property Relationship modeling, validation, and interpretation), and ""Application"" groups who utilize the information made available using the new tools and methods that are developed as part of the Center. It is our strong belief that these areas of expertise can be brought together within this Planning Grant proposal to generate something larger than the sum of the parts. The Exploratory Center will seed new interdisciplinary projects and train graduate students in these areas.   Relevance: Advances in the generation, mining and analysis of chemical information is crucial to the development of new drug therapies, and to modern methods of bioinformatics and molecular medicine. n/a",The RPI Exploratory Center for Cheminformatics(RMI),7032113,P20HG003899,"['Internet', 'bioinformatics', 'chemical models', 'cheminformatics', 'computer program /software', 'computers', 'data collection methodology /evaluation', 'data management', 'information retrieval', 'interdisciplinary collaboration', 'model design /development', 'molecular biology']",NHGRI,RENSSELAER POLYTECHNIC INSTITUTE,P20,2005,375639,0.011565251647832713
"Neuroimaging Neuroinformatics Training Program    DESCRIPTION (provided by applicant): This proposal is in response to PAR-03-034 ""Neuroinformatics Institutional Mentored Research Scientist Development Award (K12)."" The overarching goal of this application is to provide an excellent postdoctoral training program in neuroimaging neuroinformatics that capitalizes on the many strengths of the existing neuroscientists, informatics and imaging resources that our combined resources represent. Our proposed Neuroimaging Neuroinformatics Training Program (NNTP) is based upon a number of important strategic alliances. The first cornerstone of this effort is the existing HBP grants held by Dr. Anders Dale (R01 NS39581: Cortical-Surface-Based Brain Imaging) and Dr. David Kennedy (R01 NS34189: Anatomic Morphologic Analysis of MR Brain Images). These efforts span a wealth of technological developments, research and clinical application areas in the rapidly developing area of quantitative morphometric image analysis. A second and vital cornerstone is our association with the Harvard-MIT Division of Health Sciences and Technology (HST) Biomedical Informatics Program. This existing pre- and post-graduate academic program, within a world class biomedical engineering department, is an ideal setting for the development of a coordinated training effort in Neuroinformatics. The established track record in training skilled scientists in areas of informatics will prove invaluable in this new initiative. The third cornerstone is the combined clinical research opportunities afforded by the Harvard-wide biomedical imaging resources. These include the MGH/MIT/HST Athinoula A. Martinos Center for Biomedical Imaging, the Harvard Neuroimaging Center, the Surgical Planning Lab at Brigham and Women's Hospital, the Brain Morphology BIRN (Biomedical Informatics Research Network) and the MIT Artificial Intelligence Laboratory. Together, these active and vibrant programs provide for the best possible training opportunities in imaging science, computer science, clinical application areas, and cognitive neuroscience. A substantial and successful pool of internationally renowned mentors have agreed to participate in this program, and the combined resources provide the best possible exposure to all neuroimaging procedures and insure the capability to draw the highest caliber trainees. A plan for recruiting, selecting and monitoring trainees is proposed. This program will be an asset to the Neuroinformatics initiatives of the Human Brain Project by helping to prepare future scientists with advanced neuroinformatics skills         n/a",Neuroimaging Neuroinformatics Training Program,6870217,K12MH069281,"['bioimaging /biomedical imaging', 'bioinformatics', 'brain imaging /visualization /scanning', 'brain morphology', 'career', 'image processing', 'morphometry', 'neuroimaging', 'neurosciences', 'training']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,K12,2005,428924,9.683510653424107e-05
"CENTER OF EXCELLENCE IN PUBLIC HEALTH INFORMATICS    DESCRIPTION (provided by applicant): The University of Washington proposes to establish the Center of Excellence in Public Health Informatics: Improving the Public's Health through Information Integration. Partners include the Washington Department of Health, Kitsap County Health District, the Public Health Informatics Institute, and Inland Northwest Health Services. This Center will focus on three research topics: Project 1 (Surveillance Integration and Decision Support) will develop public health surveillance methods within the emerging health information infrastructure. We will: 1) develop methods by which regional health information organizations can enhance public health surveillance; 2) develop and evaluate a probabilistic decision support system classifier for disease surveillance; and 3) investigate the usability of a web survey-assessment system for population tracking and disease reporting. Project 2 (Customizable Knowledge Management Repository System for Prevention: Design, Development, and Evaluation) will develop an interactive digital knowledge management system to support the collection, management, and retrieval of public health documents, data, earning objects, and tools. The focus will be the development of tools, including concept mapping services that will provide rapid access to answers from a variety of key resources, including the ""gray literature"". The system will focus on the application of natural language processing and information visualization techniques. Components will include a knowledge repository system, integrative web services and a role-based user interface to support access to information resources for enhanced decision-making by practitioners. The long-term goal is to create an environment in which practitioners can pose questions in ""plain English"" and receive answers to their questions rather than simply a list of possible places to look for answers. Project 3 Supporting Integration: Work Process, Change Management and System Modeling) will: 1) refine and validate an integrated model of public health information technology work; 2) provide a Change Management Toolkit to support public health agencies in making changes to current practice called for by the integrated model; and 3) build a Virtual Public Health Information Technology Environment to serve as a testbed and to explore informatics challenges. These projects are supported by three cores: Administration Core (Core A), Epidemiology and Biostatistics Science Core (Core B), and Technology and Design Science Core (Core C).             n/a",CENTER OF EXCELLENCE IN PUBLIC HEALTH INFORMATICS,7084856,P01CD000261,[' '],ODCDC,UNIVERSITY OF WASHINGTON,P01,2005,1270432,-0.001515132626346383
"NEW DRUG TARGETS FOR APOPTOSIS DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",NEW DRUG TARGETS FOR APOPTOSIS,6848697,P01CA017094,"['antineoplastics', 'biomedical facility', 'chemosensitizing agent', 'clinical research', 'drug design /synthesis /production', 'drug resistance', 'drug screening /evaluation', 'neoplasm /cancer chemotherapy']",NCI,UNIVERSITY OF ARIZONA,P01,2005,1446246,-0.004638645201995156
"Integrated Neuroinformatics Resource for Alcoholism (IN* DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",Integrated Neuroinformatics Resource for Alcoholism (IN*,6943136,U01AA013524,"['alcoholic beverage consumption', 'alcoholism /alcohol abuse information system', 'bioinformatics', 'biomedical facility', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data collection methodology /evaluation', 'electrophysiology', 'neuroanatomy', 'neurochemistry', 'neurophysiology', 'neuroregulation', 'neurosciences']",NIAAA,UNIVERSITY OF COLORADO DENVER,U01,2005,467823,-0.0032650342507786964
"Computer cluster for computational biology DESCRIPTION (provided by applicant):    The present application aims to establish a computer Cluster for Computational Biology and Bioinformatic (CCBB). The cluster will consists of 256 dual nodes connected with Giganet switches to enable rapid communication between the processors. The cluster will enable the integration of the two approaches and make it possible to effectively address the highly demanding computational tasks of the field. It will serve a small group of investigators, supported by the NIH, and their close collaborators. The hardware needs of computational biology and bioinformatic applications, and of the team of investigators listed in this application can be summarized as follows:   1. Significant computer power for complex and expensive simulations.   2. Large storage capacity for the whole cluster (shared) and (separately) for the individual nodes.   3. Large and rapidly accessible memory for effective statistical analysis, application of machine learning techniques, and biological discovery.   4. Fast network for information updates across the network.   In addition CCBB will have high level of databases and software integration including   1. Updates of important ""mirrors"" of shared databases (such as NR, swissprot, human EST, human genome, protein databank, etc.)   2. Local installation and frequent upgrade of widely used software packages (e.g. BLAST, Pfam, CHARMm etc.)   3. Help in porting novel software for optimal use on the CCBB hardware platform.   The combined unification of optimal hardware and software for computational biology and bioinformatic will make the new cluster; an outstanding resource for NIH related research n/a",Computer cluster for computational biology,6877645,S10RR020889,"['bioinformatics', 'biomedical equipment purchase', 'computational biology', 'computer network', 'computer program /software', 'computer system hardware', 'computers']",NCRR,CORNELL UNIVERSITY ITHACA,S10,2005,500000,0.0018625193560247956
"Nation Center: Multi-Scale Study- Cellular Networks(RMI)    DESCRIPTION (provided by applicant):  A network of molecular interactions, involving many thousands of genes, their products, and other molecules, underlie cellular processes. Investigation of these interactions across a wide range of scales ranging from the formation/activation of transcriptional complexes, to the availability of a signaling pathway, all the way to macroscopic processes, such as cell adhesion, calls for a new level of sophistication in the design of genome- wide computational approaches. A homogeneous environment for the comprehensive mapping and analysis of molecular cellular interactions in would be a powerful resource for the biomedical research community. We propose the creation of a National Center for the Multiscale Analysis of Genomic and Cellular Networks (MAGNet). The Center will provide an integrative computational framework to organize molecular interactions in the cell into manageable context-dependent components and will develop interoperable computational models and tools that can leverage such a map of cellular interactions to elucidate important biological processes. Center activities will involve a significant, multidisciplinary effort of biological and computational sciences. Specific areas of expertise include natural language parsing (NLP), machine learning (ML), software systems and engineering, databases, computational structural biology, reverse engineering of genetic networks, biomedical literature datamining, and biomedical ontologies, among others. The Center will 1) construct an evidence integration framework to collect and fuse a variety of diverse cellular interaction clues based on their statistical relevance 2) assemble a comprehensive set of physics- and knowledge-based methodologies to fill this framework 3) provide a set of methodologies and filters, anchored in formal domain ontologies, to associated specific interactions to an organism, tissue, molecular, and cellular context. All relevant tools will be made accessible to the biomedical research community through a common, extensible, and interoperable software platform, geWorkbench. We will reach out to train and encourage researchers to use and/or develop new modules for, geWorkbench. An important element of the software platform will be the development of specific components that can exploit the evidence integration techniques developed by Core 9001 investigators to combine molecular interaction clues from Core 9002 algorithms and databases. Development will be both driven and tested by the biomedical community to ensure the usefulness of the tools and the usability of the graphical user interfaces to address biomedical problems in completely novel ways, to dissect the web of cellular interactions responsible for cellular processes and functions.         n/a",Nation Center: Multi-Scale Study- Cellular Networks(RMI),7012104,U54CA121852,"['bioinformatics', 'cell biology', 'computational biology', 'cooperative study', 'genome']",NCI,COLUMBIA UNIVERSITY HEALTH SCIENCES,U54,2005,3758967,-0.05462354393207588
"BioMediator: Biologic Data Integration& Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration& Analysis System,6805962,R01HG002288,"['artificial intelligence', 'bioengineering /biomedical engineering', 'computer program /software', 'computer system design /evaluation', 'data collection methodology /evaluation', 'information retrieval', 'molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2004,100000,0.0035528400301554235
"Markov Chain Monte Carlo and Exact Logistic Regression    DESCRIPTION (provided by applicant): Today, software for fitting logistic regression models to binary data belongs in the toolkit of every professional biostatistician, epidemiologist, and social scientist. A natural follow-up to this development is the adoption of exact logistic regression by mainstream biostatisticians and data analysts for any setting in which the accuracy of a statistical analysis based on large-sample maximum likelihood theory is in doubt. Cutting-edge researchers in biometry and numerous other fields have already recognized that it is necessary to supplement inference based on large-sample methods with exact inference for small, sparse and unbalanced data. The LogXact software package developed by Cytel Software Corporation fills this need. It has been used since its inception in 1993 to produce exact inferences for data generated from a wide range fields including clinical trials, epidemiology, disease surveillance, insurance, criminology, finance, accounting, sociology and ecology. In all these applications exact logistic regression was adopted because the limitations of the corresponding asymptotic procedures were clearly recognized in advance by the investigators and the exact inference was computationally feasible. But most of the time it will not be obvious whether asymptotic or exact methods are applicable. Ideally one would prefer to run both types of analyses if there is any doubt about the appropriateness of the asymptotic inference. However, because of the computational limits of the exact algorithms, investigators are currently inhibited from attempting the exact analysis. There is uncertainty about the how long the computations will take and even whether they will produce any results at all before the computer runs out of memory. The current project eliminates this uncertainty by introducing a new generation of numerical algorithms that utilize network based Monte Carlo rejection sampling. The Phase 1 progress report has demonstrated that these new algorithms can speed up the computations by factors of 50 to 1000 relative to what is currently available in LogXact. More importantly they can predict how long a job will take so that the user may decide whether to proceed at once or at a better time. The Phase 2 effort aims to incorporate this new generation of computing algorithms into future versions of LogXact.         n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6703756,R44CA093112,"['artificial intelligence', 'clinical research', 'computer data analysis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'human data', 'mathematical model', 'mathematics', 'statistics /biometry']",NCI,"CYTEL, INC",R44,2004,411387,0.005916392547085485
"AI Software for Science Education Related to Drug Abuse DESCRIPTION (provided by applicant): This Phase I SBIR proposal is aimed at advancing the state of the art in chemistry education software in a critically important respect demanded by students, teachers, administrators and Quantum Simulations, Inc. customers. The focus of this innovation is the development of meaningful interactive tutoring and assessment capabilities for chemistry problem solving. Empowerment of students to make the proper decisions about drugs through experiencing the scientific process requires a solid education in basic chemistry. Chemical formulas comprise much of the fundamental ""language"" of chemistry in which students must be fluent in order to succeed. The topic of writing and understanding chemical formulas, a cornerstone of all general chemistry classes, is a reasonable starting point for the development of an AI assessment system for student learning in chemistry. A solid understanding of chemical formulas is a prerequisite to success in chemistry required not only for literacy to make informed decisions about drugs from a scientific standpoint, but also to enable and prepare students to pursue careers in research related to drug abuse. Quantum has already successfully developed and commercialized an ITS for writing chemical formulas which will be used as the starting point for the present work. The proposed technology will benefit all students; however, it is specifically targeted to help those who have the greatest need, such as students of average or marginal performance and students from historically underserved groups, by lowering barriers to accessing high-quality science instructional software.  Quantum customers include textbook publishers, software providers, hardware vendors and distance learning companies. A prominent textbook publisher, Holt, Rinehart and Winston, has entered into two long-term contracts with Quantum, resulting in rapid dissemination to an established end user base. Quantum intends to employ an identical business model to commercialize the results of this project. n/a",AI Software for Science Education Related to Drug Abuse,6831228,R43DA018455,"['adolescence (12-20)', 'artificial intelligence', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'drug abuse education', 'educational resource design /development', 'human subject', 'science education']",NIDA,"QUANTUM SIMULATIONS, INC.",R43,2004,61750,-0.008897644133021637
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6777028,R01GM061372,"['Internet', 'artificial intelligence', 'automated data processing', 'biological signal transduction', 'biomedical automation', 'computer system design /evaluation', 'functional /structural genomics', 'high throughput technology', 'intermolecular interaction', 'method development', 'molecular biology information system', 'statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,341671,-0.009354626012519334
"Collaborative Brain Mapping: Tools for Sharing    DESCRIPTION (provided by applicant): Sharing data between research centers is increasingly important for contemporary brain imaging studies because they involve large numbers of subjects and complex analysis protocols that require highly specialized expertise. Our long-term objective is to facilitate brain-imaging research by enabling remote researchers to pool data between institutions and to analyze data using the appropriate algorithms executing on distributed resources. There are a number of difficult data management and technology challenges that have limited the success of data sharing environments. Rather than attempt to develop a comprehensive and general solution, we propose to develop a set of open, interoperable, and portable software tools that address critical issues currently limiting efforts to share and analyze brain-imaging data. Building upon years of providing brain-mapping expertise to collaborators, we propose to solve problems that we repeatedly encounter and that currently limit progress in brain imaging research. We propose to develop validated tools that enable collaborators to remotely access a variety of data analysis methods and databases. We will create web-based tools to perform multi-institutional studies, and provide access to complex data processing protocols executing on distributed computing resources. There are three specific aims. 1) Enable the web based acquisition and management of data utilizing an access control system that includes consideration of subject consent limits and investigator imposed conditions to facilitate data pooling for multi-institutional studies. This system will convert data files between different formats and schemas so that data can be used consistently between analysis programs and databases. It will also anonymize images and metadata according to institution-specific protocols. 2) Develop a system that is aware of data type and provenance so that it may act intelligently to arbitrate between different analysis programs. This system will capture the expertise of experienced lab personnel in the usage of various tools and assist new users in designing appropriate analytic strategies. 3) Create meta-algorithms that improve the robustness of techniques for neuroimaging analysis by intelligently combining the results from multiple algorithms. The proposed approach will provide a set of tools that address significant problems in data sharing and utilization. The resulting information technology will be scalable and applicable to other scientific data sharing problems.         n/a",Collaborative Brain Mapping: Tools for Sharing,6802141,R01MH071940,"['Internet', 'artificial intelligence', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain mapping', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'confidentiality', 'data management', 'information dissemination', 'information systems', 'mathematics']",NIMH,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2004,668796,-0.003489575315525928
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6936159,R01GM061372,"['Internet', 'artificial intelligence', 'automated data processing', 'biological signal transduction', 'biomedical automation', 'computer system design /evaluation', 'functional /structural genomics', 'high throughput technology', 'intermolecular interaction', 'method development', 'molecular biology information system', 'statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2004,52940,-0.009354626012519334
"Development of Bioinformatic Tools for Virtual Cloning  DESCRIPTION (provided by applicant): The elaboration of the sequences of the human genome and those of many cellular and viral parasites has given us an unprecedented opportunity to address the causes and treatment of every major human disease. It has also resulted in the formation of an entirely new field, bioinformatics, which promises to manage and analyze the vast amount of data being generated. Bioinformatics needs to supply tools for data analysis and tools for experimental design. Most of the scientific and corporate resources being expended in bioinformatics are being spent on data analysis tools. While these are essential, we should not neglect the opportunity to accelerate the progress of actual experimental biology. Essentially every experiment in biology now begins with cloning one or more pieces of DNA. Commercial software that facilitates virtual DNA cloning does exist, but it lacks any automation features and depends on primitive and/or fragmentary gene and vector databases. It is inadequate in planning the hundreds or thousands of clones necessary to address questions posed by the proteomics initiatives, because the lack of knowledge integration. In Phase I of this SBIR grant, we have built and tested a virtual cloning expert system, along with a very useful gene database and a uniquely annotated vector database that serve as a knowledge base for automated DNA manipulations. A collection of automated cloning modules and databases is now functional. In Phase II we will complete the virtual cloning expert system and develop a flexible platform for automated experimental design, data management and analysis. We will also construct a user database, improve the user interface and establish security protocols. The results will be a complete program suite as a stable and marketable product. n/a",Development of Bioinformatic Tools for Virtual Cloning,6788945,R44HG003506,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'computer assisted sequence analysis', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'data management', 'experimental designs', 'expression cloning', 'genetic library', 'high throughput technology', 'molecular biology information system', 'molecular cloning']",NHGRI,"VIRMATICS, LLC",R44,2004,375000,-0.011386790933521827
"Computational Approaches to Disease Causes and Treatment DESCRIPTION (provided by applicant): The State University of New York at Buffalo has assembled a multi-disciplinary team of investigators to plan and establish a National Program of Excellence in Biomedical Computing. The overall theme of the center is ""Novel Data Mining Algorithms for Applications in Genomics"" with a focus on the development of novel techniques for storing, managing, analyzing, modeling and visualizing multi-dimensional data sets. We intend to provide the expertise and infrastructure that will merge the research activities of computational and biomedical scientists. The focus of the proposed research is the study of common diseases, such as cancer, multiple sclerosis and coronary artery disease in which the underlying causes are multi-factorial. In this new paradigm, we will use advanced computational techniques and approaches to convert raw genomic data into knowledge that will advance the understanding of these common diseases and potentially identify new modalities of treatment. The Center will play a critical role in fostering multidisciplinary collaborations between faculty from the Departments of Computer Science and Engineering, Biology, Chemistry, Pharmaceutical Science and various departments in the School of Medicine and Biomedical Sciences. By co-locating biomedical and computer scientists, common understanding of research approaches will result in the development of computational tools that will meet the real-life needs of the biomedical researchers to help advance their projects. The Center will provide a broad range of educational and training activities for individuals who wish to pursue a career focusing on computational biology and bioinformatics. The focus of the education program will be the interdisciplinary training of computer science and engineering students who wish to pursue research in functional genomics and other biomedical areas, and the cross training of biomedically oriented students in topics with more of a computing orientation. We have identified three development projects that provide unique scientific opportunities to integrate the expertise of mathematicians, statisticians, and computer scientists with medical scientists, and to investigate novel computational approaches. These computational related projects are: 1. Data integration and data mining of clinical data and genomic data to advance clinical and epidemiological genetics as well as drug effect studies; 2. Pharmacodynamic analysis of drug-responsive gene expression changes; and 3. Chemi-genetic approaches to mapping regulatory pathways. These research projects will be supported by three core resources: genomics core, computational core, and clinical core. The common nature of these applications is that they all generate multidimensional data sets with numerical, functional or symbolic attributes. The management, retrieval and visualization of these data sets and analyses is likely to prove to be a rate limiting factor for new biomedical discoveries and the development of techniques for the effective analyses of genomic datasets is a critical step for the medical applications of bioinformatics. n/a",Computational Approaches to Disease Causes and Treatment,6787778,P20GM067650,"['animal tissue', 'artificial intelligence', 'bioinformatics', 'computational biology', 'computer data analysis', 'computer human interaction', 'computer simulation', 'computer system design /evaluation', 'data management', 'disease /disorder etiology', 'epidemiology', 'functional /structural genomics', 'gene expression', 'human subject', 'interdisciplinary collaboration', 'mathematical model', 'pharmacokinetics', 'science education', 'statistics /biometry', 'technology /technique development', 'therapy', 'training']",NIGMS,STATE UNIVERSITY OF NEW YORK AT BUFFALO,P20,2004,392500,0.01827216833899577
"Neuroimaging Neuroinformatics Training Program    DESCRIPTION (provided by applicant): This proposal is in response to PAR-03-034 ""Neuroinformatics Institutional Mentored Research Scientist Development Award (K12)."" The overarching goal of this application is to provide an excellent postdoctoral training program in neuroimaging neuroinformatics that capitalizes on the many strengths of the existing neuroscientists, informatics and imaging resources that our combined resources represent. Our proposed Neuroimaging Neuroinformatics Training Program (NNTP) is based upon a number of important strategic alliances. The first cornerstone of this effort is the existing HBP grants held by Dr. Anders Dale (R01 NS39581: Cortical-Surface-Based Brain Imaging) and Dr. David Kennedy (R01 NS34189: Anatomic Morphologic Analysis of MR Brain Images). These efforts span a wealth of technological developments, research and clinical application areas in the rapidly developing area of quantitative morphometric image analysis. A second and vital cornerstone is our association with the Harvard-MIT Division of Health Sciences and Technology (HST) Biomedical Informatics Program. This existing pre- and post-graduate academic program, within a world class biomedical engineering department, is an ideal setting for the development of a coordinated training effort in Neuroinformatics. The established track record in training skilled scientists in areas of informatics will prove invaluable in this new initiative. The third cornerstone is the combined clinical research opportunities afforded by the Harvard-wide biomedical imaging resources. These include the MGH/MIT/HST Athinoula A. Martinos Center for Biomedical Imaging, the Harvard Neuroimaging Center, the Surgical Planning Lab at Brigham and Women's Hospital, the Brain Morphology BIRN (Biomedical Informatics Research Network) and the MIT Artificial Intelligence Laboratory. Together, these active and vibrant programs provide for the best possible training opportunities in imaging science, computer science, clinical application areas, and cognitive neuroscience. A substantial and successful pool of internationally renowned mentors have agreed to participate in this program, and the combined resources provide the best possible exposure to all neuroimaging procedures and insure the capability to draw the highest caliber trainees. A plan for recruiting, selecting and monitoring trainees is proposed. This program will be an asset to the Neuroinformatics initiatives of the Human Brain Project by helping to prepare future scientists with advanced neuroinformatics skills         n/a",Neuroimaging Neuroinformatics Training Program,6700018,K12MH069281,"['bioimaging /biomedical imaging', 'bioinformatics', 'brain imaging /visualization /scanning', 'brain morphology', 'career', 'image processing', 'morphometry', 'neuroimaging', 'neurosciences', 'training']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,K12,2004,311472,9.683510653424107e-05
"Integrated Neuroinformatics Resource for Alcoholism (IN* DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",Integrated Neuroinformatics Resource for Alcoholism (IN*,6795323,U01AA013524,"['alcoholic beverage consumption', 'alcoholism /alcohol abuse information system', 'bioinformatics', 'biomedical facility', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data collection methodology /evaluation', 'electrophysiology', 'neuroanatomy', 'neurochemistry', 'neurophysiology', 'neuroregulation', 'neurosciences']",NIAAA,UNIVERSITY OF COLORADO DENVER,U01,2004,754129,-0.0032650342507786964
"NEW DRUG TARGETS FOR APOPTOSIS DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",NEW DRUG TARGETS FOR APOPTOSIS,6699330,P01CA017094,"['antineoplastics', 'biomedical facility', 'chemosensitizing agent', 'clinical research', 'drug design /synthesis /production', 'drug resistance', 'drug screening /evaluation', 'neoplasm /cancer chemotherapy']",NCI,UNIVERSITY OF ARIZONA,P01,2004,1405759,-0.004638645201995156
"BioMediator: Biologic Data Integration & Analysis System DESCRIPTION (provided by applicant):    The broad long-term objectives of this proposal are to collaborate with a group of biology researchers with real world needs to develop and distribute a general-purpose system (BioMediator) to permit integration and analysis of diverse types of biologic data. BioMediator will combine information from a variety of different public and private sources (e.g. experimental data) to help answer biologic questions. BioMediator builds on the foundations laid by the currently funded GeneSeek data integration system. The GeneSeek system was originally developed to query only public domain data sources (both structured and semi-structured) to assist in the curation of the GeneClinics genetic testing knowledge base. The specific aims leading to the development of the BioMediator system are: 1) Interface to additional public domain biological data sources (e.g. pathway databases, function databases). 2) Incorporate access to private databases of experimental results (e.g. proteomics and expression array data). 3) Extend model to include analytic tools operating across distributed biological data sources (e.g. across a set of both proteomic and expression array data). 4) Evolve centralized BioMediator system into a model peer to peer data sharing and analysis system. 5) Distribute and maintain BioMediator production software as a resource for the biological community. The health relatedness of the project is that biologists seeking to understand the molecular basis of human health and disease are struggling with large and increasing volumes of diverse data (mutation, expression array, proteomic) that need to be brought together (integrated) and analyzed in order to develop and test hypotheses about disease mechanisms and normal physiology. The research design is to develop BioMediator by combining and leverage recent developments in a) the domain of open source analytic tools for biologic data and b) ongoing theoretical and applied research by members of the current GeneSeek research team on both general purpose and biologic data integration systems. The methods are:  a) to use an iterative rapid prototyping software development model evaluated in a real-world test bed and b) to expand the existing GeneSeek research team (with expertise in informatics, computer science, and software development) to include biological expertise (four biologists forming a biology working group) and biostatistics expertise. The goal is to ensure the BioMediator system 1) meets the needs of a group of end users acquiring, integrating and analyzing diverse biologic data sets, 2) does so in a scaleable and expandable manner drawing on the latest theoretical developments in data analysis and integration. n/a",BioMediator: Biologic Data Integration & Analysis System,6681249,R01HG002288,"['artificial intelligence', ' bioengineering /biomedical engineering', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' information retrieval', ' molecular biology information system']",NHGRI,UNIVERSITY OF WASHINGTON,R01,2003,100000,0.0035528400301554235
"Markov Chain Monte Carlo and Exact Logistic Regression    DESCRIPTION (provided by applicant): Today, software for fitting logistic regression models to binary data belongs in the toolkit of every professional biostatistician, epidemiologist, and social scientist. A natural follow-up to this development is the adoption of exact logistic regression by mainstream biostatisticians and data analysts for any setting in which the accuracy of a statistical analysis based on large-sample maximum likelihood theory is in doubt. Cutting-edge researchers in biometry and numerous other fields have already recognized that it is necessary to supplement inference based on large-sample methods with exact inference for small, sparse and unbalanced data. The LogXact software package developed by Cytel Software Corporation fills this need. It has been used since its inception in 1993 to produce exact inferences for data generated from a wide range fields including clinical trials, epidemiology, disease surveillance, insurance, criminology, finance, accounting, sociology and ecology. In all these applications exact logistic regression was adopted because the limitations of the corresponding asymptotic procedures were clearly recognized in advance by the investigators and the exact inference was computationally feasible. But most of the time it will not be obvious whether asymptotic or exact methods are applicable. Ideally one would prefer to run both types of analyses if there is any doubt about the appropriateness of the asymptotic inference. However, because of the computational limits of the exact algorithms, investigators are currently inhibited from attempting the exact analysis. There is uncertainty about the how long the computations will take and even whether they will produce any results at all before the computer runs out of memory. The current project eliminates this uncertainty by introducing a new generation of numerical algorithms that utilize network based Monte Carlo rejection sampling. The Phase 1 progress report has demonstrated that these new algorithms can speed up the computations by factors of 50 to 1000 relative to what is currently available in LogXact. More importantly they can predict how long a job will take so that the user may decide whether to proceed at once or at a better time. The Phase 2 effort aims to incorporate this new generation of computing algorithms into future versions of LogXact.         n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6587476,R44CA093112,"['artificial intelligence', ' clinical research', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' human data', ' mathematical model', ' mathematics', ' statistics /biometry']",NCI,CYTEL SOFTWARE CORPORATION,R44,2003,400084,0.005916392547085485
"Computer Systems for Functional Analysis of Genomic Data DESCRIPTION (provided by applicant):    We propose computational approaches aiding automated compilation of molecular networks from research literature, cleansing of the resulting database, and assessing reliability of facts stored in the database.         n/a",Computer Systems for Functional Analysis of Genomic Data,6685421,R01GM061372,"['Internet', ' artificial intelligence', ' automated data processing', ' biological signal transduction', ' biomedical automation', ' computer system design /evaluation', ' functional /structural genomics', ' high throughput technology', ' intermolecular interaction', ' method development', ' molecular biology information system', ' statistics /biometry']",NIGMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2003,323936,-0.009354626012519334
"Intelligent Information Systems for Systems Biology DESCRIPTION (Provided by Applicant): Our Center will attack the challenges created by the large quantity of data generated from new high throughput technologies. We have teamed biologists, computer scientists and computational scientists from several Universities to build an experienced and distinguished team. Our first major tool building project will be an Object Oriented Framework for the integration of data and tools for genomics, proteomics, DNA arrays and protein-protein interactions. This tool will follow the data from the source through model building. It will build on existing open source tools such as a data acquisition package from particle physics (ROOT), a public database system (MYSQL or PostgreSQL), statistics tools (""R""), graphics libraries, a variety of software tools that have been developed at ISB and new tools needed for the new technologies. We stress the use of an open source system as a means to build the community, creating a functioning system that can be tailored for research and education. We then propose to augment this system with tools for analysis, visualization and model building. We will use yeast as a model system owing to the wide range of data that it available for it. Finally, we propose some novel educational programs designed to put graduate students together into interdisciplinary teams for problem solving. n/a",Intelligent Information Systems for Systems Biology,6646557,P20GM064361,"['analytical method', ' artificial intelligence', ' biotechnology', ' computer program /software', ' data management', ' educational resource design /development', ' functional /structural genomics', ' high throughput technology', ' mathematical model', ' method development', ' microarray technology', ' model design /development', ' molecular biology', ' molecular biology information system', ' protein protein interaction', ' proteomics', ' technology /technique development', ' yeasts']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,P20,2003,237000,0.01394006820344659
"Computational Approaches to Disease Causes and Treatment DESCRIPTION (provided by applicant): The State University of New York at Buffalo has assembled a multi-disciplinary team of investigators to plan and establish a National Program of Excellence in Biomedical Computing. The overall theme of the center is ""Novel Data Mining Algorithms for Applications in Genomics"" with a focus on the development of novel techniques for storing, managing, analyzing, modeling and visualizing multi-dimensional data sets. We intend to provide the expertise and infrastructure that will merge the research activities of computational and biomedical scientists. The focus of the proposed research is the study of common diseases, such as cancer, multiple sclerosis and coronary artery disease in which the underlying causes are multi-factorial. In this new paradigm, we will use advanced computational techniques and approaches to convert raw genomic data into knowledge that will advance the understanding of these common diseases and potentially identify new modalities of treatment. The Center will play a critical role in fostering multidisciplinary collaborations between faculty from the Departments of Computer Science and Engineering, Biology, Chemistry, Pharmaceutical Science and various departments in the School of Medicine and Biomedical Sciences. By co-locating biomedical and computer scientists, common understanding of research approaches will result in the development of computational tools that will meet the real-life needs of the biomedical researchers to help advance their projects. The Center will provide a broad range of educational and training activities for individuals who wish to pursue a career focusing on computational biology and bioinformatics. The focus of the education program will be the interdisciplinary training of computer science and engineering students who wish to pursue research in functional genomics and other biomedical areas, and the cross training of biomedically oriented students in topics with more of a computing orientation. We have identified three development projects that provide unique scientific opportunities to integrate the expertise of mathematicians, statisticians, and computer scientists with medical scientists, and to investigate novel computational approaches. These computational related projects are: 1. Data integration and data mining of clinical data and genomic data to advance clinical and epidemiological genetics as well as drug effect studies; 2. Pharmacodynamic analysis of drug-responsive gene expression changes; and 3. Chemi-genetic approaches to mapping regulatory pathways. These research projects will be supported by three core resources: genomics core, computational core, and clinical core. The common nature of these applications is that they all generate multidimensional data sets with numerical, functional or symbolic attributes. The management, retrieval and visualization of these data sets and analyses is likely to prove to be a rate limiting factor for new biomedical discoveries and the development of techniques for the effective analyses of genomic datasets is a critical step for the medical applications of bioinformatics. n/a",Computational Approaches to Disease Causes and Treatment,6690235,P20GM067650,"['animal tissue', ' artificial intelligence', ' computer data analysis', ' computer human interaction', ' computer simulation', ' computer system design /evaluation', ' data management', ' disease /disorder etiology', ' epidemiology', ' functional /structural genomics', ' gene expression', ' human subject', ' informatics', ' interdisciplinary collaboration', ' mathematical model', ' pharmacokinetics', ' science education', ' statistics /biometry', ' technology /technique development', ' therapy', ' training']",NIGMS,STATE UNIVERSITY OF NEW YORK AT BUFFALO,P20,2003,392500,0.01827216833899577
"NEW DRUG TARGETS FOR APOPTOSIS DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",NEW DRUG TARGETS FOR APOPTOSIS,6626535,P01CA017094,"['antineoplastics', ' biomedical facility', ' chemosensitizing agent', ' drug design /synthesis /production', ' drug resistance', ' drug screening /evaluation', ' neoplasm /cancer chemotherapy']",NCI,UNIVERSITY OF ARIZONA,P01,2003,1357166,-0.004638645201995156
"Integrated Neuroinformatics Resource for Alcoholism (IN* DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",Integrated Neuroinformatics Resource for Alcoholism (IN*,6647589,U01AA013524,"['alcoholic beverage consumption', ' alcoholism /alcohol abuse information system', ' biomedical facility', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' cooperative study', ' data collection methodology /evaluation', ' electrophysiology', ' neuroanatomy', ' neurochemistry', ' neurophysiology', ' neuroregulation', ' neurosciences']",NIAAA,UNIVERSITY OF COLORADO DENVER,U01,2003,729100,-0.0032650342507786964
"MIDDLE SCHOOL LIFE SCIENCE-EDUCATION PARTNERSHIP-PHASE I   DESCRIPTION (Adapted from the applicant's abstract):  Scientists associated          with the National Institute of Environmental Health Sciences (NIEHS) Marine          and Freshwater Biomedical Sciences Center and professionals within the               University of Wisconsin-Milwaukee (UWM) School of Education will establish a         collaborative relationship with several Milwaukee metropolitan schools.  The         long range objective is to develop a significant program to enhance the              quality of the curriculum and instruction for students enrolled in middle            school Life Science.  There are two primary thrusts.  The first involves the         creation of a number of experiment modules that relate to the biomedical             content of the course and which are designed to stimulate inquiry-based              learning.  At their center is the utilization of non-mammalian organisms in          the classroom.  Enrichment is provided with interactive videotape/CD-ROM             materials that engage students with subject matter that cannot be brought into       their classrooms.  The second emphasis provides in-service teachers with a           network of support that increases their knowledge, understanding, and ability        to conduct laboratory experiments.  It also offers pre-service teachers in           training an opportunity to develop a strong foundation in life science.  The         Specific Aims are:  A) to provide teachers with a suite of fully developed           modules that emphasize hands-on, modern biomedical science; B) to surround the       modules with support materials that utilize information technology; C) to            provide a scientific community for teachers through workshops and meetings; D)       to enhance the ability of teachers to facilitate critical thinking among             students; E) to support teachers in distance learning, including interactions        with scientists, teachers, and inter-classroom communication; F) to encourage        female and minority interest and success in science; G) to initiate a model          program to enhance life science education for pre-service teachers; and H) to        provide thorough evaluation of the effectiveness of these aims.                                                                                                           n/a",MIDDLE SCHOOL LIFE SCIENCE-EDUCATION PARTNERSHIP-PHASE I,6529842,R25RR014267,"['DVD /CD ROM', ' artificial intelligence', ' curriculum', ' education evaluation /planning', ' educational resource design /development', ' ethnic group', ' female', ' learning', ' meeting /conference /symposium', ' minority health professional', ' science education', ' secondary schools', ' social support network', ' teacher', ' university student', ' videotape /videodisc']",NCRR,UNIVERSITY OF WISCONSIN MILWAUKEE,R25,2002,269200,0.027449338283734283
"Intelligent Information Systems for Systems Biology DESCRIPTION (Provided by Applicant): Our Center will attack the challenges created by the large quantity of data generated from new high throughput technologies. We have teamed biologists, computer scientists and computational scientists from several Universities to build an experienced and distinguished team. Our first major tool building project will be an Object Oriented Framework for the integration of data and tools for genomics, proteomics, DNA arrays and protein-protein interactions. This tool will follow the data from the source through model building. It will build on existing open source tools such as a data acquisition package from particle physics (ROOT), a public database system (MYSQL or PostgreSQL), statistics tools (""R""), graphics libraries, a variety of software tools that have been developed at ISB and new tools needed for the new technologies. We stress the use of an open source system as a means to build the community, creating a functioning system that can be tailored for research and education. We then propose to augment this system with tools for analysis, visualization and model building. We will use yeast as a model system owing to the wide range of data that it available for it. Finally, we propose some novel educational programs designed to put graduate students together into interdisciplinary teams for problem solving. n/a",Intelligent Information Systems for Systems Biology,6526274,P20GM064361,"['analytical method', ' artificial intelligence', ' biotechnology', ' computer program /software', ' data management', ' educational resource design /development', ' functional /structural genomics', ' high throughput technology', ' mathematical model', ' method development', ' microarray technology', ' model design /development', ' molecular biology', ' molecular biology information system', ' protein protein interaction', ' proteomics', ' technology /technique development', ' yeasts']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,P20,2002,237000,0.01394006820344659
"Integrated Neuroinformatics Resource for Alcoholism (IN* DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",Integrated Neuroinformatics Resource for Alcoholism (IN*,6533705,U01AA013524,"['alcoholic beverage consumption', ' alcoholism /alcohol abuse information system', ' biomedical facility', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' cooperative study', ' data collection methodology /evaluation', ' electrophysiology', ' neuroanatomy', ' neurochemistry', ' neurophysiology', ' neuroregulation', ' neurosciences']",NIAAA,UNIVERSITY OF COLORADO DENVER,U01,2002,688297,-0.0032650342507786964
"NEW DRUG TARGETS FOR APOPTOSIS DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",NEW DRUG TARGETS FOR APOPTOSIS,6489015,P01CA017094,"['antineoplastics', ' biomedical facility', ' chemosensitizing agent', ' drug design /synthesis /production', ' drug resistance', ' drug screening /evaluation', ' neoplasm /cancer chemotherapy']",NCI,UNIVERSITY OF ARIZONA,P01,2002,1329187,-0.004638645201995156
"LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE   DESCRIPTION (Adapted from Applicant's Abstract): Morphometric tools developed        under this grant combine techniques from geometry, computer vision, statistics,      and biomathematics in powerful new strategies for analysis of data about size        and shape. This fourth funding period is directed to three extensions of the         established core methodology, along with continued dissemination. Aim 1.             Thin-plate spline interpolant aids the scientist's eye in detecting                  localization of interesting shape differences. Over the present funding period       the applicants reported having developed an algebraic/statistical formalization      of this tactic, the method of creases. Aim 1 of the renewal is to standardize        the parameterization of this feature, to provide protocols for significance          tests, and to produce ""a grammar of grids"" for uniting multiple creases into         coherent summaries of empirical deformations. Aim 2. The standard Procrustes         methods for discrete point landmarks have been extended for data sets of             outlines. Aim 2 of the renewal is to further extend these tools for realistic        data sets that combine discrete point landmarks and curves or surfaces               arbitrarily. The applicants proposed to formalize statistical spaces for such        structures and extend them to anticipate the emerging resource of neural tract       directional data (directions without curves). Aim 3. The best current                strategies for formal statistical inferences about shape exploit permutation         tests of Procrustes distance or its modifications. Under new Aim 3, the              applicants proposed to combine this approach with spline-based high-pass or          low-pass filters and extend it further to support studies of correlations of         shape with other measurement sets, including other aspects of shape. Finally,        as it has been for the past twelve years, Aim 4 is to continue bringing all          these methodological developments to the attention of many different biomedical      communities, by primary scientific papers, essays on methodology per se,             videotapes, and software and documentation free over the Internet. The work          proposed is expected to extend to the medical imaging community's most               sophisticated data resources, carefully labeled images and volumes, a                state-of-the-art biometric toolkit for analysis and visualization carefully          tuned to the special needs of such data.                                                                                                                                  n/a",LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE,6525584,R01GM037251,"['bioimaging /biomedical imaging', ' cardiovascular system', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' craniofacial', ' human data', ' image processing', ' mathematical model', ' morphology', ' neuroanatomy', ' statistics /biometry']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2002,128860,0.0028338883259016634
"Markov Chain Monte Carlo and Exact Logistic Regression   DESCRIPTION (provided by applicant): Logistic regression is a very popular           model for the analysis of binary data with widespread applicability in the           physical, behavioral and biomedical sciences. Parameter inference for this           model is usually based on maximizing the unconditional likelihood function.          However unconditional maximum likelihood inference can produce inconsistent          point estimates, inaccurate p-values and inaccurate confidence intervals for         small or unbalanced data sets and for data sets with a large number of               parameters relative to the number of observations. Sometimes the method fails        entirely as no estimates can be found that maximize the unconditional                likelihood function. A methodologically sound alternative approach that has          none of the aforementioned drawbacks is the exact conditional approach in which      one generates the permutation distributions of the sufficient statistics for         the parameters of interest conditional on fixing the sufficient statistics of        the remaining nuisance parameters at their observed values. The major stumbling      block to this approach is the heavy computational burden it imposes. Monte           Carlo methods attempt to overcome this problem by sampling from the reference        set of possible permutations instead of enumerating them all. Two competing          Monte Carlo methods are network based sampling and Markov Chain Monte Carlo          (MCMC) sampling. Network sampling suffers from memory limitations while MCMC         sampling can produce incorrect results if the Markov chain is not ergodic or if      the process is not in the steady state. We propose a novel approach which            combines the network and MCMC sampling, draws upon the strengths of each of          them and overcomes their individual limitations. We propose to implement this        hybrid network-MCMC method in our LogXact software and as an external procedure      in the SAS system.                                                                   PROPOSED COMMERCIAL APPLICATION:  There is great demand for logistic regression software that can handle small, sparse or  unbalanced data sets by exact methods.  Our LogXact package is the only software that  can provide exact inference for data sets which are not ""toy problems"".  Yet even  LogXact quickly breaks down on moderate sized problems.  The new generation of hybrid  network-MCMC algorithms will handle substantially larger problems that nevertheless need  exact inference.  The commercial potential is considerable since such data sets are common  in scientific studies.                                                                                      n/a",Markov Chain Monte Carlo and Exact Logistic Regression,6404971,R43CA093112,"['artificial intelligence', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' mathematics', ' statistics /biometry']",NCI,CYTEL SOFTWARE CORPORATION,R43,2001,113111,0.00011836455877265878
"MIDDLE SCHOOL LIFE SCIENCE-EDUCATION PARTNERSHIP-PHASE I   DESCRIPTION (Adapted from the applicant's abstract):  Scientists associated          with the National Institute of Environmental Health Sciences (NIEHS) Marine          and Freshwater Biomedical Sciences Center and professionals within the               University of Wisconsin-Milwaukee (UWM) School of Education will establish a         collaborative relationship with several Milwaukee metropolitan schools.  The         long range objective is to develop a significant program to enhance the              quality of the curriculum and instruction for students enrolled in middle            school Life Science.  There are two primary thrusts.  The first involves the         creation of a number of experiment modules that relate to the biomedical             content of the course and which are designed to stimulate inquiry-based              learning.  At their center is the utilization of non-mammalian organisms in          the classroom.  Enrichment is provided with interactive videotape/CD-ROM             materials that engage students with subject matter that cannot be brought into       their classrooms.  The second emphasis provides in-service teachers with a           network of support that increases their knowledge, understanding, and ability        to conduct laboratory experiments.  It also offers pre-service teachers in           training an opportunity to develop a strong foundation in life science.  The         Specific Aims are:  A) to provide teachers with a suite of fully developed           modules that emphasize hands-on, modern biomedical science; B) to surround the       modules with support materials that utilize information technology; C) to            provide a scientific community for teachers through workshops and meetings; D)       to enhance the ability of teachers to facilitate critical thinking among             students; E) to support teachers in distance learning, including interactions        with scientists, teachers, and inter-classroom communication; F) to encourage        female and minority interest and success in science; G) to initiate a model          program to enhance life science education for pre-service teachers; and H) to        provide thorough evaluation of the effectiveness of these aims.                                                                                                           n/a",MIDDLE SCHOOL LIFE SCIENCE-EDUCATION PARTNERSHIP-PHASE I,6446869,R25RR014267,"['DVD /CD ROM', ' artificial intelligence', ' curriculum', ' education evaluation /planning', ' educational resource design /development', ' ethnic group', ' female', ' learning', ' meeting /conference /symposium', ' minority health professional', ' science education', ' secondary schools', ' social support network', ' teacher', ' university student', ' videotape /videodisc']",NCRR,UNIVERSITY OF WISCONSIN MILWAUKEE,R25,2001,269200,0.027449338283734283
"PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS DESCRIPTION (Taken from application abstract):  Over the last decade             computational modeling has become central to neurobiology.  While much of        this work has focused on cellular and sub-cellular processes, the last few       years have seen increasing interest in systems level models and in               integrative accounts that span data from the subcellular to behavioral           levels.  Our proposal, in summary, is to extend existing work in parallel        discrete event simulation (PDES) and integrate it with existing work on          compartmental modeling environments, to produce a software environment which     has comprehensive support for modeling large scale, highly structured            networks of biophysically realistic cells; and which can efficiently exploit     the full range of parallel platforms, including the largest parallel             supercomputers, for simulation of these network models, which integrate          information about the nervous system from sub-cellular to the whole-brain        level.  Because of the scale of the models needed at this level of               integration, advanced parallel computing is required.  The critical              technical insight upon which this work rests is that neuronal modeling at        the systems level can often be reduced to a form of discrete event               simulation in which single cells are node functions and voltage spikes are       events.                                                                                                                                                           Three neuroscience modeling projects, will mold, test, and utilize these new     capabilities in investigations of system-level models of the nervous system      which integrate behavioral, anatomical and physiological data on a scale         that exceeds current simulation capabilities.  In collaboration with             computer scientists at Pittsburgh Supercomputing Center and UCLA,                neuroscientists at University of Virginia, the Born-Bunge Foundation,            Antwerp, and the Salk Institute, and developers of the NEURON and GENESIS        packages, these tools will be developed and made available to the                neuroscience community.  The software development aims include 1)                investigation of a portable, PDES system capable of running efficiently on       diverse parallel platforms, 2) development of interfaces to the PDES for         NEURON and GENESIS allowing models developed in those packages to be scaled      up, 3) investigation of a network specification language for neuronal            models, and associated a visualization interface, to facilitate                  investigation of systems-level models, 4) sufficiently robust and                well-documented software for download and installation at other sites.  The      three neuroscience projects will guide development of the software tools and     use the tools for investigation of large-scale models of cerebellum,             hippocampus and thalamocortical circuits.                                         n/a",PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS,6392266,R01MH057358,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biotechnology', ' cerebellar cortex', ' computational neuroscience', ' computer network', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' hippocampus', ' mathematical model', ' neural information processing', ' neurotransmitters', ' parallel processing', ' supercomputer', ' thalamocortical tract', ' vocabulary development for information system']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2001,232139,-0.016939337420692202
"Intelligent Information Systems for Systems Biology DESCRIPTION (Provided by Applicant): Our Center will attack the challenges created by the large quantity of data generated from new high throughput technologies. We have teamed biologists, computer scientists and computational scientists from several Universities to build an experienced and distinguished team. Our first major tool building project will be an Object Oriented Framework for the integration of data and tools for genomics, proteomics, DNA arrays and protein-protein interactions. This tool will follow the data from the source through model building. It will build on existing open source tools such as a data acquisition package from particle physics (ROOT), a public database system (MYSQL or PostgreSQL), statistics tools (""R""), graphics libraries, a variety of software tools that have been developed at ISB and new tools needed for the new technologies. We stress the use of an open source system as a means to build the community, creating a functioning system that can be tailored for research and education. We then propose to augment this system with tools for analysis, visualization and model building. We will use yeast as a model system owing to the wide range of data that it available for it. Finally, we propose some novel educational programs designed to put graduate students together into interdisciplinary teams for problem solving. n/a",Intelligent Information Systems for Systems Biology,6401728,P20GM064361,"['analytical method', ' artificial intelligence', ' biotechnology', ' computer program /software', ' data management', ' educational resource design /development', ' functional /structural genomics', ' high throughput technology', ' mathematical model', ' method development', ' microarray technology', ' model design /development', ' molecular biology', ' molecular biology information system', ' protein protein interaction', ' proteomics', ' technology /technique development', ' yeasts']",NIGMS,INSTITUTE FOR SYSTEMS BIOLOGY,P20,2001,237000,0.01394006820344659
"Educational Tools for Neuroscience   DESCRIPTION (provided by applicant): SHAI proposes to bring two instructional        technologies together to compliment neuroscience lectures and distance               learning. Specifically we want to embed Computer Simulations of experiments and      the chemical, genetic, and physiological systems that underlie them within an        Intelligent Tutoring System. Simulations are excellent tools for revealing the       structure and dynamics of systems to students. They can also serve as a basis        of interactive experiments where students can ""discover"" the answers to              questions. Intelligent Tutoring Systems (ITS) are an emerging educational            technology based on artificial intelligence research. They play the role of          tutor, in that they guide students with appropriate information or                   demonstrations when they are having difficulty with a lesson. They also              adaptively plan the presentation of new lessons based on evaluations of a            student's past performance and knowledge level. The objective of this phase I        proposal is to develop a prototype of NeuroTutor, a simulation-based ITS to          provide students with individualized instruction in a simulation centered            environment. Steps to reaching this objective include designing a curriculum,        developing instructional, presentations and support, developing appropriate          methods for Student Modeling and Diagnosis, and implementing a limited               prototype.                                                                           PROPOSED COMMERCIAL APPLICATION:  This project has a sizeable commercialization potential.  Medical schools and university  neuroscience courses from a significant market.  Moreover the technologies to be   developed are transferable to other domains in the natural and social sciences, business  and medicine.  The technologies used are appropriate for use in distance learning programs,  and can be used by individuals to educate themselves.                                                                                     n/a",Educational Tools for Neuroscience,6403961,R43MH065842,"['computer assisted instruction', ' computer simulation', ' educational resource design /development', ' interactive multimedia', ' neurobiology', ' science education']",NIMH,"STOTTLER HENKE ASSOCIATES, INC.",R43,2001,100000,0.023386287793875048
"Integrated Neuroinformatics Resource for Alcoholism (IN* DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",Integrated Neuroinformatics Resource for Alcoholism (IN*,6449653,U01AA013524,"['alcoholic beverage consumption', ' alcoholism /alcohol abuse information system', ' biomedical facility', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' cooperative study', ' data collection methodology /evaluation', ' electrophysiology', ' neuroanatomy', ' neurochemistry', ' neurophysiology', ' neuroregulation', ' neurosciences']",NIAAA,UNIVERSITY OF COLORADO DENVER,U01,2001,658874,-0.0032650342507786964
"NEW DRUG TARGETS FOR APOPTOSIS DESCRIPTION (provided by applicant): The aim of this proposal is to establish an Integrated Neuroinformatics Resource on Alcoholism (INRA) as the informatics core component of the Integrative Neuroscience Initiative on Alcoholism Consortium (INIA). The overall goal of the INRA will be to create an integrated, multiresolution repository of neuroscience data, ranging from molecules to behavior for collaborative research on alcoholism. As the neuroinformatics core of the INIAC, the INRA will enable the integration of all data generated by all components of the INIAC. Furthermore, it will support synthesis of new knowledge through computational neurobiology tools for exploratory analysis including visualization, data mining and simulation. The INRA will represent a synthesis of emerging approaches in bioinformatics and existing methods of neuroinformatics to provide the INIAC a versatile toolbox of computational methods for elucidating the effects of alcohol on the nervous system. The specific aims of the INRA will be: (i) implementation of an informatics infrastructure for integrating complex neuroscience data, from molecules to behavior, generated by the consortium and relevant data available in the public domain; (ii) development of an integrated secure web-based environment so that consortium members can interactively visualize, search and update the integrated neuroscience knowledge; and (iii) development of data mining tools, including biomolecular sequence analysis, gene expression array analysis, characterization of Biochemical pathways, and natural language processing to support hypothesis generation and testing regarding ethanol Consumption and neuroadaptation to alcohol. We will also collaborate with related neuroscience projects to utilize existing resources for brain atlases, neuronal circuits and neuronal properties. The INRA will The made available to the INIAC through a Neb-based system through interactive graphical user interfaces that will seamlessly integrate tools for data entry, modification, search, retrieval and mining. The core of the INRA will be based on robust knowledge management methods and tools that will Effectively integrate disparate forms of neuroscience data and make it amenable to complex inferences. Our proposed strategy ensures that the informatics resource is: (i) flexible and scalable to address the evolving needs of the INIAC, and (ii) highly intuitive and user-friendly to ensure optimal utilization by the INIAC members. The proposed INRA is a novel system for Collaborative research in neuroscience and alcoholism which will be developed by an interdisciplinary team of experts in Bioinformatics, computational biology, neuroscience and alcoholism research. We believe the INRA will greatly enhance the Dace of discovery in the area of ethanol consumption and neuroadaptation to alcohol within the INIAC as well as the general research community. n/a",NEW DRUG TARGETS FOR APOPTOSIS,6230917,P01CA017094,"['antineoplastics', ' biomedical facility', ' chemosensitizing agent', ' drug design /synthesis /production', ' drug resistance', ' drug screening /evaluation', ' neoplasm /cancer chemotherapy']",NCI,UNIVERSITY OF ARIZONA,P01,2001,1291932,-0.004638645201995156
"LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE   DESCRIPTION (Adapted from Applicant's Abstract): Morphometric tools developed        under this grant combine techniques from geometry, computer vision, statistics,      and biomathematics in powerful new strategies for analysis of data about size        and shape. This fourth funding period is directed to three extensions of the         established core methodology, along with continued dissemination. Aim 1.             Thin-plate spline interpolant aids the scientist's eye in detecting                  localization of interesting shape differences. Over the present funding period       the applicants reported having developed an algebraic/statistical formalization      of this tactic, the method of creases. Aim 1 of the renewal is to standardize        the parameterization of this feature, to provide protocols for significance          tests, and to produce ""a grammar of grids"" for uniting multiple creases into         coherent summaries of empirical deformations. Aim 2. The standard Procrustes         methods for discrete point landmarks have been extended for data sets of             outlines. Aim 2 of the renewal is to further extend these tools for realistic        data sets that combine discrete point landmarks and curves or surfaces               arbitrarily. The applicants proposed to formalize statistical spaces for such        structures and extend them to anticipate the emerging resource of neural tract       directional data (directions without curves). Aim 3. The best current                strategies for formal statistical inferences about shape exploit permutation         tests of Procrustes distance or its modifications. Under new Aim 3, the              applicants proposed to combine this approach with spline-based high-pass or          low-pass filters and extend it further to support studies of correlations of         shape with other measurement sets, including other aspects of shape. Finally,        as it has been for the past twelve years, Aim 4 is to continue bringing all          these methodological developments to the attention of many different biomedical      communities, by primary scientific papers, essays on methodology per se,             videotapes, and software and documentation free over the Internet. The work          proposed is expected to extend to the medical imaging community's most               sophisticated data resources, carefully labeled images and volumes, a                state-of-the-art biometric toolkit for analysis and visualization carefully          tuned to the special needs of such data.                                                                                                                                  n/a",LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE,6385653,R01GM037251,"['bioimaging /biomedical imaging', ' cardiovascular system', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' craniofacial', ' human data', ' image processing', ' mathematical model', ' morphology', ' neuroanatomy', ' statistics /biometry']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2001,127154,0.0028338883259016634
"DEVELOPMENT OF SPATIAL SOFTWARER This SBIR project will develop software for identifying and correcting spatial patterns in data for a wide range of alcohol-related phenomenon including alcohol consumption, problematic outcomes, and treatment modalities. Identifying and correcting statistical relationships in spatially configured data sets would be invaluable to alcohol-related research, the overall health community, and even to most social scientists (and biomedical researchers). Ecological models or models with locational components that provide unbiased estimates and increased predictive performance enhance the researcher' ability to identify new patterns within alcohol-related phenomenon. While spatial analysis has been widely researched and is a proven statistical technique, commercially available software with reasonable diagnostics and commonly used regression techniques does not yet exist. This phase I project addresses this need and will pursue three objectives: (1) Research and increase the capabilities of the current software package, (2) Design interfaces easily useable (friendly) for alcohol researchers, and (3) Improve the speed and efficiency of the core code. The proposed software development will provide powerful diagnostic and corrective tool in the analysis of mapped data describing relationships between space and alcohol- related phenomenon. PROPOSED COMMERCIAL APPLICATIONS: The need for identifying and adjusting for spatial autocorrelation in alcohol- related data sets is huge (see page 21) and so there is a large market for the proposed statistical software. The proposed package is expected to provide an easy to use, speedy, and comprehensive tool relative to current packages.  n/a",DEVELOPMENT OF SPATIAL SOFTWARER,6073824,R43AA012373,"['alcoholism /alcohol abuse', ' artificial intelligence', ' computer data analysis', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' data collection methodology /evaluation', ' mathematics', ' statistics /biometry']",NIAAA,S-THREE DEVELOPMENT,R43,2000,129935,-0.036061449043022685
"TOOLS TO SUPPORT COMPUTER BASED CLINICAL GUIDELINES DESCRIPTION (Adapted from the applicant's abstract):                                                                                                              The proposed research will build, refine, and test in operational use, a set     of software tools designed to help support, maintain, and iteratively            revalidate computer-based clinical guidelines as they evolve over time.  The     project will focus on the domain of childhood immunization, and will build       upon IMM/Serve, a childhood immunization forecasting program that takes as       input a child's immunization history, and produces recommendations as to         which vaccinations are due and which vaccinations should be scheduled next.      The effort required to modify and validate such a program as the clinical        field evolves over time is a challenging task.  It will be extremely             important to have a robust set of tools to assist in this process.  Partial      prototype versions of certain of these tools already exist.                                                                                                       1.  The project will refine and extend computer-based tools for immunization     knowledge maintenance.  These tools will include:  a) IMM/Def, a program         which automatically generates the rule-based logic for the most complex          portion (""kernel"") of IMM/Serve's knowledge, and b) IMM/Test, a program          which automatically generates a set of test cases to help test the kernel        logic.  The project will also develop an organized set of strategies for         immunization test case generation, and implement those strategies in the         refined version of IMM/Test.                                                                                                                                      2.  The project will build a Web site to support immunization knowledge          maintenance.                                                                                                                                                      3.  The project will keep a detailed record of all modifications and             customization of the knowledge, and will represent all the variations of the     knowledge using a standardized format such as GLIF, the Guideline                Interchange Format being developed as a standard for exchanging guidelines       between sites.                                                                                                                                                    4.  The project will link IMM/Serve to a database designed to hold               IMM/Serve's analysis of a set of cases, so that the resulting package can be     used as a tool to perform compliance assessment.                                                                                                                  5.  A set of evaluation studies will be carried out to help assess the           efficacy of the tools and to help improve their functionality.                    n/a",TOOLS TO SUPPORT COMPUTER BASED CLINICAL GUIDELINES,6185229,R01LM006682,"['Internet', ' artificial intelligence', ' computer assisted medical decision making', ' computer assisted patient care', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' human data', ' immunization', ' information systems', ' medical records', ' pediatrics']",NLM,YALE UNIVERSITY,R01,2000,317318,-0.008537906914176312
"MIDDLE SCHOOL LIFE SCIENCE-EDUCATION PARTNERSHIP-PHASE I   DESCRIPTION (Adapted from the applicant's abstract):  Scientists associated          with the National Institute of Environmental Health Sciences (NIEHS) Marine          and Freshwater Biomedical Sciences Center and professionals within the               University of Wisconsin-Milwaukee (UWM) School of Education will establish a         collaborative relationship with several Milwaukee metropolitan schools.  The         long range objective is to develop a significant program to enhance the              quality of the curriculum and instruction for students enrolled in middle            school Life Science.  There are two primary thrusts.  The first involves the         creation of a number of experiment modules that relate to the biomedical             content of the course and which are designed to stimulate inquiry-based              learning.  At their center is the utilization of non-mammalian organisms in          the classroom.  Enrichment is provided with interactive videotape/CD-ROM             materials that engage students with subject matter that cannot be brought into       their classrooms.  The second emphasis provides in-service teachers with a           network of support that increases their knowledge, understanding, and ability        to conduct laboratory experiments.  It also offers pre-service teachers in           training an opportunity to develop a strong foundation in life science.  The         Specific Aims are:  A) to provide teachers with a suite of fully developed           modules that emphasize hands-on, modern biomedical science; B) to surround the       modules with support materials that utilize information technology; C) to            provide a scientific community for teachers through workshops and meetings; D)       to enhance the ability of teachers to facilitate critical thinking among             students; E) to support teachers in distance learning, including interactions        with scientists, teachers, and inter-classroom communication; F) to encourage        female and minority interest and success in science; G) to initiate a model          program to enhance life science education for pre-service teachers; and H) to        provide thorough evaluation of the effectiveness of these aims.                                                                                                           n/a",MIDDLE SCHOOL LIFE SCIENCE-EDUCATION PARTNERSHIP-PHASE I,6360111,R25RR014267,"['DVD /CD ROM', ' artificial intelligence', ' curriculum', ' education evaluation /planning', ' educational resource design /development', ' ethnic group', ' female', ' learning', ' meeting /conference /symposium', ' minority health professional', ' science education', ' secondary schools', ' social support network', ' teacher', ' university student', ' videotape /videodisc']",NCRR,UNIVERSITY OF WISCONSIN MILWAUKEE,R25,2000,269199,0.027449338283734283
"MIDDLE SCHOOL LIFE SCIENCE-EDUCATION PARTNERSHIP-PHASE I   DESCRIPTION (Adapted from the applicant's abstract):  Scientists associated          with the National Institute of Environmental Health Sciences (NIEHS) Marine          and Freshwater Biomedical Sciences Center and professionals within the               University of Wisconsin-Milwaukee (UWM) School of Education will establish a         collaborative relationship with several Milwaukee metropolitan schools.  The         long range objective is to develop a significant program to enhance the              quality of the curriculum and instruction for students enrolled in middle            school Life Science.  There are two primary thrusts.  The first involves the         creation of a number of experiment modules that relate to the biomedical             content of the course and which are designed to stimulate inquiry-based              learning.  At their center is the utilization of non-mammalian organisms in          the classroom.  Enrichment is provided with interactive videotape/CD-ROM             materials that engage students with subject matter that cannot be brought into       their classrooms.  The second emphasis provides in-service teachers with a           network of support that increases their knowledge, understanding, and ability        to conduct laboratory experiments.  It also offers pre-service teachers in           training an opportunity to develop a strong foundation in life science.  The         Specific Aims are:  A) to provide teachers with a suite of fully developed           modules that emphasize hands-on, modern biomedical science; B) to surround the       modules with support materials that utilize information technology; C) to            provide a scientific community for teachers through workshops and meetings; D)       to enhance the ability of teachers to facilitate critical thinking among             students; E) to support teachers in distance learning, including interactions        with scientists, teachers, and inter-classroom communication; F) to encourage        female and minority interest and success in science; G) to initiate a model          program to enhance life science education for pre-service teachers; and H) to        provide thorough evaluation of the effectiveness of these aims.                                                                                                           n/a",MIDDLE SCHOOL LIFE SCIENCE-EDUCATION PARTNERSHIP-PHASE I,2885219,R25RR014267,"['DVD /CD ROM', ' artificial intelligence', ' curriculum', ' education evaluation /planning', ' educational resource design /development', ' ethnic group', ' female', ' learning', ' meeting /conference /symposium', ' minority health professional', ' science education', ' secondary schools', ' social support network', ' teacher', ' university student', ' videotape /videodisc']",NCRR,UNIVERSITY OF WISCONSIN MILWAUKEE,R25,2000,1,0.027449338283734283
"PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS DESCRIPTION (Taken from application abstract):  Over the last decade             computational modeling has become central to neurobiology.  While much of        this work has focused on cellular and sub-cellular processes, the last few       years have seen increasing interest in systems level models and in               integrative accounts that span data from the subcellular to behavioral           levels.  Our proposal, in summary, is to extend existing work in parallel        discrete event simulation (PDES) and integrate it with existing work on          compartmental modeling environments, to produce a software environment which     has comprehensive support for modeling large scale, highly structured            networks of biophysically realistic cells; and which can efficiently exploit     the full range of parallel platforms, including the largest parallel             supercomputers, for simulation of these network models, which integrate          information about the nervous system from sub-cellular to the whole-brain        level.  Because of the scale of the models needed at this level of               integration, advanced parallel computing is required.  The critical              technical insight upon which this work rests is that neuronal modeling at        the systems level can often be reduced to a form of discrete event               simulation in which single cells are node functions and voltage spikes are       events.                                                                                                                                                           Three neuroscience modeling projects, will mold, test, and utilize these new     capabilities in investigations of system-level models of the nervous system      which integrate behavioral, anatomical and physiological data on a scale         that exceeds current simulation capabilities.  In collaboration with             computer scientists at Pittsburgh Supercomputing Center and UCLA,                neuroscientists at University of Virginia, the Born-Bunge Foundation,            Antwerp, and the Salk Institute, and developers of the NEURON and GENESIS        packages, these tools will be developed and made available to the                neuroscience community.  The software development aims include 1)                investigation of a portable, PDES system capable of running efficiently on       diverse parallel platforms, 2) development of interfaces to the PDES for         NEURON and GENESIS allowing models developed in those packages to be scaled      up, 3) investigation of a network specification language for neuronal            models, and associated a visualization interface, to facilitate                  investigation of systems-level models, 4) sufficiently robust and                well-documented software for download and installation at other sites.  The      three neuroscience projects will guide development of the software tools and     use the tools for investigation of large-scale models of cerebellum,             hippocampus and thalamocortical circuits.                                         n/a",PARALLEL SIMULATION OF LARGE SCALE NEURONAL MODELS,6186179,R01MH057358,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' biotechnology', ' cerebellar cortex', ' computational neuroscience', ' computer network', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' hippocampus', ' mathematical model', ' neural information processing', ' neurotransmitters', ' parallel processing', ' supercomputer', ' thalamocortical tract', ' vocabulary development for information system']",NIMH,CARNEGIE-MELLON UNIVERSITY,R01,2000,234591,-0.016939337420692202
"LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE   DESCRIPTION (Adapted from Applicant's Abstract): Morphometric tools developed        under this grant combine techniques from geometry, computer vision, statistics,      and biomathematics in powerful new strategies for analysis of data about size        and shape. This fourth funding period is directed to three extensions of the         established core methodology, along with continued dissemination. Aim 1.             Thin-plate spline interpolant aids the scientist's eye in detecting                  localization of interesting shape differences. Over the present funding period       the applicants reported having developed an algebraic/statistical formalization      of this tactic, the method of creases. Aim 1 of the renewal is to standardize        the parameterization of this feature, to provide protocols for significance          tests, and to produce ""a grammar of grids"" for uniting multiple creases into         coherent summaries of empirical deformations. Aim 2. The standard Procrustes         methods for discrete point landmarks have been extended for data sets of             outlines. Aim 2 of the renewal is to further extend these tools for realistic        data sets that combine discrete point landmarks and curves or surfaces               arbitrarily. The applicants proposed to formalize statistical spaces for such        structures and extend them to anticipate the emerging resource of neural tract       directional data (directions without curves). Aim 3. The best current                strategies for formal statistical inferences about shape exploit permutation         tests of Procrustes distance or its modifications. Under new Aim 3, the              applicants proposed to combine this approach with spline-based high-pass or          low-pass filters and extend it further to support studies of correlations of         shape with other measurement sets, including other aspects of shape. Finally,        as it has been for the past twelve years, Aim 4 is to continue bringing all          these methodological developments to the attention of many different biomedical      communities, by primary scientific papers, essays on methodology per se,             videotapes, and software and documentation free over the Internet. The work          proposed is expected to extend to the medical imaging community's most               sophisticated data resources, carefully labeled images and volumes, a                state-of-the-art biometric toolkit for analysis and visualization carefully          tuned to the special needs of such data.                                                                                                                                  n/a",LANDMARK BASED METHODS FOR BIOMETRIC ANALYSIS OF SHAPE,6180399,R01GM037251,"['bioimaging /biomedical imaging', ' cardiovascular system', ' computer data analysis', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' craniofacial', ' human data', ' image processing', ' mathematical model', ' morphology', ' neuroanatomy', ' statistics /biometry']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2000,150497,0.0028338883259016634
"Center for Machine Learning in Urology PROJECT SUMMARY We propose to establish an Exploratory Center for Interdisciplinary Research in Benign Urology at the Children’s Hospital of Philadelphia (CHOP) and the University of Pennsylvania (Penn), the central mission of which is to apply machine learning to improve the understanding of the pathophysiology, diagnosis, risk stratification, and prediction of treatment responses of benign urological disease among children and adults. The proposed CHOP/Penn Center for Machine Learning in Urology (CMLU) addresses critical structural and scientific barriers that impede the development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. Structurally, urologic research occurs in silos, with little interaction among investigators that study different diseases or different populations (e.g. pediatric and adult). Scientifically, analysis of imaging and other types complex data is limited by inter-observer variability, and incomplete utilization of available information. This proposal overcomes these barriers by applying cutting-edge approaches in machine learning to analyze CT images that are routinely obtained for evaluation of individuals with kidney stone disease. Central to the CHOP/Penn CMLU is the partnership of urologists and experts in machine learning, which will bring a new approach to generating knowledge that advances research and clinical care. In addition, the CMLU will expand the urologic research community by providing a research platform and standalone machine learning executables that could be applied to other datasets. The Center’s mission will be achieved through the following Aims, with progress assessed through systematic evaluation: Aim 1. To expand the research base investigating benign urological disease. We will establish a community with the research base, particularly with the KURe, UroEpi programs, other P20 Centers, and O’Brien Centers. We will build this community by providing mini-coaching clinics to facilitate application of machine learning to individual projects, developing an educational hub for synchronous and asynchronous engagement with the research base, and making freely available all source codes and standalone executables for all machine learning tools. Aim 2. To improve prediction of ureteral stone passage using machine learning of CT images. The CMLU has developed deep learning methods that segment and automate measurement of urinary stones and adjacent renal anatomy. In the Research Project, we will compare these methods to existing segmentation methods and the current gold standard of manual measurement. We will then extract informative features from thousands of CT scans to predict the probability of spontaneous passage of ureteral stones for children and adults evaluated in the CHOP and Penn healthcare systems. Aim 3. To foster collaboration in benign urological disease research across levels of training and centers through an Educational Enrichment Program. We will amplify interactions across institutions and engage investigators locally and nationally by providing summer research internships, and interinstitutional exchange program, and an annual research symposium. PROJECT NARRATIVE The proposed CHOP/Penn O’Brien Center for Machine Learning in Urology addresses critical structural and scientific barriers that impede development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. This application overcomes these barriers by applying cutting- edge approaches in machine learning to analyze complex imaging data for individuals with kidney stone disease.The Center’s strategic vision of using machine learning to generate knowledge that improves diagnosis, risk stratification strategies, and prediction of outcomes among children and adults will be achieved through the implementation of a Educational Enrichment Program and a Research Project.",Center for Machine Learning in Urology,10133362,P20DK127488,"['Address', 'Adult', 'Algorithms', 'Anatomy', 'Area', 'Benign', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Investigator', 'Code', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Educational Status', 'Evaluation', 'Fostering', 'Functional disorder', 'Funding', 'Future', 'Gold', 'Healthcare Systems', 'Image', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internships', 'Interobserver Variability', 'Investigation', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Lead', 'Longevity', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Mission', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pediatric Hospitals', 'Pennsylvania', 'Philadelphia', 'Population', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Probability', 'Publishing', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk stratification', 'Site', 'Source Code', 'Structure', 'Students', 'Techniques', 'United States National Institutes of Health', 'Universities', 'Urinary Calculi', 'Urologic Diseases', 'Urologist', 'Urology', 'Vision', 'Visit', 'X-Ray Computed Tomography', 'base', 'clinical care', 'complex data ', 'deep learning', 'deep neural network', 'design', 'experience', 'feature selection', 'human error', 'improved', 'interdisciplinary collaboration', 'interest', 'learning strategy', 'novel strategies', 'outcome prediction', 'peer', 'programs', 'routine imaging', 'senior faculty', 'skills', 'summer research', 'symposium', 'tool', 'urologic', 'web page']",NIDDK,CHILDREN'S HOSP OF PHILADELPHIA,P20,2020,358890,-0.021737130263653922
"Creating an initial ethics framework for biomedical data modeling by mapping and exploring key decision points Project Summary Biomedical data science data modeling is relevant to a plethora of informatics research activities, such as natural language processing, machine learning, artificial intelligence, and predictive analytics. As Electronic Health Record systems become more advanced and more mature, with the potential to incorporate a wide and diverse array of data from genomics to mobile health (mHealth) applications, the scope and nature of the biomedical data science questions researchers ask become broader. Concomitantly, the answers to their questions have the potential to impact the care of millions of patients—getting the answers right, proactively, is high stakes. However, in data modeling currently, there is no bioethics framework to guide the process of mapping key decision points and recording the rationale for choices made. Making data modeling decision points, as well as the reasoning behind them, explicit would have a twofold impact on improving biomedical data science by: 1. Enhancing transparency and reproducibility and maximizing the value of data science research and 2. Supporting the ability to assess decision points and rationales in terms of their most crucial ethical ramifications. Research in this area is particularly timely amid the interest in, and enthusiasm for, leveraging Big Data sources in the service of improving patient population health and the health of the general public. The National Institutes of Health (NIH) recently released a strategic plan for data science; there is no better time than now to create an initial bioethical framework to inform common data modeling decision points. The improvements in data quality that will derive from decision point mapping and bioethical review will enhance efforts to apply data models across a range of high-impact areas, from predictive analytics to support clinical decision-making to robust trending models in population health to better inform local, regional, and national health policies and resource allocation. To develop this initial bioethics framework, we will use well- established qualitative research methods (interviews, focus groups, and in-person deliberation) to map the decision points in biomedical data modeling research and document the rationales invoked to support those decisions (Aim 1 key informant interviews); assess those data science decision points and decision-making rationales for their bioethical ramifications (Aim 2 focus groups); and create an initial bioethics data modeling framework (Aim 3 deliberative meeting). This study would be the first to provide a bioethics framework to meet a critical gap in biomedical data modeling activities, where the downstream consequences of developing data models without careful and comprehensive review of ethical issues can be severe. This approach directly supports core scientific values of inclusivity, transparency, accountability, and reproducibility that, in turn, foster trust in biomedical data modeling output and potential applications, whether local, national, or global. Project Narrative This study would be the first to develop an initial bioethics framework to meet a critical gap in biomedical data modeling activities, where the downstream consequences of developing data models without careful and comprehensive review of ethical issues can be severe—not least because poorly developed data models have the potential to impact adversely the health of individuals, groups, and communities. Currently, there is limited conversation around potential bioethics issues in data modeling, and as yet no implementable guidance on how biomedical data science modeling research activities should occur. The initial ethics framework developed by this study would provide a roadmap to ensure that data modeling decision points are documented and their ethical ramifications considered at the outset of model creation, thus supporting core scientific values of inclusivity, accountability, reproducibility, and transparency that, in turn, foster trust in biomedical data modeling output and potential applications, whether local, national, or global.",Creating an initial ethics framework for biomedical data modeling by mapping and exploring key decision points,10039527,R21HG011277,"['Accountability', 'Address', 'Area', 'Artificial Intelligence', 'Big Data', 'Bioethical Issues', 'Bioethics', 'Bioethics Consultants', 'Caring', 'Clinical', 'Communities', 'Data', 'Data Science', 'Data Scientist', 'Data Sources', 'Decision Making', 'Development', 'Electronic Health Record', 'Ensure', 'Ethical Issues', 'Ethical Review', 'Ethics', 'Focus Groups', 'Fostering', 'General Population', 'Health', 'Health Resources', 'Health system', 'Individual', 'Informatics', 'Interview', 'Machine Learning', 'Maps', 'Methods', 'Mobile Health Application', 'Modeling', 'National Health Policy', 'Natural Language Processing', 'Nature', 'Output', 'Patients', 'Persons', 'Play', 'Predictive Analytics', 'Process', 'Qualitative Research', 'Reproducibility', 'Research', 'Research Activity', 'Research Methodology', 'Research Personnel', 'Resource Allocation', 'Role', 'Services', 'Social Environment', 'Strategic Planning', 'Structure', 'System', 'Time', 'Trust', 'United States National Institutes of Health', 'Walking', 'base', 'biomedical data science', 'clinical decision support', 'clinical decision-making', 'data modeling', 'data quality', 'data tools', 'ethical legal social implication', 'genomic data', 'high standard', 'improved', 'individual patient', 'informant', 'interest', 'interoperability', 'meetings', 'model development', 'patient population', 'population health', 'programs', 'public trust', 'tool', 'trend', 'usability']",NHGRI,"HASTINGS CENTER, INC.",R21,2020,100000,-0.01424802568834235
"Neuroethical analysis of data sharing in the OpenNeuro project: Administrative supplement PROJECT SUMMARY/ABSTRACT Data sharing is essential to maximize the contributions of research subjects and the public’s investment in scientific research, but human subjects research also requires strong protection of the privacy and confidentiality of research subjects. This supplement will support an expert in neuroethics to undertake a rigorous ethical and regulatory analysis of data sharing policies, focusing in particular on the threats by artificial intelligence and machine learning techniques to reidentify neuroimaging datasets that have been thought to be deidentified. This research will lay the foundation for a sound data sharing policy for the OpenNeuro project and a regulatory framework to provide for the adequate protection of neuroimaging data while maximizing the benefits of data sharing. Project Narrative Data sharing is essential to maximize the contributions of research subjects and the public’s investment in scientific research, but human subjects research also requires strong protection of the privacy and confidentiality of research subjects. This supplement will support an expert in neuroethics to undertake a rigorous ethical and regulatory analysis of data sharing policies, focusing in particular on the threats by artificial intelligence and machine learning techniques to reidentify neuroimaging datasets that have been thought to be deidentified. This research will lay the foundation for a sound data sharing policy for the OpenNeuro project and a regulatory framework to provide for the adequate protection of neuroimaging data while maximizing the benefits of data sharing",Neuroethical analysis of data sharing in the OpenNeuro project: Administrative supplement,10149058,R24MH117179,"['Address', 'Administrative Supplement', 'Archives', 'Artificial Intelligence', 'Award', 'BRAIN initiative', 'Benefits and Risks', 'Consent Forms', 'Country', 'Data', 'Data Analyses', 'Data Security', 'Data Set', 'Ensure', 'Ethics', 'Foundations', 'Funding', 'Future', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Subject Research', 'International', 'Investments', 'Laws', 'Legal', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Neurosciences', 'Parents', 'Policies', 'Privacy', 'Process', 'Regulation', 'Research', 'Research Subjects', 'Risk', 'Security Measures', 'Series', 'Software Tools', 'Solid', 'Surveys', 'Techniques', 'United States', 'United States National Institutes of Health', 'data archive', 'data privacy', 'data sharing', 'design', 'human subject', 'human subject protection', 'machine learning algorithm', 'neuroethics', 'neuroimaging', 'novel', 'prevent', 'privacy protection', 'research study', 'sharing platform', 'sound', 'stem']",NIMH,STANFORD UNIVERSITY,R24,2020,126592,0.004260423621294848
"Big Data Predictive Phylogenetics with Bayesian Learning Big Data Predictive Phylogenetics with Bayesian Learning Abstract Andrew Holbrook, Ph.D., is a Bayesian statistician with a broad background in applied, theoretical and compu- tational data science. His proposed research Big Data Predictive Phylogenetics with Bayesian Learning tackles viral outbreak forecasting by combining Bayesian phylogenetic modeling with ﬂexible, `self-exciting' stochastic process models. The development and publication of open-source, high-performance computing software for his models will facilitate fast epidemiological ﬁeld response in a big data setting. Dr. Holbrook will apply his method- ology to the reconstruction of the 2015-2016 Zika virus epidemic in the Americas, focusing on identifying key geographical routes of transmission and phylogenetic clades with enhanced infectiousness.  Candidate: Dr. Holbrook is Postdoctoral Scholar at the UCLA Department of Human Genetics. He earned his Ph.D. in Statistics from the Department of Statistics at UC Irvine, during which time he completed his dissertation Geometric Bayes, an investigation into Bayesian modeling and computing on abstract mathematical spaces, and simultaneously participated in scientiﬁc collaborations at the UC Irvine Alzheimer's Disease Research Center. The proposed career development plan will establish Dr. Holbrook as an independent leader in data intensive viral epidemiology by 1) facilitating coursework to build biological domain knowledge, 2) affording Dr. Holbrook the opportunity to lead his own project while remaining under the expert oversight of UCLA Prof. Marc Suchard, M.D., Ph.D., and 3) allowing Dr. Holbrook to continue his focus on quantitative viral epidemiology once he has moved to a faculty commitment.  Mentors: During the ﬁrst three years of the award period, Dr. Holbrook will work closely with Prof. Suchard, continuing their current schedule of weekly meetings. Prof. Suchard is a leading expert in both Bayesian phylo- genetics and high-performance statistical computing; and with his medical background, Prof. Suchard will advise Dr. Holbrook in his expansion of domain knowledge in viral epidemiology. As secondary mentor, Prof. Kristian Andersen, Ph.D., of the Scripps Institute will advise Dr. Holbrook in the impactful application of his statistical and computational methodologies to the 2015-2016 Zika virus epidemic. Dr. Holbrook and Profs. Suchard and Andersen will maintain their collaborations after the postdoctoral period.  Research: Bayesian phylogenetics successfully reconstructs evolutionary histories but fails to predict viral spread. Self-exciting point processes are devoid of biological insight and fail to account for geographic networks of diffusion. Aim 1 addresses deﬁciencies in these two complementary viral epidemiological modeling techniques by innovating a combined model where the phylogenetic and self-excitatory components support each other. Aim 2 makes widespread adoption a reality by publishing open-source, massively parallel computing software suitable for big data analysis. Aim 3 reconstructs the 2015-2016 Zika epidemic, learns key geographical routes of transmission and identiﬁes phylogenetic clades with enhanced infectiousness. Project Narrative Tracking and predicting viral outbreaks remains an open epidemiological problem with deadly consequences. Dr. Holbrook will attack the problem with his Bayesian phylogenetic Hawkes processes, a class of models tailored to simultaneously reconstruct evolutionary histories and predict viral diffusion dynamics. With the mentorship of Profs. Marc Suchard (primary) and Kristian Andersen (secondary), Dr. Holbrook will develop open-source, high-performance computing software and apply his statistical computing methodology to the analysis of the 2015-2016 Zika virus epidemic of the Americas, learning key routes of transmission and identifying phylogenetic clades with enhanced infectiousness.",Big Data Predictive Phylogenetics with Bayesian Learning,10039150,K25AI153816,"['Accounting', 'Address', 'Adoption', 'Air', 'Alzheimer&apos', 's Disease', 'Americas', 'Award', 'Bayesian Modeling', 'Bayesian learning', 'Behavior', 'Big Data', 'Biological', 'Biology', 'Collaborations', 'Complex', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Dangerousness', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Development Plans', 'Diffusion', 'Disease Outbreaks', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evolution', 'Faculty', 'Failure', 'Free Will', 'Generations', 'Geography', 'Goals', 'Health', 'Herd Immunity', 'High Performance Computing', 'Human Genetics', 'Individual', 'Influenza', 'Institutes', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Mathematics', 'Medical', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Process', 'Publications', 'Publishing', 'Recording of previous events', 'Research', 'Route', 'Schedule', 'Scientist', 'Ships', 'Speed', 'Statistical Computing', 'Stochastic Processes', 'Structure', 'Techniques', 'Testing', 'Time', 'Travel', 'Viral', 'Viral Epidemiology', 'Viral Physiology', 'Work', 'ZIKA', 'Zika Virus', 'blind', 'career development', 'epidemiological model', 'flexibility', 'innovation', 'insight', 'meetings', 'novel', 'open source', 'parallel computer', 'pathogen', 'reconstruction', 'response', 'statistics', 'transmission process']",NIAID,UNIVERSITY OF CALIFORNIA LOS ANGELES,K25,2020,106467,-0.0024489150902847713
"Training a new generation of computational neuroscientists bridging neurobiology The Training Program in Computational Neuroscience (TPCN) will support integrated undergraduate and graduate training in computational neuroscience at New York University. The program will be hosted by the Center for Neural Science (CNS), with participation of faculty in the Departments of Psychology, Mathematics, and Computer Science, and the Institute of Neuroscience at the School of Medicine. The TPCN will fit well with NYU’s unique strengths and recent developments: (1) NYU is one of a few universities with a critical mass of computational neuroscientists. NYU has had a Sloan-Swartz Center for Theoretical Neuroscience since 1994. In the past three years alone, NYU has hired three computational neuroscientists. (2) CNS established an undergraduate major in neuroscience as early as 1992, and thus has a long track record in undergraduate education, it now has 136 students in the current academic year. (3) Recent faculty hiring in CNS, Psychology, and the School of Medicine has greatly expanded our teaching and research capabilities in the neuroscience of cognitive functions and their impairments associated with mental disorders. (3) As NYU is undertaking a merge of two historically separated neuroscience graduate programs (at CNS and the School of Medicine), this training grant will ensure that computational modeling, which has become indispensible in neuroscience, will be front-and-center in the integrated graduate program. (4) NYU is a major center of Artificial Intelligence and Data Science, with close links to Facebook’s AI Center and the Simons Center for Data Analysis. Our training faculty together with these connections will give our students ample opportunities to acquire machine learning techniques for data analysis and learn about brain-like AI algorithms. The proposed training program will support coherent undergraduate and graduate training in computational neuroscience at NYU. It will have several unique features: (1) Innovative mentorship methods: For example, (a) graduate trainees will mentor undergraduate trainees, (b) faculty will explicitly discuss human factors in academic practice; (c) there will be post-mortems after seminars by outside speakers. (2) Computational psychiatry: We propose new courses and research opportunities that are designed specifically to link cognitive function and the neurobiology of neural circuits. We propose innovative education in the nascent field of Computational Psychiatry, to bring theory and circuit modeling to clinical research in mental health. (3) Broad preparation: We aim to prepare trainees for jobs not only in academia, but also in medical and industry research. To achieve this, we will utilize our strength in machine learning and data science to broaden computational neuroscience training. The Program Directors have complementary strengths and will have complementary roles in the program. Wang will supervise graduate trainees and focus on training in mechanistic/circuit-level side of computational neuroscience as well as computational psychiatry. Ma will supervise undergraduate trainees and focus on the computational/behavioral side. This grant will support training of a new generation of graduate and undergraduate students in  computational neuroscience, which has become increasingly important to meet the challenges of  making discoveries with new data analysis tools and of understanding highly nonlinear complex  neural circuits. A salient component of our program is training in the nascent field  of   Computational  Psychiatry,  bridging  basic  neuroscience  and clinical research on mental  disorders. Therefore, the proposed program has the potential of making  a significant impact on  mental health.",Training a new generation of computational neuroscientists bridging neurobiology,10002209,R90DA043849,"['Academia', 'Algorithms', 'Artificial Intelligence', 'Behavioral', 'Brain', 'Clinical Research', 'Computer Models', 'Data Analyses', 'Data Science', 'Development', 'Education', 'Educational process of instructing', 'Ensure', 'Facebook', 'Faculty', 'Generations', 'Grant', 'Human', 'Impairment', 'Industry', 'Institutes', 'Learning', 'Link', 'Machine Learning', 'Medical', 'Mental Health', 'Mental disorders', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Neurobiology', 'Neurosciences', 'New York', 'Occupations', 'Preparation', 'Psychiatry', 'Psychology', 'Research', 'Role', 'Science', 'Side', 'Students', 'Supervision', 'Teacher Professional Development', 'Techniques', 'Training', 'Training Programs', 'Universities', 'cognitive function', 'cognitive neuroscience', 'computational neuroscience', 'computer science', 'design', 'innovation', 'mathematical sciences', 'medical schools', 'neural circuit', 'programs', 'relating to nervous system', 'theories', 'undergraduate education', 'undergraduate student']",NIDA,NEW YORK UNIVERSITY,R90,2020,100690,0.03594438421696144
"ClientBot: A conversational agent that supports skills practice and feedback for Motivational Interviewing for AUD PROJECT SUMMARY/ABSTRACT  Millions of Americans are in need of evidence-based counseling, such as motivational interviewing (MI), for alcohol use disorders (AUDs) each year. To develop competence in an evidence-based practice like MI, trainees require ample opportunities for practice and immediate, performance-based feedback on the skills that they are learning. However, this is challenging if not impossible to offer at scale -- to the large number of providers in need of training. Opportunities for practice typically rely on roleplays with other trainees with limited experience, and feedback requires either direct supervision from an expert trainer or behavioral coding from a trained coding team; these are costly, limited, and time consuming. AI-based technology can meet this need, generating many opportunities for practice, and providing regular, actionable feedback. Many practice opportunities coupled with rapid, performance-based feedback can enhance and expand training in evidence-based counseling for AUDs in a scalable and cost-efficient manner.  Lyssn.io​, Inc., (“Lyssn”) is a start-up developing AI-based technologies to support training, supervision, and quality assurance of evidence-based counseling. Our goal is to develop innovative health technology solutions that are objective, scalable, and cost efficient. ​Lyssn’s​ team includes expertise in natural language processing, machine learning, user-centered design, software engineering, and clinical expertise in evidence-based counseling. Previous research demonstrated the basic utility of a prototype conversational agent (ClientBot) for training counselors. Currently, ClientBot simulates a general mental health client who can engage in open-ended interaction with trainees and provides immediate, performance-based feedback to trainees using machine learning.  The current Fast-Track SBIR proposal partners ​Lyssn​ with Prevention Research Institute (PRI), who has a long track-record of training counselors in evidence-based approaches for AUD and currently trains approximately 1,250 counselors per year. Phase I will adapt ClientBot to an AUD training context, including understanding PRI training workflows, assessing usability, and accuracy of machine learning based MI feedback. Phase II will conduct a field-based usability trial and a randomized training trial (N = 200 PRI trainees) to evaluate the effectiveness of ClientBot on learning of MI skills compared to a wait-list and PRI training-as-usual. Analyses will also examine the hypothesized mechanisms of behavior change underlying ClientBot’s MI skills training. The successful execution of this project will break the reliance on role plays with peers and human judgment for training and performance-based feedback and support commercialization of a ClientBot product for training of AUD counselors in evidence-based practices. PROJECT NARRATIVE Training counselors in evidence-based treatments for alcohol use disorders (AUDs) requires repeated opportunities for skills practice with performance-based feedback, which is challenging to provide at scale. Building on an existing prototype, ​Lyssn.io​ – a technology start-up focused on scalable and cost-efficient human-centered technologies – will enhance and evaluate an AI-based, conversational agent (ClientBot) that simulates a realistic client with alcohol concerns and provides performance-based feedback to support counselor training.",ClientBot: A conversational agent that supports skills practice and feedback for Motivational Interviewing for AUD,10009084,R44AA028463,"['Alcohol consumption', 'Alcohol or Other Drugs use', 'Alcohols', 'American', 'Assessment tool', 'Behavioral', 'Behavioral Mechanisms', 'Client', 'Clinical', 'Code', 'Competence', 'Consumption', 'Control Groups', 'Counseling', 'Coupled', 'Development', 'Effectiveness', 'Environment', 'Evaluation', 'Evidence based practice', 'Evidence based treatment', 'Feedback', 'Goals', 'Health Personnel', 'Health Technology', 'Human', 'Individual', 'Interview', 'Judgment', 'Learning', 'Learning Skill', 'Machine Learning', 'Mental Health', 'Modeling', 'Music', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Nonprofit Organizations', 'Operative Surgical Procedures', 'Outcome', 'Participant', 'Patients', 'Performance', 'Persons', 'Phase', 'Play', 'Prevention Research', 'Professional counselor', 'Provider', 'Randomized', 'Recovery', 'Research', 'Research Institute', 'Role', 'Small Business Innovation Research Grant', 'Software Engineering', 'Sports', 'Strategic Planning', 'Structure', 'Substance abuse problem', 'Supervision', 'System', 'Technology', 'Testing', 'Text', 'Thinking', 'Time', 'Training', 'Training Activity', 'Training Support', 'Vision', 'Waiting Lists', 'Work', 'alcohol testing', 'alcohol use disorder', 'base', 'behavior change', 'behavioral health', 'commercialization', 'cost', 'cost efficient', 'design', 'effectiveness evaluation', 'evidence base', 'experience', 'experimental study', 'improved', 'innovation', 'member', 'motivational enhancement therapy', 'peer', 'prototype', 'quality assurance', 'scale up', 'skill acquisition', 'skills', 'skills training', 'tool', 'treatment choice', 'usability', 'user centered design']",NIAAA,"LYSSN.IO, INC.",R44,2020,397456,-0.06184781797974695
"Center for Critical Assessment of Genome Interpretation Genomic data hold the promise of revolutionizing our understanding and treatment of human disease. Multiple barriers stand between the acquisition of the data and realizing these and other benefits. Rapid accumulation of genomic data far exceeds our capacity to reliably interpret genomic variation. New developments in artificial intelligence and machine learning, combined with increased computing power and domain knowledge, provide hope for the deployment of enhanced computational tools in both basic research and clinical practice. Use of these methods critically depends upon reliable characterization of their performance.  The Center for Critical Assessment of Genome Interpretation (C-CAGI) will address these needs, through objective evaluation of the state of the art in relating human genetic variation and health. CAGI has had five editions since 2010 with 50 challenges posed to the community taken on by hundreds of predictors, leading to scores of publications about prediction methods and their assessment. We propose for C-CAGI to continue to advance the field of variant interpretation through the following Specific Aims: 1. Develop community experiments to evaluate the quality of computational methods for interpreting genomic variation data. C-CAGI will conduct community experiments in which participants make bona fide blinded predictions of disease related phenotypes on the basis of genomic data. We will engage a diverse predictor community to spur innovation. The CAGI Ethics Forum will vet studies to ensure that privacy and sharing maintain the highest standards and will educate the community. 2. Assess the quality of current computational methods for interpreting genomic variation data; highlight innovations and progress at interactive conferences. Predictions will be evaluated by independent assessors, who will be supported by new assessment approaches from C-CAGI. Results will be presented at CAGI experiment conferences with deep technical engagement, which will be interleaved with reflective CAGIâ meetings that create an environment for a comprehensive evaluation of the field, facilitating identification of major bottlenecks and problems faced by the current genome interpretation approaches. 3. Broadly disseminate the results and conclusions from the CAGI experiments and analysis. C-CAGI will outreach to the broader scientific and clinical community through its publications, and the creation of a calibrated reference integrated into the most common workflows for ready adoption. CAGI will also be represented at international meetings with presentations and workshops. 4. Operate effectively and responsively. C-CAGI will operate efficiently as it closely interacts with hundreds of participants. CAGI will build upon a robust information infrastructure that securely facilitates data dissemination, prediction submission, and assessment. Genomic variation is responsible for numerous rare diseases, for propensity for many common traits and diseases, for drug response, and is a key characteristic of cancer evolution. At present, our ability to characterize genetic differences far exceeds our capacity to interpret them either for basic research understanding or for clinical application. The Center for Critical Assessment of Genome Interpretation, operating on robust ethical foundations, will provide an evaluation of the current state of the art and help promote progress in understanding the impact of genomic variation.",Center for Critical Assessment of Genome Interpretation,9937546,U24HG007346,"['Address', 'Adoption', 'Affect', 'Amino Acid Sequence', 'Artificial Intelligence', 'Basic Science', 'Blinded', 'Characteristics', 'Clinical', 'Communities', 'Computing Methodologies', 'Copy Number Polymorphism', 'Data', 'Data Set', 'Development', 'Disease', 'Educational workshop', 'Ensure', 'Environment', 'Ethics', 'Evaluation', 'Evolution', 'Foundations', 'Genetic', 'Genetic Variation', 'Genome', 'Health', 'Human Genetics', 'Infrastructure', 'International', 'Knowledge', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Molecular', 'Nucleotides', 'Participant', 'Performance', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Phenotype', 'Privacy', 'Provider', 'Publications', 'RNA Splicing', 'Rare Diseases', 'Secure', 'Structure', 'Trust', 'Variant', 'Work', 'base', 'clinical application', 'clinical practice', 'computerized tools', 'data acquisition', 'data dissemination', 'exome', 'experimental study', 'genetic information', 'genetic variant', 'genomic data', 'genomic variation', 'high standard', 'human disease', 'innovation', 'meetings', 'multiple omics', 'operation', 'outreach', 'response', 'symposium', 'trait', 'whole genome']",NHGRI,UNIVERSITY OF CALIFORNIA BERKELEY,U24,2020,314933,-0.03311434260564363
"Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches Project Summary The form (or shape) and function relationship of anatomical structures is a central theme in biology where abnor- mal shape changes are closely tied to pathological functions. Morphometrics has been an indispensable quan- titative tool in medical and biological sciences to study anatomical forms for more than 100 years. Recently, the increased availability of high-resolution in-vivo images of anatomy has led to the development of a new generation of morphometric approaches, called statistical shape modeling (SSM), that take advantage of modern computa- tional techniques to model anatomical shapes and their variability within populations with unprecedented detail. SSM stands to revolutionize morphometric analysis, but its widespread adoption is hindered by a number of sig- niﬁcant challenges, including the complexity of the approaches and their increased computational requirements, relative to traditional morphometrics. Arguably, however, the most important roadblock to more widespread adop- tion is the lack of user-friendly and scalable software tools for a variety of anatomical surfaces that can be readily incorporated into biomedical research labs. The goal of this proposal is thus to address these challenges in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM), which automat- ically constructs optimal statistical landmark-based shape models of ensembles of anatomical shapes without relying on any speciﬁc surface parameterization. The proposed research will provide an automated, general- purpose, and scalable computational solution for constructing shape models of general anatomy. In Aim 1, we will build computational and machine learning algorithms to model anatomies with complex surface topologies (e.g., surface openings and shared boundaries) and highly variable anatomical populations. In Aim 2, we will introduce an end-to-end machine learning approach to extract statistical shape representation directly from im- ages, requiring no parameter tuning, image pre-processing, or user assistance. In Aim 3, we will provide intuitive graphical user interfaces and visualization tools to incorporate user-deﬁned modeling preferences and promote the visual interpretation of shape models. We will also make use of recent advances in cloud computing to enable researchers with limited computational resources and/or large cohorts to build and execute custom SSM work- ﬂows using remote scalable computational resources. Algorithmic developments will be thoroughly evaluated and validated using existing, fully funded, large-scale, and constantly growing databases of CT and MRI images lo- cated on-site. Furthermore, we will develop and disseminate standard workﬂows and domain-speciﬁc use cases for complex anatomies to promote reproducibility. Efforts to develop the proposed technology are aligned with the mission of the National Institute of General Medical Sciences (NIGMS), and its third strategic goal: to bridge biology and quantitative science for better global health through supporting the development of and access to computational research tools for biomedical research. Our long-term goal is to increase the clinical utility and widespread adoption of SSM, and the proposed research will establish the groundwork for achieving this goal. Project Narrative This project will develop general-purpose, scalable, and open-source statistical shape modeling (SSM) tools, which will present unique capabilities for automated anatomy modeling with less user input. The proposed tech- nology will introduce a number of signiﬁcant improvements to current SSM approaches and tools, including the support for challenging modeling problems, inferring shapes directly from images (and hence bypassing the seg- mentation step), parallel optimizations for speed, and new user interfaces that will be much easier and scalable than the current tools. The proposed technology will constitute an indispensable resource for the biomedical and clinical communities that will enable new avenues for biomedical research and clinical investigations, provide new ways to answer biologically related questions, allow new types of questions to be asked, and open the door for the integration of SSM with clinical care.","Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches",9969467,R01AR076120,"['Address', 'Adoption', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomic Surface', 'Anatomy', 'Area', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Brain', 'Bypass', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Collection', 'Communities', 'Complex', 'Complex Analysis', 'Computational Technique', 'Computer Models', 'Computer software', 'Computers', 'Custom', 'Data', 'Databases', 'Development', 'Disease', 'Felis catus', 'Funding', 'Generations', 'Geometry', 'Goals', 'Human', 'Ice', 'Image', 'Imagery', 'Injury', 'Intuition', 'Laboratory Research', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematical Computing', 'Measures', 'Medical', 'Medicine', 'Mission', 'Modeling', 'Modernization', 'Modification', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Occupations', 'Online Systems', 'Organism', 'Orthopedics', 'Pathologic', 'Population', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Shapes', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Speed', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Variant', 'Visual', 'Visualization software', 'Work', 'algorithm development', 'base', 'biomedical resource', 'clinical care', 'clinical investigation', 'clinically relevant', 'cohort', 'computerized tools', 'computing resources', 'deep learning', 'experience', 'flexibility', 'global health', 'graphical user interface', 'image archival system', 'image processing', 'imaging Segmentation', 'in vivo imaging', 'innovation', 'large datasets', 'machine learning algorithm', 'model development', 'multidisciplinary', 'open source', 'particle', 'preference', 'software development', 'tool', 'usability', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2020,614363,0.002461098314450759
"Abiotic-Biotic Interfaces for Ophthalmology Symposium ABSTRACT This proposal seeks funding to support a symposium, Abiotic-Biotic Interfaces for Ophthalmology (ABI), which will bring together recognized world experts in clinical, research, vision science, engineering, industrial and pharmaceutical communities as well as junior investigators (i.e., young faculty and those in training) to discuss the current state of ABI, ranging from bioelectronic implantable and wearable devices, to nanoscale scaffolds for stem cell and gene therapies. Given the multidisciplinary nature of this field, it is essential to bring together researchers and clinicians with varying levels of expertise across many domains related to ABI to advance the progress of this novel field, identify challenges of advancement, and develop a strategic action plan to overcome these challenges. The timing to have such a symposium to further the application of implantable and/or wearable bioengineered systems in ophthalmology is now as we focus on precision and personalized medicine and leverage the revolution in deep learning artificial intelligence algorithms. Through symposium talks, sessions, and discussions we will cover the fundamentals and also identify innovative and cutting-edge strategies and methodologies to accelerate the rate of major discoveries and development of novel therapeutics. The specific aims of this symposium are: Specific Aim 1. To bring together both established and junior investigators representing a broad range of disciplines to discuss cutting edge research in this novel field, catalyze the development of cross-disciplinary and translational approaches to advance abiotic-biotic interfaces for ophthalmology, and identify gaps in knowledge and barriers to advancement. We will identify research questions and develop an agenda to guide future research that is consistent with the objectives and interests of NEI. Specific Aim 2. Develop a junior investigator program to motivate a diverse group of students and junior investigators to pursue research careers in vision science and ophthalmologic therapeutic development, who will ultimately submit grant proposals to NEI solicitations and contribute to the scientific literature. Specific Aim 3. Develop a strategic action plan to set priorities for future studies that will encourage inter-agency collaborations (e.g., NEI, NSF, DARPA, etc.). This is critical because often certain engineering tasks are best suited to be supported by NSF or DARPA whereas the biological testing of the engineered systems lends itself to funding from NEI. Hence such inter-agency or cross-agency efforts can help leverage the funding to develop sophisticated abiotic-biotic systems NARRATIVE This meeting is the first on this topic dedicated to the broad use of implantable and/or wearable bioelectronics for ophthalmological applications. It is anticipated that the strategic action plan will significantly impact the field by greatly accelerating the translation of basic science and engineering research findings to stimulate the development of novel treatments and improve clinical practice. Key topics include visual restoration, drug and gene delivery, and sensing intraocular pressure. This meeting will foster training and development of future leaders in this emerging field and promote collaboration and exchange of knowledge and ideas among junior and established investigators.",Abiotic-Biotic Interfaces for Ophthalmology Symposium,10070800,R13EY031988,"['Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Basic Science', 'Biological Testing', 'Biomedical Engineering', 'Cellular Phone', 'Clinical Research', 'Collaborations', 'Communities', 'Computer software', 'Contact Lenses', 'Custom', 'Data', 'Development', 'Devices', 'Diagnosis', 'Discipline', 'Disease', 'Drug Delivery Systems', 'Electronics', 'Engineering', 'Eye', 'Faculty', 'Fostering', 'Funding', 'Future', 'Gene Delivery', 'Glass', 'Industrialization', 'Intraocular lens implant device', 'Knowledge', 'Literature', 'Medicine', 'Methodology', 'Nature', 'Neural Retina', 'Ophthalmology', 'Optics', 'Pharmacologic Substance', 'Physiologic Intraocular Pressure', 'Physiological', 'Research', 'Research Personnel', 'Route', 'Scientific Inquiry', 'Scientist', 'Senior Scientist', 'Students', 'System', 'Time', 'Training', 'Translations', 'Virtual and Augmented reality', 'Visual', 'base', 'career', 'clinical practice', 'deep learning', 'gene therapy', 'implantable device', 'improved', 'innovation', 'intelligent algorithm', 'interest', 'meetings', 'multidisciplinary', 'nanoscale', 'neural network', 'novel', 'novel therapeutics', 'personalized medicine', 'portability', 'precision medicine', 'programs', 'restoration', 'scaffold', 'stem cell therapy', 'symposium', 'therapeutic development', 'translational approach', 'vision science', 'wearable device']",NEI,UNIVERSITY OF SOUTHERN CALIFORNIA,R13,2020,42465,0.009441882812140801
"COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is still a major gap in that much data is still not openly shareable, which we propose to address. In addition, current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions) as well as for the individual requesting the data (e.g. substantial computational re- sources and time is needed to pool data from large studies with local study data). This needs to change, so that the scientific community can create a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see overview on this from our group7). The large amount of existing data requires an approach that can analyze data in a distributed way while (if required) leaving control of the source data with the individual investigator or the data host; this motivates a dynamic, decentralized way of approaching large scale analyses. During the previous funding period, we developed a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). Our system provides an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data is avoided, while the strength of large-scale analyses can be retained. During this new phase we respond to the need for advanced algorithms such as linear mixed effects models and deep learning, by proposing to develop decentralized models for these approaches and also implement a fully scalable cloud-based framework with enhanced security features. To achieve this, in Aim 1, we will incorporate the necessary functionality to scale up analyses via the ability to work with either local or commercial private cloud environments, together with advanced visualization, quality control, and privacy and security features. This suite of new functions will open the floodgates for the use of COINSTAC by the larger neuroscience community to enable new discovery and analysis of unprecedented amounts of brain imaging data located throughout the world. We will also improve usability, training materials, engage the community in contributing to the open source code base, and ultimately facilitate the use of COINSTAC's tools for additional science and discovery in a broad range of applications. In Aim 2 we will extend the framework to handle powerful algorithms such as linear mixed effects models and deep learning, and to perform meta-learning for leveraging and updating fit models. And finally, in Aim 3, we will test this new functionality through a partnership with the worldwide ENIGMA addiction group, which is currently not able to perform advanced machine learning analyses on data that cannot be centrally located. We will evaluate the impact of 6 main classes of substances of abuse (e.g. methamphetamines, cocaine, cannabis, nicotine, opiates, alcohol and their combinations) using the new developed functionality. 3 Project Narrative  Hundreds of millions of dollars have been spent on collecting human neuroimaging data for clinical and re- search studies, many of which do not come with subject consent for sharing or contain sensitive data which are not easily shared, such as genetics. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a viable solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we propose enables us to capture this `missing data' and achieve the same performance as pooling of both open and `closed' repositories by developing privacy preserving versions of advanced and cutting edge algorithms (including linear mixed effects models and deep learning) and incorpo- rating within an easy-to-use and scalable platform which enables distributed computation. 2","COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data",10058463,R01DA040487,"['Address', 'Adoption', 'Agreement', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Atlases', 'Awareness', 'Brain', 'Brain imaging', 'Cannabis', 'Clinical Data', 'Cocaine', 'Communities', 'Consent', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Pooling', 'Data Set', 'Decentralization', 'Development', 'Environment', 'Family', 'Funding', 'Genetic', 'Genomics', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Learning', 'Legal', 'Link', 'Location', 'Logistics', 'Machine Learning', 'Measures', 'Methamphetamine', 'Modeling', 'Movement', 'Neurosciences', 'Nicotine', 'Opioid', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Privacy', 'Privatization', 'Process', 'Public Health', 'Quality Control', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Security', 'Series', 'Site', 'Source', 'Source Code', 'Statistical Bias', 'Structure', 'Substance of Abuse', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Visualization', 'Work', 'addiction', 'base', 'cloud based', 'computational platform', 'computerized data processing', 'computerized tools', 'data harmonization', 'data reuse', 'data sharing', 'data visualization', 'data warehouse', 'deep learning', 'distributed data', 'improved', 'large datasets', 'learning algorithm', 'life-long learning', 'negative affect', 'neuroimaging', 'novel', 'novel strategies', 'open data', 'open source', 'peer', 'privacy preservation', 'repository', 'scale up', 'structural genomics', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'usability', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2020,627034,-0.0017503064021955382
"Combined Topological and Machine Learning Tools for Neuroscience Two major recent advances have raised the possibility of fundamental breakthroughs in both basic and clinical neuroscience: the development of new tools to probe the nervous system with single-cell resolution as well as brain-wide scope, and breakthroughs in machine learning methods for handling complex data. Yet there remain crucial barriers to progress: while data acquisition tools are now broadly within the grasp of neuroscience researchers, the same cannot be said about data analytical tools that can tackle the complexities of the new data sets being gathered. In addition, the highly training-data dependent, black-box Artificial Neural Network (ANN) methods that have shown rapid growth in the technological domain, are not well-suited to scientific data analysis, where transparency and understanding is more important than black-box performance measures. This proposal brings together a cross-disciplinary team of leading neuroscience and computer science researchers to develop and deploy a critical set of data analytical tools for the neuroscience community. The tools will be useful for data already gathered in major group efforts in the US Brain Initiative, and also for new data sets being acquired using the tools developed in the Initiative.  Extraction of the projection morphologies of individual neurons, and the classification and analysis of neuronal cell types is a central goal of the Brain Initiative. Because data from various sources are often analyzed with custom algorithms, scaling up existing approaches for use across large datasets and multiple data types has been a challenge. Instead researchers need a comprehensive, flexible mathematical framework that can be applied to a wide variety of data, including both static and dynamic measures. We propose to achieve this goal by combining Topological Data Analysis (TDA) methods with Deep Net based machine learning methods. Such a combined approach retains the flexibility of data-driven ANN methods while at the same time brings in conceptually well-grounded methods from TDA that are still able to address the complexities of brain-wide data sets with single-cell resolution. Aim 1 of the proposal will use these methods to automate tasks in neuroanatomy previously requiring intensive human expert effort. Aim 2 will apply the methods to single cell omics data sets. Aim 3 will deploy the tools developed to the Brain Initiative Cell Census Network and the neuroscience community. Recent years have seen many advances in experimental tools for probing brains in unprecedented ways, with single cell resolution, and as a result both individual investigators and large consortia are generating brain-wide single-cell data at an unprecedented scale. To derive full benefit from these data sets, researchers need theoretical and computational tools to analyze, visualize and derive knowledge from the data. In the proposed work, theoretically principled tools from Topological Data Analysis, in particular Discrete Morse Theory, are combined with artificial neural networks for Machine Learning, to provide a computational and analytical framework to deal with the complexity of the large-scale, high-dimensional data sets and derive the full benefits for basic as well as clinical neuroscience research.",Combined Topological and Machine Learning Tools for Neuroscience,10123310,RF1MH125317,"['Address', 'Algorithms', 'Area', 'Atlases', 'Axon', 'BRAIN initiative', 'Biological', 'Brain', 'Brain imaging', 'Categories', 'Cell Nucleus', 'Cells', 'Censuses', 'Classification', 'Clinical', 'Communities', 'Computer Analysis', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Dendrites', 'Development', 'Educational workshop', 'Epigenetic Process', 'Goals', 'Human', 'Image', 'Individual', 'Injections', 'Instruction', 'Knowledge', 'Letters', 'Light', 'Machine Learning', 'Mathematics', 'Measures', 'Methods', 'Molecular', 'Morphology', 'Nervous system structure', 'Neuroanatomy', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Performance', 'Pythons', 'Research Personnel', 'Resolution', 'Semantics', 'Skeleton', 'Software Tools', 'Source', 'Structure', 'Time', 'Tracer', 'Training', 'Trees', 'Visual', 'Work', 'analytical tool', 'artificial neural network', 'base', 'brain cell', 'cell type', 'complex data ', 'computer science', 'computerized tools', 'data acquisition', 'data centers', 'flexibility', 'grasp', 'high dimensionality', 'informatics tool', 'large datasets', 'machine learning method', 'mathematical methods', 'microscopic imaging', 'multidimensional data', 'multiple data types', 'neuronal cell body', 'rapid growth', 'repository', 'scale up', 'theories', 'tool', 'transcriptome sequencing', 'transcriptomics']",NIMH,COLD SPRING HARBOR LABORATORY,RF1,2020,2048230,-0.017203338787060055
"ORS-ISFR 17th Biennial Conference: Thinking big on fracture repair Abstract Bone fractures occur in more than 25 million Americans per year, and a significant percentage of those fractures fail to heal. Fractures that show delayed or failed progression to heal account for the majority of patient disability and costs. Thus, there is an urgent need to better understand the biology of bone healing, and to use that knowledge to develop new diagnostics and therapeutics. We are seeking support for the 17th Biennial conference of the International Section of Fracture Repair (ISFR). The ISFR recently became incorporated as a section within the Orthopaedic Research Society (ORS) thereby leveraging the outreach of the largest scientific organization in the world dedicated to orthopaedic research. The ISFR is dedicated to the advancement and exchange of the most current scientific ideas and research findings on fracture repair and its application to the improvement of patient care. Our mission is be the premier forum to integrate and present cutting-edge ideas related to clinical, translational, and basic science research of fracture healing. The central theme for this conference is “Thinking Big”. We will present the use of -omics approaches to solve the most significant research problems in the field and large-scale data management and advanced computational approaches to solve intractable clinical concerns. The meeting is organized around seven scientific sessions, and also includes an embedded symposium conducted with the Orthopaedic Trauma Association (OTA) focused on non-unions and a collaborative session on proximal humeral fractures conducted with the Bone and Joint Institute of the University of Western Ontario (BJI). The scientific sessions will each have a series of speakers, selected from submitted abstracts, and each will have an eminent keynote invited speaker. The sessions include: Stem Cells in Fracture; Artificial Intelligence, Machine Learning and Big data; Fracture induced pain management; Fracture repair basic research; Fracture repair clinical perspectives; Bone repair with polytrauma; and Outcomes. There will also be a short session for poster oral presentations (poster teasers), a session on how to communicate science, a practicum on data management, and an ORS Presidential Guest Speaker. Following the ISFR 17th biennial conference there will be an associated ISFR/BJI consensus workshop, which will develop a consensus white-paper on the best evidence-based treatment for proximal humeral fractures. The meeting will present the most up to date research on fracture healing basic biology, translational research and prospective clinical studies. The Program and Scientific Committees will be highly focused on fostering an inclusive environment. Surgeons, biologists, engineers, and policy makers will attend the meeting, and be drawn from academia, government, and industry. A variety of activities will be focused on career development and networking for trainees in the bone healing field. Narrative The 17th Biennial Conference of the ORS/ISFR titled, “Thinking big on fracture repair” will be held in December of 2020. The goal of the event is to foster growth and innovation in the field of fracture-induced pain management, artificial learning/machine learning/smart technology, polytrauma and stem cells, and outcomes research. Scientists, industry partners, researchers, policy makers, post-doctoral fellows and graduate students will attend the meeting to discuss the most pressing questions in the field of fracture repair, and to consider bold approaches to solving those problems.",ORS-ISFR 17th Biennial Conference: Thinking big on fracture repair,10066004,R13AR077963,"['Academia', 'American', 'Area', 'Artificial Intelligence', 'Basic Science', 'Big Data', 'Biological Process', 'Biology', 'Bone Injury', 'Bone Pain', 'Bone Regeneration', 'Canada', 'Career Mobility', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Consensus', 'Consensus Workshop', 'Development', 'Discipline', 'Engineering', 'Ensure', 'Environment', 'Event', 'Evidence based treatment', 'Exposure to', 'Fostering', 'Fracture', 'Fracture Healing', 'Germany', 'Goals', 'Government', 'Growth', 'Industry', 'Institutes', 'International', 'Japan', 'Joints', 'Knowledge', 'Laboratories', 'Logistics', 'Machine Learning', 'Mission', 'Musculoskeletal', 'Ontario', 'Oral', 'Orthopedics', 'Outcome', 'Outcome Study', 'Outcomes Research', 'Pain management', 'Paper', 'Participant', 'Patient Care', 'Patients', 'Phenotype', 'Policy Maker', 'Postdoctoral Fellow', 'Recording of previous events', 'Registries', 'Regulation', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Series', 'Shoulder Fractures', 'Societies', 'Surgeon', 'Technology', 'Thinking', 'Translational Research', 'Trauma', 'Universities', 'Work', 'base', 'bone', 'bone healing', 'career development', 'career networking', 'cost', 'data management', 'disability', 'graduate student', 'healing', 'humerus', 'industry partner', 'innovation', 'interest', 'large scale data', 'meetings', 'novel diagnostics', 'novel therapeutics', 'outreach', 'population based', 'posters', 'programs', 'prospective', 'repaired', 'scientific organization', 'stem cells', 'success', 'symposium', 'translational physician']",NIAMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R13,2020,5000,-0.018948952915611876
"SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community Physics-based simulations provide a powerful framework for understanding biological form and function. They harmonize heterogeneous experimental data with real-world physical constraints, helping researchers understand biological systems as they engineer novel drugs, new diagnostics, medical devices, and surgical interventions. The rise in new sensors and simulation tools is generating an increasing amount of data, but this data is often inaccessible, preventing reuse and limiting scientific progress. In 2005, we launched SimTK, a website to develop and share biosimulation tools, models, and data, to address these issues. SimTK now supports 62,000+ researchers globally and 950+ projects. Members use it to meet their grants’ data sharing responsibilities; experiment with new ways of collaborating; and build communities around their datasets and tools. However, challenges remain: many researchers still do not share their digital assets due to the time needed to prepare, document, and maintain those assets, and since SimTK hosts a growing number of diverse digital assets, the site now also faces the challenge of making these assets discoverable and reusable. Thus, we propose a plan to extend SimTK and implement new solutions to promote scientific data sharing and reuse. First, we will maintain the reliable, user-friendly foundation upon which SimTK is built, continuing to provide the excellent support our members expect and supporting the site’s existing features for sharing and building communities. Second, we will implement methods to establish a culture of model and data sharing in the biomechanics community. We will encourage researchers to adopt new habits, making sharing part of their workflow, by enabling the software and systems they use to automatically upload models and data to SimTK via an application programming interface (API) and by recruiting leading researchers in the community to serve as beta testers and role models. Third, we will create tools to easily replicate and extend biomechanics simulations. Containers and cloud computing services allow researchers to capture and share a snapshot of their computing environment, enabling unprecedented fidelity in sharing. We will integrate these technologies into SimTK and provide custom, easy-to-use interfaces to replicate and extend simulation studies. Lastly, we will develop a metadata standard for models and data for the biomechanics community, increasing reusability and discoverability of the rich set of resources shared on SimTK. We will use the new standard on SimTK and fill in the metadata fields automatically using natural language processing and machine learning, minimizing the burden and inaccuracies of manual metadata entry. We will evaluate our success in achieving these aims by tracking the number of assets shared and the frequency they are used as a springboard to new research. These changes will accelerate biomechanics research and provide new tools to increase the reusability and impact of shared resources. By lowering barriers to data sharing in the biosimulation community, SimTK will continue to serve as a model for how to create national infrastructure for scientific subdisciplines. SimTK is a vibrant hub for the development and sharing of simulation software, data, and models of biological structures and processes. SimTK-based resources are being used to design medical devices and drugs, to generate new diagnostics, to create surgical interventions, and to provide insights into biology. The proposed enhancements to SimTK will accelerate progress in the field by lowering barriers to and standardizing data and model sharing, thus 1) increasing the quantity and also, importantly, the quality of resources that researchers share and 2) enabling others to reproduce and build on the wealth of past biomechanics research studies.",SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community,9847973,R01GM124443,"['Achievement', 'Address', 'Adopted', 'Biological', 'Biological Models', 'Biology', 'Biomechanics', 'Biophysics', 'Cloud Computing', 'Code', 'Communities', 'Computer software', 'Consumption', 'Custom', 'Data', 'Data Files', 'Data Set', 'Development', 'Documentation', 'Engineering', 'Ensure', 'Environment', 'Explosion', 'Face', 'Foundations', 'Frequencies', 'Goals', 'Grant', 'Habits', 'Infrastructure', 'Letters', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Device', 'Medical Device Designs', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Operative Surgical Procedures', 'Pharmaceutical Preparations', 'Physics', 'Process', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Security', 'Services', 'Site', 'Structure', 'System', 'Technology', 'Time', 'Update', 'Work', 'application programming interface', 'base', 'biological systems', 'biomechanical model', 'community building', 'complex biological systems', 'data access', 'data cleaning', 'data ecosystem', 'data reuse', 'data sharing', 'data standards', 'digital', 'experience', 'experimental study', 'insight', 'member', 'new technology', 'novel diagnostics', 'novel therapeutics', 'prevent', 'recruit', 'research study', 'response', 'role model', 'sensor', 'simulation', 'simulation software', 'software systems', 'success', 'tool', 'user-friendly', 'web site']",NIGMS,STANFORD UNIVERSITY,R01,2020,489919,0.0013932243045326686
"NextGen Random Forests Project Summary/Abstract Building from the PI's current R01, we propose next generation random forests (RF) designed for unprecedented accuracy and computational scalability to meet the challenges of today's complex and big data in the health sciences. Superior accuracy is achieved using super greedy trees which circumvent limitations on local adaptivity imposed by classical tree splitting. We identify a key quantity, forest weights, and show how these can be leveraged for further improvements and generalizability. In one application, improved survival estimators are applied to worldwide esophageal cancer data to develop guidelines for clinical decision making. Richer RF inference is another issue explored. Cutting edge machine learning methods rarely consider the problem of estimating variability. For RF, bootstrapping currently exists as the only tool for reliably estimating conﬁdence intervals, but due to heavy computations is rarely applied. We introduce tools to rapidily calculate standard errors based on U-statistic theory. These will be used to increase robustness of esophageal clinical recommendations and to investigate survival temporal trends in cardiovascular disease. In another application, we make use of our new massive data scalability for discovery of tumor and immune regulators of immunotherapy in cancers. This project will set the standard for RF computational performance. Building from the core libraries of the highly accessed R-package randomForestSRC (RF-SRC), software developed under the PIs current R01, we develop open source next generation RF software, RF-SRC Everywhere, Big Data RF-SRC, and HPC RF-SRC. The software will be deployable on a number of popular machine learning workbenches, use distributed data storage technologies, and be optimized for big-p, big-n, and big-np scenarios. Project Narrative We introduce next generation random forests (RF) designed for unprecedented accuracy for complex and big data encountered in the health sciences.",NextGen Random Forests,9929599,R01GM125072,"['Atrophic', 'Benchmarking', 'Big Data', 'Biological Response Modifiers', 'Blood', 'Cancer Patient', 'Cardiovascular Diseases', 'Clinical', 'Clinical Management', 'Code', 'Combined Modality Therapy', 'Computer software', 'Confidence Intervals', 'Data', 'Data Storage and Retrieval', 'Databases', 'Development', 'Esophagus', 'Flow Cytometry', 'Guidelines', 'Health Sciences', 'Heart failure', 'Human', 'Hybrids', 'Immune', 'Immunotherapy', 'In Vitro', 'Interagency Registry for Mechanically Assisted Circulatory Support', 'Internet', 'Java', 'Laboratories', 'Language', 'Libraries', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of esophagus', 'Methodology', 'Methods', 'Modeling', 'Mus', 'Neoadjuvant Therapy', 'Operative Surgical Procedures', 'Pathologic', 'Patients', 'Performance', 'Population', 'Pump', 'Receptor Activation', 'Recommendation', 'Resistance', 'Subgroup', 'T-Lymphocyte', 'Technology', 'Therapeutic', 'Thrombosis', 'Time', 'Time trend', 'Trees', 'Weight', 'base', 'clinical decision-making', 'clinical practice', 'complex data ', 'design', 'distributed data', 'forest', 'immune checkpoint blockade', 'immunoregulation', 'improved', 'in vivo', 'lymph nodes', 'machine learning method', 'mouse model', 'next generation', 'novel', 'open source', 'outcome forecast', 'parallel processing', 'pre-clinical', 'predicting response', 'predictive modeling', 'random forest', 'receptor', 'response', 'software development', 'statistics', 'theories', 'therapeutic target', 'tool', 'tumor', 'tumor progression']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2020,347834,0.0064977420675960025
"International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) 2020 Project summary  The Medical Image Computing and Computer Assisted Interventions (MICCAI) society is dedicated to the promotion, preservation and facilitation of research and education in the fields of medical image computing and computer assisted interventions, including biomedical imaging and robotics. This aim is achieved through the organization and operation of regular international conferences of the highest quality, and publications that promote and foster the exchange and dissemination of advanced knowledge, expertise and experience by leading institutions and outstanding scientists, physicians, and educators around the world. MICCAI Conferences have their origin in three separate but related conferences beginning in early 1990s--Visualization in Biomedical Computing, Computer Vision and Virtual Reality in Robotics and Medicine, and Medical Robotics and Computer Assisted Surgery--, which merged into a single annual conference in 1998. MICCAI Conferences have defined new scientific disciplines over the years and have become the premier meeting in the field. The conference proceedings have an impact factor comparable to high-impact computational journals. Conference topics include, computer vision & medical image processing, computer-aided diagnosis, interventions & surgery, machine learning in medical imaging, guidance systems & robotics, visualization and virtual reality, bioscience and biology applications, imaging systems and new biomedical imaging applications, spanning disciplines such as radiology, pathology, surgery, oncology, cardiology, physiology, and psychiatry.  The MICCAI conference includes three days of oral presentations and poster sessions. The quality and importance of poster presentations are considered to be on a par with those of oral presentations, with both undergoing a rigorous double-blinded peer-review (~30% acceptance). Selected presented papers became landmark publications over the years with up to 2,000 citations. The conference series includes satellite events like community-driven software challenges, workshops and tutorials just before and/or after the main conference. These events focus on the current status and advances in topics relevant to MICCAI and are very well attended. The MICCAI Conferences span the entire globe and are usually rotated among the American, European, and Asian continents. Attendees are typically from over 45 countries, with strong student representation (>40%). The MICCAI 2020 Conference will be held in Lima, Peru in October 4th-8th, 2020. Since 2018, a Mentorship Program to connect students and young investigators with established mentors from academia and industry is also part of the conference. Along with the Mentorship Program and mission of the “Women in MICCAI” Committee, this proposal requests funds to support student and early investigator travel awards to enhance diversity in conference attendance (including women, underrepresented minorities, students with disabilities, and people from disadvantaged backgrounds) and provide minority groups with a unique opportunity to reach an international audience for career development and collaborations. Project narrative The Medical Image Computing and Computer Assisted Intervention (MICCAI) 2020 Conference will be held in Lima, Peru, October 4th-8th, 2020. MICCAI is the premier meeting in the medical image computing and computer assisted intervention communities, having introduced landmark papers and providing a springboard for young scientists to establish themselves in the field. This proposal requests funds to provide travel awards for students and early investigators to present their work at MICCAI 2020--with focus on minority groups and underrepresented populations--providing them with an opportunity to attend the meeting, foster professional development and identify collaborations in an established international community.",International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) 2020,10070479,R13EB030422,"['Academia', 'Academy', 'American', 'Asians', 'Award', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Cardiology', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Computer-Assisted Surgery', 'Costs and Benefits', 'Country', 'Development', 'Disabled Persons', 'Disadvantaged', 'Discipline', 'Double-Blind Method', 'Education', 'Educational workshop', 'Ensure', 'European', 'Event', 'Female', 'Fostering', 'Funding', 'Goals', 'Grant', 'Growth', 'Healthcare', 'Industrialization', 'Industry', 'Institution', 'International', 'Intervention', 'Journals', 'Knowledge', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Minority Groups', 'Mission', 'Oncology', 'Operative Surgical Procedures', 'Oral', 'Paper', 'Pathology', 'Peer Review', 'Peru', 'Physicians', 'Physiology', 'Policies', 'Postdoctoral Fellow', 'Psychiatry', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Personnel', 'Robotics', 'Role', 'Scientist', 'Series', 'Societies', 'Students', 'Training', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Populations', 'United States National Institutes of Health', 'Visualization', 'Woman', 'Women&apos', 's Group', 'Work', 'base', 'bioimaging', 'career', 'career development', 'community intervention', 'community organizations', 'cost', 'disabled students', 'early-career faculty', 'experience', 'graduate student', 'image guided', 'image processing', 'imaging system', 'innovation', 'interest', 'meetings', 'operation', 'posters', 'preservation', 'programs', 'racial and ethnic', 'robotic system', 'social', 'student participation', 'success', 'supportive environment', 'symposium', 'underrepresented minority student', 'virtual reality', 'women faculty']",NIBIB,CHILDREN'S RESEARCH INSTITUTE,R13,2020,9850,-2.6267012349757916e-05
"Deep learning approaches to decipher the impact of mobile element insertion on alternative splicing in neurological disorders The purpose of this training and research application is to study the functional impact of mobile element insertions (MEIs) in neurological disorders (NDs) using new developments in deep learning techniques. MEIs are transposable DNA fragments that are able to insert throughout the human genome. There are at least 124 independent MEIs associated with human diseases. Approximately 20% of these diseases represent a spectrum of NDs, yet the overall contribute of MEIs to the etiology of NDs has not been systematically estimated. To address this, we will (1) characterize functional MEIs in GTEx cohorts in healthy individuals; (2) build a comprehensive functional map of MEIs to determine tissue-specific and brain-specific impact; and (3) impute transcriptional changes on various NDs where whole-genome sequencing (WGS) data will be generated. The proposed application will also develop an extensive research program for Dr. Dadi Gao, a computational biologist and statistical geneticist who has trained in functional genomic studies of alternative splicing in neurodegenerative disorders and therapeutic targeting of a splicing defect that causes a severe neurodevelopmental disorder. He has developed novel methods to investigate regulation of the transcriptome and to facilitate analyses in drug development. He now seeks to expand his expertise by applying statistical and deep learning models on large cohorts of sequencing data from controls and cases with NDs from post-mortem tissues, then impute functional consequences of MEIs from WGS in large-scale disease cohorts. The training plan consists of two years of mentored research to learn new skills in genome analysis, MEI characterization, and advanced deep learning techniques, followed by three years of shaping an independent laboratory. The research plan is developed to comprehensively explore functional variation in the genome by decomposing transcriptomic changes against MEIs. Dr. Michael Talkowski at Massachusetts General Hospital, Harvard, and the Broad Institute will serve as the primary mentor, while Dr. Manolis Kellis at MIT and the MIT Computational Biology Group, and the Broad Institute will serve as a co-mentor and close collaborator. These mentors are recognized experts in genomic structural variants, functional genomics, the genetics of neurological disorders, and computational modeling to establish functional elements in the human genome. In addition, a team of independent investigators from basic and translational research will provide Dr. Gao with comprehensive feedback to keep both his science and career development on track. The highly collaborative environment in CGM, MGH, Harvard Medical School, the Broad Institute and the University of Michigan Medical School will prepare Dr. Gao for his transition to an independent investigator. This outstanding mentorship team and training program will facilitate the career development of Dr. Gao as he seeks to redefine the functional maps of MEIs in the human genome and to impute their impact in large-scale neurological disorders. Mobile element insertions (MEIs) represent a largely undefined component of the genetic architecture of neurological disorders, as a number of MEIs have been associated with alternative splicing in these disorders but large-scale genome-wide functional characterization has not been systematically performed across tissues. This program study will functionally characterize the impact of MEIs on alternative splicing from whole-genome sequencing and transcriptome sequencing in large cohorts using new developments in deep learning models. These results will enhance our understanding of the etiological role and pathogenic mechanisms associated with MEIs in neuronal development and human neurological disorders.",Deep learning approaches to decipher the impact of mobile element insertion on alternative splicing in neurological disorders,10041366,K99NS118109,"['Address', 'Algorithms', 'Alternative Splicing', 'Alzheimer&apos', 's Disease', 'Autopsy', 'Basic Science', 'Biology', 'Blood', 'Brain', 'Brain Diseases', 'CRISPR/Cas technology', 'Cells', 'Chromosome Pairing', 'Cohort Studies', 'Computational Biology', 'Computer Analysis', 'Computer Models', 'DNA', 'DNA Insertion Elements', 'Data', 'Data Set', 'Defect', 'Detection', 'Development', 'Disease', 'Disease model', 'Dorsal', 'Dystonia', 'Elements', 'Etiology', 'Event', 'Evolution', 'Excision Repair', 'Familial Dysautonomia', 'Feedback', 'Fellowship', 'Filipino', 'General Hospitals', 'Generations', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomics', 'Genotype-Tissue Expression Project', 'Haplotypes', 'Human', 'Human Genome', 'Individual', 'Institutes', 'International', 'Introns', 'Laboratories', 'Lateral', 'Lead', 'Learning', 'Linear Regressions', 'Link', 'Machine Learning', 'Maps', 'Massachusetts', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Michigan', 'Mind', 'Minisatellite Repeats', 'Modeling', 'Molecular', 'Mosaicism', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neuromuscular Diseases', 'Neurons', 'Outcome', 'Parkinsonian Disorders', 'Pathogenicity', 'Pattern', 'Peripheral', 'Pharmaceutical Preparations', 'Phase', 'Population', 'Prefrontal Cortex', 'Process', 'Property', 'RNA Splicing', 'Regulation', 'Research', 'Research Personnel', 'Retroelements', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Shapes', 'Short Interspersed Nucleotide Elements', 'Source', 'Specificity', 'Structure', 'TAF1 gene', 'Techniques', 'Therapeutic Trials', 'Tissue-Specific Splicing', 'Tissues', 'Training', 'Training Programs', 'Transcription Alteration', 'Translational Research', 'Universities', 'Untranslated RNA', 'Variant', 'Work', 'brain tissue', 'career development', 'cohort', 'collaborative environment', 'convolutional neural network', 'deep learning', 'drug development', 'functional genomics', 'functional outcomes', 'gene function', 'genetic architecture', 'genome analysis', 'genome editing', 'genome sequencing', 'genome-wide', 'human disease', 'in silico', 'insight', 'medical schools', 'mind control', 'nervous system disorder', 'neuron development', 'novel', 'programs', 'response', 'skills', 'statistical learning', 'structural genomics', 'therapeutic target', 'transcriptome', 'transcriptome sequencing', 'transcriptomics', 'whole genome']",NINDS,MASSACHUSETTS GENERAL HOSPITAL,K99,2020,91226,-0.0284555747419641
"National Resource for Network Biology (NRNB) OVERALL - PROJECT SUMMARY The mission of the National Resource for Network Biology (NRNB) is to advance the science of biological networks by creating leading-edge bioinformatic methods, software tools and infrastructure, and by engaging the scientific community in a portfolio of collaboration and training opportunities. Much of biomedical research is dependent on knowledge of biological networks of multiple types and scales, including molecular interactions among genes, proteins, metabolites and drugs; cell communication systems; relationships among genotypes and biological and clinical phenotypes; and patient and social networks. NRNB-supported platforms like Cytoscape are among the most widely used software tools in biology, with tens of thousands of active users, enabling researchers to apply network concepts and data to understand biological systems and how they are reprogrammed in disease.  NRNB’s three Technology Research and Development projects introduce innovative concepts with the potential to transform network biology, transitioning it from a static to a dynamic science (TR&D 1); from flat network diagrams to multi-scale hierarchies of biological structure and function (TR&D 2); and from descriptive interaction maps to predictive and interpretable machine learning models (TR&D 3). In previous funding periods our technology projects have produced novel and highly cited approaches, including network-based biomarkers for stratification of disease, data-driven gene ontologies assembled completely from network data, and deep learning models of cell structure and function built using biological networks as a scaffold.  During the next period of support, we introduce dynamic regulatory networks formulated from single-cell transcriptomics and advanced proteomics data (TR&D 1); substantially improved methodology for the study of hierarchical structure and pleiotropy in biological networks (TR&D 2); and procedures for using networks to seed machine learning models of drug response that are both mechanistically interpretable and transferable across biomedical contexts (TR&D 3). These efforts are developed and applied in close collaboration with outside investigators from 19 Driving Biomedical Projects who specialize in experimental generation of network data, disease biology (cancer, neuropsychiatric disorders, diabetes), single-cell developmental biology, and clinical trials. TR&Ds are also bolstered by 7 Technology Partnerships in which NRNB scientists coordinate technology development with leading resource-development groups in gene function prediction, mathematics and algorithm development, and biomedical databases. Beyond these driving collaborations, we continually support a broader portfolio of transient (non-driving) research collaborations; organize and lead international meetings including the popular Network Biology track of the Intelligent Systems for Molecular Biology conference; and deliver a rich set of training opportunities and network analysis protocols. OVERALL - PROJECT NARRATIVE We are all familiar with some of the components of biological systems – DNA, proteins, cells, organs, individuals – but understanding biological systems involves more than just cataloging its component parts. It is critical to understand the many interactions of these parts within systems, and how these systems give rise to biological functions and responses and determine states of health and disease. The National Resource for Network Biology provides the scientific community with a broad platform of computational tools for the study of biological networks and for incorporating network knowledge in biomedical research.",National Resource for Network Biology (NRNB),9937486,P41GM103504,"['Area', 'Automobile Driving', 'Beds', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Process', 'Biological Sciences', 'Biology', 'Biomedical Research', 'Biomedical Technology', 'Cataloging', 'Catalogs', 'Cell Communication', 'Cell model', 'Cell physiology', 'Cells', 'Cellular Structures', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Computer software', 'Conceptions', 'DNA', 'Data', 'Data Set', 'Databases', 'Developmental Cell Biology', 'Diabetes Mellitus', 'Disease', 'Disease stratification', 'Drug Modelings', 'Ecosystem', 'Educational workshop', 'Event', 'Expert Systems', 'Feedback', 'Funding', 'Gene Proteins', 'Generations', 'Genes', 'Genetic Risk', 'Genomics', 'Genotype', 'Goals', 'Health', 'Individual', 'Infrastructure', 'International', 'Knowledge', 'Lead', 'Life', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mentors', 'Methodological Studies', 'Methods', 'Mission', 'Modeling', 'Molecular Biology', 'National Institute of General Medical Sciences', 'Network-based', 'Ontology', 'Organ', 'Pathway Analysis', 'Patients', 'Pharmaceutical Preparations', 'Phase Transition', 'Phenotype', 'Positioning Attribute', 'Procedures', 'Proteins', 'Proteomics', 'Protocols documentation', 'Research', 'Research Personnel', 'Resource Development', 'Resources', 'Running', 'Science', 'Scientist', 'Seeds', 'Services', 'Social Network', 'Software Tools', 'Structure', 'Students', 'System', 'Technology', 'Testing', 'Tissues', 'Training', 'Visual', 'Visualization', 'Work', 'algorithm development', 'biological systems', 'clinical phenotype', 'cloud storage', 'computational platform', 'computerized tools', 'deep learning', 'gene function', 'genomics cloud', 'improved', 'innovation', 'interoperability', 'lens', 'mathematical algorithm', 'meetings', 'method development', 'multi-scale modeling', 'neuropsychiatric disorder', 'next generation', 'novel', 'pleiotropism', 'prediction algorithm', 'programs', 'protein metabolite', 'response', 'scaffold', 'single cell analysis', 'software infrastructure', 'symposium', 'technology development', 'technology research and development', 'tool', 'training opportunity', 'transcriptome', 'transcriptomics']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",P41,2020,1995376,-0.024773384670197886
"Arkansas Bioinformatics Consortium Project Summary/Abstract The Arkansas Research Alliance proposes to hold five annual workshops on the subject of bioinformatics. The purpose is to bring six major Arkansas institutions into closer collaboration. Those institutions are: University of Arkansas-Fayetteville; Arkansas State University; University of Arkansas for Medical Sciences; University of Arkansas at Little Rock; University of Arkansas at Pine Bluff; and the National Center for Toxicological Research. The workshops will focus on capabilities at each of the six in sciences related to bioinformatics including artificial intelligence, big data, machine learning, food and agriculture, high speed computing, and visualization capabilities. As this work progresses, educational coordination and student encouragement will be important components. Principals from all six institutions are collaborating to accomplish the workshop goals. Project Narrative The FDA ability to protect the public health is directly related to its ability to access and utilize the latest scientific data. Increased proficiency in collecting, presenting, validating, understanding, and drawing quantitative inference from the massive volume of new scientific results is necessary for success in that effort. The complexity involved requires continued development of new tools available and being developed within the realm of information technology, and the workshops proposed here will address this need. Specific Aims  • Thoroughly understand the resources in Arkansas available for furthering the capabilities in  bioinformatics and its associated needs, e.g., access to high speed computing capability and use  of computational tools. • Develop a set of plans to harness and grow those capabilities, especially those that are relevant  to the needs of NCTR and FDA. • Stimulate interest and capability across Arkansas in bioinformatics to produce a larger cadre of  expertise as these plans are implemented. • Enlist NCTR’s help in directing the effort toward seeking local, national and international data  that can be more effectively analyzed to produce results needed by FDA and others, e.g.,  reviewing decades of genomic/treatment data on myeloma patients at the University of  Arkansas for Medical Sciences. • Develop ways in which the Arkansas capabilities can be combined into a coordinated, synergistic  force larger than the sum of its parts. • Encourage students and faculty in the development of new models and techniques to be used in  bioinformatics and related fields. • Improve inter-institutional communication, including developing standardized bioinformatics  curricula and more universal course acceptance.",Arkansas Bioinformatics Consortium,9961522,R13FD006690,[' '],FDA,ARKANSAS RESEARCH ALLIANCE,R13,2020,15000,0.013986083910968203
"Bridging the Gap between Genomics and Clinical Outcomes in CHD PROJECT SUMMARY/ABSTRACT The NHLBI has invested extensively in the Pediatric Cardiac Genomics Consortium (PCGC), recognizing that translating genomic discoveries into optimized management and therapeutic strategies for congenital heart disease (CHD) can only be achieved in the context of multi-center, collaborative research. Currently, the PCGC is lacking two fundamental capabilities that hinder its ability to define the genomic basis for CHD outcomes: (1) a robust mechanism for extracting pertinent, machine-readable clinical data from Electronic Health Records (EHRs) across multiple institutions; and (2) a robust Artificial Intelligence (AI) platform that is capable of teasing apart the complex interplay between maternal factors, phenotypes, genotypes, gene functions and clinical outcomes. Here, we propose innovative solutions to these challenges, by assembling teams of content experts to leverage existing infrastructure to extract relevant outcomes directly from the EHR of participating PCGC Centers and by designing best-practice AI tools for outcomes research. Our principal goal is provide the vision, infrastructure and expertise to collaboratively empower CHD outcomes research, foster knowledge exchange, and train the next generation of genomic scientists. We propose to leverage existing data infrastructure to obtain Electronic Health Records (EHR) and other clinical variables at scale by partnering with other research networks to create a PCGC Data Resource. Using this resource, we will create and deploy a platform of Artificial Intelligence (AI)-based predictors for CHD outcomes research, with the goal of translating genomic discoveries into improved management and therapeutic strategies for CHD. PROJECT NARRATIVE The overall goal of this project is to apply genomic discoveries toward prediction of clinical outcomes in congenital heart disease. The proposal encompasses innovative concepts and methodologies that will advance the field of congenital heart disease in a very practical manner.",Bridging the Gap between Genomics and Clinical Outcomes in CHD,10027913,U01HL128711,"['Artificial Intelligence', 'Bayesian Network', 'Bioinformatics', 'Childhood', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical and Translational Science Awards', 'Code', 'Collaborations', 'Complex', 'Custom', 'Data', 'Data Set', 'Dependence', 'Diagnostic', 'Disease Outcome', 'Electronic Health Record', 'Fostering', 'Foundations', 'Gender', 'Genes', 'Genomics', 'Genotype', 'Goals', 'Heart', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internet', 'Knowledge', 'Methodology', 'Modeling', 'Multicenter Studies', 'National Heart, Lung, and Blood Institute', 'Network-based', 'Online Systems', 'Outcome', 'Outcomes Research', 'Pathway interactions', 'Patients', 'Pediatric Cardiac Genomics Consortium', 'Pediatric cardiology', 'Phenotype', 'Readability', 'Recording of previous events', 'Research', 'Research Personnel', 'Resources', 'Risk Factors', 'Scientist', 'Site', 'Societies', 'Standard Model', 'Testing', 'Therapeutic', 'Thoracic Surgical Procedures', 'Training', 'Translating', 'Utah', 'Vision', 'Visit', 'Work', 'base', 'clinical care', 'clinical database', 'comorbidity', 'congenital heart disorder', 'data infrastructure', 'data resource', 'design', 'gene function', 'genomic data', 'improved', 'innovation', 'member', 'next generation', 'novel', 'outcome prediction', 'patient oriented', 'predict clinical outcome', 'programs', 'relational database', 'repository', 'skills', 'surgery outcome', 'tool']",NHLBI,UNIVERSITY OF UTAH,U01,2020,419375,-0.024786268279662852
"BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy 7. Project Summary/Abstract With the wide adoption of electronic health record systems, cross-institutional genomic medicine predictive modeling is becoming increasingly important, and have the potential to enable generalizable models to accelerate research and facilitate quality improvement initiatives. For example, understanding whether a particular variable has clinical significance depends on a variety of factors, one important one being statistically significant associations between the variant and clinical phenotypes. Multivariate models that predict predisposition to disease or outcomes after receiving certain therapeutic agents can help propel genomic medicine into mainstream clinical care. However, most existing privacy-preserving machine learning methods that have been used to build predictive models given clinical data are based on centralized architecture, which presents security and robustness vulnerabilities such as single-point-of-failure. In this proposal, we will develop novel methods for decentralized privacy-preserving genomic medicine predictive modeling, which can advance comparative effectiveness research, biomedical discovery, and patient-care. Our first aim is to develop a predictive modeling framework on private Blockchain networks. This aim relies on the Blockchain technology and consensus protocols, as well as the online and batch machine learning algorithms, to provide an open-source Blockchain-based privacy-preserving predictive modeling library for further Blockchain-related studies and applications. We will characterize settings in which Blockchain technology offers advances over current technologies. The second aim is to develop a Blockchain-based privacy-preserving genomic medicine modeling architecture for real-world clinical data research networks. These aims are devoted to the mission of the National Human Genome Research Institute (NHGRI) to develop biomedical technologies with application domain of genomics and healthcare. The NIH Pathway to Independence Award provides a great opportunity for the applicant to complement his computer science background with biomedical knowledge, and specialized training in machine learning and knowledge-based systems. It will also allow him to investigate new techniques to advance genomic and healthcare privacy protection. The success of the proposed project will help his long-term career goal of obtaining a faculty position at a biomedical informatics program at a major US research university and conduct independently funded research in the field of decentralized privacy-preserving computation. 8. Project Narrative The proposed research will develop practical methods to support privacy-preserving genomic and healthcare predictive modeling, and build innovations based on Blockchain technology for secure and robust machine learning training processes. The development of such privacy technology may increase public trust in research and quality improvement. The technology we propose will also contribute to the sharing of predictive models in ways that meet the needs of genomic research and healthcare.",BECKON - Block Estimate Chain: creating Knowledge ON demand & protecting privacy,9920181,R00HG009680,"['Adoption', 'Algorithms', 'Architecture', 'Authorization documentation', 'Award', 'Biomedical Technology', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Comparative Effectiveness Research', 'Complement', 'Complex', 'Consensus', 'Data', 'Data Aggregation', 'Data Collection', 'Decentralization', 'Development', 'Disease', 'Distributed Databases', 'Electronic Health Record', 'Ethics', 'Faculty', 'Failure', 'Fibrinogen', 'Funding', 'Genomic medicine', 'Genomics', 'Goals', 'Health Care Research', 'Healthcare', 'Hybrids', 'Infrastructure', 'Institution', 'Institutional Policy', 'Intuition', 'Investigation', 'Knowledge', 'Libraries', 'Machine Learning', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Mission', 'Modeling', 'Monitor', 'National Human Genome Research Institute', 'Outcome', 'Pathway interactions', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Predisposition', 'Privacy', 'Privatization', 'Process', 'Protocols documentation', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Secure', 'Security', 'Site', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Therapeutic Agents', 'Time', 'Training', 'Transact', 'United States National Institutes of Health', 'Universities', 'Variant', 'base', 'biomedical informatics', 'blockchain', 'career', 'clinical care', 'clinical phenotype', 'clinically significant', 'computer science', 'data sharing', 'design', 'digital', 'diverse data', 'health care delivery', 'improved', 'innovation', 'interoperability', 'knowledge base', 'machine learning algorithm', 'machine learning method', 'medical specialties', 'network architecture', 'novel', 'open source', 'peer', 'peer networks', 'point of care', 'predictive modeling', 'privacy preservation', 'privacy protection', 'programs', 'public trust', 'structural genomics', 'success', 'trend', 'web portal', 'web services']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R00,2020,249000,0.004927709209659669
"Conceptualizing Actionability in Clinical Genomic Screening Project Summary/Abstract. Clinical genomic sequencing (CGS) produces large amounts of data, much of which is hard to characterize or may have a negligible influence on health. The concept of actionability is commonly used to help separate information that may be useful from information that is likely irrelevant for patients. Actionability directs attention to whether genomic information warrants action and reflects its initial development as a strategy to augment diagnosis and treatment in sick patients. As CGS expands towards healthy populations in primary care settings, actionability is still widely embraced despite little consensus regarding its definition and use. Because this ambiguity could become an obstacle to the successful implementation of clinical genomic sequencing in healthy populations, greater clarity about this concept is necessary. The proposed research will fulfill this need by characterizing the emergence and varied meanings of actionability in clinical genomics, focusing on clinical genomics' transition into primary care settings. By identifying underlying values and assumptions related to actionability, this research will push beyond definitional disputes and provide a deeper framework for assessing how genetic information is valued. The specific aims are: 1. Identify and characterize, through in-depth interviews, how genomics experts and primary care providers conceptualize what makes genomic information actionable for healthy populations. 2. Identify and characterize, through a natural language processing (NLP) analysis of published literature, how the concept of actionability emerged, spread, and is used throughout clinical genomics. 3. Convene a workshop with genomics experts, primary care providers, and ELSI scholars to produce a white paper on actionability and the ethical, effective integration of CGS into primary care, guided by the results from Aims 1 and 2. This K99/R00 Pathway to Independence Award includes a highly-structured, mentored training program that will support the candidate's goal to become an independent, mixed-methods ELSI investigator focused on assessing the value of genomic information. To achieve this career goal, the candidate will: 1. Receive training in genetic and genomic science to facilitate collaboration with genomics care teams and make scientifically accurate policy recommendations 2. Build new methodological skills in biomedical informatics and natural language processing to conduct generalizable research 3. Publish and engage with scientific and medical audiences to have a more direct impact on future guidelines and policies. 4. Develop a collaborative and interdisciplinary research network. This training will include coursework, guided readings, network building, and sustained mentorship by a highly-qualified team of faculty with expertise in ELSI research, bioethics, clinical genomics, biomedical informatics, and the history and sociology of medicine. This training will prepare the candidate to transition to an independent ELSI investigator focused on ethical issues related to the actionability of genomic health information – an ELSI research priority in Genetic and Genomic Healthcare. Project Narrative. This K99/R00 Pathway to Independence Award will prepare the candidate to become an independent, mixed-methods ELSI researcher pursing a research program on ethical issues related to the actionability of genomic information. The study examines the values and assumptions underlying conceptualizations of the actionability of genomic information for healthy populations. Results of the study will contribute to the ethical and effective implementation of genomic sequencing into care for healthy populations.",Conceptualizing Actionability in Clinical Genomic Screening,10054993,K99HG010905,"['American', 'Award', 'Bioethics', 'Caring', 'Clinical', 'Collaborations', 'Consensus', 'Data', 'Development', 'Diagnosis', 'Disease', 'Disputes', 'Educational workshop', 'Ethical Issues', 'Ethics', 'Faculty', 'Future', 'Genetic', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Healthcare', 'Individual', 'Interdisciplinary Study', 'Intervention', 'Interview', 'Laboratories', 'Level of Evidence', 'Literature', 'Medical', 'Medical Genetics', 'Medical Sociology', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Natural Language Processing', 'Outcome', 'Paper', 'Pathogenicity', 'Pathway interactions', 'Patients', 'Penetrance', 'Policies', 'Population', 'Positioning Attribute', 'Primary Health Care', 'Provider', 'Publishing', 'Qualitative Methods', 'Reading', 'Recommendation', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Priority', 'Risk', 'Science', 'Severities', 'Structure', 'Surveys', 'Technology', 'Testing', 'Training', 'Training Programs', 'Translations', 'Variant', 'biomedical informatics', 'care providers', 'career', 'clinical implementation', 'directed attention', 'genetic information', 'genome sciences', 'health management', 'innovation', 'lifestyle intervention', 'medical schools', 'prevent', 'primary care setting', 'programs', 'screening', 'skills']",NHGRI,UNIVERSITY OF PENNSYLVANIA,K99,2020,103353,-0.013060968790355638
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10016840,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2020,330502,-1.5006771319665991e-05
"Data Science Applications in Communication andSwallowing Disorders PROJECT SUMMARY/ABSTRACT The emergence of electronic medical records, large data registries and readily accessible, protected servers have resulted in an explosion of digital information with potentially high clinical impact for improving patient management and outcomes. Big data warehouses that capture standardized information within the scope of clinical practices allow trained scientists to not only engage in traditional hypothesis testing, but to also uncover new hypotheses, refine existing theories and apply new discoveries to health assessments and interventions. Despite the accessibility and potential impact of these data platforms, clinician scientists have traditionally directed experiments that incorporate relatively small sample sizes and data from individual laboratories, and have not been trained in big data analytics or in engaging appropriate team scientists who work in this space, such as computer scientists, biostatisticians and engineers. The overarching goal of this proposal is to mentor early patient oriented communication and swallowing scientists in big data analytics and to mentor and involve early data science scholars in communication and swallowing research. The PI proposes four primary mentorship and research goals in this K24 renewal proposal: 1. Train a cadre of early stage communication and swallowing scientists in data science methods, including machine learning, by an expert, interdisciplinary, collaborative data science team, 2. Engage and introduce early career data scientists from fields of biostatistics, computer science and engineering to communication and swallowing sciences, and respective data sets, toward facilitating interdisciplinary data science teams and research productivity, 3. Apply novel data science methods to identify phenotypes of swallowing impairment and severity classifications in patient groups known to be at high risk for nutritional and health complications related to dysphagia, and 4. Develop a new area of research in machine learning applications toward improving reliability of physiologic swallowing assessment. The data science theme of the career development and research plan directly align with NIDCD's Strategic Plan for Data Science which lists as its mission: Storing, managing, standardizing and publishing the vast amounts of data produced by biomedical research. NIDCD recognizes that accessible, well-organized, secure and efficiently operated data resources are critical to modern scientific inquiry…and by maximizing the value of data generated through NIH-funded efforts, the pace of biomedical discoveries and medical breakthroughs for better health outcomes can be accelerated. PROJECT NARRATIVE The emergence of electronic health records exposes clinicians to massive amounts of information about the millions of patients who suffer from communication and swallowing disorders, yet most clinical scientists do not have the training or skill to apply meaning to the data toward improving patient care. The overarching mentorship goal of this proposal is to train early, patient-oriented communication and swallowing scientists in big data analyses, including computer machine learning approaches. The research project will uncover distinct patterns and severity of swallowing impairments in large groups of patients with high risk medical diagnoses, which will have high impact on patient care planning and identification of treatments that directly target these impairments for improved outcomes.",Data Science Applications in Communication andSwallowing Disorders,9892671,K24DC012801,"['Algorithms', 'Area', 'Award', 'Barium swallow', 'Big Data', 'Big Data Methods', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Biometry', 'Chronic Obstructive Airway Disease', 'Classification', 'Clinical', 'Communication', 'Communication impairment', 'Computer Vision Systems', 'Computerized Medical Record', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Data Scientist', 'Data Set', 'Deglutition', 'Deglutition Disorders', 'Dementia', 'Development', 'Diagnosis', 'Disease', 'Economics', 'Electronic Health Record', 'Engineering', 'Explosion', 'Funding', 'Geography', 'Goals', 'Grant', 'Head and Neck Cancer', 'Health', 'Hearing', 'Impairment', 'Individual', 'Instruction', 'Intervention', 'Laboratories', 'Machine Learning', 'Medical', 'Medical Records', 'Mentored Patient-Oriented Research Career Development Award', 'Mentors', 'Mentorship', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Mission', 'Modernization', 'National Institute on Deafness and Other Communication Disorders', 'Nutritional', 'Outcome', 'Parkinson Disease', 'Patient Care', 'Patient Care Planning', 'Patients', 'Pattern', 'Phenotype', 'Physiological', 'Productivity', 'Publishing', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Sample Size', 'Science', 'Scientific Inquiry', 'Scientist', 'Secure', 'Severities', 'Speech', 'Standardization', 'Statistical Models', 'Strategic Planning', 'Stroke', 'Supervision', 'Techniques', 'Testing', 'Training', 'United States National Institutes of Health', 'Work', 'base', 'career', 'career development', 'clinical practice', 'clinically relevant', 'computer science', 'computerized', 'data registry', 'data resource', 'data warehouse', 'digital', 'experimental study', 'health assessment', 'high risk', 'human error', 'impression', 'improved', 'improved outcome', 'learning algorithm', 'novel', 'patient oriented', 'programs', 'research and development', 'skills', 'statistical learning', 'theories', 'uptake']",NIDCD,NORTHWESTERN UNIVERSITY,K24,2020,183209,0.004170699895233677
"Transforming Analytical Learning in the Era of Big Data PROJECT SUMMARY In this dawning era of `Big Data' it is vital to recruit and train the next generation of biomedical data scientists in `Big Data'. The collection of `Big Data' in the biomedical sciences is growing rapidly and has the potential to solve many of today's pressing medical needs including personalized medicine, eradication of disease, and curing cancer. Realizing the benefits of Big Data will require a new generation of leaders in (bio)statistical and computational methods who will be able to develop the approaches and tools necessary to unlock the information contained in large heterogeneous datasets. There is a great need for scientists trained in this specialized, highly heterogeneous, and interdisciplinary new field of health big data. Thus, the recruitment of talented undergraduates in science, technology, engineering and mathematics (STEM) programs is vital to our ability to tap into the potential that `Big Data' offers and the challenges that it presents. The University of Michigan Undergraduate Summer Institute: Transforming Analytical Learning in the Era of Big Data will primarily draw from the expertise and experience of faculty from three different departments within three different schools at the University of Michigan: Biostatistics in the School of Public Health, Computer Science in the School of Engineering, Statistics in the College of Literature, Sciences and the Arts. The faculty instructors and mentors have backgrounds in Statistics, Computer Science, Information Science, Medicine, Population Health, Social and Biological Sciences. They have active research programs in a broad spectrum of methodological areas including statistical modeling, data mining, natural language processing, statistical and machine learning, large-scale optimization, matrix computation, medical computing, health informatics, high- dimensional statistics, distributed computing, missing data, causal inference, data management and integration, signal processing and medical imaging. The diseases and conditions they study include obesity, diabetes, cardiovascular disease, cancer, neurological disease, kidney disease, injury, macular degeneration and Alzheimer's disease. The areas of biology include neuroscience, genetics, genomics, metabolomics, epigenetics and socio-behavioral science. Undergraduate trainees selected will have strong quantitative skills and a background in STEM. The summer institute will consist of a combination of coursework, to raise the skills and interests of the participants to a sufficient level to consider pursuing graduate studies in `Big Data' science, along with an in depth mentoring component that will allow the participants to research a specific topic/project utilizing `Big Data'. We have witnessed tremendous enthusiasm and success with the current summer program on Big Data led by this team with 164 students trained in the last 4 years (2015-2018) including 90 female students and 30 students from underrepresented minority groups. Fourteen of these participants from the last three years are currently graduate students in Michigan Biostatistics. The ongoing program has gained traction in the national landscape of summer research programs with 20% rate of admission and 80% rate of acceptance among those who are offered this opportunity. The program has consistently received very strong evaluation and our past alumni have become brand ambassadors and advocates for our program. We plan to build on the success and legacy of this program in the next three year funding cycle of this grant (2019-2021). The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm. This six week long summer institute will recruit a group of approximately 45 undergraduates nationally and internationally, with 20 domestic students supported by the requested SIBS funding mechanism and others supported by supplementary institutional and foundation support. We propose to expose the trainees to diverse techniques, skills and problems in the field of health Big Data. They will be taught and mentored by a team of interdisciplinary faculty, reflecting the shared intellectual landscape needed for Big Data research. They will engage in mentored research projects in three primary areas of health big data: Electronic Health Records/Medical Claims, Genomics and Imaging. Some of the projects will be defined in the area of cardiovascular precision medicine, defined by a team of highly quantitative researchers engaged in cardiovascular research that uses big data. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by U-M researchers, outside guests and a professional development workshop to prepare the students for graduate school. We propose an inter-SIBS collaboration with Dordt College summer program trainees who will attend this concluding symposium. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material for undergraduate students in this new field across the world. We will offer multiple professional development opportunities and resources for graduate school preparation to our trainees so that they can reflect and plan beyond their senior year. All of our proposed activities are reflected through our three specific aims: Teaching, Mentoring and Dissemination. PROJECT NARRATIVE We propose a six week long undergraduate summer institute: “Transforming Analytical Learning in the Era of Big Data” to be held at the Department of Biostatistics, University of Michigan (U-M), Ann Arbor, with a group of approximately 45 undergraduate students recruited nationally and internationally, from 2019-2021. Funding is requested for 20 domestic students with supplementary funding expected to be garnered through institutional resources and private foundation support. The program builds on the success of our existing Big Data Summer Institute (BDSI) supported by a NIH BD2K Courses and Skills grant award that is ending in 2018. We plan to expose program students to diverse techniques, skills and problems in the field of Big Data and Human Health. We enhance our ongoing summer program structure in the current proposal by involving a team of researchers working at the intersection of cardiovascular research and data science with a focus on cardiovascular precision medicine where some of the new mentored research projects will be defined. We primarily focus on three genres of health Big Data arising in Electronic Health Records/Medical Claims, Genomics and Imaging. The trainees will be taught and mentored by a team of interdisciplinary faculty from Biostatistics, Computational Medicine and Bioinformatics, Statistics, Computer Science and Engineering, Information Sciences, Epidemiology and Medicine, reflecting the shared intellectual landscape needed for Big Data research. At the conclusion of the program there will be a concluding capstone symposium showcasing the research of the students via poster and oral presentation. There will be lectures by (U-M) researchers, outside guests and a professional development workshop to prepare the students for graduate school. The resources developed for the summer institute, including lectures, assignments, projects, template codes and datasets will be freely available through a Wiki page so that this format can be replicated anywhere in the world. This democratic dissemination plan will lead to access of teaching and training material in this new field across the world. The overarching goal of our summer institute in big data is to recruit and train the next generation of big data scientists using a non-traditional, action-based learning paradigm and engage them in influential research related to human health.",Transforming Analytical Learning in the Era of Big Data,9888408,R25HL147207,"['Admission activity', 'Adverse drug effect', 'Advocate', 'Alzheimer&apos', 's Disease', 'Area', 'Arts', 'Award', 'Basic Science', 'Big Data', 'Big Data to Knowledge', 'Bioinformatics', 'Biological Markers', 'Biological Sciences', 'Biology', 'Biometry', 'Cardiovascular Diseases', 'Cardiovascular system', 'Case Study', 'Clinical', 'Clinical Sciences', 'Code', 'Collaborations', 'Collection', 'Computing Methodologies', 'Data', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Diabetes Mellitus', 'Disease', 'Educational process of instructing', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Epidemiology', 'Epigenetic Process', 'Evaluation', 'Exposure to', 'Faculty', 'Female', 'Foundations', 'Funding', 'Funding Mechanisms', 'Generations', 'Genetic', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Sciences', 'Human', 'Image', 'Influentials', 'Information Sciences', 'Injury', 'International', 'Kidney Diseases', 'Learning', 'Literature', 'Macular degeneration', 'Malignant Neoplasms', 'Medical', 'Medical Imaging', 'Medical Records', 'Medicine', 'Mentors', 'Methodology', 'Methods', 'Michigan', 'Minority Groups', 'Natural Language Processing', 'Neurosciences', 'Obesity', 'Oral', 'Participant', 'Prevention', 'Privatization', 'Problem Sets', 'Public Health Informatics', 'Public Health Schools', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'STEM program', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics', 'Scientist', 'Social Behavior', 'Social Sciences', 'Statistical Methods', 'Statistical Models', 'Structure', 'Student recruitment', 'Students', 'Talents', 'Techniques', 'Traction', 'Training', 'Underrepresented Minority', 'United States National Institutes of Health', 'Universities', 'Woman', 'Work', 'base', 'big-data science', 'burden of illness', 'cluster computing', 'college', 'computer science', 'data integration', 'data management', 'data mining', 'data visualization', 'design', 'experience', 'graduate school preparation', 'graduate student', 'heterogenous data', 'high dimensionality', 'instructor', 'interest', 'lectures', 'medical schools', 'member', 'metabolomics', 'nervous system disorder', 'network models', 'next generation', 'novel therapeutics', 'open source', 'personalized medicine', 'population health', 'posters', 'precision medicine', 'programs', 'recruit', 'signal processing', 'skills', 'statistical and machine learning', 'statistics', 'student training', 'success', 'summer institute', 'summer program', 'summer research', 'symposium', 'tool', 'undergraduate student', 'underrepresented minority student', 'wiki']",NHLBI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R25,2020,250974,0.06034460722122381
"INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE Project Summary  To understand the many disorders of the brain it is necessary to grapple with its complexity.  Increasingly large and complicated data sets are being collected, but the tools for analyzing and  modeling the data are not yet available. More researchers trained in computational neuroscience are  desperately needed. This project supports graduate and undergraduate training programs in  computational neuroscience (TPCN) at both Carnegie Mellon University (CMU) and the University of  Pittsburgh (Pitt), and a summer school in computational neuroscience for undergraduates, which are  available to students coming from colleges and universities throughout the United States.  The CMU-Pitt TPCN has 16 training faculty in computational neuroscience, 22 training faculty whose  laboratories are primarily experimental, and 20 training faculty whose laboratories are both  computational and experimental. At the graduate level the TPCN offers a PhD program in Neural  Computation (PNC) and joint PhD programs with CMU’s Department of Statistics (PNC-Stat) and its  Machine Learning Department (PNC- MLD), all set within a highly collegial, cross-disciplinary  environment of our Center for the Neural Basis of Cognition (CNBC), which is operated jointly by  CMU and Pitt. The CNBC was established in 1994 to foster interdisciplinary research on the neural  mechanisms of brain function, and now comprises 145 faculty having appointments in 22 departments.  At the undergraduate level a substantial pool of local students is supplemented during the summer  by a cohort of students from across the country. During this renewal funding period the project is  strengthening the role of statistics and machine learning throughout the training programs; (2) revising the summer undergraduate program by creating a didactic two-week “boot camp” at the  beginning, which includes a 20-lecture overview of computational neuroscience; (3) creating online  materials, in conjunction with the boot camp, that will serve not only our own students but also  the greater world of training in computational neuroscience; and (4) enhancing our minority  recruitment by (a) taking advantage of the boot camp and online materials, as well as making  promotional visits to targeted campuses, and (b) creating and running a one-year “bridge” program  to better prepare under-represented minorities for PhD programs.  TPCN trainees work in vertically integrated, cross-disciplinary research teams. Graduate students  take a year- long course in computational neuroscience that bridges modeling and modern statistical  machine learning approaches to neuroscience. To ensure their competency in core neuroscience  principles they also take courses in cognitive neuroscience, neurophysiology, and systems  neuroscience. They then pursue depth in a relevant quantitative discipline, such as computer  science, engineering, mathematics, or statistics. Graduate students have extended experience in at  least one experimental laboratory, and they take part in journal clubs and seminars within the  large Pittsburgh neuroscience community. Year-long undergraduates take courses in mathematics,  computer programming, statistics, and neuroscience; they take an additional course in neuroscience  or psychology and a course in computational neuroscience; and they complete a year-long research  project. In addition, they complete the TPCN summer program. Undergraduate trainees in the summer  program go through the boot camp on topics in computational neuroscience, including tutorials in  Matlab, statistical methods, fundamentals of differential equations, and ideas of neural coding;  they then complete a research project under careful guidance. All trainees will receive training in  responsible conduct of research. Across 5 years of funding, the TPCN supports 20 NRSA graduate  students, 10 non-NRSA graduate students, 30 undergraduate year-long fellows, and 60 undergraduate  summer fellows. Project Narrative  Research in neuroscience is crucial for attacking the causes of neurological and mental health  disorders. If the field of neuroscience is to continue its rapid advance, neuroscientists must use,  understand, and develop new technologies, acquire and analyze ever larger data sets, and grapple  more directly with the complexity of neurobiological systems. The primary goal of these training  programs will be to help train a new generation of interdisciplinary neuroscientists with strong  quantitative skills.",INTERDISCIPLINARY TRAINING IN COMPUTATIONAL NEUROSCIENCE,10004013,R90DA023426,"['Appointment', 'Brain', 'Brain Diseases', 'Code', 'Cognition', 'Communities', 'Competence', 'Country', 'Data Set', 'Differential Equation', 'Discipline', 'Doctor of Philosophy', 'Educational Status', 'Engineering', 'Ensure', 'Environment', 'Faculty', 'Fostering', 'Funding', 'Interdisciplinary Study', 'Joints', 'Journals', 'Laboratories', 'Machine Learning', 'Mathematics', 'Minority Recruitment', 'Modeling', 'Modernization', 'National Research Service Awards', 'Neurosciences', 'Psychology', 'Research', 'Research Personnel', 'Research Project Grants', 'Role', 'Running', 'Schools', 'Statistical Methods', 'Students', 'System', 'Teacher Professional Development', 'Training', 'Training Programs', 'Underrepresented Minority', 'United States', 'Universities', 'Visit', 'Work', 'bridge program', 'cognitive neuroscience', 'cohort', 'college', 'computational neuroscience', 'computer program', 'computer science', 'data modeling', 'experience', 'graduate student', 'lectures', 'neuromechanism', 'neurophysiology', 'programs', 'relating to nervous system', 'responsible research conduct', 'statistical and machine learning', 'statistics', 'summer program', 'tool', 'undergraduate student']",NIDA,CARNEGIE-MELLON UNIVERSITY,R90,2020,239423,0.03394526838430016
"Training the next generation of leaders in biomedical engineering design Project Summary/Abstract The next generation of bioengineering and biomedical researchers will have unprecedented access to technologies including wireless health, big data, genetic sequencing, and machine learning approaches to enable modern diagnostic and therapeutic techniques. This presents individuals trained at the interface of technology and biomedicine with an enormous opportunity to address the world’s needs in health and medicine. In the Bioengineering Department at the University of California, Los Angeles, we aim to develop students into leaders able to seamlessly identify clinical needs that technology can address, design and validate solutions that address these needs, communicate with a variety of stakeholders to build teams invested in problem-oriented solutions, and to navigate the regulatory and commercial pathways necessary to enable their technologies to thrive. The Bioengineering Capstone Series at UCLA leverages resources available at UCLA to enable students to: 1) gain insight into clinical needs directly from clinicians and educators across the Ronald Reagan Medical Center, David Geffen School of Medicine, School of Dentistry and UCLA Health System, 2) design their solutions through mentorship from engineering professors, 3) understand the complexities of the biomedical industry with support from the UCLA Technology Development Group and members of the Department of Engineering Industry Advisory Board, 4) utilize modern technologies in wireless health and data science by collaborating with the Center of Excellence for Mobile Sensor Data- to-Knowledge (MD2K) and Mobile Health (mHealth) Institute at UCLA, and 5) work with the National Science Foundation Precise Advanced Technologies and Health Systems for Underserved Populations Engineering Research Center (NSF PATHS- UP ERC) to learn to target and communicate their technologies to maximize societal benefits. Statement of Public Health Relevance: To prepare the next generation of engineers with skills in the design of therapeutics and medical devices, this research education program will provide bioengineering students at UCLA with enhanced opportunities to engage in real world design for biomedical applications. We will guide students through the medical design process from identifying needs, creating solutions which address these needs, and communicating the significance of their contributions to the greater community, ultimately yielding a larger pool of well-trained engineers to address biomedical challenges. !",Training the next generation of leaders in biomedical engineering design,9951056,R25EB027626,"['Address', 'Applied Research', 'Area', 'Big Data', 'Biomedical Engineering', 'Biomedical Technology', 'California', 'Clinic', 'Clinical', 'Communication', 'Communities', 'Data', 'Data Science', 'Device or Instrument Development', 'Devices', 'Diagnostic', 'Educational workshop', 'Engineering', 'Event', 'Faculty', 'Fostering', 'Foundations', 'Freedom', 'Future', 'Genetic', 'Goals', 'Health', 'Health Sciences', 'Health Technology', 'Health system', 'Healthcare', 'High School Student', 'Home environment', 'Individual', 'Industry', 'Infrastructure', 'Institutes', 'Instruction', 'Intellectual Property', 'Investments', 'Laboratories', 'Learning', 'Los Angeles', 'Machine Learning', 'Medical', 'Medical Device', 'Medical center', 'Medicine', 'Mentorship', 'Modernization', 'Pathway interactions', 'Patient Monitoring', 'Physiological', 'Process', 'Recommendation', 'Regulation', 'Research', 'Research Personnel', 'Resources', 'STEM field', 'School Dentistry', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Series', 'Societies', 'Structure', 'Students', 'System', 'Techniques', 'Technology', 'Technology Transfer', 'Therapeutic', 'Time', 'Training', 'Translations', 'Travel', 'Underrepresented Students', 'Underserved Population', 'Universities', 'Wireless Technology', 'Work', 'base', 'career', 'clinically actionable', 'cloud based', 'commercialization', 'data to knowledge', 'deep learning', 'design', 'education research', 'engineering design', 'experience', 'insight', 'interest', 'lectures', 'mHealth', 'medical schools', 'member', 'multidisciplinary', 'next generation', 'outreach', 'product development', 'professor', 'programs', 'public health relevance', 'sensor', 'skills', 'technology development', 'undergraduate student']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R25,2020,21600,0.012570940406218771
"A decentralized macro and micro gene-by-environment interaction analysis of substance use behavior and its brain biomarkers   Abstract Wide-spread data sharing has started to permeate the brain imaging community from funders to researchers. However, in recent years there have also been some concerns raised regarding ethical issues related to privacy and data ownership among others. In the parent award we are leveraging and extending a privacy preserving decentralized data sharing platform called COINSTAC to perform a study of gene-by-environmental effects by pooling together data from across the world, some of which is unable to be openly shared. In this supplement we will study various bioethical issues related to different data sharing strategies. This will include calculating risk scores from existing data to evaluate the effectiveness of machine learning to potentially reidentify from similar or different data types, a detailed survey of various policy makers and stakeholders including researchers, federal employees, IRB members, and more, and finally the development of a forward looking white paper addressing both privacy, policy, and regulatory aspects which attempts to frame the various aspects that arise in the contact of the spectrum of data sharing approaches including fully open, ‘trust’ based via data usage agreements, privacy preserving via tools like COINSTAC, and more. The outcomes of this supplement will provide a useful guide for the field going forward and also provide initial data necessary to develop a larger scale project on these topics going forward. Narrative The era of big data, open science, and deep learning is upon us, and data sharing can be done in various ways ranging from fully open to privacy preserving to fully closed. However bioethical issues related to risk, privacy, and data sharing strategies have not been well studied in the context of combined brain imaging, genomics, and macro-environmental data and can be especially sensitive in the context of information such as substance use. In this supplement we will quantify risk levels, survey a broad community of stakeholders, and develop recommendations for the field going forward.",A decentralized macro and micro gene-by-environment interaction analysis of substance use behavior and its brain biomarkers  ,10131528,R01DA049238,"['Address', 'Adolescence', 'Adolescent', 'Age', 'Agreement', 'Alcohol or Other Drugs use', 'Anxiety', 'Award', 'Behavior', 'Behavioral', 'Behavioral Genetics', 'Big Data', 'Bioethical Issues', 'Biological Markers', 'Brain', 'Brain imaging', 'Brain scan', 'China', 'Climate', 'Communities', 'Complex', 'Computer software', 'Consumption', 'Country', 'Data', 'Data Protection', 'Decentralization', 'Development', 'Disease', 'Dropout', 'Economic Burden', 'Employee', 'Environment', 'Environmental Risk Factor', 'Epidemiology', 'Ethical Issues', 'Ethnic group', 'Europe', 'Family', 'Genes', 'Genetic', 'Genomics', 'Genotype', 'Heritability', 'Household', 'Image', 'Income', 'India', 'Individual', 'Institutional Review Boards', 'International', 'Intervention', 'Learning', 'Legal', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mental Depression', 'Modeling', 'Movement', 'Neurobiology', 'Neurons', 'Neurosciences', 'Outcome', 'Ownership', 'Paper', 'Parents', 'Physiological', 'Policies', 'Policy Maker', 'Population', 'Population Density', 'Privacy', 'Quality Control', 'Race', 'Recommendation', 'Regulation', 'Research Personnel', 'Risk', 'Scanning', 'Smoking', 'Source Code', 'Structure', 'Surveys', 'System', 'Time', 'Trust', 'Twin Multiple Birth', 'Update', 'Urbanization', 'Visualization', 'adolescent substance use', 'base', 'cloud based', 'cognitive development', 'cohort', 'computerized tools', 'cost', 'data access', 'data exchange', 'data sharing', 'deep learning', 'drinking', 'early life stress', 'effectiveness evaluation', 'epidemiologic data', 'gene environment interaction', 'genetic profiling', 'human subject', 'imaging genetics', 'insight', 'member', 'neuroimaging', 'open data', 'open source', 'peer', 'privacy preservation', 'psychiatric symptom', 'relating to nervous system', 'rural area', 'sex', 'sharing platform', 'statistics', 'tool', 'tool development', 'urban area', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2020,149834,-0.013778674597094719
"Center of Excellence in Environmental Toxicology OVERALL : ABSTRACT This is the third competing continuation for an accomplished Environmental Health Sciences Core Center (EHS CC), The Center of Excellence in Environmental Toxicology (CEET) at the University of Pennsylvania (Penn). The Director is Trevor M. Penning, PhD (The Thelma Brown and Henry Charles Molinoff Professor of Pharmacology) and the Deputy Director is Rebecca A. Simmons, MD (The Hallam Hurt Endowed Professor in Pediatrics). The Center is comprised of 71 members from 18 Departments and 5 Schools, with almost equal representation of basic and clinician-scientists drawn from the Perelman School of Medicine (PSOM) and Children’s Hospital of Philadelphia (CHOP). The CEET has built an institutional, regional and national identity in environmental health sciences (EHS) in the absence of a School of Public Health and Department of EHS at Penn. The synergistic combination of basic and clinician-scientists within the CEET promotes translational environmental health research that addresses fundamental questions and translates knowledge into action to have a major impact on human health and disease consistent with the NIEHS Strategic Plan. The CEET mission is to “elucidate the mechanistic links between environmental exposures and human disease, and translate findings into action to improve the health of vulnerable individuals, and local, national, and global communities”. This mission is accomplished through five aims. In Aim 1: We use a flexible thematic area structure to conduct translational environmental health research to improve precision public health. Our current themes are in Air Pollution & Lung Health; Environmental Exposures & Cancer; Windows-of- Susceptibility; and Environmental Neuroscience. Each thematic area integrates the pillars or exposure science, adverse outcome constructs (pathways and networks) to explain the phenome with translation to communities and human subjects. In Aim 2: We conduct bi-directional communication with communities in S.E and N.E. Pennsylvania and use community engagement to set the research agenda for the CEET. In Aim 3: We provide a facility core structure to promote precision public health. Our Integrative Health Sciences Facility Core is adept in human subject study design and in conducting population exposure services, using cartographic modeling, GIS tools and biosensors. Biomarkers of exposure and effect are measured in our Translational Biomarker Core which conducts mass spectrometric assays at a level of precision and accuracy difficult to emulate elsewhere. The Exposure Biology Informatics Core brings to bear the power of computation, machine learning and AI to predict the toxicity of unknowns and integrate Big-data sets to recognize patterns in “omics” data and predict adverse outcomes. In Aim 4: We build capacity in environmental health sciences by funding pilot projects to Early Stage Investigators (ESI) and to senior investigators conducting environmental health research for the first time. In Aim 5: We cultivate the careers of ESI through a transformative Environmental Health Scientist Support Program that provides mentoring, grant proposal review, environmental health and Facility Core workshops. OVERALL : NARRATIVE The Center of Excellence in Environmental Toxicology (CEET) conducts research that links environmental exposures, to adverse outcomes and translates its findings to human subjects and communities to identify the most vulnerable and improve prevention, intervention and treatment through precision public health. Bi- directional communication through the Community Engagement Core helps set the research agenda of the CEET and inform public health decision making.",Center of Excellence in Environmental Toxicology,9917966,P30ES013508,"['Address', 'Air Pollution', 'Applications Grants', 'Area', 'Artificial Intelligence', 'Asbestos', 'Award', 'Beer', 'Big Data', 'Biological Assay', 'Biological Markers', 'Biology', 'Biosensor', 'Cities', 'Communication', 'Communities', 'Community Healthcare', 'Complement', 'Core Facility', 'Data', 'Data Set', 'Decision Making', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Environmental Exposure', 'Environmental Health', 'Exposure to', 'Funding', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Home environment', 'Human', 'Human Subject Research', 'Individual', 'Informatics', 'Integrative Medicine', 'Knowledge', 'Laboratories', 'Link', 'Lung', 'Machine Learning', 'Measures', 'Mentors', 'Mission', 'Modeling', 'National Institute of Environmental Health Sciences', 'Neurosciences', 'Pathway interactions', 'Pattern', 'Pediatric Hospitals', 'Pediatrics', 'Pennsylvania', 'Pharmacology', 'Philadelphia', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Predisposition', 'Preventive Intervention', 'Public Health', 'Public Health Schools', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Schools', 'Science', 'Scientist', 'Services', 'Strategic Planning', 'Structure', 'Superfund', 'Time', 'Toxic effect', 'Toxicology', 'Training Programs', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Ursidae Family', 'Vulnerable Populations', 'adverse outcome', 'career', 'career development', 'cheminformatics', 'environment related cancer', 'environmental toxicology', 'exposed human population', 'flexibility', 'health science research', 'human disease', 'human subject', 'improved', 'lead exposure', 'medical schools', 'member', 'next generation', 'phenome', 'professor', 'programs', 'recruit', 'response', 'skills', 'tool', 'wasting']",NIEHS,UNIVERSITY OF PENNSYLVANIA,P30,2020,1616900,-0.015528985812710368
"Nathan Shock Center of Excellence in Basic Biology of Aging OVERALL PROJECT SUMMARY This application is for renewal of the Nathan Shock Center of Excellence in the Basic Biology of Aging at the University of Washington and affiliated institutions. This Center has over the past 25 years provided key resources in support of investigators who study the biology of aging. This application continues a theme that emphasizes outreach and service to the broadest community of investigators in the gerosciences. Of proximal relevance is the characterization of aging-related phenotypes of longevity and healthspan. As our Center services must be easily accessible to outside users, our Longevity and Healthspan Core (Core E) focuses on invertebrate assays, many of them novel. Two other Resources Cores focus on the high dimensional assessments that are closely related to aging phenotypes: Protein Phenotypes of Aging (Core C) and Metabolite Phenotypes of Aging (Core D). Sophisticated computational and bioinformatic tools for data analysis and optimal insight are provided by the Artificial Intelligence and Bioinformatics Core F. Each of these four Resource Cores is led by highly respected experts in that field, including Michael MacCoss and Judit Villen (Core C), Daniel Promislow (Core D), Matt Kaeberlein and Maitreya Dunham (Core E) and Su-In Lee (Core F). Each will push the envelope of appropriate technologies, developing new state-of-the art approaches for assessments that are the most applicable to gerontology and making them accessible to the national aging community. The Research Development Core (Core B) will continue to support pilot and junior faculty studies, with a firm focus on outreach of service to the national geroscience constituency. The Administrative and Program Enrichment Core (Core A) supports administrative management, an external advisory panel, courses, and data sharing and dissemination. Core A’s program of seminars and symposia will continue a focus on sponsorship and organization of national courses, meetings and pre-meetings, as well as workshops in the fields allied to our Resource Core Services. In coordination with other Nathan Shock Centers, we will support a new Geropathology Research initiative. UW NATHAN SHOCK CENTER OVERALL - PROJECT NARRATIVE We apply for renewal of the Nathan Shock Center of Excellence in the Basic Biology of Aging at the University of Washington, which has for 25 years provided key resources supporting investigators who study the biology of aging. The overarching goal of this Center is to have a positive impact on the field by accelerating research discovery and providing research support for investigators nationally and internationally, particularly junior investigators in the process of building their own research programs. We will accomplish this goal through six cores that function synergistically together: four Resource Cores with particular expertise in protein (Core C) and metabolite (Core D) phenotypes of aging, invertebrate longevity and healthspan phenotypes (Core E) and artificial intelligence and bioinformatics (Core F), along with a Research Development Core (Core B) that supports external pilot projects and junior faculty studies, and an Administrative and Program Enrichment Core (Core A) that supports administrative management, an external advisory panel, sponsorship and organization of national meetings and pre-meetings, courses, workshops and seminars, and, in coordination with other Nathan Shock Centers, a Geropathology Research initiative.",Nathan Shock Center of Excellence in Basic Biology of Aging,10042617,P30AG013280,"['Aging', 'Artificial Intelligence', 'Bioinformatics', 'Biological Assay', 'Biology of Aging', 'Collaborations', 'Communication', 'Communities', 'Consult', 'Data', 'Data Analyses', 'Development', 'Educational workshop', 'Environment', 'Experimental Designs', 'Faculty', 'Genes', 'Genetic study', 'Gerontology', 'Geroscience', 'Goals', 'Growth', 'Informatics', 'Institution', 'International', 'Invertebrates', 'Leadership', 'Longevity', 'Methodology', 'Methods', 'Microfluidics', 'Molecular Genetics', 'Office of Administrative Management', 'Pathway interactions', 'Phenotype', 'Philosophy', 'Pilot Projects', 'Post-Translational Protein Processing', 'Process', 'Proteins', 'Proteomics', 'Research', 'Research Activity', 'Research Personnel', 'Research Support', 'Resources', 'Robotics', 'Services', 'Shock', 'Statistical Data Interpretation', 'Technology', 'Transcript', 'Universities', 'Variant', 'Washington', 'bioinformatics tool', 'career development', 'cell age', 'computerized tools', 'data dissemination', 'data sharing', 'healthspan', 'high dimensionality', 'insight', 'meetings', 'metabolomics', 'multiple omics', 'novel', 'outreach', 'outreach services', 'programs', 'protein metabolite', 'research and development', 'symposium', 'tool', 'trait']",NIA,UNIVERSITY OF WASHINGTON,P30,2020,962037,0.00958505989724463
"Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning There is an enormous need for qualified people to pursue careers in STEM (Noonan, 2017). However, the lack of a strong foundation in mathematics means students are less likely to pursue STEM majors and careers (Chen, 2013; Griffith, 2010; Huang, Taddese, & Walter, E, 2000; Kokkelenberg & Sinha, 2010; Lowell et. al., 2009). Students from low-income families, women, and underrepresented minorities are also less likely to major in STEM (Bettinger, 2010; Griffith, 2010; Hill, Corbett & Rose, 2010; Kokkelenberg & Sinha, 2010). Improving math learning in the elementary grades is important to ensure children have the essential foundational skills and strong self-efficacy beliefs to be able to succeed with later mathematics and pursue careers in STEM. With this Fast-Track grant, Class Store ( CS ) , we propose to transform the way in which students learn Number and Operations in Base Ten. CS will be an engaging, commercially available, classroom-based economy game for tablets and Chromebooks that focuses on multi-digit operations. CS will encourage conceptual understanding and build math self-efficacy for students in grades K-5 within the context of a digital, classroom-based marketplace. Within the game, students will create stores, craft objects to sell, engage in selling/purchasing transactions, and work together to increase the value of the economy. In addition, the game will utilize artificial intelligence (AI) to detect strategies students use and help teachers facilitate rich mathematical discussions thereby enhancing students’ reasoning skills. Outcomes. The proposal will encourage three main outcomes, namely: 1) algorithms for detecting math strategies students use, 2) a discussion support dashboard, and 3) algorithms for predicting at-risk status. A key research aim is to determine whether the software can predict math strategies students use and detect which students are at-risk academically as compared to standardized assessment data, which will help teachers intervene appropriately. The discussion support dashboard will help to promote rich mathematical discussion, thereby improving students’ mathematical justification and conceptual understanding. The engaging game will bolster students’ motivation and self-efficacy in mathematics. Improving students’ academic outcomes and self-efficacy in base ten during elementary school will promote later success in high school mathematics. Since the number of advanced math classes students take is correlated with likelihood to complete a STEM degree, (Chen, 2013) a distal outcome of this proposal is increasing students pursuing careers in STEM. There is an enormous need for students majoring in the fields of Science, Technology, Engineering and Mathematics (STEM), yet lacking a strong foundation in mathematics makes students, especially women, minorities and those from low-income backgrounds, less likely to pursue careers in STEM. Class Store will bolster students’ mathematics abilities, including mathematical reasoning and self-efficacy, in the foundational area of Number and Operations in Base 10 in the short and long term. This will, in turn, lead to several positive distal outcomes, such as increased STEM majors and careers.",Building a classroom game economy to improve mathematical reasoning and prepare K-5 students for success in STEM learning,9889974,R44GM130197,"['Achievement', 'Algorithms', 'Area', 'Artificial Intelligence', 'Belief', 'Child', 'Code', 'Computer software', 'Data', 'Data Files', 'Detection', 'Digit structure', 'Distal', 'Elements', 'Ensure', 'Foundational Skills', 'Foundations', 'Goals', 'Grant', 'High School Student', 'Intervention', 'Investments', 'Lead', 'Learning', 'Low income', 'Marketing', 'Mathematics', 'Measures', 'Minority', 'Modeling', 'Outcome', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Research', 'Risk', 'STEM field', 'Sales', 'Scheme', 'Schools', 'Science, Technology, Engineering and Mathematics', 'Self Efficacy', 'Standardization', 'Structure', 'Students', 'Tablets', 'Testing', 'Transact', 'Underrepresented Minority', 'Woman', 'Work', 'base', 'career', 'dashboard', 'design', 'digital', 'elementary school', 'experience', 'field study', 'fifth grade', 'fourth grade', 'high school', 'improved', 'iterative design', 'lower income families', 'mathematical ability', 'mathematical learning', 'mathematical theory', 'operation', 'prediction algorithm', 'prototype', 'second grade', 'skills', 'student participation', 'success', 'support tools', 'teacher', 'usability']",NIGMS,"TEACHLEY, LLC",R44,2020,575531,0.02652493499100191
"Clinical Research Education in Genome Science (CREiGS) Project Summary/Abstract  The sensitivity and availability of omic technologies have enabled the genomic, transcriptomic and proteomic characterization of disease phenotypes, at the tissue and even the single cell level. This has allowed development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. Patients of providers who have participated in these educational initiatives also benefit as it allows for more rapid integration of genomic study findings into the clinical care setting. Thus, in response to PAR-19-185, we propose to develop and implement the Clinical Research Education in Genome Science (CREiGS) program that will not only focus on the analysis of genomic data, but also on gene-expression data, the integration of these two data types, as well as introductory theory and application of statistical and machine learning methods. Specifically we propose to accomplish the following specific aims: 1. Develop and successfully implement the online and in-person phases of CREiGS to increase the methodologic ingenuity by which researchers tackle important genomics-related clinical problems. 2. Establish a Diversity Recruitment External Advisory Board to ensure that the most effective strategies are employed to recruit URM doctoral students, postdoctoral fellows, and faculty from academic institutions nationwide into CREiGS. 3. Enhance the dissemination phase of CREiGS by packaging and uploading the asynchronous lectures and the online critical thinking/problem solving assessments with solutions for publicly available, online teaching resources. 4. Implement effective methods to evaluate the efficacy of CREiGS by examining:1) the participants' grasp of the CREiGS core competencies, 2) the clarity and quality of the curriculum, 3) program logistics and operation, and 4) the participants' short-term and long-term success attributed to participation in CREiGS. In summary, we posit that CREiGS will provide participants with a solid foundation in genomics science to answer complex, clinical questions. We believe that CREiGS supports the mission of the NHGRI by providing researchers with rigorous training to “accelerate medical breakthroughs that improve human health.” Project Narrative The sensitivity and availability of omic technologies have allowed for the development of treatments that target specific disease subtypes, most notably in cancer treatment, and thus opened up opportunities for the development of precision/personalized medicine strategies for optimizing treatments for individual patients. Thus, new genomic science educational initiatives need to be continually updated to educate the clinical and translational workforce on how to effectively interpret and apply the findings from genomics studies. The overall goal of the Clinical Research Education in Genome Science program is to increase the methodologic ingenuity of students, postdoctoral fellows, and faculty from academic institutions nationwide through a solid foundation in genomics science to answer complex, clinical research questions and improve patient care.",Clinical Research Education in Genome Science (CREiGS),9934567,R25HG011021,"['Area', 'Biomedical Research', 'Cells', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Competence', 'Complex', 'Critical Thinking', 'Data', 'Data Analyses', 'Development', 'Educational Curriculum', 'Educational process of instructing', 'Ensure', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Gene Expression', 'Genetic', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'Hour', 'Human', 'Hybrids', 'Institution', 'Knowledge', 'Logistics', 'Machine Learning', 'Medical', 'Methodology', 'Methods', 'Mission', 'National Human Genome Research Institute', 'Outcome', 'Participant', 'Patient Care', 'Patients', 'Persons', 'Phase', 'Phenotype', 'Play', 'Postdoctoral Fellow', 'Problem Solving', 'Proteomics', 'Provider', 'Recruitment Activity', 'Reproducibility', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Role', 'Single Nucleotide Polymorphism', 'Solid', 'Statistical Methods', 'Students', 'Technology', 'Tissues', 'Training', 'Translational Research', 'Treatment outcome', 'Underrepresented Minority', 'Underserved Population', 'Update', 'cancer therapy', 'clinical care', 'clinical efficacy', 'computerized tools', 'data integration', 'data management', 'disease phenotype', 'disorder subtype', 'doctoral student', 'education research', 'genetic analysis', 'genome sciences', 'genomic data', 'grasp', 'health disparity', 'improved', 'individual patient', 'innovation', 'lectures', 'machine learning method', 'operation', 'personalized medicine', 'precision medicine', 'programs', 'recruit', 'response', 'statistical and machine learning', 'success', 'theories', 'therapy development', 'tool', 'transcriptomics', 'treatment optimization', 'virtual']",NHGRI,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R25,2020,161662,0.005573101758523138
"Statistical Methods for Ultrahigh-dimensional Biomedical Data This proposal develops novel statistics and machine learning methods for distributed analysis of big data in biomedical studies and precision medicine and for selecting a small group of molecules that are associated with biological and clinical outcomes from high-throughput data such as microarray, proteomic, and next generation sequence from biomedical research, especially for autism studies and Alzheimer’s disease research. It focuses on developing efficient distributed statistical methods for Big Data computing, storage, and communication, and for solving distributed health data collected at different locations that are hard to aggregate in meta-analysis due to privacy and ownership concerns. It develops both computationally and statistically efficient methods and valid statistical tools for exploring heterogeneity of big data in precision medicine, for studying associations of genomics and genetic information with clinical and biological outcomes, and for feature selection and model building in presence of errors-in- variables, endogeneity, and heavy-tail error distributions, and for predicting clinical outcomes and understanding molecular mechanisms. It introduces more robust and powerful statistical tests for selection of significant genes, SNPs, and proteins in presence of dependence of data, valid control of false discovery rate for dependent test statistics, and evaluation of treatment effects on a group of molecules. The strength and weakness of each proposed method will be critically analyzed via theoretical investigations and simulation studies. Related software will be developed for free dissemination. Data sets from ongoing autism research, Alzheimer’s disease, and other biomedical studies will be analyzed by using the newly developed methods and the results will be further biologically confirmed and investigated. The research findings will have strong impact on statistical analysis of high throughput big data for biomedical research and on understanding heterogeneity for precision medicine and molecular mechanisms of autism, Alzheimer’s disease, and other diseases. This proposal develops novel statistical machine learning methods and bioinformatic tools for finding genes, proteins, and SNPs that are associated with clinical outcomes and discovering heterogeneity for precision medicine. Data sets from ongoing autism research, Alzheimer’s disease and other biomedical studies will be critically analyzed using the newly developed statistical methods, and the results will be further biologically confirmed and investigated. The research findings will have strong impact on developing therapeutic targets and understanding heterogeneity for precision and molecular mechanisms of autism, Alzheimer’s diseases, and other diseases. !",Statistical Methods for Ultrahigh-dimensional Biomedical Data,9900790,R01GM072611,"['Address', 'Alzheimer&apos', 's Disease', 'Big Data', 'Big Data Methods', 'Biological', 'Biomedical Research', 'Brain', 'Classification', 'Clinical', 'Communication', 'Computer software', 'Cox Models', 'Cox Proportional Hazards Models', 'Data', 'Data Set', 'Databases', 'Dependence', 'Dimensions', 'Disease', 'Disease Progression', 'Evaluation', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genomics', 'Heterogeneity', 'Internet', 'Investigation', 'Learning', 'Linear Models', 'Location', 'Meta-Analysis', 'Methods', 'Molecular', 'Outcome', 'Ownership', 'Patients', 'Polynomial Models', 'Principal Component Analysis', 'Privacy', 'Proteins', 'Proteomics', 'Research', 'Role', 'Statistical Data Interpretation', 'Statistical Methods', 'Tail', 'Techniques', 'Testing', 'Time', 'autism spectrum disorder', 'big biomedical data', 'bioinformatics tool', 'cell type', 'computing resources', 'feature selection', 'genetic information', 'health data', 'high dimensionality', 'high throughput analysis', 'improved', 'machine learning method', 'macrophage', 'model building', 'next generation', 'novel', 'precision medicine', 'predict clinical outcome', 'simulation', 'statistical and machine learning', 'statistics', 'therapeutic target', 'tool', 'transcriptome sequencing', 'treatment effect']",NIGMS,PRINCETON UNIVERSITY,R01,2020,293003,-0.019719329287953297
"Boston University CCCR OVERALL ABSTRACT The Boston University CCCR will serve as a central resource for clinical research focused mostly on the most common musculoskeletal disorders, osteoarthritis and gout and will also provide research resources for investigator based research in scleroderma, spondyloarthritis, musculoskeletal pain and osteoporosis. Center grant funding has supported 30-35 papers annually in peer reviewed journals, most in the leading arthritis journals and some in leading general medical journals. This center has trained many of the leading clinical researchers in rheumatology throughout the US and internationally, and many of these former trainees have active collaborations with the center. We will include a broad research community and a core group of faculty in this CCCR. The research community's ready access to core faculty and to the sophisticated research methods and assistance they provide will enhance the clinical and translational research of the community and will increase collaborative opportunities for the core faculty and the community. The CCCR updates BU's historical focus on epidemiologic methods to include new approaches to causal inference and adds new methods in machine learning and mobile health. The Research and Evaluation Support Core Unit (RESCU) is the focal point of this CCCR. A key feature is the weekly research (RESCU meetings in which ongoing and proposed research projects are critically evaluated. This feature ensures frequent interactions between clinician researchers, epidemiologists and biostatisticians who are the core members of the CCCR. The RESCU core unit has provided critical support for other Center grants related to rheumatic and arthritic disorders at Boston University, three current R01/U01's; five current NIH K awards (one K24, 3 K23's, one K01), an R03, an NIH trial planning grant (U34), and multiple ACR RRF awards. The overall goal of this center is to carry out and disseminate high-level clinical research informed both by state of the art clinical research methods and by clinical and biological scientific discoveries. Ultimately, we aim either to prevent the diseases we are studying or to improve the lives of those living with the diseases. NARRATIVE The Boston University Core Center for Clinical Research will provide broad clinical research methods expertise to a large multidisciplinary group of investigators whose research focuses on osteoarthritis and gout with a secondary emphasis on scleroderma, spondyloarthritis, osteoporosis and musculoskeletal pain. The group, which includes persons with backgrounds in rheumatology, physical therapy, epidemiology, biostatistics and  . behavioral science, meets weekly to critically review research projects and serves a broad research community with which it actively engages. It has been successful in publishing influential papers on the diseases of focus and in training many of the clinical research faculty in the US and internationally",Boston University CCCR,10017004,P30AR072571,"['Allied Health Profession', 'Area', 'Arthritis', 'Award', 'Behavioral Sciences', 'Biological', 'Biometry', 'Boston', 'Clinical', 'Clinical Research', 'Cohort Studies', 'Collaborations', 'Communities', 'Complement', 'Computerized Medical Record', 'Consensus', 'Consultations', 'Databases', 'Degenerative polyarthritis', 'Disease', 'Ensure', 'Environment', 'Epidemiologic Methods', 'Epidemiologist', 'Epidemiology', 'Europe', 'Evaluation', 'Excision', 'Faculty', 'Funding', 'Goals', 'Gout', 'Grant', 'Health', 'Influentials', 'Infusion procedures', 'Institutes', 'Institution', 'International', 'Journals', 'K-Series Research Career Programs', 'Machine Learning', 'Medical', 'Medical Research', 'Medical center', 'Methods', 'Musculoskeletal Diseases', 'Musculoskeletal Pain', 'New England', 'Osteoporosis', 'Outcome', 'Pain', 'Paper', 'Peer Review', 'Persons', 'Physical therapy', 'Privatization', 'Productivity', 'Public Health Schools', 'Publications', 'Publishing', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rheumatism', 'Rheumatoid Arthritis', 'Rheumatology', 'Risk Factors', 'Schools', 'Scleroderma', 'Spondylarthritis', 'Talents', 'Training', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Update', 'base', 'clinical center', 'cohort', 'design', 'epidemiology study', 'faculty community', 'faculty research', 'improved', 'innovation', 'interdisciplinary collaboration', 'mHealth', 'machine learning method', 'medical schools', 'meetings', 'member', 'multidisciplinary', 'novel', 'novel strategies', 'patient oriented', 'prevent', 'programs', 'protocol development', 'statistical service', 'success']",NIAMS,BOSTON UNIVERSITY MEDICAL CAMPUS,P30,2020,725375,-0.0022478735091961514
"Graphical Processing Units and a Large-Memory Compute Node for Applications in Genomics, Neuroscience, and Structural Biology Project Summary  Cold Spring Harbor Laboratory (CSHL) is a private, not-for-profit institution dedicated to research and education in biology, with leading research programs in genomics, neuroscience, quantitative biology, plant biology, and cancer. Many activities at CSHL depend critically on high-performance computing resources, but at present, investigators have limited access to Graphics Processing Units (GPUs) and large-memory compute nodes. This deficiency is beginning to hamper a wide variety of biomedical research activities, particularly in the key areas of genomics, neuroscience and structural biology, where such specialty hardware is becoming essential for many important computational analyses. Here, we propose to acquire four state-of-the-art GPU nodes, each equipped with eight Nvidia Tesla V100, SXM2, 32GB GPUs, two 20-core 2.5 GHz Intel Xeon-Gold 6248 (Cascade Lake) processors, and 768 GB of RAM. A second-generation Nvidia NVLink will provide for 300 GB/s inter-GPU communication. In addition, we propose to acquire one large-memory node with 3 TB of RAM and four 20-core 2.5 GHz Intel Xeon-Gold 6248 (Cascade Lake) processors, as well as a top-of-rack 10 Gb Ethernet switch to interconnect the servers with each other and with our existing computer cluster. These new resources will enable a wide variety of innovative research across fields, with direct implications for human health. In genomics, applications will include RNA-seq read mapping; alignment, base-calling, and genome assembly for long-read sequence data; clustering of single cell RNA-seq data; analysis of transposable elements; deep-learning methods for prediction of the fitness consequences of mutations; and deep-learning methods for interpreting high-throughput mutagenesis experiments. In neuroscience, they will include analysis of multi-neuron activity recordings; analysis of mouse brain images; and artificial neural network models of the human olfactory system, of audio features, and of behavior as a function of changing motivations. In structural biology, they will include image processing and 3D reconstruction from cryo-electron microscopy data. These new compute nodes will have a primary impact on the research programs of nine major users from the CSHL faculty with substantial NIH funding. They will also impact three minor users. The new GPU and large-memory nodes will be fully integrated with a soon-to-be-upgraded high-performance computer cluster and managed by the experienced Information Technology group at CSHL, with oversight from a committee of seven faculty members and two IT staff members. Altogether, these new computational resources will substantially enhance the overall computational infrastructure at CSHL. Project Narrative  Many areas of modern biomedical research depend critically on state-of-the-art computing resources. Here we propose to acquire two types of specialty computer hardware: four Graphics Processing Unit (GPU) nodes and a large-memory compute node, both of which will be fully integrated with an existing and soon-to-be-upgraded high-performance computer cluster. These resources will meet a wide variety of computing needs across research areas at Cold Spring Harbor Laboratory, particularly in the growing areas of genomics, neuroscience, and structural biology.","Graphical Processing Units and a Large-Memory Compute Node for Applications in Genomics, Neuroscience, and Structural Biology",9939826,S10OD028632,"['3-Dimensional', 'Area', 'Behavior', 'Biology', 'Biomedical Research', 'Brain imaging', 'Communication', 'Computer Analysis', 'Cryoelectron Microscopy', 'DNA Transposable Elements', 'Data', 'Data Analyses', 'Education', 'Faculty', 'Funding', 'Generations', 'Genome', 'Genomics', 'Gold', 'Health', 'High Performance Computing', 'Human', 'Information Technology', 'Institution', 'Laboratories', 'Malignant Neoplasms', 'Memory', 'Minor', 'Motivation', 'Mus', 'Mutagenesis', 'Mutation', 'Neural Network Simulation', 'Neurons', 'Neurosciences', 'Olfactory Pathways', 'Plants', 'Privatization', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'United States National Institutes of Health', 'artificial neural network', 'base', 'computer cluster', 'computer infrastructure', 'computing resources', 'deep learning', 'experience', 'experimental study', 'fitness', 'high end computer', 'image processing', 'innovation', 'learning strategy', 'medical specialties', 'member', 'programs', 'reconstruction', 'single-cell RNA sequencing', 'structural biology', 'transcriptome sequencing']",OD,COLD SPRING HARBOR LABORATORY,S10,2020,436882,0.012041287121057653
"Developing novel technologies that ensure privacy and security in biomedical data science research Data science holds the promise of enabling new pathways to discovery and can improve the understanding, prevention and treatment of complex disorders such as cancer, diabetes, substance abuse, etc., which are significantly on the rise. The promise of data science can be fully realized only when collected data can be collaboratively shared and analyzed. However, the widespread increases in healthcare data breaches due to inappropriate access as well as the increasing number of novel privacy attacks restrict institutions from sharing data. Indeed, in some cases, the results of the analysis can themselves lead to significant privacy harm. The success of the data commons depends on ensuring the maximal access to data, subject to all of the patient privacy requirements including those mandated by legislation, and all of the constraints of the organization collecting the data itself. While there are existing solutions that can solve parts of the problem, there are significant challenges in truly incorporating these into comprehensive working solutions that are usable by the biomedical research community, and new challenges brought on by modern techniques such as deep learning. The long-term goal of this research is to develop technologies that can holistically enable data sharing while respecting privacy and security considerations and to ensure that they are implemented in existing platforms that have widespread acceptance in the research community. Towards this, the objective of this project is to develop complementary solutions for risk inference, distributed learning, and access control that can enable different modalities of data sharing. The problems studied are general in nature and will evolve depending on research successes and new impediments that arise. The proposed program of research is significant since lack of access to biomedical data can lead to fragmentation of care, resulting in higher economic and social costs, and is a significant impediment to biomedical research. The project will result in open-source, freely available software tools that will be integrated into widely used data collection, cohort identification, and distributed analytics platforms. There are several ongoing collaborations that will serve as initial pilot customers to provide use cases, identify the requirements, evaluate results, and in general validate the developed solutions. Project Narrative Statement of Relevance to Public Health Being able to ensure privacy and security while enabling data sharing and analysis is critical to pave the way forward for public health research and improve our understanding of diseases. The proposed work will address the challenges that impede the use of data across all of the different modalities of data sharing. The integration into existing platforms will ensure that the developed models, tools, and solutions directly impact the research community and improve public health interventions.",Developing novel technologies that ensure privacy and security in biomedical data science research,9851602,R35GM134927,"['Address', 'Biomedical Research', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Commons', 'Data Science', 'Diabetes Mellitus', 'Disease', 'Economics', 'Ensure', 'Goals', 'Healthcare', 'Institution', 'Lead', 'Learning', 'Malignant Neoplasms', 'Modality', 'Modeling', 'Modernization', 'Nature', 'Pathway interactions', 'Prevention', 'Privacy', 'Public Health', 'Research', 'Risk', 'Security', 'Software Tools', 'Statutes and Laws', 'Substance abuse problem', 'Techniques', 'Technology', 'Work', 'biomedical data science', 'care fragmentation', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'new technology', 'novel', 'open source', 'patient privacy', 'programs', 'public health intervention', 'public health research', 'social', 'success', 'tool']",NIGMS,RUTGERS THE STATE UNIV OF NJ NEWARK,R35,2020,382108,0.002155175993961966
"Preparing the Next Generation of Biostatisticians in the Era of Data and Translational Sciences PROJECT SUMMARY/ABSTRACT In the era of newly emerging computational tools for data science, biostatisticians need to play a fundamental role in health sciences research. There is an urgent need to encourage US Citizens and Permanent Residents to pursue graduate training in biostatistics. The design, conduct, and analysis of clinical trials and observational studies; the setting of regulatory policy; and the conception of laboratory experiments have been shaped by the fundamental contributions of biostatisticians for decades. Advances in genomics, medical imaging technologies, and computational biology; the increasing emphasis on precision and evidence-based medicine; and the widespread adoption of electronic health records; demand the skills of biostatisticians trained to collaborate effectively in a multidisciplinary environment and to develop statistical and machine learning methods to address the challenges presented by this data-rich revolutionary era of health sciences research. The proposed summer program which includes world-renowned clinical scientists and biostatisticians from two local universities, will provide an immense opportunity for student participants to learn basic yet modern statistical methods that are critical to uncovering new insights from such big and complex biomedical data and also illustrate the potential pitfalls of confounding and bias that may arise when analyzing biomedical data. A unique feature of the proposed training program is thus to expose the participants to not only basic statistical methods but also to the topics of computer science and bioinformatics which will be invaluable in creating the multidisciplinary teams required to tackle the complex research questions that often requires multipronged approaches. The proposed six-week training program will be structured around the NIH's Translation Science Spectrum and will introduce participants to opportunities in biostatistics through the lens of the science advanced by the contributions of biostatisticians. Following an initial set of weeks on basic training of biostatistical methods, the program will culminate in a data hack-a-thon style competition in which participants will employ the statistical and scientific knowledge gained during the program to produce the most innovative, statistically-sound, scientifically-relevant and effectively-communicated response to a set of research questions. The proposed research education program will enroll up to 20 such participants from across the nation and, through lectures, field trips, and opportunities to analyze data from real health sciences, inspire them to pursue graduate training. The program will draw upon considerable past collaborations and complementary resources of two local world-renowned universities to provide participants with an unparalleled view of the field, including award-winning instructors, internationally known methodological and clinical researchers, and a local area rich in opportunities to showcase careers in biostatistics. Special efforts will be made to enroll participants from underrepresented groups. Participants will be followed after completion, and the numbers attending graduate school in statistics and pursuing biostatistics careers will be documented. PROJECT NARRATIVE Biostatisticians are indispensible contributors to health sciences research. The demand for professionals with advanced training in biostatistics is high and will continue to increase, especially with the expanding challenges posed by big biomedical data. This six week summer research education program, a joint effort of North Carolina State University and Duke University, will enroll up to 20 US citizen/permanent resident participants from across the nation in the summers of 2020-2022 and expose them to the opportunities presented by careers in biostatistics and encourage them to seek graduate training in the field.",Preparing the Next Generation of Biostatisticians in the Era of Data and Translational Sciences,9888421,R25HL147228,"['Address', 'Adoption', 'Area', 'Attention', 'Award', 'Bioinformatics', 'Biomedical Research', 'Biometry', 'Biostatistical Methods', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Conceptions', 'Data', 'Data Science', 'Development', 'Discipline', 'Electronic Health Record', 'Enrollment', 'Ensure', 'Environment', 'Evaluation', 'Evidence Based Medicine', 'Exposure to', 'Faculty', 'Future', 'Genomics', 'Goals', 'Health Sciences', 'Health system', 'Imaging technology', 'Institution', 'International', 'Joints', 'Knowledge', 'Learning', 'Medical Imaging', 'Medical center', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Names', 'National Heart, Lung, and Blood Institute', 'North Carolina', 'Observational Study', 'Participant', 'Play', 'Policies', 'Positioning Attribute', 'Principal Investigator', 'Program Effectiveness', 'Request for Applications', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'Role', 'Schools', 'Science', 'Scientist', 'Statistical Methods', 'Strategic Planning', 'Structure', 'Students', 'Talents', 'Training', 'Training Programs', 'Translational Research', 'Translations', 'Underrepresented Groups', 'United States National Institutes of Health', 'Universities', 'analytical method', 'big biomedical data', 'career', 'career development', 'clinical trial analysis', 'cohort', 'computer science', 'computerized tools', 'data resource', 'design', 'education research', 'experience', 'field trip', 'graduate student', 'health science research', 'innovation', 'insight', 'instructor', 'interest', 'investigator training', 'laboratory experiment', 'lectures', 'lens', 'machine learning method', 'multidisciplinary', 'next generation', 'programs', 'public health research', 'recruit', 'response', 'skills', 'sound', 'statistical and machine learning', 'statistics', 'summer institute', 'summer program', 'summer research', 'tool', 'undergraduate student']",NHLBI,NORTH CAROLINA STATE UNIVERSITY RALEIGH,R25,2020,249789,0.03533572961483691
"Center for Modeling Complex Interactions Biomedical problems are innately complex, and their solutions require input from many fields. Many centers focus on a single disease or organ system. By contrast, the Center for Modeling Complex Interactions focuses on an approach that can address many biomedical problems: team-based, interdisciplinary research centered around modeling. Our goal is to support and facilitate biomedical discovery by integrating modeling into interdisciplinary research. Modeling improves research at all stages—hypothesis formulation, experimental design, analysis, and interpretation. It provides a unifying language by which exchange of ideas can highlight commonalities and uncover unforeseen connections between problems. Formalization of ideas into this unifying language also improves rigor and reproducibility. We define modeling broadly to include everything from deterministic and stochastic mathematical approaches, to physical and computational models of three- dimensional objects, to agent-based and machine learning approaches where exact solutions are not possible. We seek to support modelers by increasing their numbers, and by giving them opportunities to play on interdisciplinary teams. We seek to support empiricists by giving them access to relevant modeling expertise, and by creating a community and a culture to facilitate interdisciplinary research. In Phase I, the Center for Modeling Complex Interactions created the intellectual, cultural, and physical environment to promote team- based, interdisciplinary research. In Phase II, we will build on that foundation by maintaining a strong interdisciplinary culture to foster collaboration among people who might otherwise never connect, and by adding additional faculty to expand our modeling expertise. We have four Aims: 1) Support faculty to carry out model-based, interdisciplinary biomedical research and increase their competitiveness for external funding. Research in the Center is carried out in the context of Working Groups—zero-barrier, interdisciplinary, goal- focused teams that meet regularly to get work done. Supported research includes three Research Projects, Pilot Projects, Modeling Access Grants, and ad hoc teams. Our comprehensive plan for proposal preparation improves grantsmanship, and our staff assists with submission and grant management. 2) Increase University of Idaho’s faculty participation in biomedical research. We will add six new faculty as a commitment to this Phase II COBRE and attract broader participation from across the University. 3) Extend the reach of the Modeling Core into new areas of modeling to capitalize on emerging opportunities. The Modeling Core accelerates interdisciplinary research by placing Core Fellows at the hub of the research community. We have added new Core Initiatives in machine learning and geospatial modeling to stimulate research in these areas with high potential for future growth. 4) Establish a path to long-term sustainability under the umbrella of the Institute for Modeling Collaboration & Innovation. The major hurdle for sustainability is to maintain a robust Modeling Core. We have developed a business plan that calls for us to diversify our funding sources to include institutional, state, and private support to supplement federal grants. Human health is determined by interactions of complex biological systems at multiple scales, from the ecological to the biophysical; these are layered with spatial and temporal variation. To decipher these systems requires predictive modeling, coupled with strong empirical work, to be guided by and to feed the models. The Center for Modeling Complex Interactions generates model-based biomedical research and connects people who might otherwise never interact, which enhances the strong interdisciplinary culture of the University of Idaho.",Center for Modeling Complex Interactions,10026000,P20GM104420,"['Address', 'Area', 'Biological', 'Biomedical Research', 'Biophysics', 'Businesses', 'Centers of Research Excellence', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer Models', 'Coupled', 'Data', 'Development', 'Disease', 'Ensure', 'Experimental Designs', 'Faculty', 'Feedback', 'Formulation', 'Fostering', 'Foundations', 'Funding', 'Funding Agency', 'Future', 'Generations', 'Goals', 'Grant', 'Growth', 'Health', 'Holly', 'Home environment', 'Human', 'Human Resources', 'Idaho', 'Incubators', 'Individual', 'Infrastructure', 'Institutes', 'Interdisciplinary Study', 'Language', 'Lead', 'Machine Learning', 'Modeling', 'Outcome', 'Phase', 'Physical environment', 'Pilot Projects', 'Play', 'Population', 'Postdoctoral Fellow', 'Preparation', 'Privatization', 'Progress Reports', 'Property', 'Reproducibility', 'Research', 'Research Institute', 'Research Project Grants', 'Research Support', 'Schedule', 'Scientist', 'Structure', 'Students', 'System', 'Testing', 'Time', 'Training', 'Uncertainty', 'Universities', 'Ursidae Family', 'Work', 'base', 'biological systems', 'body system', 'complex biological systems', 'experience', 'faculty support', 'improved', 'innovation', 'insight', 'interdisciplinary approach', 'mathematical methods', 'member', 'next generation', 'novel strategies', 'physical model', 'predictive modeling', 'spatial temporal variation', 'success', 'three-dimensional modeling', 'undergraduate student', 'working group']",NIGMS,UNIVERSITY OF IDAHO,P20,2020,2172986,0.005287643846102856
"Society of Behavioral Medicine 2020 Annual Meeting & Scientific Sessions PROJECT ABSTRACT The Society of Behavioral Medicine (SBM) will hold its 41st Annual Meeting & Scientific Sessions April 1-4, 2020, in San Francisco, CA. This application seeks funding in support of meeting programming addressing the following specific aims: (1) to train attendees in the skills necessary to effectively integrate emerging technologies into the behavioral medicine landscape, including (but not limited to) wearable sensors, telemedicine, and artificial intelligence; (2) to showcase effective models of cross-disciplinary collaboration that facilitate acceleration of the discovery-to-dissemination pipeline for behavioral medicine interventions; (3) to enhance the diversity of behavioral medicine professionals by providing mentoring, leadership training, professional development, and employment networking opportunities to trainees, junior and midcareer faculty, clinicians, industry professionals, and others who attend the meeting; and (4) to enhance the methodological rigor of behavioral science research by having expert-led discussions on clinical trial methodology, reproducibility, open science, and interdisciplinary collaboration to produce new theoretical models and methods. SBM is the nation’s leading scientific society dedicated to behavioral medicine, representing approximately 2,400 researchers and clinicians from more than 20 disciplines. SBM’s members include researchers, clinicians, educators, and industry professionals who focus on the development and integration of behavioral, psychosocial, and biomedical theory, knowledge, and interventions relevant to the understanding of health and disease. They work to understand, prevent, and treat chronic diseases such as cardiovascular diseases, respiratory diseases, diabetes, and cancer. They conduct research and translate findings into real- world settings to improve lives while also reducing healthcare costs. SBM’s annual meetings are the premier forum for disseminating behavioral medicine’s important ideas and breakthroughs. The meeting’s educational sessions, networking events, and exhibit halls facilitate exchange of information and ideas. Attendees apply the knowledge gained to disease prevention and management, and development of innovative research designs, effective interventions and strategies, and evidence-based policies. SBM meetings feature high- impact plenary speakers who present topics such as “Health and Technology Megatrends” (Susannah Fox, 2019). The 2020 SBM Annual Meeting will be attended by an estimated 2,100 individuals from the United States and abroad, featuring more than 1,500 presentations. The meeting theme is “Accelerating Our Science: Finding Innovative Solutions to Tomorrow’s Health Challenges.” Sessions will energize attendees to accelerate behavioral medicine by using new methodological approaches, advanced behavioral theories, and novel technologies as well as by overcoming key barriers, such as health inequities, policy challenges, health misinformation, and cross-disciplinary communication difficulties. Most of our country's health challenges have behavioral origins. Behavioral medicine and the evidence it generates are more important than ever. PROJECT NARRATIVE (PUBLIC HEALTH RELEVANCE) The Society of Behavioral Medicine’s 41st Annual Meeting & Scientific Sessions, to be held April 1-4, 2020, will bring together 2,100 of the nation’s leading behavioral scientists, clinicians, educators, and policymakers to exchange new research on improving health through behavior change, in particular via accelerating behavioral medicine through new methodological approaches, behavioral theories, and advanced technology such as artificial intelligence as well as by overcoming key barriers to progress in behavioral medicine such as health inequities, policy challenges, health misinformation, and cross-disciplinary communication difficulties. Through a broad range of scientific presentations, discussions, and skill-building workshops, the meeting will facilitate the exchange of the latest population‐level, clinic‐based, and experimental research on the prevention and treatment of the leading causes of morbidity and mortality, with the goals of improving health behaviors, reducing the burden of chronic disease, lowering healthcare costs, and bettering our nation’s health.",Society of Behavioral Medicine 2020 Annual Meeting & Scientific Sessions,9992468,R13HL152518,"['Acceleration', 'Address', 'Adoption', 'Aging', 'Area', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Behavioral Medicine', 'Behavioral Sciences', 'Biometry', 'Cardiovascular Diseases', 'Cause of Death', 'Cessation of life', 'Chronic Disease', 'Chronic lung disease', 'Clinic', 'Clinical', 'Clinical Trials', 'Collaborations', 'Communication', 'Communities', 'Country', 'Development', 'Diabetes Mellitus', 'Discipline', 'Discipline of Nursing', 'Disease', 'Disease Management', 'Educational workshop', 'Emerging Technologies', 'Employment', 'Ensure', 'Etiology', 'Event', 'Exercise', 'Exhibits', 'Foxes', 'Funding', 'Goals', 'Government Agencies', 'Health', 'Health Care Costs', 'Health Technology', 'Health behavior', 'Health behavior outcomes', 'Healthy People 2020', 'Heart Diseases', 'Human Development', 'Individual', 'Industry', 'Interdisciplinary Communication', 'Intervention', 'Justice', 'Knowledge', 'Leadership', 'Link', 'Longevity', 'Lung diseases', 'Malignant Neoplasms', 'Medical', 'Medicine', 'Mentors', 'Methodology', 'Methods', 'Misinformation', 'Mission', 'Modeling', 'Morbidity - disease rate', 'National Cancer Institute', 'National Heart, Lung, and Blood Institute', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Patients', 'Play', 'Policies', 'Population', 'Prevention', 'Psychology', 'Public Health', 'Reproducibility', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Risk Factors', 'Role', 'San Francisco', 'Science', 'Scientific Societies', 'Scientist', 'Societies', 'Technology', 'Telemedicine', 'Theoretical model', 'Time', 'Tobacco use', 'Training', 'Translating', 'Unhealthy Diet', 'United States', 'Vision', 'Washington', 'Work', 'base', 'behavior change', 'clinical care', 'disorder prevention', 'effective intervention', 'evidence base', 'experimental study', 'improved', 'innovation', 'interdisciplinary collaboration', 'meetings', 'member', 'mid-career faculty', 'mortality', 'new technology', 'novel strategies', 'nutrition', 'open data', 'physical inactivity', 'prevent', 'psychosocial', 'public health intervention', 'public health relevance', 'sedentary lifestyle', 'skills', 'theories', 'wearable sensor technology']",NHLBI,SOCIETY OF BEHAVIORAL MEDICINE,R13,2020,30000,-0.0024656042082557787
"Summer Institute in Neuroimaging and Data Science Project Summary/Abstract The study of the human brain with neuroimaging technologies is at the cusp of an exciting era of Big Data. Many data collection projects, such as the NIH-funded Human Connectome Project, have made large, high- quality datasets of human neuroimaging data freely available to researchers. These large data sets promise to provide important new insights about human brain structure and function, and to provide us the clues needed to address a variety of neurological and psychiatric disorders. However, neuroscience researchers still face substantial challenges in capitalizing on these data, because these Big Data require a different set of technical and theoretical tools than those that are required for analyzing traditional experimental data. These skills and ideas, collectively referred to as Data Science, include knowledge in computer science and software engineering, databases, machine learning and statistics, and data visualization.  The Summer Institute in Data Science for Neuroimaging will combine instruction by experts in data science methodology and by leading neuroimaging researchers that are applying data science to answer scientiﬁc ques- tions about the human brain. In addition to lectures on the theoretical background of data science methodology and its application to neuroimaging, the course will emphasize experiential hands-on training in problem-solving tutorials, as well as project-based learning, in which the students will create small projects based on openly available datasets. Summer Institute in Neuroimaging and Data Science: Project Narrative The Summer Institute in Neuroimaging and Data Science will provide training in modern data science tools and methods, such as programming, data management, machine learning and data visualization. Through lectures, hands-on training sessions and team projects, it will empower scientists from a variety of backgrounds in the use of these tools in research on the human brain and on neurological and psychiatric brain disorders.",Summer Institute in Neuroimaging and Data Science,9875480,R25MH112480,"['Address', 'Adopted', 'Big Data', 'Brain', 'Brain Diseases', 'Collaborations', 'Collection', 'Communities', 'Competence', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Data Science Core', 'Data Set', 'Databases', 'Discipline', 'Face', 'Faculty', 'Fostering', 'Funding', 'Habits', 'Home environment', 'Human', 'Image', 'Institutes', 'Institution', 'Instruction', 'Internet', 'Knowledge', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mental disorders', 'Methodology', 'Methods', 'Modernization', 'Neurologic', 'Neurosciences', 'Participant', 'Positioning Attribute', 'Problem Solving', 'Psychology', 'Reproducibility', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Software Engineering', 'Software Tools', 'Structure', 'Students', 'Technology', 'Testing', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'biomedical data science', 'career', 'classification algorithm', 'computer science', 'connectome', 'data management', 'data visualization', 'design', 'e-science', 'experimental study', 'high dimensionality', 'insight', 'instructor', 'interdisciplinary collaboration', 'knowledge base', 'large datasets', 'lectures', 'nervous system disorder', 'neurogenetics', 'neuroimaging', 'novel', 'open source', 'prediction algorithm', 'programs', 'project-based learning', 'skills', 'statistics', 'success', 'summer institute', 'theories', 'tool']",NIMH,UNIVERSITY OF WASHINGTON,R25,2020,164298,-0.006953217115588497
"HERCULES: Exposome Research Center PROJECT SUMMARY: HERCULES The vision of the HERCULES P30 is to demonstrably advance the role of environmental health sciences in clinical and public health settings using the platform of the exposome. Healthcare and biomedical research have become increasingly genome-centric. While much of this is due to the impressive achievements in genomics, which have consistently outpaced gains in environmental health, it is our contention that a more persuasive case needs to be made for environmental factors. Science and intuition support the idea that the environment plays just as large of a role as genetics for the majority of diseases. The exposome, which embraces a strategy and scale similar to genomic research, is poised to elevate the environment in discussions of health and disease. We will continue to grow and enhance the environmental health science research portfolio at Emory through cutting-edge technologies and innovative data solutions. We will build upon the superb relationships we have built with the local community and continue to push the mission of NIEHS on campus and across the scientific landscape. Based on the extraordinary progress over our first three years, we propose to retain our theme to use exposome-related concepts and approaches to improve human health. This simple and unifying vision will continue to stimulate discovery, promote collaboration, and enhance communication through the following Specific Aims: Specific Aim 1. To marshal physical and intellectual resources to support exposome-related approaches (high-resolution metabolomics, analytical chemistry, systems biology, machine learning, bioinformatics, high-throughput toxicology, and spatial and temporal statistical models) through cores, pilot funding, mentoring, and research forums. Specific Aim 2. To make major contributions towards exposome and environmental health science research. Specific Aim 3. To provide career development activities around innovative and emerging concepts and approaches related to the exposome. Specific Aim 4. To enhance and expand existing relationships with community partners to resolve environmental health issues in the community using exposome principles. Specific Aim 5. To provide infrastructure and resources to facilitate rapid translation of novel scientific findings into the development of prevention and treatment strategies in humans. Pursuit of HERCULES' aims will advance environmental health sciences within our institutions and in the scientific community. PROJECT NARRATIVE: HERCULES Human health and disease is dictated by a combination of genetic and environmental factors. The HERCULES Center is focused on providing a more comprehensive assessment of these environmental influences by utilizing exposome-based concepts and approaches.",HERCULES: Exposome Research Center,9902428,P30ES019776,"['Achievement', 'Analytical Chemistry', 'Award', 'Bioinformatics', 'Biomedical Research', 'Climate', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Community Outreach', 'Core Facility', 'Data', 'Data Science Core', 'Development', 'Discipline', 'Disease', 'Environment', 'Environmental Health', 'Environmental Risk Factor', 'Evaluation', 'Fostering', 'Funding', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Grant', 'Health', 'Health Care Research', 'Health Sciences', 'Human', 'Individual', 'Infrastructure', 'Institution', 'Intuition', 'Leadership', 'Letters', 'Machine Learning', 'Marshal', 'Mentors', 'Mission', 'National Institute of Environmental Health Sciences', 'Phase', 'Play', 'Prevention strategy', 'Productivity', 'Public Health', 'Research', 'Research Activity', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Resources', 'Role', 'Science', 'Scientist', 'Statistical Models', 'Strategic Planning', 'Systems Biology', 'Technology', 'Toxicology', 'Translations', 'Update', 'Vision', 'base', 'career development', 'catalyst', 'health science research', 'improved', 'innovation', 'metabolomics', 'novel', 'operation', 'ranpirnase', 'treatment strategy']",NIEHS,EMORY UNIVERSITY,P30,2020,1492946,0.01771188660310311
"N3C & All of Us Research Program Collaborative Project Project Summary/Abstract The COVID-19 pandemic presents unprecedented clinical and public health challenges. Though institutions collect large amounts of clinical data about COVID-19 cases, these datasets individually might not be diverse enough to draw population level conclusions. Also, statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. To tackle this problem, NCATS introduced the National COVID Cohort Collaborative (N3C), an open science, community-based initiative to share patient level data for analysis. The initiative requires participating institutions to share information about their COVID-19 patients in a standard-driven way, including demographics, vital signs, diagnoses, laboratory results, medications, and other treatments. The data from multiple institutions will be merged and consolidated, and access will be provided to investigators through a centralized analytical platform. The COVID-19 data sharing collaboration with the N3C initiative offers a mechanism to initiate collaborations with other NIH sponsored data sharing programs, such as the All of Us Research Program (AoURP). This administrative supplement will support efforts to clean and standardize data at VCU, and to transfer it to the N3C data repository. The supplement will also assist in introducing new services at the Wright Center to support our investigators to use the N3C resources. It will also enable collaboration with the AoURP by establishing a pipeline to collect and transmit consented patients' EHR data and by building on existing community outreach pathways to recruit additional participants for the AoURP. The project will be overseen by the PI/Executive Committee and supervised by the Director of Research Informatics. Procedures and services developed at our local CTSA hub will be shared and disseminated to the CTSA network. Project Narrative NIH/NCATS has been working on the National COVID Cohort Collaborative (N3C), which aims to build a centralized national data resource to be used by the research community to study the COVID-19 pandemic and identify potential treatments as the pandemic continues to evolve. The COVID-19 data sharing collaboration with the N3C initiative also offers a mechanism to initiate collaborations with the All of Us Research Program (AoURP). This administrative supplement will support the creation and management of a data extraction and transfer pipeline to the N3C and AoURP data repositories from VCU.",N3C & All of Us Research Program Collaborative Project,10217339,UL1TR002649,"['Administrative Supplement', 'All of Us Research Program', 'COVID-19', 'COVID-19 pandemic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Communities', 'Community Outreach', 'Consent', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Ecosystem', 'Effectiveness', 'Funding Opportunities', 'Goals', 'Health', 'Health Status', 'Individual', 'Informatics', 'Infrastructure', 'Institution', 'Laboratories', 'Outcomes Research', 'Participant', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Population', 'Positioning Attribute', 'Procedures', 'Public Health', 'Research', 'Research Personnel', 'Resource Informatics', 'Resources', 'Services', 'Supervision', 'Testing', 'Translational Research', 'United States National Institutes of Health', 'base', 'biomedical informatics', 'clinical center', 'cohort', 'coronavirus disease', 'data resource', 'data sharing', 'data standards', 'data warehouse', 'demographics', 'design', 'improved', 'informatics infrastructure', 'innovation', 'large scale data', 'multi-site trial', 'network informatics', 'open data', 'pandemic disease', 'parent grant', 'programs', 'recruit', 'response', 'statistical and machine learning', 'tool']",NCATS,VIRGINIA COMMONWEALTH UNIVERSITY,UL1,2020,346608,0.01280336003378939
"Intelligent deployment of containerized bioinformatics workflows on the cloud PROJECT SUMMARY Cloud computing has emerged as a promising solution to address the challenges of big data. Public cloud vendors provide computing as-a-utility enabling users to pay only for the resources that are actually used. In this application, we will develop methods and tools to enable biomedical researchers to optimize the costs of cloud computing when analyzing biomedical big data. Infrastructure-as-a-Service (IaaS) cloud provides computing as a utility, on-demand, to end users, enabling cloud resources to be rapidly provisioned and scaled to meet computational and performance requirements. In addition, dynamic intelligent allocation of cloud computing resources has great potential to both improve performance and reduce hosting costs. Unfortunately, determining the most cost-effective and efficient ways to deploy modules on the cloud is non- trivial, due to a plethora of cloud vendors, each providing different types of virtual machines with different capabilities, performance trade-offs, and pricing structures. In addition, modern bioinformatics workflows consist of multiple modules, applications and libraries, each with their own set of software dependencies. Software containers package binary executables and scripts into modules with their software dependencies. With containers that compartmentalize software dependencies, modules implemented as containers can be mixed and matched to create workflows that give identical results on any platform. The high degree of reproducibility and flexibility of software containers makes them ideal instruments for disseminating complex bioinformatics workflows. Our overarching goal is to deliver the latest technological advances in containers and cloud computing to a typical biomedical researcher with limited resources who works with big data. Specifically, we will develop a user-friendly drag-and-drop interface to enable biomedical researchers to build and edit containerized workflows. Most importantly, users can choose to deploy and scale selected modules in the workflow on cloud computing platforms in a transparent, yet guided fashion, to optimize cost and performance. Our aim is to provide a federated approach that leverages resources from multiple cloud vendors. We have assembled a team of interdisciplinary scientists with expertise in bioinformatics, cloud and distributed computing, and machine learning. As part of this application, we will work closely with end users who routinely generate and analyze RNA-seq data. We will illustrate how our containerized, cloud-enabled methods and tools will benefit bioinformatics analyses. Project Narrative Cloud computing has emerged as a promising solution to address the challenge of analyzing diverse and massive data generated to advance our understanding of health and diseases. We will develop methods and tools to build and intelligently deploy modular and cloud-enabled bioinformatics workflows. These tools will allow the biomedical community to optimize the costs associated with cloud computing and to facilitate the replication of scientific results.",Intelligent deployment of containerized bioinformatics workflows on the cloud,9856493,R01GM126019,"['Address', 'Big Data', 'Bioinformatics', 'Case Study', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complex', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Storage and Retrieval', 'Dependence', 'Development', 'Disease', 'Docking', 'Documentation', 'Drops', 'Drug toxicity', 'Educational Materials', 'Ensure', 'Feedback', 'Generations', 'Goals', 'Health', 'Hospitals', 'Image', 'Infrastructure', 'Intelligence', 'Libraries', 'Machine Learning', 'Manuals', 'Methods', 'Modeling', 'Modernization', 'Performance', 'Price', 'Privatization', 'RNA analysis', 'Reproducibility', 'Research Personnel', 'Resources', 'Schedule', 'Scientist', 'Services', 'Software Tools', 'Structure', 'Technical Expertise', 'Technology Transfer', 'Testing', 'Time', 'Vendor', 'Work', 'base', 'big biomedical data', 'biomedical scientist', 'cloud platform', 'cluster computing', 'computational platform', 'computing resources', 'cost', 'cost effective', 'data exchange', 'distributed data', 'expectation', 'flexibility', 'graphical user interface', 'improved', 'instrument', 'outreach', 'predictive modeling', 'prototype', 'tool', 'tool development', 'transcriptome sequencing', 'user-friendly', 'virtual machine', 'web site']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,339098,0.005783599197093029
"Meta-analysis in human brain mapping This is the competing renewal of R01MH074457-13, which sustains the BrainMap Project (www.brainmap.org). The overall goal of the BrainMap Project is to provide the human neuroimaging community with curated data sets, metadata, computational tools, and related resources that enable coordinate-based meta-analyses (CBMA), meta-analytic connectivity modeling (MACM), meta-data informed interpretation (“decoding”) of imaging results, and meta-analytic priors for mining (including machine learning) primary (per-subject) neuroimaging data. To date, the BrainMap Project has designed and populated two coordinate-based databases: 1) a task-activation repository (TA DB); and, 2) a voxel-based morphometry repository (VBM DB). The TA DB contains >17,200 experiments, collectively representing > 78,000 subjects and > 110 task- activation paradigms. The VBM DB contains > 3,100 experiments, collectively representing > 81,000 subjects with > 80 psychiatric, neurologic and developmental disorders with ICD-10 coding. The BrainMap Project has created, optimized and validated an integrated pipeline of multi-platform (Javascript), open-access tools to curate (Scribe), filter and retrieve (Sleuth), analyze (GingerALE), visualize (Mango) and interpret analysis output (BrainMap meta-data plugins for Mango). Several network-modeling approaches have been applied to BrainMap data -- MACM, independent components analysis (ICA), graph theory modeling (GTM), author-topic modeling (ATM), structural equation modeling (SEM), and connectivity-based parcellation (CBP) – but none are yet pipeline components. Utilization of these CBMA resources is substantial: BrainMap software, data and meta-data have been used in > 825 peer-reviewed publications. Of these, > 350 were published within the current funding period (April 2015-March 2019; brainmap.org/pubs). In this competing renewal, four tool- development aims are proposed, each of which extends this high-impact research resource. Aim 1. Database Expansion. BrainMap data repositories will be expanded. Aim 2. Meta-analytic Network Modeling. Network modeling will be added to the BrainMap pipeline. Aim 3. Large-Scale Simulations, Comparisons and Validations. Data simulations, characterizations and validations will be performed. Aim 4. Meta-data Inferential tools. Tools for mining BrainMap’s location-linked meta-data will be expanded. Data Sharing Plan. BrainMap data, meta-data, pipeline tools, and templates created by whole-database modeling (e.g., ICA and ATM network masks) are shared at BrainMap.org. Of all new data entries, more than half are contributed by BrainMap users, i.e., community data sharing via BrainMap.org. For community-coded entries, the BrainMap team provides curation and quality control. Comprehensive database images (database dumps) are available to tool developers through Collaborative Use Agreements. The overall goal of the BrainMap Project is to provide the human neuroimaging community with curated data  sets, metadata, computational tools, and related resources that enable coordinate-­based meta-­analyses  (CBMA), meta-­analytic connectivity modeling (MACM), meta-­data informed interpretation (“decoding”) of  imaging results, and meta-­analytic priors for mining (including machine learning) primary (per-­subject)  neuroimaging data.    ",Meta-analysis in human brain mapping,10056029,R56MH074457,"['Agreement', 'Area', 'Brain', 'Brain Mapping', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Data', 'Data Set', 'Databases', 'Disease', 'Educational workshop', 'Equation', 'Functional disorder', 'Funding', 'Goals', 'Guidelines', 'Human', 'Image', 'Institution', 'International Statistical Classification of Diseases and Related Health Problems, Tenth Revision (ICD-10)', 'Internet', 'Java', 'Link', 'Location', 'Machine Learning', 'Mango - dietary', 'Masks', 'Mental disorders', 'Meta-Analysis', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Online Systems', 'Output', 'Peer Review', 'Plug-in', 'Publications', 'Publishing', 'Quality Control', 'Research Domain Criteria', 'Resources', 'Rest', 'Site', 'Software Framework', 'Specificity', 'Structure', 'Training', 'Universities', 'Validation', 'base', 'candidate marker', 'computerized tools', 'data pipeline', 'data sharing', 'data warehouse', 'design', 'developmental disease', 'experimental study', 'graph theory', 'independent component analysis', 'interest', 'large scale simulation', 'morphometry', 'nervous system disorder', 'network architecture', 'network models', 'neuroimaging', 'neuropsychiatric disorder', 'repository', 'simulation', 'tool', 'tool development']",NIMH,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,R56,2020,543396,-0.008384580805076711
"IEEE International Symposium on Biomedical Imaging (ISBI) 2020 Project Summary This R13 application will provide travel support for competitively selected U.S.-based students, postdoctoral fellows, and junior faculty to present their work at the IEEE International Symposium on Biomedical Imaging (ISBI) 2020 to be held April 4-8, 2020 at the Coralville Marriott Hotel & Conference Center near the University of Iowa, Iowa City, Iowa. ISBI is a scientific conference dedicated to mathematical, algorithmic, and computational aspects of biological and biomedical imaging, across all scales of observation (from microscopic to whole-body imaging) and is sponsored by both the IEEE Signal Processing Society (SPS) and the IEEE Engineering in Medicine and Biology Society (EMBS). It attracts approximately 600-700 attendees each year involved in biomedical imaging research and development from academic institutions, government laboratories, and private companies. Since its inception in 2002, ISBI has become a leading international conference bringing together researchers from diverse algorithmic fields, applications, modalities, and size scales, to facilitate cross-fertilization of ideas. ISBI, like other IEEE SPS and EMBS conferences, requires submission and review of four-page papers which are peer-reviewed much like journal articles. In addition to oral and poster presentations of peer-reviewed papers in multiple tracks during the main conference, ISBI 2020 will also include special student events, tutorials, a “clinical day” emphasizing multi-disciplinary presentations/collaborations, plenary talks, workshops, and onsite grand challenges. Recipients of the travel awards will be competitively selected based on need and scientific excellence. U.S.- based students, postdoctoral fellows, and junior faculty with accepted papers will be eligible to apply. We will be particularly supportive in providing travel awards to women and under-represented groups to help increase the diversity of the attendees. We anticipate that the travel awards will provide sufficient funding to the awardees to make the cost-benefit ratio for attendance extremely favorable. Through their attendance at ISBI, the awardees will benefit through their exposure to the simultaneous breadth and depth of topics offered at ISBI (presented by a mixture of leaders in the field as well as those early in their careers), their experience of presenting their work at an international conference, and their interactions and discussions with other attendees and leaders in the field. The conference as a whole will also benefit by not only enabling the high-quality work of the attendees to be presented but by also enabling an increased attendance of (and discussions/ideas/interactions with) U.S.-based students, postdoctoral fellows, and early career faculty with diverse backgrounds. Project Narrative This application requests funds to provide travel support for students, postdoctoral fellows, and/or early- career faculty to attend and participate in the IEEE International Symposium on Biomedical Imaging (ISBI) 2020 conference, to be held at the Coralville Marriott Hotel & Conference Center near the University of Iowa, Iowa City, Iowa, April 4-8, 2020. The conference covers many of the mathematical and computational aspects of biological and biomedical imaging problems of high relevance to human health, and hence is of high relevance to the interests of the National Institutes of Health.",IEEE International Symposium on Biomedical Imaging (ISBI) 2020,9914410,R13EB029304,"['Address', 'Algorithms', 'Appointment', 'Area', 'Artificial Intelligence', 'Award', 'Biological', 'Biological Models', 'Biology', 'Biomedical Computing', 'Breeding', 'Budgets', 'Cities', 'Clinical', 'Collaborations', 'Complement', 'Computational algorithm', 'Computer Models', 'Costs and Benefits', 'Data', 'Educational workshop', 'Engineering', 'Event', 'Exposure to', 'Faculty', 'Fertilization', 'Funding', 'Future', 'Generations', 'Goals', 'Government', 'Grant', 'Growth', 'Health', 'Human', 'Image', 'Image Analysis', 'Imaging problem', 'Institution', 'International', 'Iowa', 'Laboratories', 'Location', 'Machine Learning', 'Mathematics', 'Medical', 'Medicine', 'Methodology', 'Microscopic', 'Modality', 'Modeling', 'Oral', 'Paper', 'Participant', 'Peer Review', 'Postdoctoral Fellow', 'Privatization', 'Recommendation', 'Request for Applications', 'Research', 'Research Personnel', 'Societies', 'Statistical Models', 'Students', 'Training', 'Travel', 'Underrepresented Groups', 'United States National Institutes of Health', 'Universities', 'Visualization', 'Women&apos', 's Group', 'Work', 'authority', 'base', 'bioimaging', 'body system', 'career', 'computerized tools', 'cost', 'early-career faculty', 'experience', 'graduate student', 'imaging modality', 'innovation', 'interest', 'journal article', 'mathematical algorithm', 'meetings', 'member', 'multidisciplinary', 'physical model', 'posters', 'programs', 'reconstruction', 'research and development', 'signal processing', 'student participation', 'success', 'supportive environment', 'symposium', 'whole body imaging']",NIBIB,UNIVERSITY OF IOWA,R13,2020,5000,0.004750880303720584
"EDAC: ENCODE Data Analysis Center PROJECT SUMMARY The goal of the Encyclopedia of DNA Elements (ENCODE) project is to catalog all functional elements in the human genome through the integration and analysis of high-throughput data. We propose to continue the ENCODE Data Analysis Center (EDAC, DAC) which will provide support and leadership in analyzing and integrating data from the ENCODE project as well as work closely with other ENCODE groups including the Data Coordination Center. Our proposed DAC team (Zhiping Weng, Mark Gerstein, Manolis Kellis, Roderic Guigo, Rafael Irizarry, X. Shirley Liu, Anshul Kundaje, and William Noble) has expertise across a wide range of fields including transcriptional regulation, epigenetics, evolution, genomics and proteomics, regulatory RNA, biophysics, and computational biology, where they are the leaders in machine learning, statistical genetics, networks, and gene annotation. These investigators also have a history of successfully working collaboratively in large consortia, particularly with other ENCODE groups. Their publication records demonstrate their synergistic approach to producing high-impact science and useful resources that benefit the broader biomedical communities. The proposed DAC will pursue the following four aims: Aim 1. Analyze and integrate data and metadata from a broad range of functional genomics projects; Aim 2. Serve as an informatics resource by supporting the activities of the ENCODE Analysis Working Group; Aim 3. Create high-quality Encyclopedias of DNA elements in the human and mouse genomes; Aim 4. Assess quality and utility of the ENCODE data and provide feedback to NHGRI and the Consortium. RELEVANCE The goal of the Encyclopedia of DNA Elements (ENCODE) project is a highly collaborative effort aiming to develop a comprehensive list of functional elements in the human genome. This proposal creates a data analysis center to provide support and computational prowess for this effort in collaboration with other ENCODE groups. This comprehensive list will be of use to the wider research community and will aid in understanding human biology particularly in the context of disease, ultimately leading to improvements in human health.",EDAC: ENCODE Data Analysis Center,9858390,U24HG009446,"['ATAC-seq', 'Alleles', 'Binding', 'Biochemical', 'Biological', 'Biological Assay', 'Biophysics', 'Catalogs', 'ChIP-seq', 'Chromatin', 'Collaborations', 'Communities', 'Computational Biology', 'Computing Methodologies', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Data Element', 'Data Set', 'Deoxyribonucleases', 'Development', 'Disease', 'Elements', 'Encyclopedia of DNA Elements', 'Encyclopedias', 'Enhancers', 'Epigenetic Process', 'Event', 'Evolution', 'Feedback', 'Genes', 'Genetic', 'Genetic Transcription', 'Genome', 'Genomic Segment', 'Genomics', 'Genotype-Tissue Expression Project', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Biology', 'Human Genome', 'Intuition', 'Leadership', 'Location', 'Machine Learning', 'Manuscripts', 'Measures', 'Metadata', 'Methods', 'Mus', 'National Human Genome Research Institute', 'Nucleotides', 'Pathway Analysis', 'Process', 'Proteomics', 'Publications', 'RNA', 'RNA-Binding Proteins', 'Recording of previous events', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resource Informatics', 'Resources', 'Science', 'Signal Transduction', 'Subgroup', 'Techniques', 'The Cancer Genome Atlas', 'Transcriptional Regulation', 'Variant', 'Work', 'Writing', 'analysis pipeline', 'base', 'bisulfite sequencing', 'cell type', 'comparative', 'computerized data processing', 'data exchange', 'data infrastructure', 'data integration', 'data standards', 'experience', 'experimental study', 'functional genomics', 'genetic variant', 'genome wide association study', 'high throughput analysis', 'histone modification', 'insight', 'large scale data', 'member', 'mouse genome', 'multiple data types', 'novel', 'symposium', 'transcription factor', 'transcriptome sequencing', 'whole genome', 'working group']",NHGRI,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U24,2020,2000000,-0.0029911983325882543
"DOCKET: accelerating knowledge extraction from biomedical data sets Component type: This Knowledge Provider project will continue and significantly extend work done by the Translator Consortium Blue Team, focusing on deriving knowledge from real-world data through complex analytic workflows, integrated to the Translator Knowledge Graph, and served via tools like Big GIM and the Translator Standard API. The problem: We aim to solve the “first mile” problem of translational research: how to integrate the multitude of dynamic small-to-large data sets that have been produced by the research and clinical communities, but that are in different locations, processed in different ways, and in a variety of formats that may not be mutually interoperable. Integrating these data sets requires significant manual work downloading, reformatting, parsing, indexing and analyzing each data set in turn. The technical and ethical challenges of accessing diverse collections of big data, efficiently selecting information relevant to different users’ interests, and extracting the underlying knowledge are problems that remain unsolved. Here, we propose to leverage lessons distilled from our previous and ongoing big data analysis projects to develop a highly automated tool for removing these bottlenecks, enabling researchers to analyze and integrate many valuable data sets with ease and efficiency, and making the data FAIR [1]. Plan: (AIM 1) We will analyze and extract knowledge from rich real-world biomedical data sets (listed in the Resources page) in the domains of wellness, cancer, and large-scale clinical records. (AIM 2) We will formalize methods from Aim 1 to develop DOCKET, a novel tool for onboarding and integrating data from multiple domains. (AIM 3) We will work with other teams to adapt DOCKET to additional knowledge domains. ■ The DOCKET tool will offer 3 modules: (1) DOCKET Overview: Analysis of, and knowledge extraction from, an individual data set. (2) DOCKET Compare: Comparing versions of the same data set to compute confidence values, and comparing different data sets to find commonalities. (3) DOCKET Integrate: Deriving knowledge through integrating different data sets. ■ Researchers will be able to parameterize these functions, resolve inconsistencies, and derive knowledge through the command line, Jupyter notebooks, or other interfaces as specified by Translator Standards. ■ The outcome will be a collection of nodes and edges, richly annotated with context, provenance and confidence levels, ready for incorporation into the Translator Knowledge Graph (TKG). ■ All analyses and derived knowledge will be stored in standardized formats, enabling querying through the Reasoner Std API and ingestion into downstream AI assisted machine learning. ■ Example questions this will allow us to address include: (Wellness) Which clinical analytes, metabolites, proteins, microbiome taxa, etc. are significantly correlated, and which changing analytes predict transition to which disease? [2,3] (Cancer) Which gene mutations in any of X pathways are associated with sensitivity or resistance to any of Y drugs, in cell lines from Z tumor types? (All data sets) Which data set entities are similar to this one? Are there significant clusters? What distinguishes between the clusters? What significant correlations of attributes can be observed? How can this set of entities be expanded by adding similar ones? How do these N versions of this data set differ, and how stable is each knowledge edge as the data set changes over time? Collaboration strengths: Our team has extensive experience with biomedical and domainagnostic data analytics, integrating multiple relevant data types: omics, clinical measurements and electronic health records (EHRs). We have participated in large collaborative consortia and have subject matter experts willing to advise on proper data interpretation. Our application synergizes with those of other Translator teams (see Letters of Collaboration). Challenges: Data can come in a bewildering diversity of formats. Our solution will be modular, will address the most common formats first, and will leverage established technologies like DataFrames and importers (like pandas.io) where possible. Mapping nodes and edge types onto standard ontologies is crucial for knowledge integration; we will collaborate with the Standards component to maximize success. n/a",DOCKET: accelerating knowledge extraction from biomedical data sets,10057127,OT2TR003443,"['Address', 'Big Data', 'Cell Line', 'Clinical', 'Collaborations', 'Collection', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Disease', 'Electronic Health Record', 'Ethics', 'FAIR principles', 'Gene Mutation', 'Individual', 'Ingestion', 'Knowledge', 'Knowledge Extraction', 'Letters', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Methods', 'Ontology', 'Outcome', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Proteins', 'Provider', 'Records', 'Research', 'Research Personnel', 'Resistance', 'Resources', 'Specific qualifier value', 'Standardization', 'Technology', 'Time', 'Translational Research', 'Work', 'experience', 'indexing', 'interest', 'interoperability', 'knowledge graph', 'knowledge integration', 'large datasets', 'microbiome', 'novel', 'success', 'tool', 'tumor']",NCATS,INSTITUTE FOR SYSTEMS BIOLOGY,OT2,2020,609068,-0.03178254900364803
"New Jersey Alliance for Clinical Translational Science: NJ ACTS Contact PD/PI: Panettieri, Reynold Alexander Project Summary/Abstract Overview Coordinated by Rutgers Biomedical and Health Sciences (RBHS), the New Jersey Alliance for Clinical and Translational Science (NJ ACTS) comprises a consortium with Rutgers and Princeton Universities (PU), NJ Institute for Technology (NJIT), medical, nursing, dental and public health schools, hospitals, community health centers, outpatient practices, industry, policymakers and health information exchanges. All Alliance universities and affiliates have provided substantial resources and contributed to the planning, development and leadership of the consortium. With access to ~7 million people, NJ ACTS serves as a ‘natural laboratory’ for translational and clinical research. With a state population of ~9 million, New Jersey ranks 11th in the US, 1st in population density and higher than average in racial and ethnic diversity. Surprisingly, NJ has no CTSA Hub to coordinate translational and clinical research. Our CTSA Hub focuses on two overarching themes: the heterogeneity of disease pathogenesis and response to treatment, and the value of linking large clinical databases with interventional clinical investigations to identify cause-and-effect and predict therapeutic responses. NJ ACTS will provide: innovative approaches to link information from large databases and electronic health records to inform clinical trial design, execution and analysis; and novel platforms for biomarker discovery using fluorescence in situ hybridization and machine learning to identify unique neural signatures of chronic illness. NJ ACTS will access a large health system with significant member diversity; a rich legacy of community engagement and community-based research platforms; and proven approaches to enhance workforce development in clinical research. With a substantial investment in streamlining research administration and IRB practices at Rutgers and with the inception of NJ ACTS, there exists an unparalleled opportunity for logarithmic growth in clinical research in New Jersey. To build our capacity for participant and clinical interactions as a CTSA Hub, the newly established Trial Accelerator and Recruitment Office will coordinate feasibility assessment, implementation, recruitment, and evaluation of clinical studies. Additionally, our organization of five clinical research units into a cohesive network provides extraordinary expertise in strategic locations to enhance participant recruitment from diverse communities with a particular focus on: children; the elderly; those with serious mental illness or substance abuse issues; low-income individuals served by Medicaid; those with HIV/AIDS; and people of all ages who are minorities, underserved, and victims of health and environmental disparities. With a history of collaboration, partners and affiliates share unique skills, expertise, training and mentoring capabilities that will be greatly amplified within the infrastructure of a CTSA Hub. Princeton and NJIT, without medical schools or hospital affiliates, seeks collaboration with Rutgers to provide clinical research platforms; Rutgers seeks the PU and NJIT expertise in novel informatics platforms, expertise in natural language and ontology, machine learning and cognitive neurosciences. Together NJ ACTS will provide an alliance that will catalyze clinical research and training across New Jersey to improve population health and contribute to the CTSA Consortium. In this revised application, the overall themes remain unchanged but Cores leadership and direction has been markedly refined. Page 337 Project Summary/Abstract Contact PD/PI: Panettieri, Reynold Alexander New Jersey Alliance for Clinical and Translational Science (NJ ACTS) Project Narrative The New Jersey Alliance for Clinical and Translational Science (NJ ACTS), as a member of the CTSA Consortium, unites Rutgers University, Princeton University, the New Jersey Institute of Technology, clinical, community and industry partners in a shared vision to make New Jersey a healthier state. Building on New Jersey’s already significant capabilities to promote and facilitate clinical and translational research, NJ ACTS will serve as a catalyst, inspiring new approaches to diagnose and manage disease, and fostering career development of the next generation of translational researchers, and promoting population health.",New Jersey Alliance for Clinical Translational Science: NJ ACTS,9890029,UL1TR003017,"['AIDS/HIV problem', 'Address', 'Affect', 'Age', 'Asian Indian', 'Behavioral', 'Biometry', 'Child', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cohort Studies', 'Collaborations', 'Communities', 'Cuban', 'Databases', 'Dental', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline of Nursing', 'Disease Management', 'Diverse Workforce', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Fluorescent in Situ Hybridization', 'Fostering', 'Foundations', 'Government', 'Growth', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitals', 'Image', 'Improve Access', 'Individual', 'Industry', 'Informatics', 'Infrastructure', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Investigation', 'Investments', 'Laboratories', 'Leadership', 'Life Style', 'Link', 'Location', 'Longevity', 'Low income', 'Machine Learning', 'Medicaid', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Minority', 'Minority Groups', 'Mission', 'Muslim population group', 'Neighborhood Health Center', 'New Jersey', 'Not Hispanic or Latino', 'Ontology', 'Oral health', 'Outpatients', 'Parents', 'Participant', 'Pathogenesis', 'Patient Recruitments', 'Perception', 'Population', 'Population Density', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Preventive Intervention', 'Process', 'Public Health', 'Public Health Schools', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'School Nursing', 'Science', 'Solid', 'South Asian', 'Special Populations Research', 'Substance abuse problem', 'Technology', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Universities', 'Vision', 'Workforce Development', 'analytical tool', 'base', 'biomarker discovery', 'career development', 'catalyst', 'clinical care', 'clinical database', 'clinical investigation', 'cognitive neuroscience', 'cohesion', 'community based participatory research', 'disease heterogeneity', 'ethnic diversity', 'ethnic minority population', 'experience', 'follower of religion Jewish', 'improved', 'industry partner', 'innovation', 'interdisciplinary approach', 'logarithm', 'medical schools', 'member', 'natural language', 'next generation', 'novel', 'novel strategies', 'population health', 'programs', 'racial diversity', 'racial minority', 'recruit', 'relating to nervous system', 'research clinical testing', 'response', 'severe mental illness', 'skills', 'success', 'tool', 'translational scientist', 'treatment response', 'trial design']",NCATS,RUTGERS BIOMEDICAL/HEALTH SCIENCES-RBHS,UL1,2020,4640627,0.012278122773847143
"New Jersey Alliance for Clinical Translational Science: NJ ACTS Contact PD/PI: Panettieri, Reynold Alexander Project Summary/Abstract Overview Coordinated by Rutgers Biomedical and Health Sciences (RBHS), the New Jersey Alliance for Clinical and Translational Science (NJ ACTS) comprises a consortium with Rutgers and Princeton Universities (PU), NJ Institute for Technology (NJIT), medical, nursing, dental and public health schools, hospitals, community health centers, outpatient practices, industry, policymakers and health information exchanges. All Alliance universities and affiliates have provided substantial resources and contributed to the planning, development and leadership of the consortium. With access to ~7 million people, NJ ACTS serves as a ‘natural laboratory’ for translational and clinical research. With a state population of ~9 million, New Jersey ranks 11th in the US, 1st in population density and higher than average in racial and ethnic diversity. Surprisingly, NJ has no CTSA Hub to coordinate translational and clinical research. Our CTSA Hub focuses on two overarching themes: the heterogeneity of disease pathogenesis and response to treatment, and the value of linking large clinical databases with interventional clinical investigations to identify cause-and-effect and predict therapeutic responses. NJ ACTS will provide: innovative approaches to link information from large databases and electronic health records to inform clinical trial design, execution and analysis; and novel platforms for biomarker discovery using fluorescence in situ hybridization and machine learning to identify unique neural signatures of chronic illness. NJ ACTS will access a large health system with significant member diversity; a rich legacy of community engagement and community-based research platforms; and proven approaches to enhance workforce development in clinical research. With a substantial investment in streamlining research administration and IRB practices at Rutgers and with the inception of NJ ACTS, there exists an unparalleled opportunity for logarithmic growth in clinical research in New Jersey. To build our capacity for participant and clinical interactions as a CTSA Hub, the newly established Trial Accelerator and Recruitment Office will coordinate feasibility assessment, implementation, recruitment, and evaluation of clinical studies. Additionally, our organization of five clinical research units into a cohesive network provides extraordinary expertise in strategic locations to enhance participant recruitment from diverse communities with a particular focus on: children; the elderly; those with serious mental illness or substance abuse issues; low-income individuals served by Medicaid; those with HIV/AIDS; and people of all ages who are minorities, underserved, and victims of health and environmental disparities. With a history of collaboration, partners and affiliates share unique skills, expertise, training and mentoring capabilities that will be greatly amplified within the infrastructure of a CTSA Hub. Princeton and NJIT, without medical schools or hospital affiliates, seeks collaboration with Rutgers to provide clinical research platforms; Rutgers seeks the PU and NJIT expertise in novel informatics platforms, expertise in natural language and ontology, machine learning and cognitive neurosciences. Together NJ ACTS will provide an alliance that will catalyze clinical research and training across New Jersey to improve population health and contribute to the CTSA Consortium. In this revised application, the overall themes remain unchanged but Cores leadership and direction has been markedly refined. Page 337 Project Summary/Abstract Contact PD/PI: Panettieri, Reynold Alexander New Jersey Alliance for Clinical and Translational Science (NJ ACTS)  Project Narrative The New Jersey Alliance for Clinical and Translational Science (NJ ACTS), as a member of the CTSA Consortium, unites Rutgers University, Princeton University, the New Jersey Institute of Technology, clinical, community and industry partners in a shared vision to make New Jersey a healthier state. Building on New Jersey’s already significant capabilities to promote and facilitate clinical and translational research, NJ ACTS will serve as a catalyst, inspiring new approaches to diagnose and manage disease, and fostering career development of the next generation of translational researchers, and promoting population health. Page 338 Project Narrative",New Jersey Alliance for Clinical Translational Science: NJ ACTS,10201004,UL1TR003017,"['AIDS/HIV problem', 'Address', 'Affect', 'Age', 'Asian Indian', 'Behavioral', 'Biometry', 'Child', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cohort Studies', 'Collaborations', 'Communities', 'Cuban', 'Databases', 'Dental', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline of Nursing', 'Disease Management', 'Diverse Workforce', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Fluorescent in Situ Hybridization', 'Fostering', 'Foundations', 'Government', 'Growth', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitals', 'Image', 'Improve Access', 'Individual', 'Industry', 'Informatics', 'Infrastructure', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Investigation', 'Investments', 'Laboratories', 'Leadership', 'Life Style', 'Link', 'Location', 'Longevity', 'Low income', 'Machine Learning', 'Medicaid', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Minority', 'Minority Groups', 'Mission', 'Muslim population group', 'Neighborhood Health Center', 'New Jersey', 'Not Hispanic or Latino', 'Ontology', 'Oral health', 'Outpatients', 'Parents', 'Participant', 'Pathogenesis', 'Patient Recruitments', 'Perception', 'Population', 'Population Density', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Preventive Intervention', 'Process', 'Public Health', 'Public Health Schools', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'School Nursing', 'Science', 'Solid', 'South Asian', 'Special Populations Research', 'Substance abuse problem', 'Technology', 'Therapeutic', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Universities', 'Vision', 'Workforce Development', 'analytical tool', 'base', 'biomarker discovery', 'career development', 'catalyst', 'clinical care', 'clinical database', 'clinical investigation', 'cognitive neuroscience', 'cohesion', 'community based participatory research', 'disease heterogeneity', 'ethnic diversity', 'ethnic minority population', 'follower of religion Jewish', 'improved', 'industry partner', 'innovation', 'interdisciplinary approach', 'logarithm', 'medical schools', 'member', 'natural language', 'next generation', 'novel', 'novel strategies', 'population health', 'programs', 'racial diversity', 'racial minority', 'recruit', 'relating to nervous system', 'research clinical testing', 'response', 'severe mental illness', 'skills', 'success', 'tool', 'translational scientist', 'treatment response', 'trial design']",NCATS,RUTGERS BIOMEDICAL/HEALTH SCIENCES-RBHS,UL1,2020,1482000,0.012361500900803993
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10052188,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'combat', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2020,347094,-0.0002787491687147394
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,9944489,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Non-aphasic', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2020,39939,-0.03955528075106911
"ShapeWorks in the Cloud Project Summary This application is submitted in response to NOT-OD-20-073 as an administrative supplement to the parent award R01AR076120 titled: ""Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches."" The form (or shape) of anatomies is the clinical language that describes abnormal mor- phologies tied to pathologic functions. Quantifying such subtle morphological shape changes requires parsing the anatomy into a quantitative description that is consistent across the population in question. For more than 100 years, morphometrics has been an indispensable quantitative tool in medical and biological sciences to study anatomical forms. But its representation capacity is limited to linear distances, angles, and areas. Sta- tistical shape modeling (SSM) is the computational extension of classical morphometric techniques to analyze more detailed representations of complex anatomy and their variability within populations The parent award ad- dresses existing roadblocks for the widespread adoption of SSM computational tools in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM) and its associated suite of open-source software tools, ShapeWorks. ShapeWorks enables learning population-level shape representation via automatic dense placement of homologous landmarks on image segmentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread applicability and impact to medicine and biology are hindered by computational barriers that most existing shape modeling packages face. The goal of this supplement award is to provide supplemental support for Aim 3 of the parent award to leverage best practices in software development and advances in cloud computing to enable researchers with limited computational resources and/or large-scale cohorts to build and execute custom SSM workﬂows us- ing remote scalable computational resources. To achieve this goal, we have developed a plan to enhance the design, implementation, and cloud-readiness of ShapeWorks and augmented our scientiﬁc team to add senior, experienced software engineers/developers who have extensive experience in professional programming, code refactoring, and scientiﬁc computing. This award will provide our team with the support necessary to (Aim 1) de- sign ShapeWorks as a collection of modular and reusable services, (Aim 2) decouple ShapeWorks services from explicitly encoded data sources, and (Aim 3) refactor ShapeWorks to scale efﬁciently on the cloud. All software development will be performed in adherence to software engineering practices and design principles, including coding style, documentation, and version control. The proposed efforts will be released as open-source software in a manner consistent with the principles of reproducible research and the practices of open science. Our long- term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein in addition to the parent award will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. The impact and scientiﬁc value of ShapeWorks have been recognized in a range of applications, including psychology, biological phenotyping, car- diology, and orthopedics. If funded, this supplement will provide support to revise, refactor, and redeploy Shape- Works to take advantage of new cloud computing paradigms, to be robust, sustainable, scalable, and accessible to a broader community, and to address the growing need for shape modeling tools to handle large collections of clinical data and to obtain sufﬁcient statistical power for large shape studies.",ShapeWorks in the Cloud,10166337,R01AR076120,"['Address', 'Adherence', 'Administrative Supplement', 'Adoption', 'Anatomy', 'Applied Research', 'Architecture', 'Area', 'Award', 'Biological', 'Biological Sciences', 'Biology', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cloud Computing', 'Cloud Service', 'Code', 'Collection', 'Communication', 'Communities', 'Complex', 'Complex Analysis', 'Computer Models', 'Computer software', 'Computers', 'Coupled', 'Custom', 'Data', 'Data Sources', 'Databases', 'Disabled Persons', 'Documentation', 'Environment', 'Face', 'Funding', 'Goals', 'Image', 'Imagery', 'Language', 'Learning', 'Machine Learning', 'Mathematics', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Morphology', 'Occupations', 'Online Systems', 'Orthopedics', 'Parents', 'Pathologic', 'Phenotype', 'Population', 'Privatization', 'Psychology', 'Readiness', 'Reproducibility', 'Research', 'Research Personnel', 'Running', 'Scientist', 'Services', 'Shapes', 'Software Design', 'Software Engineering', 'Software Tools', 'Source Code', 'Speed', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Work', 'base', 'cohort', 'computational platform', 'computerized tools', 'computing resources', 'data management', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'large datasets', 'model development', 'open data', 'open source', 'particle', 'response', 'scientific computing', 'shape analysis', 'software development', 'statistics', 'tool', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2020,210000,0.0051265262140479705
"Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software. Abstract (Proposal title: Neuroscience Gateway to Enable Dissemination of Computational and Data Processing Tools and Software.): This proposal presents a focused plan for expanding the capabilities of the Neuroscience Gateway (NSG) to meet the evolving needs of neuroscientists engaged in computationally intensive research. The NSG project began in 2012 with support from the NSF. Its initial goal was to catalyze progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists faced in large scale modeling projects involving tools and software which require and run efficiently on high performance computing (HPC) resources. NSG's success is reflected in the facts that (1) its base of registered users has grown continually since it started operation in early 2013 (more than 800 at present), (2) every year the NSG team successfully acquires ever larger allocations of supercomputer time (recently more than 10,000,000 core hours/year) on academic HPC resources of the Extreme Science and Engineering Discovery (XSEDE – that coordinates NSF supercomputer centers) program by writing proposals that go through an extremely competitive peer review process, and (3) it has contributed to large number of publications and Ph.D thesis. In recent years experimentalists, cognitive neuroscientists and others have begun using NSG for brain image data processing, data analysis and machine learning. NSG now provides over 20 tools on HPC resources for modeling, simulation and data processing. While NSG is currently well used by the neuroscience community, there is increasing interest from that community in applying it to a wider range of tasks than originally conceived. For example, some are trying to use it as an environment for dissemination of lab-developed tools, even though NSG is not suitable for that use because of delays from the batch queue wait times of production HPC resources, and lack of features and resources for an interactive, graphical, and collaborative environment needed for tool development, benchmarking and testing. “Forced” use of NSG for development and dissemination makes NSG's operators a “person-in-the-middle” bottleneck in the process. Another issue is that newly developed data processing tools require high throughput computing (HTC) usage mode, as opposed to HPC, but currently NSG does not provide access to compute resources suitable for HTC. Additionally, data processing workflows require features such as the ability to transfer large size data, process shared data, and visualize output results, which are not currently available on NSG. The work we propose will enhance NSG by adding the features that it needs to be a suitable and efficient dissemination environment for lab-developed neuroscience tools to the broader neuroscience community. This will allow tool developers to disseminate their lab-developed tools on NSG taking advantage of the current functionalities that are being well served on NSG for the last six years such as a growing user base, an easy user interface, an open environment, the ability to access and run jobs on powerful compute resources, availability of free supercomputer time, a well-established training and outreach program, and a functioning user support system. All of these well-functioning features of NSG will make it an ideal environment for dissemination and use of lab-developed computational and data processing neuroscience tools. The Neuroscience Gateway (NSG) was first implemented to enable large scale computational modeling of brain cells and circuits used to study neural function in health and disease. This new project extends NSG's utility to support development, dissemination and use of new tools by the neuroscience community for analyzing enormous data sets produced by advanced experimental methods in neuroscience.",Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software.,10019388,U24EB029005,"['Behavioral', 'Benchmarking', 'Brain imaging', 'Cells', 'Cognitive', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Development', 'Disease', 'Education', 'Education and Outreach', 'Educational workshop', 'Electroencephalography', 'Engineering', 'Environment', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Hour', 'Human Resources', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurosciences Research', 'Occupations', 'Output', 'Peer Review', 'Persons', 'Process', 'Production', 'Psychologist', 'Publications', 'Reaction Time', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Software Tools', 'Students', 'Support System', 'System', 'Testing', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Wait Time', 'Work', 'Workload', 'Writing', 'base', 'bioimaging', 'brain cell', 'collaborative environment', 'computational neuroscience', 'computerized data processing', 'computing resources', 'data sharing', 'image processing', 'interest', 'models and simulation', 'open data', 'operation', 'outreach program', 'programs', 'response', 'success', 'supercomputer', 'tool', 'tool development', 'trend', 'webinar']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2020,381282,0.013731708714656492
"Integrating multidimensional genomic data to discover clinically-relevant predictive models The goal of this NIH Pathway to Independence award is to provide Dr. Brittany Lasseigne with an extensive training program to prepare her to be an effective independent investigator who uses computational genomics to study complex human diseases. We propose a formal one-year training and mentoring program in genomics, computer science, statistics, and career development to build on her 8+ years of hands-on training, followed by a three-year structured and independent research program. Research will focus on the integration of multidimensional genomic data sets in the context of complex human diseases. A critical barrier in genomic research is the complexity of data integration: the ability to leverage overlapping and unique information captured by different genomic assays would improve our understanding of data integration and generate clinically relevant genomic signatures. To meet this need, we propose to integrate a combination of genomic data we generated with public data to (1) infer genomic instability signatures from different data types, (2) improve clinically relevant phenotype prediction by building multi-omics machine learning classifiers and reducing phenotype heterogeneity, and (3) create a cloud-enabled R package and associated Shiny application to accelerate future research. The proposed work will advance our understanding of data integration, allow inference of genomic instabilities across data sets, and generate high performance classifiers for assessing clinically relevant phenotypes in both cancer and psychiatric disease using frameworks that will be broadly applicable across other complex diseases. It will also facilitate prioritization of experiments in future studies by informing on the orthogonality of genomic assays, thereby allowing more efficient study designs to capture as much information as possible within a given sample size or scope of experimentation. Collectively, this additional training will allow Dr. Lasseigne to develop new multidimensional data integration approaches and translational questions applicable across complex diseases when independent. Dr. Richard Myers (HudsonAlpha) and Dr. Gregory Cooper (HudsonAlpha), leaders in applying genetics and genomics to complex human diseases, and an Advisory Committee of additional experts including Dr. Barbara Wold (Caltech), Dr. Eddy Yang (UAB), and Dr. Timothy Reddy (Duke), will provide mentoring throughout this award. The mentored phase will take place at the HudsonAlpha Institute for Biotechnology, an ideal environment for this training with extensive translational science collaborations, expert faculty and staff, and state-of-the art computational and laboratory resources devoted to genomics. This combination will maximize Dr. Lasseigne's training program, facilitating her transition to an independent, tenure-track investigator at a university with a strong commitment to data-driven approaches to complex human disease research, i.e. strong genomics research programs with clinical collaborators, ideally at, or affiliated with, an academic medical center. Project Narrative The major outcome of this project will be a scientist with the necessary research, mentoring, teaching, and career development training to run an independent research program in computational genomics. The research proposed will apply novel strategies to further develop integrative machine learning analyses of multidimensional genomic data, discover clinically relevant predictive models, and create computational tools to accelerate future research.",Integrating multidimensional genomic data to discover clinically-relevant predictive models,9936223,R00HG009678,"['Academic Medical Centers', 'Advisory Committees', 'Award', 'Bioconductor', 'Biological', 'Biological Assay', 'Biotechnology', 'Budgets', 'Cancer Etiology', 'Cell Proliferation', 'Cells', 'Characteristics', 'Chemotherapy-Oncologic Procedure', 'Chromosomal Instability', 'Chromosomes', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Copy Number Polymorphism', 'Coupling', 'CpG Island Methylator Phenotype', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Educational process of instructing', 'Environment', 'Faculty', 'Future', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Genomic Instability', 'Genomics', 'Goals', 'Heterogeneity', 'Individual', 'Institutes', 'Instruction', 'Laboratories', 'Lasso', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mental disorders', 'Mentors', 'Methodology', 'Methylation', 'MicroRNAs', 'Microsatellite Instability', 'Modeling', 'Molecular Profiling', 'Neurons', 'Outcome', 'Pathway interactions', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Signal Transduction', 'Structure', 'Systems Biology', 'Techniques', 'Testing', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Visualization', 'Work', 'Yang', 'biomarker performance', 'career development', 'clinically relevant', 'computer science', 'computerized tools', 'data framework', 'data integration', 'data reduction', 'data standards', 'experimental study', 'genomic data', 'genomic signature', 'human disease', 'improved', 'insight', 'learning classifier', 'multidimensional data', 'multiple omics', 'novel strategies', 'predictive modeling', 'programs', 'promoter', 'protein metabolite', 'response', 'single cell sequencing', 'statistics', 'tenure track', 'tool']",NHGRI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R00,2020,249000,0.008633736972344415
"The University of Iowa Clinical and Translational Science Award ABSTRACT The Institute for Clinical and Translational Science (ICTS) at the University of Iowa (UI) was established by the Board of Regents to realize three objectives – first, to lead the development of translational science at the UI; second, to advance translational science as a distinct academic discipline; and third, to disseminate capacities in translational science across the State of Iowa. This mandate enabled us to tackle large problems affecting translational science that required institutional solutions, such as transforming regulatory processes for human subjects research, developing an informatics infrastructure for integrating electronic medical record and other health care data, establishing bi-directional relationships with community organizations, and revitalizing the pipeline of well trained clinical and translational researchers. Iowa is a rural state, which brings special health care needs and challenges. We have used these rural considerations as a catalyst for driving our approach to clinical and translational research pushing our teams to develop strategies to engage rural populations of all ages and backgrounds and to create new approaches that overcome the geographic barriers in a rural state. We are capitalizing on our established community practice networks of family physicians, clinics, school nurses and pharmacists. We utilize e Health/ e Learning platforms in novel ways and will test the efficacy of these new methods of engagement. As we move research “Beyond Our Borders,” we have created methods to capture real-time, real-life data from the home and to correlate this environmentally specific, comprehensive data to human performance. The ICTS is engaging with other CTSA hubs and national CTR systems to empirically test different approaches and to develop the evidence base of proven strategies for accelerating translation that can be more broadly disseminated. Though distance and rurality drive our approaches, the strategies that we develop are simply new and potentially better ways to generate broad representation and improved participation by patients, healthcare teams and academicians. Through our local, state and national partnerships, UI and the ICTS are poised to move clinical and translational discovery rapidly into healthcare practice in a variety of clinical settings. PROJECT NARRATIVE The mission of the University of Iowa Institute for Clinical and Translational Science (ICTS) is to accelerate translational science through programs to develop the translational workforce, promote the engagement of community members and other stakeholders, to promote research integration across the lifespan, and to catalyze innovative clinical and translational research. The ongoing development of collaborative data-based infrastructure and services is a central tenant to achieving this mission. The goals of this proposal are: for Iowa to join the N3C partnership, contributing data in an effective method that evolves and improves over time, to enable Iowa researchers to leverage the N3C data resource in their research and to leverage the N3C framework for other areas of research in the future.",The University of Iowa Clinical and Translational Science Award,10201104,UL1TR002537,"['Affect', 'Age', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Award', 'COVID-19', 'Caring', 'Center for Translational Science Activities', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical and Translational Science Awards', 'Clinics and Hospitals', 'Communities', 'Community Practice', 'Computerized Medical Record', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Development', 'Discipline', 'Disease', 'E-learning', 'Emergency Situation', 'Family Physicians', 'Future', 'Genomics', 'Geography', 'Goals', 'Health', 'Health system', 'Healthcare', 'Home environment', 'Human', 'Human Subject Research', 'Image', 'Infrastructure', 'Institutes', 'Institutional Review Boards', 'Iowa', 'Knowledge', 'Lead', 'Life', 'Longevity', 'Machine Learning', 'Medical Care Team', 'Methods', 'Mission', 'Modeling', 'Outcome', 'Patient Participation', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Pharmacists', 'Phenotype', 'Positioning Attribute', 'Process', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Rural', 'Rural Health', 'Rural Population', 'School Nursing', 'Services', 'System', 'Testing', 'Time', 'Training', 'Transfer Agreement', 'Translational Research', 'Translations', 'Universities', 'Work', 'base', 'biomedical informatics', 'catalyst', 'clinical decision support', 'cohort', 'collaborative approach', 'community organizations', 'coronavirus disease', 'data acquisition', 'data enclave', 'data exchange', 'data resource', 'data sharing', 'data warehouse', 'efficacy testing', 'evidence base', 'health management', 'improved', 'informatics infrastructure', 'innovation', 'interest', 'member', 'novel', 'novel strategies', 'pandemic disease', 'phenotypic data', 'programs', 'rurality', 'social determinants', 'support tools', 'translational scientist']",NCATS,UNIVERSITY OF IOWA,UL1,2020,98933,0.007414128364152234
"Carolina Population Center PROJECT SUMMARY/ABSTRACT The Carolina Population Center requests infrastructure support that will advance population dynamics research at CPC by increasing research impact, innovation, and productivity, supporting the development of junior scientists, and reducing the administrative burden on scientists. Infrastructure support will advance science in three primary research areas: Sexuality, Reproduction, Fertility, and Families; Population, Health, and the Environment; and Inequality, Mobility, Disparities, and Well-Being. Much of the research at CPC draws on large publicly available longitudinal data sets that our faculty have designed and collected, including the National Longitudinal Study of Adolescent to Adult Health, the China Health and Nutrition Survey, newer surveys associated with the Transfer Project, and the Study of the Tsunami Aftermath and Recovery, all of which will continue to be important in work related to our primary research areas over the next five years. These projects embody several themes that have guided research at CPC since the Center's inception. These themes, which will continue to shape our work, are the importance of life course processes and longitudinal data, multi-level processes and measurement of context, interventions and natural experiments as means of learning about causal processes, and the relevance of sociodemographic variables such as age, gender, race- ethnicity, and socioeconomic status for disparities in health and well-being. By embedding these themes, our projects provide data that enable us to address barriers that otherwise impede progress in the population sciences generally, and in our primary research areas in particular. We request support for three cores which in combination will provide an institutional infrastructure that will push populations dynamics research forward by empowering CPC faculty to tackle challenging questions using state of the art measurement techniques and methods. The Administrative Core plans activities that maintain a stimulating intellectual community, streamlines administrative processes so that scientists can focus on research, coordinates activities of the Cores so that services are offered efficiently, and communicates information about research and data more broadly. The Development Core supports early stage investigators and other faculty with exciting new ideas through multiple mechanisms: workshops, access to technical expertise in measurement, and seed grants. The Research Services Core enables scientists to address complex and important population research issues by providing access to state-of-the-art research tools and professional support for programming, survey development, and analysis. NARRATIVE This project will provide infrastructure support for a cutting edge program of research on population dynamics at the Carolina Population Center. Research at the Center will analyze state-of-the art data to address fundamental questions regarding fertility, adolescent health, and links between the environment and health. Special attention will be paid to factors creating health disparities.",Carolina Population Center,10005569,P2CHD050924,"['Address', 'Adolescent', 'Adopted', 'Adult', 'Age', 'Applications Grants', 'Area', 'Attention', 'Biological Markers', 'China', 'Cognitive', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer Vision Systems', 'Creativeness', 'Data', 'Data Collection', 'Development', 'Diffuse', 'Educational workshop', 'Environment', 'Ethnic Origin', 'Extramural Activities', 'Faculty', 'Family', 'Fertility', 'Fostering', 'Funding', 'Gender', 'Genetic', 'Grant', 'Hand', 'Health', 'Health Surveys', 'Home environment', 'Inequality', 'Infrastructure', 'Intervention', 'Journals', 'Learning', 'Life Cycle Stages', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Mainstreaming', 'Measurement', 'Mentors', 'Methods', 'Natural experiment', 'Nutrition Surveys', 'Personal Satisfaction', 'Phase', 'Policy Making', 'Population', 'Population Dynamics', 'Population Research', 'Population Sciences', 'Postdoctoral Fellow', 'Process', 'Production', 'Productivity', 'Publishing', 'Race', 'Recovery', 'Reproduction', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resources', 'Schools', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Seeds', 'Services', 'Sexuality', 'Shapes', 'Socioeconomic Status', 'Structure', 'Students', 'Surveys', 'Talents', 'Teacher Professional Development', 'Technical Expertise', 'Techniques', 'Training Programs', 'Tsunami', 'Universities', 'Work', 'adolescent health', 'career', 'collaborative environment', 'cost', 'data access', 'design', 'empowered', 'experience', 'faculty support', 'health disparity', 'innovation', 'interdisciplinary collaboration', 'longitudinal dataset', 'novel strategies', 'population health', 'privacy protection', 'programs', 'research and development', 'response', 'sociodemographic variables', 'success', 'tool']",NICHD,UNIV OF NORTH CAROLINA CHAPEL HILL,P2C,2020,774402,0.006340842773689786
"A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers PROJECT SUMMARY/ABSTRACT  This application, “A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,” is in response to PAR-16-238, Dissemination and Implementation Research in Health (R01). Acute respiratory distress syndrome (ARDS) has high prevalence (10% of intensive care unit admissions) and mortality up to 46%. Low tidal volume ventilation (LTVV) is the most effective therapy for ARDS, lowering mortality by 20-25%, and is part of standard practice. However, use of LTVV is as low as 19% of ARDS patients. There is a poor understanding of the barriers to LTVV adoption: current approaches are deficient because they incorporate biases, lack consistency and comprehensiveness, ignore the influence of interpersonal network- or team- based factors, and do not address setting-specific variation. Our research team has previously identified some patient- and clinician-specific facilitators of and barriers to LTVV adoption. We have used two state-of-the-art data driven methods—data science and network analysis—to preliminarily quantify the impact of a diverse array of potential factors affecting LTVV adoption, including network- and team-based factors. The proposed research is guided by the Consolidated Framework for Implementation Research (CFIR) and Rogers' Diffusion of Innovations theory. The overall goals of the proposed research are to understand the differences in facilitators and barriers to LTVV adoption between academic and community settings through a definitive, systematic study in a large, diverse consortium of medical centers, and to advance implementation science by providing a model for how data science and network analysis can be applied to understand the adoption of a complex intervention. The overarching hypothesis is that there are different patient-, clinician-, network-, and team-based facilitators and barriers to LTVV adoption in academic and community settings. We will determine whether different patient- and clinician- (Aim 1 cohort study, clinician survey, and data science analysis), clinician interpersonal network- (Aim 2 network analysis), and team structure and dynamics-based (Aim 3 team construction and modeling) facilitators of and barriers to LTVV adoption exist between academic and community hospital settings. Successful completion of the proposed research will provide a comprehensive understanding of the differences in the facilitators of and barriers to LTVV adoption between academic and community settings, and will advance implementation science by serving as a model of how data science and network analysis can be applied to complex implementation problems. Implementation strategies that account for all these factors may be more likely to lead to significant practice change. PROJECT NARRATIVE  Acute respiratory distress syndrome (ARDS) has high prevalence and mortality among critically ill patients; low tidal volume ventilation is the most effective therapy for ARDS but is used infrequently. Successful completion of the proposed research will identify differences in the facilitators of and barriers to adoption of low tidal volume ventilation between academic and community hospital settings in a large and diverse consortium of medical centers. The proposed research will generate a model of how data science and network analysis can be used to understand the implementation of a complex evidence-based practice.",A novel data science and network analysis approach to quantifying facilitators and barriers of low tidal volume ventilation in an international consortium of medical centers,9963341,R01HL140362,"['Acute', 'Admission activity', 'Adoption', 'Adult Respiratory Distress Syndrome', 'Affect', 'Attitude', 'Caring', 'Characteristics', 'Cohort Studies', 'Community Hospitals', 'Complex', 'Critical Illness', 'Data', 'Data Science', 'Diffusion of Innovation', 'Environment', 'Evidence based practice', 'Goals', 'Health', 'Healthcare Systems', 'Height', 'High Prevalence', 'Hypoxemia', 'Individual', 'Inflammatory', 'Intensive Care Units', 'International', 'Intervention', 'Investigation', 'Knowledge', 'Lead', 'Machine Learning', 'Measurement', 'Medical center', 'Methods', 'Modeling', 'National Heart, Lung, and Blood Institute', 'Nurses', 'Pathway Analysis', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Professional Organizations', 'Pulmonary Edema', 'Research', 'Severities', 'Speed', 'Structure', 'Surveys', 'Syndrome', 'System', 'Testing', 'Tidal Volume', 'Variant', 'base', 'community setting', 'complex data ', 'computer science', 'dissemination research', 'effective therapy', 'experimental study', 'health care settings', 'implementation research', 'implementation science', 'implementation strategy', 'lung injury', 'machine learning method', 'mortality', 'multidisciplinary', 'novel', 'respiratory', 'response', 'theories', 'ventilation']",NHLBI,NORTHSHORE UNIVERSITY HEALTHSYSTEM,R01,2020,745390,0.005072721312108212
"Novel Statistical Inference for Biomedical Big Data Project Summary This project develops novel statistical inference procedures for biomedical big data (BBD), including data from diverse omics platforms, various medical imaging technologies and electronic health records. Statistical inference, i.e., assess- ing uncertainty, statistical signiﬁcance and conﬁdence, is a key step in computational pipelines that aim to discover new disease mechanisms and develop effective treatments using BBD. However, the development of statistical inference procedures for BBD has lagged behind technological advances. In fact, while point estimation and variable selection procedures for BBD have matured over the past two decades, existing inference procedures are either limited to simple methods for marginal inference and/or lack the ability to integrate biomedical data across multiple studies and plat- forms. This paucity is, in large part, due to the challenges of statistical inference in high-dimensional models, where the number of features is considerably larger than the number of subjects in the study. Motivated by our team's extensive and complementary expertise in analyzing multi-omics data from heterogenous studies, including the TOPMed project on which multiple team members currently collaborate, the current proposal aims to address these challenges. The ﬁrst aim of the project develops a novel inference procedure for conditional parameters in high-dimensional models based on dimension reduction, which facilitates seamless integration of external biological information, as well as biomedical data across multiple studies and platforms. To expand the application of this method to very high-dimensional models that arise in BBD applications, the second aim develops a data-adaptive screening procedure for selecting an optimal subset of relevant variables. The third aim develops a novel inference procedure for high-dimensional mixed linear models. This method expands the application domain of high-dimensional inference procedures to studies with longitu- dinal data and repeated measures, which arise commonly in biomedical applications. The fourth aim develops a novel data-driven procedure for controlling the false discovery rate (FDR), which facilitates the integration of evidence from multiple BBD sources, while minimizing the false negative rate (FNR) for optimal discovery. Upon evaluation using ex- tensive simulation experiments and application to multi-omics data from the TOPMed project, the last aim implements the proposed methods into easy-to-use open-source software tools leveraging the R programming language and the capabilities of the Galaxy workﬂow system, thus providing an expandable platform for further developments for BBD methods and tools. Public Health Relevance Biomedical big data (BBD), including large collections of omics data, medical imaging data, and electronic health records, offer unprecedented opportunities for discovering disease mechanisms and developing effective treatments. However, despite their tremendous potential, discovery using BBD has been hindered by computational challenges, including limited advances in statistical inference procedures that allow biomedical researchers to investigate uncon- founded associations among biomarkers of interest and various biological phenotypes, while integrating data from multiple BBD sources. The current proposal bridges this gap by developing novel statistical machine learning methods and easy-to-use open-source software for statistical inference in BBD, which are designed to facilitate the integration of data from multiple studies and platforms.",Novel Statistical Inference for Biomedical Big Data,9969887,R01GM133848,"['Address', 'Adoption', 'Behavioral', 'Big Data Methods', 'Biological', 'Biological Assay', 'Biological Markers', 'Code', 'Collection', 'Communities', 'Computer software', 'Data', 'Data Sources', 'Development', 'Dimensions', 'Disease', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Galaxy', 'Genetic study', 'Goals', 'Heart', 'Imaging technology', 'Individual', 'Linear Models', 'Measurement', 'Measures', 'Medical Imaging', 'Methods', 'Modeling', 'Molecular', 'Multiomic Data', 'Outcome', 'Phenotype', 'Procedures', 'R programming language ', 'Research Personnel', 'Sample Size', 'Scientist', 'Screening procedure', 'Software Tools', 'Structure', 'System', 'Testing', 'Trans-Omics for Precision Medicine', 'Uncertainty', 'Work', 'base', 'big biomedical data', 'computational pipelines', 'data integration', 'design', 'diverse data', 'effective therapy', 'experimental study', 'heterogenous data', 'high dimensionality', 'interest', 'machine learning method', 'member', 'novel', 'open source', 'public health relevance', 'screening', 'simulation', 'statistical and machine learning', 'structured data', 'tool', 'treatment strategy', 'user friendly software']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,456980,-0.008426271227253609
"Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome Addiction is a highly complex disease with risk factors that include genetic variants and differences in development, sex, and environment. The long term potential of precision medicine to improve drug treatment and prevention depends on gaining a much better understanding how genetics, drugs, brain cells, and neuronal circuitry interact to influence behavior. There are serious technical barriers that prevent researchers and clinicians from incorporating more powerful computational and predictive methods in addiction research. The purpose of the NIDA P30 Core Center of Excellence in Omics, Systems Genetics, and the Addictome is to empower and train researchers supported by NIH, NIDA, NIAAA, and other federal and state institutions to use more quantitative and testable ways to analyze genetic, epigenetic, and the environmental factors that influence drug abuse risk and treatment. In the Transcriptome Informatics and Mechanisms research core we assemble and upgrade hundreds of large genome (DNA) and transcriptome (RNA) datasets for experimental rodent (rat) models of addiction. In the Systems Analytics and Modeling research core, we are using innovative systems genetics methods (gene mapping) to understand the linkage between DNA differences, environmental risks such as stress, and the differential risk of drug abuse and relapse. Our Pilot core is catalyzing new collaborations among young investigator in the field of addiction research. In sum the Center is a national resource for more reproducible research in addiction. We are centralizing, archiving, distributing, analyzing and integrating high quality data, metadata, using open software systems in collaboration with many other teams of researchers. Our goal is to help build toward an NIDA Addictome Portal that will include all genomic research relevant to addiction research. PROJECT NARRATIVE The NIDA Core Center of Excellence in Omics, Systems Genetics, and the Addictome (OSGA) provides genomic and computational support to a large number of research scientists working on mechanisms and treatment of addiction. The two main research cores of OSGA are providing support for transcriptome, epigenome, and metagenome studies of rat models of addiction at many levels of analysis. We are also creating open access tools and a powerful web portal to catalyze more effective and replicable use of massive datasets generated by programs in addiction biology and treatment.","Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome",9929423,P30DA044223,"['Archives', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Bioinformatics', 'Biology', 'Biometry', 'Cellular Assay', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consult', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Interactions', 'Drug abuse', 'Educational workshop', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Epigenetic Process', 'Foundations', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Institution', 'Joints', 'Leadership', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences Research', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Prevention', 'Proteome', 'Publications', 'Publishing', 'Quantitative Genetics', 'Quantitative Trait Loci', 'RNA', 'Rattus', 'Relapse', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Rodent', 'Role', 'Scientist', 'Site', 'Standardization', 'Statistical Models', 'Stress', 'Sum', 'System', 'Systems Analysis', 'Testing', 'Training', 'Translations', 'United States National Institutes of Health', 'Update', 'Variant', 'Visualization', 'Work', 'addiction', 'base', 'behavior influence', 'brain cell', 'career', 'cohort', 'computerized tools', 'computing resources', 'data archive', 'data integration', 'data modeling', 'data tools', 'data warehouse', 'deep learning', 'digital imaging', 'drug relapse', 'epigenome', 'experience', 'genetic analysis', 'genetic variant', 'genomic variation', 'graphical user interface', 'health record', 'high dimensionality', 'improved', 'innovation', 'insight', 'metagenome', 'mouse model', 'multiple omics', 'neurogenomics', 'neuronal circuitry', 'novel', 'precision medicine', 'prevent', 'programs', 'ranpirnase', 'rat genome', 'repository', 'sex', 'single cell analysis', 'software systems', 'tool', 'transcriptome', 'transcriptomics', 'web portal']",NIDA,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,P30,2020,754121,-0.006378251379133539
"CORE CENTER FOR CLINICAL RESEACH IN TOTAL JOINT ARTHROPLASTY (CORE-TJA) ABSTRACT - OVERALL Total joint arthroplasty (TJA) is the most common and fastest growing surgery in the nation. There are currently more than 7 million Americans living with artificial joints. Despite the high surgery volume, the evidence base for TJA procedures, technologies and associated interventions are limited. Many surgical approaches and implant technologies in TJA are adopted based on theoretical grounds with limited clinical evidence. The wider TJA research community needs access to large, high quality and rich data sources and state-of-the-art clinical research standards and information technologies to overcome methodological and practical challenges in studies of surgical and nonsurgical interventions in TJA. The overarching goal of Mayo Core Center for Clinical Research in Total Joint Arthroplasty (CORE-TJA) is to facilitate innovative, methodologically rigorous and interdisciplinary clinical research that will directly improve TJA care and the outcomes. The CORE-TJA will serve as a disease (TJA) and theme-focused Center providing shared methodological expertise, education and data resources. The CORE-TJA will leverage big data resources for TJA research, provide customized methodology resources in epidemiology, biostatistics, health services research and medical informatics, and establish synergistic interactions around an integrated Core (American Joint Replacement Registry – AJRR). The Specific Aims of CORE-TJA are: (1) To provide administrative and scientific oversight of CORE-TJA activities (Administrative Core), (2) To provide integrated services, access to large databases and novel analytical methods for clinical research in TJA (Methodology Core); and (3) To meet the unique data needs of the TJA research community and to strengthen the national capacity for large-scale observational and interventional studies in TJA using national registry data (Resource Core). The CORE-TJA will be integrated within the long-standing and highly centralized clinical research environment of the Mayo Clinic, thereby leveraging existing expertise and infrastructure resources, including the Center for Clinical and Translational Science. All CORE-TJA activities will be evaluated using robust metrics to ensure continuous evaluation, flexibility and improvement in response to the most pressing needs of the TJA research community. NARRATIVE The Mayo Core Center for Clinical Research in Total Joint Arthroplasty (CORE-TJA) will provide methodological expertise and access to nationwide data resources to facilitate innovative, methodologically rigorous and interdisciplinary clinical research in TJA. The clinical research needs of the TJA research community that will be addressed by the CORE-TJA include training of the next generation of TJA researchers, customized consultations, facilitated access to high quality, rich data sources and national TJA registry data as well as informatics and methodology support.",CORE CENTER FOR CLINICAL RESEACH IN TOTAL JOINT ARTHROPLASTY (CORE-TJA),10019333,P30AR076312,"['Address', 'Adopted', 'Adoption', 'Advisory Committees', 'American', 'Area', 'Berry', 'Big Data', 'Biometry', 'Characteristics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Communication', 'Communities', 'Consultations', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Element', 'Data Sources', 'Databases', 'Development', 'Disease', 'Documentation', 'Education', 'Electronic Health Record', 'Ensure', 'Environment', 'Epidemiology', 'Evaluation', 'Future', 'Goals', 'Health Services Research', 'Hip Prosthesis', 'Implant', 'Informatics', 'Information Technology', 'Infrastructure', 'Intervention', 'Intervention Studies', 'Joint Prosthesis', 'Knee Prosthesis', 'Leadership', 'Link', 'Medical Informatics', 'Methodology', 'Modeling', 'Musculoskeletal', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Outcome', 'Patient Care', 'Patients', 'Policies', 'Positioning Attribute', 'Procedures', 'Productivity', 'Registries', 'Replacement Arthroplasty', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Secure', 'Services', 'Surgeon', 'Technology', 'Time', 'Training', 'Translating', 'Translational Research', 'Translations', 'United States', 'Vision', 'analytical method', 'base', 'care outcomes', 'clinical center', 'cost', 'data registry', 'data resource', 'education resources', 'evidence base', 'experience', 'flexibility', 'improved', 'improved outcome', 'innovation', 'next generation', 'novel', 'outreach', 'programs', 'response', 'skills', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,P30,2020,629384,0.007836626181192088
"Graspy: A python package for rigorous statistical analysis of populations of attributed connectomes PROJECT SUMMARY Overview: We will extend and develop implementations of foundational methods for analyzing populations of attributed connectomes. Our toolbox will enable brain scientists to (1) infer latent structure from individual connectomes, (2) identify meaningful clusters among populations of connectomes, and (3) detect relationships between connectomes and multivariate phenotypes. The methods we develop and extend will naturally overcome the challenges inherent in connectomics: high-dimensional non-Euclidean data with multi-level nonlinear interactions. Our implementations will comply with the highest open-source standards by: providing extensive online documentation and extended tutorials, hosting workshops to demonstrate our tools on an annual basis, and merging our implementations into commonly used packages such as scikit-learn [1], scipy [2], and networkx [3]. All of the code we develop is open source. We strive to ensure that our code is shared in accordance with the strictest guiding principles. We chose to implement these algorithms in Python due to its wide adoption in the neuroscience and data science fields. In particular, many other neuroscience tools applicable to connectomics, including NetworkX DiPy, mindboggle, nilearn, and nipy, are also implemented in Python. This will enable researchers to chain our analysis tools onto pre-existing pipelines for data preprocessing and visualization. Nonetheless, we feel that sharing our code in our own public repositories is insufficient for global reach. We have also begun reaching out to developers of the leading data science packages in python, including scipy, sklearn, networkx, scikit-image, and DiPy. For each of those packages, we have informal approval to begin integrating algorithms that we have developed. Those packages are collectively used by >220,000 other packages, so merging our algorithms into those packages will significantly extend our global reach. All researchers investigating connectomics, including all the authors of the 24,000 papers that mention the word “connectome”, will be able to apply state-of-the-art statistical theory and methods to their data. Currently, we have about 150 open source software projects on our NeuroData GitHub organization. Collectively, these projects get about 2,000 downloads and >11,000 views per month. As we incorporate additional functionality as described in this proposal, we expect far more researchers across disciplines and sectors will utilize our software. 20 ​ ​​ ​ ​​ Project Narrative Connectomes are an increasingly important modality for characterizing the structure of the brain, to complement behavior, genetics, and physiology. We and others have developed foundational statistical theory and methods over the last decade for the analysis of networks, networks with edge, vertex, and other attributes, and populations thereof, with preliminary implementations of those tools that we leverage in our laboratory for various application papers. In this project, we will extend our package, called graspy, to be of professional quality, implementing key functionality to include (1) estimating latent structure from attributed connectomes, (2) identifying meaningful clusters among populations of connectomes, and (3) detecting relationships between connectomes and multivariate phenotypes, such as behavior, genetics, and physiology. 18",Graspy: A python package for rigorous statistical analysis of populations of attributed connectomes,10012519,RF1MH123233,"['Adoption', 'Algorithms', 'Behavioral Genetics', 'Brain', 'Code', 'Coin', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Development', 'Discipline', 'Documentation', 'Educational workshop', 'Ensure', 'Foundations', 'Funding', 'Genes', 'Human', 'Image', 'Individual', 'Journals', 'Laboratories', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modality', 'Modernization', 'Motivation', 'Neurosciences', 'Paper', 'Pathway Analysis', 'Phenotype', 'Physiology', 'Population', 'Population Analysis', 'Population Study', 'Property', 'PubMed', 'Publishing', 'Pythons', 'Research Personnel', 'Scientist', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Study', 'Structure', 'Telecommunications', 'Testing', 'Visualization', 'Work', 'brain research', 'connectome', 'data pipeline', 'design', 'high dimensionality', 'high standard', 'open source', 'public repository', 'software development', 'theories', 'tool', 'user-friendly']",NIMH,JOHNS HOPKINS UNIVERSITY,RF1,2020,1246005,-0.003959420797451654
"CRCNS: US-France Data Sharing Proposal: Lowering the barrier of entry to network neuroscience The field of network neuroscience has developed powerful analysis tools for studying brain networks and holds promise for deepening our understanding of the role played by brain networks in health, disease, development, and cognition. Despite widespread interest, barriers exist that prevent these tools from having broader impact. These include (1) unstandardized practices for sharing and documenting software, (2) long delays from when a method is first introduced to when it becomes publicly available, and (3) gaps in theoretic knowledge and understanding leading to incorrect, delays due to mistakes, and errors in reported results. These barriers ultimately slow the rate of neuroscientific discovery and stall progress in applied domains. To overcome these challenges, we will use open science methods and cloud-computing, to increase the availability of network neuroscience tools. We will use the platform ""brainlife.io"" for sharing these tools, which will be packaged into self-contained, standardized, reproducible Apps, shared with and modified by a community of users, and integrated into existing brainlife.io analysis pipelines. Apps will also be accompanied by links to primary sources, in-depth tutorials, and documentation, and worked-through examples, highlighting their correct usage and offering solutions for mitigating possible pitfalls. In standardizing and packaging network neuroscience tools as Apps, this proposed research will engage a new generation of neuroscientists, providing them powerful new and leading to new discoveries. Second, the proposed research will contribute growing suite of modeling analysis that can be modified to suit specialized purposes. Finally, the Brainlife.io platform will serve as part of the infrastructure supporting neuroscience research. Altogether, these advances will lead to new opportunities in network neuroscience research and further stimulate its growth while increasing synergies with other domains in neuroscience. Structural and functional networks support cognitive processes. Miswiring networks lead to maladaptive behavior and neuropsychicatric disorders. Network neuroscience is a young field that provides a quantitative framework for modeling brain networks. This project will make network neuroscientific tools available to new users via open science and cloud-computing. New applications of these tools this will lead deeper insight into the role of networks in health as well as in clinical disorders.",CRCNS: US-France Data Sharing Proposal: Lowering the barrier of entry to network neuroscience,10019389,R01EB029272,"['Address', 'Aging', 'Behavior', 'Biophysics', 'Brain', 'Clinical', 'Cloud Computing', 'Cognition', 'Communities', 'Complex Analysis', 'Computer software', 'Data', 'Data Set', 'Development', 'Disease', 'Documentation', 'Ecosystem', 'Education', 'Elements', 'France', 'Funding', 'Generations', 'Graph', 'Growth', 'Health', 'Infrastructure', 'Instruction', 'Knowledge', 'Language', 'Lead', 'Libraries', 'Link', 'Literature', 'Mathematics', 'Methods', 'Modeling', 'Neurosciences', 'Neurosciences Research', 'Pathway Analysis', 'Play', 'Process', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Role', 'Running', 'Science', 'Sociology', 'Source', 'Standardization', 'Structure', 'Study models', 'System', 'Techniques', 'Time', 'Training', 'Work', 'analysis pipeline', 'brain computer interface', 'cloud based', 'cognitive process', 'cyber infrastructure', 'data sharing', 'experience', 'innovation', 'insight', 'interest', 'machine learning method', 'network architecture', 'network models', 'neuroimaging', 'open data', 'prevent', 'relating to nervous system', 'statistics', 'support network', 'synergism', 'tool']",NIBIB,INDIANA UNIVERSITY BLOOMINGTON,R01,2020,218594,-0.015907479562313444
"University of Buffalo Clinical and Translational Science Institute The Buffalo Translational Consortium (BTC), which includes the University at Buffalo (UB) health sciences schools, the major healthcare institutions in our region, four key research institutes and five influential community partners, have embarked on a comprehensive strategic plan to build a strong foundation for clinical and translational research in response to our community needs. Buffalo is the second most populous city in New York State and has a rich cultural history. The proportion of underrepresented minorities in Buffalo in 2018 (50%) parallels that projected for the US in 2050, making Buffalo a microcosm of what the US will look like in 30 years. A similar proportion of our population experiences health disparities. The vision for our CTSA hub is to perform innovative research across the translational spectrum to improve the health of our community and the nation. We will develop, test and share novel approaches to engage difficult-to-engage populations and reduce health disparities in our community, which represents a “population of the future”. Guided by our vision, the CTSA has catalyzed a transformation of our environment since our CTSA was first funded in August 2015 with remarkable growth in clinical and translational research. Further, in just the past year, the UB medical school has moved into a spectacular new building and our clinical partner, Kaleida Health, the largest healthcare system in the region, opened the new Oishei Children’s Hospital, both on the Buffalo Niagara Medical Campus and connected to the Clinical and Translational Research Center devoted entirely to clinical and translational research that opened in 2012. This rapid and continuing trajectory of growth in healthcare and research in the region has resulted in a new 21st century Academic Health Center with healthcare, medical education and clinical and translational research on one campus in the heart of Buffalo, creating a foundation to enhance the impact of our CTSA even further. While launching our CTSA, we have prioritized participation in the national consortium through hosting and testing Innovation Labs as a team science tool, working with multiple hubs on initiatives to solve translational research barriers and sharing tools that we have developed with the CTSA consortium, including novel health informatics tools. Our CTSA has five ambitious but achievable aims, including: 1) Accelerate innovative translational research with teams that engage communities, regional stakeholders and the national consortium; 2) Train an excellent, diverse workforce to advance translation of discoveries; 3) Enhance inclusion of special populations across the lifespan and difficult-to-engage populations; 4) Streamline clinical research processes focusing on quality and efficiency with emphasis on multisite studies; 5) Develop, test and share biomedical informatics tools to integrate data from multiple sources to speed translation. Guided by our vision to perform research to improve the health of our community and the nation, we will continue our momentum to expand translational research, train our diverse workforce, streamline processes, engage our community, and actively contribute to the national consortium. The University at Buffalo Clinical and Translational Science Institute (CTSI) is the coordinating center of the Buffalo Translational Consortium, which includes the region's premier research, educational and clinical institutions with influential community partners. The vision of the CTSI is to perform innovative clinical and translational research to reduce health disparities and improve the health of our community and the nation. We engage our community as research partners to create a shared environment to bring discoveries in the laboratory, clinic and community to benefit individual and public health.",University of Buffalo Clinical and Translational Science Institute,10053435,UL1TR001412,"['Achievement', 'Address', 'Adopted', 'African American', 'Buffaloes', 'Center for Translational Science Activities', 'Cities', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Communities', 'Community Health', 'County', 'Coupled', 'Cultural Backgrounds', 'Data', 'Diverse Workforce', 'Ensure', 'Environment', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'Growth', 'Health', 'Health Care Research', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Healthcare', 'Healthcare Systems', 'Heart', 'Image', 'Imaging technology', 'Individual', 'Influentials', 'Informatics', 'Institutes', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Life Expectancy', 'Longevity', 'Medical', 'Medical Education', 'Medical center', 'Methods', 'Natural Language Processing', 'New York', 'Outcomes Research', 'Participant', 'Pediatric Hospitals', 'Phenotype', 'Population', 'Poverty', 'Process', 'Program Development', 'Prospective Studies', 'Public Health', 'Public Health Informatics', 'Recording of previous events', 'Recruitment Activity', 'Refugees', 'Research', 'Research Institute', 'Research Personnel', 'Research Training', 'Resources', 'Schools', 'Science', 'Sensitivity and Specificity', 'Site', 'Speed', 'Strategic Planning', 'System', 'Testing', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'Universities', 'Vision', 'Work', 'Workforce Development', 'base', 'biomedical informatics', 'clinical center', 'clinical data warehouse', 'community partnership', 'data sharing', 'education research', 'experience', 'health care disparity', 'health disparity', 'imaging genetics', 'improved', 'informatics tool', 'innovation', 'interoperability', 'medical schools', 'multidisciplinary', 'multiple data sources', 'named group', 'novel', 'novel strategies', 'recruit', 'response', 'sharing platform', 'skills', 'social health determinants', 'structured data', 'tool', 'translational impact', 'translational pipeline', 'translational scientist', 'unstructured data']",NCATS,STATE UNIVERSITY OF NEW YORK AT BUFFALO,UL1,2020,4118079,0.009900573079051048
"Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics Abstract Support is requested for a Keystone Symposia conference entitled Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics, organized by Drs. Jose M. Lora and Timothy K. Lu. The conference will be held in Breckenridge, Colorado from March 29- April 1, 2019. Synthetic Biology tools and principles have matured tremendously over the last decade and have reached extraordinary levels of sophistication, both in eukaryotic and prokaryotic systems. Synthetic biology as a therapeutic modality is starting to enter multiple clinical studies and has the potential to have a significant impact on medicine across a wide range of diseases (e.g., metabolic, immune-mediated, cancer, and neurologic diseases). This Keystone Symposia conference will delve into the field of synthetic biology with a special emphasis on its applications to medicine. While there are conferences that capture synthetic biology in only a few talks mixed in among other various topics, there is a paucity of conferences focused on synthetic biology as drugs to treat disease. However, due to the rapid pace of fundamental scientific advances along with an expanding number of biotechnology companies and emerging clinical studies with synthetic biology at their core, this conference will be highly relevant for a wide audience of scientists both from academia and industry. In addition, other meetings in this field have a highly technology-driven focus on synthetic biology techniques with relatively little attention given to biological and medical context. Ultimately, this Keystone Symposia conference should inspire researchers from diverse backgrounds to discuss synthetic biology via many new angles. PROJECT NARRATIVE Over the past two decades, tremendous advances have been made in the use of biological parts to engineer systems that can effectively direct living cells for a vast variety of purposes (a.k.a. synthetic biology). Synthetic biology is being used to construct more effective therapies in diseases such as cancer, but there are remaining obstacles to the clinical translation of these therapies. This Keystone Symposia conference will delve into the field of synthetic biology with a special emphasis on its applications to medicine.",Synthetic Biology: At the Crossroads of Genetic Engineering and Human Therapeutics,9913772,R13EB029305,"['Academia', 'Address', 'Area', 'Attention', 'Biological', 'Biomedical Research', 'Biotechnology', 'Cells', 'Clinical Research', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Colorado', 'Computers', 'Disease', 'Educational workshop', 'Engineering', 'Future', 'Genetic Engineering', 'Genetic Screening', 'Human', 'Immune', 'Industrialization', 'Industry', 'Knowledge', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Mediating', 'Medical', 'Medicine', 'Metabolic', 'Methodology', 'Modality', 'Neurologic', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Postdoctoral Fellow', 'Preventive', 'Process', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Scientific Advances and Accomplishments', 'Scientist', 'System', 'Techniques', 'Technology', 'Therapeutic', 'Work', 'clinical application', 'clinical practice', 'clinical translation', 'combinatorial', 'design', 'effective therapy', 'graduate student', 'meetings', 'nervous system disorder', 'next generation', 'novel diagnostics', 'posters', 'symposium', 'synthetic biology', 'targeted treatment', 'tool']",NIBIB,KEYSTONE SYMPOSIA,R13,2020,10000,-0.00256434619337516
"Mixed Reality System for STEM Education and the promotion of health-related careers Project Summary/Abstract Proposed is a system to combine and leverage the advantages of existing medical props with interactive media to provide engaging and cooperative group STEM learning experiences. Significance: The PowerPoint lecture style has become the standard method for teaching groups of students. Unfortunately, this style does not emphasize student-instructor or student-student instruction, and in fact seems to have made students even less engaged than before. Broad agreement exists in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning exercises. Despite their substantial benefits, physical props are fundamentally limited as they are primarily static (e.g. fixed coloration, disease depiction), their internal structures (with limited exceptions) often bear little resemblance to actual human anatomy, and they are passive objects. Hypothesis: A system which can provide more engaging interaction with physical props will be able to improve student retention and increase interest in STEM related subjects. Specific Aims: To prove the feasibility of the proposed system in Phase I IDL will 1) Determine stakeholder requirements through round table discussions; 2) Create prototype system hardware & software to augment learning with physical props; and 3) Validate the prototype system through a pilot study. The overall Phase I effort will demonstrate the ability of the proposed system to augment learning with physical props. In the Phase II effort IDL will ready the system for commercialization by 1) Developing production-quality software, hardware, and user interfaces; 2) Developing a set of comprehensive curricula for the system; and 3) Validating the system through human subject testing. Project Narrative Passive learning methods, i.e. PowerPoint lectures, have become the standard method for teaching groups of students topics including Anatomy and Physiology in spite of broad agreement in the field of science education that more engaging pedagogies benefit students in introductory classes. A variety of teaching aids, for example plastic medical props and mannequins are available to support more engaging learning; however, these props are fundamentally limited.",Mixed Reality System for STEM Education and the promotion of health-related careers,9997967,R44GM130247,"['3-Dimensional', 'Agreement', 'Algorithmic Software', 'Anatomy', 'Biological', 'Biological Sciences', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Development', 'Disease', 'Disease Progression', 'Dissection', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Environment', 'Exercise', 'Hand', 'Health', 'Health Promotion and Education', 'Hour', 'Human', 'Hybrids', 'Image', 'Instruction', 'Intervention', 'Learning', 'Location', 'Manikins', 'Medical', 'Minnesota', 'Modeling', 'Participant', 'Phase', 'Physiological', 'Physiology', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Production', 'Role', 'Sampling', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Slide', 'Small Business Innovation Research Grant', 'Structure', 'Students', 'Support Groups', 'System', 'Teaching Method', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'animation', 'career', 'college', 'commercialization', 'design', 'digital media', 'experience', 'flexibility', 'graphical user interface', 'guided inquiry', 'hands-on learning', 'human subject', 'improved', 'innovation', 'instructor', 'interactive tool', 'interest', 'learning strategy', 'lectures', 'machine vision', 'mid-career faculty', 'mixed reality', 'pedagogy', 'prototype', 'retention rate', 'science education', 'software systems']",NIGMS,"INNOVATIVE DESIGN LABS, INC.",R44,2020,698435,0.008275876977055667
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,9935719,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Asses', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2020,599090,-0.008866550184722965
"South Carolina Clinical & Translational Research Institute (SCTR) PROJECT SUMMARY – SCTR INSTITUTE Parent Award UL1-TR001450 Since 2009, the South Carolina Clinical and Translational Research Institute (SCTR) has transformed the research environment across South Carolina (SC) by creating a Learning Health System that supports high- quality clinical and translational research (CTR) and fosters collaboration and innovation. Headquartered at the Medical University of South Carolina (MUSC), SCTR has engaged stakeholders and created statewide partnerships to improve care and address social determinants of health across SC. However, greater than 75% of SC is rural, and all 46 counties contain areas designated as medically underserved, so health disparities remain an issue. Over the next five years, SCTR will strengthen its outreach to these medically underserved areas through collaboration with the Clemson University Health Extension Program and the MUSC Telehealth Center of Excellence. With a focus on implementation and dissemination as well as discovery, we will develop and demonstrate innovative technologies and outreach to improve the health of our stakeholders. We will build on prior successes and introduce innovative approaches to expand CTR across SC through the following aims: Aim 1. Extend and enhance high-quality, innovative, flexible curricula and training experiences for all levels of the CTR workforce, with particular emphasis on enhancing workforce heterogeneity and team science. Aim 2. Engage a diverse group of stakeholders as active partners in CTR to address health care priorities while enhancing the scientific knowledge base about collaboration and engagement. Aim 3. Promote greater inclusion across the full translational spectrum of research by engaging investigators from many disciplines and patient populations from diverse demographic backgrounds and geographic areas. Aim 4. Develop, demonstrate and disseminate innovative methods and processes to address barriers and accelerate the translation of research discoveries to improvements in human health that can be generalized to a variety of practice settings. Aim 5. Enhance the conduct of translational research through the development of secure and innovative informatics and digital health solutions, tools and methodologies that affect every aspect of CTR. SCTR’s vision is to be a major force in facilitating the translation of innovative science into practice to address the health priorities of the citizens of SC and beyond. To achieve this vision, SCTR’s mission is to catalyze the development of methods and technologies that lead to more efficient translation of biomedical discoveries into interventions that improve individual and public health. SCTR will serve as the statewide academic home for CTR, one that is well-integrated with SC’s healthcare systems and provides essential support for innovative, efficient, multidisciplinary research and research training. We will work within SCTR, with our partners across SC and with the CTSA Consortium to realize this vision. PROJECT NARRATIVE The South Carolina Clinical and Translational Research Institute (SCTR) has transformed the research environment across South Carolina by creating a Learning Health System characterized by strong training and infrastructure resources that stimulate collaboration and innovation as a means to accelerate the translation of biomedical research discoveries into human health improvements. A major focus of this application is to strengthen SCTR’s statewide collaborations through innovative partnerships and initiatives with an emphasis on rural and medically underserved communities where significant health disparities exist. We will develop, demonstrate and disseminate innovative ways to train a diverse workforce and address barriers to translational research, and we will continue to collaborate across the CTSA Consortium to maximize impact and improve the health of the nation.",South Carolina Clinical & Translational Research Institute (SCTR),10241088,UL1TR001450,"['2019-nCoV', 'Address', 'Administrative Supplement', 'Affect', 'Area', 'Award', 'Biomedical Research', 'COVID-19', 'COVID-19 pandemic', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials Network', 'Clinical and Translational Science Awards', 'Clinical effectiveness', 'Collaborations', 'Communities', 'County', 'Databases', 'Development', 'Discipline', 'Diverse Workforce', 'Educational Curriculum', 'Electronic Health Record', 'Emergency Situation', 'Environment', 'Fast Healthcare Interoperability Resources', 'Fostering', 'Geographic Locations', 'Health', 'Health Priorities', 'Health Sciences', 'Health system', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Home environment', 'Human', 'Individual', 'Informatics', 'Information Retrieval', 'Interdisciplinary Study', 'Intervention', 'Lead', 'Learning', 'Link', 'Medical', 'Medically Underserved Area', 'Methodology', 'Methods', 'Mission', 'Modeling', 'Natural Language Processing', 'Outcome', 'Parents', 'Patients', 'Phenotype', 'Population', 'Population Heterogeneity', 'Process', 'Public Health', 'Research', 'Research Institute', 'Research Personnel', 'Research Training', 'Resources', 'Rural', 'Science', 'Secure', 'South Carolina', 'Support System', 'Technology', 'Terminology', 'Text', 'Training', 'Training and Infrastructure', 'Translating', 'Translational Research', 'Translations', 'Universities', 'Vision', 'Work', 'base', 'biomedical informatics', 'cohort', 'coronavirus disease', 'cost effective', 'data access', 'data enclave', 'data interoperability', 'data modeling', 'data sharing', 'digital', 'expectation', 'experience', 'flexibility', 'health disparity', 'improved', 'innovation', 'innovative technologies', 'interest', 'knowledge base', 'medically underserved', 'member', 'method development', 'outreach', 'parent grant', 'patient population', 'practice setting', 'programs', 'response', 'rural underserved', 'social health determinants', 'success', 'synergism', 'telehealth', 'tool', 'translational pipeline', 'web services']",NCATS,MEDICAL UNIVERSITY OF SOUTH CAROLINA,UL1,2020,100000,0.008495038270359807
"Augmented Reality System for the Education of Clinical Caregivers of Older Adults Project Summary/Abstract Proposed is a system to combine and leverage the advantages of both existing physical mannequin-based training and virtual media to support clinical learning using Augmented Reality (AR). Significance: Education in clinical settings is often challenging, infeasible, risky, difficult to organize, time-consuming, and expensive. Due to these barriers, the value of mannequin-based simulation is well recognized and is incorporated extensively into medical education. In general, the purpose of mannequin use in education is to simulate a physical ""patient"" on which to learn, demonstrate, and test skill without fear of harming patients prior to entering clinical environments. Despite their substantial benefits, physical mannequins have several fundamental limitations that do not allow them to demonstrate the many unique phases and expressions of a disease or person-to-person differences in anatomy and physiology. This limits the ability for a learner to view dynamic changes over time and to explore disease progression and consequences of interventions. Hypothesis: This research hypothesizes that existing, current mannequins can be enhanced through an innovative and practical Augmented Reality solution. In the Phase I effort a prototype system and sample educational material covering Pressure Ulcer care was developed and analyzed through pilot studies with Nursing educators, Doctoral Degree in Nursing (DNP) students, and pre-licensure students. The pilot results of the technology demonstrated a high degree of positivity and exceptional enthusiasm and all Phase I metrics of success were met or exceeded. Specific Aims: In Phase II the following aims are proposed: 1) Design a comprehensive suite of course content and design the technology's integration into a College of Nursing course, 2) Develop a production-ready system, and 3) Validate the system utility through human subject testing and expert evaluation of the system. Project Narrative Over the past decade, medical simulation has been experiencing explosive growth and widespread adoption. There are now over 800 medical simulation centers in the US alone, located in medical schools, nursing schools, hospitals, military simulation centers, and schools of allied health professions. The global market for Mannequin-Based Simulation is projected to reach $1 Billion by 2020. It is hypothesized that the combination of existing physical mannequin-based training with virtual media will open new possibilities for exploration and enhanced learning interactions for medical education. 3T",Augmented Reality System for the Education of Clinical Caregivers of Older Adults,9964623,R44AG057257,"['Adoption', 'Adult', 'Algorithmic Software', 'Allied Health Profession', 'Anatomy', 'Area', 'Augmented Reality', 'Caregivers', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer Vision Systems', 'Computer software', 'Computers', 'Consumption', 'Course Content', 'Development', 'Discipline of Nursing', 'Disease', 'Disease Progression', 'Dissection', 'Doctor&apos', 's Degree', 'Education', 'Educational Curriculum', 'Educational Materials', 'Elderly', 'Environment', 'Evaluation', 'Focus Groups', 'Fright', 'Goals', 'Growth', 'Hospitals', 'Hour', 'Human', 'Image', 'Individual', 'Intervention', 'Laboratories', 'Learning', 'Licensure', 'Location', 'Manikins', 'Medical', 'Medical Education', 'Military Personnel', 'Minnesota', 'Modeling', 'Movement', 'Nursing Faculty', 'Nursing Schools', 'Nursing Students', 'Patients', 'Performance', 'Persons', 'Phase', 'Physiology', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Production', 'Research', 'Sampling', 'School Nursing', 'Schools', 'Scientist', 'Severity of illness', 'Skin', 'Structure', 'Students', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Ursidae Family', 'animation', 'base', 'caregiver education', 'college', 'commercialization', 'cost', 'decubitus ulcer', 'design', 'experience', 'flexibility', 'human subject', 'impression', 'innovation', 'medical schools', 'miniaturize', 'person centered', 'professor', 'programs', 'prototype', 'simulation', 'skills', 'success', 'teacher', 'virtual']",NIA,"INNOVATIVE DESIGN LABS, INC.",R44,2020,688185,-0.011031297795861443
"Tufts Clinical and Translational Science Institute (N3C Supplement) PROJECT SUMMARY Tufts Clinical and Translational Science Institute (Tufts CTSI) is based on the conviction that authentic involvement of the entire spectrum of clinical and translational research (CTR) is critical to fulfilling the promise of biomedical science for meeting the public's needs. This includes not only from translation from bench to bedside (T1 translation), but also, crucially for having health impact, translation into effective clinical practice (T2), care delivery and public health (T3), and health policy (T4). Advances on all of these fronts is increasingly dependent on making effective use of scientific data from multiple domains. The COVID-19 global emergency presents both an immediate challenge and an opportunity to progress on important data sharing aims emphasized by NIH. In response, NCATS and the Centers for Translational Science Award (CTSA) hubs, several HHS agencies, and other partnering organizations have committed to developing a next-generation repository for clinical data related to COVID-19, the National COVID Cohort Collaborative (N3C), as a means of accelerating global research into the disease and aiding the development of diagnostics, therapeutics, and effective vaccines. The N3C initiative's goal of improving the efficiency and accessibility of analyses with clinical data is consistent with the primary informatics objectives of Tufts CTSI, which am to reduce barriers to the integration of healthcare and research by providing innovative systems, data repositories, and analytical tools, and by enabling greater exchange and collaboration through interoperability, standardization, and resource sharing. In- line with shared objectives, in this supplement we seek to contribute to the N3C initiative as a data provider and thought partner through the following specific aims: (1) continue to play an important role providing tools and resources for N3C's analytics platform; and (2) ensure Tufts CTSI's Informatics Program has sufficient staff and technical resources to continue to provide COVID-specific patient data from our hub to the N3C repository. PROJECT NARRATIVE An integrated, continuously updated data repository and a platform of putting powerful analytics capabilities at the disposal of the scientific community can generate insights into COVID-19 and accelerate the development of effective treatments and vaccines to counter the disease. In this project, Tufts Clinical and Translational Science Institute plans to contribute to this goal by providing carefully structured clinical data and innovative informatics tools to the National COVID Cohort Collaborative (N3C), an initiative demonstrating a novel approach for collaborative pandemic data sharing.",Tufts Clinical and Translational Science Institute (N3C Supplement),10172199,UL1TR002544,"['Award', 'COVID-19', 'Caring', 'Center for Translational Science Activities', 'Clinical Data', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Communities', 'Data', 'Development', 'Diagnostic', 'Disease', 'Emergency Situation', 'Ensure', 'Environment', 'Funding', 'Goals', 'Health', 'Health Care Research', 'Health Policy', 'Informatics', 'Institutes', 'Knowledge', 'Machine Learning', 'Mission', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Play', 'Provider', 'Public Health', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Risk', 'Role', 'Science', 'Secure', 'Speed', 'Standardization', 'Structure', 'System', 'Time', 'Translational Research', 'Translations', 'Treatment Efficacy', 'United States National Institutes of Health', 'Update', 'Vaccines', 'analytical tool', 'base', 'bench to bedside', 'care delivery', 'clinical data warehouse', 'clinical decision support', 'clinical practice', 'cohort', 'collaborative approach', 'convict', 'coronavirus disease', 'data integration', 'data sharing', 'data warehouse', 'effective therapy', 'health management', 'improved', 'informatics tool', 'innovation', 'insight', 'interoperability', 'meetings', 'next generation', 'novel strategies', 'pandemic disease', 'programs', 'repository', 'response', 'social determinants', 'support tools', 'tool']",NCATS,TUFTS UNIVERSITY BOSTON,UL1,2020,100000,0.008198468321244538
"Discovery and validation of neuronal enhancers as development of psychiatric disorders supplement Project Summary/Abstract The mandate of the PsychENCODE Data Analysis Core (DAC) includes the development of novel integrative methodologies to construct a coherent interpretational framework for the data emerging from the consortium. The complexity of building such a framework lies in the diversity of experimental assays and their associated confounding factors, as well as in the inherent uncertainty regarding how the various target biological components function together. As a result, any analytical and computational methods would need to capture this high dimensionality of structure in the data. While classical, parallel computation advances at an incredible pace and continues to serve the needs of the research community, our experience with the ever- increasing complexity of neuropsychiatric datasets has motivated us to also look at other promising technological avenues. Accordingly, motivated by recent developments in the field of quantum computing (QC), we herein explore the use of QC algorithms as applied to two problems of relevance to the PsychENCODE DAC: (1) the prediction of brain-specific enhancers based on variants and functional genomic assays (Aim S1; related to Aim 1 of the parent grant); and (2) the calculation of the contributions of cell types to tissue-level gene expression and to the occurrence of psychiatric disorders like schizophrenia, autism spectrum disorder and bipolar disorder (Aim S2; related to Aim 1 of the parent grant). The nascency of QC hardware technologies and the complexity of simulating quantum algorithms on classical computing resources means that our exploration will be confined to smaller, judiciously chosen datasets.Nevertheless, the work in this supplement will serve to evaluate future prospects for the use of QC algorithms and hardware in genomic analyses. We also consider two different paradigms of QC, the quantum annealer and the quantum gate model, and weigh their efficiency relative to classical computing. Finally, we will incorporate the QC and classical predictions into PsychENCODE consortium's database and online portal for visualizing the relationships between different genetic and genomic elements, and evaluate corroborating evidence for the predictions (Aim S3; related to Aim 2 of the parent grant). Project Narrative The PsychENCODE consortium has conducted extensive functional genomic analyses of samples from individuals diagnosed with psychiatric disorders aim to discover the complex biological architecture that lead from genetic and epigenetic markers of disease to the observed phenotypes. To reveal this underlying structure, the consortium relies on the use of sophisticated computational methods, including machine learning techniques, implemented on cutting-edge massively parallel computing resources by the consrtium’s Data Analysis Core (DAC). However, the scale and complexity of the tasks place significant burdens on these resources, and suggest the need for exploring alternative computing hardware technologies. This supplement to the DAC parent grant evaluates the promise of the emerging field of quantum computing to speed up large-scale computations and more efficiently explore the model landscape, using a comparative analysis of classical and quantum computing algorithms applied to problems relevant to the PsychENCODE DAC: the annotation of brain-specific enhancers and the quantification of cell-type contributions to bulk tissue gene expression.",Discovery and validation of neuronal enhancers as development of psychiatric disorders supplement,10047746,U01MH116492,"['Algorithms', 'Architecture', 'Biological', 'Biological Assay', 'Bipolar Disorder', 'Brain', 'Cells', 'Communities', 'Complex', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Disease Marker', 'Electronic Medical Records and Genomics Network', 'Elements', 'Enhancers', 'Future', 'Gene Expression', 'Genetic', 'Genetic Markers', 'Genomics', 'Goals', 'Individual', 'Lead', 'Least-Squares Analysis', 'Machine Learning', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Neurons', 'Output', 'Performance', 'Phenotype', 'Publishing', 'Research', 'Resources', 'Running', 'Sampling', 'Schizophrenia', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Tissues', 'Toy', 'Training', 'Uncertainty', 'Validation', 'Variant', 'Visualization', 'Work', 'analytical method', 'autism spectrum disorder', 'base', 'cell type', 'comparative', 'computing resources', 'data framework', 'design', 'epigenetic marker', 'epigenomics', 'experience', 'functional genomics', 'high dimensionality', 'neuropsychiatry', 'novel', 'parallel computer', 'parent grant', 'prototype', 'quantum', 'quantum computing', 'simulation', 'transcriptome sequencing', 'web portal']",NIMH,UNIV OF MASSACHUSETTS MED SCH WORCESTER,U01,2020,195697,-0.015848131973025623
"An interactive, digital platform to transform physical science learning Abstract: The next generation of science and health care professionals will need to understand the foundational concepts of physics. While textbooks play a critical role in science learning, these books are not designed to meet the diverse learning needs of students in today’s classrooms. Unfortunately, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current physical science textbooks and to revolutionize reading with interactive texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned force and motion (NGSS PS2A) content into Spanish (Aim 1); designing and developing science learning games (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content in both English and Spanish to address 9 additional NGSS standards (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive learning technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning disabilities. This Fast-Track project will produce a bilingual, digital platform to support students’ understanding of Physical Science, which will allow students to seamlessly move between different reading levels and languages, play science learning games, and receive personalized content. This project will also solicit feedback from teachers and students, develop teacher support materials, and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform physical science learning",10006915,R44GM137622,"['Address', 'Adoption', 'Books', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Drops', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Health Professional', 'Healthcare', 'Home environment', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Motion', 'Phase', 'Physics', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Rewards', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Scientist', 'Students', 'Techniques', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'adaptive learning', 'base', 'bilingualism', 'design', 'digital', 'education resources', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'physical science', 'reading ability', 'response', 'science teacher', 'scientific literacy', 'skills', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2020,231500,0.017673095398908267
"AUGS/DUKE UrogynCREST program PROJECT SUMMARY Health Services Research (HSR) and predictive analytics are rapidly growing fields and will have enormous implications for women’s health research in pelvic floor disorders (PFDs). The AUGS/DUKE Urogynecology Clinical Research Educational Scientist Training (UrogynCREST) program will prepare participants to recognize the critical role that data play in delivering high quality health care. It brings together expertise in health service and women’s health research, medical informatics and prediction modeling. This program will target Urogynecology Faculty at the Assistant Professor level who seek successful careers in health services research (HSR) and analytics. Participants will obtain skills through a combination of didactic and interactive coursework; hands-on manipulation of data through extraction, cleaning, and analysis; and project-based one on one mentoring. The UrogynCREST program will be an interactive, hands-on educational program with centralized activities organized and delivered by distance through a popular on-line learning platform called Sakai, with educational software designed to support teaching, research and collaboration. A diverse faculty with expertise in data sciences teaches courses and the advanced methodology required to perform HSR. Yearly in-person meetings at the annual American Urogynecologic Society meeting enhance networking and the development of partnerships between participants from various institutions, as well as, interactions with the mentors and other HSR in the field. The program’s strategy allows national leaders with particular skills in the field to provide their knowledge to the participants and help mentor them through development of a relevant research question and identification of an appropriate and existing database(s) to address the question. With the guidance of a dedicated statistician and analyst programmer, participants will learn and perform the necessary computer programming needed to extract, clean and analyze these data. Participants whose projects involve the development of prediction models in the form of scores, nomograms or other tools will learn how to build and validate such tools in the existing project. Each participant’s project will culminate in the completion of a submitted manuscript to a peer- reviewed journal or study proposal and publicly available tools when relevant. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and resources for invigorating data discovery and tools for investigations in HSR specifically addressing (PFDs). PROJECT NARRATIVE: The AUGS/DUKE UrogynCREST program will prepare participants to recognize the critical role that data play in delivering high quality health care for pelvic floor disorders. It will add structure to the health data science education for Assistant Professor Level Faculty in Urogynecology by bringing together expertise in health service and women’s health research, medical informatics, and prediction modeling. Overall, the program will shape future scientific leaders in Urogynecology by encouraging the development of clinical-scientists and provide the skills and mentorship for invigorating data discovery and tools for investigations in health service research specifically addressing pelvic floor disorders.",AUGS/DUKE UrogynCREST program,9918946,R25HD094667,"['Address', 'Age', 'American', 'Area', 'Caring', 'Clinical Research', 'Collaborations', 'Communities', 'Connective Tissue', 'Data', 'Data Discovery', 'Data Science', 'Databases', 'Development', 'E-learning', 'Educational process of instructing', 'Faculty', 'Fecal Incontinence', 'Fostering', 'Future', 'Goals', 'Health Services', 'Health Services Research', 'Healthcare', 'Infrastructure', 'Institution', 'Instruction', 'Investigation', 'Journals', 'Knowledge', 'Lead', 'Learning', 'Manuscripts', 'Medical Informatics', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Modernization', 'Muscle', 'Nomograms', 'Participant', 'Peer Review', 'Pelvic Floor Disorders', 'Pelvis', 'Persons', 'Play', 'Predictive Analytics', 'Process', 'Public Health', 'Research', 'Resources', 'Role', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Shapes', 'Societies', 'Software Design', 'Structure', 'Techniques', 'Testing', 'Training Programs', 'Urinary Incontinence', 'Woman', 'Women&apos', 's Health', 'base', 'career', 'clinical decision-making', 'clinical development', 'computer program', 'computer science', 'data tools', 'design', 'health care quality', 'health data', 'improved', 'injured', 'innovation', 'meetings', 'pelvic organ prolapse', 'predictive modeling', 'professor', 'programs', 'recruit', 'science education', 'skills', 'social', 'statistical and machine learning', 'tool']",NICHD,DUKE UNIVERSITY,R25,2020,153800,0.0196010517068736
"The Center for Innovation in Intensive Longitudinal Studies (CIILS) PROJECT SUMMARY Significance. The Intensive Longitudinal Behavior Network (ILHBN) provides an unprecedented opportunity to advance and shape the future landscape of health behavior science and related intervention practice. The proposed Research Coordinating Center, the Center for Innovation in Intensive Longitudinal Studies (CIILS), housed at the Pennsylvania State University (Penn State), will bring together an interdisciplinary team to synergistically support and coordinate research activities across a diverse portfolio of anticipated U01 projects to accomplish the Network’s larger goal of sustained innovation in the use of intensive longitudinal data (ILD) and associated methods in the study of health behavior change, and in informing prevention and intervention designs. Innovation. The proposed organizational structure of the ILHBN as a small-world network is motivated by our team’s collective decades of experience with multidisciplinary and multi-site collaborations, and is designed to facilitate information flow, collective decision making, and coordination of goals and effort within the ILHBN. Approach. CIILS consists of five Cores with expertise in management of multi-site projects and coordinating centers (Administrative Core); development of novel methods for analysis of ILD (Methods Core); ILD collection, harmonization, sharing, security, as well as collection of digital footprints (Data Core); ILD design, harmonization and instrumentation support (Design Core); and integration of health behavior theories, translation, and implementation of within-person health preventions/interventions (Theory Core). Key personnel with rich and complementary expertise are supported by a roster of advisory Co-Is at Penn State and distributed consultants who are leaders and innovators in their respective fields. Institutional support and contributed staff time by Penn State provide robust infrastructure, expertise, and “boots on the ground” to support the operation and coordination activities of ILHBN; and a wealth of additional resources to elevate and broaden the collective impacts of the Network. PROJECT NARRATIVE This project proposes an RCC, the Center for Innovation in Intensive Longitudinal Studies (CIILS), housed at the Pennsylvania State University, to provide a repertoire of expertise and resources to support the Intensive Longitudinal Health Behavior Network (ILHBN). Our interdisciplinary team – consisting of social scientists with expertise in design and management of intensive longitudinal studies; methodological experts who are leading figures in developing novel within-person analytic techniques; health theorists and prevention/intervention experts well-versed in the translation of health theories into within-person health intervention; cyberscience experts with expertise in collection of digital footprints, data security and data sharing issues; and administrative personnel with expertise in management and coordination of network activities – is uniquely poised to advance the collective innovations of the ILHBN by synergistically supporting and coordinating research activities across a diverse portfolio of anticipated U01 projects.",The Center for Innovation in Intensive Longitudinal Studies (CIILS),10007746,U24AA027684,"['Administrative Personnel', 'Algorithms', 'Behavior', 'Big Data', 'Collaborations', 'Collection', 'Communication', 'Communities', 'Consultations', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Security', 'Databases', 'Decision Making', 'Development', 'Devices', 'Future', 'General Population', 'Goals', 'Health', 'Health Sciences', 'Health behavior', 'Health behavior change', 'Healthcare', 'Human Resources', 'Individual', 'Infrastructure', 'Intervention', 'Lead', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Manuals', 'Measures', 'Methodology', 'Methods', 'Neurobiology', 'Pennsylvania', 'Persons', 'Positioning Attribute', 'Preventive Intervention', 'Process', 'Production', 'Progress Reports', 'Protocols documentation', 'Publications', 'Records', 'Regulation', 'Reporting', 'Research', 'Research Activity', 'Research Design', 'Resources', 'Science', 'Scientist', 'Security', 'Shapes', 'Site', 'Social Work', 'Source', 'Structure', 'Technical Expertise', 'Techniques', 'Testing', 'Time', 'Training', 'Translations', 'United States National Institutes of Health', 'Universities', 'Update', 'Visualization software', 'Workplace', 'control theory', 'data de-identification', 'data harmonization', 'data management', 'data portal', 'data privacy', 'data sharing', 'data tools', 'data visualization', 'data warehouse', 'design', 'digital', 'dynamic system', 'experience', 'human subject', 'innovation', 'instrumentation', 'member', 'multidisciplinary', 'novel', 'operation', 'organizational structure', 'preservation', 'social', 'success', 'theories', 'therapy design']",NIAAA,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,U24,2020,103799,0.003983265503648803
"An interactive, digital platform to transform biological learning Abstract: The next generation of health care professionals will need to understand the foundational principles of biology. Science textbooks play a critical role in supporting biological understanding in school, yet these books are not designed to meet the diverse learning needs of students in today’s classrooms. By their nature, science textbooks assume a one-size-fits-all approach to learning. Because of this problem, teachers spend substantial time outside of the classroom locating and adapting texts to support students who are learning English, students who read below grade level, and students with learning disabilities. The proposed Fast-Track project seeks to address the limitations of current Life Science textbooks and to revolutionize reading with adaptable texts. Transforming the learning process, SquidBooks makes texts flexible by offering digital texts at different difficulty levels with embedded language support to create a personalized reading experience, optimizing both learning and engagement. In particular, the project will support ELL students and students unable to read at their grade level. Because science textbooks are often written 3 to 5 years above the intended grade level, it is almost impossible for students with emerging and intermediate English reading skills to comprehend and learn from traditional science books. The Phase I project includes 3 aims: translating NGSS-aligned inheritance (NGSS LS3A) content into Spanish (Aim 1); designing, developing, and testing the application to function through a web browser (Aim 2); and conducting user testing with students and teachers (Aim 3). The Phase II project will have 3 aims, including creating content to address 12 additional NGSS standards in English and Spanish (Aim 4); designing, developing, and testing improved software features (Aim 5); developing educator resources and conducting user testing with students and teachers (Aim 6). Successful completion of the proposed project will create knowledge about disciplinary textual processing and adaptive reading technologies and will support students who have historically been marginalized from STEM fields, especially students with low reading achievement and ELL students. In turn, this project will enhance and diversify the STEM and health care fields. Project Narrative: Although science textbooks are a central curricular resource in K-12 education, they are often inaccessible and difficult to read; this problem is compounded when students are unable to read at their grade level, are learning English, or have diagnosed learning needs. This Fast-Track project will produce an interactive, digital textbook to support students’ understanding of Life Science by giving them the ability to seamlessly move between different reading levels and languages and to play games that enhance their understanding of scientific language and concepts. This project will also solicit feedback from teachers and students to develop teacher support materials and evaluate the efficacy of SquidBooks at improving science learning outcomes.","An interactive, digital platform to transform biological learning",9970958,R44GM133245,"['Address', 'Adoption', 'Biological', 'Biological Sciences', 'Biology', 'Books', 'Brain', 'Collaborations', 'Complex', 'Computer software', 'Diagnosis', 'Education Projects', 'English Learner', 'Feedback', 'Foundations', 'Future Teacher', 'Gametogenesis', 'Health Professional', 'Healthcare', 'Home environment', 'Individual', 'Internet', 'K-12 Education', 'Knowledge', 'Language', 'Learning', 'Learning Disabilities', 'Middle School Student', 'Modeling', 'Nature', 'Phase', 'Play', 'Process', 'Randomized', 'Reader', 'Reading', 'Research Personnel', 'Resources', 'Role', 'STEM field', 'Schools', 'Science', 'Science, Technology, Engineering and Mathematics Education', 'Spinal Cord', 'Students', 'Technology', 'Testing', 'Text', 'Textbooks', 'Time', 'Translating', 'Translations', 'Vocabulary', 'base', 'concept mapping', 'design', 'digital', 'education resources', 'egg', 'eighth grade', 'experience', 'field study', 'flexibility', 'hands-on learning', 'improved', 'learning community', 'learning engagement', 'learning outcome', 'machine learning algorithm', 'next generation', 'personalized learning', 'reading ability', 'resource guides', 'response', 'science teacher', 'scientific literacy', 'skills', 'sperm cell', 'statistics', 'teacher', 'theories', 'tool', 'usability']",NIGMS,"SQUID BOOKS, LLC",R44,2020,750000,0.011957743171417822
"WASHINGTON UNIVERSITY SCHOOL OF MEDICINE UNDIAGNOSED DISEASES NETWORK CLINICAL SITE 1.0 PROJECT SUMMARY The scientific premise of this application is that the individualized translational research process of the Undiagnosed Diseases Network (UDN) developed during Phase I is scalable and that its impact on patients, families, and disease discovery can be advanced and sustained by addition of a Clinical Site at Washington University School of Medicine (WUSM). WUSM represents a large academic medical center that is fully integrated with world-renowned basic science capabilities and demonstrated expertise in a gene first approach for patients with undiagnosed diseases. The highly collaborative clinical and biomedical research culture at WUSM promotes interactions within and across Departments, with institutional genomic, clinical, computational, and model system experts, and with colleagues regionally, nationally, and internationally. These interactions support recruitment, selection, evaluation, diagnosis discovery, and follow up of pediatric and adult patients with undiagnosed diseases through both established networks and individual referrals. Building on this infrastructure, WUSM faculty and staff will advance the success of the UDN in diagnosing and managing disease in undiagnosed patients by, first, using, refining, and improving protocols designed during Phase I of the UDN for comprehensive, timely clinical evaluations of 30 undiagnosed patients annually. Secondly, we will collect, securely store, and share standardized, high-quality clinical and laboratory data including genotyping, phenotyping, and documentation of environmental exposures and promote an integrated and collaborative community across the UDN and among laboratory and clinical investigators focused on defining the pathophysiology, cell biologic, and molecular mechanisms that cause these difficult to diagnose diseases. Thirdly, the WUSM UDN Clinical Site will propose a bioinformatics plan for leveraging institutional infrastructure and expertise to develop innovative strategies to improve discovery of pathogenic variants. Fourthly, the assessment, dissemination, outreach, and training plan will accelerate assessment and dissemination of data, protocols, consent materials, and methods, availability of educational and outreach materials for participants, clinicians, and other researchers, engagement of underrepresented minorities, and training for students, fellows, staff, and faculty in collaboration with WUSM’s Clinical and Translational Science Award infrastructure. Finally, WUSM will make a clear institutional commitment to maintain its Clinical Site, to adapt UDN Phase I practices for sustainability, to contribute to formation of a sustainable national UDN resource, and to adapt to unique needs and unexpected circumstances that may arise once Common Fund support ends in fiscal year 2022. 2.0 PROJECT NARRATIVE Undiagnosed diseases in children and adults represent frustrating and costly challenges for patients, families, physicians, and society. Building on established institutional infrastructure similar to the Undiagnosed Diseases Network (UDN), Washington University School of Medicine (WUSM) will establish a UDN Clinical Site to improve the level of diagnosis and care for patients with undiagnosed diseases, facilitate research into the etiology of undiagnosed diseases, and promote an integrated and collaborative community across multiple UDN Clinical Sites, Sequencing Cores, Model Organisms Screening Centers, and among laboratory and clinical investigators. Specifically, the WUSM UDN Clinical Site will annually recruit, select, evaluate, and follow 30 participants with disorders in any clinical specialty, adult and pediatric, provide comprehensive clinical evaluations that require <5 days and follow up, and participate in all UDN protocols, data management and sharing, and sustainability planning.",WASHINGTON UNIVERSITY SCHOOL OF MEDICINE UNDIAGNOSED DISEASES NETWORK CLINICAL SITE,10124937,U01HG010215,"['Academic Medical Centers', 'Accreditation', 'Adult', 'Animal Model', 'Basic Science', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Businesses', 'Cells', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical and Translational Science Awards', 'Collaborations', 'Communities', 'Computer Models', 'Consent', 'DNA Sequencing Facility', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Management', 'Documentation', 'Environmental Exposure', 'Etiology', 'Evaluation', 'Expert Systems', 'Faculty', 'Family', 'Family Physicians', 'Functional disorder', 'Funding', 'Genes', 'Genomics', 'Genotype', 'Geographic Locations', 'Individual', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Methods', 'Molecular', 'Monitor', 'Network-based', 'Participant', 'Pathogenicity', 'Patient Care', 'Patients', 'Phase', 'Phase I Clinical Trials', 'Phenotype', 'Process', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Review Committee', 'Secure', 'Societies', 'Standardization', 'Time', 'Training', 'Translational Research', 'Underrepresented Minority', 'Universities', 'Variant', 'Washington', 'clinical practice', 'clinical research site', 'cost', 'data dissemination', 'data management', 'data sharing', 'deep learning', 'design', 'disease diagnosis', 'exome sequencing', 'experience', 'follow-up', 'genetic variant', 'genome sequencing', 'improved', 'innovation', 'medical schools', 'medical specialties', 'network models', 'operation', 'outreach', 'recruit', 'research clinical testing', 'screening', 'sequencing platform', 'student training', 'success', 'transcriptome sequencing']",NHGRI,WASHINGTON UNIVERSITY,U01,2020,150000,0.012077823451963388
"Washington University School of Medicine Undiagnosed Diseases Network Clinical Site 1.0 PROJECT SUMMARY The scientific premise of this application is that the individualized translational research process of the Undiagnosed Diseases Network (UDN) developed during Phase I is scalable and that its impact on patients, families, and disease discovery can be advanced and sustained by addition of a Clinical Site at Washington University School of Medicine (WUSM). WUSM represents a large academic medical center that is fully integrated with world-renowned basic science capabilities and demonstrated expertise in a gene first approach for patients with undiagnosed diseases. The highly collaborative clinical and biomedical research culture at WUSM promotes interactions within and across Departments, with institutional genomic, clinical, computational, and model system experts, and with colleagues regionally, nationally, and internationally. These interactions support recruitment, selection, evaluation, diagnosis discovery, and follow up of pediatric and adult patients with undiagnosed diseases through both established networks and individual referrals. Building on this infrastructure, WUSM faculty and staff will advance the success of the UDN in diagnosing and managing disease in undiagnosed patients by, first, using, refining, and improving protocols designed during Phase I of the UDN for comprehensive, timely clinical evaluations of 30 undiagnosed patients annually. Secondly, we will collect, securely store, and share standardized, high-quality clinical and laboratory data including genotyping, phenotyping, and documentation of environmental exposures and promote an integrated and collaborative community across the UDN and among laboratory and clinical investigators focused on defining the pathophysiology, cell biologic, and molecular mechanisms that cause these difficult to diagnose diseases. Thirdly, the WUSM UDN Clinical Site will propose a bioinformatics plan for leveraging institutional infrastructure and expertise to develop innovative strategies to improve discovery of pathogenic variants. Fourthly, the assessment, dissemination, outreach, and training plan will accelerate assessment and dissemination of data, protocols, consent materials, and methods, availability of educational and outreach materials for participants, clinicians, and other researchers, engagement of underrepresented minorities, and training for students, fellows, staff, and faculty in collaboration with WUSM’s Clinical and Translational Science Award infrastructure. Finally, WUSM will make a clear institutional commitment to maintain its Clinical Site, to adapt UDN Phase I practices for sustainability, to contribute to formation of a sustainable national UDN resource, and to adapt to unique needs and unexpected circumstances that may arise once Common Fund support ends in fiscal year 2022. 2.0 PROJECT NARRATIVE Undiagnosed diseases in children and adults represent frustrating and costly challenges for patients, families, physicians, and society. Building on established institutional infrastructure similar to the Undiagnosed Diseases Network (UDN), Washington University School of Medicine (WUSM) will establish a UDN Clinical Site to improve the level of diagnosis and care for patients with undiagnosed diseases, facilitate research into the etiology of undiagnosed diseases, and promote an integrated and collaborative community across multiple UDN Clinical Sites, Sequencing Cores, Model Organisms Screening Centers, and among laboratory and clinical investigators. Specifically, the WUSM UDN Clinical Site will annually recruit, select, evaluate, and follow 30 participants with disorders in any clinical specialty, adult and pediatric, provide comprehensive clinical evaluations that require <5 days and follow up, and participate in all UDN protocols, data management and sharing, and sustainability planning.",Washington University School of Medicine Undiagnosed Diseases Network Clinical Site,9977220,U01HG010215,"['Academic Medical Centers', 'Accreditation', 'Adult', 'Animal Model', 'Basic Science', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Businesses', 'Cells', 'Child', 'Childhood', 'Classification', 'Clinical', 'Clinical Investigator', 'Clinical Research', 'Clinical Sciences', 'Clinical and Translational Science Awards', 'Collaborations', 'Communities', 'Computer Models', 'Consent', 'DNA Sequencing Facility', 'Data', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Management', 'Documentation', 'Environmental Exposure', 'Etiology', 'Evaluation', 'Expert Systems', 'Faculty', 'Family', 'Family Physicians', 'Functional disorder', 'Funding', 'Genes', 'Genomics', 'Genotype', 'Geographic Locations', 'Individual', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Methods', 'Molecular', 'Monitor', 'Network-based', 'Participant', 'Pathogenicity', 'Patient Care', 'Patients', 'Phase', 'Phase I Clinical Trials', 'Phenotype', 'Process', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Review Committee', 'Secure', 'Societies', 'Standardization', 'Time', 'Training', 'Translational Research', 'Underrepresented Minority', 'Universities', 'Variant', 'Washington', 'clinical practice', 'clinical research site', 'cost', 'data dissemination', 'data management', 'data sharing', 'deep learning', 'design', 'disease diagnosis', 'exome sequencing', 'experience', 'follow-up', 'genetic variant', 'genome sequencing', 'improved', 'innovation', 'medical schools', 'medical specialties', 'network models', 'operation', 'outreach', 'recruit', 'research clinical testing', 'screening', 'sequencing platform', 'student training', 'success', 'transcriptome sequencing']",NHGRI,WASHINGTON UNIVERSITY,U01,2020,550000,0.012077823451963388
"Estimating Mediation Effects in Prevention Studies The purpose of this competing continuation grant proposal is to develop, evaluate and apply  methodological and statistical procedures to investigate how prevention programs change outcome  variables. These mediation analyses assess the link between program effects on the constructs targeted  by a prevention program and effects on the outcome. As noted by many researchers and federal  agencies, mediation analyses identify the most effective program components and increase  understanding of the underlying mechanisms leading to changing outcome variables. Information from  mediation analysis can make interventions more powerful, more efficient, and shorter. The P. I. of this grant received a one-year NIDA small grant and four multi-year grants to develop and evaluate mediation  analysis in prevention research. This work led to many publications and innovations. The proposed  five-year continuation focuses on the further development and refinement of exciting new mediation  analysis statistical developments. Four statistical topics represent next steps in this research and include  analytical and simulation research as well as applications to etiological and prevention data. The work expands on our development of causal mediation and Bayesian mediation methods that hold great promise for mediation analysis. In Study 1, practical causal mediation and Bayesian mediation analyses  for research designs are developed and evaluated. This approach will clarify methods and develop  approaches for dealing with violation of testable and untestable assumptions. Study 2 investigates  important measurement issues for the investigation of mediation. This work will focus on methods to identify critical facets of mediating variables, approaches to understanding whether mediators and  outcomes are redundant, and develop methods for studies with big data. Study 3 continues the development and evaluation of new longitudinal mediation methods for ecological momentary assessment data and other studies with massive data collection. These new methods promise to more accurately model change over time for both individuals and groups of individuals. Study 4 develops methods to  uncover subgroups in mediation analysis including causal mediation methods, multilevel models, and new  approaches based on residuals for identifying individuals for whom mediating processes differ in  effectiveness from other individuals. For each study, we will investigate unique issues with mediation analysis of prevention data including methods for small N and also massive data collection (big data), the RcErLitEicVaANl rCoEle(Soeef imnsetruacstiounrse):ment for mediating mechanisms, and the application of the growing literature on  causal methods and Bayesian methods. Study 5 applies new statistical methods to data from several NIH  The project further develops a method, statistical mediation analysis, that extracts more information from  funded prevention studies providing important feedback about the usefulness of the methods. Study 6  research. Mediation analysis explains how and why prevention and treatments are successful. Mediation  disseminates new information about mediation analysis through our website and other media, by  analysis improves prevention and treatment so that their effects are greater and even cost less. communication with researchers, and publications from the project. n/a",Estimating Mediation Effects in Prevention Studies,9851457,R37DA009757,"['Address', 'Alcohol or Other Drugs use', 'Applications Grants', 'Bayesian Method', 'Behavioral Mechanisms', 'Big Data', 'Biological Models', 'Communication', 'Complex', 'Consultations', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Ecological momentary assessment', 'Educational workshop', 'Effectiveness', 'Etiology', 'Evaluation', 'Feedback', 'Funding', 'Grant', 'Individual', 'Individual Differences', 'Intervention', 'Investigation', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Outcome', 'Persons', 'Prevention', 'Prevention Research', 'Prevention program', 'Principal Investigator', 'Procedures', 'Process', 'Psychometrics', 'Publications', 'Randomized', 'Recommendation', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Residual state', 'Statistical Data Interpretation', 'Statistical Methods', 'Subgroup', 'Testing', 'Time', 'Translating', 'United States National Institutes of Health', 'Work', 'base', 'computer program', 'cost', 'data space', 'design', 'dynamic system', 'improved', 'innovation', 'interest', 'longitudinal design', 'model design', 'multilevel analysis', 'novel strategies', 'programs', 'simulation', 'successful intervention', 'theories', 'therapy design', 'tool', 'treatment research', 'web site']",NIDA,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R37,2020,382893,-0.004468667138996497
"Pipelines into Quantitative Aging Research Project Summary It is well documented that a diverse workforce has the potential to reduce racial and ethnic disparities, which have strong effects in aging populations1-3. As the percentage of racial and ethnic minorities in the U.S. population increases, including among the aged population, the public health workforce should reflect this diversity1,4,5. With an increase in undergraduate public health majors across the country6,7, due in part to heightened excitement and opportunities in data science and quantitative big data analysis, and with breakthroughs in the science of aging on the horizon, this is an opportune moment to develop strong pipeline programs for underrepresented minority (URM) undergraduates. We will target URM undergraduates who have quantitative and computational interests and expose them to opportunities for graduate study and research careers, and the possibilities and excitement of marrying their quantitative interests with substantive research in aging. Introducing undergraduates, who are more diverse in public health majors than other majors7, and than graduate students6, to careers in public health, holds much promise for increasing the diversity of graduate students and faculty in the field, which has increased very little in the past 20 years6. This holds for the MSTEM subfields of public health, such as Biostatistics, Epidemiology and Data Science, as well. Motivated by these factors, and in response to NIA Funding Opportunity (PAR-17-290), “MSTEM: Advancing Diversity in Aging Research through Undergraduate Education (R25),” we propose an intensive, six-week summer program for 12 undergraduates from underrepresented backgrounds with interests in Biostatistics, Epidemiology, Data Science and other quantitative methods to learn about the applications of these methods in aging research. The summer program includes formal instruction, a broad lecture series, mentored research projects, oral research presentation at an annual symposium, career and professional development sessions, site visits to labs and other research settings, group and informal mentoring, social activities and network building, and training in responsible conduct of research. To reinforce the intensive summer experience, we will continue to offer group and individual mentoring and research experiences into the following academic years. Additionally, we will offer a select group of summer program participants the opportunity to return to NYU during the January term for an extended research experience and a quantitative course. With the guidance of a professional evaluator and internal and external advisory committees, we will evaluate all aspects of our program and review results in real-time to enable constant adjustment and improvement. Our proposal addresses three critical needs to strengthen and galvanize the research enterprise in the field of aging: increased engagement of MSTEM experts, increased engagement of URM researchers, and increased attention to disparities. We believe that our intensive and long-term programmatic components will support the entry of talented URM students into successful careers in MSTEM research in aging. Project Narrative The goal of this R25 program is to increase the participation of underrepresented minority groups in the fields of Biostatistics and quantitative Public Health, with a collaborative focus on the diseases and processes of aging. The program includes an intensive six-week summer program for 12 students, with formal and informal instruction, mentored research, and extensive professional development activities, with a culminating symposium. For lasting impact, follow-up mentoring, continuing research and professional development will occur on a regular basis, both via webcast platforms and return, in-person visits.",Pipelines into Quantitative Aging Research,10024768,R25AG067931,"['Academia', 'Address', 'Advisory Committees', 'Aging', 'Alzheimer&apos', 's disease model', 'Attention', 'Autopsy', 'Big Data', 'Biometry', 'Career Choice', 'Community Networks', 'Data Analyses', 'Data Science', 'Development', 'Disease', 'Diverse Workforce', 'Education', 'Epidemiology', 'Faculty', 'Funding Opportunities', 'GRE Preparation', 'Goals', 'Health Personnel', 'Individual', 'Instruction', 'Joints', 'Journals', 'Learning', 'Life', 'Machine Learning', 'Medicine', 'Mentors', 'Methods', 'Minority Groups', 'Oral', 'Outcome', 'Participant', 'Persons', 'Population', 'Process', 'Program Reviews', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Schools', 'Science', 'Series', 'Site Visit', 'Statistical Computing', 'Students', 'Talents', 'Time', 'Training', 'Underrepresented Minority', 'Visit', 'aging population', 'biomarker selection', 'career', 'cohort', 'design', 'epidemiologic data', 'epidemiology study', 'ethnic minority population', 'experience', 'faculty mentor', 'follow-up', 'graduate student', 'informal learning', 'interest', 'lectures', 'meetings', 'minority undergraduate', 'posters', 'programs', 'racial and ethnic disparities', 'racial minority', 'response', 'responsible research conduct', 'social', 'student mentoring', 'summer program', 'symposium', 'undergraduate education', 'undergraduate student', 'underrepresented minority student']",NIA,NEW YORK UNIVERSITY,R25,2020,367149,-0.004894824118371253
"Big Flow Cytometry Data: Data Standards, Integration and Analysis PROJECT SUMMARY Flow cytometry is a single-cell measurement technology that is data-rich and plays a critical role in basic research and clinical diagnostics. The volume and dimensionality of data sets currently produced with modern instrumentation is orders of magnitude greater than in the past. Automated analysis methods in the field have made great progress in the past five years. The tools are available to perform automated cell population identification, but the infrastructure, methods and data standards do not yet exist to integrate and compare non-standardized big flow cytometry data sets available in public repositories. This proposal will develop the data standards, software infrastructure and computational methods to enable researchers to leverage the large amount of public cytometry data in order to integrate, re-analyze, and draw novel biological insights from these data sets. The impact of this project will be to provide researchers with tools that can be used to bridge the gap between inference from isolated single experiments or studies, to insights drawn from large data sets from cross-study analysis and multi-center trials. PROJECT NARRATIVE The aims of this project are to develop standards, software and methods for integrating and analyzing big and diverse flow cytometry data sets. The project will enable users of cytometry to directly compare diverse and non-standardized cytometry data to each other and make biological inferences about them. The domain of application spans all disease areas where cytometry is utilized.","Big Flow Cytometry Data: Data Standards, Integration and Analysis",9969443,R01GM118417,"['Address', 'Adoption', 'Advisory Committees', 'Archives', 'Area', 'Basic Science', 'Bioconductor', 'Biological', 'Biological Assay', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Analyses', 'Data Analytics', 'Data Files', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Environment', 'Flow Cytometry', 'Foundations', 'Genes', 'Goals', 'Heterogeneity', 'Immune System Diseases', 'Immunologic Monitoring', 'Industry', 'Informatics', 'Infrastructure', 'International', 'Knock-out', 'Knowledge', 'Manuals', 'Measurable', 'Measurement', 'Measures', 'Meta-Analysis', 'Metadata', 'Methods', 'Modernization', 'Mouse Strains', 'Multicenter Trials', 'Mus', 'Output', 'Phenotype', 'Play', 'Population', 'Procedures', 'Protocols documentation', 'Reagent', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Societies', 'Software Tools', 'Standardization', 'Technology', 'Testing', 'Validation', 'Work', 'automated analysis', 'base', 'bioinformatics tool', 'body system', 'cancer diagnosis', 'clinical diagnostics', 'community based evaluation', 'computerized tools', 'data exchange', 'data integration', 'data standards', 'data submission', 'data warehouse', 'experimental study', 'human disease', 'insight', 'instrument', 'instrumentation', 'large datasets', 'mammalian genome', 'multidimensional data', 'novel', 'operation', 'phenotypic data', 'public repository', 'repository', 'research and development', 'software development', 'software infrastructure', 'statistics', 'supervised learning', 'tool', 'vaccine development']",NIGMS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2020,158388,-0.002244982904308015
"Computational Methods for Enhancing Privacy in Biomedical Data Sharing Project Summary Data sharing is essential to modern biomedical data science. Access to a large amount of genomic and clinical data can help us better understand human genetics and its impact on health and disease. However, the sensitive nature of biomedical information presents a key bottleneck in data sharing and collection efforts, limiting the utility of these data for science. The goal of this project is to leverage cutting-edge advances in cryptography and information theory to develop innovative computational frameworks for privacy-preserving sharing and analysis of biomedical data. We will draw upon our recent success in developing secure pipelines for collaborative biomedical analyses to address the imminent need to share sensitive data securely and at scale.  Practical adoption of existing privacy-preserving techniques in biomedicine has thus far been largely limited due to two major pitfalls, which this project overcomes with novel technical advances. First, emerging cryptographic data sharing frameworks, which promise to enable collaborative analysis pipelines that securely combine data across multiple institutions with theoretical privacy guarantees, are too costly to support complex and large-scale computations required in biomedical analyses. In this project, we will build upon recent advances in cryptography (e.g., secure distributed computation, pseudorandom correlation, zero-knowledge proofs) to significantly enhance the scalability and security of cryptographic biomedical data sharing pipelines. Second, existing approaches that locally transform data to protect sensitive information before sharing (e.g. de-identification techniques) either offer insufficient levels of protection or require excessive perturbation in order to ensure privacy. We will draw upon recent tools from information theory to develop effective local privacy protection methods that achieve superior utility-privacy tradeoffs on a range of biomedical data including genomes, transcriptomes, and medical images by directly exploiting the latent correlation structure of the data.  To promote the use of our privacy techniques, we will create production-grade software of our tools and publicly release them. We will also actively participate in international standard-setting organizations in genomics, e.g. GA4GH and ICDA, to incorporate our insights into community guidelines for biomedical privacy. Successful completion of these aims will result in computational methods and software tools that open the door to secure sharing and analysis of massive sets of sensitive genomic and clinical data. Our long-term goal is to broadly enable data sharing and collaboration efforts in biomedicine, thus empowering researchers to better understand the molecular basis of human health and to drive translation of new biological insights to the clinic. Project Narrative Rapidly-growing volume of biomedical datasets around the world promises to enable unprecedented insights into human health and disease. However, increasing concerns for individual privacy severely limited the extent of data sharing in the field. This project draws upon cutting-edge tools from cryptography and information theory to develop effective privacy- preserving methods for collecting, sharing, and analyzing sensitive biomedical data to empower advances in genomics and medicine.",Computational Methods for Enhancing Privacy in Biomedical Data Sharing,10017554,DP5OD029574,"['Address', 'Adoption', 'Biological', 'Biology', 'Biomedical Research', 'Brain', 'Clinic', 'Clinical Data', 'Code', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Complex Analysis', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Collection', 'Data Science', 'Data Set', 'Disease', 'Electronic Health Record', 'Engineering', 'Enhancement Technology', 'Ensure', 'Foundations', 'Genome', 'Genomic medicine', 'Genomics', 'Goals', 'Guidelines', 'Health', 'Human', 'Human Genetics', 'Image', 'Individual', 'Information Theory', 'Institutes', 'Institution', 'Interdisciplinary Study', 'International', 'Knowledge', 'Letters', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mainstreaming', 'Mathematics', 'Medical Genetics', 'Medical Imaging', 'Mentorship', 'Methods', 'Modernization', 'Molecular', 'Nature', 'Pattern', 'Pharmacology', 'Policies', 'Polynomial Models', 'Preservation Technique', 'Privacy', 'Privatization', 'Production', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Science', 'Secure', 'Security', 'Software Tools', 'Structure', 'Techniques', 'Technology', 'Translations', 'Vision', 'Work', 'analysis pipeline', 'base', 'biomedical data science', 'computer framework', 'computing resources', 'cost', 'cryptography', 'data sharing', 'design', 'empowered', 'experience', 'experimental study', 'genetic analysis', 'genome wide association study', 'genomic data', 'infancy', 'innovation', 'insight', 'novel', 'privacy preservation', 'privacy protection', 'software development', 'statistics', 'structured data', 'success', 'task analysis', 'tool', 'transcriptome', 'transcriptomics', 'web server']",OD,"BROAD INSTITUTE, INC.",DP5,2020,392799,-0.023827554548478187
"Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0) OVERALL: ABSTRACT  The scope of regenerative medicine encompasses the repair, regeneration, and replacement of defective, injured, and diseased tissues and organs. The success of regenerative therapies is dependent, at least in part, on a favorable microenvironment in which the regenerative processes occur. Technological innovations and a deepened mechanistic understanding of how these microenvironmental signals influence tissue regeneration has drawn attention to the critical importance of the clinical field with foundations in the application of physical, thermal, and electrical stimuli to promote functional restoration—rehabilitation. We propose that the fields of regenerative medicine and rehabilitative science are inextricably intertwined, an intersection of disciplines that we and others have termed Regenerative Rehabilitation. To realize the full potential of Regenerative Rehabilitation, there is a need for formalized mechanisms that promote the interaction of basic scientists with rehabilitation specialists. During the initial funding cycle, the Alliance for Regenerative Rehabilitation Research & Training (AR3T) built a national network of investigators and programs that has helped to expand scientific knowledge, expertise and methodologies across the domains of regenerative medicine and rehabilitation. This proposal seeks funding for AR3T 2.0, in which we will build on successes achieved and lessons learned over the initial period of support with the goal of being even more responsive to the needs of the greater community. Six specific aims define a framework upon which we will achieve our goals. AR3T will provide education and drive the science underlying Regenerative Rehabilitation by: 1) Providing didactic programs that expose rehabilitation researchers to cutting-edge investigations and state-of-the-art technologies in the field of regenerative medicine (Didactic Aim); 2) Cultivating collaborative opportunities between renowned investigators in the fields of regenerative medicine and rehabilitation (Collaborations Aim); 3) Coordinating a pilot funding program to support novel lines of Regenerative Rehabilitation research (Pilot Funding Aim); 4) Developing and validating technologies to advance the measurement and use of the regenerative rehabilitation programs (Technology Aim); 5) Promoting our center’s expertise to a broad community of trainees, investigators, and clinicians (Promotion Aim); 6) Carefully monitoring and evaluating the effectiveness of our program will ensure that we are successful in achieving our goals (Quality Control Aim). Administrative note: In the preparation of this proposal, we made every effort to present a comprehensive and detailed plan for achieving our goals while minimizing redundancy. Therefore, in multiple places, we refer the reader to specific components of the application, rather than repeating text. We appreciate the time and effort the reviewers devote to the evaluation of the proposals.  Sincerely, Fabrisia, Tom and Mike PROJECT NARRATIVE  Regenerative Rehabilitation is the integration of principles and approaches across the fields of rehabilitation science and regenerative medicine. The integration of these two fields will increase the efficiency of interventions designed to optimize physical functioning to the benefit of a wide range of individuals with disabilities. The Alliance for Regenerative Rehabilitation Research & Training (AR3T) 2.0 will build on the momentum gained over the first cycle of funding with the goal of continuing to illuminate and seize opportunities to expand scientific knowledge, expertise and methodologies in the domain of Regenerative Rehabilitation.",Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0),9967689,P2CHD086843,"['Accountability', 'Activities of Daily Living', 'Age', 'Attention', 'Awareness', 'Basic Science', 'Biocompatible Materials', 'Clinical', 'Collaborations', 'Communities', 'Congenital Abnormality', 'Country', 'Data Analyses', 'Development', 'Disabled Persons', 'Discipline', 'Disease', 'Documentation', 'Education', 'Effectiveness', 'Ensure', 'Evaluation', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'In Vitro', 'Incubators', 'Individual', 'Injury', 'Intervention', 'Investigation', 'Journals', 'Knowledge', 'Laboratories', 'Machine Learning', 'Marketing', 'Measurement', 'Mechanics', 'Mentors', 'Methodology', 'Methods', 'Mission', 'Monitor', 'Natural regeneration', 'Organ', 'Performance', 'Physical Function', 'Pre-Clinical Model', 'Preparation', 'Process', 'Quality Control', 'Reader', 'Regenerative Medicine', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Science', 'Scientist', 'Series', 'Signal Transduction', 'Specialist', 'Stimulus', 'Structure', 'Systems Analysis', 'Technology', 'Text', 'Time', 'Tissues', 'Training', 'Trauma', 'Treatment Efficacy', 'Update', 'career', 'effectiveness evaluation', 'falls', 'functional restoration', 'gait examination', 'healing', 'injured', 'innovation', 'interest', 'investigator training', 'multidisciplinary', 'new technology', 'novel', 'novel strategies', 'pre-clinical', 'programs', 'regenerative', 'regenerative therapy', 'rehabilitation research', 'rehabilitation science', 'repaired', 'response', 'sabbatical', 'social media', 'success', 'symposium', 'technological innovation', 'therapy design', 'tissue regeneration', 'webinar']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P2C,2020,1059198,-0.013086892849700372
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. Its software collection supports exploration and quantitative analyses of its own and other databases by providing a wide range of well-documented, rigorously tested open-source programs that can be run on any platform. PhysioNet's team of researchers drive the creation and enrichment of: i) Data collections that provide comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC (Medical Information Mart for Intensive Care) Databases of critical care patients; ii) Analytic methods for quantification of information encoded in physiologic signals relevant to risk stratification and health status assessment; iii) User interfaces, reference materials and services that add value and improve access to the resource’s data and software; and iv) unique annual Challenges focusing on high priority clinical problems, such as early prediction of sepsis, detection and quantification of sleep apnea syndromes from a single lead electrocardiogram (ECG), false alarm detection in the intensive care unit (ICU), continuous fetal ECG monitoring, and paroxysmal atrial fibrillation detection and prediction. PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are otherwise inaccessible. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world-wide, growing community of researchers, clinicians, educators, trainees, and medical instrument and software developers retrieve about 380 GB of data per day and publish a yearly average of nearly 300 new scholarly articles. Over the next five years we aim to: 1) Enhance PhysioNet’s impact with new data and technology; 2) Develop new methods to quantify dynamical information in physiologic signals relevant for health status assessment, and for acute and chronic risk stratification, and 3) Harness the research community through our international Challenges that address key clinical problems and a new data annotation initiative. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,10050843,R01EB030362,"['Acute', 'Address', 'Adult', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Biological Markers', 'Biomedical Research', 'Cardiovascular system', 'Chronic', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computerized Medical Record', 'Coupling', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Doctor of Philosophy', 'Documentation', 'Educational Background', 'Electrocardiogram', 'Entropy', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Growth', 'Health Status', 'Heart failure', 'Image', 'Improve Access', 'Intensive Care', 'Intensive Care Units', 'International', 'Label', 'Lead', 'Legal patent', 'Life', 'Link', 'Machine Learning', 'Measures', 'Medical', 'Methods', 'Monitor', 'Neonatal', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patient Care', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Risk stratification', 'Role', 'Running', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Stroke', 'Students', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'United States National Institutes of Health', 'Visualization', 'Visualization software', 'Work', 'analytical method', 'base', 'clinical care', 'cloud based', 'data archive', 'data exploration', 'data resource', 'fetal', 'graphical user interface', 'high school', 'innovation', 'instrument', 'instrumentation', 'interest', 'open source', 'opioid use', 'programs', 'repository', 'response', 'time interval', 'tool']",NIBIB,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2020,759918,-0.023005209950580804
"Privacy-preserving genomic medicine at scale 1 Project Summary  2  3 High-throughput sequencing, biomedical imaging, and electronic health record technologies are 4 generating health-related datasets of unprecedented scale. Integrative analysis of these  5 resources promises to reveal new biology and drive personal and precision medicine. Yet, the  6 sensitive nature of these data often requires that they be kept in isolated silos, limiting their 7 usefulness to science. The goal of this project is to develop innovative privacy-preserving  8 algorithms to enable data sharing and drive genomic medicine. Crucially, we will draw upon our  9 past success in secure genome analysis and algorithmic expertise in computational biology to 10 address the imminent need to perform complex integrative analyses securely and at scale. 11 Current privacy-preserving tools are prohibitively too costly to perform the complex 12 calculations required in genomic analysis. We previously leveraged the highly structured nature 13 of biological data and novel optimization strategies to implement efficient pipelines for secure 14 genome-wide association studies (GWAS) and drug interaction predictions which scaled to 15 millions of samples. In this project, we will further exploit the unique properties of biomedical data 16 to: (i) develop secure integrative analysis methods for genomic medicine; (ii) develop an easy-to- 17 use programming environment with advanced automated optimizations to facilitate the adoption 18 of privacy-preserving analyses; and (iii) promote the use of our privacy techniques to gain novel 19 biological insights through large-scale collaborative genetic studies of multi-ethnic cohorts. 20 With co-I’s Amarasinghe (MIT) and Cho (Broad Institute), we aim to apply these tools to 21 realize the first multi-institution, multi-national secure genetic studies with our partners at the 22 Swiss Personalized Health Network, UK Biobank, Finnish FinnGen, All of Us, NIH NCBI, Broad 23 and Barcelona Supercomputing Center (Letters of Support). We will also use our privacy- 24 preserving approaches to study genomic origins of polygenic traits for disease as well as 25 neuroimaging and other clinical phenotypes. We will continue to actively integrate our methods 26 into community standards (MPEG-G, GA4GH). 27 Successful completion of these aims will result in computational methods and open-source, 28 easy-to-use, production-grade implementations that open the door to secure integration and 29 analysis of massive sets of sensitive genomic and clinical data. With input from our collaborations, 30 we will build these tools and apply them to better understand the molecular causes of human 31 health and its translation to the clinic. Project Narrative Combining genomic and health-related data from millions of patients will empower the development of clinically relevant measures of human health and disease risks. However, this task requires securely sharing sensitive data at an immense scale beyond what existing cryptographic platforms can achieve. Here we develop novel computational methods to enable biomedical data integration, analysis, and interpretation in a privacy-preserving and highly scalable manner.",Privacy-preserving genomic medicine at scale,9998648,R01HG010959,"['Address', 'Adoption', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biological', 'Biology', 'Clinic', 'Clinical Data', 'Collaborations', 'Communities', 'Complex', 'Complex Analysis', 'Computational Biology', 'Computer software', 'Computing Methodologies', 'Consumption', 'Data', 'Data Analyses', 'Data Pooling', 'Data Security', 'Data Set', 'Disease', 'Drug Interactions', 'Electronic Health Record', 'Engineering', 'Environment', 'Genetic', 'Genetic study', 'Genome', 'Genomic medicine', 'Genomics', 'Goals', 'Health', 'High-Throughput Nucleotide Sequencing', 'Human', 'Individual', 'Institutes', 'Institution', 'Knowledge', 'Letters', 'Machine Learning', 'Mainstreaming', 'Measures', 'Medical Imaging', 'Medical Records', 'Medicine', 'Methods', 'Modernization', 'Molecular', 'Nature', 'Patients', 'Performance', 'Pharmacology', 'Polygenic Traits', 'Privacy', 'Process', 'Production', 'Property', 'Research Personnel', 'Resources', 'Risk', 'Sampling', 'Science', 'Secure', 'Security', 'Software Engineering', 'Software Tools', 'Standardization', 'Stream', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Time', 'Translations', 'United States National Institutes of Health', 'Work', 'analysis pipeline', 'base', 'biobank', 'bioimaging', 'clinical development', 'clinical phenotype', 'clinically relevant', 'cohort', 'computer framework', 'cost', 'cryptography', 'data analysis pipeline', 'data integration', 'data sharing', 'data warehouse', 'disorder risk', 'epidemiology study', 'experimental study', 'genome analysis', 'genome wide association study', 'genomic data', 'health data', 'innovation', 'insight', 'monomethoxypolyethylene glycol', 'neuroimaging', 'novel', 'open source', 'polygenic risk score', 'precision medicine', 'preservation', 'privacy preservation', 'statistics', 'success', 'task analysis', 'theories', 'tool']",NHGRI,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2020,636185,-0.010143437406978316
"Patient Oriented Research and Mentorship and Training in Functional Neuroimaging of Obsessive-Compulsive Disorder ABSTRACT  This K24 Mid-Career Investigator Career Development Award seeks support for training and mentorship for Christopher Pittenger, MD, Ph.D., a well-established, tenured Associate Professor in Psychiatry at Yale University, Director of the Yale OCD Research Clinic, and Assistant Chair for Translational Research in the Department of Psychiatry. Dr. Pittenger leads a robust patient-oriented research (POR) research program, which is integrated with his basic/translational lab-based research and has produced important new insights into the neurobiological underpinnings and novel treatment avenues for obsessive-compulsive disorder (OCD) and Tourette syndrome (TS). Dr. Pittenger has a long-standing commitment to mentorship; most notably, he is Co-Director of the Neuroscience Research Training Program (NRTP), the research track within the Yale psychiatry residency.  The training plan supported by this grant will allow Dr. Pittenger to increase his skills in quantitative analysis, with a focus on advanced statistical methods and on the design and analysis of fMRI studies. These are areas in which he already has active research with expert collaborators; the aim of the proposed training plan is to enhance his own proficiency to make him a more effective collaborator and mentor in these important domains. Additional training is focused on his own abilities as a mentor and leader, with the goal of increasing his efficacy in the management of his own research groups and in effective and individualized mentorship. These training activities will take place in the context of two NIMH- funded research studies. The first, R01 MH116038, is a recently funded grant on which Dr. Pittenger is co-PI with his close collaborator Alan Anticevic and deploys cutting-edge imaging technology and data analysis approaches to examine brain network connectivity parallels and predictors of therapeutic response to pharmacotherapy in OCD. The second, R01 MH100068, is a grant with collaborator Michelle Hampson that is developing real-time fMRI neurofeedback as a probe and potential treatment for OCD, with promising early results. These two exciting projects provide a fruitful vehicle for the proposed training in statistics and neuroimaging.  Dr. Pittenger will devote substantial time to mentoring under this award. One major focus will be the NRTP; the plan is for him to take over as Director of this program over the next few years, and to take the lead in the next resubmission of our T32 grant in 2022. Support of this increased mentorship effort is a second major motivation for the current application. Dr. Pittenger will also provide mentorship to students, postdocs, and junior faculty in his own research program and throughout the Department of Psychiatry  Together, these integrated plans for training, research, and mentorship will support a well-established mid-career investigator whose robust research program is producing important insights into the neurobiology and treatment of OCD and TS, and whose dedicated mentorship efforts are helping to establish a new generation of translationally grounded patient-oriented researchers in psychiatric neuroscience. NARRATIVE This K24 Mid-Career Investigator Career Development Award in Patient-Oriented Research seeks support for Christopher Pittenger, a tenured Associate Professor of Psychiatry at Yale University and Director of the Yale OCD Research Clinic; training and mentorship activities supported by this award will take place in the context of two NIMH-funded projects, R01 MH100068 and R01 MH116038. The Award will support Dr. Pittenger in a robust training plan aimed at increasing his skills in statistics and in the design and analysis of fMRI experiments, with the goal of making him a more effective collaborator and mentor in these domains. The robust Mentorship Plan supports a range of trainees, from high school students through junior faculty, with a particular focus on the research track with the Yale Psychiatry Residency, of which Dr. Pittenger will become the Director in the coming years.",Patient Oriented Research and Mentorship and Training in Functional Neuroimaging of Obsessive-Compulsive Disorder,9871479,K24MH121571,"['Achievement', 'Adult', 'Area', 'Award', 'Brain', 'Clinic', 'Clinical', 'Code', 'Collaborations', 'Data', 'Data Analyses', 'Department chair', 'Disease', 'Dissociation', 'Doctor of Philosophy', 'Double-Blind Method', 'Drug Exposure', 'Faculty', 'Feedback', 'Fluoxetine', 'Fostering', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Funding', 'Future', 'Generations', 'Gilles de la Tourette syndrome', 'Goals', 'Grant', 'Health Sciences', 'High School Student', 'Human', 'Image', 'Imaging technology', 'Individual', 'Infrastructure', 'K-Series Research Career Programs', 'Lead', 'Leadership', 'Linux', 'Machine Learning', 'Mentors', 'Mentorship', 'Motivation', 'National Institute of Mental Health', 'Neurobiology', 'Neurosciences', 'Neurosciences Research', 'Obsessive-Compulsive Disorder', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Physicians', 'Positioning Attribute', 'Postdoctoral Fellow', 'Preceptorship', 'Prediction of Response to Therapy', 'Protocols documentation', 'Psychiatry', 'Publishing', 'Pythons', 'Research', 'Research Ethics', 'Research Personnel', 'Research Project Grants', 'Residencies', 'Rest', 'Scanning', 'Scientist', 'Services', 'Statistical Methods', 'Structure', 'Students', 'Time', 'Training', 'Training Activity', 'Training Programs', 'Training Support', 'Translational Research', 'Universities', 'Work', 'base', 'career', 'career development', 'connectome', 'design', 'disorder control', 'experimental study', 'graph theory', 'innovation', 'insight', 'mid-career faculty', 'neurofeedback', 'neuroimaging', 'next generation', 'novel', 'patient oriented', 'patient oriented research', 'predicting response', 'programs', 'research study', 'simulation', 'skills', 'statistics', 'success', 'symptomatic improvement', 'symptomatology', 'teacher mentor']",NIMH,YALE UNIVERSITY,K24,2020,181291,0.012894951665017291
"Overall: Eunice Kennedy Shriver Intellectual and Developmental Disabilities Research Center at Vanderbilt Founded in 1965 as one of the original Intellectual and Developmental Disorders Research Centers (IDDRC), the Vanderbilt Kennedy Center (VKC) IDDRC serves as the central nexus across Vanderbilt for interdisciplinary research, communication, and training in intellectual and developmental disabilities (IDD). The VKC IDDRC serves as a trans-institutional institute that brings together over 200 faculty from 38 departments in 10 schools at Vanderbilt. The VKC’s mission to facilitate discoveries that inform best practices to improve the lives of people with IDD and their families. This mission is met by leveraging our outstanding institutional resources and support, partnering with disability communities, and capitalizing on synergistic interactions across the VKC’s federally-designated centers: the VKC IDDRC, a University Center of Excellence in Developmental Disabilities and a Leadership Education in Neurodevelopmental Disabilities program. The IDDRC as the centerpiece of the VKC is the foundational organizing structure that creates a “Center culture” wherein research and discovery permeates the VKC’s broader training and service activities, thus enhancing the translational research goals of the IDDRC. Demonstrable IDDRC success includes 976 investigator- authored publications and robust NIH funding to Vanderbilt to support IDD-related research ($52.6M in FY20). Harnessing and leveraging this trans-institutional strength to focus on unique challenges in IDD, the overarching goal of the next phase of the IDDRC is to develop precision care for IDD by providing infrastructure and scientific leadership to enable rapid translation of basic discoveries into high- impact IDD interventions and treatments. Three global Aims guide the IDDRC’s work. Aim 1 provides core services to enable and disseminate impactful research on individualizing treatments based upon the causes, mechanisms, and contributing co-morbid sequelae of IDD; Aim 2 focuses on incorporating innovative methods and approaches to enhance multidisciplinary IDD research; and Aim 3 proposes to conduct a signature research project to improve the precision use of antipsychotic medication in people with autism. Across these Aims and five Cores supported by the IDDRC (Administrative, Clinical Translational, Translational Neuroscience, Behavioral Phenotyping, and Data Sciences), three themes permeate our work: (1) recruitment of highly-skilled researchers not currently conducting IDD research (non-traditional researchers); (2) inclusion of IDD participants into research studies that currently do not include IDD (non-traditional subjects); and (3) incorporation of novel scientific approaches and methods (non-traditional approaches). Our IDDRC is ideally posed to enable rapid discovery of precision care approaches by supporting 50 investigators leading 70 research projects (15 from NICHD) and, as highlighted by the Signature Research Project, to promote and implement generative, novel, and impactful research directions, thus meeting the NICHD’s vision of applying newly evolved technologies and approaches to rapidly accelerate the prevention and/or amelioration of IDDs. PUBLIC HEALTH RELEVANCE: As a group, intellectual and developmental disabilities, including Down syndrome and autism spectrum disorder, have dramatic effects on affected people’s and their caregiver’s lives. Unfortunately, there remains a lack of understanding about what causes these disabilities and, critically, how to treat them with targeted therapies. The Vanderbilt Kennedy Center’s Intellectual and Developmental Disabilities Research Center serves as the hub for Vanderbilt’s research efforts focusing on improving the lives of people with intellectual and developmental disabilities by understanding the causes of these disorders and developing and testing therapies tailored to each individual’s precise needs.",Overall: Eunice Kennedy Shriver Intellectual and Developmental Disabilities Research Center at Vanderbilt,10085550,P50HD103537,"['Academic Medical Centers', 'Affect', 'Antipsychotic Agents', 'Basic Science', 'Behavioral', 'Biomedical Research', 'Caregivers', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communication', 'Communities', 'Computerized Medical Record', 'Data', 'Data Science', 'Development', 'Developmental Disabilities', 'Diagnosis', 'Disease', 'Disease model', 'Down Syndrome', 'Education', 'Evaluation', 'Faculty', 'Family', 'Foundations', 'Funding', 'Future', 'Gap Junctions', 'Genotype', 'Goals', 'Image', 'Individual', 'Infrastructure', 'Institutes', 'Intellectual and Developmental Disabilities Research Centers', 'Intellectual functioning disability', 'Interdisciplinary Study', 'Intervention', 'Leadership', 'Longevity', 'Machine Learning', 'Medical Records', 'Methods', 'Mission', 'Modeling', 'National Institute of Child Health and Human Development', 'Neurodevelopmental Disability', 'Obesity', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Pilot Projects', 'Policy Research', 'Prevention', 'Problem behavior', 'Publications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Sampling', 'Schools', 'Series', 'Services', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Universities', 'Vision', 'Weight Gain', 'Work', 'autism spectrum disorder', 'base', 'behavioral phenotyping', 'clinical translation', 'comorbidity', 'cost effective', 'developmental disease', 'disability', 'drug-induced weight gain', 'experience', 'image processing', 'implementation science', 'improved', 'individualized medicine', 'innovation', 'large datasets', 'lectures', 'meetings', 'multidisciplinary', 'novel', 'personalized approach', 'personalized care', 'personalized medicine', 'population based', 'pragmatic trial', 'predictive modeling', 'programs', 'public health relevance', 'recruit', 'research study', 'success', 'targeted treatment', 'translational neuroscience', 'trial comparing']",NICHD,VANDERBILT UNIVERSITY MEDICAL CENTER,P50,2020,1387605,-0.007934518050449842
