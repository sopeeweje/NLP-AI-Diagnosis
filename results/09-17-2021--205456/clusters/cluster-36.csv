text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,9739919,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Base Management', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistics', 'subchondral bone', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2019,588354,0.02894739615476008
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,9976740,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Heterogeneity', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2019,299197,-0.025576597257699778
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9748523,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical effect', 'convolutional neural network', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'machine learning algorithm', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2019,195128,0.027429427818161798
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9783816,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2019,438449,-0.007050063976913783
"Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment PROJECT SUMMARY We propose a study of radiomic texture analysis in terms of robustness assessment and classification utility. We will introduce novel robustness metrics geared towards assessment of radiomic features in comparison across two image conditions, and apply these metrics to study feature robustness across imaging parameters and patient biology. In addressing the utility of radiomic features in cancer risk assessment, we will identify and evaluate texture signatures from mammography and tomosynthesis datasets. The field of radiomics is evolving fast, and quantitative texture analysis is being applied to a growing number of applications in medical imaging. By performing a thorough investigation of the robustness of these radiomic features to dataset heterogeneities we aim to identify the strengths and weaknesses of commonly used features to guide their implementations on future applications.  Two clinical tasks will be studied under the proposed research: 1) risk assessment and cancer prediction and 2) malignancy evaluation. Multiple modalities including tomosynthesis, mammography and MRI will be involved in studies geared towards addressing these clinical questions. An evaluation of the robustness of commonly employed radiomic features will help guide the field of medical texture analysis and contribute to meaningful conclusions in future studies throughout the field of quantitative image analysis. The first aim of the proposed research involves the proposition and evaluation of novel robustness metrics for investigations lacking a classification task. The second aim will extend the study of radiomics to investigate the utility of robust features in classification tasks and identification of texture signatures relate to biomedical characteristics. The third aim will build upon the two previous aims and culminate in the application of cutting-edge technologies in machine learning and deep learning in further promoting image processing in the field of medical physics. PROJECT NARRATIVE The goal of the proposed research is to evaluate and improve the application of radiomic texture features in cancer risk assessment. We will accomplish this by evaluating the robustness of various radiomic metrics, testing the classification utility of texture features in clinical tasks, and extending current classification methods to include cutting-edge developments in machine learning technology. Careful preliminary studies have demonstrated methods for selection of robust texture features and improvement in classification tasks by emphasizing feature robustness in feature selection methodology and we therefore believe that a meticulous evaluation of the impact of imaging parameters on feature calculations will lead to overall improvement of computer-aided diagnosis and clinical translation to progress in cancer screening protocols.",Machine Learning in Breast Parenchyma and Tumor Characterization for Cancer Risk Assessment,9683697,F31CA228247,"['Address', 'Benign', 'Biological', 'Biology', 'Breast', 'Breast Cancer Risk Factor', 'Characteristics', 'Classification', 'Clinical', 'Computer-Assisted Diagnosis', 'Data', 'Data Set', 'Descriptor', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Effectiveness', 'Eligibility Determination', 'Emerging Technologies', 'Evaluation', 'Family', 'Future', 'Goals', 'Heterogeneity', 'Image', 'Image Analysis', 'Impact evaluation', 'Incidence', 'Intuition', 'Investigation', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant - descriptor', 'Malignant Neoplasms', 'Mammography', 'Maps', 'Mathematics', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Output', 'Patients', 'Pattern', 'Performance', 'Physics', 'Protocols documentation', 'Psychological Transfer', 'Recording of previous events', 'Research', 'Risk', 'Risk Assessment', 'Risk Factors', 'Screening for cancer', 'System', 'Techniques', 'Technology', 'Testing', 'Texture', 'Three-Dimensional Imaging', 'Time', 'Translations', 'Variant', 'Work', 'base', 'breast imaging', 'cancer risk', 'clinical translation', 'deep learning', 'expectation', 'high risk', 'image processing', 'image registration', 'imaging modality', 'imaging system', 'improved', 'innovation', 'molecular subtypes', 'multimodality', 'novel', 'outcome forecast', 'patient population', 'quantitative imaging', 'radiomics', 'response', 'tomosynthesis', 'tumor']",NCI,UNIVERSITY OF CHICAGO,F31,2019,24304,-0.01751536518820656
"Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images ABSTRACT Manual analysis of biomedical images by researchers and pathologists has the potential to introduce bias and error that compromise the reliability of research and clinical findings. These problems are significant barriers to delivering the most beneficial evidence-based medicine, developing effective medical treatments, and promoting confidence in scientific inquiry. Identification of biomarkers and cellular targets following microscopy requires manual analysis of biomedical images, which is time intensive, difficult, and prone to bias and errors. Unintentional bias and attentional limitations during analysis of biomarkers can underlie poor reproducibility of findings in biomedical research and potentially introduce error in clinical diagnostics. We recently developed a “beta” software package designed to improve automation and standardization of image analysis, called “PIPSQUEAK” (Perineuronal net Intensity Program for the Standardization and Quantification of Extracellular matrix Analysis Kit). Since its publication in 2016, PIPSQUEAK beta has amassed approximately 1,300 users worldwide who use it to quantify the intensity and number of perineuronal nets and other neural markers in the brain. This technology significantly increases data reliability between image raters and decreases the time required for analysis by more than 100-fold. However, PIPSQUEAK beta currently uses target detection algorithms that require high-contrast images to automatically identify neurons as clusters of bright pixels on dark backgrounds. A significant current limitation to PIPSQUEAK beta, and other available imaging programs, is that detection of biomarkers can be difficult unless image conditions are ideal. Suboptimal conditions, like high background staining, off-target structures, overlapping or clustered biomarkers, and atypical morphologies, can lead to artifacts and consequently to inaccurate results and erroneous conclusions. Here, we propose to develop a user-friendly artificial intelligence (AI) platform for the automated detection of targeted biomarkers in digital microscopy that reduces this error by learning to distinguish between true cellular biomarkers and artifacts. We propose to integrate AI capabilities into our PIPSQUEAK technology to produce an adaptive, high-throughput, biomedical image analysis platform that quickly and accurately identifies biomarker targets from bench to bedside. A key advantage is that this AI program will be user friendly and available online, making it highly accessible to basic researchers and to technicians and clinicians identifying human pathologies. Thus, successful development of our AI program has a high translational potential. The goal of this proposal is 1) to develop and validate a machine learning model that is capable of detecting common histological marker morphologies in digital microscopy, and 2) to test the feasibility of adapting our AI platform to new biomarker datasets with minimal additional supervised training. Our end goal is to advance the reliability and speed of research findings and clinical diagnoses by making this technology widely available to researchers and clinicians. PROJECT NARRATIVE Manual analysis of biomedical images by researchers and pathologists has the potential to introduces bias and error that compromise the reliability of research and clinical findings; problems which are significant barriers to delivering the most beneficial evidence-based medicine and developing effective medical treatments. Application of artificial intelligence for the detection of disease or cellular targets has the potential to improve the reliability of research findings and clinical diagnoses, while reducing waste, time, and expense. We propose a method to improve the quality of biomedical research reproducibility and clinical diagnoses by developing a high-throughput, adaptive artificial intelligence platform for automated analysis of cellular and disease targets in digital microscopy images, which will be made available to scientists and clinicians as a user-friendly analysis platform.",Development of an adaptive machine learning platform for automated analysis of biomarkers in biomedical images,9845994,R43GM134789,"['Abbreviations', 'Algorithms', 'Artificial Intelligence', 'Attention', 'Automation', 'Biological Markers', 'Biomedical Research', 'Brain', 'Cell Line', 'Cell model', 'Cellular Morphology', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Coupled', 'Custom', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Evidence Based Medicine', 'Extracellular Matrix', 'FOS gene', 'Fluorescence', 'Future', 'Glial Fibrillary Acidic Protein', 'Goals', 'Histologic', 'Histology', 'Human Pathology', 'Image', 'Image Analysis', 'Immunoassay', 'Immunohistochemistry', 'Lead', 'Learning', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Medical', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Neurons', 'Nuclear', 'Pathologist', 'Performance', 'Procedures', 'Psychological Transfer', 'Publications', 'Rattus', 'Reproducibility', 'Reproducibility of Results', 'Research', 'Research Personnel', 'Sampling', 'Scientific Inquiry', 'Scientist', 'Shapes', 'Speed', 'Stains', 'Standardization', 'Structure', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Banks', 'Tissue Model', 'Tissue imaging', 'Tissues', 'Training', 'Zebrafish', 'automated analysis', 'base', 'bench to bedside', 'bioimaging', 'biomarker identification', 'cell type', 'cellular targeting', 'clinical Diagnosis', 'clinical diagnostics', 'contrast imaging', 'design', 'digital', 'digital imaging', 'extracellular', 'histological specimens', 'histological stains', 'imaging biomarker', 'imaging program', 'improved', 'interest', 'lateral line', 'microscopic imaging', 'predictive marker', 'programs', 'relating to nervous system', 'software as a service', 'statistics', 'targeted biomarker', 'tool', 'user-friendly', 'wasting']",NIGMS,"REWIRE NEUROSCIENCE, LLC",R43,2019,224915,0.01746943672071204
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9692717,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2019,695400,0.06437222279711453
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9706921,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Dimensions', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2019,381629,-0.002069720488149189
"Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches Project Summary The form (or shape) and function relationship of anatomical structures is a central theme in biology where abnor- mal shape changes are closely tied to pathological functions. Morphometrics has been an indispensable quan- titative tool in medical and biological sciences to study anatomical forms for more than 100 years. Recently, the increased availability of high-resolution in-vivo images of anatomy has led to the development of a new generation of morphometric approaches, called statistical shape modeling (SSM), that take advantage of modern computa- tional techniques to model anatomical shapes and their variability within populations with unprecedented detail. SSM stands to revolutionize morphometric analysis, but its widespread adoption is hindered by a number of sig- niﬁcant challenges, including the complexity of the approaches and their increased computational requirements, relative to traditional morphometrics. Arguably, however, the most important roadblock to more widespread adop- tion is the lack of user-friendly and scalable software tools for a variety of anatomical surfaces that can be readily incorporated into biomedical research labs. The goal of this proposal is thus to address these challenges in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM), which automat- ically constructs optimal statistical landmark-based shape models of ensembles of anatomical shapes without relying on any speciﬁc surface parameterization. The proposed research will provide an automated, general- purpose, and scalable computational solution for constructing shape models of general anatomy. In Aim 1, we will build computational and machine learning algorithms to model anatomies with complex surface topologies (e.g., surface openings and shared boundaries) and highly variable anatomical populations. In Aim 2, we will introduce an end-to-end machine learning approach to extract statistical shape representation directly from im- ages, requiring no parameter tuning, image pre-processing, or user assistance. In Aim 3, we will provide intuitive graphical user interfaces and visualization tools to incorporate user-deﬁned modeling preferences and promote the visual interpretation of shape models. We will also make use of recent advances in cloud computing to enable researchers with limited computational resources and/or large cohorts to build and execute custom SSM work- ﬂows using remote scalable computational resources. Algorithmic developments will be thoroughly evaluated and validated using existing, fully funded, large-scale, and constantly growing databases of CT and MRI images lo- cated on-site. Furthermore, we will develop and disseminate standard workﬂows and domain-speciﬁc use cases for complex anatomies to promote reproducibility. Efforts to develop the proposed technology are aligned with the mission of the National Institute of General Medical Sciences (NIGMS), and its third strategic goal: to bridge biology and quantitative science for better global health through supporting the development of and access to computational research tools for biomedical research. Our long-term goal is to increase the clinical utility and widespread adoption of SSM, and the proposed research will establish the groundwork for achieving this goal. Project Narrative This project will develop general-purpose, scalable, and open-source statistical shape modeling (SSM) tools, which will present unique capabilities for automated anatomy modeling with less user input. The proposed tech- nology will introduce a number of signiﬁcant improvements to current SSM approaches and tools, including the support for challenging modeling problems, inferring shapes directly from images (and hence bypassing the seg- mentation step), parallel optimizations for speed, and new user interfaces that will be much easier and scalable than the current tools. The proposed technology will constitute an indispensable resource for the biomedical and clinical communities that will enable new avenues for biomedical research and clinical investigations, provide new ways to answer biologically related questions, allow new types of questions to be asked, and open the door for the integration of SSM with clinical care.","Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches",9803774,R01AR076120,"['Address', 'Adoption', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomic Surface', 'Anatomy', 'Area', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Brain', 'Bypass', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Collection', 'Communities', 'Complex', 'Complex Analysis', 'Computational Technique', 'Computer Simulation', 'Computer software', 'Computers', 'Custom', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Felis catus', 'Funding', 'Generations', 'Geometry', 'Goals', 'Human', 'Ice', 'Image', 'Imagery', 'Injury', 'Intuition', 'Laboratory Research', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematical Computing', 'Measures', 'Medical', 'Medicine', 'Mission', 'Modeling', 'Modernization', 'Modification', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Occupations', 'Online Systems', 'Organism', 'Orthopedics', 'Pathologic', 'Population', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Shapes', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Speed', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Variant', 'Visual', 'Visualization software', 'Work', 'base', 'biomedical resource', 'clinical care', 'clinical investigation', 'clinically relevant', 'cohort', 'computerized tools', 'computing resources', 'deep learning', 'experience', 'flexibility', 'global health', 'graphical user interface', 'image archival system', 'image processing', 'imaging Segmentation', 'in vivo imaging', 'innovation', 'machine learning algorithm', 'model development', 'multidisciplinary', 'open source', 'particle', 'preference', 'software development', 'tool', 'usability', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2019,631809,0.0016624964909503917
"IEEE International Symposium on Biomedical Imaging Project Summary This proposal requests funds to provide travel support for graduates to attend and participate in the IEEE Inter- national Symposium on Biomedical Imaging (ISBI) 2019 conference, Venice, Italy on April 08-11, 2019. The main objective of the IEEE ISBI is to bring together researchers with interests in mathematical and computa- tional aspects of biomedical imaging, with a focus on addressing problems of significance to the development and application of imaging systems across spatial scales, from microscopy to whole-body imaging. ISBI partici- pants – on the order of 600-700 from across the world are involved in biomedical imaging research and development in academic institutions, government laboratories, or R&D departments of private companies. ISBI is co-sponsored by two IEEE societies: Signal Processing Society (SPS) and Engineering in Medicine and Biology Society (EMBS), representing academia, industry, and healthcare, and considered the world's foremost societies in biomedical engineering and imaging. SPS and EMBS publish IEEE Transactions on Medical Imag- ing, Transactions on Image Processing, Transactions on Biomedical Engineering, Transactions on Computational Imaging, and IEEE Journal of Biomedical and Health Informatics, among others. Since incep- tion in 2002, ISBI has become the leading international conference bringing together researchers from diverse algorithmic fields, applications, modalities, and size scales, to facilitate cross-fertilization of ideas across imag- ing modalities and scales. Conference topics include physical, biological and statistical modeling, image formation and reconstruction, computational and statistical image analysis, visualization and image quality as- sessment, and artificial intelligence and machine learning for big image data. ISBI, like other IEEE SPS and EMBS conferences, requires submission and review of a 4-page paper. Peer reviews are handled by a 50-mem- ber editorial board (area editors) of leading experts in the community, who in turn assign papers to well- qualified reviewers. All oral and poster papers are published in IEEExplore as Proceedings of ISBI. If awarded, IEEE anticipates the primary impact of this R13 grant will be increased attendance of U.S.-based students, postdoctoral fellows, and early career faculty. By offering to cover a significant portion of attendee's travel expenses, the cost-benefit ratio for attending ISBI 2019 will be extremely favorable. Furthermore, IEEE will award travel grants based on need and scientific excellence, creating opportunities for those early career researchers who have accepted papers (of which less than 50% are accepted to ISBI) and who have limited means to travel. IEEE will be particularly supportive in providing travel awards to women, under-represented groups, and persons with disabilities. Benefits can largely be summarized as “exposure” and education. ISBI provides opportunity for student exposure to many more areas of computational imaging research than generally available in her/his home institution, and concurrently provides opportunity for students to interact with leaders in the field through tutorials, plenary, oral, and poster presentations, and individual discussions. This proposal requests funds to provide travel support for graduate to attend and participate in the IEEE International Symposium on Biomedical Imaging (ISBI) 2019 conference, to be held in Venice, Italy on April 08-11, 2019. The main objective of the IEEE international Symposium on Biomedical Imaging is to bring together researchers with interests in the mathematical and computational aspects of biomedical imaging, with a focus on addressing problems of significance to the development and application of imaging systems across spatial scales, from microscopy to whole-body imaging. The conference covers biomedical imaging problems of high relevance to human health, and hence is of high relevance to the interests of the National Institute of Health.",IEEE International Symposium on Biomedical Imaging,9685477,R13EB027566,"['Academia', 'Address', 'Algorithms', 'Appointment', 'Area', 'Artificial Intelligence', 'Award', 'Biological Models', 'Biology', 'Biomedical Computing', 'Biomedical Engineering', 'Breeding', 'Budgets', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Costs and Benefits', 'Data', 'Development', 'Disabled Persons', 'Education', 'Engineering', 'Exposure to', 'Fertilization', 'Funding', 'Future', 'Generations', 'Goals', 'Government', 'Grant', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging problem', 'Individual', 'Industry', 'Institution', 'International', 'Italy', 'Journals', 'Laboratories', 'Location', 'Machine Learning', 'Mathematics', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Microscopic', 'Microscopy', 'Modality', 'Modeling', 'Oral', 'Paper', 'Participant', 'Peer Review', 'Postdoctoral Fellow', 'Privatization', 'Public Health Informatics', 'Publishing', 'Recommendation', 'Request for Proposals', 'Research', 'Research Personnel', 'Series', 'Societies', 'Statistical Models', 'Students', 'System', 'Training', 'Transact', 'Travel', 'Underrepresented Groups', 'United States National Institutes of Health', 'Woman', 'authority', 'base', 'biocomputing', 'bioimaging', 'biomedical informatics', 'body system', 'career', 'computerized tools', 'cost', 'early-career faculty', 'editorial', 'graduate student', 'image processing', 'imaging modality', 'imaging system', 'innovation', 'interest', 'meetings', 'member', 'physical model', 'posters', 'programs', 'reconstruction', 'research and development', 'signal processing', 'student participation', 'success', 'supportive environment', 'symposium', 'whole body imaging']",NIBIB,UNIVERSITY OF IOWA,R13,2019,10000,0.0023563764548327286
"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",Image analytics prediction of corneal keratoplasty failure,9765316,R21EY029498,"['Affect', 'Age', 'Ancillary Study', 'Anxiety', 'Area', 'Biological Markers', 'Blindness', 'Caring', 'Cataract Extraction', 'Cell Density', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Classification', 'Clinical Management', 'Clinical Research', 'Companions', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cornea', 'Corneal Endothelium', 'Counseling', 'Data', 'Data Set', 'Descemet&apos', 's membrane', 'Devices', 'Diabetes Mellitus', 'Endothelial Cells', 'Endothelium', 'Exhibits', 'Eye', 'Failure', 'Funding', 'Future', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Institutes', 'Intraocular lens implant device', 'Intuition', 'Keratoplasty', 'Knowledge', 'Lead', 'Liquid substance', 'Machine Learning', 'Measures', 'Methods', 'Microscopy', 'Multi-Institutional Clinical Trial', 'Netherlands', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Paper', 'Patient Care', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Penetrating Keratoplasty', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Pump', 'Reading', 'Research Support', 'Risk', 'Seminal', 'Software Framework', 'Suggestion', 'Testing', 'Time', 'Time Study', 'Tissue Transplantation', 'Topical Corticosteroids', 'Translating', 'Transplanted tissue', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Variant', 'Visual', 'cellular imaging', 'clinical practice', 'data management', 'density', 'experimental study', 'hazard', 'image processing', 'imaging biomarker', 'improved', 'individualized medicine', 'innovation', 'preservation', 'prevent', 'quantitative imaging', 'research study', 'secondary outcome', 'success', 'validation studies', 'vision science']",NEI,CASE WESTERN RESERVE UNIVERSITY,R21,2019,200104,0.024226423503663497
"Neuroimaging Analysis Center (NAC) Project Summary/Abstract The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the pos- sibility for a new era in neuroimaging, disease understanding, and patient treatment. To unlock the full medical potential made possible by these new technologies, new algorithms and clinically-relevant techniques must be developed by close collaboration between computer scientists, physicians, and medical researchers. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and exten- sive collaboration. The overarching theme for this P41 renewal is the discovery and analysis of novel imaging phenotypes to characterize disease. We use the term imaging phenotypes to describe patterns or features of disease that can be detected through imaging (predominantly MRI) followed by machine learning, statistical analysis, feature detection, and correlation with other indicators of disease such as structured patient infor- mation. The three proposed Technology Research & Development (TR&D) projects address this common question us- ing a variety of complementary approaches and clinical testbeds. TR&D 1 addresses microstructure of tissue, including novel imaging methods to detect tumor microstructure. TR&D 2 investigates rich spatial patterns of disease extracted from clinical imaging with a focus on cerebrovascular and neurodegenerative conditions such as stroke. Finally, TR&D 3 proposes novel image and connectivity-based features that can be correlated with a variety of diseases, with a clinical emphasis on pediatric brain development. Technical innovation will be driven by intense collaboration between the TR&Ds and key collaborators in neurosurgery, neurology, and pe- diatrics. The TR&Ds will leverage recent important developments in the fields of image acquisition, machine learning, and data science to identify and exploit novel imaging phenotypes of disease. Building on our long history of developing clinically-relevant methods, each TR&D includes a translational and clinical validation aim to ensure our work is clinically relevant and effective at meeting the driving clinical goals. NAC's proven software engi- neering, translation, and dissemination infrastructure, along with its established network of academic, medical, and industrial partners, enhance the center's value as a national resource. Project Narrative The Neuroimaging Analysis Center is a research and technology center with the mission of advancing the role of neuroimaging in health care. The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the possibility for a new era in neuroimaging, disease understanding, and patient treatment. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and extensive collaboration.",Neuroimaging Analysis Center (NAC),9791176,P41EB015902,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biomedical Technology', 'Biotechnology', 'Brain', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Science', 'Development', 'Disease', 'Educational process of instructing', 'Ensure', 'Goals', 'Healthcare', 'Image', 'Industrialization', 'Infrastructure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Patients', 'Pattern', 'Pediatrics', 'Phenotype', 'Physicians', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Software Engineering', 'Software Framework', 'Statistical Data Interpretation', 'Stroke', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Validation', 'Work', 'algorithmic methodologies', 'base', 'cerebrovascular', 'clinical application', 'clinical imaging', 'clinically relevant', 'cohort', 'disease phenotype', 'feature detection', 'imaging modality', 'innovation', 'meetings', 'neuroimaging', 'neurosurgery', 'new technology', 'novel', 'novel imaging technique', 'open source', 'response', 'technology research and development', 'tumor']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2019,1339073,0.030470984244431152
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9806367,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2019,184118,0.014609831988362904
"Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry PROJECT SUMMARY  Cellular interactions with the environment form the basis of health and disease for all organisms. Exposure to nutrients, toxins, and neighboring cells trigger coordinated molecular responses that impact cell function and metabolism in a beneficial, adaptive, or detrimental manner. Although the benefits of multicellularity for the formation of complex tissue structures or the function of entire organ systems has been long appreciated, it has only recently been understood that microbial inhabitants of vertebrates also have a tremendous impact on host cell function and dysfunction. Despite this, an understanding of these interactions has not moved beyond simple associations, and there are virtually no molecular technologies available that adequately define how a complex microbial ecosystem impacts host cell function, or how the host response to microbial colonization affects the bacterial community. This gap in knowledge is striking when one considers the broad and significant impact that microbes have on human health. In this application, we propose to expressly fill this knowledge gap through development of a novel multimodal imaging pipeline that will provide 3-dimensional information on the molecular heterogeneity of microbial communities and the immune response at the host-pathogen interface.  This proposal combines our expertise in immunology, infection biology, mass spectrometry, small animal imaging, machine learning, and computer vision to develop an integrated multimodal visualization method for studying infectious disease. Our unique approach will computationally combine ultra-high speed (~50px/s) MALDI-TOF images, ultra-high mass resolution (>200,000 resolving power) MALDI FTICR IMS, metal imaging by LA-ICP-IMS, high-spatial resolution optical microscopy, and MR imaging using data-driven image fusion. This strategy will enable 3-D molecular images to be generated for thousands of elements, metabolites, lipids, and proteins with an unprecedented combination of chemical specificity and spatial fidelity more than 50x faster than is currently possible. We will use this next-generation imaging capability to (i) define the heterogeneous microbial subpopulations throughout the 3-D volume of a S. aureus community, (ii) uncover the host molecules that form the abscess and accumulate to restrict microbial growth in murine models, and (iii) elucidate molecular markers that differentiate in vivo biofilms at the host-pathogen interface, between abscesses at various stages of progression, and under distinct degrees of nutrient stress. These studies will uncover new targets for therapeutic intervention and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research. PROJECT NARRATIVE This proposal will enable detailed views of the molecular components of infectious disease with unprecedented resolution through the development of a multimodal, 3-dimensional imaging platform. The proposed technologies will improve throughput and molecular specificity, enable automated high-precision and high-accuracy image alignment, and allow for descriptions of molecular signals in 3-D through the fusion of multi-modal imaging data. These studies will uncover targets for therapeutic intervention and antibiotic development and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research.",Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry,9788239,R01AI138581,"['3-Dimensional', 'Abscess', 'Affect', 'Animal Model', 'Animals', 'Anterior nares', 'Antibiotics', 'Antibodies', 'Architecture', 'Awareness', 'Bacteria', 'Bacterial Infections', 'Bacterial Proteins', 'Behavior', 'Biology', 'Biomedical Research', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Cellular Metabolic Process', 'Chemicals', 'Communicable Diseases', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Custom', 'Data', 'Development', 'Diagnosis', 'Differentiation Antigens', 'Dimensions', 'Disease', 'Ecosystem', 'Elements', 'Environment', 'Exposure to', 'Fourier transform ion cyclotron resonance', 'Functional disorder', 'Genus staphylococcus', 'Glean', 'Growth', 'Health', 'Health Promotion', 'Heterogeneity', 'Histology', 'Human', 'Image', 'Imagery', 'Imaging technology', 'Immune', 'Immune response', 'Immunology', 'Imprisonment', 'Individual', 'Infection', 'Infectious Diseases Research', 'Integration Host Factors', 'Knowledge', 'Label', 'Lesion', 'Lipids', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Mass Spectrum Analysis', 'Metals', 'Methodology', 'Methods', 'Microbe', 'Microbial Biofilms', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nutrient', 'Optics', 'Organism', 'Pathogenesis', 'Physiological', 'Population', 'Process', 'Proteins', 'Reagent', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Spatial Distribution', 'Specificity', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Staphylococcus aureus', 'Stress', 'Structure', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Tissues', 'Toxin', 'Vertebrates', 'Work', 'animal imaging', 'bacterial community', 'base', 'body system', 'commensal bacteria', 'experimental study', 'host colonization', 'imaging capabilities', 'imaging detection', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'innovation', 'interest', 'microbial', 'microbial colonization', 'microbial community', 'microscopic imaging', 'molecular imaging', 'molecular marker', 'mouse model', 'multimodality', 'neutrophil', 'new therapeutic target', 'next generation', 'novel', 'pathogen', 'protein expression', 'response', 'supervised learning', 'targeted treatment', 'virtual']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2019,562232,0.0038379778672275916
"NIDDK Extramural Digital Pathology Repository System In recent years, new technology and data processing capabilities have removed barriers to integration of molecular and histopathological data sets. Several clinical research networks across the National Institute of Diabetes, Digestive and Kidney Diseases extramural programs have put Digital Pathology Repositories (DPRs) into place with digital whole slide images (WSI) available to support standardization of classical diagnostic criteria across clinical sites. A developing line of investigation is the “mining” of these digital sets to identify features which correlate with disease. Computer assisted-image analysis for feature detection and feature recognition are key components of such investigation. The Centralized NIDDK Digital Pathology Repository will serve as an online repository to facilitate standardized archiving of WSI with the goal of providing controlled access for standardization, discovery and validation research efforts. n/a",NIDDK Extramural Digital Pathology Repository System,10032690,5N94019F00322,"['Archives', 'Artificial Intelligence', 'Clinical', 'Clinical Research', 'Computer-Assisted Image Analysis', 'Data Set', 'Diabetes Mellitus', 'Diagnostic', 'Digestive System Disorders', 'Disease', 'Extramural Activities', 'Future', 'Goals', 'Institutes', 'Investigation', 'Kidney Diseases', 'Machine Learning', 'Metadata', 'Mining', 'Molecular', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Research', 'Standardization', 'System', 'Validation', 'clinical research site', 'computerized data processing', 'digital', 'digital pathology', 'feature detection', 'new technology', 'online repository', 'programs', 'repository', 'whole slide imaging']",NICHD, ,N02,2019,95738,-0.00038654619046620496
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9797689,R44MH118815,"['Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'Stem cells', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'treatment strategy', 'two-dimensional', 'usability', 'virtual reality', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2019,748584,0.0345035717739992
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,9859232,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Dimensions', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'One-Step dentin bonding system', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2019,345016,0.008295017354278128
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9618878,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Decubitus ulcer', 'Diabetic Foot Ulcer', 'Diabetic wound', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2019,401916,0.017980046765402758
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,9893208,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human body', 'Image', 'Image Analysis', 'Imagery', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed\xa0imaging', 'open source', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2019,587413,0.03945153688851724
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,9752019,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2019,991516,0.0011828964357037536
"THE XNAT IMAGING INFORMATICS PLATFORM PROJECT SUMMARY This proposal aims to continue the development of XNAT. XNAT is an imaging informatics platform designed to facilitate common management and productivity tasks for imaging and associated data. We will develop the next generation of XNAT technology to support the ongoing evolution of imaging research. Development will focus on modernizing and expanding the current system. In Aim 1, we will implement new web application infrastructure that includes a new archive file management system, a new event bus to manage cross-service orchestration and a new Javascript library to simplify user interface development. We will also implement new core services, including a Docker Container service, a dynamic scripting engine, and a global XNAT federation. In Aim 2, we will implement two innovative new capabilities that build on the services developed in Aim 1. The XNAT Publisher framework will streamline the process of data sharing by automating the creation and curation of data releases following best practices for data publication and stewardship. The XNAT Machine Learning framework will streamline the development and use of machine learning applications by integrating XNAT with the TensorFlow machine learning environment and implementing provenance and other monitoring features to help avoid the pitfalls that often plague machine learning efforts. For both Aim 1 and 2, all capabilities will be developed and evaluated in the context of real world scientific programs that are actively using the XNAT platform. In Aim 3, we will provide extensive support to the XNAT community, including training workshops, online documentation, discussion forums, and . These activities will be targeted at both XNAT users and developers. RELEVANCE Medical imaging is one of the key methods used by biomedical researchers to study human biology in health and disease. The imaging informatics platform described in this application will enable biomedical researchers to capture, analyze, and share imaging and related data. These capabilities address key bottlenecks in the pathway to discovering cures to complex diseases such as Alzheimer's disease, cancer, and heart disease.",THE XNAT IMAGING INFORMATICS PLATFORM,9772886,R01EB009352,"['Address', 'Administrator', 'Alzheimer&apos', 's Disease', 'Architecture', 'Archives', 'Area', 'Automation', 'Biomedical Research', 'Brain', 'Cardiology', 'Categories', 'Classification', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Docking', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Evolution', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Informatics', 'Infrastructure', 'Instruction', 'Internet', 'Libraries', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Modality', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Newsletter', 'Optics', 'Paper', 'Pathway interactions', 'Peer Review', 'Persons', 'Plague', 'Positron-Emission Tomography', 'Principal Investigator', 'Process', 'Productivity', 'Publications', 'Publishing', 'Radiology Specialty', 'Research', 'Research Personnel', 'Security', 'Services', 'System', 'Technology', 'TensorFlow', 'Training', 'Validation', 'base', 'biomedical resource', 'computer framework', 'computing resources', 'data sharing', 'design', 'distributed data', 'educational atmosphere', 'hackathon', 'imaging informatics', 'imaging program', 'improved', 'informatics\xa0tool', 'innovation', 'next generation', 'online tutorial', 'open source', 'outreach program', 'pre-clinical', 'programs', 'skills', 'symposium', 'tool', 'virtual', 'web app']",NIBIB,WASHINGTON UNIVERSITY,R01,2019,663419,0.01988654969198593
"Center for Advanced Imaging Innovation and Research (CAI2R) Overall Project Summary  The Center for Advanced Imaging Innovation and Research (CAI2R) pursues a mission of bringing people together to create new ways of seeing. The work of our Center has been focused on creating new paradigms for the acquisition, reconstruction, and interpretation of biomedical images, and on implementing new collaboration models in order to translate these developments rapidly into clinical practice.  The world of biomedical imaging is changing, and CAI2R has been at the forefront of that change. Tasks that were once the sole domain of meticulously-engineered imaging hardware are now beginning to be accomplished in software, increasingly informed by diverse arrays of inexpensive auxiliary sensors. Information once pursued through the laborious acquisition of carefully separated image datasets is now being derived from newly integrated, and richly quantitative, data streams. In keeping with these themes, our Center will be organized around the following four Technology Research and Development (TR&D) projects going forward: 1. Reimagining the Future of Scanning: Intelligent image acquisition, reconstruction, and analysis. 2. Unshackling the Scanners of the Future: Flexible, self-correcting, multisensor machines. 3. Enriching the Data Stream: MRI and PET in concert. 4. Revealing Microstructure: Biophysical modeling and validation for discovery and clinical care.  In each of these projects, we aim to push medical imaging technology to the next level, both in hardware and in software. Having made great strides in developing rapid, continuous imaging data streams, we will next aim to add key new information to those streams, both from physics-driven microstructural modeling and from data- driven machine learning. Having focused on the development of robust tools for image acquisition and reconstruction, we will extend the pipeline to image interpretation, using the results of human- or machine- derived evaluations of image content as feedback for the further improvement of acquisition strategies and sensor designs. We will also aim to close the loop between diagnostic sensing and therapeutic intervention, exploring new ways to guide therapy with continuously-acquired information about tissue bioeffects.  Our Center has an explicit translational focus, which is reflected in the day-to-day operation of TR&D projects as well as in the topics of Collaborative Projects (CPs) and Service Projects (SPs), which are focused on three general areas of high public health impact: cancer, musculoskeletal disease, and neurologic disease.  In keeping with this translational emphasis, CAI2R is also be driven by an embedded collaboration model in which basic scientists, clinicians, and industry developers sit down together regularly at the scanners for interactive technology development and assessment. With early involvement of clinical stakeholders and industry partners, we aim to make CAI2R technologies widely available, for the advancement of biomedical knowledge and for the benefit of patients and the physicians who care for them. Overall Project Narrative  The Center for Advanced Imaging Innovation and Research (CAI2R) develops novel imaging techniques and technologies for the improved diagnosis and management of cancer, musculoskeletal disease, neurological disease and other disorders with a profound impact on human health. By exploiting connections between imaging modalities such as MRI and PET, we aim to advance the fundamental capabilities of each, so as to expand biomedical knowledge and improve the care of patients.",Center for Advanced Imaging Innovation and Research (CAI2R),9804438,P41EB017183,"['Adopted', 'Area', 'Artificial Intelligence', 'Biology', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer software', 'Country', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Engineering', 'Feedback', 'Funding', 'Future', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Imagination', 'Imaging Device', 'Imaging technology', 'Industrial Product', 'Industry', 'Institution', 'Intelligence', 'Knowledge', 'Legal patent', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Musculoskeletal Diseases', 'Patient Care', 'Patients', 'Performance', 'Philosophy', 'Physicians', 'Physics', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Scanning', 'Scientist', 'Services', 'Software Tools', 'Stream', 'Technology', 'Technology Assessment', 'Testing', 'Therapeutic Intervention', 'Time', 'Tissues', 'Training', 'Translating', 'Ursidae Family', 'Validation', 'Visit', 'Work', 'bioimaging', 'biophysical model', 'cancer imaging', 'clinical care', 'clinical practice', 'data acquisition', 'design', 'flexibility', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging scientist', 'improved', 'industry partner', 'innovation', 'interest', 'medical schools', 'multidisciplinary', 'musculoskeletal imaging', 'nervous system disorder', 'neuroimaging', 'novel imaging technique', 'off-patent', 'open source', 'operation', 'radio frequency', 'reconstruction', 'sensor', 'technology development', 'technology research and development', 'tool', 'web site']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,P41,2019,1715698,0.013860942663691483
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,9748417,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'machine learning algorithm', 'multidisciplinary', 'pathogen', 'point of care', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2019,991540,0.014572111361328419
"High throughput cell screening for toxic metal exposure Project Summary The overall objective of this research project is to develop a novel approach for high throughput screening of individual cells based on holographic imaging. To achieve this goal, we propose to implement a new quantitative phase imaging modality, holographic cytomtery, which incorporates several novel technical advances to enable high throughput imaging. Holographic cytometry (HC) will bring the high sensitivity of quantitative phase microscopy (QPM) to imaging of cells flowing through microfluidic devices. While QPM has been used for cell analysis previously, typically only a handful of cells have been imaged. To enable significant application of QPM for fundamental cell biology and clinical studies, it is necessary to move to a high throughput implementation. Technical advances needed to realize the high resolution HC system include use of high speed line scan cameras, microfluidic chips with multiple parallel channels, and light from a pulsed laser source to enable stroboscopic illumination. In order to efficiently analyze and process this data set, rapid analysis software will be developed that leverages the highly parallel processing capabilities of graphics processing units and machine learning algorithms to enable automated classification. The proposed HC method can be applied to imaging a wide range of flowing cells. To demonstrate the utility of the approach, we will initially target the measurement of cancerous progression due to environmental toxicant exposure. We have conducted a preliminary study that shows QPM can detect early changes in the biomechanical properties of cells due to arsenic exposure. In the proposed project, we seek to develop QPM based biomarkers of pre-cancerous change that will enable rapid assessesment. QPM has not been implemented in such a format to date and thus is not yet a feasible approach for clinical or research studies. To meet the goal of high throughput imaging with QPM, the following Specific Aims are proposed: 1. Develop new instrumentation for high speed imaging using off axis digital holography. 2. Implement high throughput analysis methods based on machine learning 3. Test and validate high throughput system with pilot studies of heavy metal exposed epithelial cells to show the approach can detect early pre-cancerous changes due to environmental toxicant exposure. Upon completion of this project, we will have realized a high throughput imaging cytometry system for research and clinical applications. Project Narrative  The proposed research will develop a new high throughput cellular screening technology based on quantitative phase image of cells flowing in a microfluidic chip. This technology will allow researchers and doctors to obtain holographic images of every single cell in a sample in a short amount of time which can then be analyzed by a computer. This would offer the opportunity to evaluate the characteristics of populations of cells for understanding changes in public health due to environmental factors.",High throughput cell screening for toxic metal exposure,9732537,R21ES029791,"['Arsenic', 'Biological', 'Biological Assay', 'Biological Markers', 'Biomechanics', 'Cancerous', 'Cells', 'Cellular biology', 'Classification', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Cytology', 'Cytometry', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Descriptor', 'Development', 'Discrimination', 'Disease', 'Environmental Exposure', 'Environmental Risk Factor', 'Epithelial Cells', 'Evaluation', 'Exhibits', 'Exposure to', 'Functional disorder', 'Future', 'Geometry', 'Goals', 'Heavy Metals', 'Holography', 'Image', 'Image Cytometry', 'Individual', 'Lasers', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Mechanics', 'Metal exposure', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscopy', 'Morphology', 'Motion', 'Neoplasm Metastasis', 'Phase', 'Phenotype', 'Physiologic pulse', 'Pilot Projects', 'Population Characteristics', 'Premalignant', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Sampling', 'Scanning', 'Source', 'Speed', 'Stream', 'System', 'Technology', 'Testing', 'Time', 'Toxic Environmental Substances', 'Toxicant exposure', 'automated analysis', 'base', 'cancer cell', 'carcinogenesis', 'cellular imaging', 'clinical application', 'detector', 'digital', 'high throughput analysis', 'high throughput screening', 'imaging approach', 'imaging modality', 'instrument', 'instrumentation', 'machine learning algorithm', 'machine vision', 'mechanical properties', 'microscopic imaging', 'nanoscale', 'novel', 'novel strategies', 'parallel computer', 'parallel processing', 'prevent', 'research clinical testing', 'research study', 'screening', 'shear stress', 'systems research', 'tool', 'toxic metal']",NIEHS,DUKE UNIVERSITY,R21,2019,194177,-0.020342120599187465
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE Mapping effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing of different types of individual cells, understanding the func- tion and relationships between those cell types, and modeling their individual and collective function. In order to exploit human and machine intelligence, different visual interfaces will be implemented that use the CCF in support of data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, mathematical biology, and biomedical data standards to develop a highly accurate and extensible multidimen- sional spatial basemap of the human body and associated data overlays that can be interactively explored online as an atlas of tissue maps. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across the human body along multiple functional contexts (e.g., systems physiology, vascular, or endocrine systems), and connect and integrate further computational, analytical, visualization, and biometric resources as driven by the context or “position” on the map. The CCF and the interactive data visualizations will be multi-level and multi-scale sup- porting the exploration and communication of tissue and publication data--from single cell to whole body. In the first year, the proposed Mapping Component will run user needs analyses, compile an initial CCF using pre-existing classifications and ontologies; implement two interactive data visualizations; and evaluate the usa- bility and effectiveness of the CCF and associated visualizations in formal user studies. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an ex- tensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spa- tial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high- resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",9988039,OT2OD026671,"['Address', 'Anatomy', 'Artificial Intelligence', 'Atlases', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Classification', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Ecosystem', 'Educational workshop', 'Effectiveness', 'Endocrine system', 'Future', 'Genetic', 'Goals', 'Human', 'Human body', 'Image', 'Imagery', 'Individual', 'Infrastructure', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Mathematical Biology', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Organ', 'Participant', 'Physiological', 'Physiology', 'Positioning Attribute', 'Production', 'Publications', 'Resolution', 'Resources', 'Running', 'Services', 'System', 'Tissues', 'Update', 'Vascular System', 'Visual', 'Visualization software', 'Work', 'base', 'cell type', 'computing resources', 'data integration', 'data mining', 'data visualization', 'design', 'hackathon', 'human imaging', 'interoperability', 'member', 'systematic review', 'usability', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2019,49496,-0.021273910021791225
"Application of Advanced Quantitative Methods to Schizophrenia Research in Macedonia PROJECT SUMMARY  Abnormalities of white matter are important in schizophrenia. A preponderance of studies have found decreased levels of transcripts for myelin-related proteins in autopsy brains. Some have found decrease in the proteins themselves, and some have not. Hundreds of diffusion tensor imaging (DTI) studies have found reduced fractional anisotropy (FA) in the brains of many people with schizophrenia (SCH). Decreased FA is interpreted as disruption of normal architecture. However, postmortem examination has failed to identify characteristic abnormalities. This suggests that abnormalities are subtle, and perhaps postmortem examinations have not used the right tools to find them. We have therefore been developing, as part of a collaboration supported by our concluding Fogarty project, two new methods to characterize white matter at high resolution. The first is a machine learning protocol to measure axonal diameters and myelin sheath thickness in electron microscope (EM) images of prefrontal white matter, recognizing and avoiding artifacts in EM of autopsy tissue. This will enable us to measure thousands of fibers in EM images produced as part of our concluding Fogarty project, from individuals with SCH, major depressive disorder (MDD), or no psychiatric illness (NPI). The second method, suggested by the DTI findings, is to analyze the arrangement of the axons themselves. We will use 3-dimensional (3D) reconstructions of high-resolution images of the axons themselves, identified by Bielschowsky silver stain or immunohistochemistry for phosphorylated neurofilament protein. To obtain high-resolution images of Bielschowsy stains, we will take advantage of the recent observation by Dr. Mark Sonders, co-investigator on this project, that these and other heavy metal stains luminesce under 2-photon infrared excitation. This yields clear and measurable images of individual axons. We will perform these procedures on sections from existing paraffin blocks that comprise a complete left prefrontal coronal section from 36 triads containing 1 case each of SCH, MDD, or NPI, matched for sex and age. These brains were included in earlier studies that yielded data on protein composition, mRNA for myelin-related proteins, DNA methylation, microglial activation, and semiquantitative myelin histology. In a third, exploratory aim, we will employ graphical models to combine these various types of data with known properties of CNS white matter and myelin to build a model of what is disturbed in schizophrenia. We expect that novel techniques for data fusion will reveal associations based on multidimensional correlations that could not be detected by modeling the single-domain datasets separately. In the process of completing these scientific aims, we will pursue the pedagogic goals of training the first two professional biostatisticians in Macedonia, and an academic pathologist. We will also hold a seminar course for biological researchers to build awareness and understanding of the power of biostatistical and other computational methods to enrich their research. NARRATIVE Our ongoing Fogarty/NIMH research project in Macedonia (R01 MH060877, “Building Schizophrenia Research in Macedonia”), has demonstrated biochemical abnormalities of white matter in schizophrenia that are not present in major depressive disorder. However, we have not seen anatomical abnormalities of white matter, which MRI studies of schizophrenia tell us should exist, and as the biochemistry also suggests. To explore white matter in novel ways, we are developing new methods of microscopy, image analysis and statistical inference, which we now propose to employ on a large scale.",Application of Advanced Quantitative Methods to Schizophrenia Research in Macedonia,9953486,R56MH117769,"['3-Dimensional', 'Academy', 'Age', 'Anisotropy', 'Architecture', 'Autopsy', 'Awareness', 'Axon', 'Biochemical', 'Biochemistry', 'Biological', 'Biological Assay', 'Biometry', 'Brain', 'Caliber', 'Cerebrum', 'Characteristics', 'Charge', 'Collaborations', 'Complex', 'Computer-Assisted Diagnosis', 'Computers', 'Computing Methodologies', 'Confocal Microscopy', 'DNA Methylation', 'Data', 'Data Set', 'Deformity', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electron Microscope', 'Electrons', 'Fiber', 'Goals', 'Heavy Metals', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Individual', 'Informatics', 'International', 'Knowledge', 'Learning', 'Left', 'Macedonia', 'Machine Learning', 'Magnetic Resonance Imaging', 'Major Depressive Disorder', 'Measurable', 'Measurement', 'Measures', 'Medical', 'Mental disorders', 'Messenger RNA', 'Methodology', 'Methods', 'Microscopy', 'Modeling', 'Modernization', 'Morphologic artifacts', 'Morphology', 'Multiomic Data', 'Myelin', 'Myelin Sheath', 'National Institute of Mental Health', 'Neurofilament Proteins', 'Paraffin', 'Pathologist', 'Pathology', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Recording of previous events', 'Reporting', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Schizophrenia', 'Scientist', 'Silver Staining', 'Stains', 'Statistical Data Interpretation', 'Statistical Methods', 'Structural Models', 'Students', 'Techniques', 'Thick', 'Time', 'Tissues', 'Training', 'Transcript', 'Translational Research', 'Triad Acrylic Resin', 'base', 'cognitive function', 'computerized', 'computerized tools', 'data modeling', 'deep neural network', 'diffusion anisotropy', 'high resolution imaging', 'histological image', 'histological studies', 'imaging study', 'innovation', 'interest', 'low and middle-income countries', 'microscopic imaging', 'multidimensional data', 'multimodality', 'network models', 'novel', 'pedagogy', 'reconstruction', 'sex', 'tool', 'two photon microscopy', 'two-photon', 'water diffusion', 'white matter']",NIMH,NEW YORK STATE PSYCHIATRIC INSTITUTE,R56,2019,10000,-0.01233130095040616
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,9782980,UG3HL145593,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'automated analysis', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'preservation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NHLBI,PURDUE UNIVERSITY,UG3,2019,375000,0.006973012843499094
"Conference on Modern Challenges in Imaging in the Footsteps of Allan Cormack Project Summary: Tufts University physics professor Allan Cormack pioneered the field of tomography. His seminal work, from 1963 and 1964, provided both the mathematical foundations of computerized tomography (CT), and tangible proof-of-concept by engineering a rudimentary CT scanner. Taken together, this effort represented the first practical method to ""see into"" an object without physically breaking it open. Along with the engineer Godfrey Hounsfield, he won the 1979 Nobel Prize in Physiology or Medicine for these contributions. Since then, tomography has broadened to include a wide range of modalities and problems. This field is unique for the rich interplay among applications in medicine, security, earth sciences, industry, physics, and the mathematics required to solve these problems. This international conference at Tufts, “Modern Challenges in Imaging: In the Footsteps of Allan Cormack” will honor the achievements of Cormack and reflect this diversity in the field by gathering top international researchers in mathematics, engineering, science, and medicine to communicate the most current research and challenges in the field. This will include work on mathematical models of emerging modalities, tomographic machine learning, dynamic methods, and spectral imaging with applications include medicine and security. The best research from the conference will be disseminated in a special issue of the journal Inverse Problems. Talks will be posted on the conference website. The organizers will recruit a diverse set of experienced participants and trainees, and the conference will be advertised in a range of publications reflecting the scientific and demographic diversity of the field. This conference is unique in that it combines high-level mathematical participants with experts in medical and industrial CT. It is structured to encourage participants from different fields to talk with each other, broaden their horizons, and make connections between problems and methodologies in the various fields. Several of the plenary talks will provide introductions to the areas. Trainees will be integrated into the conference through an informal welcome lunch and a poster session to introduce them to researchers in the field. This supports goals 1, 4, and 5, of the NIBIB: Researchers will present innovative biomedical technologies, engineering solutions, and mathematical methods to better image the body and objects more generally. The synergy between research areas will support the translation of technologies from the academic sphere to medical utility. The training opportunities for graduate students and beginners support the training of the next generation of diverse scientists. Project Narrative This conference will bring together medical, scientific, engineering, and applied mathematical researchers to present their newest research for a range of tomographic problems. Graduate students and beginners will be encouraged to participate and learn by being offered introductory talks, a student poster session, a welcome event, and an informal atmosphere. The conference will be structured so researchers will learn about important challenges in practical tomography as well as new techniques and methods, thereby creating synergies and research connections among the areas.",Conference on Modern Challenges in Imaging in the Footsteps of Allan Cormack,9837131,R13EB028700,"['Achievement', 'Advertising', 'Algorithms', 'Area', 'Biomedical Technology', 'Communication', 'Development', 'Earth science', 'Engineering', 'Environment', 'Event', 'Fertilization', 'Foundations', 'Goals', 'Image', 'Individual', 'Industrialization', 'Industry', 'International', 'Journals', 'Lead', 'Learning', 'Lightning', 'Machine Learning', 'Mathematics', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Modality', 'Modernization', 'National Institute of Biomedical Imaging and Bioengineering', 'Nobel Prize', 'Outcome', 'Participant', 'Physics', 'Physiology', 'Population', 'Problem Solving', 'Publications', 'Research', 'Research Personnel', 'Science', 'Scientist', 'Security', 'Seminal', 'Societies', 'Structure', 'Students', 'Techniques', 'Technology', 'Time', 'Training Support', 'Translations', 'Underrepresented Groups', 'Universities', 'Work', 'X-Ray Computed Tomography', 'cohort', 'demographics', 'design', 'experience', 'graduate student', 'higher level mathematics', 'informal atmosphere', 'innovation', 'mathematical methods', 'mathematical model', 'meetings', 'member', 'next generation', 'posters', 'professor', 'recruit', 'spectrograph', 'symposium', 'synergism', 'tomography', 'training opportunity', 'web site']",NIBIB,TUFTS UNIVERSITY MEDFORD,R13,2019,10000,-0.00022614208659318442
"Groundwork for a Synchrotron MicroCT Imaging Resource for Biology (SMIRB) Project Summary Each major human disease is associated with a specific range of morphological changes to cells and tissues in the micron scale. Normal and abnormal structure was discovered and is still characterized using histology - a microscopic technique that depends on physical tissue slices. Presently, histology’s use in systems biology is limited by its largely descriptive and two-dimensional nature. Making histology quantitative and three-dimensional would be potentially transformational for research and diagnostics, but has been impractical. Accordingly, we have now created a 3D form of histology by customizing X-ray microtomography (micro-CT) of fixed and stained, millimeter-scale, whole organisms and tissue samples. We used fixed and metal-stained, whole zebrafish because they contain a full range of tissues within the size range currently studied histologically. The result is the first practical way to create virtual histology-like “sections” in any plane. Three-dimensional, complete histological phenotyping has potential use in genetic and chemical screens, and in clinical and toxicological tissue diagnostics. Here, we propose the next steps needed to enable high-throughput, quantitative, 3D histological phenotyping of whole, millimeter-scale animals. The proposed work applies the principles of chemistry, physics, and computer science to improve image resolution, throughput, and analytics, organized into three specific aims. Specific Aim 1 will build on our developments in this project and further improve imaging volume and resolution by upgrading imaging array, optics, and sub-pixel shifting, and to throughput by changes in sample embedding, loading geometry and mechanics, helical CT scanning, scintillator material, and to data sharing by improvements to the ViewTool infrastructure and user interface. Specific Aim 2 will yield reference images to define the range of normal phenotypic variation and to obtain samples related to a range of potential applications. Specific Aim 3 will apply the power of machine learning to segmentation, annotation, and analytics. Together, this work will establish a practical foundation for large-scale genetic and chemical screens involving mm-scale, whole organisms based on 3-dimensional, quantitative, histological phenotyping. The instrumentation and analytics will be state-of-the-art in its combination of resolution, field-of-view, pancellularity, image quality, analytical potential, throughput, sample stability, and reproducibility and largely usable with both tube and synchrotron X-ray sources. The voxel resolution will be at least 0.5 μm across fields-of-view of up to 1 cm. Representation of every cell type make the images suitable for cross-referencing across imaging modalities. Potential applications will be explored, “wild-type” will begin to be defined, and training sets for automated segmentation generated. The potential impact will encompass the missions of most NIH Institutes and Centers. The whole-animal genetic and chemical screens enabled are expected to impact drug development, diagnostics, and our basic understanding of how genes and environment define phenotype. Project Narrative Our group has established the only three-dimensional form of histology that is suitable for histopathology and quantitative tissue phenotyping, tissue X-ray microtomography (micro-CT). We outline here a plan to establish mechanisms for increasing resolution and field-of-view, to add sample multiplexing, to simply sample preparation, and to explore machine learning mechanisms for defining normal and abnormal structure towards whole-organism complete tissue phenotyping. The resulting tools will allow the community to comprehensively and computationally determine the roles of genes and environment in defining phenotype, which has implications in drug development, biomedical research, and medicine.",Groundwork for a Synchrotron MicroCT Imaging Resource for Biology (SMIRB),9792960,R24OD018559,"['3-Dimensional', 'Adolescent', 'Age', 'Animal Genetics', 'Animals', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Body measure procedure', 'Caenorhabditis elegans', 'Cells', 'Cellular Structures', 'Cesium', 'Chemicals', 'Chemistry', 'Communities', 'Custom', 'Data', 'Development', 'Diagnostic', 'Dimensions', 'Drosophila genus', 'Embryo', 'Environment', 'Fishes', 'Foundations', 'Genes', 'Genetic', 'Geometry', 'Goals', 'Histologic', 'Histology', 'Histopathology', 'Image', 'Infrastructure', 'Institutes', 'Iodides', 'Machine Learning', 'Measures', 'Mechanics', 'Medicine', 'Metals', 'Microscopic', 'Mission', 'Morphology', 'Mus', 'Mutation', 'Nature', 'Nerve', 'Normal Range', 'Online Systems', 'Optics', 'Organ', 'Output', 'Pharmaceutical Preparations', 'Phenotype', 'Physics', 'Preparation', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Robotics', 'Roentgen Rays', 'Role', 'Sampling', 'Scanning', 'Series', 'Siblings', 'Signal Transduction', 'Slice', 'Source', 'Spiral Computed Tomography', 'Stains', 'Structural defect', 'Structure', 'Synchrotrons', 'Systems Biology', 'Techniques', 'Testing', 'Texture', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Training', 'Travel', 'Tube', 'United States National Institutes of Health', 'Variant', 'Whole Organism', 'Work', 'Writing', 'X-Ray Computed Tomography', 'Zebrafish', 'base', 'bone', 'cell type', 'clinical toxicology', 'computer science', 'computerized tools', 'crowdsourcing', 'data sharing', 'detector', 'disease phenotype', 'drug development', 'feature detection', 'histological studies', 'human disease', 'imaging modality', 'improved', 'instrumentation', 'microCT', 'millimeter', 'mutant', 'programs', 'supervised learning', 'tool', 'two-dimensional', 'unsupervised learning', 'virtual']",OD,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,R24,2019,667280,0.004267741239769954
"An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography SUMMARY – OVERALL Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function. Although the basic electron cryo-tomography technique has been used for several decades, the technology is being revolutionized by recent advances in sample preparation, electron cryo-microscopy hardware, improved capabilities for automatic data collection, direct electron detection imaging devices, and phase plate technologies. Combined, these advances led to the ability to generate extraordinarily large numbers of cellular cryo-tomograms of exquisite quality. In principle, such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. However, collection of cellular data is now at a far faster rate than can currently be analyzed with existing methods, producing a serious barrier to progress: to match the data production rates of a single laboratory, at least 50 experienced scientists would need to handle the data analysis. The primary goal of this Program Project is to establish quantitative and highly automated tools for the reconstruction and interpretation of highly complex cellular tomographic data. We have assembled a highly synergistic team of PIs with complimentary expertise in cutting-edge computational and experimental electron microscopy techniques to achieve this goal through collaborative efforts. Project 1 (Hanein & Penczek) focuses on development and implementation of tomogram quality assessment and validation techniques and on experimentally guided optimization of data collection strategies. Project 2 focuses on automatic tomographic reconstruction technology, extraction of various features from the tomograms, and the analysis of distribution patterns derived from the extracted features. Project 3 focuses on development of quantitative tools for tomogram annotation through deep learning and sub-tomogram alignment as well as interactive visualization tools. The set of highly automated tools developed in this Program Project will permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study. NARRATIVE Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function and—with recent instrumental advances—it is now possible to image hundreds of cells per months, enabling collection of cellular data at a far faster rate than can currently be analyzed. Such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. This Program Project brings together an accomplished team of investigators to develop new strategies for effectively processing and interpreting this massive influx of data, developing a set of highly automated tools to permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study.",An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography,9769773,P01GM121203,"['Address', 'Algorithms', 'Artificial Intelligence', 'Big Data', 'Biological', 'Biology', 'Cancer Diagnostics', 'Cell physiology', 'Cells', 'Classification', 'Collection', 'Complex', 'Computing Methodologies', 'Cryo-electron tomography', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Disease', 'Electron Microscopy', 'Electrons', 'Environment', 'Floods', 'Goals', 'Health', 'Heart', 'Human', 'Image', 'Imaging Device', 'Individual', 'Knowledge', 'Laboratories', 'Methodology', 'Methods', 'Molecular', 'Molecular Structure', 'Morphology', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Preparation', 'Process', 'Production', 'Real-Time Systems', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Stimulus', 'Structure', 'System', 'Techniques', 'Technology', 'Tomogram', 'Validation', 'Variant', 'Visualization software', 'base', 'computer framework', 'convolutional neural network', 'deep learning', 'electron tomography', 'experience', 'imaging detection', 'improved', 'insight', 'knowledge base', 'learning strategy', 'nanomachine', 'novel diagnostics', 'particle', 'programs', 'reconstruction', 'response', 'software development', 'statistics', 'tomography', 'tool', 'virtual']",NIGMS,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,P01,2019,928444,-0.02135481757093666
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",9882865,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2019,340827,0.01914485285717326
"Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software. Abstract (Proposal title: Neuroscience Gateway to Enable Dissemination of Computational and Data Processing Tools and Software.): This proposal presents a focused plan for expanding the capabilities of the Neuroscience Gateway (NSG) to meet the evolving needs of neuroscientists engaged in computationally intensive research. The NSG project began in 2012 with support from the NSF. Its initial goal was to catalyze progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists faced in large scale modeling projects involving tools and software which require and run efficiently on high performance computing (HPC) resources. NSG's success is reflected in the facts that (1) its base of registered users has grown continually since it started operation in early 2013 (more than 800 at present), (2) every year the NSG team successfully acquires ever larger allocations of supercomputer time (recently more than 10,000,000 core hours/year) on academic HPC resources of the Extreme Science and Engineering Discovery (XSEDE – that coordinates NSF supercomputer centers) program by writing proposals that go through an extremely competitive peer review process, and (3) it has contributed to large number of publications and Ph.D thesis. In recent years experimentalists, cognitive neuroscientists and others have begun using NSG for brain image data processing, data analysis and machine learning. NSG now provides over 20 tools on HPC resources for modeling, simulation and data processing. While NSG is currently well used by the neuroscience community, there is increasing interest from that community in applying it to a wider range of tasks than originally conceived. For example, some are trying to use it as an environment for dissemination of lab-developed tools, even though NSG is not suitable for that use because of delays from the batch queue wait times of production HPC resources, and lack of features and resources for an interactive, graphical, and collaborative environment needed for tool development, benchmarking and testing. “Forced” use of NSG for development and dissemination makes NSG's operators a “person-in-the-middle” bottleneck in the process. Another issue is that newly developed data processing tools require high throughput computing (HTC) usage mode, as opposed to HPC, but currently NSG does not provide access to compute resources suitable for HTC. Additionally, data processing workflows require features such as the ability to transfer large size data, process shared data, and visualize output results, which are not currently available on NSG. The work we propose will enhance NSG by adding the features that it needs to be a suitable and efficient dissemination environment for lab-developed neuroscience tools to the broader neuroscience community. This will allow tool developers to disseminate their lab-developed tools on NSG taking advantage of the current functionalities that are being well served on NSG for the last six years such as a growing user base, an easy user interface, an open environment, the ability to access and run jobs on powerful compute resources, availability of free supercomputer time, a well-established training and outreach program, and a functioning user support system. All of these well-functioning features of NSG will make it an ideal environment for dissemination and use of lab-developed computational and data processing neuroscience tools. The Neuroscience Gateway (NSG) was first implemented to enable large scale computational modeling of brain cells and circuits used to study neural function in health and disease. This new project extends NSG's utility to support development, dissemination and use of new tools by the neuroscience community for analyzing enormous data sets produced by advanced experimental methods in neuroscience.",Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software.,9882822,U24EB029005,"['Behavioral', 'Benchmarking', 'Brain imaging', 'Cells', 'Cognitive', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Development', 'Disease', 'Education', 'Education and Outreach', 'Educational workshop', 'Electroencephalography', 'Engineering', 'Environment', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Hour', 'Human Resources', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurosciences Research', 'Occupations', 'Output', 'Peer Review', 'Persons', 'Process', 'Production', 'Psychologist', 'Publications', 'Reaction Time', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Software Tools', 'Students', 'Support System', 'System', 'Testing', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Wait Time', 'Work', 'Workload', 'Writing', 'base', 'bioimaging', 'brain cell', 'collaborative environment', 'computational neuroscience', 'computerized data processing', 'computing resources', 'data sharing', 'image processing', 'interest', 'models and simulation', 'open data', 'operation', 'outreach program', 'programs', 'response', 'success', 'supercomputer', 'tool', 'tool development', 'trend', 'webinar']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2019,390806,0.002315022993873414
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9746721,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Infrastructure', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'classification algorithm', 'clinical practice', 'community involvement', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2019,334204,0.024018831571256612
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9750736,R01EB021396,"['3-Dimensional', 'Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'data pipeline', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'off-label use', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2019,434944,0.022728794852476614
"A robust platform for multiplexed, subcellular proteomic imaging in human tissue Project Summary Multiplexed Ion Beam Imaging by Time of Flight (MIBI-TOF) uses secondary ion mass spectrometry and metal conjugated primary antibodies to simultaneously visualize dozens of proteins at subcellular resolution in a single tissue section. This technology is back compatible with archival formalin fixed, paraffin embedded tissue (FFPE) and has been used in peer-reviewed work to simultaneously visualize and quantify 36 proteins in retrospective human tissue cohorts. In line with the stated goals of the HuBMAP consortium to develop both “High-sensitivity, high-resolution imaging techniques that can rapidly provide spectral data over large areas of tissue” and “Quantitative imaging analysis tools, including automated 3D image segmentation, feature extraction, and image annotation,” the work outlined here will create a standardized, high throughput, and user-friendly workflow for using MIBI-TOF in basic and translational research to gain insight into how single cell phenotype and tissue structure are functionally-linked in health and disease. To achieve this, we will validate 100 FFPE antibodies and optimize ready-to-use multiplexed staining panels in lyophilized format that will permit storage for at least two years. Protocols and reagents for multiplexed signal amplification of protein and mRNA targets will be further refined, while next generation instrumentation will increase sample throughput to permit full tissue section imaging of up to 40 proteins in 1 hour. Standardized reagents and more robust instrumentation will be accompanied by an automated computational pipeline that utilizes a standard set of segmentation markers and machine learning to accurately identify nuclei and cell borders in any non-neural human tissue. This data will be used to cluster single cell events into functionally distinct populations according to morphology, protein expression, and histological distribution. The reagents and computational pipeline proposed here synergize with existing HuBMAP-funded platforms and could be readily generalized to virtually any high dimensional imaging modality. Thus, this work will not only provide a practical, back compatible imaging platform for high throughput multiplexed imaging, but will also accelerate development of other complimentary imaging technologies as well. Project Narrative Multiplexed ion beam imaging by time of flight (MIBI-TOF) is a new technology for visualizing dozens of proteins in standard clinical tissue biopsies at high resolution. The work outlined here will create a standardized, high throughput, and user-friendly workflow for using MIBI-TOF in basic and translational research to gain insight into how single cell phenotype and tissue structure are functionally-linked in health and disease.","A robust platform for multiplexed, subcellular proteomic imaging in human tissue",9894465,UH3CA246633,"['Allergic', 'Antibodies', 'Archives', 'Area', 'Atlases', 'Back', 'Basic Science', 'Biopsy', 'Cell Nucleus', 'Cells', 'Clinical', 'Cloud Computing', 'Communities', 'Data', 'Data Set', 'Decidua', 'Development', 'Disease', 'Equipment', 'Event', 'Extramural Activities', 'Feedback', 'First Pregnancy Trimester', 'Formalin', 'Foundations', 'Freeze Drying', 'Funding', 'Goals', 'Granuloma', 'Health', 'Hippocampus (Brain)', 'Histologic', 'Hour', 'Human', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Immune', 'Immunosuppression', 'Individual', 'Institutes', 'Ions', 'Letters', 'Link', 'Machine Learning', 'Medical center', 'Messenger RNA', 'Metals', 'Morphology', 'Multiplexed Ion Beam Imaging', 'Noninfiltrating Intraductal Carcinoma', 'Optics', 'Organ', 'Paraffin Embedding', 'Pathology', 'Peer Review', 'Phenotype', 'Population', 'Proteins', 'Proteomics', 'Protocols documentation', 'Pulmonary Tuberculosis', 'Readiness', 'Reagent', 'Reproducibility', 'Resolution', 'Resources', 'Sampling', 'Scanning', 'Signal Transduction', 'Site', 'Spectrometry, Mass, Secondary Ion', 'Stains', 'Standardization', 'Structure', 'Technology', 'Three-Dimensional Image', 'Time', 'Tissue Embedding', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Work', 'cancer immunotherapy', 'cohort', 'computational platform', 'computerized tools', 'design', 'graphical user interface', 'high dimensionality', 'high resolution imaging', 'human imaging', 'human tissue', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'insight', 'instrumentation', 'ion source', 'learning strategy', 'multiplexed\xa0imaging', 'new technology', 'next generation', 'programs', 'protein expression', 'quantitative imaging', 'reagent standardization', 'technology validation', 'tool', 'tumor microenvironment', 'user-friendly', 'virtual']",NCI,STANFORD UNIVERSITY,UH3,2019,590000,-0.008347531142005512
"New instrument and methods for fast, diagnostic-quality histology of un-embedded bone marrow and lymph node specimens Project Summary Over 600,000 bone marrow biopsies are performed every year in the United States, while hundreds of thousands more lymph node biospies are performed. Histological evaluation of these biopsies is a critical component of care for hematologic diseases including leukemia, lymphoma, myelodysplastic syndrome, myeloproliferative disease and non-neoplastic conditions such as viral infections and autoimmune conditions.  We have developed a platform that we consider a paradigm shift in the histologic examination of tissues. It is based on a new chemical process, imaging, and image processing approach that we have dubbed Clearing Histology with MultiPhoton microscopy (CHiMP).The CHiMP technology enables visual analysis of entire intact, un-embedded and uncut specimens within a short time-frame and with a resolution that is amenable to primary diagnosis. The significant clinical benefits include: 1) potential for same-day diagnosis, 2) labor and cost savings, 3) access to 3D perspective, 4) increased visual data from same specimen, 5) complete tissue preservation for ancillary studies such as DNA analysis and 6) inherent benefits of digital data such as reduced risk of loss, ready remote review by experts, and amenability to machine learning tools. Hematopoietic tissue evaluation would similarly benefit from these advantages, but unfortunately the systems developed thus far lack the resolution typically needed for visual examination of hematopoietic tissues.  For this Phase I SBIR proposal, an objective is to develop customized optics to improve the resolution of our current microscopes and thereby enable use in the specialized field of hematology. Commercially available objective lenses that are compatible with our immersion medium are either limited to numerical apertures (NA) that are less than one, affecting resolution and image quality, or have insufficient working distances for imaging past the coverslip and surface roughness to obtain complete sections. We will design and test a custom objective lens with high NA and long working distance, suited for our proprietary reagents. Integrating such a lens into our microscope will also require the design of a custom scan lens, custom beam conditioning optics, and a custom polygon scanner.  An associated goal is to develop a novel approach to preparing bone marrow aspiration specimens that will make them amenable to imaging with CHiMP, potentially reducing the need for core biopsies by permitting unambiguous morphologic categorization of cell subtypes in their architectural context, without the routine need for immunohistochemistry, and while preserving nucleic acids for molecular/genetic evaluation. Project Narrative Applikate Technologies has developed a powerful platform for histological evaluation of tissue called Clearing Histology with MultiPhoton Microscopy, or CHiMP. This platform has many advantages over traditional approaches, including same-day turn-around, reduced labor costs, preservation of tissue for DNA analysis, and direct-to-digital imaging for ease of consultation with remote experts. This proposal seeks to develop custom optics to enable very-high-resolution imaging of bone marrow and lymph node samples that are critical for diagnosing diseases such as leukemia and lymphoma.","New instrument and methods for fast, diagnostic-quality histology of un-embedded bone marrow and lymph node specimens",9677952,R43CA235890,"['3-Dimensional', 'Address', 'Adoption', 'Affect', 'Ancillary Study', 'Antigens', 'Architecture', 'Aspirate substance', 'Autoimmune Diseases', 'Autoimmune Process', 'Biopsy', 'Blinded', 'Bone Marrow', 'Bone Marrow Aspiration', 'Bone marrow biopsy', 'Caring', 'Cells', 'Chemicals', 'Chronic', 'Clinical', 'Clinical Data', 'Communicable Diseases', 'Consultations', 'Consumption', 'Core Biopsy', 'Cost Savings', 'Custom', 'DNA', 'DNA analysis', 'Data', 'Decalcification', 'Diagnosis', 'Diagnostic', 'Disease', 'Dysmyelopoietic Syndromes', 'Evaluation', 'Fibrosis', 'Goals', 'Hematological Disease', 'Hematology', 'Hematopathology', 'Histologic', 'Histology', 'Image', 'Imagery', 'Immersion Investigative Technique', 'Immunohistochemistry', 'Iron', 'Lateral', 'Lymph', 'Machine Learning', 'Marrow', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Molecular Genetics', 'Morphologic artifacts', 'Morphology', 'Myeloproliferative disease', 'Nucleic Acids', 'Optics', 'Pan Genus', 'Pathologist', 'Pathology', 'Phase', 'Preparation', 'Process', 'Protocols documentation', 'RNA', 'Reagent', 'Recovery', 'Resolution', 'Risk', 'Sampling', 'Scanning', 'Slice', 'Slide', 'Small Business Innovation Research Grant', 'Specimen', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Preservation', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'United States', 'Virus Diseases', 'Visual', 'Waxes', 'Work', 'base', 'bone imaging', 'conditioning', 'cost', 'design', 'digital', 'digital imaging', 'disease diagnosis', 'hematopoietic tissue', 'high resolution imaging', 'image processing', 'improved', 'instrument', 'lens', 'leukemia/lymphoma', 'lymph nodes', 'medical specialties', 'multiphoton microscopy', 'nanoparticle', 'novel', 'novel strategies', 'particle', 'pre-clinical', 'preservation', 'second harmonic', 'tool', 'whole slide imaging']",NCI,"APPLIKATE TECHNOLOGIES, LLC",R43,2019,224713,0.001522842896942855
"Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers ﻿    DESCRIPTION (provided by applicant): The Quantitative Imaging Network (QIN) is a consortium of centers developing quantitative image features, which are proving to be valuable biomarkers of the underlying cancer biology and that can be used for assessing response to treatment and predicting clinical outcome. It is now important to discover the best quantitative imaging features for detection of response to therapeutics, to identify subtypes of cancer, and to correlate with cancer genomics. However, progress is thwarted by the lack of shared software algorithms, architectures, and resources required to compute, compare, evaluate, and disseminate these quantitative imaging features within the QIN and the broader community. We propose to develop the Quantitative Imaging Feature Pipeline (QIFP), a cloud-based, open source platform that will give researchers free access to these capabilities and hasten the introduction of quantitative image biomarkers into single- and multi-center clinical trials. The QIFP will facilitate assessment of the incremental value of new vs. existing image feature sets. It will also allow researchers to add their own algorithms to compute novel quantitative image features in their own studies and to disseminate them to the greater research community. To accomplish this: (1) We will create an expandable library of quantitative imaging feature algorithms capable of comprehensive characterization of the imaging phenotype of cancer. It will support a broad set of imaging modalities and algorithms implemented in a variety of languages, including algorithms that provide volumetric and time-varying assessment of lesion size, shape, edge sharpness, and pixel statistics. (2) We will build a cloud-based software architecture for creating, executing, and comparing quantitative image feature-generating pipelines, including algorithms in the library and/or those supplied by QIN or other researchers as plug-ins. QIFP will also have (a) a machine learning engine that lets users specify a dependent variable (e.g., progression-free survival) that the quantitative image features can used to predict, and (b) an evaluation engine that compares the utility of particular features for predicting the dependent variable. (3) We will assess the QIFP in four ways: (a) by its ability to recapitulate the role of known biomarkers in a related clinical trial, (b) by comparing linear measurement, metabolic tumor burden and novel combinations of the features in our library for predicting one-year progression-free survival, (c) by merging imaging features with known host-, drug- and tumor-based follicular lymphoma biomarkers in order to develop the most robust and integrative predictive model for patient outcomes, and (d) by using the QIFP to combine and to evaluate image feature algorithms developed by another QIN team and our own NCI- funded team in the study of radiogenomics of non-small cell lung cancer. The QIFP will fill a substantial gap in the science currently being carried out in the QIN and in the community by providing the tools and infrastructure to assess the value of novel quantitative imaging features of cancer, and will thereby accelerate incorporating new imaging biomarkers into single and multi-center clinical trials and into oncology practice. PUBLIC HEALTH RELEVANCE: We propose to develop and evaluate a software platform that has major relevance for human health. Many investigators are pursuing image-based surrogates for response to therapy that could be used in clinical trials to predict their success/failure earlier and that are more accurate than existing surrogates. Our developments will facilitate sharing, assessing, and comparing combinations of image feature-generating software algorithms for predicting treatment response, survival, and tissue genomics, which will, in turn, greatly accelerate the development and acceptance of new and more relevant imaging surrogates for assessing cancer treatments.","Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers",9753130,U01CA187947,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Cancer Biology', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computational algorithm', 'Computer software', 'Data', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Eastern Cooperative Oncology Group', 'Evaluation', 'Failure', 'Follicular Lymphoma', 'Funding', 'Gene Expression', 'Generations', 'Genomics', 'Health', 'Human', 'Image', 'Infrastructure', 'Investigation', 'Java', 'Language', 'Lesion', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Metabolic', 'Modality', 'Modernization', 'Molecular', 'Multi-Institutional Clinical Trial', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patient-Focused Outcomes', 'Pharmaceutical Preparations', 'Phenotype', 'Plug-in', 'Positron-Emission Tomography', 'Prediction of Response to Therapy', 'Privatization', 'Progression-Free Survivals', 'Pythons', 'RNA Sequences', 'Radiogenomics', 'Research', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Specific qualifier value', 'System', 'Therapeutic', 'Time', 'Tissues', 'Tumor Burden', 'base', 'cancer biomarkers', 'cancer genomics', 'cancer imaging', 'cancer subtypes', 'cancer therapy', 'clinical predictors', 'cloud based', 'disorder subtype', 'feature detection', 'image archival system', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'novel', 'novel therapeutics', 'oncology', 'open source', 'predict clinical outcome', 'predictive modeling', 'public health relevance', 'quantitative imaging', 'repository', 'response', 'specific biomarkers', 'statistics', 'success', 'survival prediction', 'tool', 'treatment response', 'tumor', 'vector', 'web based interface']",NCI,STANFORD UNIVERSITY,U01,2019,567509,0.011378146160068691
"LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research PROJECT SUMMARY Imaging forms the backbone of living subjects research. Living subjects research is both essential to the progress of translational medicine and very expensive. The research community actively seeks to develop and validate new clinical endpoints to solve a range of etiology, natural history, diagnostic and prognostic problems. This project aims to develop and commercialize LATTICE, an Electronic Research Record, Image Management and Sharing Solution, and Deep Learning Platform. LATTICE is designed to increase the efficiency of imaging-driven biomedical research and clinical trials. This efficiency is accomplished first through a structured workflow that includes protocol management, subject scheduling, and records collection from multiple imaging modalities. Access to imaging and associated data within the same workflow simplifies the process for the research team. Structuring the data into a de-identified, privacy-managed Image Bank enables sharing for collaboration and re-use for retrospective research. Image processing algorithms connected to the Image Bank facilitate batch analysis, while the system also provides a platform for the development of new image-based outcome measures and clinical endpoints. A key objective of LATTICE is to enable investigators and collaborators to accelerate the translation of insights to the clinic with maximum efficiency. Successful translation requires structuring the workflow, record keeping, and protocols into a rigorous, transparent, reproducible and validated process. LATTICE is designed to reduce the friction in translating successful research projects to the clinic. Researchers in the Advanced Ocular Imaging Program (AOIP) at the Medical College of Wisconsin developed elements of LATTICE as separate technologies. The Specific Aims of this proposal are directed to an integrated workflow addressing a broader set of objectives. The AOIP LATTICE Electronic Research Record will be translated into a commercially managed repository and brought under regulatory Design Control. The current AOIP Image Bank containing 3,000,000 de- identified retinal images will be integrated into the LATTICE workflow. Critically, this integration will allow the sharing of the Image Bank with external researchers. Three retinal image process algorithms that operate on retinal images will integrate into this workflow. These algorithms include analysis of adaptive optics images of the fundus, analysis of the foveal avascular zone from optical coherence tomography angiography (OCTA), and model-based analysis of the fovea imaged with OCT. A computational deep learning workflow will also be prototyped using a cloud-based architecture. This final workflow will be constructed to demonstrate the feasibility of deploying a collaborative deep learning environment for the development of new clinical endpoints using shared, de-identified images. LATTICE will be a unique system for both prospective and retrospective translational research. LATTICE will make a profound impact on the cost of managing image-based research and add leverage to translational research expenditures for moving insights into the clinic. PROJECT NARRATIVE LATTICE is an innovative electronic research record and development platform for image-based ophthalmic research. LATTICE is designed to reduce the cost of translational research, promote the re- use of images, and simplify the development and application of new techniques to analyze medical images. LATTICE will integrate research workflow tools with a database of 3,000,000 retinal images and advanced image processing software to accelerate the process of translating eye research insights from the lab to the clinic.",LATTICE: A Software Platform for Prospective and Retrospective Image Based Translational Research,9777970,R43EY030408,"['Address', 'Algorithmic Software', 'Algorithms', 'Angiography', 'Architecture', 'Biomedical Research', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Data', 'Databases', 'Development', 'Diagnostic', 'Documentation', 'Elements', 'Etiology', 'Expenditure', 'Eye', 'Friction', 'Future', 'Health Insurance Portability and Accountability Act', 'Image', 'Libraries', 'Medical Imaging', 'Methods', 'Modeling', 'Morphology', 'Natural History', 'Optical Coherence Tomography', 'Outcome Measure', 'Output', 'Privacy', 'Process', 'Protocols documentation', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Scanning', 'Schedule', 'Secure', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Translational Research', 'Translations', 'Vertebral column', 'Wisconsin', 'Writing', 'adaptive optics', 'base', 'cloud based', 'cost', 'deep learning', 'design', 'educational atmosphere', 'fovea centralis', 'fundus imaging', 'image processing', 'imaging modality', 'imaging platform', 'imaging program', 'innovation', 'insight', 'medical schools', 'ocular imaging', 'operation', 'prognostic', 'programs', 'prospective', 'prototype', 'repository', 'retinal imaging', 'system architecture', 'tool', 'translational medicine', 'web services', 'wiki']",NEI,"TRANSLATIONAL IMAGING INNOVATIONS, INC.",R43,2019,299999,0.011966827993857189
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9761481,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2019,873369,-0.02035267935184431
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,9740493,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Augmented Reality', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Imagery', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Visual', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'tool', 'trend', 'virtual reality', 'web services']",NIBIB,"KITWARE, INC.",R01,2019,508446,0.011455911327308596
"Expanding field-of-view with reduced tissue displacement in micro-endoscopic computational imaging PROJECT SUMMARY Optical imaging methods are well-established in neuroscience, but high-speed, high- resolution volumetric imaging of neural activity in deep tissue remains a challenge. A number of techniques address limited aspects of this goal, and most are applicable primarily to acute preparations. We propose to develop and test a novel approach to achieve three-dimensional “deep-tissue” imaging for high spatial and temporal resolution neural recording by combining aspects of embedded optical probes with computational imaging techniques. Rather than use a single micro-endoscopic probe, we propose to utilize an array of narrower probes, or optrodes, to reduce the volume of tissue displacement. Computational imaging through each probe can be performed to achieve a field of view (FOV) at a desired distance from the probe tip. Combining the fields of view from multiple probes arranged in an array then provides a composite image field that is much larger than achievable from a single micro-endoscope. In our approach, each ∼0.1 mm diameter probe of the array acts as an independent micro- endoscope. In order to achieve full-field imaging across the array, the individual fields must intersect, and the computational method must be scaled to accommodate, and stitch, multiple fields. In pursuit of these goals, we propose three Aims: Optimizing the FOV of a single micro-endoscope - The purpose of this Aim is to characterize the FOV for an individual probe at multiple depths, and optimize the FOV to about 0.3mm through control over the shape of the probe tip and light collection numerical aperture. Accelerating calibration and reconstruction - In this Aim, we will pursue efficient computational approaches for calibration based upon ray-tracing simulations and image reconstruction based on deep learning. Scaling the FOV with an endoscope array - The computational image reconstruction method will be scaled to accommodate small micro-endoscope arrays (e.g. 4 element) arranged in a hexagonal lattice with FOV of 0.6mm at a 1.5mm depth. NARRATIVE Imaging deep inside tissue, including the brain, is critical to understanding various biological processes. Doing so through a small probe is also of primary importance for minimizing tissue damage. In this proposal, we apply computational techniques to create fluorescent images using an array of microscopic glass needles to guide light in and out of a mouse brain. The simplicity and small footprint of our system have the potential for deep-brain imaging (depths > 1.5 mm) across a large (mm) field of view, which should enable a wide variety of biological and neuroscience studies in the future.",Expanding field-of-view with reduced tissue displacement in micro-endoscopic computational imaging,9829467,R21EY030717,"['3-Dimensional', 'Acute', 'Address', 'Biological', 'Biological Process', 'Brain', 'Brain imaging', 'Caliber', 'Calibration', 'Collection', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Confocal Microscopy', 'Coupled', 'Devices', 'Dimensions', 'Elements', 'Endoscopes', 'Fluorescence Microscopy', 'Fluorescent Probes', 'Future', 'Glass', 'Goals', 'Head', 'Holography', 'Image', 'Imaging Techniques', 'Individual', 'Light', 'Methods', 'Microscope', 'Microscopic', 'Microscopy', 'Miniaturization', 'Mus', 'Needles', 'Neurosciences', 'Optics', 'Penetration', 'Preparation', 'Resolution', 'Risk', 'Running', 'Scanning', 'Shapes', 'Source', 'Speed', 'System', 'Techniques', 'Testing', 'Time', 'Tissue imaging', 'Tissues', 'Work', 'absorption', 'adaptive optics', 'attenuation', 'base', 'cost', 'deep learning', 'fluorescence imaging', 'image reconstruction', 'imaging modality', 'improved', 'in vivo', 'interest', 'lens', 'microendoscope', 'multi-photon', 'neural circuit', 'novel strategies', 'optical fiber', 'optical imaging', 'reconstruction', 'relating to nervous system', 'retinal rods', 'simulation', 'temporal measurement']",NEI,UNIVERSITY OF UTAH,R21,2019,456800,-0.008766544509373007
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. ​A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,9787575,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Imagery', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Structure', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'autism spectrum disorder', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'learning strategy', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2019,291536,0.004470445256050238
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive, PhysioBank, was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. PhysioToolkit, its software collection, supports exploration and quantitative analyses of PhysioBank and similar data with a wide range of well-documented, rigorously tested open-source software that can be run on any platform. PhysioNet's team of researchers leverages results of other funded projects to drive the creation and enrichment of: i) Data collections that provide increasingly comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC III (Medical Information Mart for Intensive Care) Database of critical care patients; ii) Analytic methods that lead to more timely and accurate diagnoses of major public health problems (such as life-threatening cardiac arrhythmias, infant apneas, fall risk in older individuals and those with neurologic disease, and seizures), and iii) Elucidation of dynamical changes associated with a variety of pathophysiologic processes and aging (such as cardiopulmonary interactions during sleep disordered breathing syndromes); User interfaces, reference materials and services that add value and improve accessibility to PhysioNet's data and software (such as PhysioNetWorks, a virtual laboratory for data sharing). Impact: Cited in The White House Fact Sheet on Big Data Across the Federal Government (March 29, 2012), PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are inaccessible otherwise. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world- wide, growing community of researchers, clinicians, educators, students, and medical instrument and software developers, retrieve about 380 GB of data per day. By providing free access to its unique and wide-ranging data and software collections, PhysioNet is invaluable to studies that currently result in an impressive average of nearly 250 new scholarly articles per month by academic, clinical, and industry-affiliated researchers worldwide. Over the next year we aim to sustain and enhance PhysioNet's impact with new technology and data; and complete the 2019 PhysioNet/Computing in Cardiology Challenge on sepsis. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,9993811,R01GM104987,"['Aging', 'Algorithms', 'Apnea', 'Area', 'Arrhythmia', 'Big Data', 'Biomedical Research', 'Boston', 'Bypass', 'Cardiology', 'Cardiopulmonary', 'Categories', 'Clinical', 'Clinical Data', 'Cloud Service', 'Collection', 'Communities', 'Community Outreach', 'Complex', 'Computer software', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Dedications', 'Development', 'Diagnostic radiologic examination', 'Entropy', 'FAIR principles', 'Federal Government', 'Functional disorder', 'Funding', 'Grant', 'Imagery', 'Individual', 'Industry', 'Infant', 'Infrastructure', 'Intensive Care', 'Israel', 'Journals', 'Laboratories', 'Lead', 'Licensing', 'Life', 'Link', 'Machine Learning', 'Maintenance', 'Medical', 'Medical center', 'Methods', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Pharmaceutical Preparations', 'Phase Transition', 'Physiological', 'Process', 'Public Health', 'Publishing', 'Radiology Specialty', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Roentgen Rays', 'Role', 'Running', 'Seizures', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Students', 'Switzerland', 'Syndrome', 'Testing', 'Thoracic Radiography', 'Time', 'United States National Institutes of Health', 'University Hospitals', 'Visit', 'accurate diagnosis', 'analytical method', 'clinical application', 'computerized data processing', 'computing resources', 'data archive', 'data sharing', 'experience', 'fall risk', 'heart rate variability', 'improved', 'innovation', 'instrument', 'instrumentation', 'interest', 'member', 'nervous system disorder', 'new technology', 'open source', 'preservation', 'repository', 'signal processing', 'software repository', 'symposium', 'time interval', 'virtual laboratory']",NIGMS,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2019,409563,-0.01423884081147121
"Automated Diagnosis and Progression Rate of IPF Using HRCT Project Summary: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. Diagnosis and stratification of disease phenotypes are important in order to decipher the effects of novel therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individuals. Few computerized diagnostic tools have been developed for IPF that correlate with visual and surgical lung biopsy; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good predictive models with localized region exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use as a derivative dataset the anonymized clinical data and source images on 234 patients with IPF and 266 patients with IPF suspected, but not IPF based on HRCT and the surgical biopsy who have participated in multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for high through-put quantitative image analysis, we will train a classifier with features of anatomic distribution and reproducible imaging features expressed with a quantitative lung fibrosis (QLF) score, testing on separate data from in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitial Lung Disease Program. Furthermore, the second aim is to develop a rate of progression at local region and to aggregate predictive models using Cox proportional regression models, which will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that diagnose and anticipate disease course in patients with IPF and subdividing patients into more homogeneous groups prior to the development of significant respiratory impairment. We anticipate that models can be used clinically at the individual patient level to enable more informed and timely management decisions to define more homogeneous cohorts for purposes of testing new targeted therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. Relevance to Public Health: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rate of progression is highly variables, which hampers timely decisions about referral for lung transplantation or treatments using new drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to diagnose and predict disease course robustly in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with IPF and non-IPF with reducing chance of lung biopsy and predict slowly versus rapidly progressive disease, leading to more time to treat patients and timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Automated Diagnosis and Progression Rate of IPF Using HRCT,9765383,R21HL140465,"['Acute', 'Air', 'Algorithms', 'Anatomy', 'Archives', 'Automation', 'Biological', 'Biopsy', 'Categories', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease stratification', 'Elderly', 'Etiology', 'Exhibits', 'General Population', 'Glass', 'Goals', 'Growth', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Informatics', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Laboratories', 'Lobar', 'Lobe', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathology', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Prevalence', 'Probability', 'Progression-Free Survivals', 'Progressive Disease', 'Public Health', 'Pulmonary Fibrosis', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Spatial Distribution', 'Stable Disease', 'Standardization', 'Testing', 'Texture', 'Time', 'Time Management', 'Training', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinically relevant', 'cohort', 'computerized', 'data archive', 'digital imaging', 'disease natural history', 'disease phenotype', 'functional decline', 'idiopathic pulmonary fibrosis', 'image processing', 'imaging biomarker', 'improved', 'individual patient', 'individualized medicine', 'new therapeutic target', 'novel', 'novel therapeutics', 'predictive modeling', 'prognostic', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'success', 'survival prediction', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2019,113241,-0.034741579970470574
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE MC-IU effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing, exploration, and download of different types of tissue and individual cell data. The CCF will use different visual interfaces in order to exploit human and machine intelligence to improve data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, biology, and biomedical data standards. The goal is to develop a highly accurate and extensible multidimensional spatial basemap of the human body with associated data overlays. This basemap will be designed for online exploration as an atlas of tissue maps composed of diverse cell types, developed in close collaboration with the HIVE MC-NYGC team. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across multiple levels (whole body, organ, tissue, cells). MC-IU will work in close collaboration with the HIVE Infrastructure and Engagement Component (IEC) and tools components (TCs) to connect and integrate further computational, analytical, visualization, and biometric resources driven by spatial context. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an ex- tensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spa- tial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high- resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector and Meta Datasets",9919259,OT2OD026671,"['Anatomy', 'Artificial Intelligence', 'Atlases', 'Biology', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Collaborations', 'Communication', 'Data', 'Data Set', 'Ecosystem', 'Goals', 'Human', 'Human body', 'Image', 'Imagery', 'Individual', 'Infrastructure', 'Maps', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Organ', 'Resolution', 'Resources', 'Tissues', 'Visual', 'Work', 'base', 'cell type', 'design', 'human imaging', 'improved', 'interoperability', 'tool', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2019,600000,-0.017406447204375786
"3-D Imaging Flow Cytometry PROJECT SUMMARY This project aims to develop and test two innovative platforms and related software for 3-D imaging flow cytometry of fluorescent or absorbing (stained) samples. These systems will allow 3-D structural and functional imaging of many single cells at a subcellular resolution and at a scale that used to be available only in flow cytometry or recently in 2-D imaging. Thereby, the proposed methods have the potential to fundamentally change the ways cultured cells, patient-derived samples, and small experimental organisms are studied. Automated classification based on the 3-D features will enable the diagnosis of hematologic disorders at single-cell precision. Existing 3-D microscopy methods can provide the same information at higher resolution; however, by relying on a scanning mechanism they cannot be applied to suspending cells, especially in a flow configuration, which is essential for high-speed interrogation. Snapshot 3-D microscopy techniques have been developed to address this challenge, but they have insufficient spatial resolution for single-cell imaging and suffer from long data processing time. We overcome these limitations by combining two novel snapshot techniques developed by the PI with the most rigorous optical imaging theories and cutting-edge component technologies. We will use an array of lenslets, which simultaneously records many projection images corresponding with different viewing angles. The use of pupil phase masks, designed using wavefront coding and a theory of 3-D high-numerical-aperture optical imaging, will increase the resolution of each projection image to the theoretical limit given by the objective-lens numerical aperture. The target resolution is 0.5 µm, which is comparable to existing 2-D imaging flow cytometry systems. The target imaging throughputs based on current component technologies are 120 volumes/sec for fluorescence imaging and 700 volumes/sec for absorption imaging, which are higher than 100 volumes/sec of cutting-edge 3-D optical microscopy for stationary specimens. The vast amount of data acquired by these 3-D imaging systems imposes a serious challenge to data processing. The developed systems record true projection images, which obviate iterative deconvolution process, thereby allowing much faster tomographic reconstruction than in existing snapshot techniques. Using general-purpose graphics processing units and optical diffraction tomography, which includes the diffraction of light by subcellular organelles, our tomographic reconstruction algorithm will be faster yet more accurate than existing approaches. Further, we will explore the feasibility of applying a deep convolutional neural network to the images acquired by the developed systems for accurate single-cell classification based on 3-D features. PROJECT NARRATIVE This project aims to develop 3-D imaging flow cytometry platforms for fluorescent or absorbing (stained) cells at high resolution and high throughput in a flow configuration. The developed systems will be built upon two novel snapshot 3-D techniques developed by the PI in combination with most rigorous 3-D optical imaging theories and cutting-edge component technologies. The proposed methods have the potential to fundamentally change the ways that biological specimens are examined by allowing 3-D structural and functional imaging of suspending cells at a scale that used to be available only in flow cytometry or 2-D imaging.",3-D Imaging Flow Cytometry,9877321,R21GM135848,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Biological', 'Blood', 'Blood specimen', 'Cells', 'Classification', 'Code', 'Computer software', 'Cultured Cells', 'Data', 'Diagnosis', 'Dimensions', 'Flow Cytometry', 'Functional Imaging', 'Geometry', 'Hematological Disease', 'Holography', 'Image', 'Laboratory Organism', 'Leukocytes', 'Lifting', 'Lighting', 'Masks', 'Methods', 'Microscope', 'Microscopy', 'Optical Tomography', 'Optics', 'Organelles', 'Patients', 'Phase', 'Process', 'Pupil', 'Records', 'Resolution', 'Sampling', 'Scanning', 'Specimen', 'Speed', 'Stains', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Work', 'absorption', 'base', 'cellular imaging', 'commercialization', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'diffraction of light', 'digital', 'fluorescence imaging', 'imaging system', 'innovation', 'lens', 'novel', 'optical imaging', 'reconstruction', 'software development', 'targeted imaging', 'theories', 'three dimensional structure', 'tomography']",NIGMS,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2019,195110,-0.0023948602634060504
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,9886087,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Quality', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Drug effect disorder', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'deep learning', 'denoising', 'detector', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2019,344862,0.01436356976787397
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9784742,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data pipeline', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2019,533529,0.027591184462099932
"UC Davis Alzheimer's Core Center PROJECT SUMMARY/ABSTRACT As reflected in recent budget increases in the National Institutes of Health, and in line with the National Alzheimer’s Project Act, there is a need to enhance and leverage resources to decrease dementia disparities and change the trajectory of Alzheimer’s disease and related dementias. To fill this gap, we seek to enhance the University of California Davis Alzheimer’s Disease Center (UCD ADC), which contains a diverse ethnoracial cohort (having Hispanic, Black, and non-Hispanic White decedents), through implementation of digital pathology within our Neuropathology Core. This implementation will allow for rapid transmission of pathological data for consultation and collaborations, distribution of materials for educational purposes, tissue specimen archiving, and image analysis. In addition, by having a digital pathology with immunofluorescent capabilities will allow for viewing of the distribution (including overlap) of multiple proteins at one time within a tissue specimen. This can enhance biological studies by providing spatial relationships of proteins resulting in a deeper phenotype of disease. This supplement application is designed to support equipment and leverage and enhance infrastructure to allow the UCD ADC the ability to 1) purchase a whole slide image system to digitize existing and future histologically stained samples 2) leverage and enhance current servers and database systems to allow for storage and rapid retrieval of digital images and their data and 3) leverage and enhance hardware to develop and deploy pipelines for quantitative computational methodologies for pathologies found within a diverse ethnoracial cohort of Alzheimer’s disease brains. The UCD ADC continues to excel and expand in its research initiatives to collect and provide brain specimens and pathological data on a diverse population of individuals at various stages of cognitive ability and dementia risk. This supplement will further enable suitable infrastructure for enhancement of current collaborations and facilitate emerging collaborations by providing a means to share and analysis pathology on digitized whole slide images. PROJECT NARRATIVE Digital microscopy paired with machine learning algorithms has aided in diagnosis and provide more quantitative pathology data to unlock the secrets of diseases. These technologies are needed within the dementia field, specifically in diverse cohorts, as disease presentations may differ. By implementing state of the art imaging systems and analysis, the goals of this supplement are to enhance the ADC’s ability to provide greater access to high quality pathological data for educational, consultation and collaborative purposes, infrastructure to pursue digital solutions for more quantitative analysis, and safe secure storage of histologic specimens.",UC Davis Alzheimer's Core Center,9852188,P30AG010129,"['Age', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Archives', 'Autopsy', 'Back', 'Basic Science', 'Biological', 'Brain', 'Brain Diseases', 'Budgets', 'California', 'Clinical', 'Collaborations', 'Communities', 'Complex', 'Computing Methodologies', 'Consultations', 'Data', 'Database Management Systems', 'Dementia', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Educational Materials', 'Equipment', 'Extramural Activities', 'Future', 'Generations', 'Genetic', 'Genetic Variation', 'Glass', 'Glean', 'Goals', 'Grant', 'Heterogeneity', 'Hispanics', 'Image', 'Image Analysis', 'Immunofluorescence Immunologic', 'Individual', 'Infrastructure', 'Infusion procedures', 'Knowledge', 'Measurement', 'Measures', 'Medical Genetics', 'Methods', 'Microscope', 'Microscopy', 'Modernization', 'Neurodegenerative Disorders', 'Not Hispanic or Latino', 'Outcome', 'Paper', 'Pathologic', 'Pathologist', 'Pathology', 'Phenotype', 'Population Heterogeneity', 'Proteins', 'Publishing', 'Research', 'Research Infrastructure', 'Resources', 'Retrieval', 'Sampling', 'Scientist', 'Secure', 'Senile Plaques', 'Slide', 'Specimen', 'Stains', 'Structure', 'Systems Analysis', 'Technology', 'Thioflavin S', 'Time', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Work', 'analysis pipeline', 'base', 'beta pleated sheet', 'cognitive ability', 'cohort', 'cost effective', 'data resource', 'data sharing', 'dementia risk', 'design', 'digital', 'digital imaging', 'digital pathology', 'disease phenotype', 'histological specimens', 'histological stains', 'human tissue', 'imaging system', 'machine learning algorithm', 'neuropathology', 'novel therapeutic intervention', 'spatial relationship', 'synergism', 'transmission process', 'whole slide imaging']",NIA,UNIVERSITY OF CALIFORNIA AT DAVIS,P30,2019,289154,-0.031025521758589955
"Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD ABSTRACT The goal of this NIDDK Mentored Research Scientist Development Award is to provide an organized scientific and educational environment for Dr. Timothy Kline to begin his transition into an independent research career focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. This proposal outlines a five-year training plan at Mayo Clinic under the primary mentorship of Dr. Bradley Erickson and a Mentoring Team comprised of accomplished researchers in the fields of: biology, nephrology, genetics, radiology, informatics; medical physics, biostatistics, image processing, and physiology. The focus of this proposal is to improve both research studies and disease prognosis for autosomal dominant polycystic kidney disease (ADPKD) patients through biomedical imaging techniques. It is well understood that imaging is essential for ADPKD diagnosis, monitoring, and outcome prediction. Clinical studies utilize total kidney volume (TKV) (as measured by MRI as an image-based biomarker) to follow the progression of ADPKD, as larger TKVs have been shown to correlate with worse prognosis in both human and animal-model studies. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming, costly, and poorly standardized. The introduction of automated approaches for measuring TKV will: greatly improve measurement throughput, significantly reduce costs associated with performing research studies, allow accurate and reproducible measurements to be obtained both within and across institutions; facilitate the search for new imaging biomarkers. The specific aims of this project are to: (i) develop and validate automated tools to characterize renal structure, such as TKV and cystic burden; (ii) explore new imaging biomarkers by image texture feature analysis and pattern recognition techniques; and (iii) develop a new technique to measure renal blood flow. This research will be facilitated by Mayo Clinic's outstanding clinical and research environment dedicated to improving patient care, as well as the Mayo Clinic Translational PKD Center, which focuses on translating basic science research into improvements in the management and treatment of ADPKD patients. Dr. Kline's background in imaging technologies and image processing makes him particularly suited to perform this research. In addition to the above aims, Dr. Kline will: 1) develop a strong knowledge base in both nephrology and radiology by attending relevant rounds, seminars, and national conferences; 2) enhance his knowledge of medical imaging, biology, physiology, genetics, and programming through coursework and mentoring; 3) attend workshops focused on grant and publication writing; and 4) submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of new imaging biomarkers of ADPKD. Obtaining this K Award will greatly facilitate Dr. Kline's transition into a prosperous independent research career. Narrative Autosomal dominant polycystic kidney disease (ADPKD) is one of the most common monogenic disorders and is a leading cause of end-stage renal disease. Total kidney volume (TKV) has become the main image-based biomarker for following ADPKD progression. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming and costly. This project will develop automated tools to increase measurement throughput, and explore new image-based biomarkers that will significantly add to the assessment of patient prognosis, and will have the ability to more quickly judge the effectiveness of interventions.",Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD,9782929,K01DK110136,"['3-Dimensional', 'Abdomen', 'Affect', 'Age', 'Anatomy', 'Animals', 'Architecture', 'Area', 'Autosomal Dominant Polycystic Kidney', 'Basic Science', 'Biological Markers', 'Biology', 'Biometry', 'Blood Vessels', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Consumption', 'Cyst', 'Data', 'Databases', 'Disease', 'Disease Marker', 'Disease Progression', 'Educational workshop', 'Effectiveness of Interventions', 'End stage renal failure', 'Environment', 'FarGo', 'Fibrosis', 'Genetic', 'Genetic Programming', 'Geometry', 'Goals', 'Gold', 'Grant', 'Hepatic Cyst', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Informatics', 'Institution', 'Intervention', 'K-Series Research Career Programs', 'Kidney', 'Knowledge', 'Liver', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Mendelian disorder', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Microscopic', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrology', 'Organ', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Physics', 'Physiologic pulse', 'Physiology', 'Polycystic Kidney Diseases', 'Process', 'Protocols documentation', 'Publications', 'Radiology Specialty', 'Renal Blood Flow', 'Renal Tissue', 'Renal function', 'Reproducibility', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Spin Labels', 'Standardization', 'Structure', 'Study models', 'Suggestion', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'Writing', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'disease diagnosis', 'educational atmosphere', 'functional decline', 'human model', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'insight', 'interest', 'kidney vascular structure', 'knowledge base', 'novel imaging technology', 'outcome forecast', 'outcome prediction', 'precision medicine', 'pressure', 'prognostic value', 'radiological imaging', 'renal artery', 'research study', 'shear stress', 'symposium', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,K01,2019,154915,-0.0008827937811928445
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9600285,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biological Neural Networks', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imagery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Work', 'base', 'clinical effect', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2018,194115,0.027429427818161798
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9521289,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2018,471965,-0.007050063976913783
"Extracting rich information from biological images Project Summary  Most laboratories studying biological processes and human disease use microscopes to image samples. Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.  The principal investigator envisions bringing transformative image analysis and machine learning algorithms and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in 3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­ scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image analysis into complex workflows with other software for microscope control, cloud computing, and data mining.  The PI will also pioneer novel algorithms and approaches changing the way images are used in biology, including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines. Public Health Relevance/Narrative Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering computational techniques and software that will change the way microscopy images are used in biology. Biologists will use the resulting software to tackle fundamentally new problems using quantitative image analysis, including detecting changes in the appearance of cells that are overlooked by human vision and studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the context of dozens of projects addressing important fundamental biological questions and world health problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source image analysis software, CellProfiler.",Extracting rich information from biological images,9708392,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,128747,0.06191872781642476
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9474630,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2018,695400,0.06437222279711453
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9518217,R01HL142036,"['Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Simulation', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Dimensions', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2018,392932,-0.002069720488149189
"Image analytics prediction of corneal keratoplasty failure Image analytics for prediction of keratoplasty failure Summary We will create specialized image analytics software for prediction of keratoplasty (penetrating, endothelial) fail- ure from specular-reflection corneal endothelial cell (EC) images. Keratoplasties are the most common tissue transplant, with roughly a 10% failure rate, leading to blindness, patient discomfort/anxiety, and repeat kerato- plasties with a higher chance for failure than the initial procedure. With successful predictive image analytics, we will be in a position to identify transplanted corneas at risk and possibly treat them more aggressively with topical corticosteroids or other measures to prevent failure. Since a functional endothelial cell (EC) layer is necessary for the active ionic-pump-driven redistribution of fluid necessary to maintain the clear cornea, EC images have been analyzed as an indicator of cornea health. The normal EC layer exhibits high cell density arranged in a predominantly regular, hexagonal array. We will build on the use of existing quantitative bi- omarkers from EC images (EC density, coefficient of variation of cell areas, and hexagonality) used to evaluate cornea health. We will compute additional image features associated with local and long-range cell disarray, image attributes relevant to keratoplasty rejection, and traditional features from computer vision. Including this combination of features will provide rich inputs to machine-learning classifiers aimed at predicting future out- comes (e.g., failure or no failure). We will apply methods to a large aggregation of well-curated data from pre- vious NIH-funded studies at Case Western Reserve University (CWRU) and from previous studies at the Neth- erlands Institute for Innovative Ocular Surgery (NIIOS). Our team consists of image processing experts, oph- thalmologists, and staff from the CWRU Department of Ophthalmology and Visual Sciences and University Hospitals (UH) Eye Institute’s Cornea Image Analysis Reading Center (CIARC), which is well-known for rigor- ous, highly repeatable assessment of conventional quantitative biomarkers in a large number of multi- institutional clinical trials. Together, our goal will be to determine if this “second generation” analysis of EC im- ages can lead to prediction of keratoplasty failure. If successful, this project will lead to software which can be translated to support research and clinical practice. Narrative Our goal is to create image analytic software that will predict the risk of keratoplasty failure from readily ob- tained corneal endothelial cell images. With knowledge of eyes at risk, physicians will be able to tailor treat- ments to improve cornea transplant success, thereby very positively impacting patients’ health.",Image analytics prediction of corneal keratoplasty failure,9592472,R21EY029498,"['Affect', 'Age', 'Ancillary Study', 'Anxiety', 'Area', 'Biological Markers', 'Blindness', 'Caring', 'Cataract Extraction', 'Cell Density', 'Cell Nucleus', 'Cells', 'Cellular Morphology', 'Classification', 'Clinical Management', 'Clinical Research', 'Companions', 'Computer Vision Systems', 'Computer software', 'Computers', 'Cornea', 'Corneal Endothelium', 'Counseling', 'Data', 'Data Set', 'Descemet&apos', 's membrane', 'Devices', 'Diabetes Mellitus', 'Endothelial Cells', 'Exhibits', 'Eye', 'Failure', 'Funding', 'Future', 'Generations', 'Glaucoma', 'Goals', 'Graph', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Institutes', 'Intraocular lens implant device', 'Intuition', 'Keratoplasty', 'Knowledge', 'Lead', 'Liquid substance', 'Machine Learning', 'Measures', 'Methods', 'Microscopy', 'Multi-Institutional Clinical Trial', 'Netherlands', 'Operative Surgical Procedures', 'Ophthalmology', 'Outcome', 'Paper', 'Patient Care', 'Patient Noncompliance', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Penetrating Keratoplasty', 'Performance', 'Persons', 'Pharmaceutical Preparations', 'Physicians', 'Positioning Attribute', 'Postoperative Period', 'Procedures', 'Pump', 'Reading', 'Research Support', 'Risk', 'Seminal', 'Software Framework', 'Suggestion', 'Testing', 'Time', 'Time Study', 'Topical Corticosteroids', 'Translating', 'Transplantation', 'Transplanted tissue', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Variant', 'Visual', 'cellular imaging', 'clinical practice', 'data management', 'density', 'experimental study', 'hazard', 'image processing', 'imaging biomarker', 'improved', 'individualized medicine', 'innovation', 'preservation', 'prevent', 'quantitative imaging', 'research study', 'secondary outcome', 'success', 'validation studies', 'vision science']",NEI,CASE WESTERN RESERVE UNIVERSITY,R21,2018,240000,0.024226423503663497
"Neuroimaging Analysis Center (NAC) Project Summary/Abstract The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the pos- sibility for a new era in neuroimaging, disease understanding, and patient treatment. To unlock the full medical potential made possible by these new technologies, new algorithms and clinically-relevant techniques must be developed by close collaboration between computer scientists, physicians, and medical researchers. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and exten- sive collaboration. The overarching theme for this P41 renewal is the discovery and analysis of novel imaging phenotypes to characterize disease. We use the term imaging phenotypes to describe patterns or features of disease that can be detected through imaging (predominantly MRI) followed by machine learning, statistical analysis, feature detection, and correlation with other indicators of disease such as structured patient infor- mation. The three proposed Technology Research & Development (TR&D) projects address this common question us- ing a variety of complementary approaches and clinical testbeds. TR&D 1 addresses microstructure of tissue, including novel imaging methods to detect tumor microstructure. TR&D 2 investigates rich spatial patterns of disease extracted from clinical imaging with a focus on cerebrovascular and neurodegenerative conditions such as stroke. Finally, TR&D 3 proposes novel image and connectivity-based features that can be correlated with a variety of diseases, with a clinical emphasis on pediatric brain development. Technical innovation will be driven by intense collaboration between the TR&Ds and key collaborators in neurosurgery, neurology, and pe- diatrics. The TR&Ds will leverage recent important developments in the fields of image acquisition, machine learning, and data science to identify and exploit novel imaging phenotypes of disease. Building on our long history of developing clinically-relevant methods, each TR&D includes a translational and clinical validation aim to ensure our work is clinically relevant and effective at meeting the driving clinical goals. NAC's proven software engi- neering, translation, and dissemination infrastructure, along with its established network of academic, medical, and industrial partners, enhance the center's value as a national resource. Project Narrative The Neuroimaging Analysis Center is a research and technology center with the mission of advancing the role of neuroimaging in health care. The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the possibility for a new era in neuroimaging, disease understanding, and patient treatment. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and extensive collaboration.",Neuroimaging Analysis Center (NAC),9789424,P41EB015902,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biomedical Technology', 'Biotechnology', 'Brain', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Data Science', 'Development', 'Disease', 'Educational process of instructing', 'Ensure', 'Goals', 'Healthcare', 'Image', 'Industrialization', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Patients', 'Pattern', 'Pediatrics', 'Phenotype', 'Physicians', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Software Engineering', 'Software Framework', 'Statistical Data Interpretation', 'Stroke', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Validation', 'Work', 'algorithmic methodologies', 'base', 'cerebrovascular', 'clinical application', 'clinical imaging', 'clinically relevant', 'cohort', 'disease phenotype', 'imaging modality', 'innovation', 'meetings', 'neuroimaging', 'neurosurgery', 'new technology', 'novel', 'novel imaging technique', 'open source', 'response', 'technology research and development', 'tumor']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2018,293560,0.030470984244431152
"Neuroimaging Analysis Center (NAC) Project Summary/Abstract The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the pos- sibility for a new era in neuroimaging, disease understanding, and patient treatment. To unlock the full medical potential made possible by these new technologies, new algorithms and clinically-relevant techniques must be developed by close collaboration between computer scientists, physicians, and medical researchers. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and exten- sive collaboration. The overarching theme for this P41 renewal is the discovery and analysis of novel imaging phenotypes to characterize disease. We use the term imaging phenotypes to describe patterns or features of disease that can be detected through imaging (predominantly MRI) followed by machine learning, statistical analysis, feature detection, and correlation with other indicators of disease such as structured patient infor- mation. The three proposed Technology Research & Development (TR&D) projects address this common question us- ing a variety of complementary approaches and clinical testbeds. TR&D 1 addresses microstructure of tissue, including novel imaging methods to detect tumor microstructure. TR&D 2 investigates rich spatial patterns of disease extracted from clinical imaging with a focus on cerebrovascular and neurodegenerative conditions such as stroke. Finally, TR&D 3 proposes novel image and connectivity-based features that can be correlated with a variety of diseases, with a clinical emphasis on pediatric brain development. Technical innovation will be driven by intense collaboration between the TR&Ds and key collaborators in neurosurgery, neurology, and pe- diatrics. The TR&Ds will leverage recent important developments in the fields of image acquisition, machine learning, and data science to identify and exploit novel imaging phenotypes of disease. Building on our long history of developing clinically-relevant methods, each TR&D includes a translational and clinical validation aim to ensure our work is clinically relevant and effective at meeting the driving clinical goals. NAC's proven software engi- neering, translation, and dissemination infrastructure, along with its established network of academic, medical, and industrial partners, enhance the center's value as a national resource. Project Narrative The Neuroimaging Analysis Center is a research and technology center with the mission of advancing the role of neuroimaging in health care. The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the possibility for a new era in neuroimaging, disease understanding, and patient treatment. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and extensive collaboration.",Neuroimaging Analysis Center (NAC),9633463,P41EB015902,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biomedical Technology', 'Biotechnology', 'Brain', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Data Science', 'Development', 'Disease', 'Educational process of instructing', 'Ensure', 'Goals', 'Healthcare', 'Image', 'Industrialization', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Records', 'Methodology', 'Methods', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Patients', 'Pattern', 'Pediatrics', 'Phenotype', 'Physicians', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Software Engineering', 'Software Framework', 'Statistical Data Interpretation', 'Stroke', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Validation', 'Work', 'algorithmic methodologies', 'base', 'cerebrovascular', 'clinical application', 'clinical imaging', 'clinically relevant', 'cohort', 'disease phenotype', 'imaging modality', 'innovation', 'meetings', 'neuroimaging', 'neurosurgery', 'new technology', 'novel', 'novel imaging technique', 'open source', 'response', 'technology research and development', 'tumor']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2018,1583573,0.030470984244431152
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. Narrative There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9680657,R44MH118815,"['Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'Stem cells', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'professional atmosphere', 'prototype', 'research and development', 'treatment strategy', 'two-dimensional', 'usability', 'virtual reality', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2018,449918,0.03442870436823045
"Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry PROJECT SUMMARY  Cellular interactions with the environment form the basis of health and disease for all organisms. Exposure to nutrients, toxins, and neighboring cells trigger coordinated molecular responses that impact cell function and metabolism in a beneficial, adaptive, or detrimental manner. Although the benefits of multicellularity for the formation of complex tissue structures or the function of entire organ systems has been long appreciated, it has only recently been understood that microbial inhabitants of vertebrates also have a tremendous impact on host cell function and dysfunction. Despite this, an understanding of these interactions has not moved beyond simple associations, and there are virtually no molecular technologies available that adequately define how a complex microbial ecosystem impacts host cell function, or how the host response to microbial colonization affects the bacterial community. This gap in knowledge is striking when one considers the broad and significant impact that microbes have on human health. In this application, we propose to expressly fill this knowledge gap through development of a novel multimodal imaging pipeline that will provide 3-dimensional information on the molecular heterogeneity of microbial communities and the immune response at the host-pathogen interface.  This proposal combines our expertise in immunology, infection biology, mass spectrometry, small animal imaging, machine learning, and computer vision to develop an integrated multimodal visualization method for studying infectious disease. Our unique approach will computationally combine ultra-high speed (~50px/s) MALDI-TOF images, ultra-high mass resolution (>200,000 resolving power) MALDI FTICR IMS, metal imaging by LA-ICP-IMS, high-spatial resolution optical microscopy, and MR imaging using data-driven image fusion. This strategy will enable 3-D molecular images to be generated for thousands of elements, metabolites, lipids, and proteins with an unprecedented combination of chemical specificity and spatial fidelity more than 50x faster than is currently possible. We will use this next-generation imaging capability to (i) define the heterogeneous microbial subpopulations throughout the 3-D volume of a S. aureus community, (ii) uncover the host molecules that form the abscess and accumulate to restrict microbial growth in murine models, and (iii) elucidate molecular markers that differentiate in vivo biofilms at the host-pathogen interface, between abscesses at various stages of progression, and under distinct degrees of nutrient stress. These studies will uncover new targets for therapeutic intervention and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research. PROJECT NARRATIVE This proposal will enable detailed views of the molecular components of infectious disease with unprecedented resolution through the development of a multimodal, 3-dimensional imaging platform. The proposed technologies will improve throughput and molecular specificity, enable automated high-precision and high-accuracy image alignment, and allow for descriptions of molecular signals in 3-D through the fusion of multi-modal imaging data. These studies will uncover targets for therapeutic intervention and antibiotic development and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research.",Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry,9659850,R01AI138581,"['3-Dimensional', 'Abscess', 'Affect', 'Animal Model', 'Animals', 'Anterior nares', 'Antibiotics', 'Antibodies', 'Architecture', 'Awareness', 'Bacteria', 'Bacterial Infections', 'Bacterial Proteins', 'Behavior', 'Biology', 'Biomedical Research', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Cellular Metabolic Process', 'Chemicals', 'Communicable Diseases', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Custom', 'Data', 'Development', 'Diagnosis', 'Differentiation Antigens', 'Dimensions', 'Disease', 'Ecosystem', 'Elements', 'Environment', 'Exposure to', 'Fourier transform ion cyclotron resonance', 'Functional disorder', 'Glean', 'Growth', 'Health', 'Health Promotion', 'Heterogeneity', 'Histology', 'Human', 'Image', 'Imagery', 'Imaging technology', 'Immune', 'Immune response', 'Immunology', 'Imprisonment', 'Individual', 'Infection', 'Infectious Diseases Research', 'Integration Host Factors', 'Knowledge', 'Label', 'Lesion', 'Lipids', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Mass Spectrum Analysis', 'Metals', 'Methodology', 'Methods', 'Microbe', 'Microbial Biofilms', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nutrient', 'Optics', 'Organism', 'Pathogenesis', 'Physiological', 'Population', 'Process', 'Proteins', 'Reagent', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Spatial Distribution', 'Specificity', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Staphylococcus aureus', 'Stress', 'Structure', 'Supervision', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Tissues', 'Toxin', 'Vertebrates', 'Work', 'animal imaging', 'bacterial community', 'base', 'body system', 'commensal bacteria', 'experimental study', 'host colonization', 'imaging capabilities', 'imaging detection', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'innovation', 'interest', 'microbial', 'microbial colonization', 'microbial community', 'microscopic imaging', 'molecular imaging', 'molecular marker', 'mouse model', 'multimodality', 'neutrophil', 'new therapeutic target', 'next generation', 'novel', 'pathogen', 'protein expression', 'response', 'targeted treatment', 'virtual']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2018,593526,0.0038379778672275916
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9496652,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Decubitus ulcer', 'Diabetic Foot Ulcer', 'Diabetic wound', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2018,425994,0.017980046765402758
"THE XNAT IMAGING INFORMATICS PLATFORM PROJECT SUMMARY This proposal aims to continue the development of XNAT. XNAT is an imaging informatics platform designed to facilitate common management and productivity tasks for imaging and associated data. We will develop the next generation of XNAT technology to support the ongoing evolution of imaging research. Development will focus on modernizing and expanding the current system. In Aim 1, we will implement new web application infrastructure that includes a new archive file management system, a new event bus to manage cross-service orchestration and a new Javascript library to simplify user interface development. We will also implement new core services, including a Docker Container service, a dynamic scripting engine, and a global XNAT federation. In Aim 2, we will implement two innovative new capabilities that build on the services developed in Aim 1. The XNAT Publisher framework will streamline the process of data sharing by automating the creation and curation of data releases following best practices for data publication and stewardship. The XNAT Machine Learning framework will streamline the development and use of machine learning applications by integrating XNAT with the TensorFlow machine learning environment and implementing provenance and other monitoring features to help avoid the pitfalls that often plague machine learning efforts. For both Aim 1 and 2, all capabilities will be developed and evaluated in the context of real world scientific programs that are actively using the XNAT platform. In Aim 3, we will provide extensive support to the XNAT community, including training workshops, online documentation, discussion forums, and . These activities will be targeted at both XNAT users and developers. RELEVANCE Medical imaging is one of the key methods used by biomedical researchers to study human biology in health and disease. The imaging informatics platform described in this application will enable biomedical researchers to capture, analyze, and share imaging and related data. These capabilities address key bottlenecks in the pathway to discovering cures to complex diseases such as Alzheimer's disease, cancer, and heart disease.",THE XNAT IMAGING INFORMATICS PLATFORM,9749413,R01EB009352,"['Address', 'Administrator', 'Alzheimer&apos', 's Disease', 'Architecture', 'Archives', 'Area', 'Automation', 'Biomedical Research', 'Brain', 'Cardiology', 'Categories', 'Classification', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Docking', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Evolution', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Informatics', 'Instruction', 'Internet', 'Libraries', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Modality', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Newsletter', 'Optics', 'Paper', 'Pathway interactions', 'Peer Review', 'Persons', 'Plague', 'Positron-Emission Tomography', 'Principal Investigator', 'Process', 'Productivity', 'Publications', 'Publishing', 'Radiology Specialty', 'Research', 'Research Infrastructure', 'Research Personnel', 'Security', 'Services', 'System', 'Technology', 'TensorFlow', 'Training', 'Validation', 'base', 'biomedical resource', 'computer framework', 'computing resources', 'data sharing', 'design', 'distributed data', 'educational atmosphere', 'hackathon', 'imaging informatics', 'imaging program', 'improved', 'innovation', 'next generation', 'online tutorial', 'open source', 'outreach program', 'pre-clinical', 'programs', 'skills', 'symposium', 'tool', 'virtual', 'web app']",NIBIB,WASHINGTON UNIVERSITY,R01,2018,155743,0.01988654969198593
"THE XNAT IMAGING INFORMATICS PLATFORM PROJECT SUMMARY This proposal aims to continue the development of XNAT. XNAT is an imaging informatics platform designed to facilitate common management and productivity tasks for imaging and associated data. We will develop the next generation of XNAT technology to support the ongoing evolution of imaging research. Development will focus on modernizing and expanding the current system. In Aim 1, we will implement new web application infrastructure that includes a new archive file management system, a new event bus to manage cross-service orchestration and a new Javascript library to simplify user interface development. We will also implement new core services, including a Docker Container service, a dynamic scripting engine, and a global XNAT federation. In Aim 2, we will implement two innovative new capabilities that build on the services developed in Aim 1. The XNAT Publisher framework will streamline the process of data sharing by automating the creation and curation of data releases following best practices for data publication and stewardship. The XNAT Machine Learning framework will streamline the development and use of machine learning applications by integrating XNAT with the TensorFlow machine learning environment and implementing provenance and other monitoring features to help avoid the pitfalls that often plague machine learning efforts. For both Aim 1 and 2, all capabilities will be developed and evaluated in the context of real world scientific programs that are actively using the XNAT platform. In Aim 3, we will provide extensive support to the XNAT community, including training workshops, online documentation, discussion forums, and . These activities will be targeted at both XNAT users and developers. RELEVANCE Medical imaging is one of the key methods used by biomedical researchers to study human biology in health and disease. The imaging informatics platform described in this application will enable biomedical researchers to capture, analyze, and share imaging and related data. These capabilities address key bottlenecks in the pathway to discovering cures to complex diseases such as Alzheimer's disease, cancer, and heart disease.",THE XNAT IMAGING INFORMATICS PLATFORM,9560825,R01EB009352,"['Address', 'Administrator', 'Alzheimer&apos', 's Disease', 'Architecture', 'Archives', 'Area', 'Automation', 'Biomedical Research', 'Brain', 'Cardiology', 'Categories', 'Classification', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Docking', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Evolution', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Informatics', 'Instruction', 'Internet', 'Libraries', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Modality', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Newsletter', 'Optics', 'Paper', 'Pathway interactions', 'Peer Review', 'Persons', 'Plague', 'Positron-Emission Tomography', 'Principal Investigator', 'Process', 'Productivity', 'Publications', 'Publishing', 'Radiology Specialty', 'Research', 'Research Infrastructure', 'Research Personnel', 'Security', 'Services', 'System', 'Technology', 'TensorFlow', 'Training', 'Validation', 'base', 'biomedical resource', 'computer framework', 'computing resources', 'data sharing', 'design', 'distributed data', 'educational atmosphere', 'hackathon', 'imaging informatics', 'imaging program', 'improved', 'innovation', 'next generation', 'online tutorial', 'open source', 'outreach program', 'pre-clinical', 'programs', 'skills', 'symposium', 'tool', 'virtual', 'web app']",NIBIB,WASHINGTON UNIVERSITY,R01,2018,674602,0.01988654969198593
"Quantifying NETosis via Automated High Content Imaging Convolutional Neural Networks PROJECT SUMMARY NETosis was identified as a distinct mode of cell death in neutrophils more than a decade ago. Dysregulation of NETosis has been implicated in the etiology of human pathologies such as preeclampsia, sickle cell disease, systemic lupus erythematosus, multiple sclerosis, rheumatoid arthritis, sepsis, cystic fibrosis, lupus nephritis, and coagulopathies that include cancer-associated thrombosis. The literature consistently cites the lack of a standardized methodology for quantitation of NETosis as an impediment to basic and translational research. Thus, the premise is that there is a compelling, unmet need for a standardized, quantitative and automated method for the measurement of NETosis to accelerate neutrophil and inflammation-based research and facilitate the discovery and development of therapeutic compounds. The scope of this STTR project is to develop a high-throughput image analysis and quantitation method by using high content imaging and the revolutionary technology of convolutional neural networks (CNN) for the identification and quantitation of NETosis in human neutrophils. The target readout is based on the primary morphological difference between NETotic and non-NETotic nuclei--the decondensation of chromatin. This image-based quantitative method will be observer-independent and will enable robust and rapid evaluation of a large number of samples that would exceed any attempts at manual assessment. In Phase I we will complete the following Specific Aims: Aim 1: Optimize and standardize the high- throughput platform for quantitation of NETosis in adherent human neutrophils. This includes standard assay optimization procedures, training the CNN to identify and quantitate NETotic neutrophil, and demonstrating that the CNN reliably distinguishes between necrosis and NETosis, whose phenotypes appear similar to the human eye. Aim 2: Validate the NETosis assay biochemically and clinically. This includes concentration-response assays with NETosis agonists, assessment of NETosis inhibitors, and evaluation of the NETotic status of Sickle Cell Disease patient samples (a disease in which aberrant NETosis has been implicated). The expected outcome of this Phase I effort is to demonstrate proof-of-concept for this automated high- throughput NETosis assay. Further, we expect to provide insight into the utility of the assay for assessment of inhibitors of NETosis as therapeutic agents. Upon completion of our Phase I aims, our Phase II program will focus on further optimizing and validating this NETosis assay and preparing it for commercialization.   PROJECT NARRATIVE Aberrant NETosis has been implicated in the etiology of several inflammatory and autoimmune diseases. The lack of a standardized, quantitative and automated method for the measurement of NETosis is impeding basic and translational research. We have developed a high-throughput assay using convolutional neural networks to quantify NETosis in human neutrophils. This assay will accelerate neutrophil and inflammation-based research and facilitate the discovery and development of compounds with therapeutic potential.",Quantifying NETosis via Automated High Content Imaging Convolutional Neural Networks,9465292,R41AI131840,"['Agonist', 'Apoptosis', 'Autoimmune Diseases', 'Basic Science', 'Benchmarking', 'Biochemical', 'Biochemical Pathway', 'Biological Assay', 'Biological Neural Networks', 'Blood Coagulation Disorders', 'Caymans', 'Cell Death', 'Cell Death Process', 'Cell Nucleus', 'Cells', 'Chromatin', 'Classification', 'Clinical', 'Cystic Fibrosis', 'DNA', 'Data', 'Development', 'Diagnostic', 'Diagnostic tests', 'Diagnostics Research', 'Disease', 'Drug Screening', 'Ensure', 'Enzymes', 'Etiology', 'Evaluation', 'Eye', 'Histones', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Impairment', 'Infection', 'Inflammation', 'Inflammatory', 'Innate Immune Response', 'Letters', 'Literature', 'Lupus Nephritis', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Mediating', 'Methodology', 'Methods', 'Morphology', 'Multiple Sclerosis', 'Nature', 'Necrosis', 'Nuclear', 'Opportunistic Infections', 'Outcome', 'Pathway interactions', 'Patients', 'Peptide Hydrolases', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Physical condensation', 'Population', 'Pre-Eclampsia', 'Predisposition', 'Procedures', 'Process', 'Publishing', 'Reproducibility', 'Research', 'Rheumatoid Arthritis', 'Sampling', 'Sepsis', 'Severity of illness', 'Sickle Cell Anemia', 'Side', 'Small Business Technology Transfer Research', 'Specificity', 'Stains', 'Standardization', 'Systemic Lupus Erythematosus', 'Technology', 'Therapeutic', 'Therapeutic Agents', 'Thrombosis', 'Training', 'Translational Research', 'antimicrobial', 'antimicrobial peptide', 'base', 'commercial application', 'commercialization', 'extracellular', 'high throughput screening', 'inhibitor/antagonist', 'innovation', 'insight', 'neutrophil', 'novel', 'patient population', 'predictive test', 'programs', 'response', 'suicidal', 'symptom management', 'therapeutic development', 'tool']",NIAID,"EPICYPHER, INC.",R41,2018,299751,-0.0005679493356227981
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE Mapping effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing of different types of individual cells, understanding the func- tion and relationships between those cell types, and modeling their individual and collective function. In order to exploit human and machine intelligence, different visual interfaces will be implemented that use the CCF in support of data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, mathematical biology, and biomedical data standards to develop a highly accurate and extensible multidimen- sional spatial basemap of the human body and associated data overlays that can be interactively explored online as an atlas of tissue maps. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across the human body along multiple functional contexts (e.g., systems physiology, vascular, or endocrine systems), and connect and integrate further computational, analytical, visualization, and biometric resources as driven by the context or “position” on the map. The CCF and the interactive data visualizations will be multi-level and multi-scale sup- porting the exploration and communication of tissue and publication data--from single cell to whole body. In the first year, the proposed Mapping Component will run user needs analyses, compile an initial CCF using pre-existing classifications and ontologies; implement two interactive data visualizations; and evaluate the usa- bility and effectiveness of the CCF and associated visualizations in formal user studies. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an ex- tensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spa- tial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high- resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",9687220,OT2OD026671,"['Address', 'Anatomy', 'Artificial Intelligence', 'Atlases', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Classification', 'Clinical', 'Code', 'Communication', 'Communities', 'Computer Simulation', 'Computer software', 'Data', 'Data Set', 'Ecosystem', 'Educational workshop', 'Effectiveness', 'Endocrine system', 'Future', 'Genetic', 'Goals', 'Human', 'Human body', 'Image', 'Imagery', 'Individual', 'Investigation', 'Knowledge', 'Machine Learning', 'Maps', 'Mathematical Biology', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Ontology', 'Organ', 'Participant', 'Physiological', 'Physiology', 'Positioning Attribute', 'Production', 'Publications', 'Research Infrastructure', 'Resolution', 'Resources', 'Running', 'Services', 'System', 'Tissues', 'Update', 'Vascular System', 'Visual', 'Visualization software', 'Work', 'base', 'cell type', 'computing resources', 'data integration', 'data mining', 'data visualization', 'design', 'hackathon', 'human imaging', 'interoperability', 'member', 'systematic review', 'usability', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2018,330000,-0.021273910021791225
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,9659552,UG3HL145593,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NHLBI,PURDUE UNIVERSITY,UG3,2018,375000,0.006973012843499094
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,9577245,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'multidisciplinary', 'pathogen', 'point of care', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2018,1329765,0.014572111361328419
"High throughput cell screening for toxic metal exposure Project Summary The overall objective of this research project is to develop a novel approach for high throughput screening of individual cells based on holographic imaging. To achieve this goal, we propose to implement a new quantitative phase imaging modality, holographic cytomtery, which incorporates several novel technical advances to enable high throughput imaging. Holographic cytometry (HC) will bring the high sensitivity of quantitative phase microscopy (QPM) to imaging of cells flowing through microfluidic devices. While QPM has been used for cell analysis previously, typically only a handful of cells have been imaged. To enable significant application of QPM for fundamental cell biology and clinical studies, it is necessary to move to a high throughput implementation. Technical advances needed to realize the high resolution HC system include use of high speed line scan cameras, microfluidic chips with multiple parallel channels, and light from a pulsed laser source to enable stroboscopic illumination. In order to efficiently analyze and process this data set, rapid analysis software will be developed that leverages the highly parallel processing capabilities of graphics processing units and machine learning algorithms to enable automated classification. The proposed HC method can be applied to imaging a wide range of flowing cells. To demonstrate the utility of the approach, we will initially target the measurement of cancerous progression due to environmental toxicant exposure. We have conducted a preliminary study that shows QPM can detect early changes in the biomechanical properties of cells due to arsenic exposure. In the proposed project, we seek to develop QPM based biomarkers of pre-cancerous change that will enable rapid assessesment. QPM has not been implemented in such a format to date and thus is not yet a feasible approach for clinical or research studies. To meet the goal of high throughput imaging with QPM, the following Specific Aims are proposed: 1. Develop new instrumentation for high speed imaging using off axis digital holography. 2. Implement high throughput analysis methods based on machine learning 3. Test and validate high throughput system with pilot studies of heavy metal exposed epithelial cells to show the approach can detect early pre-cancerous changes due to environmental toxicant exposure. Upon completion of this project, we will have realized a high throughput imaging cytometry system for research and clinical applications. Project Narrative  The proposed research will develop a new high throughput cellular screening technology based on quantitative phase image of cells flowing in a microfluidic chip. This technology will allow researchers and doctors to obtain holographic images of every single cell in a sample in a short amount of time which can then be analyzed by a computer. This would offer the opportunity to evaluate the characteristics of populations of cells for understanding changes in public health due to environmental factors.",High throughput cell screening for toxic metal exposure,9610235,R21ES029791,"['Algorithms', 'Arsenic', 'Biological', 'Biological Assay', 'Biological Markers', 'Biomechanics', 'Cancerous', 'Cell Count', 'Cells', 'Cellular biology', 'Classification', 'Clinical', 'Clinical Research', 'Computer software', 'Computers', 'Cytology', 'Cytometry', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Descriptor', 'Development', 'Discrimination', 'Disease', 'Environmental Exposure', 'Environmental Risk Factor', 'Epithelial Cells', 'Evaluation', 'Exhibits', 'Exposure to', 'Functional disorder', 'Future', 'Geometry', 'Goals', 'Heavy Metals', 'Holography', 'Image', 'Image Cytometry', 'Individual', 'Lasers', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Mechanics', 'Metal exposure', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscopy', 'Morphology', 'Motion', 'Neoplasm Metastasis', 'Phase', 'Phenotype', 'Physiologic pulse', 'Pilot Projects', 'Population Characteristics', 'Premalignant', 'Process', 'Property', 'Public Health', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Sampling', 'Scanning', 'Source', 'Speed', 'Stream', 'System', 'Technology', 'Testing', 'Time', 'Toxic Environmental Substances', 'Toxicant exposure', 'Vision', 'base', 'cancer cell', 'carcinogenesis', 'cellular imaging', 'clinical application', 'detector', 'digital', 'high throughput analysis', 'high throughput screening', 'imaging approach', 'imaging modality', 'instrument', 'instrumentation', 'mechanical properties', 'microscopic imaging', 'nanoscale', 'novel', 'novel strategies', 'parallel computer', 'parallel processing', 'prevent', 'research clinical testing', 'research study', 'screening', 'shear stress', 'systems research', 'tool', 'toxic metal']",NIEHS,DUKE UNIVERSITY,R21,2018,209312,-0.020342120599187465
"An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography SUMMARY – OVERALL Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function. Although the basic electron cryo-tomography technique has been used for several decades, the technology is being revolutionized by recent advances in sample preparation, electron cryo-microscopy hardware, improved capabilities for automatic data collection, direct electron detection imaging devices, and phase plate technologies. Combined, these advances led to the ability to generate extraordinarily large numbers of cellular cryo-tomograms of exquisite quality. In principle, such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. However, collection of cellular data is now at a far faster rate than can currently be analyzed with existing methods, producing a serious barrier to progress: to match the data production rates of a single laboratory, at least 50 experienced scientists would need to handle the data analysis. The primary goal of this Program Project is to establish quantitative and highly automated tools for the reconstruction and interpretation of highly complex cellular tomographic data. We have assembled a highly synergistic team of PIs with complimentary expertise in cutting-edge computational and experimental electron microscopy techniques to achieve this goal through collaborative efforts. Project 1 (Hanein & Penczek) focuses on development and implementation of tomogram quality assessment and validation techniques and on experimentally guided optimization of data collection strategies. Project 2 focuses on automatic tomographic reconstruction technology, extraction of various features from the tomograms, and the analysis of distribution patterns derived from the extracted features. Project 3 focuses on development of quantitative tools for tomogram annotation through deep learning and sub-tomogram alignment as well as interactive visualization tools. The set of highly automated tools developed in this Program Project will permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study. NARRATIVE Cellular cryo-tomography has emerged as a critical tool for the visualization and structural study of the molecular nanomachines at the heart of cellular function and—with recent instrumental advances—it is now possible to image hundreds of cells per months, enabling collection of cellular data at a far faster rate than can currently be analyzed. Such large data sets offer insights into cellular variation in disease states as well as better insights into basic cellular function, opening new possibilities for studying the underpinnings of health and disease at the finest possible level, potentially leading to completely new diagnostics for cancer and other cell-altering diseases. This Program Project brings together an accomplished team of investigators to develop new strategies for effectively processing and interpreting this massive influx of data, developing a set of highly automated tools to permit us to interpret 5–10x as much data as is possible using existing methods, greatly expanding the types of cellular variations we can effectively study.",An automated pipeline for macromolecular structure discovery in cellular  electron cryo-tomography,9416022,P01GM121203,"['Address', 'Algorithms', 'Artificial Intelligence', 'Big Data', 'Biological', 'Biological Neural Networks', 'Biology', 'Cancer Diagnostics', 'Cell physiology', 'Cells', 'Classification', 'Collection', 'Complex', 'Computing Methodologies', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Detection', 'Development', 'Disease', 'Electron Microscopy', 'Electrons', 'Environment', 'Floods', 'Goals', 'Health', 'Heart', 'Human', 'Image', 'Imaging Device', 'Individual', 'Knowledge', 'Laboratories', 'Methodology', 'Methods', 'Molecular', 'Molecular Structure', 'Morphology', 'Pattern', 'Pharmaceutical Preparations', 'Phase', 'Preparation', 'Process', 'Production', 'Real-Time Systems', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Stimulus', 'System', 'Techniques', 'Technology', 'Tomogram', 'Validation', 'Variant', 'Visualization software', 'base', 'computer framework', 'deep learning', 'electron tomography', 'experience', 'imaging detection', 'improved', 'insight', 'knowledge base', 'learning strategy', 'nanomachine', 'novel diagnostics', 'particle', 'programs', 'reconstruction', 'response', 'software development', 'statistics', 'tomography', 'tool', 'virtual']",NIGMS,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,P01,2018,981617,-0.02135481757093666
"2018 Image Science Gordon Research Conference & Gordon Research Seminar Project Summary: The proposal requests support for early-career investigators to attend the 2018 Gordon Research Conference on Image Science. The unique feature of this conference in its third offering compared with others in medical imaging is the bringing together of renown speakers from disparate application areas, including astronomy, biology, medicine, remote sensing, and security and defense industries, in a forum that encourages each to describe their greatest challenges and most promising solutions. All speakers are invited based on their leadership in their field and their willingness to debate fundamental issues shared by everyone developing, evaluating, and applying imaging in medicine and biology. We believe the GRC format placed in the context of a small-college venue promotes the type of innovative interdisciplinary thinking that leads to breakthroughs. An environment where leading senior scientists debate core issues is valuable to young investigators trying to build successful independent careers in medical imaging in industry and academia. All attendees are invited to present a poster describing their research in poster sessions that are a key element of the Gordon Conference format. The June 17-22, 2018 GRC conference theme is “Image Science: Creating Knowledge from Information,” which is focused on appropriate acquisition and efficient uses of the massive volume of imaging information now collected from patients. Speakers give 40 minutes presentations in a single-track format with 20 minute discussions following each presentation that are led by experts in the field. Topic range from “Imaging in Brain Science Discovery” to “Advanced Machine Learning” and “Computational Imaging.” At the center of each presentation is a discussion of the core challenges shared by image scientists and novel techniques for acquiring and displaying information in a manner that maximizes decision performance. Given the success of the previous meeting, we will hold the first-ever, student-run Gordon Research Seminars (GRS) on Image Science June 16, 17, 2018. Our aim is to build Image Science as an independent field of study through detailed interdisciplinary discussions and by fostering the success of a new generation of image scientists. Project Narrative: Solutions to very difficult problems often emerge from discussions among experts in different fields of study being challenged by the same core problems. The 2018 GRC on Imaging Science strives to build a community of problem solvers by creating an environment for detailed discussions among senior investigators that involves young investigators at a time when they are building careers. This is a proposal to fund young investigators to attend the conference.",2018 Image Science Gordon Research Conference & Gordon Research Seminar,9461211,R13EB025662,"['Academia', 'Area', 'Astronomy', 'Big Data', 'Biology', 'Brain', 'Collaborations', 'Communities', 'Computational Science', 'Data', 'Data Analytics', 'Development', 'Disabled Persons', 'Discipline', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Evaluation', 'Event', 'Fees', 'Female', 'Financial Support', 'Fostering', 'Funding', 'Housing', 'Human', 'Image', 'Industry', 'Information Sciences', 'Interdisciplinary Study', 'Knowledge', 'Leadership', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medicine', 'Methods', 'Minority', 'Modeling', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Recruitment Activity', 'Request for Proposals', 'Research', 'Research Personnel', 'Resource Development', 'Risk-Taking', 'Role', 'Running', 'Science', 'Scientist', 'Security', 'Senior Scientist', 'Series', 'Societies', 'Source', 'Statistical Models', 'Students', 'Systems Development', 'Techniques', 'Thinking', 'Time', 'Training', 'United States National Institutes of Health', 'base', 'career', 'college', 'cost', 'design', 'disabled students', 'educational atmosphere', 'field study', 'frontier', 'graduate student', 'image reconstruction', 'imaging scientist', 'imaging system', 'information display', 'innovation', 'instrument', 'meetings', 'minority student', 'multidisciplinary', 'next generation', 'novel', 'posters', 'preference', 'remote sensing', 'skills', 'success', 'symposium', 'training opportunity', 'virtual', 'willingness']",NIBIB,GORDON RESEARCH CONFERENCES,R13,2018,10000,0.032730202006755346
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment Project Summary NIH is increasing its investment in large mutli-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several open-source software systems. For example, the NIH NIAAA and BD2K funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements that called for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for multi-site QC workflows as that would require a unified platform, design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that supports simplified creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific findings findable, accessible, interoperable, and reusable.  Specifically, our multi-site open-source software platform for Medical Image Quality Assurance (mIQa) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system, machine learning to aid in QC process, and an interactive electronic notebook platform. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automating notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, mIQa is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop multi-site, open-source software for Medical Image Quality Assurance (mIQa) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. mIQa will enable efficient and accurate QC processing by levering open-source, state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive review and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment,9622218,R43MH119022,"['Active Learning', 'Address', 'Adolescence', 'Alcohols', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Provenance', 'Data Set', 'Data Sources', 'Development', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Environment', 'Evaluation', 'FAIR principles', 'Four-dimensional', 'Funding', 'Geography', 'Goals', 'Image', 'Image Analysis', 'Imagery', 'International', 'Internet', 'Investments', 'Label', 'Libraries', 'Logic', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical', 'Medical Imaging', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'System', 'Techniques', 'Technology', 'Time', 'United States National Institutes of Health', 'Visual', 'Work', 'Writing', 'application programming interface', 'base', 'cohesion', 'cost', 'dashboard', 'data access', 'data management', 'design', 'experience', 'flexibility', 'image archival system', 'imaging study', 'improved', 'innovation', 'member', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'prototype', 'quality assurance', 'research study', 'software systems', 'success', 'tool', 'web interface', 'web-enabled']",NIMH,"KITWARE, INC.",R43,2018,225001,0.04313436807128445
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages. PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,9517061,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Drug Targeting', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Hydration status', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Reproducibility', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Statistical Data Interpretation', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'algorithmic methodologies', 'base', 'computer code', 'cryogenics', 'data warehouse', 'density', 'design', 'fiber cell', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'microscopic imaging', 'new technology', 'next generation', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2018,306284,-0.014812131046919749
"The Blackfynn Platform for Rapid Data Integration and Collaboration Summary One in seven people worldwide suffers from a brain disorder, e.g., epilepsy, Parkinson's, stroke, or dementia. Development of future treatments depends on improving our understanding of brain function and disease, and validating new treatments critically depends on identifying the underlying biomarkers associated with different conditions. Biomarker discovery requires volume, quality, richness, and diversity of data. This Direct-to-Phase II project extends Blackfynn's cloud data management platform for team science, in order to support interactive data curation and integration and to facilitate biomarker discovery. Our first technical aim develops tools to help select, curate, assess, and regularize datasets: we develop novel “live” query capabilities to ensure users discover relevant data, develop mechanisms for using data's provenance to decide on trustworthiness, and build tools for mapping fields to common data elements. These capabilities address the critical, under-served problem of selecting the data to analyze. Our second technical aim develops techniques for incorporating algorithms to link and co-register across multi-modal data and metadata. Using ranking and machine learning, we can incorporate and combine state-of-the-art algorithms for finding data relationships, and we can link to remote data sources. These capabilities enable scientists to analyze richer datasets with multiple data modalities and properties – thus enabling them to discover more complex correlations and biomarkers. In our third aim, Blackfynn's new technical capabilities will be applied to challenges faced by Blackfynn partners, including problems assessing trustworthiness of data annotations, conducting image analysis, modeling epileptic networks, and identifying biomarkers for neuro-oncology indications. As part of this validation we will also develop HIPAA-compliant mechanisms for working with protected and de-identified data together. Together, these three thrusts will ensure that development of the Blackfynn platform results in tools and technologies that meaningfully accelerate scientific understanding and discovery over rich and complex data, leading to improved treatments for neurologic disease.   Narrative This Direct-to-Phase II project extends the Blackfynn cloud data management platform to enable biomarker discovery for research and development of improved drugs, devices and clinical care for patients with neurologic disease: it develops tools for assembling, evaluating, and rating data, and linking it across modalities and to external systems. It also validates the techniques' effectiveness using real challenges faced by Blackfynn partners, in imaging, epilepsy, and brain tumor research.",The Blackfynn Platform for Rapid Data Integration and Collaboration,9468362,R44DA044929,"['Address', 'Algorithms', 'Benchmarking', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain Neoplasms', 'Case Study', 'Clinical Pharmacology', 'Collaborations', 'Common Data Element', 'Complex', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Discovery', 'Data Provenance', 'Data Science', 'Data Set', 'Data Sources', 'Dementia', 'Development', 'Devices', 'Disease', 'Effectiveness', 'Ensure', 'Epilepsy', 'Funding', 'Future', 'Health', 'Health Insurance Portability and Accountability Act', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Link', 'Machine Learning', 'Maps', 'Mental Depression', 'Metadata', 'Modality', 'Modeling', 'National Institute of Neurological Disorders and Stroke', 'Neurosciences', 'Neurosciences Research', 'Notification', 'Ontology', 'Output', 'Parkinson Disease', 'Patient Care', 'Pharmaceutical Preparations', 'Phase', 'Plug-in', 'Process', 'Property', 'Research', 'Research Infrastructure', 'Science', 'Scientist', 'Semantics', 'Series', 'Small Business Innovation Research Grant', 'Source', 'Standardization', 'Stroke', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translational Research', 'Trust', 'Use Effectiveness', 'Validation', 'Work', 'base', 'biomarker discovery', 'clinical application', 'clinical care', 'cloud platform', 'computer science', 'data access', 'data integration', 'data management', 'improved', 'indexing', 'nervous system disorder', 'neuro-oncology', 'neuroimaging', 'novel', 'novel therapeutics', 'open source', 'research and development', 'tool']",NIDA,"BLACKFYNN, INC.",R44,2018,696602,-0.003944265393736575
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9535994,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2018,444363,0.022728794852476614
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9525950,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wait Time', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool', 'tuberculosis diagnostics']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2018,333515,0.024018831571256612
"Towards a FAIR Digital Ecosystem in the Cloud Cloud Computing, Big Data Analytics, and Artificial Intelligence are transforming biomedical research. The NIH Data Commons will provide a common, cloud-agnostic, harmonized environment where these technologies can be deployed to serve NIH intra- and extra-mural researchers, implementing FAIR principles [Wilkinson2016]. Our proposal provides two essential capabilities: (1) Global Unique Identification (GUIDs) and (2) Digital Object Publication, Citation, Replication and Reuse. We propose a FAIR biomedical ecosystem where all primary and derived digital objects (e.g., datasets, software) receive GUIDs, assisting with Findability and Accessibility, Reusability, data provenance, reproducibility, and accountability of research outcomes. GUIDs will provide full Interoperability between DOIs and prefix: accession based Compact Identifiers through a common resolution services prefix registry. All digital objects will interoperate with multiple, hybrid clouds—open source and commercial—enabling researchers to select computing resources best matching their needs. 1 - The Global Unique Identifier (GUID) Capability provides a persistent, machine resolvable identifier platform for all FAIR objects in the Commons, fully aligned with community practices, recommendations, and metadata models. 2 - The Cloud Dataverse for Biomedical Digital Object Publication, Citation, Replication, and Reuse applies FAIR principles to primary and derived datasets, computational provenance, and software, making them fully FAIR compliant, while documenting the production processes. Cloud Dataverse integrates with multiple cloud computing solutions. As an example, with these capabilities, a researcher can extract a subset of data from TOPMed or GTEx and publish it in Cloud Dataverse, with its associated metadata, provenance, and terms of use. In publications, she can cite the data and software according to Data Citation Publishers guidelines [Cousijn2017] and Software Citation Principles [Smith2016]. Other researchers can access the dataset using the GUID in the citation, resolving the repository’s dataset landing page (as recommended by the Data Citation Principles [Martone2014, Fenner2017, Starr2015]). From this landing page, researchers can repeat the original calculation, perform new computations on the dataset, or use the provenance graph to learn how the dataset was created. The data and software published in the repository reflect the evolving nature of research; anyone can publish new versions with the provenance documenting the process. Our open-source software platforms used in production, adhere to FAIR principles, and provide the basis for the two capabilities: GUIDs and Cloud Dataverse enabling the use cases above. We will expand upon them, produce new tools, and reach a wider community. Currently GUIDs and provenance describe datasets; we will generalize these mechanisms to support other digital objects, focusing on software in the pilot phase. We will connect and harmonize DataCite, identifiers.org, and N2T/EZID services to provide GUIDs; and integrate the Dataverse repository software with the Massachusetts Open Cloud, built on top of the OpenStack cloud platform, and public commercial clouds (Microsoft Azure, Google Cloud) to provide Cloud Dataverse. Our past experience producing sustainable services for overlapping communities of developers and users demonstrates our ability to apply our expertise to supporting the larger and more diverse NIH Data Commons user community. n/a",Towards a FAIR Digital Ecosystem in the Cloud,9672008,OT3OD025456,"['Accountability', 'Artificial Intelligence', 'Big Data', 'Biomedical Research', 'Cloud Computing', 'Communities', 'Community Practice', 'Computer software', 'Data', 'Data Analytics', 'Data Provenance', 'Data Set', 'Ecosystem', 'Environment', 'FAIR principles', 'Genotype-Tissue Expression Project', 'Graph', 'Guidelines', 'Hybrids', 'Learning', 'Massachusetts', 'Metadata', 'Modeling', 'Nature', 'Outcomes Research', 'Phase', 'Process', 'Production', 'Publications', 'Publishing', 'Recommendation', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Services', 'Technology', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'base', 'cloud platform', 'computing resources', 'digital', 'digital ecosystem', 'experience', 'interoperability', 'open source', 'repository', 'software repository', 'tool']",OD,HARVARD UNIVERSITY,OT3,2018,347221,-0.008150222406668356
"Towards a FAIR Digital Ecosystem in the Cloud Cloud Computing, Big Data Analytics, and Artificial Intelligence are transforming biomedical research. The NIH Data Commons will provide a common, cloud-agnostic, harmonized environment where these technologies can be deployed to serve NIH intra- and extra-mural researchers, implementing FAIR principles [Wilkinson2016]. Our proposal provides two essential capabilities: (1) Global Unique Identification (GUIDs) and (2) Digital Object Publication, Citation, Replication and Reuse. We propose a FAIR biomedical ecosystem where all primary and derived digital objects (e.g., datasets, software) receive GUIDs, assisting with Findability and Accessibility, Reusability, data provenance, reproducibility, and accountability of research outcomes. GUIDs will provide full Interoperability between DOIs and prefix: accession based Compact Identifiers through a common resolution services prefix registry. All digital objects will interoperate with multiple, hybrid clouds—open source and commercial—enabling researchers to select computing resources best matching their needs. 1 - The Global Unique Identifier (GUID) Capability provides a persistent, machine resolvable identifier platform for all FAIR objects in the Commons, fully aligned with community practices, recommendations, and metadata models. 2 - The Cloud Dataverse for Biomedical Digital Object Publication, Citation, Replication, and Reuse applies FAIR principles to primary and derived datasets, computational provenance, and software, making them fully FAIR compliant, while documenting the production processes. Cloud Dataverse integrates with multiple cloud computing solutions. As an example, with these capabilities, a researcher can extract a subset of data from TOPMed or GTEx and publish it in Cloud Dataverse, with its associated metadata, provenance, and terms of use. In publications, she can cite the data and software according to Data Citation Publishers guidelines [Cousijn2017] and Software Citation Principles [Smith2016]. Other researchers can access the dataset using the GUID in the citation, resolving the repository’s dataset landing page (as recommended by the Data Citation Principles [Martone2014, Fenner2017, Starr2015]). From this landing page, researchers can repeat the original calculation, perform new computations on the dataset, or use the provenance graph to learn how the dataset was created. The data and software published in the repository reflect the evolving nature of research; anyone can publish new versions with the provenance documenting the process. Our open-source software platforms used in production, adhere to FAIR principles, and provide the basis for the two capabilities: GUIDs and Cloud Dataverse enabling the use cases above. We will expand upon them, produce new tools, and reach a wider community. Currently GUIDs and provenance describe datasets; we will generalize these mechanisms to support other digital objects, focusing on software in the pilot phase. We will connect and harmonize DataCite, identifiers.org, and N2T/EZID services to provide GUIDs; and integrate the Dataverse repository software with the Massachusetts Open Cloud, built on top of the OpenStack cloud platform, and public commercial clouds (Microsoft Azure, Google Cloud) to provide Cloud Dataverse. Our past experience producing sustainable services for overlapping communities of developers and users demonstrates our ability to apply our expertise to supporting the larger and more diverse NIH Data Commons user community. n/a",Towards a FAIR Digital Ecosystem in the Cloud,9559873,OT3OD025456,"['Accountability', 'Artificial Intelligence', 'Big Data', 'Biomedical Research', 'Cloud Computing', 'Communities', 'Community Practice', 'Computer software', 'Data', 'Data Analytics', 'Data Provenance', 'Data Set', 'Ecosystem', 'Environment', 'FAIR principles', 'Genotype-Tissue Expression Project', 'Graph', 'Guidelines', 'Hybrids', 'Learning', 'Massachusetts', 'Metadata', 'Modeling', 'Nature', 'Outcomes Research', 'Phase', 'Process', 'Production', 'Publications', 'Publishing', 'Recommendation', 'Registries', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Services', 'Technology', 'Trans-Omics for Precision Medicine', 'United States National Institutes of Health', 'base', 'cloud platform', 'computing resources', 'digital', 'digital ecosystem', 'experience', 'interoperability', 'open source', 'repository', 'software repository', 'tool']",OD,HARVARD UNIVERSITY,OT3,2018,300000,-0.008150222406668356
"Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers ﻿    DESCRIPTION (provided by applicant): The Quantitative Imaging Network (QIN) is a consortium of centers developing quantitative image features, which are proving to be valuable biomarkers of the underlying cancer biology and that can be used for assessing response to treatment and predicting clinical outcome. It is now important to discover the best quantitative imaging features for detection of response to therapeutics, to identify subtypes of cancer, and to correlate with cancer genomics. However, progress is thwarted by the lack of shared software algorithms, architectures, and resources required to compute, compare, evaluate, and disseminate these quantitative imaging features within the QIN and the broader community. We propose to develop the Quantitative Imaging Feature Pipeline (QIFP), a cloud-based, open source platform that will give researchers free access to these capabilities and hasten the introduction of quantitative image biomarkers into single- and multi-center clinical trials. The QIFP will facilitate assessment of the incremental value of new vs. existing image feature sets. It will also allow researchers to add their own algorithms to compute novel quantitative image features in their own studies and to disseminate them to the greater research community. To accomplish this: (1) We will create an expandable library of quantitative imaging feature algorithms capable of comprehensive characterization of the imaging phenotype of cancer. It will support a broad set of imaging modalities and algorithms implemented in a variety of languages, including algorithms that provide volumetric and time-varying assessment of lesion size, shape, edge sharpness, and pixel statistics. (2) We will build a cloud-based software architecture for creating, executing, and comparing quantitative image feature-generating pipelines, including algorithms in the library and/or those supplied by QIN or other researchers as plug-ins. QIFP will also have (a) a machine learning engine that lets users specify a dependent variable (e.g., progression-free survival) that the quantitative image features can used to predict, and (b) an evaluation engine that compares the utility of particular features for predicting the dependent variable. (3) We will assess the QIFP in four ways: (a) by its ability to recapitulate the role of known biomarkers in a related clinical trial, (b) by comparing linear measurement, metabolic tumor burden and novel combinations of the features in our library for predicting one-year progression-free survival, (c) by merging imaging features with known host-, drug- and tumor-based follicular lymphoma biomarkers in order to develop the most robust and integrative predictive model for patient outcomes, and (d) by using the QIFP to combine and to evaluate image feature algorithms developed by another QIN team and our own NCI- funded team in the study of radiogenomics of non-small cell lung cancer. The QIFP will fill a substantial gap in the science currently being carried out in the QIN and in the community by providing the tools and infrastructure to assess the value of novel quantitative imaging features of cancer, and will thereby accelerate incorporating new imaging biomarkers into single and multi-center clinical trials and into oncology practice. PUBLIC HEALTH RELEVANCE: We propose to develop and evaluate a software platform that has major relevance for human health. Many investigators are pursuing image-based surrogates for response to therapy that could be used in clinical trials to predict their success/failure earlier and that are more accurate than existing surrogates. Our developments will facilitate sharing, assessing, and comparing combinations of image feature-generating software algorithms for predicting treatment response, survival, and tissue genomics, which will, in turn, greatly accelerate the development and acceptance of new and more relevant imaging surrogates for assessing cancer treatments.","Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers",9525301,U01CA187947,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Cancer Biology', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Development', 'Eastern Cooperative Oncology Group', 'Evaluation', 'Failure', 'Follicular Lymphoma', 'Funding', 'Gene Expression', 'Generations', 'Genomics', 'Health', 'Human', 'Image', 'Investigation', 'Java', 'Language', 'Lesion', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Metabolic', 'Modality', 'Modernization', 'Molecular', 'Multi-Institutional Clinical Trial', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patient-Focused Outcomes', 'Pharmaceutical Preparations', 'Phenotype', 'Plug-in', 'Positron-Emission Tomography', 'Prediction of Response to Therapy', 'Privatization', 'Progression-Free Survivals', 'Pythons', 'RNA Sequences', 'Radiogenomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Specific qualifier value', 'System', 'Therapeutic', 'Time', 'Tissues', 'Tumor Burden', 'base', 'cancer biomarkers', 'cancer genomics', 'cancer imaging', 'cancer subtypes', 'cancer therapy', 'clinical predictors', 'cloud based', 'disorder subtype', 'image archival system', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'novel', 'novel therapeutics', 'oncology', 'open source', 'predict clinical outcome', 'predictive modeling', 'public health relevance', 'quantitative imaging', 'repository', 'response', 'specific biomarkers', 'statistics', 'success', 'survival prediction', 'tool', 'treatment response', 'tumor', 'vector', 'web based interface']",NCI,STANFORD UNIVERSITY,U01,2018,593292,0.011378146160068691
"Imaging Live Cells with Super-Resolution Microscopy NIH-R15 “Imaging Live Cells with Super-Resolution Microscopy” Project Summary Fluorescence optical microscopy is one of the most important tools available for the study of biological systems at the cellular level. Unfortunately, due to diffraction phenomena the resolution of fluorescence microscopes in the lateral dimension is limited to about 250 nm. As many biological structures within cells are much smaller than this, increasing resolution is of prime importance. Although several methods are now available which are able to extend the resolution of optical microscopes beyond the diffraction limit, imaging live cells with these methods remains a major challenge. Super-resolution structured illumination microscopy (SIM), which can achieve a resolution of approximately 100 nm, is a suitable super-resolution method for imaging live cells. However, adoption of this technique by biologists is hindered by the inflexible equipment and artifact-prone image analysis algorithms which are currently available. The solution to this problem demands innovations in both optical design and in data processing methods which are used in SIM. Another new method, single molecule localization microscopy, achieves much higher resolution. Although live cell imaging has been demonstrated using single molecule localization approaches, applicability of this method in live cell studies is extremely limited due to the need to collect several thousand images to reconstruct a single super-resolution image. One solution to this problem is to greatly increase the density of photoactivated molecules in a given camera frame, but doing so requires more sophisticated computational methods to produce a satisfactory result. The goal of this interdisciplinary project is to develop, improve, and utilize super-resolution microscopy with a focus on imaging live cells. In Aim 1 we will develop alternative illumination approaches for SIM using economical components, and we will develop and implement improved SIM reconstruction algorithms which produce higher quality, more reliable results than are available with current methods. In Aim 2, we will improve single molecule localization microscopy, by developing and implementing algorithms for analysis of images with high densities of photoactivated molecules. Using the high density single molecule methods we develop, we expect to be able to accelerate imaging speed by a factor of 50, with a resulting image resolution of approximately 20 nm. In Aim 3, we will use the newly developed methods for studies of the molecular basis of allergic responses. We will use a novel total internal reflection-SIM microscope with polarized excitation to reveal the relationship between cell surface receptors and the morphology of the plasma membrane, in particular membrane regions with high curvature. NIH-R15: Imaging Live Cells with Super-Resolution Microscopy Project Narrative Several methods are now available which are able to produce optical fluorescence microscopy images of cells with a resolution that is not limited by diffraction. These methods, known together as super-resolution microscopy, are limited in their capabilities and applications when imaging live cells. This interdisciplinary AREA project, submitted by a team of three investigators, will involve undergraduate and graduate students at the University of Colorado, Colorado Springs in improving live cell imaging with super-resolution microscopy techniques. We will use the improved methods for studies of the molecular basis of allergic responses, which affect more than 50 million Americans each year.",Imaging Live Cells with Super-Resolution Microscopy,9515507,R15GM128166,"['Adoption', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'American', 'Award', 'Basophilic leukemia', 'Biological', 'Biological Models', 'Biology', 'Cell Surface Receptors', 'Cell membrane', 'Cells', 'Chemistry', 'Colorado', 'Computing Methodologies', 'Data', 'Data Analyses', 'Development', 'Dimensions', 'Doctor of Philosophy', 'Equipment', 'Event', 'Fluorescence', 'Fluorescence Microscopy', 'Focus Groups', 'Frequencies', 'Goals', 'HELLS gene', 'IgE Receptors', 'Image', 'Image Analysis', 'Lateral', 'Lighting', 'Lysosomes', 'Machine Learning', 'Malignant neoplasm of pancreas', 'Membrane', 'Membrane Proteins', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Nobel Prize', 'Noise', 'Optics', 'Pattern', 'Photobleaching', 'Phototoxicity', 'Physics', 'Principal Investigator', 'Proteins', 'Quantitative Evaluations', 'Rattus', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Signal Transduction', 'Software Tools', 'Speed', 'Structure', 'Students', 'Techniques', 'Testing', 'Thick', 'United States National Institutes of Health', 'Universities', 'Work', 'allergic response', 'biological systems', 'cellular imaging', 'computer science', 'computerized data processing', 'computerized tools', 'deep learning', 'density', 'design', 'experimental study', 'fluorescence imaging', 'fluorescence microscope', 'graduate student', 'imaging detector', 'imaging modality', 'immunological synapse formation', 'improved', 'innovation', 'live cell imaging', 'microscopic imaging', 'novel', 'optical imaging', 'overexpression', 'receptor', 'reconstruction', 'single molecule', 'tool', 'undergraduate student']",NIGMS,UNIVERSITY OF COLORADO,R15,2018,432000,-0.016634054366919865
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,9622047,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Biological Neural Networks', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Quality', 'Data Set', 'Development', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Imagery', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2018,1057846,-0.02035267935184431
"MICCAI 2018 - 21th International Conference on Medical Image Computing and Computer Assisted Intervention Project Summary The Medical Image Computing and Computer Assisted Intervention (MICCAI) society is dedicated to the promotion, preservation, facilitation of research and education in the fields of medical image computing (MIC) and computer assisted interventions (CAI) including biomedical imaging and robotics; this is achieved through the organization and operation of regular international conferences of highest quality and publications which promote and foster the exchange and dissemination of advanced knowledge, expertise and experience in the field produced by leading institutions and outstanding scientists, physicians, and educators around the world. MICCAI Conferences have their roots and origin in three separate but related conferences beginning in early 1990s, the Visualization in Biomedical Computing (VBC), Computer Vision and Virtual Reality in Robotics and Medicine (CVRMed), and Medical Robotics and Computer Assisted Surgery (MRCAS), which merged into a single annual conference in 1998. MICCAI Conferences have defined a new scientific discipline over the years and have become the premier conference in the field with their proceedings having an impact factor comparable to high-impact computational journals. Conference topics include, computer vision & image processing for medical imaging, computer-aided diagnosis, computer-assisted intervention & surgery, guidance systems & robotics, visualization and virtual reality, bioscience and biology applications, specific imaging systems and new biomedical imaging applications, spanning disciplines such as radiology, pathology, surgery, oncology, cardiology, physiology, and psychiatry. The main MICCAI conference includes three days of oral presentations and poster sessions. The quality and importance of poster presentations are considered to be on a par with those of oral presentations, with both undergoing a rigorous double-blinded peer-review (~30% acceptance) and several presented papers becoming landmark publications over the years reaching up to 2,000 citations. The conference series includes community-driven software challenges, workshops and tutorials just before and/or after the main conference. These satellite events focus in detail on the current status and advances in topics relevant to MICCAI and are very highly attended. The MICCAI Conferences span the entire globe and are usually rotated among the American, European, and Asian continents. Attendance typically includes more than 45 countries, with strong student representation (~40%). The MICCAI 2018 Conference will be held in Granada, Spain in September 16th-20th, 2018. An innovative aspect of MICCAI 2018 is the initiation of a “Mentoring Program” to connect students and young investigators with established mentors from academia and industry. Along with the mission of “Women in MICCAI” committee, this proposal requests funds to initiate and ultimately sustain student travel awards to specifically enhance diversity in conference attendance, including women, underrepresented minorities, students with disabilities, and students from disadvantaged backgrounds, to present their work, providing them with a unique opportunity to reach an international audience for career development and collaborations. Project Narrative The MICCAI 2018 Conference will be held in Granada, Spain during September 16th-20th, 2018. The MICCAI conferences are the premier meeting in the medical image computing (MIC) and computer assisted intervention (CAI) communities, having introduced several landmark papers and providing a springboard for young scientists to establish themselves in the field. This proposal requests funds to provide travel awards for students, focusing on enhancing diversity by supporting the participation of women, underrepresented minorities, students with disabilities, and from disadvantaged backgrounds, to present their work, providing them with an opportunity for visibility in an established international audience, foster professional development and collaborations.",MICCAI 2018 - 21th International Conference on Medical Image Computing and Computer Assisted Intervention,9617533,R13CA225202,"['Academia', 'Address', 'American', 'Area', 'Asians', 'Award', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Cardiology', 'Climate', 'Clinic', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Computer-Assisted Surgery', 'Country', 'Development', 'Disadvantaged', 'Discipline', 'Double-Blind Method', 'Education', 'Educational workshop', 'Ensure', 'European', 'Event', 'Female', 'Fostering', 'Funding', 'Grant', 'Imagery', 'Industrialization', 'Industry', 'Institution', 'International', 'Intervention', 'Journals', 'Knowledge', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Minority', 'Mission', 'Occupations', 'Operative Surgical Procedures', 'Oral', 'Paper', 'Pathology', 'Peer Review', 'Physicians', 'Physiology', 'Plant Roots', 'Policies', 'Psychiatry', 'Publications', 'Publishing', 'Radiology Specialty', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Personnel', 'Research Support', 'Robotics', 'Scientist', 'Series', 'Sex Bias', 'Societies', 'Spain', 'Students', 'System', 'Translations', 'Travel', 'United States National Institutes of Health', 'Woman', 'Work', 'Writing', 'base', 'bioimaging', 'career', 'career development', 'community intervention', 'computer science', 'design', 'digital imaging', 'disabled students', 'disadvantaged student', 'experience', 'image processing', 'imaging system', 'improved', 'innovation', 'lecture notes', 'meetings', 'new technology', 'oncology', 'operation', 'peer', 'posters', 'preservation', 'programs', 'prototype', 'racial and ethnic', 'research and development', 'social', 'symposium', 'underrepresented minority student', 'virtual reality', 'women faculty']",NCI,UNIVERSITY OF PENNSYLVANIA,R13,2018,5000,0.028544941597965872
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9542210,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting', 'whole slide imaging']",NIAMS,UNIVERSITY OF FLORIDA,R01,2018,377571,0.06377465574925842
"Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner Project Summary/Abstract This application is for a shared instrumentation grant from the Light Microscope Imaging Facility at Case Western Reserve University (CWRU) School of Medicine (SOM) to acquire a fully automated, high-capacity, high- resolution Hamamatsu Nanozoomer S60 slide scanner that can accommodate both brightfield and fluorescence imaging in single-slide and double-slide formats. We also request MicroDimensions 3D reconstruction and alignment software packages for manipulating and analyzing the whole slide images produced with the scanner. We need to replace a scanner that is not functioning properly. Our well-established shared core facility supports NIH-funded investigators by giving them access to state-of-the-art microscopy technologies that enhance collaborative, multidisciplinary research. Acquisition of this instrument will have a high impact on the biomedical research at CWRU and expand the scope of our NIH-funded projects. Several projects have been identified that will utilize the scanner and its associated analyses programs. These include: the genetic mechanisms underlying skin fibrosis and cranial bone development (Atit); the mechanisms behind the lifelong functions of transcription factors in axonal growth and architecture (Deneris); deep-learning for histologic image predictors of various diseases (Madabhushi); the development of diagnostic probes to discriminate between glioma subtypes for screening and survival therapies (Brady-Kalnay); the role of progesterone receptors in the control of parturition and the development of therapies to prevent preterm birth (Messiano); the mechanisms by which breast cancer stem cells overcome metastatic latency leading to disease recurrence and the biomarkers that could potentially identify those tumors likely to undergo this process (Schiemann); and the significance of cholesterol-related proteins in brain and retinal function (Pikuleva). Many additional projects of minor users and others at CWRU are anticipated. All of the proposed projects are in need of a high-capacity automated scanner acquiring whole slide images so that analyses can be applied to tissues that cover hundreds of fields of view, rather than the single regions of interest that can be acquired on a standard microscope. Narrative This proposal seeks to acquire a new, state-of-the-art high-speed, high content digital slide scanner for high resolution cellular and biomarker identfcation across large tissue areas. The dual mode (fluorescence and brightfield) allows flexibility in marker visualization while the software allows the automated alignment of whole slide images for multi-stain analysis and 3d reconstruction of serial section for in-depth analysis of specimens. This equipment is essential for our NIH disease-related studies providing a profound positive impact on a wide range of public health areas.",Hamamatsu Nanozoomer S60 Digital Whole Slide Scanner,9489976,S10OD024981,"['Architecture', 'Biological Markers', 'Biomedical Research', 'Birth', 'Bone Development', 'Brain', 'Cephalic', 'Cholesterol', 'Computer software', 'Core Facility', 'Development', 'Diagnostic', 'Disease', 'Enhancement Technology', 'Funding', 'Genetic', 'Glioma', 'Grant', 'Interdisciplinary Study', 'Light Microscope', 'Microscope', 'Microscopy', 'Minor', 'Premature Birth', 'Process', 'Progesterone Receptors', 'Proteins', 'Recurrence', 'Research Personnel', 'Resolution', 'Retinal', 'Role', 'Slide', 'Tissues', 'United States National Institutes of Health', 'Universities', 'axon growth', 'cancer stem cell', 'deep learning', 'digital', 'equipment acquisition', 'fluorescence imaging', 'histological image', 'imaging facilities', 'instrumentation', 'interest', 'malignant breast neoplasm', 'medical schools', 'prevent', 'programs', 'reconstruction', 'screening', 'skin fibrosis', 'therapy development', 'transcription factor', 'tumor', 'whole slide imaging']",OD,CASE WESTERN RESERVE UNIVERSITY,S10,2018,303390,0.006519731341488981
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. ​A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,9679722,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Autistic Disorder', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Imagery', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'learning strategy', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2018,303226,0.004470445256050238
"Automated Diagnosis and Progression Rate of IPF Using HRCT Project Summary: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. Diagnosis and stratification of disease phenotypes are important in order to decipher the effects of novel therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individuals. Few computerized diagnostic tools have been developed for IPF that correlate with visual and surgical lung biopsy; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good predictive models with localized region exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use as a derivative dataset the anonymized clinical data and source images on 234 patients with IPF and 266 patients with IPF suspected, but not IPF based on HRCT and the surgical biopsy who have participated in multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for high through-put quantitative image analysis, we will train a classifier with features of anatomic distribution and reproducible imaging features expressed with a quantitative lung fibrosis (QLF) score, testing on separate data from in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitial Lung Disease Program. Furthermore, the second aim is to develop a rate of progression at local region and to aggregate predictive models using Cox proportional regression models, which will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that diagnose and anticipate disease course in patients with IPF and subdividing patients into more homogeneous groups prior to the development of significant respiratory impairment. We anticipate that models can be used clinically at the individual patient level to enable more informed and timely management decisions to define more homogeneous cohorts for purposes of testing new targeted therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. Relevance to Public Health: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rate of progression is highly variables, which hampers timely decisions about referral for lung transplantation or treatments using new drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to diagnose and predict disease course robustly in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with IPF and non-IPF with reducing chance of lung biopsy and predict slowly versus rapidly progressive disease, leading to more time to treat patients and timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Automated Diagnosis and Progression Rate of IPF Using HRCT,9592308,R21HL140465,"['Acute', 'Air', 'Algorithms', 'Anatomy', 'Archives', 'Automation', 'Biological', 'Biopsy', 'Categories', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Assisted', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Deterioration', 'Development', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease stratification', 'Elderly', 'Etiology', 'Exhibits', 'General Population', 'Glass', 'Goals', 'Growth', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Impairment', 'Individual', 'Informatics', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Laboratories', 'Lobar', 'Lobe', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathology', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Prevalence', 'Probability', 'Progression-Free Survivals', 'Progressive Disease', 'Public Health', 'Pulmonary Fibrosis', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Spatial Distribution', 'Stable Disease', 'Standardization', 'Testing', 'Texture', 'Time', 'Time Management', 'Training', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'clinically relevant', 'cohort', 'computerized', 'data archive', 'digital imaging', 'disease natural history', 'disease phenotype', 'functional decline', 'idiopathic pulmonary fibrosis', 'image processing', 'imaging biomarker', 'improved', 'individual patient', 'individualized medicine', 'new therapeutic target', 'novel', 'novel therapeutics', 'predictive modeling', 'prognostic', 'programs', 'pulmonary function', 'quantitative imaging', 'respiratory', 'success', 'survival prediction', 'tool']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2018,113241,-0.034741579970470574
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,9547416,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Anatomy', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathologic', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'clinical application', 'clinical imaging', 'clinical phenotype', 'clinical practice', 'cloud based', 'cluster computing', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'heart imaging', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'multi-atlas segmentation', 'multidisciplinary', 'new technology', 'novel', 'open source', 'outreach', 'public health relevance', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2018,597688,0.05150572568071851
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9548627,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'digital pathology', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'pathology imaging', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2018,573677,0.027591184462099932
"Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD ABSTRACT The goal of this NIDDK Mentored Research Scientist Development Award is to provide an organized scientific and educational environment for Dr. Timothy Kline to begin his transition into an independent research career focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. This proposal outlines a five-year training plan at Mayo Clinic under the primary mentorship of Dr. Bradley Erickson and a Mentoring Team comprised of accomplished researchers in the fields of: biology, nephrology, genetics, radiology, informatics; medical physics, biostatistics, image processing, and physiology. The focus of this proposal is to improve both research studies and disease prognosis for autosomal dominant polycystic kidney disease (ADPKD) patients through biomedical imaging techniques. It is well understood that imaging is essential for ADPKD diagnosis, monitoring, and outcome prediction. Clinical studies utilize total kidney volume (TKV) (as measured by MRI as an image-based biomarker) to follow the progression of ADPKD, as larger TKVs have been shown to correlate with worse prognosis in both human and animal-model studies. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming, costly, and poorly standardized. The introduction of automated approaches for measuring TKV will: greatly improve measurement throughput, significantly reduce costs associated with performing research studies, allow accurate and reproducible measurements to be obtained both within and across institutions; facilitate the search for new imaging biomarkers. The specific aims of this project are to: (i) develop and validate automated tools to characterize renal structure, such as TKV and cystic burden; (ii) explore new imaging biomarkers by image texture feature analysis and pattern recognition techniques; and (iii) develop a new technique to measure renal blood flow. This research will be facilitated by Mayo Clinic's outstanding clinical and research environment dedicated to improving patient care, as well as the Mayo Clinic Translational PKD Center, which focuses on translating basic science research into improvements in the management and treatment of ADPKD patients. Dr. Kline's background in imaging technologies and image processing makes him particularly suited to perform this research. In addition to the above aims, Dr. Kline will: 1) develop a strong knowledge base in both nephrology and radiology by attending relevant rounds, seminars, and national conferences; 2) enhance his knowledge of medical imaging, biology, physiology, genetics, and programming through coursework and mentoring; 3) attend workshops focused on grant and publication writing; and 4) submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of new imaging biomarkers of ADPKD. Obtaining this K Award will greatly facilitate Dr. Kline's transition into a prosperous independent research career. Narrative Autosomal dominant polycystic kidney disease (ADPKD) is one of the most common monogenic disorders and is a leading cause of end-stage renal disease. Total kidney volume (TKV) has become the main image-based biomarker for following ADPKD progression. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming and costly. This project will develop automated tools to increase measurement throughput, and explore new image-based biomarkers that will significantly add to the assessment of patient prognosis, and will have the ability to more quickly judge the effectiveness of interventions.",Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD,9566167,K01DK110136,"['Abdomen', 'Affect', 'Age', 'Anatomy', 'Animals', 'Architecture', 'Area', 'Autosomal Dominant Polycystic Kidney', 'Basic Science', 'Biological Markers', 'Biology', 'Biometry', 'Blood Vessels', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Cyst', 'Data', 'Databases', 'Disease', 'Disease Marker', 'Disease Progression', 'Educational workshop', 'Effectiveness of Interventions', 'End stage renal failure', 'Environment', 'FarGo', 'Fibrosis', 'Genetic', 'Genetic Programming', 'Geometry', 'Goals', 'Gold', 'Grant', 'Hepatic Cyst', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Informatics', 'Institution', 'Intervention', 'K-Series Research Career Programs', 'Kidney', 'Knowledge', 'Liver', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Mendelian disorder', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Microscopic', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrology', 'Organ', 'Pathology', 'Patient Care', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Physics', 'Physiologic pulse', 'Physiology', 'Polycystic Kidney Diseases', 'Process', 'Protocols documentation', 'Publications', 'Radiology Specialty', 'Renal Blood Flow', 'Renal Tissue', 'Renal function', 'Reproducibility', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Spin Labels', 'Standardization', 'Structure', 'Study models', 'Suggestion', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'Writing', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'disease diagnosis', 'educational atmosphere', 'functional decline', 'human model', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'insight', 'interest', 'kidney vascular structure', 'knowledge base', 'novel imaging technology', 'outcome forecast', 'outcome prediction', 'precision medicine', 'pressure', 'prognostic value', 'radiological imaging', 'renal artery', 'research study', 'shear stress', 'symposium', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,K01,2018,154915,-0.0008827937811928445
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,9215686,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cells', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Education', 'Educational Curriculum', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'faculty research', 'graduate student', 'lecturer', 'lectures', 'personalized approach', 'programs', 'public health relevance', 'quantitative imaging', 'student training', 'teaching assistant', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2017,59383,0.004646304225760531
"Extracting rich information from biological images Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Extracting rich information from biological images,9276910,R35GM122547,"['Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Learning', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'bioimaging', 'data mining', 'data visualization', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2017,513030,0.06191872781642476
"A high-throughput imaging and classification system for fruit flies PROJECT SUMMARY / ABSTRACT In this Phase I SBIR application, FlySorter proposes to development a high throughput imaging and classification system to aid research with fruit flies, a widely-used model organism relevant to both basic science as well as studies in human health. The use of animal model systems is essential for research in almost all aspects of biology: genetics, development, neuroscience, disease, physiology, and beyond. The fruit fly – Drosophila melanogaster – is small and easy to care for, but is complex enough an organism to provide a wealth of information that directly relates to human biology and health. Over 75% of human diseases with a genetic basis (including depression, alcoholism, certain forms of cancer, and many more) are either present or have an analog in Drosophila. Modern genetic tools, such as CRISPR/cas9, allow the creation of transgenic flies that provide the opportunity to study diseases, pathways and systems that don’t exist naturally in Drosophila. With these advances, fruit flies are becoming more frequently subjects for drugs screens. For all the advances in the biological tools and techniques applicable to flies, however, the limiting factor in many experiments is the manual labor involved in a few common tasks: moving flies from vial to vial or other lab equipment; classifying and sorting flies by sex, eye color and other phenotypes; and collecting virgin female flies before they mate so that they can be used in controlled crosses, etc. FlySorter’s patent-pending fly dispensing mechanism can reliably deliver a single organism from a vial containing hundreds of awake flies, and our novel FlyPlate system allows storage of individual flies in custom 96 well plates. FlySorter’s robotic fly handling system, co-developed with the de Bivort Lab at Harvard, is capable of manipulating and transporting those individual flies between vial, 96 well plate, and experimental apparatus. The next piece of the automation puzzle to solve is high throughput imaging and classification. To accomplish this goal, FlySorter will: 1) complete a prototype automated image capture hardware system; 2) adapt state-of-the-art computer vision and machine learning algorithms for use on Drosophila; and 3) build a module that can physically sort the classified flies into different vials. Once integrated into the existing FlySorter product ecosystem, this imaging and classification module will greatly expand the kinds of experiments and screens that can be automated, allowing for the study of larger populations or a wider variety of flies, reducing the impact of human error, and freeing up valuable time for researchers. PROJECT NARRATIVE Fruit flies – Drosophila melanogaster – are one of the most widely used model organisms in biology, for research in genetics, development, neuroscience, disease, and much more. One of the most common tasks in Drosophila labs is sorting flies by various markers and phenotypes using a microscope and paintbrush. FlySorter aims to build an automated system for sorting flies using high resolution digital cameras and modern computer vision algorithms, which will obviate the need for such tedious manual labor.",A high-throughput imaging and classification system for fruit flies,9408980,R43OD023302,"['Air', 'Alcoholism', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Animal Model', 'Animals', 'Appearance', 'Automation', 'Basic Science', 'Biological', 'Biological Assay', 'Biological Models', 'Biological Neural Networks', 'Biology', 'CRISPR/Cas technology', 'Caring', 'Classification', 'Code', 'Complex', 'Computer Vision Systems', 'Custom', 'Data Set', 'Development', 'Devices', 'Disease', 'Disease Pathway', 'Dorsal', 'Drosophila genus', 'Drosophila melanogaster', 'Ecosystem', 'Ensure', 'Eye', 'Eye Color', 'Female', 'Floor', 'Genes', 'Genetic', 'Genetic Screening', 'Genetic study', 'Genotype', 'Goals', 'Grant', 'Head', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Legal patent', 'Lighting', 'Longevity', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mechanics', 'Mental Depression', 'Methodology', 'Microscope', 'Modernization', 'Motor', 'Mutation', 'Names', 'Neurosciences', 'Obesity', 'Optics', 'Organism', 'Partner in relationship', 'Phase', 'Phenotype', 'Physiology', 'Population', 'Preclinical Drug Evaluation', 'Pump', 'Research', 'Research Personnel', 'Resolution', 'Robot', 'Robotics', 'Sampling', 'Sclera', 'Shapes', 'Small Business Innovation Research Grant', 'Sorting - Cell Movement', 'Standardization', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Transgenic Organisms', 'Universities', 'Vial device', 'Walking', 'Work', 'analog', 'awake', 'base', 'depression model', 'digital', 'digital imaging', 'experimental study', 'fly', 'genetic strain', 'human disease', 'improved', 'interest', 'laboratory equipment', 'male', 'meter', 'novel', 'phenotypic biomarker', 'prevent', 'prototype', 'sex', 'tool', 'virtual']",OD,"FLYSORTER, LLC",R43,2017,225000,0.01678637382553311
"THE XNAT IMAGING INFORMATICS PLATFORM PROJECT SUMMARY This proposal aims to continue the development of XNAT. XNAT is an imaging informatics platform designed to facilitate common management and productivity tasks for imaging and associated data. We will develop the next generation of XNAT technology to support the ongoing evolution of imaging research. Development will focus on modernizing and expanding the current system. In Aim 1, we will implement new web application infrastructure that includes a new archive file management system, a new event bus to manage cross-service orchestration and a new Javascript library to simplify user interface development. We will also implement new core services, including a Docker Container service, a dynamic scripting engine, and a global XNAT federation. In Aim 2, we will implement two innovative new capabilities that build on the services developed in Aim 1. The XNAT Publisher framework will streamline the process of data sharing by automating the creation and curation of data releases following best practices for data publication and stewardship. The XNAT Machine Learning framework will streamline the development and use of machine learning applications by integrating XNAT with the TensorFlow machine learning environment and implementing provenance and other monitoring features to help avoid the pitfalls that often plague machine learning efforts. For both Aim 1 and 2, all capabilities will be developed and evaluated in the context of real world scientific programs that are actively using the XNAT platform. In Aim 3, we will provide extensive support to the XNAT community, including training workshops, online documentation, discussion forums, and . These activities will be targeted at both XNAT users and developers. RELEVANCE Medical imaging is one of the key methods used by biomedical researchers to study human biology in health and disease. The imaging informatics platform described in this application will enable biomedical researchers to capture, analyze, and share imaging and related data. These capabilities address key bottlenecks in the pathway to discovering cures to complex diseases such as Alzheimer's disease, cancer, and heart disease.",THE XNAT IMAGING INFORMATICS PLATFORM,9384200,R01EB009352,"['Address', 'Administrator', 'Alzheimer&apos', 's Disease', 'Architecture', 'Archives', 'Area', 'Automation', 'Biomedical Research', 'Brain', 'Cardiology', 'Categories', 'Classification', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Docking', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Evolution', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Informatics', 'Instruction', 'Internet', 'Libraries', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Modality', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Newsletter', 'Optics', 'Paper', 'Pathway interactions', 'Peer Review', 'Persons', 'Plague', 'Positron-Emission Tomography', 'Principal Investigator', 'Process', 'Productivity', 'Publications', 'Publishing', 'Radiology Specialty', 'Research', 'Research Infrastructure', 'Research Personnel', 'Security', 'Services', 'System', 'Technology', 'Training', 'Validation', 'base', 'biomedical resource', 'computer framework', 'computing resources', 'data sharing', 'design', 'distributed data', 'educational atmosphere', 'hackathon', 'imaging informatics', 'imaging program', 'improved', 'innovation', 'next generation', 'online tutorial', 'open source', 'outreach program', 'pre-clinical', 'programs', 'skills', 'symposium', 'tool', 'virtual', 'web app']",NIBIB,WASHINGTON UNIVERSITY,R01,2017,685783,0.01988654969198593
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,9315808,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Computing', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Pulmonary Emphysema', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'image guided', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'public health relevance', 'quantitative imaging', 'response', 'task analysis', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2017,413289,0.03874656675671057
"Interpreting limits to nanoparticle delivery in high-stroma low-perfusion tumors 4.4.7 Project Summary/Abstract  The central theme in this work is that critical spatial patterns exist in highly resistant cancer stroma and vascular density that inherently inhibit larger nanoparticle penetration into cancer, and that these phenotypes can be imaged in vivo. We will use in vivo diagnostic imaging, combined with ex vivo analysis to test this in pancreatic cancer, which has as well known drug penetration limitation. Specifically, we will quantify nanoparticle penetration in pancreas cancer, which has high stroma content and low vascular density. The analysis and prediction of efficacy will be quantitatively developed by methodological correlation of in-vivo and ex vivo images using Fourier spatial frequency analysis.  We will determine the characteristic spatial patterns of these tumor microstructures that present as barriers to nanoparticle transport, as assayed through in vivo/ex vivo studies. We have seen that these characteristic spectral features appear in high-field magnetic resonance imaging (HF-MRI) scans and micro-Computed Tomography (uCT) scans of tumors imaged within the ongoing nanoparticle project at DHMC. The scope of this project is to conduct a secondary analysis on the images that are being produced within these projects, with two specific aims. 1) We will directly correlate nanoparticle penetration and distribution to the Fourier spatial frequencies found in in vivo images by Fourier spatial frequency analysis in which we have demonstrated expertise. The in vivo images will be analyzed by correlating them with histological sections of nanoparticle distribution post-treatment. Tumors will be classified on two levels as either a high or low permeability to a specific nanoparticle formulation (to quantify the amount of agent delivered), and as having high or low isotropy (to quantify the dispersion of the agent). 2) We will then apply this characteristic morphology analysis to pre-treatment, pre-operative HF-MRI, uCT images, and analyze their value as a potential diagnostic classifier. We will use a Support Vector Machine Analysis to predict the permeability and isotropy of unknown tumors, and validate our results against experimental outcomes. An iterative strategy will optimize the predictive power of the method, and be used to distinguish between characteristic spectra that are good and bad classifiers.  The research will be produced using the unique software systems that we have designed during preliminary studies, and will be deployed on an analysis platform that can be integrated with the hospital- based DICOM and virtual pathology environment to allow clinical investigators to plan adjuvant therapies to promote nanoparticle efficacy. Several hundred high-quality scans are now available for analysis, which will be processed and reported on within the first year of funding. By year two, the established system is projected to be able to analyze images within a few minutes post-scan. These analysis methods will give us the key background needed to advance our fundamental understanding of nanoparticle in-vivo delivery, and test ways to interrupt transport barriers in interventional future work. 4.4.8 Project Narrative The PI will apply a novel image analysis method to identify spatial patterns in images taken from in vivo experiments that indicate the presence of physical barriers to nanoparticle and liposomal transport in solid cancer tumor. Successful completion of this proposal will result in methods to predict the permeability of tumors to nanoparticle and large-molecule adjuvant therapies during the planning stage.",Interpreting limits to nanoparticle delivery in high-stroma low-perfusion tumors,9307795,R03CA208510,"['Adjuvant Therapy', 'Aftercare', 'Antineoplastic Agents', 'Area', 'Behavior', 'Biological', 'Biological Assay', 'Blood Vessels', 'Cancer Center', 'Characteristics', 'Clinical Investigator', 'Clinical Trials', 'Coupled', 'Deposition', 'Diagnostic', 'Diagnostic Imaging', 'Environment', 'Extracellular Matrix', 'Formulation', 'Frequencies', 'Funding', 'Future', 'Goals', 'Histologic', 'Histology', 'Hospitals', 'Image', 'Image Analysis', 'Immune', 'Intercellular Fluid', 'Interruption', 'Intervention', 'Investigation', 'Isotropy', 'Liposomes', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Mediating', 'Methodology', 'Methods', 'Morphology', 'Nanotechnology', 'Outcome', 'Pathology', 'Pattern', 'Penetration', 'Perfusion', 'Permeability', 'Pharmaceutical Preparations', 'Phenotype', 'Process', 'Reporting', 'Research', 'Resistance', 'Sampling', 'Scanning', 'Solid', 'Spectrum Analysis', 'System', 'Testing', 'Therapeutic', 'Vascular Permeabilities', 'Work', 'X-Ray Computed Tomography', 'base', 'cancer imaging', 'cancer therapy', 'density', 'design', 'ex vivo imaging', 'experimental study', 'fluid flow', 'histological image', 'improved', 'in vivo', 'in vivo imaging', 'magnetic field', 'nanoparticle', 'neovasculature', 'novel', 'oncology', 'prevent', 'secondary analysis', 'software systems', 'therapy resistant', 'treatment response', 'tumor', 'virtual']",NCI,DARTMOUTH COLLEGE,R03,2017,2500,-0.03444704909291926
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages. PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,9306122,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Drug Targeting', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Hydration status', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Medical', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Reproducibility', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Statistical Data Interpretation', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'algorithmic methodologies', 'base', 'computer code', 'cryogenics', 'density', 'design', 'fiber cell', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'microscopic imaging', 'new technology', 'next generation', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2017,306527,-0.014812131046919749
"The Blackfynn Platform for Rapid Data Integration and Collaboration Summary One in seven people worldwide suffers from a brain disorder, e.g., epilepsy, Parkinson's, stroke, or dementia. Development of future treatments depends on improving our understanding of brain function and disease, and validating new treatments critically depends on identifying the underlying biomarkers associated with different conditions. Biomarker discovery requires volume, quality, richness, and diversity of data. This Direct-to-Phase II project extends Blackfynn's cloud data management platform for team science, in order to support interactive data curation and integration and to facilitate biomarker discovery. Our first technical aim develops tools to help select, curate, assess, and regularize datasets: we develop novel “live” query capabilities to ensure users discover relevant data, develop mechanisms for using data's provenance to decide on trustworthiness, and build tools for mapping fields to common data elements. These capabilities address the critical, under-served problem of selecting the data to analyze. Our second technical aim develops techniques for incorporating algorithms to link and co-register across multi-modal data and metadata. Using ranking and machine learning, we can incorporate and combine state-of-the-art algorithms for finding data relationships, and we can link to remote data sources. These capabilities enable scientists to analyze richer datasets with multiple data modalities and properties – thus enabling them to discover more complex correlations and biomarkers. In our third aim, Blackfynn's new technical capabilities will be applied to challenges faced by Blackfynn partners, including problems assessing trustworthiness of data annotations, conducting image analysis, modeling epileptic networks, and identifying biomarkers for neuro-oncology indications. As part of this validation we will also develop HIPAA-compliant mechanisms for working with protected and de-identified data together. Together, these three thrusts will ensure that development of the Blackfynn platform results in tools and technologies that meaningfully accelerate scientific understanding and discovery over rich and complex data, leading to improved treatments for neurologic disease.   Narrative This Direct-to-Phase II project extends the Blackfynn cloud data management platform to enable biomarker discovery for research and development of improved drugs, devices and clinical care for patients with neurologic disease: it develops tools for assembling, evaluating, and rating data, and linking it across modalities and to external systems. It also validates the techniques' effectiveness using real challenges faced by Blackfynn partners, in imaging, epilepsy, and brain tumor research.",The Blackfynn Platform for Rapid Data Integration and Collaboration,9343385,R44DA044929,"['Address', 'Algorithms', 'Benchmarking', 'Biological Markers', 'Brain', 'Brain Diseases', 'Brain Neoplasms', 'Case Study', 'Clinical Pharmacology', 'Collaborations', 'Common Data Element', 'Complex', 'Data', 'Data Analyses', 'Data Analytics', 'Data Collection', 'Data Discovery', 'Data Provenance', 'Data Science', 'Data Set', 'Data Sources', 'Dementia', 'Development', 'Devices', 'Disease', 'Effectiveness', 'Ensure', 'Epilepsy', 'Funding', 'Future', 'Health', 'Health Insurance Portability and Accountability Act', 'Image', 'Image Analysis', 'Individual', 'Learning', 'Link', 'Machine Learning', 'Maps', 'Mental Depression', 'Metadata', 'Modality', 'Modeling', 'National Institute of Neurological Disorders and Stroke', 'Neurosciences', 'Neurosciences Research', 'Notification', 'Ontology', 'Output', 'Parkinson Disease', 'Patient Care', 'Pharmaceutical Preparations', 'Phase', 'Plug-in', 'Process', 'Property', 'Research', 'Research Infrastructure', 'Science', 'Scientist', 'Semantics', 'Series', 'Small Business Innovation Research Grant', 'Source', 'Standardization', 'Stroke', 'Supervision', 'System', 'Techniques', 'Technology', 'Testing', 'Training', 'Translational Research', 'Trust', 'Use Effectiveness', 'Validation', 'Work', 'base', 'biomarker discovery', 'clinical application', 'clinical care', 'cloud platform', 'computer science', 'data access', 'data integration', 'data management', 'improved', 'indexing', 'nervous system disorder', 'neuro-oncology', 'neuroimaging', 'novel', 'novel therapeutics', 'open source', 'research and development', 'tool']",NIDA,"BLACKFYNN, INC.",R44,2017,652921,-0.003944265393736575
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9544350,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,56360,0.022728794852476614
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9355633,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intervention', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Research Support', 'Shapes', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'aging population', 'base', 'catalyst', 'clinical translation', 'cohesion', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'portability', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2017,454865,0.022728794852476614
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics. PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9150601,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Community Health', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Data Analytics', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disadvantaged population', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'mobile computing', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2017,326571,0.024018831571256612
"Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle ﻿    DESCRIPTION (provided by applicant):  There is growing awareness that weakness of muscle is a significant biomedical health issue associated with many different chronic diseases and aging. There are a variety of different diseases that affect muscle, including muscular dystrophy, fibromyalgia, cerebral palsy, amyotrophic lateral sclerosis, and myasthenia gravis, each of which carries its own unique set of symptoms, accompanied by a myriad of genetic and molecular abnormalities. There is agreement within the basic research and clinical communities that important morphological characteristics of muscle fibers, such as fiber cross sectional area, fiber type, the number and position of myonuclei, cellular infiltration, and fibrosis are among many critical factors that determine the health and functionality of the muscle. Until now, the imaging equipment available is relatively low throughput and the quantification is still largely based on manual or, at best, semi-automatic methods that require extensive human intervention. In Phase I, CytoInformatics LLC has developed a software called CytoQuant, which can accurately perform automatic segmentation and provide accurate boundaries of each muscle fiber for a cropped image patch. The goal of CytoInformatics LLC in Phase II is to 1) deliver the first version of the CytoQuant software to the market, 2) develop the second version of CytoQuant by continuously improving its performance, especially in handling large scale, whole slide images, and also 3) develop an integrated multiplexing imaging hardware and analysis software framework as a seamless solution for high throughput, automated image analysis of muscle specimens. After careful investigation in Phase I (please refer to the details in business plan), we conclude that this integrated software/hardware platform with cutting-edge technologies in advanced imaging, large scale machine learning, and big data is commercially attractive to the entire muscle community including research institutes, hospitals, and pharmaceutical and athletic companies, demonstrated by strong enthusiasm among end users and many supporting letters. The specific aims are: 1) Deliver the first version of CytoQuant developed in Phase I to the market, continue to develop the second version of CytoQuant, which will focus on improving the robustness and speed in handling whole slide images; 2) Develop an integrated platform that provides unified imaging hardware and image analysis software to handle whole slide images labeled with multiple bio-relevant markers. This unified whole-slide based software and hardware solution will deliver an efficient and specialized imaging platform that seamlessly integrates with a high throughput, multi-marker, and automatic image analysis software specifically designed for muscle. PUBLIC HEALTH RELEVANCE:  In Phase II, CytoInformatics is proposing a unified whole-slide multispectral imaging (MSI) system that seamlessly integrates with a high throughput, accurate, and automated software to provide fast and efficient, multiplexed imaging and quantitative muscle image analysis simultaneously. This will be the first integrated hardware/software solution that is specifically designed for muscle.",Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle,9355100,R42AG055375,"['Affect', 'Aging', 'Agreement', 'Amyotrophic Lateral Sclerosis', 'Area', 'Athletic', 'Awareness', 'Basic Science', 'Big Data', 'Biological Markers', 'Biology', 'Businesses', 'Cellular Infiltration', 'Cerebral Palsy', 'Characteristics', 'Chronic Disease', 'Clinical', 'Communities', 'Computer software', 'Development', 'Discipline', 'Disease', 'Eosine Yellowish', 'Equipment', 'Exhibits', 'Feedback', 'Fiber', 'Fibromyalgia', 'Fibrosis', 'Fluorescence', 'Future', 'Goals', 'Health', 'Hematoxylin', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Institutes', 'Intervention', 'Intuition', 'Investigation', 'Label', 'Laboratory Research', 'Learning', 'Learning Module', 'Letters', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Microscopy', 'Molecular Abnormality', 'Morphology', 'Muscle', 'Muscle Fibers', 'Muscle Weakness', 'Muscle function', 'Muscular Dystrophies', 'Myasthenia Gravis', 'Noise', 'Performance', 'Pharmacologic Substance', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Qi', 'Recruitment Activity', 'Reporting', 'Research Institute', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Slide', 'Software Design', 'Software Framework', 'Specimen', 'Speed', 'Staining method', 'Stains', 'Symptoms', 'Technology', 'Tissue Sample', 'Tissue imaging', 'Universities', 'Update', 'Variant', 'Yang', 'adaptive learning', 'base', 'bioimaging', 'commercialization', 'design', 'experience', 'gigabyte', 'graphical user interface', 'image processing', 'image visualization', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'interest', 'member', 'muscle form', 'novel', 'optical imaging', 'programs', 'public health relevance', 'success', 'technology development', 'user-friendly']",NIA,"CYTOINFORMATICS, LLC",R42,2017,391844,0.06945302897987218
"Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers ﻿    DESCRIPTION (provided by applicant): The Quantitative Imaging Network (QIN) is a consortium of centers developing quantitative image features, which are proving to be valuable biomarkers of the underlying cancer biology and that can be used for assessing response to treatment and predicting clinical outcome. It is now important to discover the best quantitative imaging features for detection of response to therapeutics, to identify subtypes of cancer, and to correlate with cancer genomics. However, progress is thwarted by the lack of shared software algorithms, architectures, and resources required to compute, compare, evaluate, and disseminate these quantitative imaging features within the QIN and the broader community. We propose to develop the Quantitative Imaging Feature Pipeline (QIFP), a cloud-based, open source platform that will give researchers free access to these capabilities and hasten the introduction of quantitative image biomarkers into single- and multi-center clinical trials. The QIFP will facilitate assessment of the incremental value of new vs. existing image feature sets. It will also allow researchers to add their own algorithms to compute novel quantitative image features in their own studies and to disseminate them to the greater research community. To accomplish this: (1) We will create an expandable library of quantitative imaging feature algorithms capable of comprehensive characterization of the imaging phenotype of cancer. It will support a broad set of imaging modalities and algorithms implemented in a variety of languages, including algorithms that provide volumetric and time-varying assessment of lesion size, shape, edge sharpness, and pixel statistics. (2) We will build a cloud-based software architecture for creating, executing, and comparing quantitative image feature-generating pipelines, including algorithms in the library and/or those supplied by QIN or other researchers as plug-ins. QIFP will also have (a) a machine learning engine that lets users specify a dependent variable (e.g., progression-free survival) that the quantitative image features can used to predict, and (b) an evaluation engine that compares the utility of particular features for predicting the dependent variable. (3) We will assess the QIFP in four ways: (a) by its ability to recapitulate the role of known biomarkers in a related clinical trial, (b) by comparing linear measurement, metabolic tumor burden and novel combinations of the features in our library for predicting one-year progression-free survival, (c) by merging imaging features with known host-, drug- and tumor-based follicular lymphoma biomarkers in order to develop the most robust and integrative predictive model for patient outcomes, and (d) by using the QIFP to combine and to evaluate image feature algorithms developed by another QIN team and our own NCI- funded team in the study of radiogenomics of non-small cell lung cancer. The QIFP will fill a substantial gap in the science currently being carried out in the QIN and in the community by providing the tools and infrastructure to assess the value of novel quantitative imaging features of cancer, and will thereby accelerate incorporating new imaging biomarkers into single and multi-center clinical trials and into oncology practice. PUBLIC HEALTH RELEVANCE: We propose to develop and evaluate a software platform that has major relevance for human health. Many investigators are pursuing image-based surrogates for response to therapy that could be used in clinical trials to predict their success/failure earlier and that are more accurate than existing surrogates. Our developments will facilitate sharing, assessing, and comparing combinations of image feature-generating software algorithms for predicting treatment response, survival, and tissue genomics, which will, in turn, greatly accelerate the development and acceptance of new and more relevant imaging surrogates for assessing cancer treatments.","Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers",9324146,U01CA187947,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Cancer Biology', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Development', 'Eastern Cooperative Oncology Group', 'Evaluation', 'Failure', 'Follicular Lymphoma', 'Funding', 'Gene Expression', 'Generations', 'Genomics', 'Health', 'Human', 'Image', 'Investigation', 'Java', 'Language', 'Lesion', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Metabolic', 'Modality', 'Modernization', 'Molecular', 'Multi-Institutional Clinical Trial', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patient-Focused Outcomes', 'Pharmaceutical Preparations', 'Phenotype', 'Plug-in', 'Positron-Emission Tomography', 'Privatization', 'Progression-Free Survivals', 'Pythons', 'RNA Sequences', 'Radiogenomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Specific qualifier value', 'System', 'Therapeutic', 'Time', 'Tissues', 'Tumor Burden', 'base', 'cancer biomarkers', 'cancer genomics', 'cancer imaging', 'cancer subtypes', 'cancer therapy', 'clinical predictors', 'cloud based', 'disorder subtype', 'image archival system', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'novel', 'novel therapeutics', 'oncology', 'open source', 'predict clinical outcome', 'predictive modeling', 'predictive of treatment response', 'public health relevance', 'quantitative imaging', 'repository', 'response', 'specific biomarkers', 'statistics', 'success', 'survival prediction', 'tool', 'treatment response', 'tumor', 'vector', 'web based interface']",NCI,STANFORD UNIVERSITY,U01,2017,487132,0.011378146160068691
"Software for OCT Analysis of Vascular Stents Software for OCT Analysis of Vascular Stents PI: Ronny Shalev, PhD, Dyad Medical Summary Dyad Medical, Inc. will create intravascular OCT (IVOCT) software for clinical, live time determination of stent apposition (OCTivat-live, the live time OCT image visualization and analysis tool) and for offline analysis of stent implantation (OCTivat-stent). Every year, 100s of thousands of patients in the US are treated with intra- vascular stents creating an opportunity for both solutions. Although advancements such as drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent design parameters include drug, material (bioresorbable vs metal), polymer composition, coatings to stimulate cell coverage, etc. To opti- mize designs, sensitive, in vivo assessments are needed for preclinical and clinical evaluations. Intravascular OCT (IVOCT) is the lone imaging modality with the resolution and contrast to meet this challenge. The Core Lab at CWRU is the premiere site in the world for manual analysis of IVOCT image data. A cardiologist analyst takes 6-16 hrs to analyze manually a single stent, and despite training and quality assurance measures, inter- analyst variability can limit the power to determine changes between stent designs. Building upon work at CWRU, we will develop advanced, highly automated software to greatly speed analysis, improve reproducibil- ity, increase accuracy, and harmonize analysis. Software will reduce costs by decreasing manual labor, and with improved reproducibility, possibly enable the use of historical data, eliminating cost of a control arm. Re- garding live time analysis, rather than manually reviewing >500 images in a pullback, with fast software, it will be possible to present the number and location of malapposed struts in 3D, providing instant feedback to phy- sicians on the need for additional dilatation with a larger balloon or higher pressure. In addition, we will auto- matically determine stent and vessel area along the length of the pullback, allowing us to compute stent ex- pansion and eccentricity, quantitative measures related to successful stent deployment, the most important de- terminant of outcome. IVOCT could also play a role at patient follow up. If a stent is well covered, then long- term anti-platelet therapy might be unnecessary, minimizing bleeding risk. If a stent has many uncovered struts, a therapeutic might prevent stent thrombosis or stimulate healing. Project Narrative: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies and improved deployment for improved treatment of vascular dis- ease.",Software for OCT Analysis of Vascular Stents,9407267,R43HL137500,"['Agreement', 'Algorithms', 'Area', 'Blinded', 'Blood Vessels', 'Cells', 'Classification', 'Clinical', 'Clinical Trials', 'Code', 'Computer software', 'Data', 'Detection', 'Devices', 'Dilatation - action', 'Doctor of Philosophy', 'Feedback', 'Follow-Up Studies', 'Heart', 'Hemorrhage', 'Hour', 'Image', 'Image Analysis', 'Implant', 'Institutes', 'International', 'Ions', 'Laboratories', 'Length', 'Location', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Metals', 'Methods', 'Myocardial Ischemia', 'Needs Assessment', 'Outcome', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Physicians', 'Play', 'Polymers', 'Process', 'Reproducibility', 'Research Personnel', 'Resolution', 'Risk', 'Role', 'Services', 'Site', 'Speed', 'Stents', 'Surrogate Markers', 'Technology', 'Testing', 'Therapeutic', 'Time', 'Tissues', 'Training', 'Variant', 'Vascular Diseases', 'Work', 'arm', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'image visualization', 'imaging modality', 'implantation', 'improved', 'in vivo', 'personalized diagnostics', 'preclinical evaluation', 'pressure', 'prevent', 'prototype', 'quality assurance', 'research clinical testing', 'restenosis', 'statistics', 'stent thrombosis', 'tool', 'treatment choice']",NHLBI,"DYAD MEDICAL, INC.",R43,2017,224744,0.023534180016302815
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9316507,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Exhibits', 'Fascicle', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Muscle', 'Muscle Fibers', 'Muscle function', 'Myopathy', 'Pathologic', 'Phase', 'Procedures', 'Process', 'Reproducibility', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'parallel computer', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'public health relevance', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2017,379732,0.06377465574925842
"Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II ﻿    DESCRIPTION (provided by applicant): An online community called EyeWire proved that volunteers can be motivated to reconstruct neural circuits through an activity resembling a 3D coloring book. EyeWire helped discover space-time speciﬁcity of the wiring from bipolar cells to starburst amacrine cells, which suggested a surprising new model for direction selectivity in the retina. Motivated by this success, we are preparing to launch EyeWire II, which aims to map the entire retinal connectome, yielding the ﬁrst complete wiring diagram for any region of the mammalian CNS. This ambitious goal will require innovative advances in virtually every component of EyeWire. The underlying electron microscopic image of the retina will be replaced by a new image with increased size and quality. A new artiﬁcial intelligence (AI) will be trained using a new software package for 3D deep learning. While the improved AI is expected to reduce the amount of human effort required to reconstruct a neuron, the number of neurons targeted for reconstruction will also increase dramatically. Overall, the absolute amount of human effort required will increase rather than decrease. Therefore it is critical to improve EyeWire's crowdsourcing to (1) mobilize more human effort and (2) to use human effort more efﬁciently. This project aims to radically improve both aspects, thereby making the retinal connectome achievable by EyeWire II. In Aim 1, we will create a compelling mobile game with the target of engaging 10x more people than the existing EyeWire community. In Aim 2, we will develop and deploy new crowdsourcing algorithms that extract wisdom from the crowd by weighted voting and optimally assign players to tasks. The Aims will be achieved through collaboration between three organizations. Wired Differently, Inc. (WD) is a new Boston-based nonproﬁt organization dedicated to ""citizen neuroscience"" that was recently spun out of MIT. WD currently operates EyeWire in collaboration with the Princeton Neuroscience Institute. The Entertainment Technology Center (ETC) at Carnegie Mellon University will offer a project-based class to its master's students to design and prototype new ideas for the mobile game. Both Aims will produce code and algorithms that will be made publicly available, and could have broad impact on citizen science. As the ﬁrst crowdsourcing of 3D image analysis, the code produced by Aim 1 could be useful for the many other kinds of 3D images found in biomedical research. The crowdsourcing algorithms of Aim 2 are potentially useful for any citizen science project facing the challenge of obtaining accurate and reliable results from a heterogeneous group of volunteers. PUBLIC HEALTH RELEVANCE: EyeWire II will increase public understanding of the structure of the nervous system. The retinal connectome could aid those attempting to develop blindness therapies based on regenerating cells and their wiring. It could also aid the development of retinal prosthetics that directly stimulate ganglion cells and computationally emulate the bypassed micro circuitry. 1",Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II,9330810,UH2CA203710,"['Algorithms', 'Artificial Intelligence', 'Attention', 'BRAIN initiative', 'Behavior', 'Biomedical Research', 'Blindness', 'Books', 'Boston', 'Breathing', 'Bypass', 'Caenorhabditis elegans', 'Cells', 'Cellular Phone', 'Classification', 'Code', 'Collaborations', 'Communities', 'Computer software', 'Country', 'Crowding', 'Data', 'Development', 'Electrons', 'Event', 'Goals', 'Human', 'Image', 'Image Analysis', 'Institutes', 'Learning', 'Love', 'Maps', 'Modeling', 'Natural regeneration', 'Nature', 'Nervous system structure', 'Neurons', 'Neurosciences', 'New York', 'Nonprofit Organizations', 'Organism', 'Performance', 'Play', 'Production', 'Publishing', 'Retina', 'Retinal', 'Scheme', 'Science', 'Sensory', 'Social Interaction', 'Source', 'Specificity', 'Statistical Models', 'Students', 'Technology', 'Territoriality', 'Three-Dimensional Image', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Volunteer Group', 'Voting', 'Weight', 'Work', 'base', 'citizen science', 'connectome', 'crowdsourcing', 'design', 'fine art', 'ganglion cell', 'improved', 'innovation', 'microscopic imaging', 'neural circuit', 'online community', 'pleasure', 'programs', 'prototype', 'public health relevance', 'reconstruction', 'retinal prosthesis', 'simulation', 'starburst amacrine cell', 'success', 'university student', 'virtual', 'visual neuroscience', 'volunteer']",NCI,PRINCETON UNIVERSITY,UH2,2017,320900,-0.004631666484115162
"CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development DESCRIPTION (provided by applicant): Background: Dendritic arbor shape and functional properties emerge from the interaction of many complex developmental processes. It is now accepted that multiple local-level interactions of cytoskeleton elements direct the growth and development of the dendrite arbor. However, the specific mechanisms that control developmental acquisition of final functional dendritic properties are largely unknown. Addressing this fundamental question requires novel data driven systems-biology tools to study developmental and biophysical mechanisms in the same neuronal model. A tightly-knit collaboration between molecular genetics, quantitative morphometry, and mathematical simulation can for the first time enable large-scale studies capable of achieving holistic understanding of the mechanisms underlying emergent features of the arbor. Project Goals: The main neuroscientific goal of this project is to understand how multiple local interactions of cytoskeleton components during differentiation define mature dendritic arbor shape and its functional integrative properties, using Drosophila sensory neurons as a model. The technological goal of this project is to develop a novel investigative approach that integrates and extends previously separate approaches from developmental biology & genetics, in vivo confocal imaging & electrophysiology, computer vision, and neuroanatomical modeling. Specific Aims: We propose 3 tightly integrated specific aims. Aim 1: use genetic manipulations and electrophysiological recordings to model the role of cytoskeletal organization and dynamics as a fundamental determinant of emergent dendrite arbor shape and function. Aim 2: Implement advanced 4D multi-parameter imaging protocols and automated algorithms to reconstruct the arbor, and quantify spatial and temporal associations among multiple sub-cellular components. Aim 3: using automated reconstructions & measurements from aim 2, statistically characterize the structural and cytoskeletal features of dendrite arbors, and stochastically simulate the growth and electrotonic properties of anatomically realistic virtual neuronal analogues. The data from aim 3 will feed back novel hypotheses to be tested by a subsequent repetition of the (aim 1 - aim 2 - aim 3) cycle. Approach: We will focus on a single model system - Drosophila dendritic arborization (da) sensory neurons. More specifically, we will investigate class I and class IV da neuron arborization based upon their radically distinct dendritic morphologies (simple vs. complex) and underlying cytoskeletal organizations. We will make fusion constructs of cytoskeleton components with spectrally distinct fluorescent proteins. These will be used in transgenic Drosophila in order to quantitatively measure the distribution of F-actin, microtubules, and microtubule polarity within the dendrite arbor throughout its development in vivo using confocal multi-fluor imaging. The resulting images will be processed by automated quantitative computer vision algorithms that will accurately extract the topology of the dendritic arbor, and it changes over time. We will use the resulting maps in neuroanatomical stochastic simulations to establish the links between the emergent morphometrics of the dendrite and specific cytoskeleton features at various developmental stages. Intellectual Merit: From a neurogenetics perspective, this project will pioneer the use of cytoskeletal features as putative fundamental determinants in statistical neuroanatomical models. These determinants will be linked to morphological determinants. From a computational perspective, this project will advance the state of the art in automated algorithms for delineating neuroanatomy (and its morphological dynamics) by deploying core technologies for large-scale multi-parameter studies, and result in an effective interfacing of automated reconstruction and simulation technologies. With this innovation, model predictions can be tested by molecular biological techniques, and findings of statistical models can be used to inform molecular models of dendrite arbor development. Educational Impact: This project will result in a cross-disciplinary training of post-doctoral fellows, graduate students, undergraduate students and high school interns. It will result in practical insight on ways to conduct cutting-edge systems-level scientific research overcoming disciplinary boundaries and using best-available collaborative tools. The trainees from this program will be uniquely positioned to develop the broader field of imaging-driven integrative systems neurobiology. It will expose minority and K-12 students to a new world of trans-disciplinary research that is indicative of the future. Broader Impacts: The combined body of molecular, imaging, and computational tools and datasets from this research will be disseminated widely, and made available to a broad class of investigators for adoption in the study of other major neuroscience problems. This project will serve as a new model for computationally enabled neuroscience research that achieves a long-desired synergy between the wet lab and computation. n/a",CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development,9310382,R01NS086082,"['Address', 'Adoption', 'Affect', 'Afferent Neurons', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Back', 'Biological', 'Biological Models', 'Biophysical Process', 'Characteristics', 'Coal', 'Collaborations', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Crystallization', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Data Set', 'Dendrites', 'Development', 'Developmental Biology', 'Developmental Process', 'Discipline', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Elements', 'F-Actin', 'Future', 'Genetic', 'Genetic Structures', 'Goals', 'Growth', 'Growth and Development function', 'Image', 'Imaging Device', 'Internships', 'Investigation', 'K-12 student', 'Knowledge', 'Link', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Microtubules', 'Minority', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Models', 'Morphology', 'Mosaicism', 'Nervous system structure', 'Neurites', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Series', 'Shapes', 'Signal Transduction', 'Statistical Data Interpretation', 'Statistical Models', 'Structure', 'Synapses', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Transgenic Organisms', 'Trees', 'analog', 'base', 'computerized tools', 'data sharing', 'developmental genetics', 'developmental neurobiology', 'digital', 'experimental study', 'feeding', 'fluorescence imaging', 'genetic manipulation', 'graduate student', 'high school', 'in vivo', 'innovation', 'insight', 'molecular imaging', 'molecular modeling', 'morphometry', 'neurogenetics', 'neuroinformatics', 'next generation', 'novel', 'open source', 'post-doctoral training', 'programs', 'reconstruction', 'relating to nervous system', 'role model', 'simulation', 'spatiotemporal', 'synergism', 'tool', 'undergraduate student', 'virtual']",NINDS,GEORGIA STATE UNIVERSITY,R01,2017,323033,-0.003216859685262052
"Statistical methods for large and complex databases of ultra-high-dimensional DESCRIPTION: Medical imaging is a cornerstone of basic science and clinical practice. To discover new mechanisms and markers of disease and their crucial implications for clinical practice, large multi-center imaging studies are acquiring terabytes of complex multi-modality imaging data cross-sectionally and longitudinally over decades. The statistical analysis of data from such studies is challenging due to the complex structure of the imaging data acquired and the ultra-high dimensionality. Furthermore, the heterogeneity of anatomy, pathology, and imaging protocols causes instability and failure of many current state-of-the-art image analysis methods. This grant proposes statistical frameworks for studying populations through biomedical imaging, scalable and robust methods for the identification and accurate quantification of pathology, and analytic tools for the cross-sectional and longitudinal examination of etiology and disease progression. These techniques will be applied to address key goals of the motivating large and multi- center studies of multiple sclerosis and Alzheimer's disease conducted at Johns Hopkins Hospital, the National Institute of Neurological Disorders and Stroke, and across the globe. The project will create methods for uncovering and quantifying brain lesion pathology, incidence, and trajectory. Methods developed under this grant will be targeted towards these neuroimaging goals, but will form the basis for statistical image analysis methods applicable broadly in the biomedical sciences. PUBLIC HEALTH RELEVANCE: This project involves the development of statistical frameworks and methods for the analysis of complex ultra-high-dimensional biomedical imaging. Methods developed are applied to study the clinical management and etiology of multiple sclerosis and Alzheimer's disease longitudinally and cross-sectionally.",Statistical methods for large and complex databases of ultra-high-dimensional,9320865,R01NS085211,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Applications Grants', 'Area', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Brain', 'Brain Pathology', 'Brain imaging', 'Clinical Management', 'Complex', 'Computer software', 'Computing Methodologies', 'Contrast Media', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease Marker', 'Disease Progression', 'Etiology', 'Failure', 'Goals', 'Grant', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Incidence', 'Journals', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Multicenter Studies', 'Multimodal Imaging', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Pathology', 'Positioning Attribute', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Site', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Visualization software', 'analytical tool', 'base', 'bioimaging', 'clinical practice', 'contrast enhanced', 'data visualization', 'design', 'high dimensionality', 'imaging Segmentation', 'imaging modality', 'imaging study', 'member', 'neuroimaging', 'next generation', 'open source', 'public health relevance', 'skills', 'spatiotemporal', 'study population', 'terabyte', 'white matter']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2017,347156,0.02416990271319141
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,9350173,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Anatomy', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Intervention', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multimodal Imaging', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathologic', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'cardiovascular visualization', 'clinical application', 'clinical imaging', 'clinical phenotype', 'clinical practice', 'cloud based', 'cluster computing', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'multi-atlas segmentation', 'multidisciplinary', 'new technology', 'novel', 'open source', 'outreach', 'public health relevance', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2017,597688,0.05150572568071851
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9341177,U24CA199374,"['Address', 'Adoption', 'Advanced Development', 'Algorithmic Analysis', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Felis catus', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Standardization', 'Stream', 'Training', 'Training and Education', 'Validation', 'analytical tool', 'annotation  system', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'radiological imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2017,579791,0.027591184462099932
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,9021663,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Health', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'exercise program', 'faculty research', 'graduate student', 'lecturer', 'lectures', 'personalized approach', 'programs', 'quantitative imaging', 'student training', 'teaching assistant', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2016,59383,0.004646304225760531
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9111923,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,539886,0.07340805712992504
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,9324484,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'microscopic imaging', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2016,175692,0.07340805712992504
"Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals ﻿    DESCRIPTION (provided by applicant): Microscope techniques to image inside brain tissue are generally limited by poor depth penetration. Micro-endoscopy, wherein a probe is physically inserted into the tissue, can overcome this limitation in depth penetration, but at the expense of invasiveness and tissue damage due to the size of the probe. Our goal here is to palliate these problems by developing an ultra-miniature microendoscope probe based on a single, lensless optical fiber.  The direct transmission of an image through an optical ﬁber is diﬃcult because spatial information becomes scrambled upon propagation. We have recently demonstrated an image transmission strategy where spatial information is ﬁrst converted to spectral information. Our strategy is based on a principle of spread-spectrum encoding, borrowed from wireless communications, wherein object pixels are converted into distinct spectral codes that span the full bandwidth of the object spectrum. Image recovery is performed by numerical inversion of the detected spectrum at the ﬁber output. We have provided a simple demonstration of spread-spectrum encoding using macroscopic Fabry-Perot etalons. Our technique enables the 2D imaging of luminous (i.e. fluorescent or bioluminescent) objects with high throughput independent of pixel number. Moreover, it is insensitive to ﬁber bending, contains no moving parts, and opens the attractive possibility of extreme miniaturization down to the size of a single optical fiber.  Our goal here is to develop, characterize, and establish the versatility of a new class of ultra-miniature fiber probes that can provide functional 2D brain imaging at arbitrary depths and with minimal tissue damage. Our strategy will involve probe development, machine-learning algorithm development, and the actual demonstration of microendoscopic imaging in freely moving behaving animals. PUBLIC HEALTH RELEVANCE: We have recently demonstrated a strategy to image through a single, lensless optical fiber. We propose to develop this into an ultraminiaturized microendoscope for functional brain imaging with minimal surgical damage in freely moving behaving animals.",Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals,9137657,R21EY026310,"['Address', 'Algorithms', 'Animals', 'Behavioral', 'Brain imaging', 'Caliber', 'Calibration', 'Code', 'Collaborations', 'Communication', 'Data', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Endoscopes', 'Endoscopy', 'Fiber', 'Geometry', 'Goals', 'Health', 'Image', 'Imaging Device', 'Label', 'Lasers', 'Learning', 'Lighting', 'Machine Learning', 'Microscope', 'Miniaturization', 'Motion', 'Mus', 'Operative Surgical Procedures', 'Optics', 'Output', 'Penetration', 'Recovery', 'Resolution', 'Side', 'Societies', 'Structure', 'System', 'Techniques', 'Tissues', 'Wireless Technology', 'base', 'brain tissue', 'high risk', 'image reconstruction', 'imprint', 'improved', 'in vivo', 'indexing', 'interest', 'lens', 'microscopic imaging', 'miniaturize', 'minimally invasive', 'optical fiber', 'optical imaging', 'photonics', 'portability', 'reconstruction', 'relating to nervous system', 'targeted imaging', 'transmission process', 'trend']",NEI,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2016,246750,0.0028259102565576536
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,9110984,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Health', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Pulmonary Emphysema', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'quantitative imaging', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2016,412881,0.03874656675671057
"Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular DESCRIPTION (provided by applicant): A career development plan is proposed for Dr. David Mayerich, a computer scientist who is committed to developing an interdisciplinary career in biomedical engineering, with a focus on the collection and analysis of large-scale data sets at sub-micrometer resolution. His graduate research was in the areas of computer visualization and optical imaging, where his work lead to the development of the prototype Knife-Edge Scanning Microscope (KESM). This is the first instrument capable of imaging three-dimensional macro-scale tissue volumes at sub-micrometer resolution while providing a data rate approaching the transfer speed of most modern computer systems.         Since receiving his Ph.D., Dr. Mayerich worked as a postdoctoral fellow at the Beckman Institute for Advanced Science and Technology at the University of Illinois at Urbana-Champaign, where he has worked with biologists and biomedical engineers to develop tools for the segmentation and classification of large data sets. This provided experience in addressing the needs and limitations of the computational tools available to the interdisciplinary community.        The goal of the mentored phase of this proposal is to provide Dr. Mayerich with the opportunity to work as a developer for the FARSIGHT Toolkit. The FARSIGHT Toolkit is an open-source segmentation toolkit that focuses on developing computer vision algorithms specifically tailored to deal with the unique structures found in microscopy data sets. This project is directed by Prof. Badrinath Roysam at the University of Houston, and was awarded first-place in the NIH-sponsored DIADEM Challenge in neuron segmentation. Dr. Mayerich will use his previous experience in biomedical segmentation, GPU-based computing, and efficient data structures to help make the FARSIGHT Toolkit scalable to the terabyte-scale data sets produced using next-generation high-throughput imaging techniques. Dr. Mayerich will receive mentoring in the algorithms and techniques used in the FARSIGHT Toolkit, as well as valuable experience working on a collaborative software development project.         The goal of the independent phase is to use recently developed imaging techniques, along with scalable segmentation algorithms, to construct complete microvascular models of mouse organs. Recent advances in KESM demonstrate that sub-micrometer images of 1cm3 tissue samples can be collected in less than 50 hours. These images have the resolution and quality necessary for (a) complete reconstruction of microvascular networks in whole organs, and (b) the geometric distribution of cell soma in relation to this network. Models describing cellular and microvascular relationships have implications in several diseases, including neurodegenerative disease and tumor growth, as well as clinical applications in tissue engineering and the quantitative analysis of angiogenic drugs and therapies. PROJECT NARRATIVE The goal of this work is to produce high-resolution microvascular models from mouse brain tissue, as well as create algorithms for querying, distributing, and building models from next-generation high-throughput microscopy data sets. These techniques will allow researchers to create large-scale blood flow simulations, simulate the extent of tissue damage due to stroke or aneurism, and explore the relationships between cells and microvessels on a tissue-wide scale. Clinical applications include the quantification of angiogenesis in tumors and tissue implants, and the quantification of neurovascular effects in neurodegenerative disease models.",Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular,9117645,R00LM011390,"['Active Learning', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Atlases', 'Award', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood Vessels', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Computer Systems', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Disease model', 'Doctor of Philosophy', 'Funding', 'Future', 'Goals', 'Hour', 'Illinois', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Institutes', 'Lead', 'Learning', 'Machine Learning', 'Memory', 'Mentors', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Mus', 'Neurodegenerative Disorders', 'Neurons', 'Online Systems', 'Organ', 'Pharmacotherapy', 'Phase', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Speed', 'Stroke', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Engineering', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'Transgenic Organisms', 'Tumor Angiogenesis', 'Tumor Tissue', 'United States National Institutes of Health', 'Universities', 'Work', 'analytical method', 'angiogenesis', 'base', 'brain tissue', 'career', 'career development', 'clinical application', 'computerized tools', 'design', 'experience', 'imaging Segmentation', 'improved', 'instrument', 'learning strategy', 'memory process', 'model building', 'mouse model', 'neuronal cell body', 'neurovascular', 'next generation', 'open source', 'optical imaging', 'programs', 'prototype', 'reconstruction', 'research study', 'simulation', 'software development', 'success', 'terabyte', 'tool', 'tumor growth']",NLM,UNIVERSITY OF HOUSTON,R00,2016,244245,0.012418241986791145
"Interpreting limits to nanoparticle delivery in high-stroma low-perfusion tumors 4.4.7 Project Summary/Abstract  The central theme in this work is that critical spatial patterns exist in highly resistant cancer stroma and vascular density that inherently inhibit larger nanoparticle penetration into cancer, and that these phenotypes can be imaged in vivo. We will use in vivo diagnostic imaging, combined with ex vivo analysis to test this in pancreatic cancer, which has as well known drug penetration limitation. Specifically, we will quantify nanoparticle penetration in pancreas cancer, which has high stroma content and low vascular density. The analysis and prediction of efficacy will be quantitatively developed by methodological correlation of in-vivo and ex vivo images using Fourier spatial frequency analysis.  We will determine the characteristic spatial patterns of these tumor microstructures that present as barriers to nanoparticle transport, as assayed through in vivo/ex vivo studies. We have seen that these characteristic spectral features appear in high-field magnetic resonance imaging (HF-MRI) scans and micro-Computed Tomography (uCT) scans of tumors imaged within the ongoing nanoparticle project at DHMC. The scope of this project is to conduct a secondary analysis on the images that are being produced within these projects, with two specific aims. 1) We will directly correlate nanoparticle penetration and distribution to the Fourier spatial frequencies found in in vivo images by Fourier spatial frequency analysis in which we have demonstrated expertise. The in vivo images will be analyzed by correlating them with histological sections of nanoparticle distribution post-treatment. Tumors will be classified on two levels as either a high or low permeability to a specific nanoparticle formulation (to quantify the amount of agent delivered), and as having high or low isotropy (to quantify the dispersion of the agent). 2) We will then apply this characteristic morphology analysis to pre-treatment, pre-operative HF-MRI, uCT images, and analyze their value as a potential diagnostic classifier. We will use a Support Vector Machine Analysis to predict the permeability and isotropy of unknown tumors, and validate our results against experimental outcomes. An iterative strategy will optimize the predictive power of the method, and be used to distinguish between characteristic spectra that are good and bad classifiers.  The research will be produced using the unique software systems that we have designed during preliminary studies, and will be deployed on an analysis platform that can be integrated with the hospital- based DICOM and virtual pathology environment to allow clinical investigators to plan adjuvant therapies to promote nanoparticle efficacy. Several hundred high-quality scans are now available for analysis, which will be processed and reported on within the first year of funding. By year two, the established system is projected to be able to analyze images within a few minutes post-scan. These analysis methods will give us the key background needed to advance our fundamental understanding of nanoparticle in-vivo delivery, and test ways to interrupt transport barriers in interventional future work. 4.4.8 Project Narrative The PI will apply a novel image analysis method to identify spatial patterns in images taken from in vivo experiments that indicate the presence of physical barriers to nanoparticle and liposomal transport in solid cancer tumor. Successful completion of this proposal will result in methods to predict the permeability of tumors to nanoparticle and large-molecule adjuvant therapies during the planning stage.",Interpreting limits to nanoparticle delivery in high-stroma low-perfusion tumors,9172223,R03CA208510,"['Adjuvant Therapy', 'Aftercare', 'Antineoplastic Agents', 'Area', 'Behavior', 'Biological', 'Biological Assay', 'Blood Vessels', 'Cancer Center', 'Characteristics', 'Clinical Investigator', 'Clinical Trials', 'Coupled', 'Deposition', 'Diagnostic', 'Diagnostic Imaging', 'Environment', 'Extracellular Matrix', 'Formulation', 'Frequencies', 'Funding', 'Future', 'Goals', 'Histology', 'Hospitals', 'Image', 'Image Analysis', 'Immune', 'Intercellular Fluid', 'Interruption', 'Intervention', 'Isotropy', 'Lead', 'Liposomes', 'MRI Scans', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of pancreas', 'Maps', 'Mediating', 'Methods', 'Morphology', 'Nanotechnology', 'Outcome', 'Pathology', 'Pattern', 'Penetration', 'Perfusion', 'Permeability', 'Pharmaceutical Preparations', 'Phenotype', 'Process', 'Reporting', 'Research', 'Resistance', 'Sampling', 'Scanning', 'Solid', 'Spectrum Analysis', 'Staging', 'System', 'Testing', 'Therapeutic', 'Vascular Permeabilities', 'Work', 'X-Ray Computed Tomography', 'abstracting', 'base', 'cancer imaging', 'cancer therapy', 'density', 'design', 'fluid flow', 'histological image', 'improved', 'in vivo', 'in vivo imaging', 'nanoparticle', 'neovasculature', 'novel', 'oncology', 'prevent', 'research study', 'software systems', 'therapy resistant', 'treatment response', 'tumor', 'virtual']",NCI,DARTMOUTH COLLEGE,R03,2016,81000,-0.03444704909291926
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages. PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,9099858,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Heating', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Statistical Data Interpretation', 'Stereocilium', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'base', 'computer code', 'cryogenics', 'density', 'design', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'microscopic imaging', 'new technology', 'next generation', 'programs', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2016,306754,-0.014812131046919749
"Slicer+PLUS: Collaborative, open-source software for ultrasound analysis Abstract The target users of the proposed Slicer+PLUS framework are researchers and developers who are focusing on low-cost point-of-care ultrasound (POCUS) applications. POCUS applications are characterized by utilizing low-cost, portable U/S systems; in the hands of novice operators; with novel data acquisition, signal processing, and machine learning methods; with imprecise trackers; and in highly unconstrained point-of-care environments, e.g.: at the scene of accidents for patient triage, in the offices of general practitioners for scoliosis detection and monitoring, in patients' homes for an aging population, as well as throughout hospitals. In these contexts, many are considering POCUS devices to be the stethoscopes of the future.  The foundation of Slicer+PLUS is the integration and extension of 3D Slicer, PLUS, and MUSiiC. We are the developers of these libraries. We, and the users of our libraries, are proposing Slicer+PLUS so that the Slicer, PLUS, and MUSiiC communities can come together and cohesively address the important challenges and opportunities posed by POCUS applications. Over 30 letters of support are included with this application.  3D Slicer is a world-class, freely available open-source platform for medical image segmentation, registration, and visualization. PLUS is a world-class, open-source library for communicating with ultrasound machines and trackers (for following objects in 3D using magnetic, optical, and other technologies). MUSiiC is a (previously closed source) library that focuses on advanced ultrasound acquisition and analysis methods, such as ultrasound reconstruction pipelines, elastography, and photoacoustic imaging. Together, these toolkits have averaged over 5,100 downloads per month for the past year.  A central tenant of our work is that POCUS applications should not be viewed as simply involving the use of inexpensive, portable U/S systems; POCUS must be viewed as a new modality for it to attain its full potential. POCUS must involve innovative, automated data analysis methods and workflows that can guide a user to properly place and manipulate an ultrasound probe and interpret the returned ultrasound data. In particular, the output of those workflows and analyses should be quantitative measures, not b-mode images, since the expertise to interpret such images will not be readily available at points-of-care. To that end, the proposed work goes well beyond simple integration of Slicer, PLUS, and MUSiiC. Multiple innovations are proposed such as Ultrasound Spectroscopy for tissue labeling, Dynamic Textures for anatomic localization of ultrasound probes, and self-tracking ultrasound probes.  To assess our progress towards our goals, our team includes our target users: researchers, medical device manufacturers, and clinical innovators dedicated to low-cost POCUS applications. They will be validating our efforts by integrating them into their research and translational POCUS product development projects. Project Narrative  Low-cost ultrasound probes have the potential to become the stethoscopes of the future and revolutionize in-field and in-hospital patient care. Our goal is to integrate, enhance, and disseminate three cutting edge ultrasound acquisition, analysis, and display toolkits to create a new framework called Slicer+PLUS that will serve as a catalyst for research and product development into low-cost point-of-care ultrasound applications. In particular, our framework will include and facilitate innovative methods for guiding a novice user in ultrasound probe placement and for automatically interpreting ultrasound data to provide a diagnosis, without the user having to interpret a traditional B-mode ultrasound image at any point in the process. The Slicer+PLUS framework will be validated using tasks associated with (a) emergency service personnel performing Focused Assessment with Sonography for Trauma (FAST) exams at the scene of an accident to detect or rule-out intra-abdominal bleeding; (b) the clinical monitoring of scoliosis progression in children in general practitioners' offices; and (c) the translation of research into regulatory-approved products based on Slicer+PLUS.","Slicer+PLUS: Collaborative, open-source software for ultrasound analysis",9176982,R01EB021396,"['Abdomen', 'Accidents', 'Address', 'Algorithms', 'Anatomy', 'Blood', 'Child', 'Classification', 'Clinical', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Documentation', 'Emergency medical service', 'Environment', 'Foundations', 'Frequencies', 'Future', 'General Practitioners', 'Goals', 'Hemorrhage', 'Home environment', 'Hospitals', 'Human Resources', 'Image', 'Imagery', 'Intra-abdominal', 'Label', 'Letters', 'Libraries', 'Life', 'Machine Learning', 'Magnetism', 'Manufacturer Name', 'Measures', 'Medical Device', 'Medical Imaging', 'Methods', 'Modality', 'Monitor', 'Optics', 'Output', 'Patient Triage', 'Patients', 'Process', 'Protocols documentation', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Shapes', 'Slice', 'Source', 'Spectrum Analysis', 'Stethoscopes', 'System', 'Technology', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'Tissues', 'Translational Research', 'Translations', 'Trauma', 'Ultrasonography', 'United States National Institutes of Health', 'Vertebral column', 'Work', 'abstracting', 'aging population', 'base', 'catalyst', 'cost', 'data acquisition', 'elastography', 'emergency service responder', 'hospital patient care', 'image guided therapy', 'imaging Segmentation', 'innovation', 'innovative technologies', 'learning strategy', 'novel', 'open source', 'photoacoustic imaging', 'point of care', 'product development', 'reconstruction', 'research and development', 'scoliosis', 'signal processing', 'software development', 'transmission process']",NIBIB,"KITWARE, INC.",R01,2016,677628,0.022728794852476614
"Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle ﻿    DESCRIPTION (provided by applicant):  There is growing awareness that weakness of muscle is a significant biomedical health issue associated with many different chronic diseases and aging. There are a variety of different diseases that affect muscle, including muscular dystrophy, fibromyalgia, cerebral palsy, amyotrophic lateral sclerosis, and myasthenia gravis, each of which carries its own unique set of symptoms, accompanied by a myriad of genetic and molecular abnormalities. There is agreement within the basic research and clinical communities that important morphological characteristics of muscle fibers, such as fiber cross sectional area, fiber type, the number and position of myonuclei, cellular infiltration, and fibrosis are among many critical factors that determine the health and functionality of the muscle. Until now, the imaging equipment available is relatively low throughput and the quantification is still largely based on manual or, at best, semi-automatic methods that require extensive human intervention. In Phase I, CytoInformatics LLC has developed a software called CytoQuant, which can accurately perform automatic segmentation and provide accurate boundaries of each muscle fiber for a cropped image patch. The goal of CytoInformatics LLC in Phase II is to 1) deliver the first version of the CytoQuant software to the market, 2) develop the second version of CytoQuant by continuously improving its performance, especially in handling large scale, whole slide images, and also 3) develop an integrated multiplexing imaging hardware and analysis software framework as a seamless solution for high throughput, automated image analysis of muscle specimens. After careful investigation in Phase I (please refer to the details in business plan), we conclude that this integrated software/hardware platform with cutting-edge technologies in advanced imaging, large scale machine learning, and big data is commercially attractive to the entire muscle community including research institutes, hospitals, and pharmaceutical and athletic companies, demonstrated by strong enthusiasm among end users and many supporting letters. The specific aims are: 1) Deliver the first version of CytoQuant developed in Phase I to the market, continue to develop the second version of CytoQuant, which will focus on improving the robustness and speed in handling whole slide images; 2) Develop an integrated platform that provides unified imaging hardware and image analysis software to handle whole slide images labeled with multiple bio-relevant markers. This unified whole-slide based software and hardware solution will deliver an efficient and specialized imaging platform that seamlessly integrates with a high throughput, multi-marker, and automatic image analysis software specifically designed for muscle.           PUBLIC HEALTH RELEVANCE:  In Phase II, CytoInformatics is proposing a unified whole-slide multispectral imaging (MSI) system that seamlessly integrates with a high throughput, accurate, and automated software to provide fast and efficient, multiplexed imaging and quantitative muscle image analysis simultaneously. This will be the first integrated hardware/software solution that is specifically designed for muscle.              ",Development of An Integrated High Throughput Imaging and Image Analysis Platform for Muscle,9047634,R42AG055375,"['Affect', 'Aging', 'Agreement', 'Amyotrophic Lateral Sclerosis', 'Area', 'Athletic', 'Awareness', 'Basic Science', 'Big Data', 'Biological Markers', 'Biology', 'Businesses', 'Cellular Infiltration', 'Cerebral Palsy', 'Characteristics', 'Chronic Disease', 'Clinical', 'Communities', 'Computer software', 'Development', 'Discipline', 'Disease', 'Doctor of Philosophy', 'Educational process of instructing', 'Eosine Yellowish', 'Equipment', 'Exhibits', 'Feedback', 'Fiber', 'Fibromyalgia', 'Fibrosis', 'Fluorescence', 'Future', 'Genetic', 'Goals', 'Health', 'Hematoxylin', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Immunofluorescence Immunologic', 'Immunohistochemistry', 'Institutes', 'Intervention', 'Investigation', 'Label', 'Laboratory Research', 'Learning', 'Learning Module', 'Letters', 'Machine Learning', 'Manuals', 'Marketing', 'Methods', 'Microscopy', 'Molecular Abnormality', 'Muscle', 'Muscle Fibers', 'Muscle Weakness', 'Muscular Dystrophies', 'Myasthenia Gravis', 'Noise', 'Performance', 'Pharmacologic Substance', 'Phase', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Qi', 'Recruitment Activity', 'Reporting', 'Research Institute', 'Research Personnel', 'Scanning', 'Signal Transduction', 'Slide', 'Software Design', 'Software Framework', 'Specimen', 'Speed', 'Staining method', 'Stains', 'Symptoms', 'Technology', 'Tissue Sample', 'Tissue imaging', 'Universities', 'Update', 'Variant', 'Yang', 'adaptive learning', 'base', 'bioimaging', 'commercialization', 'design', 'experience', 'gigabyte', 'graphical user interface', 'image processing', 'image visualization', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'imaging system', 'improved', 'interest', 'member', 'muscle form', 'novel', 'optical imaging', 'programs', 'public health relevance', 'quantitative imaging', 'success', 'technology development', 'user-friendly']",NIA,"CYTOINFORMATICS, LLC",R42,2016,609726,0.06945302897987218
"Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers ﻿    DESCRIPTION (provided by applicant): The Quantitative Imaging Network (QIN) is a consortium of centers developing quantitative image features, which are proving to be valuable biomarkers of the underlying cancer biology and that can be used for assessing response to treatment and predicting clinical outcome. It is now important to discover the best quantitative imaging features for detection of response to therapeutics, to identify subtypes of cancer, and to correlate with cancer genomics. However, progress is thwarted by the lack of shared software algorithms, architectures, and resources required to compute, compare, evaluate, and disseminate these quantitative imaging features within the QIN and the broader community. We propose to develop the Quantitative Imaging Feature Pipeline (QIFP), a cloud-based, open source platform that will give researchers free access to these capabilities and hasten the introduction of quantitative image biomarkers into single- and multi-center clinical trials. The QIFP will facilitate assessment of the incremental value of new vs. existing image feature sets. It will also allow researchers to add their own algorithms to compute novel quantitative image features in their own studies and to disseminate them to the greater research community. To accomplish this: (1) We will create an expandable library of quantitative imaging feature algorithms capable of comprehensive characterization of the imaging phenotype of cancer. It will support a broad set of imaging modalities and algorithms implemented in a variety of languages, including algorithms that provide volumetric and time-varying assessment of lesion size, shape, edge sharpness, and pixel statistics. (2) We will build a cloud-based software architecture for creating, executing, and comparing quantitative image feature-generating pipelines, including algorithms in the library and/or those supplied by QIN or other researchers as plug-ins. QIFP will also have (a) a machine learning engine that lets users specify a dependent variable (e.g., progression-free survival) that the quantitative image features can used to predict, and (b) an evaluation engine that compares the utility of particular features for predicting the dependent variable. (3) We will assess the QIFP in four ways: (a) by its ability to recapitulate the role of known biomarkers in a related clinical trial, (b) by comparing linear measurement, metabolic tumor burden and novel combinations of the features in our library for predicting one-year progression-free survival, (c) by merging imaging features with known host-, drug- and tumor-based follicular lymphoma biomarkers in order to develop the most robust and integrative predictive model for patient outcomes, and (d) by using the QIFP to combine and to evaluate image feature algorithms developed by another QIN team and our own NCI- funded team in the study of radiogenomics of non-small cell lung cancer. The QIFP will fill a substantial gap in the science currently being carried out in the QIN and in the community by providing the tools and infrastructure to assess the value of novel quantitative imaging features of cancer, and will thereby accelerate incorporating new imaging biomarkers into single and multi-center clinical trials and into oncology practice. PUBLIC HEALTH RELEVANCE: We propose to develop and evaluate a software platform that has major relevance for human health. Many investigators are pursuing image-based surrogates for response to therapy that could be used in clinical trials to predict their success/failure earlier and that are more accurate than existing surrogates. Our developments will facilitate sharing, assessing, and comparing combinations of image feature-generating software algorithms for predicting treatment response, survival, and tissue genomics, which will, in turn, greatly accelerate the development and acceptance of new and more relevant imaging surrogates for assessing cancer treatments.","Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers",9132190,U01CA187947,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Cancer Biology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Development', 'Eastern Cooperative Oncology Group', 'Evaluation', 'Failure', 'Follicular Lymphoma', 'Funding', 'Gene Expression', 'Generations', 'Genomics', 'Health', 'Human', 'Image', 'Investigation', 'Java', 'Language', 'Lesion', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Metabolic', 'Modality', 'Molecular', 'Multi-Institutional Clinical Trial', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patient-Focused Outcomes', 'Pharmaceutical Preparations', 'Phenotype', 'Plug-in', 'Positron-Emission Tomography', 'Progression-Free Survivals', 'Pythons', 'RNA Sequences', 'Radiogenomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Specific qualifier value', 'System', 'Therapeutic', 'Time', 'Tissue Survival', 'Tissues', 'Tumor Burden', 'base', 'cancer genomics', 'cancer imaging', 'cancer subtypes', 'cancer therapy', 'cloud based', 'disorder subtype', 'image archival system', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'novel', 'novel therapeutics', 'oncology', 'open source', 'predict clinical outcome', 'predictive modeling', 'quantitative imaging', 'repository', 'response', 'statistics', 'success', 'survival prediction', 'tool', 'treatment response', 'tumor', 'vector', 'web based interface']",NCI,STANFORD UNIVERSITY,U01,2016,626891,0.011378146160068691
"Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics System for Muscle,9282051,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'muscular system', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,58482,0.06359876528189884
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,9126405,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging biomarker', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'personalized diagnostics', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2016,316467,0.06377465574925842
"Objective decision support environment for clinical trials DESCRIPTION:  Brain tumors are the second- and fifth-most common cause of cancer death in males and females under 40, respectively. The 5-year relative survival rate is only 33%, even after decades of research into new treatments. Imaging based on ""virtual biopsy"" can provide information about the entire lesion in a minimally or non-invasive way. Prior work by our group has demonstrated that image processing methods applied to serial examinations together (as opposed to applying them to individual examinations) can make subtle changes in brain tumors more apparent, allowing earlier detection of progression. We see the union of virtual biopsy methods and change detection methods as an innovative and powerful combination that our team is uniquely qualified to develop and evaluate. In this application, we will implement several feature selection (FS) methods in a tool that is ""image friendly"". This tool will help select informative features from images; apply a wide range of existing ML algorithms to determine which features are important predictors of therapy response, and to evaluate the impact of a decision support application using these features and ML in a clinical trial. The final stage of th proposal will test the decision support tools in 3 clinical scenarios to see if they are able to significantly improve the decision making of clinicians in a clinical trial.  The long-term goal of this proposal is to develop virtual biopsy technology that will enhance the clinical decision making process by providing tools for investigation of image-based therapy response assessment tools, that may also have some ability to predict outcome. We hope to apply the technology to other organ systems and other imaging technologies. We anticipate this project will impact clinical trials by enabling investigation of alternative outcome measures that are objectively assessed using algorithm evaluation methods. Such a toolset should be useful to the entire cancer imaging community to help evaluate features in old and new imaging technologies that correlate with patient survival. As such, this is ideal for helping the Quantitative Imaging Network (QIN) achieve its goals. The selection of features that reflect response to therapy has long been the domain of the clinical radiologist. When imaging was relatively straightforward (e.g. a chest X-ray of lung cancer), a measurement or a visual assessment was a reasonable metric. Today, advanced imaging devices produce large amounts of data that reflect a range of properties. In this work, we build on previous work developing computer techniques for identifying and characterizing changes in brain tumors, using MRI. In this proposal, we will focus on building 1) a high quality database of brain cancer imaging, clinical data, ""-omic"" data, outcomes data; 2) a library of easily accessed tools for computing features that might be important predictors of tumor response; 3) a tool that will help objectively establish the feature() that are valuable through a variety of machine learning methods; and 4) use the above to create a decision support tool that will be used in 3 clinical trial situations.",Objective decision support environment for clinical trials,9143689,U01CA160045,"['Algorithms', 'Assessment tool', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Cancer Etiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collection', 'Communities', 'Computers', 'Data', 'Databases', 'Decision Making', 'Detection', 'Differentiation Therapy', 'Early Diagnosis', 'Environment', 'Evaluation', 'Female', 'Goals', 'Image', 'Imaging Device', 'Imaging technology', 'Individual', 'Investigation', 'Lesion', 'Libraries', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Outcome', 'Outcome Measure', 'Output', 'Pathologic', 'Patients', 'Primary Brain Neoplasms', 'Process', 'Property', 'Qualifying', 'Research', 'Staging', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Visual', 'Work', 'base', 'body system', 'cancer imaging', 'clinical decision-making', 'image processing', 'improved', 'innovation', 'interactive tool', 'learning strategy', 'male', 'predicting response', 'quantitative imaging', 'radiologist', 'response', 'support tools', 'tool', 'tumor', 'virtual biopsy']",NCI,MAYO CLINIC ROCHESTER,U01,2016,522865,-0.019446011741334587
"In vivo Characterization of Stents using Intravascular OCT Imaging DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel. PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,9097737,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Health', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shapes', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Surrogate Markers', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'preclinical trial', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'stent thrombosis', 'tool', 'treatment choice']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2016,447440,0.008922973206218869
"CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development DESCRIPTION (provided by applicant): Background: Dendritic arbor shape and functional properties emerge from the interaction of many complex developmental processes. It is now accepted that multiple local-level interactions of cytoskeleton elements direct the growth and development of the dendrite arbor. However, the specific mechanisms that control developmental acquisition of final functional dendritic properties are largely unknown. Addressing this fundamental question requires novel data driven systems-biology tools to study developmental and biophysical mechanisms in the same neuronal model. A tightly-knit collaboration between molecular genetics, quantitative morphometry, and mathematical simulation can for the first time enable large-scale studies capable of achieving holistic understanding of the mechanisms underlying emergent features of the arbor. Project Goals: The main neuroscientific goal of this project is to understand how multiple local interactions of cytoskeleton components during differentiation define mature dendritic arbor shape and its functional integrative properties, using Drosophila sensory neurons as a model. The technological goal of this project is to develop a novel investigative approach that integrates and extends previously separate approaches from developmental biology & genetics, in vivo confocal imaging & electrophysiology, computer vision, and neuroanatomical modeling. Specific Aims: We propose 3 tightly integrated specific aims. Aim 1: use genetic manipulations and electrophysiological recordings to model the role of cytoskeletal organization and dynamics as a fundamental determinant of emergent dendrite arbor shape and function. Aim 2: Implement advanced 4D multi-parameter imaging protocols and automated algorithms to reconstruct the arbor, and quantify spatial and temporal associations among multiple sub-cellular components. Aim 3: using automated reconstructions & measurements from aim 2, statistically characterize the structural and cytoskeletal features of dendrite arbors, and stochastically simulate the growth and electrotonic properties of anatomically realistic virtual neuronal analogues. The data from aim 3 will feed back novel hypotheses to be tested by a subsequent repetition of the (aim 1 - aim 2 - aim 3) cycle. Approach: We will focus on a single model system - Drosophila dendritic arborization (da) sensory neurons. More specifically, we will investigate class I and class IV da neuron arborization based upon their radically distinct dendritic morphologies (simple vs. complex) and underlying cytoskeletal organizations. We will make fusion constructs of cytoskeleton components with spectrally distinct fluorescent proteins. These will be used in transgenic Drosophila in order to quantitatively measure the distribution of F-actin, microtubules, and microtubule polarity within the dendrite arbor throughout its development in vivo using confocal multi-fluor imaging. The resulting images will be processed by automated quantitative computer vision algorithms that will accurately extract the topology of the dendritic arbor, and it changes over time. We will use the resulting maps in neuroanatomical stochastic simulations to establish the links between the emergent morphometrics of the dendrite and specific cytoskeleton features at various developmental stages. Intellectual Merit: From a neurogenetics perspective, this project will pioneer the use of cytoskeletal features as putative fundamental determinants in statistical neuroanatomical models. These determinants will be linked to morphological determinants. From a computational perspective, this project will advance the state of the art in automated algorithms for delineating neuroanatomy (and its morphological dynamics) by deploying core technologies for large-scale multi-parameter studies, and result in an effective interfacing of automated reconstruction and simulation technologies. With this innovation, model predictions can be tested by molecular biological techniques, and findings of statistical models can be used to inform molecular models of dendrite arbor development. Educational Impact: This project will result in a cross-disciplinary training of post-doctoral fellows, graduate students, undergraduate students and high school interns. It will result in practical insight on ways to conduct cutting-edge systems-level scientific research overcoming disciplinary boundaries and using best-available collaborative tools. The trainees from this program will be uniquely positioned to develop the broader field of imaging-driven integrative systems neurobiology. It will expose minority and K-12 students to a new world of trans-disciplinary research that is indicative of the future. Broader Impacts: The combined body of molecular, imaging, and computational tools and datasets from this research will be disseminated widely, and made available to a broad class of investigators for adoption in the study of other major neuroscience problems. This project will serve as a new model for computationally enabled neuroscience research that achieves a long-desired synergy between the wet lab and computation. n/a",CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development,9097814,R01NS086082,"['Address', 'Adoption', 'Affect', 'Afferent Neurons', 'Algorithms', 'Anatomic Models', 'Back', 'Biological', 'Biological Models', 'Biophysical Process', 'Characteristics', 'Coal', 'Collaborations', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Data Set', 'Dendrites', 'Development', 'Developmental Biology', 'Developmental Process', 'Discipline', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Elements', 'F-Actin', 'Future', 'Genetic', 'Genetic Structures', 'Goals', 'Growth', 'Growth and Development function', 'Image', 'Internships', 'K-12 student', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Minority', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Models', 'Morphology', 'Nervous system structure', 'Neurites', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Positioning Attribute', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Series', 'Shapes', 'Signal Transduction', 'Staging', 'Statistical Data Interpretation', 'Statistical Models', 'Structure', 'Synapses', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Transgenic Organisms', 'Trees', 'analog', 'base', 'computerized tools', 'data sharing', 'developmental genetics', 'developmental neurobiology', 'digital', 'feeding', 'fluorescence imaging', 'genetic manipulation', 'graduate student', 'high school', 'in vivo', 'innovation', 'insight', 'molecular imaging', 'molecular modeling', 'morphometry', 'neurogenetics', 'neuroinformatics', 'next generation', 'novel', 'open source', 'post-doctoral training', 'programs', 'quantitative imaging', 'reconstruction', 'relating to nervous system', 'research study', 'role model', 'simulation', 'tool', 'undergraduate student', 'virtual']",NINDS,GEORGIA STATE UNIVERSITY,R01,2016,323032,-0.003216859685262052
"Statistical methods for large and complex databases of ultra-high-dimensional DESCRIPTION: Medical imaging is a cornerstone of basic science and clinical practice. To discover new mechanisms and markers of disease and their crucial implications for clinical practice, large multi-center imaging studies are acquiring terabytes of complex multi-modality imaging data cross-sectionally and longitudinally over decades. The statistical analysis of data from such studies is challenging due to the complex structure of the imaging data acquired and the ultra-high dimensionality. Furthermore, the heterogeneity of anatomy, pathology, and imaging protocols causes instability and failure of many current state-of-the-art image analysis methods. This grant proposes statistical frameworks for studying populations through biomedical imaging, scalable and robust methods for the identification and accurate quantification of pathology, and analytic tools for the cross-sectional and longitudinal examination of etiology and disease progression. These techniques will be applied to address key goals of the motivating large and multi- center studies of multiple sclerosis and Alzheimer's disease conducted at Johns Hopkins Hospital, the National Institute of Neurological Disorders and Stroke, and across the globe. The project will create methods for uncovering and quantifying brain lesion pathology, incidence, and trajectory. Methods developed under this grant will be targeted towards these neuroimaging goals, but will form the basis for statistical image analysis methods applicable broadly in the biomedical sciences. PUBLIC HEALTH RELEVANCE: This project involves the development of statistical frameworks and methods for the analysis of complex ultra-high-dimensional biomedical imaging. Methods developed are applied to study the clinical management and etiology of multiple sclerosis and Alzheimer's disease longitudinally and cross-sectionally.",Statistical methods for large and complex databases of ultra-high-dimensional,9115248,R01NS085211,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Applications Grants', 'Area', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Brain', 'Brain Pathology', 'Brain imaging', 'Clinical Management', 'Complex', 'Computer software', 'Computing Methodologies', 'Contrast Media', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease Marker', 'Disease Progression', 'Etiology', 'Failure', 'Goals', 'Grant', 'Health', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Journals', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Multicenter Studies', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Pathology', 'Positioning Attribute', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Site', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Visualization software', 'Work', 'base', 'bioimaging', 'clinical practice', 'contrast enhanced', 'data visualization', 'design', 'falls', 'imaging Segmentation', 'imaging modality', 'member', 'neuroimaging', 'next generation', 'open source', 'skills', 'study population', 'terabyte', 'tool', 'white matter']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2016,347156,0.02416990271319141
"Prediction of IPF Progression Using Imaging Patterns ﻿    DESCRIPTION (provided by applicant): Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. These designations of natural history assume great importance at a time when insights from preclinical studies are beginning to translate into therapies targeted at specific key pathways of fibrosis. Stratification of disease phenotypes is important in order to decipher the effects of newly approved therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individual patients.  Various prognostic tools have been developed for IPF that correlate with overall survival; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good early predictive models exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use the anonymized clinical data and source images on 234 patients with IPF from multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for quantitative image analysis, we will train a classifier on scans annotated manually by an expert radiologist, analyzing in separate aims static image features present on baseline scans and transitional (difference) morphologic features on sequential scans that herald progressive disease. Features of anatomic distribution will be explored and reproducible imaging features will be expressed with a quantitative lung fibrosis (QLF) score. Aggregate prognostic models using Cox proportional regression models will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Finally, we will externally validate our models in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitia Lung Disease Program.  Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that anticipate disease course in patients with IPF. We anticipate that these models can be used clinically at the individual patient level to enable more informed and timely management decisions for the choice in treatment as well as future research to define more homogeneous cohorts for testing new safe and effective therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression. PUBLIC HEALTH RELEVANCE: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rates of progression are highly variable, which hampers timely decisions about referral for lung transplantation or treatments using newer drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to predict disease course in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with slowly versus rapidly progressive disease, leading to more timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.",Prediction of IPF Progression Using Imaging Patterns,9122467,R21HL123477,"['Acute', 'Algorithms', 'Anatomy', 'Archives', 'Behavior', 'Biopsy', 'Categories', 'Classification', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Decision Making', 'Derivation procedure', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease model', 'Elderly', 'Etiology', 'Exhibits', 'Fibrosis', 'Functional disorder', 'General Population', 'Goals', 'Hamman-Rich syndrome', 'Health', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Individual', 'Institution', 'Interobserver Variability', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Investigation', 'Laboratories', 'Lung Transplantation', 'Lung diseases', 'Measures', 'Mining', 'Modeling', 'Morphology', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathway interactions', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Play', 'Prevalence', 'Progression-Free Survivals', 'Progressive Disease', 'Pulmonary Fibrosis', 'Pulmonary function tests', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Stable Disease', 'Stratification', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'cohort', 'data archive', 'digital imaging', 'disease classification', 'disease natural history', 'disease phenotype', 'effective therapy', 'functional decline', 'image processing', 'imaging biomarker', 'individual patient', 'insight', 'interstitial', 'novel', 'novel therapeutics', 'preclinical study', 'predictive modeling', 'prognostic', 'prognostic tool', 'programs', 'pulmonary function', 'quantitative imaging', 'radiologist', 'respiratory', 'success', 'targeted treatment']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2016,107290,0.0002905773987469192
"Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease Abstract: Advances in imaging technology offer great opportunities to study Alzheimer's disease (AD) in many ways that are not previously possible. This leads to various large-scale imaging studies, i.e., ADNI, for discovering AD-related imaging biomarkers. In these imaging studies, image registration plays a key role in reducing the confounding inter-subject variability and also enhancing the statistical power of identifying abnormalities related to AD. However, automated processing of large-scale imaging data, i.e., involving anything from hundreds to thousands of 3D brain images, is not trivial and requires dedicated computational tools. The goal of this project is to develop a series of novel deep multi-layer groupwise registration methods for effective, efficient and simultaneous registration of all brain images with possibly large anatomical and appearance differences. Also, to accommodate for new images acquired from the on-going large-scale imaging study, an efficient incremental groupwise registration method will be further developed to avoid time- and resource-consuming re-registration of all new and existing images from scratch. Our key idea is to break down the complex groupwise registration problem into hierarchical sets of small- scale registration tasks that can be solved easily, thus making the large-scale registration more manageable and fast. Specifically, 1) for fast initialization of large-scale groupwise registration of brain images, we will develop in Aim 1 a hierarchical learning-based landmark detection algorithm, based on random forest regression, to detect salient anatomical landmarks and then jointly align all images with detected landmarks. Since all images are distributed in a complex manifold and also the registration of similar images is much faster and more accurate, we propose to first build a graph to link each image only with similar images, and then formulate groupwise registration as dynamic graph shrinkage. This avoids direct registration of each image to the group-mean image as done in the conventional methods, thus improving both speed and accuracy. 2) To significantly speed up and also improve this single-layer graph-based groupwise registration, we will further develop in Aim 2 a deep multi-layer groupwise registration by simultaneous layer-by-layer graph construction and layer-wise registration. 3) Finally, to significantly increase both the speed and accuracy of registration for new images acquired from on-going large-scale imaging study, we will develop in Aim 3 a novel incremental groupwise registration method to reuse previous registration results of existing images for guiding registration of new images. Specifically, each new image can be quickly registered to the common space of existing images by finding its most similar existing image(s). Accordingly, all new and existing images will become similar in the common space and then can be quickly updated for their overall groupwise registration. All computational tools developed will be made freely available to the research community, for accelerating the imaging study of Alzheimer's disease. Narrative Description of Project Modern imaging techniques offer great opportunities to study Alzheimer's disease (AD) in many ways that are not previously possible. This leads to increasing number of large-scale imaging studies, including ADNI. However, the overwhelmingly big data poses new challenges to researchers in automated data processing. Thus, modern computational tools are expected to be able to handle the vast amount of data within a manageable time frame. In light of this, we aim to solve this large-scale spatial registration problem – a critical step directly related to accuracy and precision of imaging biomarkers to be discovered for AD. In particular, we will develop novel deep multi-layer groupwise registration methods for effective, efficient and simultaneous registration of all brain images with possibly large anatomical and appearance differences. Also, to accommodate for new images acquired from the on-going study, an efficient incremental groupwise registration will be further developed to avoid time- and resource-consuming re-registration of all new and existing images from scratch. The development of these advanced computational tools will eventually benefit for discovery of new imaging biomarkers for AD.",Analyzing Large-Scale Neuroimaging Data in Alzheimer's Disease,9240850,RF1AG053867,"['Advanced Development', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Appearance', 'Automatic Data Processing', 'Big Data', 'Brain', 'Brain imaging', 'Communities', 'Complex', 'Computer software', 'Data', 'Detection', 'Documentation', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Imaging technology', 'Learning', 'Light', 'Link', 'Mainstreaming', 'Methods', 'Play', 'Process', 'Research', 'Research Personnel', 'Resources', 'Running', 'Series', 'Speed', 'Subgroup', 'Time', 'Update', 'Work', 'abstracting', 'base', 'computerized tools', 'cost', 'empowered', 'forest', 'image guided', 'image registration', 'imaging biomarker', 'improved', 'neuroimaging', 'novel', 'rapid technique']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,RF1,2016,2485857,-0.05026237215949062
"Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II ﻿    DESCRIPTION (provided by applicant): An online community called EyeWire proved that volunteers can be motivated to reconstruct neural circuits through an activity resembling a 3D coloring book. EyeWire helped discover space-time speciﬁcity of the wiring from bipolar cells to starburst amacrine cells, which suggested a surprising new model for direction selectivity in the retina. Motivated by this success, we are preparing to launch EyeWire II, which aims to map the entire retinal connectome, yielding the ﬁrst complete wiring diagram for any region of the mammalian CNS. This ambitious goal will require innovative advances in virtually every component of EyeWire. The underlying electron microscopic image of the retina will be replaced by a new image with increased size and quality. A new artiﬁcial intelligence (AI) will be trained using a new software package for 3D deep learning. While the improved AI is expected to reduce the amount of human effort required to reconstruct a neuron, the number of neurons targeted for reconstruction will also increase dramatically. Overall, the absolute amount of human effort required will increase rather than decrease. Therefore it is critical to improve EyeWire's crowdsourcing to (1) mobilize more human effort and (2) to use human effort more efﬁciently. This project aims to radically improve both aspects, thereby making the retinal connectome achievable by EyeWire II. In Aim 1, we will create a compelling mobile game with the target of engaging 10x more people than the existing EyeWire community. In Aim 2, we will develop and deploy new crowdsourcing algorithms that extract wisdom from the crowd by weighted voting and optimally assign players to tasks. The Aims will be achieved through collaboration between three organizations. Wired Differently, Inc. (WD) is a new Boston-based nonproﬁt organization dedicated to ""citizen neuroscience"" that was recently spun out of MIT. WD currently operates EyeWire in collaboration with the Princeton Neuroscience Institute. The Entertainment Technology Center (ETC) at Carnegie Mellon University will offer a project-based class to its master's students to design and prototype new ideas for the mobile game. Both Aims will produce code and algorithms that will be made publicly available, and could have broad impact on citizen science. As the ﬁrst crowdsourcing of 3D image analysis, the code produced by Aim 1 could be useful for the many other kinds of 3D images found in biomedical research. The crowdsourcing algorithms of Aim 2 are potentially useful for any citizen science project facing the challenge of obtaining accurate and reliable results from a heterogeneous group of volunteers.         PUBLIC HEALTH RELEVANCE: EyeWire II will increase public understanding of the structure of the nervous system. The retinal connectome could aid those attempting to develop blindness therapies based on regenerating cells and their wiring. It could also aid the development of retinal prosthetics that directly stimulate ganglion cells and computationally emulate the bypassed micro circuitry. 1        ",Retinal connectome: mobile game and crowdsourcing algorithms for EyeWire II,9076876,UH2CA203710,"['Algorithms', 'Arts', 'Attention', 'BRAIN initiative', 'Behavior', 'Biomedical Research', 'Blindness', 'Books', 'Boston', 'Breathing', 'Bypass', 'Caenorhabditis elegans', 'Cells', 'Cellular Phone', 'Code', 'Collaborations', 'Color', 'Communities', 'Computer software', 'Country', 'Crowding', 'Data', 'Development', 'Electrons', 'Event', 'Goals', 'Human', 'Image', 'Institutes', 'Intelligence', 'Lead', 'Learning', 'Love', 'Maps', 'Modeling', 'Natural regeneration', 'Nature', 'Nervous system structure', 'Neurons', 'Neurosciences', 'New York', 'Organism', 'Performance', 'Play', 'Production', 'Publishing', 'Retina', 'Retinal', 'Scheme', 'Science', 'Sensory', 'Social Interaction', 'Source', 'Statistical Models', 'Students', 'Technology', 'Three-Dimensional Image', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Volunteer Group', 'Voting', 'Weight', 'Work', 'base', 'citizen science', 'connectome', 'crowdsourcing', 'design', 'ganglion cell', 'improved', 'innovation', 'microscopic imaging', 'neural circuit', 'online community', 'pleasure', 'programs', 'prototype', 'public health relevance', 'reconstruction', 'retinal prosthesis', 'simulation', 'starburst amacrine cell', 'success', 'university student', 'visual neuroscience', 'volunteer']",NCI,PRINCETON UNIVERSITY,UH2,2016,320900,-0.004631666484115162
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,9119513,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Health', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Intervention Studies', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'cardiovascular visualization', 'clinical application', 'clinical phenotype', 'clinical practice', 'cloud based', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'multi-atlas segmentation', 'new technology', 'novel', 'open source', 'outreach', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2016,597688,0.05150572568071851
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities. PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.","Pathology Image Informatics Platform for visualization, analysis and management",9145647,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmacologic Substance', 'Professional Organizations', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomarker discovery', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'drug discovery', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'support tools', 'symposium', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2016,605366,0.027591184462099932
"Computational Image Analysis for Cellular and Developmental Biology DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.",Computational Image Analysis for Cellular and Developmental Biology,8813596,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Health', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'quantitative imaging', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2015,59383,0.004646304225760531
"Continued Development of CellProfiler Cell Image Analysis Software DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology. PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.",Continued Development of CellProfiler Cell Image Analysis Software,8910751,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Health', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,589523,0.07340805712992504
"Image analysis for high-throughput C. elegans infection and metabolism assays DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute. PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8786567,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression Profile', 'Gene Expression Profiling', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'imaging platform', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2015,309263,0.048279612979707065
"Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals ﻿    DESCRIPTION (provided by applicant): Microscope techniques to image inside brain tissue are generally limited by poor depth penetration. Micro-endoscopy, wherein a probe is physically inserted into the tissue, can overcome this limitation in depth penetration, but at the expense of invasiveness and tissue damage due to the size of the probe. Our goal here is to palliate these problems by developing an ultra-miniature microendoscope probe based on a single, lensless optical fiber.  The direct transmission of an image through an optical ﬁber is diﬃcult because spatial information becomes scrambled upon propagation. We have recently demonstrated an image transmission strategy where spatial information is ﬁrst converted to spectral information. Our strategy is based on a principle of spread-spectrum encoding, borrowed from wireless communications, wherein object pixels are converted into distinct spectral codes that span the full bandwidth of the object spectrum. Image recovery is performed by numerical inversion of the detected spectrum at the ﬁber output. We have provided a simple demonstration of spread-spectrum encoding using macroscopic Fabry-Perot etalons. Our technique enables the 2D imaging of luminous (i.e. fluorescent or bioluminescent) objects with high throughput independent of pixel number. Moreover, it is insensitive to ﬁber bending, contains no moving parts, and opens the attractive possibility of extreme miniaturization down to the size of a single optical fiber.  Our goal here is to develop, characterize, and establish the versatility of a new class of ultra-miniature fiber probes that can provide functional 2D brain imaging at arbitrary depths and with minimal tissue damage. Our strategy will involve probe development, machine-learning algorithm development, and the actual demonstration of microendoscopic imaging in freely moving behaving animals.         PUBLIC HEALTH RELEVANCE: We have recently demonstrated a strategy to image through a single, lensless optical fiber. We propose to develop this into an ultraminiaturized microendoscope for functional brain imaging with minimal surgical damage in freely moving behaving animals.            ",Ultra-miniaturized single fiber probe for functional brain imaging in freely moving animals,9053610,R21EY026310,"['Address', 'Algorithms', 'Animals', 'Behavioral', 'Brain imaging', 'Caliber', 'Calibration', 'Code', 'Collaborations', 'Communication', 'Data', 'Detection', 'Development', 'Devices', 'Effectiveness', 'Endoscopes', 'Endoscopy', 'Fiber', 'Geometry', 'Goals', 'Image', 'Imaging Device', 'Label', 'Lasers', 'Learning', 'Lighting', 'Machine Learning', 'Microscope', 'Microscopic', 'Miniaturization', 'Motion', 'Mus', 'Operative Surgical Procedures', 'Optics', 'Output', 'Penetration', 'Recovery', 'Resolution', 'Side', 'Societies', 'Structure', 'System', 'Techniques', 'Tissues', 'Wireless Technology', 'base', 'brain tissue', 'high risk', 'image reconstruction', 'imprint', 'improved', 'in vivo', 'indexing', 'interest', 'lens', 'miniaturize', 'minimally invasive', 'optical fiber', 'optical imaging', 'photonics', 'portability', 'public health relevance', 'reconstruction', 'relating to nervous system', 'targeted imaging', 'transmission process', 'trend']",NEI,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R21,2015,239361,0.0028259102565576536
"Graph-Based Medical Image Segmentation in 3D and 4D DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care. PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.",Graph-Based Medical Image Segmentation in 3D and 4D,8902139,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Health', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Solutions', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'personalized care', 'quantitative imaging', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2015,405249,0.03874656675671057
"Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular DESCRIPTION (provided by applicant): A career development plan is proposed for Dr. David Mayerich, a computer scientist who is committed to developing an interdisciplinary career in biomedical engineering, with a focus on the collection and analysis of large-scale data sets at sub-micrometer resolution. His graduate research was in the areas of computer visualization and optical imaging, where his work lead to the development of the prototype Knife-Edge Scanning Microscope (KESM). This is the first instrument capable of imaging three-dimensional macro-scale tissue volumes at sub-micrometer resolution while providing a data rate approaching the transfer speed of most modern computer systems.         Since receiving his Ph.D., Dr. Mayerich worked as a postdoctoral fellow at the Beckman Institute for Advanced Science and Technology at the University of Illinois at Urbana-Champaign, where he has worked with biologists and biomedical engineers to develop tools for the segmentation and classification of large data sets. This provided experience in addressing the needs and limitations of the computational tools available to the interdisciplinary community.        The goal of the mentored phase of this proposal is to provide Dr. Mayerich with the opportunity to work as a developer for the FARSIGHT Toolkit. The FARSIGHT Toolkit is an open-source segmentation toolkit that focuses on developing computer vision algorithms specifically tailored to deal with the unique structures found in microscopy data sets. This project is directed by Prof. Badrinath Roysam at the University of Houston, and was awarded first-place in the NIH-sponsored DIADEM Challenge in neuron segmentation. Dr. Mayerich will use his previous experience in biomedical segmentation, GPU-based computing, and efficient data structures to help make the FARSIGHT Toolkit scalable to the terabyte-scale data sets produced using next-generation high-throughput imaging techniques. Dr. Mayerich will receive mentoring in the algorithms and techniques used in the FARSIGHT Toolkit, as well as valuable experience working on a collaborative software development project.         The goal of the independent phase is to use recently developed imaging techniques, along with scalable segmentation algorithms, to construct complete microvascular models of mouse organs. Recent advances in KESM demonstrate that sub-micrometer images of 1cm3 tissue samples can be collected in less than 50 hours. These images have the resolution and quality necessary for (a) complete reconstruction of microvascular networks in whole organs, and (b) the geometric distribution of cell soma in relation to this network. Models describing cellular and microvascular relationships have implications in several diseases, including neurodegenerative disease and tumor growth, as well as clinical applications in tissue engineering and the quantitative analysis of angiogenic drugs and therapies. PROJECT NARRATIVE The goal of this work is to produce high-resolution microvascular models from mouse brain tissue, as well as create algorithms for querying, distributing, and building models from next-generation high-throughput microscopy data sets. These techniques will allow researchers to create large-scale blood flow simulations, simulate the extent of tissue damage due to stroke or aneurism, and explore the relationships between cells and microvessels on a tissue-wide scale. Clinical applications include the quantification of angiogenesis in tumors and tissue implants, and the quantification of neurovascular effects in neurodegenerative disease models.",Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular,8920669,R00LM011390,"['Active Learning', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Atlases', 'Award', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood Vessels', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical Research', 'Collection', 'Communities', 'Complex', 'Computer Systems', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Disease model', 'Doctor of Philosophy', 'Funding', 'Future', 'Goals', 'Hour', 'Illinois', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Institutes', 'Lead', 'Learning', 'Machine Learning', 'Memory', 'Mentors', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Mus', 'Neurodegenerative Disorders', 'Neurons', 'Online Systems', 'Organ', 'Pharmacotherapy', 'Phase', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Speed', 'Stroke', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Engineering', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'Transgenic Organisms', 'Tumor Angiogenesis', 'Tumor Tissue', 'United States National Institutes of Health', 'Universities', 'Work', 'analytical method', 'angiogenesis', 'base', 'brain tissue', 'career', 'career development', 'clinical application', 'computerized tools', 'design', 'experience', 'imaging Segmentation', 'improved', 'instrument', 'memory process', 'model building', 'mouse model', 'neuronal cell body', 'next generation', 'open source', 'optical imaging', 'programs', 'prototype', 'reconstruction', 'research study', 'simulation', 'software development', 'success', 'tool', 'tumor growth']",NLM,UNIVERSITY OF HOUSTON,R00,2015,239130,0.012418241986791145
"Multi-Resolution Docking Methods for Electron Microscopy ﻿    DESCRIPTION (provided by applicant): In the past decade, significant progress was made in 3D imaging of macromolecular assemblies via electron microscopy and in the development of computational algorithms that relate the resulting volumetric maps to atomic-resolution structures. The overall goal of the proposed research is to further develop computational fitting and validation tools for electron microscopy (EM). We intend to establish new modeling, visualization, and simulation techniques that would serve as bridges between atomic structures and EM densities. The proposed multi-scale software will aid in the routine determination of large-scale structures of biomolecular assemblies and in the validation of structural models that will be deposited to public databases such as the Protein Data Bank (PDB) and the EM Data Bank (EMDB). Key questions to be addressed include the following: (i) How can one improve, validate, and disseminate well-established matching algorithms for intermediate-resolution (8-15 Å) cryo-electron microscopy? (ii) How can one accurately identify and segment geometric features of subcellular assemblies in low-resolution (4-5 nm) cryo-electron tomograms or in focused ion beam milling of resin-embedded specimen blocks? (iii) Given the recent increase in resolution achieved with direct detection cameras, how can one systematically characterize high-resolution (2-10 Å) density patterns and validate atomic models based on local signatures in the data? We will adapt a new modeling paradigm for these studies, namely simultaneous refinement of multiple subunits. This approach is based on a ""systems"" perspective because biological assemblies exhibit ""emergent behavior"" in the spatial domain, that is, the whole is more than the sum of its parts. The new paradigm, in combination with docking protocols, improves model accuracy and opens the door to new global fitting applications in the above three areas. In addition, we will use statistical analysis and machine learning of local signatures to complement the global strategies. The collaborative efforts supported by this grant will include refinement of cytoskeletal filaments, molecular motors, chromatin fibers, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established internet-based mechanisms used by the Situs and Sculptor packages.         PUBLIC HEALTH RELEVANCE: This project helps biological electron microscopists bridge a broad range of resolution levels from atomic to living organism-level. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.            ",Multi-Resolution Docking Methods for Electron Microscopy,8964685,R01GM062968,"['Address', 'Algorithms', 'Architecture', 'Area', 'Behavior', 'Biological', 'Cells', 'Characteristics', 'Chromatin Fiber', 'Code', 'Collaborations', 'Communities', 'Complement', 'Computational algorithm', 'Computer Simulation', 'Computer software', 'Computer-Assisted Image Analysis', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Discipline', 'Docking', 'Drug Design', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Heating', 'Image', 'Imagery', 'Internet', 'Ions', 'Laboratories', 'Life', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Measures', 'Membrane', 'Methods', 'Microtubules', 'Modeling', 'Molecular', 'Molecular Motors', 'Noise', 'Organism', 'Pattern', 'Pattern Recognition', 'Plant Resins', 'Proteins', 'Protocols documentation', 'Relative (related person)', 'Research', 'Resolution', 'Scanning Electron Microscopy', 'Series', 'Specimen', 'Stereocilium', 'Structural Models', 'Structure', 'Sum', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Tomogram', 'Training', 'Validation', 'Vesicle', 'base', 'computer code', 'cryogenics', 'density', 'design', 'fitness', 'fundamental research', 'high standard', 'image reconstruction', 'improved', 'in vivo', 'insight', 'macromolecular assembly', 'new technology', 'next generation', 'programs', 'public health relevance', 'reconstruction', 'relating to nervous system', 'simulation', 'statistics', 'tomography', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2015,307928,-0.014812131046919749
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8852613,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,213115,0.0199191927571512
"SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies ﻿    DESCRIPTION (provided by applicant): Efforts to reduce the burden of Tuberculosis (TB) are challenged by the persistent social inequalities in health, the limited number of local healthcare professionals, and the weak healthcare infrastructure found in resource-poor communities. Reducing the TB diagnosis delay is critical in mitigating disease transmission and minimizing the reproductive rate of the TB epidemic in high-burden areas. The main objective of this proposal is to expedite the TB diagnosis process by developing novel image processing and machine learning techniques to analyze chest X-ray images thus reducing patient wait times for being diagnosed with TB. The study will be conducted in the district of Carabayllo, a densely occupied, high-burden TB area in Lima, the capital of Perú. Efforts to develop the proposed user-centered, mobile device-based computing system are aligned with the mission of the National Institute of Biomedical Imaging and Bioengineering (NIBIB) and its strategic goals 2 and 4 in particular-the proposed socio-technical intervention aims at developing biomedical imaging techniques (i.e. wireless and image sensing/analyzing) to enable a point-of-care mobile device-based computing system for TB screening and diagnostic. Anticipated outcomes include a) a large-scale, real-world, well-annotated, and public available chest X-ray image database for TB screening, b) development of new image analysis techniques for X-ray image capturing and pre- processing, and c) novel learning-based feature extraction and classification algorithms. This  interdisciplinary effort, involving community, university, hospitals and health care establishments in all stages of the research, responds to the need for increased partnerships between academia and community stakeholders, and the potential for building capacity in biomedical and technology solutions for health in both directions (North-South, South-North). Its scientific contribution lies in the intersection of three NIBIB scientific program areas including image processing, telehealth, and biomedical informatics.         PUBLIC HEALTH RELEVANCE: This project is highly relevant to public and global health because it offers a socio-technical solution for resource-poor communities severely affected by TB. Outcomes of this project will contribute significantly to improving specific healthcare processes affecting hard-to-reach communities that are socially excluded and lack the benefits of technological advances while broadening our understanding about effective human centered designs to improve healthcare systems with mobile computing technologies.            ",SCH: INT A.Soclotechnilcal Systems Systems  Approach for Improving Tuberculosis Diagnostics Using Mobile Health Technologies,9072725,R01EB021900,"['Academia', 'Address', 'Affect', 'Algorithms', 'Area', 'Benchmarking', 'Biomedical Technology', 'Capital', 'Cessation of life', 'Chest', 'Chronic Disease', 'Cities', 'Classification', 'Clinic', 'Communicable Diseases', 'Communities', 'Complex', 'Computer Assisted', 'Computer Systems', 'Computer software', 'Computers', 'Data', 'Databases', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic radiologic examination', 'Disadvantaged', 'Discipline', 'Engineering', 'Epidemic', 'Evaluation', 'Female', 'Goals', 'Health', 'Health Professional', 'Health Sciences', 'Health Technology', 'Healthcare', 'Healthcare Systems', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Image Enhancement', 'Imaging Techniques', 'Intervention', 'Learning', 'Lung nodule', 'Machine Learning', 'Medical', 'Minority', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Outcome', 'Patients', 'Peru', 'Population', 'Process', 'Public Health', 'Reader', 'Recruitment Activity', 'Reporting', 'Research', 'Research Infrastructure', 'Resources', 'Running', 'Sensitivity and Specificity', 'Software Tools', 'Solutions', 'Staging', 'System', 'Systems Analysis', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Time', 'Training', 'Treatment Protocols', 'Tuberculosis', 'Underrepresented Students', 'University Hospitals', 'Vaccines', 'Wireless Technology', 'Woman', 'World Health Organization', 'accurate diagnosis', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'compliance behavior', 'data exchange', 'design', 'digital imaging', 'disease transmission', 'global health', 'handheld mobile device', 'image processing', 'improved', 'mHealth', 'novel', 'open source', 'point of care', 'programs', 'public health relevance', 'reproductive', 'screening', 'social inequality', 'telehealth', 'tool']",NIBIB,UNIVERSITY OF MASSACHUSETTS LOWELL,R01,2015,299984,0.024018831571256612
"Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers ﻿    DESCRIPTION (provided by applicant): The Quantitative Imaging Network (QIN) is a consortium of centers developing quantitative image features, which are proving to be valuable biomarkers of the underlying cancer biology and that can be used for assessing response to treatment and predicting clinical outcome. It is now important to discover the best quantitative imaging features for detection of response to therapeutics, to identify subtypes of cancer, and to correlate with cancer genomics. However, progress is thwarted by the lack of shared software algorithms, architectures, and resources required to compute, compare, evaluate, and disseminate these quantitative imaging features within the QIN and the broader community. We propose to develop the Quantitative Imaging Feature Pipeline (QIFP), a cloud-based, open source platform that will give researchers free access to these capabilities and hasten the introduction of quantitative image biomarkers into single- and multi-center clinical trials. The QIFP will facilitate assessment of the incremental value of new vs. existing image feature sets. It will also allow researchers to add their own algorithms to compute novel quantitative image features in their own studies and to disseminate them to the greater research community. To accomplish this: (1) We will create an expandable library of quantitative imaging feature algorithms capable of comprehensive characterization of the imaging phenotype of cancer. It will support a broad set of imaging modalities and algorithms implemented in a variety of languages, including algorithms that provide volumetric and time-varying assessment of lesion size, shape, edge sharpness, and pixel statistics. (2) We will build a cloud-based software architecture for creating, executing, and comparing quantitative image feature-generating pipelines, including algorithms in the library and/or those supplied by QIN or other researchers as plug-ins. QIFP will also have (a) a machine learning engine that lets users specify a dependent variable (e.g., progression-free survival) that the quantitative image features can used to predict, and (b) an evaluation engine that compares the utility of particular features for predicting the dependent variable. (3) We will assess the QIFP in four ways: (a) by its ability to recapitulate the role of known biomarkers in a related clinical trial, (b) by comparing linear measurement, metabolic tumor burden and novel combinations of the features in our library for predicting one-year progression-free survival, (c) by merging imaging features with known host-, drug- and tumor-based follicular lymphoma biomarkers in order to develop the most robust and integrative predictive model for patient outcomes, and (d) by using the QIFP to combine and to evaluate image feature algorithms developed by another QIN team and our own NCI- funded team in the study of radiogenomics of non-small cell lung cancer. The QIFP will fill a substantial gap in the science currently being carried out in the QIN and in the community by providing the tools and infrastructure to assess the value of novel quantitative imaging features of cancer, and will thereby accelerate incorporating new imaging biomarkers into single and multi-center clinical trials and into oncology practice.         PUBLIC HEALTH RELEVANCE: We propose to develop and evaluate a software platform that has major relevance for human health. Many investigators are pursuing image-based surrogates for response to therapy that could be used in clinical trials to predict their success/failure earlier and that are more accurate than existing surrogates. Our developments will facilitate sharing, assessing, and comparing combinations of image feature-generating software algorithms for predicting treatment response, survival, and tissue genomics, which will, in turn, greatly accelerate the development and acceptance of new and more relevant imaging surrogates for assessing cancer treatments.                ","Computing, Optimizing, and Evaluating Quantitative Cancer Imaging Biomarkers",8960049,U01CA187947,"['Algorithmic Software', 'Algorithms', 'Architecture', 'Biological', 'Biological Markers', 'Cancer Biology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Data', 'Data Set', 'Development', 'Eastern Cooperative Oncology Group', 'Evaluation', 'Failure', 'Follicular Lymphoma', 'Funding', 'Gene Expression', 'Generations', 'Genomics', 'Health', 'Human', 'Image', 'Investigation', 'Java', 'Language', 'Lesion', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Metabolic', 'Modality', 'Molecular', 'Multi-Institutional Clinical Trial', 'Non-Small-Cell Lung Carcinoma', 'Outcome', 'Patients', 'Pharmaceutical Preparations', 'Phenotype', 'Plug-in', 'Positron-Emission Tomography', 'Progression-Free Survivals', 'Pythons', 'RNA Sequences', 'Radiogenomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Science', 'Shapes', 'Specific qualifier value', 'System', 'Therapeutic', 'Time', 'Tissue Survival', 'Tissues', 'Tumor Burden', 'base', 'cancer genomics', 'cancer imaging', 'cancer therapy', 'cloud based', 'disorder subtype', 'image archival system', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'novel', 'novel therapeutics', 'oncology', 'open source', 'predictive modeling', 'public health relevance', 'quantitative imaging', 'repository', 'response', 'statistics', 'success', 'tool', 'transcriptome sequencing', 'treatment response', 'tumor', 'vector', 'web based interface']",NCI,STANFORD UNIVERSITY,U01,2015,652612,0.011378146160068691
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics. n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8792208,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2015,248295,0.029778483687918307
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community. PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8922953,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'precision medicine', 'prognostic value', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2015,314327,0.06377465574925842
"Objective decision support environment for clinical trials DESCRIPTION:  Brain tumors are the second- and fifth-most common cause of cancer death in males and females under 40, respectively. The 5-year relative survival rate is only 33%, even after decades of research into new treatments. Imaging based on ""virtual biopsy"" can provide information about the entire lesion in a minimally or non-invasive way. Prior work by our group has demonstrated that image processing methods applied to serial examinations together (as opposed to applying them to individual examinations) can make subtle changes in brain tumors more apparent, allowing earlier detection of progression. We see the union of virtual biopsy methods and change detection methods as an innovative and powerful combination that our team is uniquely qualified to develop and evaluate. In this application, we will implement several feature selection (FS) methods in a tool that is ""image friendly"". This tool will help select informative features from images; apply a wide range of existing ML algorithms to determine which features are important predictors of therapy response, and to evaluate the impact of a decision support application using these features and ML in a clinical trial. The final stage of th proposal will test the decision support tools in 3 clinical scenarios to see if they are able to significantly improve the decision making of clinicians in a clinical trial.  The long-term goal of this proposal is to develop virtual biopsy technology that will enhance the clinical decision making process by providing tools for investigation of image-based therapy response assessment tools, that may also have some ability to predict outcome. We hope to apply the technology to other organ systems and other imaging technologies. We anticipate this project will impact clinical trials by enabling investigation of alternative outcome measures that are objectively assessed using algorithm evaluation methods. Such a toolset should be useful to the entire cancer imaging community to help evaluate features in old and new imaging technologies that correlate with patient survival. As such, this is ideal for helping the Quantitative Imaging Network (QIN) achieve its goals. The selection of features that reflect response to therapy has long been the domain of the clinical radiologist. When imaging was relatively straightforward (e.g. a chest X-ray of lung cancer), a measurement or a visual assessment was a reasonable metric. Today, advanced imaging devices produce large amounts of data that reflect a range of properties. In this work, we build on previous work developing computer techniques for identifying and characterizing changes in brain tumors, using MRI. In this proposal, we will focus on building 1) a high quality database of brain cancer imaging, clinical data, ""-omic"" data, outcomes data; 2) a library of easily accessed tools for computing features that might be important predictors of tumor response; 3) a tool that will help objectively establish the feature() that are valuable through a variety of machine learning methods; and 4) use the above to create a decision support tool that will be used in 3 clinical trial situations.",Objective decision support environment for clinical trials,8926887,U01CA160045,"['Algorithms', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Cancer Etiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collection', 'Communities', 'Computers', 'Data', 'Databases', 'Decision Making', 'Detection', 'Differentiation Therapy', 'Early Diagnosis', 'Environment', 'Evaluation', 'Female', 'Goals', 'Image', 'Imaging Device', 'Imaging technology', 'Individual', 'Investigation', 'Lesion', 'Libraries', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Outcome', 'Outcome Measure', 'Output', 'Pathologic', 'Patients', 'Primary Brain Neoplasms', 'Process', 'Property', 'Qualifying', 'Relative (related person)', 'Research', 'Staging', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Visual', 'Work', 'base', 'body system', 'cancer imaging', 'clinical decision-making', 'image processing', 'improved', 'innovation', 'male', 'quantitative imaging', 'radiologist', 'response', 'tool', 'tumor', 'virtual']",NCI,MAYO CLINIC ROCHESTER,U01,2015,522865,-0.019446011741334587
"In vivo Characterization of Stents using Intravascular OCT Imaging DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel. PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,8885879,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Health', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'stent thrombosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2015,457216,0.008922973206218869
"CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development DESCRIPTION (provided by applicant): Background: Dendritic arbor shape and functional properties emerge from the interaction of many complex developmental processes. It is now accepted that multiple local-level interactions of cytoskeleton elements direct the growth and development of the dendrite arbor. However, the specific mechanisms that control developmental acquisition of final functional dendritic properties are largely unknown. Addressing this fundamental question requires novel data driven systems-biology tools to study developmental and biophysical mechanisms in the same neuronal model. A tightly-knit collaboration between molecular genetics, quantitative morphometry, and mathematical simulation can for the first time enable large-scale studies capable of achieving holistic understanding of the mechanisms underlying emergent features of the arbor. Project Goals: The main neuroscientific goal of this project is to understand how multiple local interactions of cytoskeleton components during differentiation define mature dendritic arbor shape and its functional integrative properties, using Drosophila sensory neurons as a model. The technological goal of this project is to develop a novel investigative approach that integrates and extends previously separate approaches from developmental biology & genetics, in vivo confocal imaging & electrophysiology, computer vision, and neuroanatomical modeling. Specific Aims: We propose 3 tightly integrated specific aims. Aim 1: use genetic manipulations and electrophysiological recordings to model the role of cytoskeletal organization and dynamics as a fundamental determinant of emergent dendrite arbor shape and function. Aim 2: Implement advanced 4D multi-parameter imaging protocols and automated algorithms to reconstruct the arbor, and quantify spatial and temporal associations among multiple sub-cellular components. Aim 3: using automated reconstructions & measurements from aim 2, statistically characterize the structural and cytoskeletal features of dendrite arbors, and stochastically simulate the growth and electrotonic properties of anatomically realistic virtual neuronal analogues. The data from aim 3 will feed back novel hypotheses to be tested by a subsequent repetition of the (aim 1 - aim 2 - aim 3) cycle. Approach: We will focus on a single model system - Drosophila dendritic arborization (da) sensory neurons. More specifically, we will investigate class I and class IV da neuron arborization based upon their radically distinct dendritic morphologies (simple vs. complex) and underlying cytoskeletal organizations. We will make fusion constructs of cytoskeleton components with spectrally distinct fluorescent proteins. These will be used in transgenic Drosophila in order to quantitatively measure the distribution of F-actin, microtubules, and microtubule polarity within the dendrite arbor throughout its development in vivo using confocal multi-fluor imaging. The resulting images will be processed by automated quantitative computer vision algorithms that will accurately extract the topology of the dendritic arbor, and it changes over time. We will use the resulting maps in neuroanatomical stochastic simulations to establish the links between the emergent morphometrics of the dendrite and specific cytoskeleton features at various developmental stages. Intellectual Merit: From a neurogenetics perspective, this project will pioneer the use of cytoskeletal features as putative fundamental determinants in statistical neuroanatomical models. These determinants will be linked to morphological determinants. From a computational perspective, this project will advance the state of the art in automated algorithms for delineating neuroanatomy (and its morphological dynamics) by deploying core technologies for large-scale multi-parameter studies, and result in an effective interfacing of automated reconstruction and simulation technologies. With this innovation, model predictions can be tested by molecular biological techniques, and findings of statistical models can be used to inform molecular models of dendrite arbor development. Educational Impact: This project will result in a cross-disciplinary training of post-doctoral fellows, graduate students, undergraduate students and high school interns. It will result in practical insight on ways to conduct cutting-edge systems-level scientific research overcoming disciplinary boundaries and using best-available collaborative tools. The trainees from this program will be uniquely positioned to develop the broader field of imaging-driven integrative systems neurobiology. It will expose minority and K-12 students to a new world of trans-disciplinary research that is indicative of the future. Broader Impacts: The combined body of molecular, imaging, and computational tools and datasets from this research will be disseminated widely, and made available to a broad class of investigators for adoption in the study of other major neuroscience problems. This project will serve as a new model for computationally enabled neuroscience research that achieves a long-desired synergy between the wet lab and computation. n/a",CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development,8920676,R01NS086082,"['Address', 'Adoption', 'Affect', 'Afferent Neurons', 'Algorithms', 'Anatomic Models', 'Back', 'Biological', 'Biological Models', 'Biophysical Process', 'Characteristics', 'Coal', 'Collaborations', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Data Set', 'Dendrites', 'Development', 'Developmental Biology', 'Developmental Process', 'Discipline', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Elements', 'F-Actin', 'Future', 'Goals', 'Growth', 'Growth and Development function', 'Image', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Minority', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Models', 'Morphology', 'Nervous system structure', 'Neurites', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Role', 'Series', 'Shapes', 'Signal Transduction', 'Staging', 'Statistical Models', 'Structure', 'Students', 'Synapses', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Transgenic Organisms', 'Trees', 'analog', 'base', 'computerized tools', 'data sharing', 'developmental genetics', 'developmental neurobiology', 'digital', 'feeding', 'genetic manipulation', 'graduate student', 'high school', 'in vivo', 'innovation', 'insight', 'molecular imaging', 'molecular modeling', 'morphometry', 'neurogenetics', 'next generation', 'novel', 'open source', 'post-doctoral training', 'programs', 'quantitative imaging', 'reconstruction', 'relating to nervous system', 'research study', 'role model', 'simulation', 'tool', 'undergraduate student', 'virtual']",NINDS,GEORGIA STATE UNIVERSITY,R01,2015,323033,-0.003216859685262052
"Statistical methods for large and complex databases of ultra-high-dimensional DESCRIPTION: Medical imaging is a cornerstone of basic science and clinical practice. To discover new mechanisms and markers of disease and their crucial implications for clinical practice, large multi-center imaging studies are acquiring terabytes of complex multi-modality imaging data cross-sectionally and longitudinally over decades. The statistical analysis of data from such studies is challenging due to the complex structure of the imaging data acquired and the ultra-high dimensionality. Furthermore, the heterogeneity of anatomy, pathology, and imaging protocols causes instability and failure of many current state-of-the-art image analysis methods. This grant proposes statistical frameworks for studying populations through biomedical imaging, scalable and robust methods for the identification and accurate quantification of pathology, and analytic tools for the cross-sectional and longitudinal examination of etiology and disease progression. These techniques will be applied to address key goals of the motivating large and multi- center studies of multiple sclerosis and Alzheimer's disease conducted at Johns Hopkins Hospital, the National Institute of Neurological Disorders and Stroke, and across the globe. The project will create methods for uncovering and quantifying brain lesion pathology, incidence, and trajectory. Methods developed under this grant will be targeted towards these neuroimaging goals, but will form the basis for statistical image analysis methods applicable broadly in the biomedical sciences. PUBLIC HEALTH RELEVANCE: This project involves the development of statistical frameworks and methods for the analysis of complex ultra-high-dimensional biomedical imaging. Methods developed are applied to study the clinical management and etiology of multiple sclerosis and Alzheimer's disease longitudinally and cross-sectionally.",Statistical methods for large and complex databases of ultra-high-dimensional,8890255,R01NS085211,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Applications Grants', 'Area', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Brain', 'Brain Pathology', 'Brain imaging', 'Clinical Management', 'Complex', 'Computer software', 'Computing Methodologies', 'Contrast Media', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease Marker', 'Disease Progression', 'Etiology', 'Failure', 'Goals', 'Grant', 'Health', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Journals', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Multicenter Studies', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Pathology', 'Population Study', 'Positioning Attribute', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Site', 'Solutions', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Visualization software', 'Work', 'base', 'bioimaging', 'clinical practice', 'contrast enhanced', 'data visualization', 'design', 'falls', 'imaging Segmentation', 'imaging modality', 'member', 'neuroimaging', 'next generation', 'open source', 'skills', 'tool', 'white matter']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2015,347156,0.02416990271319141
"Prediction of IPF Progression Using Imaging Patterns ﻿    DESCRIPTION (provided by applicant): Idiopathic pulmonary fibrosis (IPF) is a devastating disease of unknown etiology occurring in older adults. IPF is ultimately fatal with a median survival of 2 to 5 years, and exhibits a highly heterogeneous natural history. Broad categories of disease progression have been defined, but are not predictable at the time of diagnosis. These designations of natural history assume great importance at a time when insights from preclinical studies are beginning to translate into therapies targeted at specific key pathways of fibrosis. Stratification of disease phenotypes is important in order to decipher the effects of newly approved therapies among individuals with biologically dissimilar natural histories and to better tailor therapy to individual patients.  Various prognostic tools have been developed for IPF that correlate with overall survival; most use clinical and functional variables independent of imaging findings. Prognostic determinants based on imaging features rely largely on subjective visual assessment of disease. In contrast, no good early predictive models exist that anticipate the natural history of disease in advance of significant functional decline. Given the indispensable role of high resolution computed tomography (HRCT) in the diagnosis and surveillance of IPF, we propose to mine the rich information in HRCT data sets to develop robust, quantitative features that can anticipate disease progression in advance of debilitating respiratory compromise. We propose to use the anonymized clinical data and source images on 234 patients with IPF from multicenter trials, and whose data are archived at the UCLA Computer Vision and Imaging Biomarkers Laboratory. Using an image processing pipeline developed in our laboratory for quantitative image analysis, we will train a classifier on scans annotated manually by an expert radiologist, analyzing in separate aims static image features present on baseline scans and transitional (difference) morphologic features on sequential scans that herald progressive disease. Features of anatomic distribution will be explored and reproducible imaging features will be expressed with a quantitative lung fibrosis (QLF) score. Aggregate prognostic models using Cox proportional regression models will be derived using only clinical covariates and combined clinical and imaging covariates, correlating these models with progression free survival. Finally, we will externally validate our models in an independent institutional registry of clinical and image data on patients with IPF seen in the UCLA Interstitia Lung Disease Program.  Our objectives are centered on the goals of using preexisting datasets to develop clinically meaningful models that anticipate disease course in patients with IPF. We anticipate that these models can be used clinically at the individual patient level to enable more informed and timely management decisions for the choice in treatment as well as future research to define more homogeneous cohorts for testing new safe and effective therapies and to better elucidate the effects of therapies in patients with biologically heterogeneous disease progression.         PUBLIC HEALTH RELEVANCE: Idiopathic pulmonary fibrosis (IPF) is a devastating disease of older adults that now has a few treatment options: The natural history of IPF and its rates of progression are highly variable, which hampers timely decisions about referral for lung transplantation or treatments using newer drug therapies. This research takes advantage of clinical and imaging datasets previously collected for research or clinical purposes, and will define image features using computer analysis of computed tomography (CT) images to predict disease course in advance of respiratory deterioration. The success of this research will enable us to distinguish between patients with slowly versus rapidly progressive disease, leading to more timely management decisions, and may help us to understand which patients might benefit from novel promising therapies or treatments and which may not.            ",Prediction of IPF Progression Using Imaging Patterns,8956609,R21HL123477,"['Acute', 'Algorithms', 'Anatomy', 'Archives', 'Behavior', 'Biopsy', 'Categories', 'Classification', 'Clinical', 'Clinical Data', 'Computer Analysis', 'Computer Vision Systems', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Decision Making', 'Derivation procedure', 'Deterioration', 'Diagnosis', 'Diagnostic', 'Diffuse', 'Disease', 'Disease Progression', 'Disease model', 'Elderly', 'Etiology', 'Exhibits', 'Fibrosis', 'Functional disorder', 'General Population', 'Goals', 'Hamman-Rich syndrome', 'High Resolution Computed Tomography', 'Image', 'Image Analysis', 'Individual', 'Institution', 'Interobserver Variability', 'Interstitial Lung Diseases', 'Intraobserver Variability', 'Investigation', 'Laboratories', 'Lung', 'Lung Transplantation', 'Lung diseases', 'Measures', 'Mining', 'Modeling', 'Morphology', 'Multicenter Trials', 'Natural History', 'Operative Surgical Procedures', 'Pathway interactions', 'Patient Triage', 'Patients', 'Pattern', 'Pharmacologic Substance', 'Pharmacotherapy', 'Phenotype', 'Play', 'Prevalence', 'Progression-Free Survivals', 'Progressive Disease', 'Pulmonary function tests', 'Registries', 'Reproducibility', 'Research', 'Risk', 'Role', 'Scanning', 'Stable Disease', 'Stratification', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Transplantation', 'Visual', 'X-Ray Computed Tomography', 'base', 'clinical application', 'cohort', 'digital imaging', 'disease classification', 'disease natural history', 'disease phenotype', 'effective therapy', 'functional decline', 'image processing', 'imaging biomarker', 'insight', 'interstitial', 'novel', 'preclinical study', 'predictive modeling', 'prognostic', 'prognostic tool', 'programs', 'public health relevance', 'pulmonary function', 'quantitative imaging', 'radiologist', 'respiratory', 'success', 'targeted treatment']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2015,107290,0.0002905773987469192
"Quantitative Image Analysis Techniques for Optic Nerve Disease DESCRIPTION (provided by applicant): Disorders of the optic nerve (ON) account for a significant percentage of the 20 most impactful ophthalmological conditions. Collectively, diseases of the ON are the number one cause of irreversible blindness worldwide, and present serious public health concerns in the U.S. Consider, for example, that glaucoma impacts more than three million Americans and costs the U.S. economy almost $3 billion per year. Optic neuritis (i.e., inflammatory demyelination of the ON) is the initial symptom in ~25% of all multipl sclerosis (MS) cases (which impacts over 400 thousand Americans and introduces societal health care costs of nearly $30 billion per year). Nearly two thirds of MS patients will experience episodes of optic neuritis in their lifetimes, and 40-60% of patients have visual defects localized to the ON. These disorders irreversibly damage the ON. Even so, damage to axons in the ON is progressive, defined by a window of opportunity for treatment between loss of function and actual degeneration. The potential for recovery exists because there are treatments that can help prevent progression if administered during this window of opportunity. Yet, we do not have effective means to assess who is in the window and who will benefit from treatment. We propose to translate computational imaging methods from the neuroimaging community to provide robust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. These efforts will improve prognostic accuracy, lead to better understanding of patient responses, and enhance targeted interventions. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not.  The overall goal of this research is to provide a foundation for image analysis of the ON and its relationships with pathological disorders. We will build upon recent advances in robust medical image computing to segment the ON in clinical CT and MRI acquisitions, develop registration procedures to establish intra- and inter-subject correspondence, and bring together information from the multi-modal battery of imaging studies that are typically used in clinical care (aim 1). With these new methods, we will address the exploratory hypothesis that quantitative use of clinical imaging data can increase prognostic accuracy (aim 2). We note that aim 2 is particularly exploratory and in line with the high- risk/high-reward aspect of this mechanism; many studies have shown that baseline imaging does not conclusively predict long term outcome or treatment response. We hypothesize that this may be because early findings are related to edema and inflammation rather than cellular damage per se. Once this exploratory phase is complete, we will pursue promising prognostic biomarkers using more detailed condition staging criteria and including more than two longitudinal time points in the analysis. Ultimately, these efforts will improve assessment ON disease and, in turn, patient care. PUBLIC HEALTH RELEVANCE:  We propose to translate medical imaging computing procedures from the neuroimaging community to provide robust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not more effectively than traditional pre-interventional measures.",Quantitative Image Analysis Techniques for Optic Nerve Disease,8774908,R21EY024036,"['Accounting', 'Acute', 'Address', 'Adrenal Cortex Hormones', 'Affect', 'Aftercare', 'Age', 'Algorithms', 'American', 'Area', 'Axon', 'Biological Markers', 'Blindness', 'Brain', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Communities', 'Data', 'Defect', 'Demyelinations', 'Diagnostic', 'Disease', 'Edema', 'Eye', 'Foundations', 'Gap Junctions', 'Glaucoma', 'Goals', 'Health', 'Health Care Costs', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Inflammatory', 'Interferons', 'Intervention', 'Intracranial Hypertension', 'Lead', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical Imaging', 'Methods', 'Modality', 'Multiple Sclerosis', 'Myelin', 'Nerve Tissue', 'Neurologic', 'Nutritional', 'Operative Surgical Procedures', 'Optic Disk', 'Optic Nerve', 'Optic Nerve Injuries', 'Optic Neuritis', 'Outcome', 'Patient Care', 'Patients', 'Phase', 'Phenotype', 'Procedures', 'Prognostic Marker', 'Property', 'Protective Agents', 'Public Health', 'Publishing', 'Recovery', 'Recurrence', 'Relapse', 'Research', 'Resource Sharing', 'Resources', 'Scanning', 'Sclerosis', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Swelling', 'Symptoms', 'Tars', 'Techniques', 'Thyroid Diseases', 'Time', 'Training', 'Translating', 'Treatment outcome', 'Tweens', 'Validation', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical care', 'clinical practice', 'clinical sequencing', 'computerized tools', 'contrast imaging', 'cost', 'direct application', 'experience', 'high reward', 'high risk', 'image processing', 'imaging modality', 'improved', 'innovation', 'loss of function', 'nerve decompression', 'neuroimaging', 'optic nerve disorder', 'outcome forecast', 'pressure', 'prevent', 'prognostic', 'prognostic value', 'quantitative imaging', 'response', 'standard of care', 'success', 'thyroid associated ophthalmopathies', 'tool', 'treatment response', 'vector']",NEI,VANDERBILT UNIVERSITY,R21,2015,185147,-0.008628188952473768
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,8887334,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Atlases', 'Biomedical Research', 'Brain', 'Brain imaging', 'Cardiac', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Health', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'cardiovascular visualization', 'clinical application', 'clinical phenotype', 'clinical practice', 'cloud based', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'open source', 'outreach', 'research study', 'success', 'targeted imaging', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2015,591379,0.05150572568071851
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8919113,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'imaging software', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'targeted imaging', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2015,341788,0.06604082032739456
"Pathology Image Informatics Platform for visualization, analysis and management ﻿    DESCRIPTION (provided by applicant): With the advent of whole slide digital scanners, histopathology slides can be digitized into very high-resolution digital images, realizing a new ""big data"" stream that can potentially rival ""omics data"" in size and complexity. Just as with the analysis of high-throughput genetic and expression data, the application of sophisticated image analytic tools and data pipelines can render the often passive data of digital pathology (DP) archives into a powerful source for: (a) rich quantitative insights into cancer biology and (b) companion diagnostic decision support tools for precision medicine. Digital pathology enabled companion diagnostic tests could yield predictions of cancer risk and aggressiveness in a manner similar to molecular diagnostic tests. However, prior to widespread clinical adoption of DP, extensive evaluation of clinical interpretation of DP imaging (DPI) and accompanying decision support tools needs to be undertaken. Wider acceptance of DPI by the cancer community (clinical and research) is hampered by lack of a publicly available, open access image informatics platform for easily viewing, managing, and quantitatively analyzing DPIs. While some commercial platforms exist for viewing and analyzing DPI data, none of these platforms are freely available. Open source image viewing/management platforms that cater to the radiology (e.g. XNAT) and computational biology communities are typically not conducive to handling very large file sizes as encountered with DPI datasets.  This multi-PI U24 proposal seeks to expand on an existing, freely available pathology image viewer (Sedeen Image Viewer) to create a pathology informatics platform (PIIP) for managing, annotating, sharing, and quantitatively analyzing DPI data. Sedeen was designed as a universal platform for DPI (by addressing several proprietary scanner formats and ""big data"" challenges), to provide (1) reliable and useful image annotation tools, and (2) for image registration and analysis of DPI data. Additionally, Sedeen has become an application for cropping large DPIs so that they can be input into programs such as Matlab or ImageJ. Sedeen has been freely available to the public for three years, with over 160 unique users from over 20 countries.  Building on the initial successes of Sedeen and its existing user base, our intent is to massively increase dissemination of DPI and algorithms in the cancer research community and clinical trial efforts, as well as to contribute towards the adoption of a rational and standardized set of DP operational conventions. This unique project will allow end users with different needs and technical backgrounds to seamlessly (a) archive and manage, (b) share, and (c) visualize their DPI data, acquired from different sites, formats, and platforms. The PIIP will provide a unified user interface for third party algorithms (nuclear segmentation, color normalization, biomarker quantification, radiology-pathology fusion) and will allow for algorithmic evaluation upon data arising from a plurality of source sites. By partnering with professional societies, we envision that the PIIP user base will expand to include the oncology, pathology, radiology, and pharmaceutical communities.         PUBLIC HEALTH RELEVANCE: This grant will result in the further development of advanced functionality of the already existing digital pathology image informatics platform (PIIP) with an established user-base for cancer research. Such an enhanced platform will provide the much-needed foundation for advancing (a) routine clinical adoption of digital pathology for primary diagnosis and (b) training and validation of companion diagnostic decision support systems based off histopathology. Thus, the project is aligned with the NCI's goal to foster innovative research strategies and their applications as a basis for ultimately protecting and improving human health.                ","Pathology Image Informatics Platform for visualization, analysis and management",8970326,U24CA199374,"['Accounting', 'Address', 'Adoption', 'Advanced Development', 'Algorithms', 'American', 'Archives', 'Big Data', 'Biological Markers', 'Cancer Biology', 'Cancer Prognosis', 'Clinical', 'Clinical Pathology', 'Clinical Research', 'Clinical Trials', 'Collaborations', 'Color', 'Communities', 'Community Clinical Oncology Program', 'Community Trial', 'Complex', 'Computational Biology', 'Computer Vision Systems', 'Computer software', 'Country', 'Data', 'Data Aggregation', 'Data Collection', 'Data Set', 'Data Storage and Retrieval', 'Decision Support Systems', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Ensure', 'Evaluation', 'Fostering', 'Foundations', 'Genetic', 'Goals', 'Grant', 'Health', 'Histopathology', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'International', 'Language', 'Length', 'Letters', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Medical Imaging', 'Medical Students', 'Molecular Diagnostic Testing', 'Morphology', 'Nuclear', 'Ontology', 'Optics', 'Pathologist', 'Pathology', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Protocols documentation', 'Pythons', 'Radiology Specialty', 'Research', 'Resolution', 'Scientist', 'Site', 'Slide', 'Societies', 'Source', 'Stream', 'Training', 'Training and Education', 'Validation', 'anticancer research', 'base', 'biomedical scientist', 'cancer diagnosis', 'cancer imaging', 'cancer risk', 'clinical research site', 'companion diagnostics', 'computer human interaction', 'data exchange', 'data integration', 'data sharing', 'design', 'digital', 'digital imaging', 'high throughput analysis', 'image archival system', 'image registration', 'imaging informatics', 'improved', 'in vivo imaging', 'innovation', 'insight', 'interest', 'malignant breast neoplasm', 'oncology', 'open source', 'photonics', 'precision medicine', 'programs', 'public health relevance', 'quantitative imaging', 'repository', 'research clinical testing', 'success', 'tool', 'tumor', 'user friendly software', 'validation studies']",NCI,CASE WESTERN RESERVE UNIVERSITY,U24,2015,606305,0.027591184462099932
"Computational Image Analysis for Cellular and Developmental Biology     DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. !         PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.             ",Computational Image Analysis for Cellular and Developmental Biology,8628140,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'public health relevance', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2014,59383,0.004646304225760531
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8699686,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'E-learning', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2014,142837,0.06167984198149524
"Automated retinopathy of prematurity classification using machine learning     DESCRIPTION (provided by applicant): The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH-funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi-disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing.         PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.",Automated retinopathy of prematurity classification using machine learning,8723225,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2014,198905,0.011874912857756353
"Continued Development of CellProfiler Cell Image Analysis Software     DESCRIPTION (provided by applicant): Most laboratories studying biological processes and human disease use microscopes to image cells or other biological samples. Even for small-scale experiments, the information sought from images is increasingly quantitative and complex, and automated microscopes collect images faster than can be examined by eye.  We will continue our development of CellProfiler (www.cellprofiler.org) to meet this strong and growing demand for software to analyze biological images. CellProfiler is a versatile, open-source toolbox. Using its point-and-click interface, researchers build a customized workflow of image-analysis modules to identify and measure biological objects in images. It can extract valuable biological information from images quickly, even for high-throughput experiments, while increasing objectivity and statistical power in microscopy experiments.  Published only seven years ago, CellProfiler is already an important and widely used tool: it is launched 100,000+ times per year by users around the world and has been cited in more than 800 papers from 600 distinct laboratories. The software evolves in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  We propose to improve CellProfiler's capabilities in order to enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler:  First, microscopy experiments are rapidly expanding in both scale and scope, and are beginning to push CellProfiler's limits, particularly when they involve larger images (e.g., for tissue samples, cellular microarrays, large field-of-view cameras), multi-dimensional images (time-lapse and three-dimensional imaging), images for morphological profiling, and novel microscopy types (super-resolution and single-molecule imaging). We will upgrade CellProfiler's capabilities to serve these needs and add proven, state-of-the-art algorithms for image processing (especially segmentation and filtering for non-fluorescence images), time-lapse and 3D analysis, and novel microscopy types. We will also add features and usability improvements requested by the large CellProfiler community.  Second, we will enable researchers to create sophisticated bioimaging analysis workflows by expanding CellProfiler's interoperability with complementary software (e.g., MATLAB, ImageJ, MicroManager, KNIME).  Third, we will disseminate CellProfiler and provide user, educator, and developer support. There is great demand for our online forum, downloadable materials, and in-person tutorials (1,000+ attendees so far).  These improvements to the first, and still preeminent, open-source software for modular, high- throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from microscopy images across all disciplines within biology.         PUBLIC HEALTH RELEVANCE: Most laboratories studying biological processes and human disease use microscopy to analyze cells and other samples. We will enable these researchers to rapidly and accurately extract numerical data from microscopy images by continuing to develop and support our popular, user-friendly, open-source image analysis software, CellProfiler (www.cellprofiler.org), to accommodate the increasing scale and scope of modern microscopy experiments.            ",Continued Development of CellProfiler Cell Image Analysis Software,8761195,R01GM089652,"['Address', 'Algorithms', 'Award', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Cell Count', 'Cells', 'Cloud Computing', 'Code', 'Communities', 'Complex', 'Computer Vision Systems', 'Computer software', 'Custom', 'Data', 'Development', 'Discipline', 'Educational process of instructing', 'Educational workshop', 'Environment', 'Explosion', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Leadership', 'Machine Learning', 'Maintenance', 'Measurement', 'Measures', 'Memory', 'Methods', 'Microscope', 'Microscopy', 'Movement', 'Organism', 'Paper', 'Persons', 'Phenotype', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Slide', 'Software Engineering', 'Speed', 'Staining method', 'Stains', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Time', 'Tissue Sample', 'Training', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'bioimaging', 'cellular imaging', 'data mining', 'flexibility', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'novel', 'open source', 'public health relevance', 'research study', 'single molecule', 'tool', 'usability', 'user-friendly', 'web site']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,522488,0.07340805712992504
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8600293,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2014,310129,0.048279612979707065
"ENTROPY-BASED TISSUE DISCRIMINATORS     DESCRIPTION (provided by applicant): The major problem addressed in this proposal is the development and evaluation of an automated noninvasive approach to discriminate different normal and pathological tissue types using machine learning algorithms; previous applications of machine learning have been based on features of the backscattered ultrasound that are essentially energy based. Our approach will be based on extracting features from images whose pixels are determined by the entropy contained in segments of the backscattered ultrasound. The unique attributes of entropy imaging suggest that the automated analysis we propose would be particularly robust for discrimination of deep tissues in a clinical environment.        PUBLIC HEALTH RELEVANCE: All skilled clinical practitioners and interpreters of ultrasound studies realize that much information exists in recorded US images that is processed immediately by the visual cortex and is useful for qualitatively defining pathology, yet defies ready quantification by any robust algorithm. Traditional energy-based representations display grayscale intensities and speckle patterns that have been mapped parametrically into various tissue classification schemes that have yet to demonstrate organ or tissue specificity, although progress has been reported in distinguishing pathologies over the last 30 years. However, the fact that US signal processing and representation of backscatter data in terms of energy functions has not changed over the last 50 years suggests that alternative signal processing schemes may be indicated to represent the richness of the information contained within the backscattered data. To meet this challenge, we have been involved over the past 10 years in processing backscattered RF to create ""information"" images and in designing ""information sensitive"" approaches to classifying the data sets based on statistical analysis of these images These novel and user independent metrics utilize the entropy of windowed segments of radiofrequency (RF) backscatter signal from tis- sue, which represents a radical departure from grayscale or speckle metrics. In this approach the entropy of the backscattered segment is used to produce a pixel value in the tissue image. This processing strategy has proven to be sensitive to weak, sub-resolution sized changes in tissue.            ",ENTROPY-BASED TISSUE DISCRIMINATORS,8737902,R21EB018095,"['Address', 'Algorithms', 'Back', 'Base Composition', 'Bayesian Analysis', 'Cardiac', 'Classification', 'Classification Scheme', 'Clinical', 'Color', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffuse', 'Dimensions', 'Discrimination', 'Disease', 'Ensure', 'Entropy', 'Environment', 'Evaluation', 'Expeditions', 'Fatty Liver', 'Fibrosis', 'Fishes', 'Foundations', 'Fractals', 'Frequencies', 'Heart', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Ischemia', 'Joints', 'Kidney', 'Knowledge', 'Label', 'Liver', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Metric', 'Microscopic', 'Normal tissue morphology', 'Organ', 'Outcome', 'Pathology', 'Pattern', 'Pharmaceutical Preparations', 'Physiological', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Prostate', 'Radio', 'Reporting', 'Resolution', 'Rodent', 'Scheme', 'Shapes', 'Signal Transduction', 'Specificity', 'Staining method', 'Stains', 'Stream', 'Structure', 'Testing', 'Time', 'Tissue Differentiation', 'Tissue Model', 'Tissues', 'Ultrasonic Transducer', 'Ultrasonics', 'Ultrasonography', 'Visual Cortex', 'Work', 'attenuation', 'base', 'data reduction', 'design', 'detector', 'heart motion', 'indexing', 'meetings', 'n-dimensional', 'novel', 'public health relevance', 'radiofrequency', 'signal processing', 'sound', 'tissue processing', 'vector']",NIBIB,WASHINGTON UNIVERSITY,R21,2014,184300,0.0013838296632325117
"GPU COMPUTING RESOURCE TO ENABLE INNOVATION IN IMAGING AND NETWORK BIOLOGY     DESCRIPTION:  Many complex diseases such as cancer, cardiovascular disorders, and schizophrenia may be understood as failures in the functioning of nested hierarchies of biomolecular and cellular networks. These nested hierarchies control a range of processes including the differentiation and migration of cells, remodeling of extracellular matrices and tissues, and information encoding in neuronal subsystems. Washington University has established expertise in cutting edge imaging, molecular biology and genomic technologies synergistic with computational approaches such as machine learning and unraveling the principles of hierarchical organization and dynamics of complex systems. This collective expertise is being leveraged to develop new drugs, improve our ability to interpret sophisticated imaging data, understand how populations of neurons act collectively to accomplish complex tasks, and model the onset and progression of complex diseases as dynamical rewiring of hierarchical, multi-scale networks. Biological network analyses provide a rich set of tools for organizing and interpreting the vast quantities of data produced by state-of-the-art experimental protocols. The rapid advancement of computationally intensive research in these areas is outstripping the capabilities of CPU-based high performance computing (HPC) systems. This application would support the acquisition and integration of a large-scale IBM high performance cluster of Graphics Processor Units (GPUs) to be added as an upgrade to the existing IBM-designed Heterogeneous High Performance Computing environment to form a state-of-the-art hybrid computing capability. Such a resource is essential to match the growing need for high performance computing at Washington University and to support state of the art research software applications that are optimized for GPU computing. The acquisition and integration of a high performance GPU cluster will solve critical computing challenges that exist within Washington University's growing NIH research portfolio. The proposed state-of-the-art hybrid GPU/CPU computing capabilities will be deployed within the framework of a stable, productive and rapidly growing resource center. The addition of high-capacity GPU computing capabilities will allow critical calculation to be performed in hours instead of days and enable substantial increases in productivity for existing projects covering a broad range of application areas as well as enabling new research directions.             n/a",GPU COMPUTING RESOURCE TO ENABLE INNOVATION IN IMAGING AND NETWORK BIOLOGY,8640341,S10OD018091,"['Area', 'Biological', 'Biology', 'Cardiovascular Diseases', 'Complex', 'Computer Systems', 'Computer software', 'Data', 'Disease', 'Environment', 'Extracellular Matrix', 'Failure', 'Genomics', 'High Performance Computing', 'Hour', 'Hybrids', 'Image', 'Machine Learning', 'Malignant Neoplasms', 'Modeling', 'Molecular Biology', 'Neurons', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Process', 'Productivity', 'Protocols documentation', 'Research', 'Resources', 'Schizophrenia', 'System', 'Technology', 'Tissues', 'United States National Institutes of Health', 'Universities', 'Washington', 'base', 'cell motility', 'computing resources', 'design', 'improved', 'innovation', 'tool']",OD,WASHINGTON UNIVERSITY,S10,2014,597700,0.008688218722533614
"Graph-Based Medical Image Segmentation in 3D and 4D     DESCRIPTION (provided by applicant): This is a competitive continuation of our Phase-II project. After successfully fulfilling all of its aims, our framework for optimal multi-surface andor multi-object n-D biomedical image segmentation was further extended, validated, and its practical utility demonstrated in clinical and translational image analysis tasks. This Phase-III proposal will develop several important extensions addressing identified limitations of the current framework and specifically focusing on applicability of the methodology to translational and routine healthcare tasks. Novel methods will be developed for simultaneous segmentation of mutually interacting regions and surfaces, automated design of cost functions from segmentation examples, and overcoming failures of automated techniques in routine diagnostic quality images by allowing limited and highly efficient expert input to guide the image segmentation processes.  We hypothesize that advanced graph-based image segmentation algorithms merging machine- learning-derived segmentation parameters and image-specific expert guidance will significantly increase quantitative analysis performance in routinely acquired complex diagnostic-quality medical images across diverse application areas. We propose to: 1) Develop 3D, 4D, and generally n-D approaches for simultaneous segmentation of mutually interacting regions (objects) and surfaces. 2) Develop methods for data-driven automated design of cost functions used for surface-based, region-based, and surface-and-region-based graph search image segmentation. 3) Develop ""Just-Enough-Interaction"" (JEI) approaches for efficient ""real-time"" medical image segmentation, thus achieving robust clinical applicability of quantitative medical image analysis. 4) Assess performance of all developed methods in translational research settings; determine performance in quantitative medical image analysis and radiation oncology treatment planning workflow. As a result, our project will enable routine quantification and therefore personalized care.         PUBLIC HEALTH RELEVANCE: Phases I and II of this research project multi-surface and/or multi-object n-D biomedical image segmentation and demonstrated its practical utility. This Phase-III proposal will develop important extensions leading to higher flexibility and healthcare utility of the developed methods, facilitating routine use of quantitative medical image analysis i personalized medical care.            ",Graph-Based Medical Image Segmentation in 3D and 4D,8759436,R01EB004640,"['3-Dimensional', 'Address', 'Adopted', 'Affect', 'Age related macular degeneration', 'Algorithms', 'Appearance', 'Area', 'Attention', 'Biomedical Research', 'Breathing', 'Caring', 'Clinical', 'Complex', 'Computational Science', 'Cyst', 'Data', 'Devices', 'Diagnostic', 'Disease', 'Environment', 'Failure', 'Foundations', 'Graph', 'Healthcare', 'Hour', 'Image', 'Image Analysis', 'Intuition', 'Machine Learning', 'Manuals', 'Medical', 'Medical Imaging', 'Medicine', 'Methodology', 'Methods', 'Modification', 'Nodule', 'Organ', 'Outcome', 'Pathology', 'Performance', 'Phase', 'Positioning Attribute', 'Process', 'Publications', 'Radiation Oncology', 'Research', 'Research Project Grants', 'Retinal', 'Slice', 'Solutions', 'Speed', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Translational Research', 'Update', 'attenuation', 'base', 'bioimaging', 'clinical application', 'clinical care', 'clinical practice', 'clinically relevant', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'innovation', 'lung imaging', 'novel', 'public health relevance', 'response', 'treatment planning', 'tumor', 'user-friendly']",NIBIB,UNIVERSITY OF IOWA,R01,2014,395708,0.03874656675671057
"Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular DESCRIPTION (provided by applicant): A career development plan is proposed for Dr. David Mayerich, a computer scientist who is committed to developing an interdisciplinary career in biomedical engineering, with a focus on the collection and analysis of large-scale data sets at sub-micrometer resolution. His graduate research was in the areas of computer visualization and optical imaging, where his work lead to the development of the prototype Knife-Edge Scanning Microscope (KESM). This is the first instrument capable of imaging three-dimensional macro-scale tissue volumes at sub-micrometer resolution while providing a data rate approaching the transfer speed of most modern computer systems.         Since receiving his Ph.D., Dr. Mayerich worked as a postdoctoral fellow at the Beckman Institute for Advanced Science and Technology at the University of Illinois at Urbana-Champaign, where he has worked with biologists and biomedical engineers to develop tools for the segmentation and classification of large data sets. This provided experience in addressing the needs and limitations of the computational tools available to the interdisciplinary community.        The goal of the mentored phase of this proposal is to provide Dr. Mayerich with the opportunity to work as a developer for the FARSIGHT Toolkit. The FARSIGHT Toolkit is an open-source segmentation toolkit that focuses on developing computer vision algorithms specifically tailored to deal with the unique structures found in microscopy data sets. This project is directed by Prof. Badrinath Roysam at the University of Houston, and was awarded first-place in the NIH-sponsored DIADEM Challenge in neuron segmentation. Dr. Mayerich will use his previous experience in biomedical segmentation, GPU-based computing, and efficient data structures to help make the FARSIGHT Toolkit scalable to the terabyte-scale data sets produced using next-generation high-throughput imaging techniques. Dr. Mayerich will receive mentoring in the algorithms and techniques used in the FARSIGHT Toolkit, as well as valuable experience working on a collaborative software development project.         The goal of the independent phase is to use recently developed imaging techniques, along with scalable segmentation algorithms, to construct complete microvascular models of mouse organs. Recent advances in KESM demonstrate that sub-micrometer images of 1cm3 tissue samples can be collected in less than 50 hours. These images have the resolution and quality necessary for (a) complete reconstruction of microvascular networks in whole organs, and (b) the geometric distribution of cell soma in relation to this network. Models describing cellular and microvascular relationships have implications in several diseases, including neurodegenerative disease and tumor growth, as well as clinical applications in tissue engineering and the quantitative analysis of angiogenic drugs and therapies. PROJECT NARRATIVE The goal of this work is to produce high-resolution microvascular models from mouse brain tissue, as well as create algorithms for querying, distributing, and building models from next-generation high-throughput microscopy data sets. These techniques will allow researchers to create large-scale blood flow simulations, simulate the extent of tissue damage due to stroke or aneurism, and explore the relationships between cells and microvessels on a tissue-wide scale. Clinical applications include the quantification of angiogenesis in tumors and tissue implants, and the quantification of neurovascular effects in neurodegenerative disease models.",Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular,8916335,R00LM011390,"['Active Learning', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Atlases', 'Award', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood Vessels', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical Research', 'Collection', 'Commit', 'Communities', 'Complex', 'Computer Systems', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Disease model', 'Doctor of Philosophy', 'Funding', 'Future', 'Goals', 'Hour', 'Illinois', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Institutes', 'Lead', 'Learning', 'Machine Learning', 'Memory', 'Mentors', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Mus', 'Neurodegenerative Disorders', 'Neurons', 'Online Systems', 'Organ', 'Pharmacotherapy', 'Phase', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Simulate', 'Speed', 'Stroke', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Engineering', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'Transgenic Organisms', 'Tumor Angiogenesis', 'Tumor Tissue', 'United States National Institutes of Health', 'Universities', 'Work', 'analytical method', 'angiogenesis', 'base', 'brain tissue', 'career', 'career development', 'clinical application', 'computerized tools', 'design', 'experience', 'imaging Segmentation', 'improved', 'instrument', 'memory process', 'mouse model', 'neuronal cell body', 'next generation', 'open source', 'optical imaging', 'programs', 'prototype', 'reconstruction', 'research study', 'simulation', 'software development', 'success', 'tool', 'tumor growth']",NLM,UNIVERSITY OF HOUSTON,R00,2014,246867,0.012418241986791145
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8668954,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'screening', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2014,1029385,-0.02353623117659017
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8653848,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2014,436094,0.018621653380670476
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8664845,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,214609,0.0199191927571512
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci     DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics.              n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8631080,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2014,250003,0.029778483687918307
"Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus     DESCRIPTION (provided by applicant):  Image evaluation of skeletal muscle biopsies is a procedure essential to research and clinical practice. Although widely used, several major limitations exist with respect to current muscle image morphometric measurement, archiving, visualization, querying, searching, retrieval, and mining procedures: 1) Although traditional morphometric parameters, such as cross-sectional area (CSA) and minimum Feret diameter, etc., serve as critical indicators for assessing muscle function, current measurements are still largely based on manual or semi-automated methods, leading to significant labor costs with large potential inter-observer variability. 2) The current archiving of muscle images is still mainy based on outdated tools such as Excel spreadsheets and computer file folders. Given a new muscle image, it is almost impossible to quickly cross-compare, visualize, query, search, and retrieve previous cases exhibiting similar image contents with comparable morphometric measures, for the purpose of either discovering novel biological co-correlations at benchside, or providing personalized diagnosis and prognosis at bedside. 3) Although a typical muscle image often contains millions of data points (pixels), in clinical practice, doctors often condense this rich information into one or two diagnostic labels and discard the rest. Novel image markers, which are not always apparent through visual inspections or not manually quantifiable, but potentially represent critical diagnostic and prognostic values for precision medicine, have not been rigorously examined. Similarly, in basic science research, only a very limited number of known measures (e.g., CSA) are considered. Some non-traditional measures, such as myofiber shapes that hold the potential to serve as new indicators of muscle functions, are not fully investigated. 4) Current muscle image analysis and searching functions are fairly low throughput. As a frontier research area, Cloud computing can handle big image data in a distributed manner by providing high-throughput computational power. However, its application to muscle images has never been explored. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, bioinformatics image mining, and Cloud computing. The objectives of this proposal are to: 1) Develop the automated morphometric measurement unit, content-based image retrieval (CBIR) unit, and the image archiving and visualization unit. 2) Develop the advanced bioinformatics image mining unit to assist in the rapid discovery and validation of new image markers. 3) Develop the Cloud computing unit to enable big image data processing and searching functions. Disseminate this freely available, Cloud-enabled imaging informatics system to muscle research community.         PUBLIC HEALTH RELEVANCE:  We propose to develop and disseminate an advanced Cloud-enabled imaging informatics tool - MuscleMiner. MuscleMiner will provide a complete suite of tools for automated image morphometric measurements, archiving, visualization, querying, searching, content-based image retrieval, and bioinformatics image mining. The goal of MuscleMiner is to offer a freely available and powerful tool to help all clinician and basic scienc muscle researchers in their daily work. Beyond fast, objective, reproducible, and automated morphometric measurements, the impact of MuscleMiner will be multiplied by laboratories using the CBIR and visualization units (Aim 1), bioinformatics image mining unit (Aim 2), and Cloud-computing unit (Aim 3) to deeply mine and fully utilize the rich information embedded in large collections of muscle images.            ",Development and Dissemination of MuscleMiner: An Imaging Informatics Tool for Mus,8761698,R01AR065479,"['Address', 'Adoption', 'Architecture', 'Archives', 'Area', 'Award', 'Basic Science', 'Big Data', 'Bioinformatics', 'Biological', 'Biopsy', 'Caliber', 'Cells', 'Client', 'Cloud Computing', 'Collection', 'Communities', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Exhibits', 'Fascicle', 'Fiber', 'Goals', 'Health', 'Image', 'Image Analysis', 'Imagery', 'Informatics', 'Institution', 'Interobserver Variability', 'Label', 'Laboratories', 'Lead', 'Licensing', 'Location', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medicine', 'Methods', 'Mining', 'Mus', 'Phase', 'Procedures', 'Process', 'Research', 'Research Personnel', 'Rest', 'Retrieval', 'Shapes', 'Slide', 'Small Business Technology Transfer Research', 'System', 'Technology', 'United States National Institutes of Health', 'Validation', 'Visual', 'Work', 'base', 'bioimaging', 'biomedical informatics', 'clinical practice', 'computerized data processing', 'cost', 'design', 'frontier', 'image archival system', 'image visualization', 'imaging informatics', 'improved', 'indexing', 'novel', 'open source', 'outcome forecast', 'prognostic', 'public health relevance', 'skeletal', 'tool', 'wasting']",NIAMS,UNIVERSITY OF FLORIDA,R01,2014,314327,0.06377465574925842
"Objective decision support environment for clinical trials     DESCRIPTION:  Brain tumors are the second- and fifth-most common cause of cancer death in males and females under 40, respectively. The 5-year relative survival rate is only 33%, even after decades of research into new treatments. Imaging based on ""virtual biopsy"" can provide information about the entire lesion in a minimally or non-invasive way. Prior work by our group has demonstrated that image processing methods applied to serial examinations together (as opposed to applying them to individual examinations) can make subtle changes in brain tumors more apparent, allowing earlier detection of progression. We see the union of virtual biopsy methods and change detection methods as an innovative and powerful combination that our team is uniquely qualified to develop and evaluate. In this application, we will implement several feature selection (FS) methods in a tool that is ""image friendly"". This tool will help select informative features from images; apply a wide range of existing ML algorithms to determine which features are important predictors of therapy response, and to evaluate the impact of a decision support application using these features and ML in a clinical trial. The final stage of th proposal will test the decision support tools in 3 clinical scenarios to see if they are able to significantly improve the decision making of clinicians in a clinical trial.  The long-term goal of this proposal is to develop virtual biopsy technology that will enhance the clinical decision making process by providing tools for investigation of image-based therapy response assessment tools, that may also have some ability to predict outcome. We hope to apply the technology to other organ systems and other imaging technologies. We anticipate this project will impact clinical trials by enabling investigation of alternative outcome measures that are objectively assessed using algorithm evaluation methods. Such a toolset should be useful to the entire cancer imaging community to help evaluate features in old and new imaging technologies that correlate with patient survival. As such, this is ideal for helping the Quantitative Imaging Network (QIN) achieve its goals.           The selection of features that reflect response to therapy has long been the domain of the clinical radiologist. When imaging was relatively straightforward (e.g. a chest X-ray of lung cancer), a measurement or a visual assessment was a reasonable metric. Today, advanced imaging devices produce large amounts of data that reflect a range of properties. In this work, we build on previous work developing computer techniques for identifying and characterizing changes in brain tumors, using MRI. In this proposal, we will focus on building 1) a high quality database of brain cancer imaging, clinical data, ""-omic"" data, outcomes data; 2) a library of easily accessed tools for computing features that might be important predictors of tumor response; 3) a tool that will help objectively establish the feature() that are valuable through a variety of machine learning methods; and 4) use the above to create a decision support tool that will be used in 3 clinical trial situations.  .            ",Objective decision support environment for clinical trials,8711361,U01CA160045,"['Algorithms', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Cancer Etiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collection', 'Communities', 'Computers', 'Data', 'Databases', 'Decision Making', 'Detection', 'Differentiation Therapy', 'Early Diagnosis', 'Environment', 'Evaluation', 'Female', 'Goals', 'Image', 'Imaging Device', 'Imaging technology', 'Individual', 'Investigation', 'Lesion', 'Libraries', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Metric', 'Outcome', 'Outcome Measure', 'Output', 'Pathologic', 'Patients', 'Primary Brain Neoplasms', 'Process', 'Property', 'Qualifying', 'Relative (related person)', 'Research', 'Staging', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Visual', 'Work', 'base', 'body system', 'cancer imaging', 'clinical decision-making', 'image processing', 'improved', 'innovation', 'male', 'radiologist', 'response', 'tool', 'tumor', 'virtual']",NCI,MAYO CLINIC ROCHESTER,U01,2014,503175,-0.019446011741334587
"In-field FAST Procedure Support and Automation     DESCRIPTION (provided by applicant): The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound examination performed to identify intra-peritoneal hemorrhage or pericardial tamponade. FAST involves the detection of free fluid in ultrasound images from four specific abdominal areas. Unstable patients with positive FAST results are operated on, and stable patients with negative results tend to be observed.  We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life-saving FAST procedures. The proposed system will consist of a low-cost ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an intuitive application. Using that system, a novice operator will be visually guided to acquire ultrasound images from the abdominal locations and quantify the free fluid in those images.  The target for our initial deployment of the system is level 3 and 4 trauma centers. These centers must often serve areas spanning hundreds and even thousands of miles; however, they are typically under-staffed and under-equipped.  The proposal is being clinically driven by Jeffrey Lowell, MD. He is a USNR Trauma Surgeon, and he was recently deployed to Landstuhl Regional Medical Center, the only Level I Trauma Center outside the U.S.         PUBLIC HEALTH RELEVANCE: The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound-based examination for rapidly detecting blood in the abdomen, particularly after blunt abdominal trauma, which is common, for example, with car accidents. The challenge is that the FAST procedure requires expertise and equipment which is not commonly available at level 3 and 4 trauma centers that serve rural populations. We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life- saving FAST procedures. The proposed system will consist of a low-cost, hand-held ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an easy-to-follow software application.            ",In-field FAST Procedure Support and Automation,8652454,R43EB016621,"['Abdomen', 'Abdominal Injuries', 'Accidents', 'Address', 'Age', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Blood', 'Businesses', 'Caring', 'Cause of Death', 'Cessation of life', 'Computer Vision Systems', 'Computer software', 'Conduct Clinical Trials', 'Custom', 'Data', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Doctor of Medicine', 'Environment', 'Equipment', 'Evaluation', 'FDA approved', 'Funding', 'Hand', 'Hemoperitoneum', 'Hemorrhage', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imagery', 'Injury', 'Kidney', 'Life', 'Liquid substance', 'Location', 'Medical', 'Medical center', 'Methods', 'Military Personnel', 'Morbidity - disease rate', 'Nurses', 'Operating Rooms', 'Organ Harvestings', 'Organ Procurements', 'Patients', 'Pediatric Hospitals', 'Pelvis', 'Pericardial body location', 'Persons', 'Phase', 'Physical Examination', 'Physics', 'Population', 'Positioning Attribute', 'Procedures', 'Publishing', 'Research', 'Running', 'Rural', 'Rural Population', 'Surgeon', 'System', 'Systems Integration', 'Tablet Computer', 'Tablets', 'Technology', 'Testing', 'Time', 'Training', 'Transplant Surgeon', 'Trauma', 'Ultrasonography', 'Uncompensated Care', 'Universities', 'Washington', 'Work', 'base', 'cost', 'emergency service responder', 'experience', 'follower of religion Jewish', 'health disparity', 'imaging Segmentation', 'innovation', 'medical schools', 'mortality', 'novel', 'pericardial sac', 'prototype', 'public health relevance', 'tool', 'trauma centers']",NIBIB,"KITWARE, INC.",R43,2014,195709,0.01157040926315207
"In vivo Characterization of Stents using Intravascular OCT Imaging     DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel.         PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.",In vivo Characterization of Stents using Intravascular OCT Imaging,8724992,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Geometry', 'Goals', 'Graph', 'Healed', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Simulate', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thrombosis', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'public health relevance', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2014,402534,0.008922973206218869
"CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development     DESCRIPTION (provided by applicant): Background: Dendritic arbor shape and functional properties emerge from the interaction of many complex developmental processes. It is now accepted that multiple local-level interactions of cytoskeleton elements direct the growth and development of the dendrite arbor. However, the specific mechanisms that control developmental acquisition of final functional dendritic properties are largely unknown. Addressing this fundamental question requires novel data driven systems-biology tools to study developmental and biophysical mechanisms in the same neuronal model. A tightly-knit collaboration between molecular genetics, quantitative morphometry, and mathematical simulation can for the first time enable large-scale studies capable of achieving holistic understanding of the mechanisms underlying emergent features of the arbor. Project Goals: The main neuroscientific goal of this project is to understand how multiple local interactions of cytoskeleton components during differentiation define mature dendritic arbor shape and its functional integrative properties, using Drosophila sensory neurons as a model. The technological goal of this project is to develop a novel investigative approach that integrates and extends previously separate approaches from developmental biology & genetics, in vivo confocal imaging & electrophysiology, computer vision, and neuroanatomical modeling. Specific Aims: We propose 3 tightly integrated specific aims. Aim 1: use genetic manipulations and electrophysiological recordings to model the role of cytoskeletal organization and dynamics as a fundamental determinant of emergent dendrite arbor shape and function. Aim 2: Implement advanced 4D multi-parameter imaging protocols and automated algorithms to reconstruct the arbor, and quantify spatial and temporal associations among multiple sub-cellular components. Aim 3: using automated reconstructions & measurements from aim 2, statistically characterize the structural and cytoskeletal features of dendrite arbors, and stochastically simulate the growth and electrotonic properties of anatomically realistic virtual neuronal analogues. The data from aim 3 will feed back novel hypotheses to be tested by a subsequent repetition of the (aim 1 - aim 2 - aim 3) cycle. Approach: We will focus on a single model system - Drosophila dendritic arborization (da) sensory neurons. More specifically, we will investigate class I and class IV da neuron arborization based upon their radically distinct dendritic morphologies (simple vs. complex) and underlying cytoskeletal organizations. We will make fusion constructs of cytoskeleton components with spectrally distinct fluorescent proteins. These will be used in transgenic Drosophila in order to quantitatively measure the distribution of F-actin, microtubules, and microtubule polarity within the dendrite arbor throughout its development in vivo using confocal multi-fluor imaging. The resulting images will be processed by automated quantitative computer vision algorithms that will accurately extract the topology of the dendritic arbor, and it changes over time. We will use the resulting maps in neuroanatomical stochastic simulations to establish the links between the emergent morphometrics of the dendrite and specific cytoskeleton features at various developmental stages. Intellectual Merit: From a neurogenetics perspective, this project will pioneer the use of cytoskeletal features as putative fundamental determinants in statistical neuroanatomical models. These determinants will be linked to morphological determinants. From a computational perspective, this project will advance the state of the art in automated algorithms for delineating neuroanatomy (and its morphological dynamics) by deploying core technologies for large-scale multi-parameter studies, and result in an effective interfacing of automated reconstruction and simulation technologies. With this innovation, model predictions can be tested by molecular biological techniques, and findings of statistical models can be used to inform molecular models of dendrite arbor development. Educational Impact: This project will result in a cross-disciplinary training of post-doctoral fellows, graduate students, undergraduate students and high school interns. It will result in practical insight on ways to conduct cutting-edge systems-level scientific research overcoming disciplinary boundaries and using best-available collaborative tools. The trainees from this program will be uniquely positioned to develop the broader field of imaging-driven integrative systems neurobiology. It will expose minority and K-12 students to a new world of trans-disciplinary research that is indicative of the future. Broader Impacts: The combined body of molecular, imaging, and computational tools and datasets from this research will be disseminated widely, and made available to a broad class of investigators for adoption in the study of other major neuroscience problems. This project will serve as a new model for computationally enabled neuroscience research that achieves a long-desired synergy between the wet lab and computation.             n/a",CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development,8697162,R01NS086082,"['Address', 'Adoption', 'Affect', 'Afferent Neurons', 'Algorithms', 'Anatomic Models', 'Back', 'Biological', 'Biological Models', 'Biophysical Process', 'Characteristics', 'Coal', 'Collaborations', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Data Set', 'Dendrites', 'Development', 'Developmental Biology', 'Developmental Process', 'Discipline', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Elements', 'F-Actin', 'Future', 'Goals', 'Growth', 'Growth and Development function', 'Image', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Minority', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Models', 'Morphology', 'Nervous system structure', 'Neurites', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Role', 'Series', 'Shapes', 'Signal Transduction', 'Simulate', 'Staging', 'Statistical Models', 'Structure', 'Students', 'Synapses', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Transgenic Organisms', 'Trees', 'analog', 'base', 'computerized tools', 'data sharing', 'developmental genetics', 'developmental neurobiology', 'digital', 'feeding', 'genetic manipulation', 'graduate student', 'high school', 'in vivo', 'innovation', 'insight', 'molecular imaging', 'molecular modeling', 'morphometry', 'neurogenetics', 'next generation', 'novel', 'open source', 'post-doctoral training', 'programs', 'reconstruction', 'relating to nervous system', 'research study', 'role model', 'simulation', 'tool', 'undergraduate student', 'virtual']",NINDS,GEORGIA STATE UNIVERSITY,R01,2014,333533,-0.003216859685262052
"Statistical methods for large and complex databases of ultra-high-dimensional     DESCRIPTION: Medical imaging is a cornerstone of basic science and clinical practice. To discover new mechanisms and markers of disease and their crucial implications for clinical practice, large multi-center imaging studies are acquiring terabytes of complex multi-modality imaging data cross-sectionally and longitudinally over decades. The statistical analysis of data from such studies is challenging due to the complex structure of the imaging data acquired and the ultra-high dimensionality. Furthermore, the heterogeneity of anatomy, pathology, and imaging protocols causes instability and failure of many current state-of-the-art image analysis methods. This grant proposes statistical frameworks for studying populations through biomedical imaging, scalable and robust methods for the identification and accurate quantification of pathology, and analytic tools for the cross-sectional and longitudinal examination of etiology and disease progression. These techniques will be applied to address key goals of the motivating large and multi- center studies of multiple sclerosis and Alzheimer's disease conducted at Johns Hopkins Hospital, the National Institute of Neurological Disorders and Stroke, and across the globe. The project will create methods for uncovering and quantifying brain lesion pathology, incidence, and trajectory. Methods developed under this grant will be targeted towards these neuroimaging goals, but will form the basis for statistical image analysis methods applicable broadly in the biomedical sciences.         PUBLIC HEALTH RELEVANCE: This project involves the development of statistical frameworks and methods for the analysis of complex ultra-high-dimensional biomedical imaging. Methods developed are applied to study the clinical management and etiology of multiple sclerosis and Alzheimer's disease longitudinally and cross-sectionally.                ",Statistical methods for large and complex databases of ultra-high-dimensional,8738735,R01NS085211,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Applications Grants', 'Area', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Brain', 'Brain Pathology', 'Brain imaging', 'Clinical Management', 'Complex', 'Computer software', 'Computing Methodologies', 'Contrast Media', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease Marker', 'Disease Progression', 'Etiology', 'Failure', 'Goals', 'Grant', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Journals', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Pathology', 'Population Study', 'Positioning Attribute', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Site', 'Solutions', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Visualization software', 'Work', 'base', 'bioimaging', 'clinical practice', 'design', 'falls', 'imaging Segmentation', 'imaging modality', 'member', 'neuroimaging', 'next generation', 'open source', 'public health relevance', 'skills', 'tool', 'white matter']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2014,343683,0.02416990271319141
"Quantitative Image Analysis Techniques for Optic Nerve Disease  PROJECT SUMMARY/ABSTRACT  Disorders of the optic nerve (ON) account for a significant percentage of the 20 most impactful ophthalmological conditions. Collectively, diseases of the ON are the number one cause of irreversible blindness worldwide, and present serious public health concerns in the U.S. Consider, for example, that glaucoma impacts more than three million Ameri- cans and costs the U.S. economy almost $3 billion per year. Optic neuritis (i.e., inflammatory demyelination of the ON) is the initial symptom in ~25% of all multiple sclerosis (MS) cases (which impacts over 400 thousand Americans and intro- duces societal health care costs of nearly $30 billion per year). Nearly two thirds of MS patients will experience episodes of optic neuritis in their lifetimes, and 40-60% of patients have visual defects localized to the ON. These disorders irre- versibly damage the ON. Even so, damage to axons in the ON is progressive, defined by a window of opportunity for treatment between loss of function and actual degeneration. The potential for recovery exists because there are treatments that can help prevent progression if administered during this window of opportunity. Yet, we do not have effective means to assess who is in the window and who will benefit from treatment.  We propose to translate computational imaging methods from the neuroimaging community to provide ro- bust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. These efforts will improve prognostic accuracy, lead to better understanding of patient responses, and enhance targeted interven- tions. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not.  The overall goal of this research is to provide a foundation for image analysis of the ON and its relationships with pathological disorders. We will build upon recent advances in robust medical image computing to segment the ON in clinical CT and MRI acquisitions, develop registration procedures to establish intra- and inter-subject correspondence, and bring together information from the multi-modal battery of imaging studies that are typically used in clinical care (aim 1). With these new methods, we will address the exploratory hypothesis that quantitative use of clinical imaging data can increase prognostic accuracy (aim 2). We note that aim 2 is particularly exploratory and in line with the high- risk/high-reward aspect of this mechanism; many studies have shown that baseline imaging does not conclusively pre- dict long term outcome or treatment response. We hypothesize that this may be because early findings are related to edema and inflammation rather than cellular damage per se. Once this exploratory phase is complete, we will pursue promising prognostic biomarkers using more detailed condition staging criteria and including more than two longitudinal time points in the analysis. Ultimately, these efforts will improve assessment ON disease and, in turn, patient care. PUBLIC HEALTH RELEVANCE:  We propose to translate medical imaging computing procedures from the neuroimaging community to provide robust, quantitative tools for assessing the optic nerve (ON) on clinical and research imaging sequences. The technical hypothesis of this work is that quantitative image processing can robustly and accurately segment, register, and fuse ON data from modern MRI and CT clinical sequences. The central hypothesis of this proposal is that qualitative ON phenotypes on longitudinal clinical imaging will differentiate individuals who respond to treatment versus those who do not more effectively than traditional pre-interventional measures.                ",Quantitative Image Analysis Techniques for Optic Nerve Disease,8620598,R21EY024036,"['Accounting', 'Acute', 'Address', 'Adrenal Cortex Hormones', 'Affect', 'Aftercare', 'Age', 'Algorithms', 'American', 'Area', 'Axon', 'Biological Markers', 'Blindness', 'Brain', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Clinical assessments', 'Communities', 'Data', 'Defect', 'Demyelinations', 'Diagnostic', 'Disease', 'Edema', 'Eye', 'Foundations', 'Gap Junctions', 'Glaucoma', 'Goals', 'Health Care Costs', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Inflammatory', 'Interferons', 'Intervention', 'Intracranial Hypertension', 'Lead', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Measures', 'Medical Imaging', 'Methods', 'Metric', 'Modality', 'Multiple Sclerosis', 'Myelin', 'Nerve Tissue', 'Neurologic', 'Nutritional', 'Operative Surgical Procedures', 'Optic Disk', 'Optic Nerve', 'Optic Nerve Injuries', 'Optic Neuritis', 'Outcome', 'Patient Care', 'Patients', 'Phase', 'Phenotype', 'Procedures', 'Prognostic Marker', 'Property', 'Protective Agents', 'Public Health', 'Publishing', 'Recovery', 'Recurrence', 'Relapse', 'Research', 'Resource Sharing', 'Resources', 'Scanning', 'Sclerosis', 'Shapes', 'Signal Transduction', 'Source', 'Staging', 'Swelling', 'Symptoms', 'Tars', 'Techniques', 'Thyroid Diseases', 'Time', 'Training', 'Translating', 'Treatment outcome', 'Tweens', 'Validation', 'Visual', 'Work', 'X-Ray Computed Tomography', 'base', 'clinical care', 'clinical practice', 'computerized tools', 'cost', 'direct application', 'experience', 'high reward', 'high risk', 'image processing', 'imaging modality', 'improved', 'innovation', 'loss of function', 'nerve decompression', 'neuroimaging', 'optic nerve disorder', 'outcome forecast', 'pressure', 'prevent', 'prognostic', 'public health relevance', 'response', 'standard of care', 'success', 'thyroid associated ophthalmopathies', 'tool', 'treatment response', 'vector']",NEI,VANDERBILT UNIVERSITY,R21,2014,225089,-0.009430852985334507
"Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation DESCRIPTION (provided by applicant): Multi-atlas label fusion (MALF) is a powerful new technology that can automatically detect and label anatomical structures in biomedical images. It is arguably the most successful general-purpose automatic image segmentation technique ever developed. Automatic segmentation is in high demand in clinical and research applications of medical imaging, since segmentation forms a crucial step towards extracting quantitative information from imaging data, and since manual and semi-automatic approaches are ill suited for today's increasingly large and complex imaging datasets. Despite a number of papers that demonstrated outstanding performance of MALF methods across a range of biomedical imaging applications, the broader biomedical imaging research community has been slow to adopt this technique. This can be explained by multiple factors, including the technique's high computational demands, lack of a turnkey software implementation, as well as scarcity of validation in clinical imaging datasets and in the presence of extensive pathology. The present application seeks to remove these barriers and to enable a broad range of clinicians and biomedical researchers to take advantage of MALF technology. It builds on our strong track record of innovation in the MALF field, including a novel redundancy-correcting MALF technique that led in segmentation grand challenges in the past two years. Aim 1 seeks to improve the computational performance of MALF by replacing dense deformable image registration, by far the most time consuming component of MALF, with faster and less constrained sparse registration strategies. We hypothesize that this will not only reduce the computational cost of MALF, but will also make it more robust to anatomical variability, in particular enabling its use for tumor and lesion segmentation. Aim 2 proposes algorithmic extensions to MALF that support automatic segmentation of dynamic and multi-modality imaging datasets, which have been largely overlooked in the MALF literature. Aim 3 will develop a turnkey open-source implementation of MALF methodology. Taking advantage of cloud computing technology, this software will allow users with minimal image processing expertise to take full advantage of MALF segmentation on their desktop. Aim 3 will also provide a set of publicly available atlases and the means for users to build new custom atlas sets from their own data. Aim 4 will perform extensive evaluation of the new methods and software in challenging real-world clinical imaging data, including brain and cardiac imaging. As part of this evaluation, we will quantify how well our MALF approach and competing techniques generalize to novel imaging datasets with heterogeneity in acquisition parameters and clinical phenotypes. PUBLIC HEALTH RELEVANCE: This research will make it possible for a wide community of researchers who collect and analyze medical imaging data to take advantage of a new class of computer algorithms that very accurately label and measure anatomical structures and pathological formations in medical images. By offering more accurate image-derived measurements, the project promises to improve the accuracy of diagnosis, reduce the costs of biomedical re- search studies and pharmaceutical trials, and accelerate scientific discovery.",Adaptive Large-Scale Framework for Automatic Biomedical Image Segmentation,8761531,R01EB017255,"['Address', 'Adopted', 'Affect', 'Algorithms', 'Atlases', 'Biomedical Research', 'Brain', 'Build-it', 'Cardiac', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cloud Computing', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Consensus', 'Custom', 'Data', 'Data Set', 'Dementia', 'Diagnostic', 'Evaluation', 'Gold', 'Health', 'Heterogeneity', 'High Performance Computing', 'Hippocampus (Brain)', 'Image', 'Image Analysis', 'International', 'Joints', 'Label', 'Lead', 'Learning', 'Lesion', 'Literature', 'Magnetic Resonance Imaging', 'Manuals', 'Measurement', 'Measures', 'Medial', 'Medical Imaging', 'Medical Research', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Multiple Sclerosis Lesions', 'Myocardium', 'Paper', 'Pathology', 'Patient Care', 'Performance', 'Pharmacologic Substance', 'Public Domains', 'Research', 'Research Infrastructure', 'Research Personnel', 'S-nitro-N-acetylpenicillamine', 'Scheme', 'Services', 'Structure', 'Techniques', 'Technology', 'Temporal Lobe', 'Temporal Lobe Epilepsy', 'Time', 'Training', 'Ultrasonography', 'Uncertainty', 'Validation', 'Work', 'aortic valve', 'base', 'bioimaging', 'clinical application', 'clinical phenotype', 'clinical practice', 'cloud based', 'cohort', 'cost', 'diagnostic accuracy', 'experience', 'image processing', 'image registration', 'imaging Segmentation', 'imaging modality', 'improved', 'innovation', 'interest', 'new technology', 'novel', 'open source', 'outreach', 'research study', 'success', 'tool', 'tumor']",NIBIB,UNIVERSITY OF PENNSYLVANIA,R01,2014,611476,0.05150572568071851
"Multimodal image registration by proxy image synthesis     DESCRIPTION (provided by applicant): Image registration is a fundamentally important capability in modern neuroscience and clinical medicine. Normalization in functional imaging studies, studies of shape changes in growth, aging, and disease, overlaying surgical plans on intraoperative images, and geometric distortion correction are examples of important applications of image registration. There are dozens of needs for registration in both intrasubject and intersubject applications as well. Therefore, any improvement in image registration performance will have an immediate impact on the scientific and clinical communities. Despite numerous advances in image reconstruction algorithms, the use of multiple modalities (or tissue contrasts) to carry out image registration is a virtually untapped area. The vastly dominant framework is to register a single image of the subject to another single image of the target, and if multiple images are available of either subject or target, they are registered by using the transformation derived from the single image registration. The proposed research will develop, evaluate, and validate a very simply explained but quite radical idea for multi-modal registration. The basic idea is to synthesize a ""proxy"" image from the subject image that has the same tissue contrast and intensity range as the target image and then use a conventional metric such as sum-of-square difference to carry out the registration between the subject proxy and target. Preliminary results demonstrate significant benefits in this approach. In the grant we will: 1) Optimize ""proxy"" multimodal image registration by exploring its theoretical justification as well a key parameters of the overall approach; 2) Apply ""proxy"" multimodal image registration to three key applications in neuroscience in order to validate the method and develop principles of best practice; and 3) Write open source software to carry out image synthesis, similarity computation, and rigid and deformable registration using the ""proxy"" image concept. Both the software to synthesize images for use in a user's favorite image registration method as well as software to carry out the entire ""proxy"" registration process in an optimized way will be made publicly available as open source computer code. The results of this research will lead to a new era in image registration by changing the way researchers and practitioners acquire and use data for neuroscientific studies and clinical medicine.         PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8737899,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Geometry', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2014,335356,0.06604082032739456
"Computational Image Analysis for Cellular and Developmental Biology     DESCRIPTION (provided by applicant): This proposal requests support for an intensive ten-day course on Computational Image Analysis for Cellular and Developmental Biology. The course is designed for graduate students and postdoctoral fellows, and takes place at the Marine Biological Laboratory in Woods Hole, MA. The course is the first of its kind, giving students formal training in computer vision for the specific analysis of cell and developmental biology image data. Building strong foundations in this topic is critical for pushing cell and developmental biology forward, as imaging has become more and more an indispensable tool in these fields. The course covers the fundamentals of computer vision, taking the students through the sequence of low-, intermediate-, and high-level computer vision tasks that are required to solve image analysis problems in quantitative cellular and developmental biology. The curriculum starts with filtering, thresholding and edge/line/generic feature detection, followed by more sophisticated detection algorithms that employ model fitting. After this introductory block to low-level computer vision tasks, the course moves on to intermediate and higher-level tasks, including object association in space and time (such as tracking) and machine learning tools for phenotype classification. Each topic is covered first by a lecture, generally taught by one of the four core faculty, followed by a 3-4 hour computer programming session where students immediately implement the concepts they learn. There are usually two lectures + computer labs per day. Most programming exercises are individual, giving each student the opportunity to ""get their hands dirty,"" while two are team projects allowing the students to also learn and practice methods of code sharing. Over the course's ten days there are three guest lectures by leading researchers in the fields of biological imaging and computer vision, each followed by in-depth discussion, as well as research talks given by the students, faculty and teaching assistants. With this, the core lectures and labs teach the students the fundamentals of computer vision in a logical, continuous manner, the guest lecturers introduce the students to exciting new challenges in imaging and image analysis, and the student/faculty research talks encourage communication between all course participants and give especially the students the opportunity to reflect on how the course can help them with their research. !         PUBLIC HEALTH RELEVANCE:  Imaging has become an indispensable tool in cellular and developmental biology research, but without rigorous, quantitative image analysis it cannot achieve its full potential. This proposal requests support for a new course that will fill the voidof education in computer vision as applied to cellular and developmental biology. The curriculum incorporates a carefully balanced mixture of lectures and associated programming exercises. We have given a pilot course once in October 2010, with very positive reviews from the students and their advisers.             ",Computational Image Analysis for Cellular and Developmental Biology,8414506,R25GM103792,"['Address', 'Algorithms', 'Biological', 'Cellular biology', 'Classification', 'Code', 'Collection', 'Communication', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Data', 'Detection', 'Development', 'Developmental Biology', 'Developmental Cell Biology', 'Education', 'Educational Curriculum', 'Educational process of instructing', 'Equilibrium', 'Exercise', 'Faculty', 'Foundations', 'Future', 'Generic Drugs', 'Goals', 'Hand', 'Home environment', 'Hour', 'Image', 'Image Analysis', 'Individual', 'Knowledge', 'Laboratories', 'Learning', 'Machine Learning', 'Marines', 'Methodology', 'Methods', 'Modeling', 'Participant', 'Phenotype', 'Postdoctoral Fellow', 'Request for Proposals', 'Research', 'Research Personnel', 'Seeds', 'Software Design', 'Solid', 'Students', 'Time', 'Training', 'Wood material', 'computer program', 'design', 'graduate student', 'lecturer', 'lectures', 'programs', 'public health relevance', 'tool']",NIGMS,MARINE BIOLOGICAL LABORATORY,R25,2013,59383,0.004646304225760531
"Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi     DESCRIPTION (provided by applicant): It is well established that aging and many chronic diseases, such as cancer and heart failure, are associated with significant losses in skeletal muscle mass and strength in humans. There is agreement across the muscle biology community that important morphological characteristics of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health and function of the muscle. However, at this time, quantification of muscle characteristics from standard histological and immunohistological techniques is still a manual or, at best, a semi-automatic process. This process is labor intensive and can be prone to errors, leading to high inter-observer variability. On the other hand, when muscle characteristics are calculated by computer-aided image analysis, data acquisition times decrease and objectivity improves significantly. The objective of this Phase I STTR project is to build a fully automatic, intelligent, and high throughput image acquisition and analysis software for quantitative muscle morphological analysis on digitized muscle cross-sections. We propose to utilize the most recent technical advances in machine learning and biomedical image analysis. This includes a newly developed deformable model and mean-shift based seed detection algorithm for better segmentation accuracy; an asymmetric online boosting based machine learning algorithm which allows the software to learn from errors and adjust its segmentation strategies adaptively; and a data parallelization schema using the graphic processing unit (GPU) to handle the computational bottleneck for extremely large scale image, such as whole slide scanned specimens. We believe that this software, equipped with the most advanced technical innovations, will be commercially attractive for the skeletal muscle research community including basic scientists, clinician scientists, and the pharmaceutical industry. The specific aim are: 1) Develop, implement, and validate an automatic biological image analysis software package for skeletal muscle tissue; 2) Develop a novel online updated intelligent artificial intelligence unit to enable the software to learn from errors; 3) Build a novel high performance computing unit to enable fast and high throughput automatic image analysis, which is capable of processing whole slide scanned muscle specimens. The analysis approach proposed will provide more consistent, accurate, and objective quantification of skeletal muscle morphological properties and the time for data analysis will be reduced by over a factor of 100 for standalone version and 2000 for parallel version. The long-term goal of Cytoinformatics, LLC for the Phase II stage is to apply the software to analyze histology/pathology from human muscle biopsy samples and extension of the software to other biological tissues, such as adipose tissue.         PUBLIC HEALTH RELEVANCE: Important features of muscle fibers, such as fiber area, the number and position of myonuclei, cellular infiltration and fibrosis are critical factors that determine the health of the muscle. However quantification of muscle features from digitized images is still a manual or, at best, a semi-automatic process. The objective of this Phase I STTR project is to build software using the most recent technical advances in machine learning and biomedical image analyses to significantly move the skeletal muscle basic and clinical research fields ahead.            ",Intelligent and Automatic Image Segmentation Software for High ThroughputAnalysi,8522756,R41AR064596,"['Adipose tissue', 'Aging', 'Agreement', 'Algorithms', 'Appearance', 'Area', 'Artificial Intelligence', 'Basic Science', 'Biological', 'Biology', 'Biometry', 'Biopsy Specimen', 'Cell Nucleus', 'Cellular Infiltration', 'Characteristics', 'Chronic Disease', 'Clinical Research', 'Communities', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Data Analyses', 'Defect', 'Detection', 'Drug Industry', 'Eosine Yellowish', 'Exhibits', 'Fiber', 'Fibrosis', 'Freezing', 'Future', 'Goals', 'Health', 'Heart failure', 'Hematoxylin', 'High Performance Computing', 'Histology', 'Human', 'Human Pathology', 'Image', 'Image Analysis', 'Interobserver Variability', 'Intervention', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Marketing', 'Methods', 'Modeling', 'Morphologic artifacts', 'Muscle', 'Muscle Fibers', 'Muscle function', 'NIH Program Announcements', 'Performance', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Process', 'Property', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Seeds', 'Shapes', 'Site', 'Skeletal Muscle', 'Slide', 'Small Business Technology Transfer Research', 'Specimen', 'Speed', 'Staging', 'Staining method', 'Stains', 'Techniques', 'Technology', 'Time', 'Tissues', 'United States National Institutes of Health', 'Update', 'Yang', 'base', 'bioimaging', 'biomedical informatics', 'cohort', 'computer science', 'data acquisition', 'design', 'fluorescence imaging', 'imaging Segmentation', 'improved', 'innovation', 'muscle form', 'muscle strength', 'novel', 'public health relevance']",NIAMS,"CYTOINFORMATICS, LLC",R41,2013,150000,0.06167984198149524
"Automated retinopathy of prematurity classification using machine learning  Project Summary/Abstract The goal of this project is to develop a web-based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease,"" using an existing data set of retinal images collected from previous NIH- funded research studies. ROP is treatable if diagnosed early, yet continues to be a leading cause of childhood blindness throughout the world. Diagnosis and documentation of ophthalmoscopic findings in ROP are subjective and qualitative, and studies have found that there is often significant diagnostic variation, even when experts are shown the exact same clinical data. Computer-based image analysis and the application of machine learning techniques to feature extraction and image classification have potential to address many of these limitations. Recent advances in image processing have had led to sophisticated techniques for tracing vessel-like structures. Additionally, machine-learning techniques will enable us to leverage these existing annotated image databases to improve the performance of our algorithms for vessel segmentation and disease classification. Our overall hypothesis is that retinal vascular features may be quantified and used to assist clinicians in the diagnosis of ROP. These hypotheses will be tested using two Specific Aims: (1) Develop and evaluate semi-automated algorithms to segment retinal vessels and generate a set of retinal vessel-based features. (2) Develop computer-based decision support algorithms that best correlate with expert opinions. Overall, this project will build upon infrastructure developed from previous studies, create potential for improving the accuracy and consistency of clinical ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP. This project will be performed by a multi- disciplinary team of investigators with expertise in ophthalmology, biomedical informatics, computer science, machine learning, and image processing. PUBLIC HEALTH RELEVANCE:  Retinopathy of prematurity (ROP) is a leading cause of childhood blindness in the United States and throughout the world, and current diagnostic and documentation methods are often subjective and qualitative. We propose to use existing data sets to develop a web- based, semi-automated system for identifying severe retinopathy of prematurity (ROP) with ""plus disease"" from retinal images. This has potential to improve the accuracy and consistency of ROP diagnosis, provide a demonstration of computer-based decision support from image analysis during real-world medical care, and stimulate future research toward understanding the vascular features associated with severe ROP.                 ",Automated retinopathy of prematurity classification using machine learning,8445584,R21EY022387,"['Address', 'Algorithms', 'Blindness', 'Blood Vessels', 'Caring', 'Characteristics', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Complement', 'Computers', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Progression', 'Documentation', 'Early Diagnosis', 'Evaluation', 'Expert Opinion', 'Funding', 'Goals', 'Human', 'Image', 'Image Analysis', 'Infant', 'Machine Learning', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Neonatal Intensive Care Units', 'Online Systems', 'Ophthalmologist', 'Ophthalmology', 'Performance', 'Pilot Projects', 'Premature Infant', 'Process', 'Public Health', 'Reading', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Retinal', 'Retinal Diseases', 'Retinopathy of Prematurity', 'Structure', 'System', 'Techniques', 'Telemedicine', 'Testing', 'Time', 'Training', 'Travel', 'Tubular formation', 'United States', 'United States National Institutes of Health', 'Variant', 'base', 'bioimaging', 'biomedical informatics', 'clinical care', 'clinical decision-making', 'clinically significant', 'computer science', 'design', 'disease classification', 'disorder risk', 'experience', 'image processing', 'improved', 'public health relevance', 'research study', 'retina blood vessel structure', 'two-dimensional']",NEI,MASSACHUSETTS GENERAL HOSPITAL,R21,2013,283543,0.011389732058564533
"Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications     DESCRIPTION (provided by applicant): Abstract In this small business innovations research (SBIR) project, we present aiArt: Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine applications. aiArt (pronounced eye-art), with its automated image analysis tools and user-friendly telemedicine web-interface, will enable exponential expansion of diabetic retinopathy screenings, thus fulfilling a significant health need as the number of people with diabetes climbs over the years. Latino population is genetically more prone to diabetes. Factors such as lack of awareness, lack of insurance coverage, and lack of access to expert clinicians greatly increase this disparity population's vulnerability to blindness due to DR. The situation is particularly grim in Los Angeles County, where there is a backlog of several thousand patients waiting to see an ophthalmologist, causing very long appointment wait times (often over six months). To help reduce risk of vision loss in this population, we propose to use advanced image analysis algorithms in conjunction with existing telemedicine initiatives to enable faster screening, allow reprioritization of ophthalmologist appointments, and to provide patient education tools. Our automated image analysis algorithms represent cutting-edge of research in image processing, computer vision, and machine learning. The analysis engine will be closely integrated with simple, easy-to-use web-based telemedicine infrastructure provided by an existing, popular, telemedicine initiative, EyePACS.         PUBLIC HEALTH RELEVANCE: Narrative The proposed image analysis tools will greatly reduce the cost of diabetic retinopathy screening, and with its web and mobile phone accessible interface will drive an expansion of diabetic retinopathy screening, making it accessible to disparity populations (such as Latinos) which are not currently being screened due to socio-economic factors. The proposed tools will also enable quick turnaround time for screening, thus further helping prevent blindness due to diabetes complications.            ",Advanced Image Analysis Tools for Diabetic Retinopathy Telemedicine Applications,8466969,R43EB013585,"['Address', 'Agreement', 'Algorithms', 'Appointment', 'Architecture', 'Area', 'Arts', 'Awareness', 'Blindness', 'California', 'Car Phone', 'Clinic', 'Clinical', 'Code', 'Complications of Diabetes Mellitus', 'Computer Vision Systems', 'Computer software', 'Consult', 'County', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Dictionary', 'Disadvantaged', 'Economic Factors', 'Ensure', 'Exudate', 'Eye', 'Faculty', 'Feedback', 'Goals', 'Gold', 'Health', 'Healthcare', 'Hemorrhage', 'Hispanics', 'Human', 'Image', 'Image Analysis', 'Incidence', 'Institutes', 'Insurance Coverage', 'Internet', 'Joints', 'Latino', 'Lesion', 'Localized Lesion', 'Location', 'Los Angeles', 'Machine Learning', 'Measures', 'Medical center', 'Microaneurysm', 'Online Systems', 'Ophthalmologist', 'Optometry', 'Patient Education', 'Patients', 'Phase', 'Plug-in', 'Population', 'Populations at Risk', 'Primary Health Care', 'Principal Investigator', 'Process', 'ROC Curve', 'Reading', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Retinal Diseases', 'Risk', 'Rural', 'Rural Health', 'Sensitivity and Specificity', 'Severities', 'Side', 'Small Business Innovation Research Grant', 'Software Design', 'Software Engineering', 'Software Tools', 'Statistical Computing', 'System', 'Telemedicine', 'Testing', 'Time', 'Universities', 'Work', 'abstracting', 'base', 'bioimaging', 'computerized data processing', 'cost', 'cotton wool spots', 'diabetes risk', 'experience', 'image processing', 'neovascularization', 'prevent', 'prototype', 'public health relevance', 'screening', 'socioeconomics', 'success', 'tool', 'tv watching', 'user-friendly', 'web interface']",NIBIB,"EYENUK, INC.",R43,2013,1,-0.023673209576596493
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.       PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8402395,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Targeting', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'screening', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,301051,0.048279612979707065
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8522304,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2013,216041,0.018695566067959184
"Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular     DESCRIPTION (provided by applicant): A career development plan is proposed for Dr. David Mayerich, a computer scientist who is committed to developing an interdisciplinary career in biomedical engineering, with a focus on the collection and analysis of large-scale data sets at sub-micrometer resolution. His graduate research was in the areas of computer visualization and optical imaging, where his work lead to the development of the prototype Knife-Edge Scanning Microscope (KESM). This is the first instrument capable of imaging three-dimensional macro-scale tissue volumes at sub-micrometer resolution while providing a data rate approaching the transfer speed of most modern computer systems.         Since receiving his Ph.D., Dr. Mayerich worked as a postdoctoral fellow at the Beckman Institute for Advanced Science and Technology at the University of Illinois at Urbana-Champaign, where he has worked with biologists and biomedical engineers to develop tools for the segmentation and classification of large data sets. This provided experience in addressing the needs and limitations of the computational tools available to the interdisciplinary community.        The goal of the mentored phase of this proposal is to provide Dr. Mayerich with the opportunity to work as a developer for the FARSIGHT Toolkit. The FARSIGHT Toolkit is an open-source segmentation toolkit that focuses on developing computer vision algorithms specifically tailored to deal with the unique structures found in microscopy data sets. This project is directed by Prof. Badrinath Roysam at the University of Houston, and was awarded first-place in the NIH-sponsored DIADEM Challenge in neuron segmentation. Dr. Mayerich will use his previous experience in biomedical segmentation, GPU-based computing, and efficient data structures to help make the FARSIGHT Toolkit scalable to the terabyte-scale data sets produced using next-generation high-throughput imaging techniques. Dr. Mayerich will receive mentoring in the algorithms and techniques used in the FARSIGHT Toolkit, as well as valuable experience working on a collaborative software development project.         The goal of the independent phase is to use recently developed imaging techniques, along with scalable segmentation algorithms, to construct complete microvascular models of mouse organs. Recent advances in KESM demonstrate that sub-micrometer images of 1cm3 tissue samples can be collected in less than 50 hours. These images have the resolution and quality necessary for (a) complete reconstruction of microvascular networks in whole organs, and (b) the geometric distribution of cell soma in relation to this network. Models describing cellular and microvascular relationships have implications in several diseases, including neurodegenerative disease and tumor growth, as well as clinical applications in tissue engineering and the quantitative analysis of angiogenic drugs and therapies.                  PROJECT NARRATIVE The goal of this work is to produce high-resolution microvascular models from mouse brain tissue, as well as create algorithms for querying, distributing, and building models from next-generation high-throughput microscopy data sets. These techniques will allow researchers to create large-scale blood flow simulations, simulate the extent of tissue damage due to stroke or aneurism, and explore the relationships between cells and microvessels on a tissue-wide scale. Clinical applications include the quantification of angiogenesis in tumors and tissue implants, and the quantification of neurovascular effects in neurodegenerative disease models.",Large-Scale Reconstruction of Microvascular Networks and the Surrounding Cellular,8508596,K99LM011390,"['Active Learning', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Atlases', 'Award', 'Biological Neural Networks', 'Biomedical Engineering', 'Blood Vessels', 'Blood flow', 'Brain', 'Cell Nucleus', 'Cells', 'Classification', 'Clinical Research', 'Collection', 'Commit', 'Communities', 'Complex', 'Computer Systems', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Disease model', 'Doctor of Philosophy', 'Funding', 'Future', 'Goals', 'Hour', 'Illinois', 'Image', 'Imagery', 'Imaging Techniques', 'Implant', 'Institutes', 'Lead', 'Learning', 'Machine Learning', 'Memory', 'Mentors', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Mus', 'Neurodegenerative Disorders', 'Neurons', 'Online Systems', 'Organ', 'Pharmacotherapy', 'Phase', 'Play', 'Positioning Attribute', 'Postdoctoral Fellow', 'Process', 'Relative (related person)', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Scanning', 'Science', 'Scientist', 'Simulate', 'Speed', 'Stroke', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissue Engineering', 'Tissue Sample', 'Tissue Stains', 'Tissues', 'Training', 'Transgenic Organisms', 'Tumor Angiogenesis', 'Tumor Tissue', 'United States National Institutes of Health', 'Universities', 'Work', 'analytical method', 'angiogenesis', 'base', 'brain tissue', 'career', 'career development', 'clinical application', 'computerized tools', 'design', 'experience', 'imaging Segmentation', 'improved', 'instrument', 'memory process', 'mouse model', 'neuronal cell body', 'next generation', 'open source', 'optical imaging', 'programs', 'prototype', 'reconstruction', 'research study', 'simulation', 'software development', 'success', 'tool', 'tumor growth']",NLM,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,K99,2013,87300,0.012418241986791145
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8464703,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'screening', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2013,1054947,-0.02353623117659017
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex. We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning. To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support: First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management. Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices. Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements. These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8479372,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2013,474880,0.06360101775535158
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8461069,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2013,425454,0.018621653380670476
"BIGDATA Small Project Structurization and Direct Search of Medical Image Data     DESCRIPTION (provided by applicant): IBM estimates that 30% of the entire data in the world is medical information. Medical images occupy a significant portion of medical records with approximately 100 million scans in US and growing every year. In addition, the data size from each scan steadfastly increases as the image resolution improves. These BigData are not structured and due to lack of standardized imaging protocols, they are highly heterogeneous with different spatial resolutions, contrasts, slice orientations, etc. In this project, we will deelop a technology to structure and search medical imaging information, which will make the past data available for education and evidence-based clinical decision-making. In this grant, we will focus on brain MRI, which comprises the largest portion of MRI data. The target community will be physicians who make decisions and the patients will be the ultimate beneficiaries. Currently, radiological image data are stored in clinical database called PACS. The image data in PACS are not structured. Consequently, once the diagnosis of a patient is completed, most of the data in PACS are currently discarded in the archive. Radiologists rely on their experience and education to reach medical decisions. This is a typical problem in medical practice that calls for objective evidence-based medicine. There are many ongoing attempts to structure the text fields of PACS, which include natural language processing of free-text radiological reports, clinical information, and diagnosis. In our approach, we propose to structure the image data, not text fields, to support direct search of images. Namely, physicians will submit an image of a new patient and search past images with similar anatomical phenotypes. Then, the clinical reports of the retrieved data will be compiled for a statistical report of the diagnosis and prognosis. We believe this image structuration is the key to ""unlock the vast amounts of information currently stored"" in PACS and use them for education and modern evidence-based medical decisions. The specific aims are; Objective 1: To develop and test the accuracy of high-throughput image structuration technologies Objective 2: To develop and test the image search engine Objective 3: Capacity Building Requirement: To develop prototype cloud system for data structuration / search services for research and educational purposes                  n/a",BIGDATA Small Project Structurization and Direct Search of Medical Image Data,8599843,R01EB017638,"['Archives', 'Brain', 'Clinical', 'Communities', 'Data', 'Databases', 'Decision Making', 'Diagnosis', 'Education', 'Evidence Based Medicine', 'Grant', 'Health Services Research', 'Image', 'Information Systems', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Medical Records', 'Natural Language Processing', 'Patients', 'Phenotype', 'Physicians', 'Protocols documentation', 'Reporting', 'Resolution', 'Scanning', 'Slice', 'Structure', 'Technology', 'Testing', 'Text', 'beneficiary', 'clinical decision-making', 'evidence base', 'experience', 'improved', 'outcome forecast', 'prototype', 'radiologist']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,224942,0.0199191927571512
"Developing a Platform for Prediction of Metastasis Using Multiplexed QD-imaging    DESCRIPTION (provided by applicant): Multiplexed biomarker analysis is more powerful in reflecting the biological behaviors of a tumor than single biomarker analysis, but its standardization and quantification is still a challenge. Furthermore, most computer software does not provide methods for imaging and analyzing subcellular localization of biomarkers and correlating them with biological and clinical information. The objective of this project is to develop a platform which combines imaging and quantification of multiplexed immunostaining plus bioinformatics for the prediction of lymph node metastases (LNM) from the primary tumor (PT) of squamous cell carcinoma of the head and neck (SCCHN). LNM of SCCHN is a precisely defined biological phenomenon which is an ideal model to be utilized to develop this multiplexed biomarker platform (MBP). Based on our preliminary studies, we aim to test the hypothesis that that the MBP can be developed to identify the subcellular distribution and expression of multiple metastasis-related biomarkers simultaneously in PTs. Accurate quantification of these biomarkers will facilitate the prediction of metastasis from PTs. Three emerging technologies, quantum dot (QD)-based immunohistofluorescence (IHF), multispectral imaging, and machine learning will be used to test this hypothesis. Using these approaches, a platform that combines quantifying multiplexed immunostaining with biostatistics will be developed and tested for its sensitivity, specificity, and prediction power for use in the clinic. Therefore, this project fits appropriately to the scope of the NCI program announcement ""Developmental Research in Cancer Prognosis and Prediction"" (PA-09-159).  Three aims are proposed in the study. (1) To develop a multiplexed biomarker system and method based on a bulk tissue model for prediction of LNM in SCCHN PT tissues. This Aim will establish and validate an analysis methodology for multiplexed quantification of membrane and cytoplasmic staining using a new function in InForm software where subcellular localization of certain biomarkers will be specifically analyzed. Prediction of LNM based on this bulk tissue model will be achieved. (2) To develop a per-cell quantification method based on a sub-population model for prediction of LNM in SCCHN PT tissue.  The per-cell analysis results will quantified as the percentage of high risk cells from the multiplexed biomarker analyses in the same PTs. The high risk population will be correlated with LNM. The sensitivity and specificity of the prediction by the sub-population model will be compared with that of the bulk tissue model. (3) To develop and validate a nomogram with software combining clinical characterizations of metastasis as a working platform for the prediction of LNM. While the primary endpoint of Aim 1 and 2 is to correlate the three biomarkers with metastasis, other clinical factors such as differentiation status, tumor stage, and site, etc. may also correlate with LNM. The most predictive biomarker set combined with relevant clinical factors will constitute a platform with computer software that will be validated in an additional 100 SCCHN samples for prediction of LNM.        Imaging and quantifying expression and subcellular localization of multiplexed biomarkers is currently a challenge in cancer research and clinical application. This project aims to develop a platform which combines imaging and quantifying multiplexed biomarkers plus their correlation with lymph node metastasis of squamous cell carcinoma of the head and neck. This platform can be used for an assessment of LNM which is paramount for appropriate treatment planning.         ",Developing a Platform for Prediction of Metastasis Using Multiplexed QD-imaging,8504823,R33CA161873,"['Behavior', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Phenomena', 'Biometry', 'Breast Cancer Cell', 'Cancer Prognosis', 'Cell membrane', 'Cells', 'Clinic', 'Clinical', 'Color', 'Colorectal Cancer', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disseminated Malignant Neoplasm', 'E-Cadherin', 'Emerging Technologies', 'Epidermal Growth Factor Receptor', 'Epithelial', 'Flow Cytometry', 'Head and Neck Squamous Cell Carcinoma', 'Human', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Literature', 'Lung', 'Machine Learning', 'Mesenchymal', 'Methodology', 'Methods', 'Modeling', 'NIH Program Announcements', 'Neoplasm Metastasis', 'Nomograms', 'Operative Surgical Procedures', 'Outcome', 'Population', 'Primary Neoplasm', 'Production', 'Quantum Dots', 'Reaction', 'Receiver Operating Characteristics', 'Research', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Specificity', 'Specimen', 'Staining method', 'Stains', 'Standardization', 'System', 'Technology', 'Testing', 'Tissue Model', 'Tissues', 'Tumor Tissue', 'Tumor stage', 'Work', 'aldehyde dehydrogenases', 'anticancer research', 'base', 'cancer cell', 'cancer stem cell', 'clinical application', 'high risk', 'lymph nodes', 'model development', 'nanoparticle', 'neoplastic cell', 'novel', 'outcome forecast', 'tool', 'treatment planning', 'tumor']",NCI,EMORY UNIVERSITY,R33,2013,296962,-0.02964888794009039
"BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci     DESCRIPTION (provided by applicant): Ideally, as neuroscientists collect terabytes of image stacks, the data are automatically processed for open access and analysis. Yet, while several labs around the world are collecting data at unprecedented rates- up to terabytes per day-the computational technologies that facilitate streaming data-intensive computing remain absent. Also deploying data-intensive compute clusters is beyond the means and abilities of most experimental labs. This project will extend, develop, and deploy such technologies. To demonstrate these tools, we will utilize them in support of the ongoing mouse brain architecture (MBA) project, which already has amassed over 0.5 petabytes (PBs) of image data. The main computational challenges posed by these datasets are ones of scale. The tasks that follow remain relatively stereotyped across acquisition modalities. Until now, labs collecting data on this scale have been almost entirely isolated, left to ""reinvent the wheel"" for each of these problems. Moreover, the extant solutions are insufficient for a number of reasons: they often include numerous excel spreadsheets that rely on manual data entry, they lack scalable scientific database backends, and they run on ad hoc clusters not specifically designed for the computational tasks at hand. We aim to augment the current state of the art by implementing the following technological advancements into the MBA project pipeline: (1) Data Management will consist of a unified system that automatically captures metadata, launches processing pipelines, and provides quality control feedback in minutes instead of hours. (2) Data Processing tasks will run algorithms ""out-of-core"", appropriate for their computational requirements, including registration, alignment, and semantic segmentation of cell bodies and processes. (3) Data Storage will automatically build databases for storing multimodal image data and extracted annotations learned from the machine vision algorithms. These databases will be spatially co-registered and stored on an optimized heterogeneous compute cluster. (4) Data Access will be automatically available to everyone-including all the image data and data derived products-via Web-services, including 3D viewing, downloading, and further processing. (5) Data Analytics will extend random graph models suitable for multiscale circuit graphs. RELEVANCE (See instructions): Nervous system disorders are responsible for approximately 30% of the total burden of illness in the United States. Whole brain neuroanatomy-available from massive neuroscientific image stacks-is widely believed to be a key missing link in our ability to prevent and treat such illnesses. Thus, this project aims to close this gap via the development and application of BIGDATA tools for management, storage, access, and analytics.              n/a",BIGDATA: Small DCM: ESCA DA Computational infrastructure for massive neurosci,8599834,R01DA036400,"['Algorithms', 'Architecture', 'Brain', 'Cell physiology', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Feedback', 'Graph', 'Hand', 'Hour', 'Image', 'Instruction', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Metadata', 'Modality', 'Modeling', 'Multimodal Imaging', 'Mus', 'Neuroanatomy', 'Process', 'Quality Control', 'Running', 'Semantics', 'Solutions', 'Stereotyping', 'Stream', 'System', 'Technology', 'United States', 'Vision', 'burden of illness', 'cluster computing', 'computer infrastructure', 'computerized data processing', 'data management', 'design', 'nervous system disorder', 'neuronal cell body', 'prevent', 'tool', 'web services']",NIDA,COLD SPRING HARBOR LABORATORY,R01,2013,249999,0.029778483687918307
"Objective decision support environment for clinical trials     DESCRIPTION:  Brain tumors are the second- and fifth-most common cause of cancer death in males and females under 40, respectively. The 5-year relative survival rate is only 33%, even after decades of research into new treatments. Imaging based on ""virtual biopsy"" can provide information about the entire lesion in a minimally or non-invasive way. Prior work by our group has demonstrated that image processing methods applied to serial examinations together (as opposed to applying them to individual examinations) can make subtle changes in brain tumors more apparent, allowing earlier detection of progression. We see the union of virtual biopsy methods and change detection methods as an innovative and powerful combination that our team is uniquely qualified to develop and evaluate. In this application, we will implement several feature selection (FS) methods in a tool that is ""image friendly"". This tool will help select informative features from images; apply a wide range of existing ML algorithms to determine which features are important predictors of therapy response, and to evaluate the impact of a decision support application using these features and ML in a clinical trial. The final stage of th proposal will test the decision support tools in 3 clinical scenarios to see if they are able to significantly improve the decision making of clinicians in a clinical trial.  The long-term goal of this proposal is to develop virtual biopsy technology that will enhance the clinical decision making process by providing tools for investigation of image-based therapy response assessment tools, that may also have some ability to predict outcome. We hope to apply the technology to other organ systems and other imaging technologies. We anticipate this project will impact clinical trials by enabling investigation of alternative outcome measures that are objectively assessed using algorithm evaluation methods. Such a toolset should be useful to the entire cancer imaging community to help evaluate features in old and new imaging technologies that correlate with patient survival. As such, this is ideal for helping the Quantitative Imaging Network (QIN) achieve its goals.           The selection of features that reflect response to therapy has long been the domain of the clinical radiologist. When imaging was relatively straightforward (e.g. a chest X-ray of lung cancer), a measurement or a visual assessment was a reasonable metric. Today, advanced imaging devices produce large amounts of data that reflect a range of properties. In this work, we build on previous work developing computer techniques for identifying and characterizing changes in brain tumors, using MRI. In this proposal, we will focus on building 1) a high quality database of brain cancer imaging, clinical data, ""-omic"" data, outcomes data; 2) a library of easily accessed tools for computing features that might be important predictors of tumor response; 3) a tool that will help objectively establish the feature() that are valuable through a variety of machine learning methods; and 4) use the above to create a decision support tool that will be used in 3 clinical trial situations.  .            ",Objective decision support environment for clinical trials,8527740,U01CA160045,"['Algorithms', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Cancer Etiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collection', 'Communities', 'Computers', 'Data', 'Databases', 'Decision Making', 'Detection', 'Differentiation Therapy', 'Early Diagnosis', 'Environment', 'Evaluation', 'Female', 'Goals', 'Image', 'Imaging Device', 'Imaging technology', 'Individual', 'Investigation', 'Lesion', 'Libraries', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Metric', 'Outcome', 'Outcome Measure', 'Output', 'Pathologic', 'Patients', 'Primary Brain Neoplasms', 'Process', 'Property', 'Qualifying', 'Relative (related person)', 'Research', 'Staging', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Visual', 'Work', 'base', 'body system', 'cancer imaging', 'clinical decision-making', 'image processing', 'improved', 'innovation', 'male', 'radiologist', 'response', 'tool', 'tumor', 'virtual']",NCI,MAYO CLINIC ROCHESTER,U01,2013,514055,-0.019446011741334587
"In-field FAST Procedure Support and Automation     DESCRIPTION (provided by applicant): The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound examination performed to identify intra-peritoneal hemorrhage or pericardial tamponade. FAST involves the detection of free fluid in ultrasound images from four specific abdominal areas. Unstable patients with positive FAST results are operated on, and stable patients with negative results tend to be observed.  We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life-saving FAST procedures. The proposed system will consist of a low-cost ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an intuitive application. Using that system, a novice operator will be visually guided to acquire ultrasound images from the abdominal locations and quantify the free fluid in those images.  The target for our initial deployment of the system is level 3 and 4 trauma centers. These centers must often serve areas spanning hundreds and even thousands of miles; however, they are typically under-staffed and under-equipped.  The proposal is being clinically driven by Jeffrey Lowell, MD. He is a USNR Trauma Surgeon, and he was recently deployed to Landstuhl Regional Medical Center, the only Level I Trauma Center outside the U.S.         PUBLIC HEALTH RELEVANCE: The Focused Assessment with Sonography for Trauma (FAST) procedure is an ultrasound-based examination for rapidly detecting blood in the abdomen, particularly after blunt abdominal trauma, which is common, for example, with car accidents. The challenge is that the FAST procedure requires expertise and equipment which is not commonly available at level 3 and 4 trauma centers that serve rural populations. We propose to develop the hardware and image analysis algorithms necessary for novice ultrasound operators to perform life- saving FAST procedures. The proposed system will consist of a low-cost, hand-held ultrasound probe, connected to a ruggedize tablet computer, running innovative computer vision algorithms, embedded in an easy-to-follow software application.            ",In-field FAST Procedure Support and Automation,8472102,R43EB016621,"['Abdomen', 'Abdominal Injuries', 'Accidents', 'Address', 'Age', 'Algorithms', 'Angiography', 'Area', 'Automation', 'Blood', 'Businesses', 'Caring', 'Cause of Death', 'Cessation of life', 'Computer Vision Systems', 'Computer software', 'Computers', 'Conduct Clinical Trials', 'Custom', 'Data', 'Decision Making', 'Detection', 'Development', 'Diagnosis', 'Doctor of Medicine', 'Environment', 'Equipment', 'Evaluation', 'FDA approved', 'Funding', 'Hand', 'Hemoperitoneum', 'Hemorrhage', 'Hospitals', 'Hour', 'Image', 'Image Analysis', 'Imagery', 'Injury', 'Kidney', 'Life', 'Liquid substance', 'Location', 'Medical', 'Medical center', 'Methods', 'Military Personnel', 'Morbidity - disease rate', 'Nurses', 'Operating Rooms', 'Organ Harvestings', 'Organ Procurements', 'Patients', 'Pediatric Hospitals', 'Pelvis', 'Pericardial body location', 'Persons', 'Phase', 'Physical Examination', 'Physics', 'Population', 'Positioning Attribute', 'Procedures', 'Publishing', 'Research', 'Running', 'Rural', 'Rural Population', 'Surgeon', 'System', 'Systems Integration', 'Tablets', 'Technology', 'Testing', 'Time', 'Training', 'Transplant Surgeon', 'Trauma', 'Ultrasonography', 'Uncompensated Care', 'Universities', 'Washington', 'Work', 'base', 'cost', 'emergency service responder', 'experience', 'follower of religion Jewish', 'health disparity', 'imaging Segmentation', 'innovation', 'medical schools', 'mortality', 'novel', 'pericardial sac', 'prototype', 'public health relevance', 'tool', 'trauma centers']",NIBIB,"KITWARE, INC.",R43,2013,200000,0.01157040926315207
"In vivo Characterization of Stents using Intravascular OCT Imaging     DESCRIPTION (provided by applicant): Every year, 100s of thousands of patients in the US are treated with intravascular stents. Although the technology has advanced and drug eluting metal stents hinder restenosis, there remains significant room for improvement. Stent parameters include drug choice, bioresorbable versus metal, mechanical design, coatings to stimulate cell coverage, etc. To optimize designs, sensitive, in vivo assessments are needed for preclinical and clinical studies. Intravascular OCT (iOCT) alone provides the resolution and contrast s necessary for in vivo interrogation of vascular healing; stent deployment issues such as malposition; and assessment of stent strut tissue coverage. The Cardiovascular Imaging Core Laboratory at CWRU analyzes iOCT images as a service to numerous clinical and preclinical trials from around the world. An analyst takes many hours to analyze manually a single stent, greatly limiting the size and number of studies. Despite training and quality assurance measures, inter-analyst variability limits the ability to determine changes between stent types. We will develop highly automated software to greatly speed analysis, improve reproducibility, increase accuracy, etc. Careful evaluations/validations will be performed using our database of >1500 manually analyzed stents, and new phantom and pig studies. With the successful completion of this research and development, we will deliver well-validated, highly automated software, which will enable routine use of iOCT for sensitive evaluation of emerging stent technologies, thereby providing greatly improved treatments of cardiovascular disease. In addition, fast, robust software will contribute to clinical usage of iOCT for assessment of stent deployment and healing of a stented vessel.         PUBLIC HEALTH RELEVANCE: We will develop methods for improved in vivo assessment of intravascular stents, the treatment of choice for 100s of thousands of patients, suffering from ischemic heart disease, in the US every year. Our methods will enable optimization of stent technologies for improved treatment of vascular disease.            ",In vivo Characterization of Stents using Intravascular OCT Imaging,8529140,R01HL114406,"['Algorithms', 'Ally', 'Area', 'Arteries', 'Back', 'Biological Markers', 'Blood Vessels', 'Cardiac', 'Cardiovascular Diseases', 'Catheters', 'Cells', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Code', 'Color', 'Computer software', 'Data', 'Databases', 'Dependence', 'Detection', 'Development', 'Devices', 'Evaluation', 'Family suidae', 'Feedback', 'Fibrin', 'Fracture', 'Goals', 'Graph', 'Healed', 'Histocompatibility Testing', 'Hour', 'Hyperplasia', 'Image', 'Image Analysis', 'Imagery', 'Industry', 'International', 'Laboratories', 'Licensing', 'Life', 'Machine Learning', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Myocardial Ischemia', 'Needs Assessment', 'Optics', 'Pathology', 'Patients', 'Pharmaceutical Preparations', 'Polymers', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Shadowing (Histology)', 'Shapes', 'Simulate', 'Site', 'Speed', 'Statistical Data Interpretation', 'Stents', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thrombosis', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Universities', 'Validation', 'Vascular Diseases', 'arm', 'base', 'cardiovascular imaging', 'cost', 'design', 'follow-up', 'healing', 'imaging modality', 'implantation', 'improved', 'in vivo', 'innovation', 'meetings', 'novel', 'preclinical evaluation', 'preclinical study', 'public health relevance', 'quality assurance', 'research and development', 'research clinical testing', 'restenosis', 'tool']",NHLBI,CASE WESTERN RESERVE UNIVERSITY,R01,2013,412883,0.008922973206218869
"CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development     DESCRIPTION (provided by applicant): Background: Dendritic arbor shape and functional properties emerge from the interaction of many complex developmental processes. It is now accepted that multiple local-level interactions of cytoskeleton elements direct the growth and development of the dendrite arbor. However, the specific mechanisms that control developmental acquisition of final functional dendritic properties are largely unknown. Addressing this fundamental question requires novel data driven systems-biology tools to study developmental and biophysical mechanisms in the same neuronal model. A tightly-knit collaboration between molecular genetics, quantitative morphometry, and mathematical simulation can for the first time enable large-scale studies capable of achieving holistic understanding of the mechanisms underlying emergent features of the arbor. Project Goals: The main neuroscientific goal of this project is to understand how multiple local interactions of cytoskeleton components during differentiation define mature dendritic arbor shape and its functional integrative properties, using Drosophila sensory neurons as a model. The technological goal of this project is to develop a novel investigative approach that integrates and extends previously separate approaches from developmental biology & genetics, in vivo confocal imaging & electrophysiology, computer vision, and neuroanatomical modeling. Specific Aims: We propose 3 tightly integrated specific aims. Aim 1: use genetic manipulations and electrophysiological recordings to model the role of cytoskeletal organization and dynamics as a fundamental determinant of emergent dendrite arbor shape and function. Aim 2: Implement advanced 4D multi-parameter imaging protocols and automated algorithms to reconstruct the arbor, and quantify spatial and temporal associations among multiple sub-cellular components. Aim 3: using automated reconstructions & measurements from aim 2, statistically characterize the structural and cytoskeletal features of dendrite arbors, and stochastically simulate the growth and electrotonic properties of anatomically realistic virtual neuronal analogues. The data from aim 3 will feed back novel hypotheses to be tested by a subsequent repetition of the (aim 1 - aim 2 - aim 3) cycle. Approach: We will focus on a single model system - Drosophila dendritic arborization (da) sensory neurons. More specifically, we will investigate class I and class IV da neuron arborization based upon their radically distinct dendritic morphologies (simple vs. complex) and underlying cytoskeletal organizations. We will make fusion constructs of cytoskeleton components with spectrally distinct fluorescent proteins. These will be used in transgenic Drosophila in order to quantitatively measure the distribution of F-actin, microtubules, and microtubule polarity within the dendrite arbor throughout its development in vivo using confocal multi-fluor imaging. The resulting images will be processed by automated quantitative computer vision algorithms that will accurately extract the topology of the dendritic arbor, and it changes over time. We will use the resulting maps in neuroanatomical stochastic simulations to establish the links between the emergent morphometrics of the dendrite and specific cytoskeleton features at various developmental stages. Intellectual Merit: From a neurogenetics perspective, this project will pioneer the use of cytoskeletal features as putative fundamental determinants in statistical neuroanatomical models. These determinants will be linked to morphological determinants. From a computational perspective, this project will advance the state of the art in automated algorithms for delineating neuroanatomy (and its morphological dynamics) by deploying core technologies for large-scale multi-parameter studies, and result in an effective interfacing of automated reconstruction and simulation technologies. With this innovation, model predictions can be tested by molecular biological techniques, and findings of statistical models can be used to inform molecular models of dendrite arbor development. Educational Impact: This project will result in a cross-disciplinary training of post-doctoral fellows, graduate students, undergraduate students and high school interns. It will result in practical insight on ways to conduct cutting-edge systems-level scientific research overcoming disciplinary boundaries and using best-available collaborative tools. The trainees from this program will be uniquely positioned to develop the broader field of imaging-driven integrative systems neurobiology. It will expose minority and K-12 students to a new world of trans-disciplinary research that is indicative of the future. Broader Impacts: The combined body of molecular, imaging, and computational tools and datasets from this research will be disseminated widely, and made available to a broad class of investigators for adoption in the study of other major neuroscience problems. This project will serve as a new model for computationally enabled neuroscience research that achieves a long-desired synergy between the wet lab and computation.             n/a",CRCNS: Cytoskeletal Mechanisms of Dendrite Arbor Shape Development,8644396,R01NS086082,"['Address', 'Adoption', 'Affect', 'Afferent Neurons', 'Algorithms', 'Anatomic Models', 'Back', 'Biological', 'Biological Models', 'Characteristics', 'Coal', 'Collaborations', 'Collection', 'Complex', 'Computer Simulation', 'Computer Vision Systems', 'Computer software', 'Confocal Microscopy', 'Cytoskeletal Modeling', 'Cytoskeleton', 'Data', 'Data Set', 'Dendrites', 'Development', 'Developmental Biology', 'Developmental Process', 'Discipline', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Elements', 'F-Actin', 'Future', 'Goals', 'Growth', 'Growth and Development function', 'Image', 'Knowledge', 'Link', 'Maps', 'Measurement', 'Measures', 'Microtubules', 'Minority', 'Modeling', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Molecular Models', 'Morphology', 'Nervous system structure', 'Neurites', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'Positioning Attribute', 'Principal Investigator', 'Process', 'Property', 'Proteins', 'Protocols documentation', 'Research', 'Research Personnel', 'Resources', 'Role', 'Series', 'Shapes', 'Signal Transduction', 'Simulate', 'Staging', 'Statistical Models', 'Structure', 'Students', 'Synapses', 'System', 'Systems Biology', 'Techniques', 'Technology', 'Testing', 'Time', 'Transgenic Organisms', 'Trees', 'analog', 'base', 'computerized tools', 'data sharing', 'developmental genetics', 'developmental neurobiology', 'digital', 'feeding', 'genetic manipulation', 'graduate student', 'high school', 'in vivo', 'innovation', 'insight', 'molecular imaging', 'molecular modeling', 'morphometry', 'neurogenetics', 'next generation', 'novel', 'open source', 'post-doctoral training', 'programs', 'reconstruction', 'relating to nervous system', 'research study', 'role model', 'simulation', 'tool', 'undergraduate student', 'virtual']",NINDS,GEORGE MASON UNIVERSITY,R01,2013,322109,-0.003216859685262052
"Statistical methods for large and complex databases of ultra-high-dimensional  Abstract Medical imaging is a cornerstone of basic science and clinical practice. To discover new mechanisms and markers of disease and their crucial implications for clinical practice, large multi-center imaging studies are acquiring terabytes of complex multi-modality imaging data cross-sectionally and longitudinally over decades. The statistical analysis of data from such studies is challenging due to the complex structure of the imaging data acquired and the ultra-high dimensionality. Furthermore, the heterogeneity of anatomy, pathology, and imaging protocols causes instability and failure of many current state-of-the-art image analysis methods. This grant proposes statistical frameworks for studying populations through biomedical imaging, scalable and robust methods for the identification and accurate quantification of pathology, and analytic tools for the cross-sectional and longitudinal examination of etiology and disease progression. These techniques will be applied to address key goals of the motivating large and multi- center studies of multiple sclerosis and Alzheimer's disease conducted at Johns Hopkins Hospital, the National Institute of Neurological Disorders and Stroke, and across the globe. The project will create methods for uncovering and quantifying brain lesion pathology, incidence, and trajectory. Methods developed under this grant will be targeted towards these neuroimaging goals, but will form the basis for statistical image analysis methods applicable broadly in the biomedical sciences. PUBLIC HEALTH RELEVANCE: This project involves the development of statistical frameworks and methods for the analysis of complex ultra-high-dimensional biomedical imaging. Methods developed are applied to study the clinical management and etiology of multiple sclerosis and Alzheimer's disease longitudinally and cross-sectionally.                ",Statistical methods for large and complex databases of ultra-high-dimensional,8614974,R01NS085211,"['Address', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Applications Grants', 'Area', 'Attention deficit hyperactivity disorder', 'Basic Science', 'Behavior', 'Brain', 'Brain Pathology', 'Brain imaging', 'Clinical Management', 'Complex', 'Computer software', 'Computing Methodologies', 'Contrast Media', 'Data', 'Data Analyses', 'Databases', 'Development', 'Disease Marker', 'Disease Progression', 'Etiology', 'Failure', 'Goals', 'Grant', 'Heterogeneity', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Incidence', 'Journals', 'Lesion', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Multiple Sclerosis', 'National Institute of Neurological Disorders and Stroke', 'Pathology', 'Population Study', 'Positioning Attribute', 'Protocols documentation', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scheme', 'Science', 'Site', 'Solutions', 'Statistical Data Interpretation', 'Statistical Methods', 'Statistical Models', 'Structure', 'Techniques', 'Technology', 'United States National Institutes of Health', 'Visualization software', 'Work', 'base', 'bioimaging', 'clinical practice', 'design', 'falls', 'imaging Segmentation', 'imaging modality', 'member', 'neuroimaging', 'next generation', 'open source', 'public health relevance', 'skills', 'tool', 'white matter']",NINDS,UNIVERSITY OF PENNSYLVANIA,R01,2013,373406,0.023400203139848894
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.        The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8383103,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2013,222916,0.03397921330499528
"ENTROPY-BASED TISSUE DISCRIMINATORS No abstract available PUBLIC HEALTH RELEVANCE: All skilled clinical practitioners and interpreters of ultrasound studies realize that much information exists in recorded US images that is processed immediately by the visual cortex and is useful for qualitatively defining pathology, yet defies ready quantification by any robust algorithm. Traditional energy-based representations display grayscale intensities and speckle patterns that have been mapped parametrically into various tissue classification schemes that have yet to demonstrate organ or tissue specificity, although progress has been reported in distinguishing pathologies over the last 30 years. However, the fact that US signal processing and representation of backscatter data in terms of energy functions has not changed over the last 50 years suggests that alternative signal processing schemes may be indicated to represent the richness of the information contained within the backscattered data. To meet this challenge, we have been involved over the past 10 years in processing backscattered RF to create ""information"" images and in designing ""information sensitive"" approaches to classifying the data sets based on statistical analysis of these images These novel and user independent metrics utilize the entropy of windowed segments of radiofrequency (RF) backscatter signal from tis- sue, which represents a radical departure from grayscale or speckle metrics. In this approach the entropy of the backscattered segment is used to produce a pixel value in the tissue image. This processing strategy has proven to be sensitive to weak, sub-resolution sized changes in tissue.            ",ENTROPY-BASED TISSUE DISCRIMINATORS,8636638,R21EB018095,"['Address', 'Algorithms', 'Back', 'Base Composition', 'Bayesian Analysis', 'Cardiac', 'Classification', 'Classification Scheme', 'Clinical', 'Color', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diffuse', 'Dimensions', 'Discrimination', 'Disease', 'Ensure', 'Entropy', 'Environment', 'Evaluation', 'Expeditions', 'Fatty Liver', 'Fibrosis', 'Fishes', 'Foundations', 'Fractals', 'Frequencies', 'Heart', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Individual', 'Infarction', 'Injury', 'Investigation', 'Ischemia', 'Joints', 'Kidney', 'Knowledge', 'Label', 'Liver', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Metric', 'Microscopic', 'Normal tissue morphology', 'Organ', 'Outcome', 'Pathology', 'Pattern', 'Pharmaceutical Preparations', 'Physiological', 'Positioning Attribute', 'Procedures', 'Process', 'Property', 'Prostate', 'Radio', 'Reporting', 'Resolution', 'Rodent', 'Scheme', 'Shapes', 'Signal Transduction', 'Specificity', 'Staining method', 'Stains', 'Stream', 'Structure', 'Testing', 'Time', 'Tissue Differentiation', 'Tissue Model', 'Tissues', 'Ultrasonic Transducer', 'Ultrasonics', 'Ultrasonography', 'Visual Cortex', 'Work', 'attenuation', 'base', 'computerized data processing', 'data reduction', 'design', 'detector', 'heart motion', 'indexing', 'meetings', 'n-dimensional', 'novel', 'public health relevance', 'radiofrequency', 'sound', 'tissue processing', 'vector']",NIBIB,WASHINGTON UNIVERSITY,R21,2013,228000,-0.0029926118315671255
"Multimodal image registration by proxy image synthesis No abstract available PUBLIC HEALTH RELEVANCE: Medical image registration is a method used throughout clinical medicine and medical research and it is vital to the success of many treatments and therapies and for answering a myriad of important scientific questions. This research will permit better alignment by devising and testing a new similarity criterion for multimodal images using the first significantly new approach in over a decade. The result will be better alignment of these images, which will enable better clinical diagnosis and prognosis and more significant research discoveries.            ",Multimodal image registration by proxy image synthesis,8614480,R01EB017743,"['Adopted', 'Affect', 'Aging', 'Algorithms', 'Appearance', 'Area', 'Atlases', 'Clinical', 'Clinical Medicine', 'Communities', 'Computer Vision Systems', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Diffusion weighted imaging', 'Disease', 'Environment', 'Evaluation', 'Functional Imaging', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grant', 'Growth', 'Health', 'Image', 'Java', 'Lead', 'Liquid substance', 'Magnetic Resonance Imaging', 'Manufacturer Name', 'Measures', 'Medical Imaging', 'Medical Research', 'Methods', 'Metric', 'Modality', 'Modeling', 'Motion', 'Multimodal Imaging', 'Neurosciences', 'Operative Surgical Procedures', 'Pathology', 'Performance', 'Physiologic pulse', 'Plague', 'Population', 'Positron-Emission Tomography', 'Predisposition', 'Procedures', 'Process', 'Proxy', 'Radial', 'Research', 'Research Personnel', 'Resources', 'Scanning', 'Science', 'Shapes', 'Specific qualifier value', 'Sum', 'Surface', 'Testing', 'Therapeutic', 'Tissues', 'Validation', 'Variant', 'Weight', 'Work', 'Writing', 'X-Ray Computed Tomography', 'base', 'clinical Diagnosis', 'computer code', 'cone-beam computed tomography', 'image reconstruction', 'image registration', 'improved', 'intraoperative imaging', 'longitudinal analysis', 'neuroimaging', 'novel strategies', 'open source', 'outcome forecast', 'public health relevance', 'shape analysis', 'statistics', 'success', 'theories', 'tool', 'vector', 'web site']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2013,343798,0.025430097947263374
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8323502,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2012,234509,0.018695566067959184
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Public Health Relevance/Narrative Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.",Image analysis for high-throughput C. elegans infection and metabolism assays,8208036,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'Gene Expression Profile', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'public health relevance', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,311786,0.04897801363429195
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8274480,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Screening procedure', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2012,1070334,-0.02353623117659017
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8393965,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Screening procedure', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'physical property', 'predictive modeling', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2012,75559,-0.02353623117659017
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8274831,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2012,503268,0.06399212915772821
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8259135,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'public health relevance', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2012,445075,0.018621653380670476
"Objective decision support environment for clinical trials     DESCRIPTION:  Brain tumors are the second- and fifth-most common cause of cancer death in males and females under 40, respectively. The 5-year relative survival rate is only 33%, even after decades of research into new treatments. Imaging based on ""virtual biopsy"" can provide information about the entire lesion in a minimally or non-invasive way. Prior work by our group has demonstrated that image processing methods applied to serial examinations together (as opposed to applying them to individual examinations) can make subtle changes in brain tumors more apparent, allowing earlier detection of progression. We see the union of virtual biopsy methods and change detection methods as an innovative and powerful combination that our team is uniquely qualified to develop and evaluate. In this application, we will implement several feature selection (FS) methods in a tool that is ""image friendly"". This tool will help select informative features from images; apply a wide range of existing ML algorithms to determine which features are important predictors of therapy response, and to evaluate the impact of a decision support application using these features and ML in a clinical trial. The final stage of th proposal will test the decision support tools in 3 clinical scenarios to see if they are able to significantly improve the decision making of clinicians in a clinical trial.  The long-term goal of this proposal is to develop virtual biopsy technology that will enhance the clinical decision making process by providing tools for investigation of image-based therapy response assessment tools, that may also have some ability to predict outcome. We hope to apply the technology to other organ systems and other imaging technologies. We anticipate this project will impact clinical trials by enabling investigation of alternative outcome measures that are objectively assessed using algorithm evaluation methods. Such a toolset should be useful to the entire cancer imaging community to help evaluate features in old and new imaging technologies that correlate with patient survival. As such, this is ideal for helping the Quantitative Imaging Network (QIN) achieve its goals.        PUBLIC HEALTH RELEVANCE:  The selection of features that reflect response to therapy has long been the domain of the clinical radiologist. When imaging was relatively straightforward (e.g. a chest X-ray of lung cancer), a measurement or a visual assessment was a reasonable metric. Today, advanced imaging devices produce large amounts of data that reflect a range of properties. In this work, we build on previous work developing computer techniques for identifying and characterizing changes in brain tumors, using MRI. In this proposal, we will focus on building 1) a high quality database of brain cancer imaging, clinical data, ""-omic"" data, outcomes data; 2) a library of easily accessed tools for computing features that might be important predictors of tumor response; 3) a tool that will help objectively establish the feature() that are valuable through a variety of machine learning methods; and 4) use the above to create a decision support tool that will be used in 3 clinical trial situations.  .               The selection of features that reflect response to therapy has long been the domain of the clinical radiologist. When imaging was relatively straightforward (e.g. a chest X-ray of lung cancer), a measurement or a visual assessment was a reasonable metric. Today, advanced imaging devices produce large amounts of data that reflect a range of properties. In this work, we build on previous work developing computer techniques for identifying and characterizing changes in brain tumors, using MRI. In this proposal, we will focus on building 1) a high quality database of brain cancer imaging, clinical data, ""-omic"" data, outcomes data; 2) a library of easily accessed tools for computing features that might be important predictors of tumor response; 3) a tool that will help objectively establish the feature() that are valuable through a variety of machine learning methods; and 4) use the above to create a decision support tool that will be used in 3 clinical trial situations.  .            ",Objective decision support environment for clinical trials,8369358,U01CA160045,"['Algorithms', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Brain imaging', 'Cancer Etiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collection', 'Communities', 'Computers', 'Data', 'Databases', 'Decision Making', 'Detection', 'Differentiation Therapy', 'Early Diagnosis', 'Environment', 'Evaluation', 'Female', 'Goals', 'Image', 'Imaging Device', 'Imaging technology', 'Individual', 'Investigation', 'Lesion', 'Libraries', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant neoplasm of brain', 'Malignant neoplasm of lung', 'Measurement', 'Methods', 'Metric', 'Outcome', 'Outcome Measure', 'Output', 'Pathologic', 'Patients', 'Primary Brain Neoplasms', 'Process', 'Property', 'Qualifying', 'Relative (related person)', 'Research', 'Staging', 'Survival Rate', 'Techniques', 'Technology', 'Testing', 'Thoracic Radiography', 'Visual', 'Work', 'base', 'body system', 'cancer imaging', 'clinical decision-making', 'image processing', 'improved', 'innovation', 'male', 'radiologist', 'response', 'tool', 'tumor', 'virtual']",NCI,MAYO CLINIC ROCHESTER,U01,2012,578313,-0.030240604612945653
"Developing a Platform for Prediction of Metastasis Using Multiplexed QD-imaging    DESCRIPTION (provided by applicant): Multiplexed biomarker analysis is more powerful in reflecting the biological behaviors of a tumor than single biomarker analysis, but its standardization and quantification is still a challenge. Furthermore, most computer software does not provide methods for imaging and analyzing subcellular localization of biomarkers and correlating them with biological and clinical information. The objective of this project is to develop a platform which combines imaging and quantification of multiplexed immunostaining plus bioinformatics for the prediction of lymph node metastases (LNM) from the primary tumor (PT) of squamous cell carcinoma of the head and neck (SCCHN). LNM of SCCHN is a precisely defined biological phenomenon which is an ideal model to be utilized to develop this multiplexed biomarker platform (MBP). Based on our preliminary studies, we aim to test the hypothesis that that the MBP can be developed to identify the subcellular distribution and expression of multiple metastasis-related biomarkers simultaneously in PTs. Accurate quantification of these biomarkers will facilitate the prediction of metastasis from PTs. Three emerging technologies, quantum dot (QD)-based immunohistofluorescence (IHF), multispectral imaging, and machine learning will be used to test this hypothesis. Using these approaches, a platform that combines quantifying multiplexed immunostaining with biostatistics will be developed and tested for its sensitivity, specificity, and prediction power for use in the clinic. Therefore, this project fits appropriately to the scope of the NCI program announcement ""Developmental Research in Cancer Prognosis and Prediction"" (PA-09-159).  Three aims are proposed in the study. (1) To develop a multiplexed biomarker system and method based on a bulk tissue model for prediction of LNM in SCCHN PT tissues. This Aim will establish and validate an analysis methodology for multiplexed quantification of membrane and cytoplasmic staining using a new function in InForm software where subcellular localization of certain biomarkers will be specifically analyzed. Prediction of LNM based on this bulk tissue model will be achieved. (2) To develop a per-cell quantification method based on a sub-population model for prediction of LNM in SCCHN PT tissue.  The per-cell analysis results will quantified as the percentage of high risk cells from the multiplexed biomarker analyses in the same PTs. The high risk population will be correlated with LNM. The sensitivity and specificity of the prediction by the sub-population model will be compared with that of the bulk tissue model. (3) To develop and validate a nomogram with software combining clinical characterizations of metastasis as a working platform for the prediction of LNM. While the primary endpoint of Aim 1 and 2 is to correlate the three biomarkers with metastasis, other clinical factors such as differentiation status, tumor stage, and site, etc. may also correlate with LNM. The most predictive biomarker set combined with relevant clinical factors will constitute a platform with computer software that will be validated in an additional 100 SCCHN samples for prediction of LNM.        Imaging and quantifying expression and subcellular localization of multiplexed biomarkers is currently a challenge in cancer research and clinical application. This project aims to develop a platform which combines imaging and quantifying multiplexed biomarkers plus their correlation with lymph node metastasis of squamous cell carcinoma of the head and neck. This platform can be used for an assessment of LNM which is paramount for appropriate treatment planning.         ",Developing a Platform for Prediction of Metastasis Using Multiplexed QD-imaging,8307808,R33CA161873,"['Behavior', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Phenomena', 'Biometry', 'Breast Cancer Cell', 'Cancer Prognosis', 'Cell membrane', 'Cells', 'Clinic', 'Clinical', 'Color', 'Colorectal Cancer', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disseminated Malignant Neoplasm', 'E-Cadherin', 'Emerging Technologies', 'Epidermal Growth Factor Receptor', 'Epithelial', 'Flow Cytometry', 'Head and Neck Squamous Cell Carcinoma', 'Human', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Literature', 'Lung', 'Machine Learning', 'Mesenchymal', 'Methodology', 'Methods', 'Modeling', 'NIH Program Announcements', 'Neoplasm Metastasis', 'Nomograms', 'Operative Surgical Procedures', 'Outcome', 'Population', 'Primary Neoplasm', 'Production', 'Quantum Dots', 'Reaction', 'Receiver Operating Characteristics', 'Research', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Specificity', 'Specimen', 'Staining method', 'Stains', 'Standardization', 'System', 'Technology', 'Testing', 'Tissue Model', 'Tissues', 'Tumor Tissue', 'Tumor stage', 'Work', 'aldehyde dehydrogenases', 'anticancer research', 'base', 'cancer cell', 'cancer stem cell', 'clinical application', 'high risk', 'lymph nodes', 'model development', 'nanoparticle', 'neoplastic cell', 'novel', 'outcome forecast', 'tool', 'treatment planning', 'tumor']",NCI,EMORY UNIVERSITY,R33,2012,354843,-0.02964888794009039
"An automated high throughput phenotypic screen for schistosomiasis drug discovery    DESCRIPTION (provided by applicant): Schistosomiasis is a tropical parasitic disease infecting over 200 million people. Treatment relies on a single drug, praziquantel (PZQ). In the absence of back-up drugs with PZQ's therapeutic spectrum, the risk of resistance to PZQ and eventual drug failure is a major concern. Traditional phenotypic screens, using adult- stage S. mansoni, are low-throughput and incompatible with modern high-throughput screen (HTS) systems. In keeping with the NIAID's mission, the present proposal aims to turn a newly developed, moderate- throughput phenotypic screen (MTS), into a fully automated, quantitative HTS to accelerate drug discovery for this infectious disease. The proposal involves three PIs with ongoing collaborations and respective biological, screening-technology and bio-computational skills who are focused on just this goal. As a first research track for this proposal, we will utilize in-house automation and a high-content screening (HCS) system to significantly increase throughput over our published MTS approach. The proposal will involve; expanding robotic plating of the parasite, developing protocols for bright-field and fluorescence-based microscopy and adapting commercial image-analysis software to identify (segment), quantitatively describe and track the motion of parasites with a view to prioritizing compounds for further pre-clinical development. Because commercial HCS analysis tools are not likely optimized for recording the complex and dynamic phenotypes displayed by this multicellular parasite, we will also pursue a second and parallel track of research. Specifically, we will develop de novo an automated image-analysis screening technology to define, identify, and quantify the range of phenotypic responses (morphological and behavioral) possible in this parasite. Ultimately, both the experimental and computation tracks will together produce a standardized HTS protocol and a comprehensive, quantitative suite of image-analysis programs to categorize parasite phenotypes. Such rigor will facilitate the screening of large numbers of potential compounds and their prioritization into the secondary and tertiary screening assays available in-house. We also intend to make the algorithmic framework including its methods and implementations, publicly available.      PUBLIC HEALTH RELEVANCE: The major goal of the project is to turn a moderate-throughput phenotypic screen (MTS) system for schistosomiasis, into a fully automated, quantitative high-throughput screen (HTS). By so doing, the rate of discovery of drugs to treat this global tropical disease will be increased.           Project Narrative The major goal of the project is to turn a moderate-throughput phenotypic screen (MTS) system for schistosomiasis, into a fully automated, quantitative high-throughput screen (HTS). By so doing, the rate of discovery of drugs to treat this global tropical disease will be increased.",An automated high throughput phenotypic screen for schistosomiasis drug discovery,8259789,R01AI089896,"['Address', 'Adult', 'Algorithms', 'Area', 'Automation', 'Back', 'Behavioral', 'Biological', 'Biological Assay', 'Characteristics', 'Classification', 'Clinical', 'Clinical Drug Development', 'Collaborations', 'Collection', 'Color', 'Communicable Diseases', 'Complex', 'Computer software', 'Computers', 'Descriptor', 'Development', 'Disease', 'Economic Development', 'Failure', 'Fluorescence', 'Foundations', 'Goals', 'Housing', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Left', 'Life', 'Liquid substance', 'Machine Learning', 'Manuals', 'Methods', 'Microscope', 'Microscopy', 'Mission', 'Motion', 'Movement', 'Parasites', 'Parasitic Diseases', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Praziquantel', 'Praziquantel resistance', 'Protocols documentation', 'Publishing', 'Research', 'Risk', 'Robotics', 'San Francisco', 'Schistosoma mansoni', 'Schistosome Parasite', 'Schistosomiasis', 'Screening procedure', 'Shapes', 'Social Development', 'Staging', 'System', 'Techniques', 'Technology', 'Texture', 'Therapeutic', 'Thick', 'Time', 'Tropical Disease', 'Universities', 'World Health Organization', 'assay development', 'base', 'chemotherapy', 'computerized tools', 'design', 'drug development', 'drug discovery', 'high throughput screening', 'neglect', 'novel', 'pre-clinical', 'programs', 'protocol development', 'public health relevance', 'response', 'skills', 'success', 'tool', 'transmission process']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2012,428854,-0.015927019809355087
"Coupled level set framework for retinal segmentation and atlasing in SD-OCT    DESCRIPTION (provided by applicant): Some eye diseases exhibit abnormalities or atrophy of the retina, which can impair vision and cause blindness. Certain other diseases traditionally thought to be exclusively associated with the brain are now known to be associated with changes or differences in the retina, which can also impair vision. Optical coherence tomography (OCT), an imaging device that is enabling modern in-vivo high-resolution studies of the retina, is rapidly becoming a key imaging technology both in ophthalmology, where clinical diagnoses and disease monitoring are experiencing a dramatic technical revolution, and also in neurology, where noninvasive retinal markers of brain disease are beginning to emerge. A key limitation in the current technology is the lack of detailed, accurate, and fully-automated analysis of the retinal layers that are observed throughout the retina in a typical three-dimensional spectral domain (SD)-OCT exam. Although tools are beginning to appear in association with commercial devices, they are currently lacking in sophistication and are not validated or standardized across manufacturers. This deficiency is problematic for both clinical and scientific application of SD-OCT since the measurements are not of known precision and are therefore not easily compared both in the same subject longitudinally and in population cross sections. The proposed research takes advantage of state-of-the-art algorithms that are emerging in both computer vision and medical imaging and will apply, adapt, and extend them to the specific application of layer segmentation in three-dimensional retinal SD-OCT. Advanced tools for population averaging in a normalized space will also be developed specifically for retinal SD-OCT data. The methods will be validated against manual segmentation and normalization on both normal subjects and patients experiencing retinal degeneration largely associated with thinning of selective layers of the retina. Scans of patients with diseases causing significant retinopathy such as cysts, detachment, or scarring will be evaluated, but further development beyond the present research is expected to be needed to properly segment and quantify such cases. The developed software will be developed within the open-source Java Image Science Toolkit (JIST) framework and released as open source software.      PUBLIC HEALTH RELEVANCE: The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.           The project will develop software for the image analysis of optical coherence tomography (OCT) scans of the retina. Segmentation and quantification of the characteristics of nerve layers within the retina is expected to be of great use on both ophthalmology and neurology, where the retina can be a sensitive indicator of both vision and neurological problems or diseases. Open source software written in a highly portable language will be made available to the research community at the conclusion of the research grant.         ",Coupled level set framework for retinal segmentation and atlasing in SD-OCT,8227796,R21EY022150,"['Address', 'Adoption', 'Age related macular degeneration', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Ataxia', 'Atlases', 'Atrophic', 'Biological Markers', 'Blindness', 'Brain', 'Brain Diseases', 'Central Nervous System Diseases', 'Characteristics', 'Choroid', 'Cicatrix', 'Clinical', 'Collection', 'Communities', 'Computer Vision Systems', 'Computer software', 'Coupled', 'Cyst', 'Cystoid Macular Edema', 'Data', 'Development', 'Devices', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exhibits', 'Exploratory/Developmental Grant', 'Eye', 'Eye diseases', 'Functional disorder', 'Glaucoma', 'Heterogeneity', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Immune', 'Individual', 'Java', 'Joints', 'Knowledge', 'Language', 'Lead', 'Light', 'Manuals', 'Manufacturer Name', 'Measurement', 'Measures', 'Medical Imaging', 'Methodology', 'Methods', 'Microscopic', 'Modification', 'Monitor', 'Multiple Sclerosis', 'Nerve', 'Neurologic', 'Neurology', 'Ophthalmology', 'Optical Coherence Tomography', 'Parkinson Disease', 'Patients', 'Pattern', 'Pattern Recognition', 'Phase', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Retina', 'Retinal', 'Retinal Degeneration', 'Retinal Diseases', 'Scanning', 'Science', 'Severity of illness', 'Shapes', 'Spinocerebellar Ataxias', 'Staging', 'Techniques', 'Technology', 'Testing', 'Texture', 'Thick', 'Three-Dimensional Image', 'Three-dimensional analysis', 'Time', 'Tissues', 'Variant', 'Vision', 'Vision Disorders', 'Visual', 'Visual Fields', 'Work', 'Writing', 'clinical Diagnosis', 'cost', 'design', 'disability', 'experience', 'improved', 'in vivo', 'insight', 'instrumentation', 'macula', 'method development', 'neuroimaging', 'open source', 'optic nerve disorder', 'population based', 'prognostic', 'retinal nerve fiber layer', 'software development', 'statistics', 'tool', 'two-dimensional']",NEI,JOHNS HOPKINS UNIVERSITY,R21,2012,197444,0.037884906147119556
"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis  Project Summary All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This proposal takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.  Project Narrative This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.",Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,8300746,R21HS019792,[' '],AHRQ,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2012,151744,-0.011400605995719881
"Clinical Image Retrieval: User needs assessment toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a",Clinical Image Retrieval: User needs assessment toolbox development & evaluation,8299311,R00LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'information model', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,MASSACHUSETTS GENERAL HOSPITAL,R00,2011,239426,0.018695566067959184
"Image analysis for high-throughput C. elegans infection and metabolism assays    DESCRIPTION (provided by applicant): High-throughput screening (HTS) is a technique for searching large libraries of chemical or genetic perturbants, to find new treatments for a disease or to better understand disease pathways. As automated image analysis for cultured cells has improved, microscopy has emerged as one of the most powerful and informative ways to analyze screening samples. However, many diseases and biological pathways can be better studied in whole animals-particularly diseases that involve organ systems and multicellular interactions, such as metabolism and infection. The worm Caenorhabditis elegans is a well-established and effective model organism, used by thousands of researchers worldwide to study complex biological processes. Samples of C. elegans can be robotically prepared and imaged by high-throughput microscopy, but existing image-analysis methods are insuf- ficient for most assays. In this project, image-analysis algorithms that are capable of scoring high-throughput assays of C. elegans will be developed.  The algorithms will be tested and refined in three high-throughput screens, which will uncover chemical and genetic regulators of fat metabolism and infection: (1) A C. elegans viability assay to identify modulators of infection. The proposed algorithms use a probabilistic shape model of C. elegans in order to identify and mea- sure individual worms even when the animals touch or cross. These methods are the basis for quantifying many other phenotypes, including body morphology and subtle variations in reporter signal levels. (2) A C. elegans lipid assay to identify genes that regulate fat metabolism. The algorithms proposed for illumination correction, level-set-based foreground segmentation, well-edge detection, and artifact removal will result in improved or- business in high-throughput experiments. (3) A fluorescence gene expression assay to identify regulators of the response of the C. elegans host to Staphylococcus aureus infection. The proposed techniques for constructing anatomical maps of C. elegans will make it possible to quantify a variety of changes in fluorescent localization patterns in a biologically relevant way.  In addition to discovering new metabolism- and infection-related drugs and genetic regulators through these specific screens, this work will provide the C. elegans community with (a) a new framework for extracting mor- phological features from C. elegans for quantitative analysis of this organism, and (b) a versatile, modular, open-source toolbox of algorithms enabling the discovery of genetic pathways, chemical probes, and drug can- didates in whole organism high-throughput screens relevant to a variety of diseases.  This work is a close collaboration with C. elegans experts Fred Ausubel and Gary Ruvkun at Massachusetts General Hospital/Harvard Medical School, with Polina Golland and Tammy Riklin-Raviv, experts in model-based segmentation and statistical image analysis at MIT's Computer Science and Artificial Intelligence Laboratory, and with Anne Carpenter, developer of open-source image analysis software at the Broad Institute.      PUBLIC HEALTH RELEVANCE: Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.           Large-scale screening experiments that test the effects of thousands of chemicals or genetic perturbants by microscopy and image analysis can discover new treatments and help biomedical scientists understand dis- ease mechanisms. Microscopy screens of cultured cells are routine, but researchers wish to study complex processes like metabolism and infection in a whole animal like the tiny worm Caenorhabditis elegans, for which existing image analysis methods are insufficient. The goal of this research is to develop open-source software to automatically identify and measure C. elegans in microscopy images, thereby making it possible for researchers worldwide to screen a wide variety of complex biological processes related to human disease.         ",Image analysis for high-throughput C. elegans infection and metabolism assays,8022635,R01GM095672,"['Address', 'Algorithms', 'Animal Model', 'Animals', 'Anti-Infective Agents', 'Artificial Intelligence', 'Atlases', 'Bacteria', 'Biological', 'Biological Assay', 'Biological Process', 'Businesses', 'Caenorhabditis elegans', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Cultured Cells', 'Data Quality', 'Descriptor', 'Detection', 'Development', 'Disease', 'Disease Pathway', 'Drug Delivery Systems', 'Excision', 'Fluorescence', 'Gene Expression', 'General Hospitals', 'Genes', 'Genetic', 'Goals', 'Human', 'Image', 'Image Analysis', 'Immune response', 'Individual', 'Infection', 'Institutes', 'Laboratories', 'Learning', 'Life', 'Lighting', 'Lipids', 'Machine Learning', 'Maps', 'Massachusetts', 'Measurement', 'Measures', 'Metabolism', 'Methods', 'Microscopy', 'Microsporidia', 'Modeling', 'Morphologic artifacts', 'Morphology', 'Organism', 'Pathway interactions', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Preparation', 'Process', 'Reporter', 'Research', 'Research Personnel', 'Resistance', 'Sampling', 'Screening procedure', 'Shapes', 'Signal Transduction', 'Software Engineering', 'Staining method', 'Stains', 'Staphylococcus aureus', 'Techniques', 'Testing', 'Touch sensation', 'Variant', 'Whole Organism', 'Work', 'base', 'biomedical scientist', 'body system', 'chemical genetics', 'computer science', 'computerized tools', 'design', 'drug candidate', 'follow-up', 'high throughput analysis', 'high throughput screening', 'human disease', 'image processing', 'imaging Segmentation', 'improved', 'interest', 'lipid metabolism', 'medical schools', 'novel', 'open source', 'pathogen', 'research study', 'response', 'small molecule libraries', 'two-dimensional']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,304318,0.049386863948654824
"Continued development of CellProfiler cell image analysis software    DESCRIPTION (provided by applicant):        Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology.      PUBLIC HEALTH RELEVANCE:           Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,8102722,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Light', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2011,458901,0.06399212915772821
"SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID DESCRIPTION (provided by applicant): Advanced instrumentation and cellular imaging techniques using high-throughput 3D electron microscopy are driving a new revolution in the exploration of complex biological systems by providing near seamless views across multiple scales of resolution. These datasets provide the necessary breadth and depth to analyze multicellular, cellular, and subcelluar structure across large swathes of neural tissue. While these new imaging procedures are generating extremely large datasets of enormous value, the quantities are such that no single user or even laboratory team can possibly analyze the full content of their own imaging activities through traditional means. To address this challenge, we propose to further develop and refine a prototype hybrid system for high-throughput segmentation of large neuropil datasets that: 1) advances automatic algorithms for segmentation of cellular and sub-cellular structures using machine learning techniques; 2) couples these techniques to a scalable and flexible process or tool suite allowing multiple users to simultaneously review, edit and curate the results of these automatic approaches; and, 3) builds a knowledge base of training data guiding and improving automated processing. This system will allow project scientists to select areas of interest, execute automatic segmentation algorithms, and distribute workload, curate data, and deposit final results into the Cell Centered Database (Martone et al. 2008) via accessible web-interfaces. Emerging techniques in cellular and subcellular 3D imaging are generating datasets of enormous value to the study of disease processes and to the pursuit of greater insight into the structure and function of the nervous system. To unlock the potential of these data, new solutions are needed to improve the capability to segment and label the individual molecular, subcellular and cellular components within very large volumetric expanses. To address this challenge, we propose a hybrid system for high-throughput segmentation of large neuropil datasets that advances machine learning algorithms for automatic segmentation and couples these techniques to a scalable tool suite for multiple users to simultaneously review, edit and curate results.",SLASH: SCALABLE LARGE ANALYTIC SEGMENTATION HYBRID,8163481,R01NS075314,"['Address', 'Adoption', 'Algorithms', 'Area', 'Automobile Driving', 'Biological', 'Cell membrane', 'Cell physiology', 'Cells', 'Cellular Structures', 'Classification', 'Complex', 'Computer software', 'Computers', 'Computers and Advanced Instrumentation', 'Couples', 'Cytoskeleton', 'Data', 'Data Set', 'Databases', 'Deposition', 'Devices', 'Disease', 'Electron Microscopy', 'Electrons', 'Face', 'Generations', 'Goals', 'Growth', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Institutes', 'Internet', 'Label', 'Laboratories', 'Machine Learning', 'Manuals', 'Methods', 'Microscopic', 'Mitochondria', 'Molecular', 'Molecular Target', 'Names', 'Nervous System Physiology', 'Nervous system structure', 'Neurofibrillary Tangles', 'Neurons', 'Neuropil', 'Online Systems', 'Organelles', 'Participant', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Scanning Electron Microscopy', 'Scientist', 'Services', 'Solutions', 'Staining method', 'Stains', 'Structure', 'Subcellular structure', 'System', 'Techniques', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Utah', 'Validation', 'Work', 'Workload', 'biological systems', 'cellular imaging', 'complex biological systems', 'data mining', 'digital imaging', 'electron optics', 'flexibility', 'image processing', 'improved', 'insight', 'interest', 'knowledge base', 'novel', 'prototype', 'relating to nervous system', 'scientific computing', 'tomography', 'tool', 'web interface']",NINDS,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2011,459174,0.018621653380670476
"PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY    DESCRIPTION (provided by applicant): Well trained, experienced gastroenterologists in academic and high volume settings can reliably recognize 97% of pathologies in Capsule Endoscopy (CE) video. However, community physicians and infrequent users may miss up to 20%. The end goal of our proposed new line of research is to develop clinical software that provides automatic decision support to physicians who are trying to declare that a patient is pathology free or has a certain disease process. The risk for the physician - and their patients - is that of a less than optimal clinical outcome due to:  1) missing a lesion/pathology in the video and putting the patient at risk of developing a more serious condition over time, or  2) mistakenly ""identifying"" a pathology that is not present and thus subjecting the patient to unnecessary further diagnostic or surgical procedures.  The research aims in this proposal will enable Ikona to create a pathology prioritization image processing module. Implementing modern machine learning techniques such as Support Vector Machines (SVM) and Adaboost methodologies together with proprietary image feature analysis, this technology will assign a probability metric to every frame in the image sequence for specific pathology (lesions, ulcers, bleeding, etc) and the major landmarks in the GI tract (ileo-cecal valve, pyloric valve etc.). Filtering and sorting endoscopy image data will be done such that the images with the highest probability of containing pathology will be presented to the reviewer first.  This pathology prioritized sequencing is not intended to replace the clinician in the workflow, but rather to allow the clinician to focus more time on frames with a higher potential of containing pathology. Often times, clinically significant pathology may only be present in a single frame. A single ""pathological"" frame in the middle of a 50,000 frame sequence can easily be overlooked by a novice reviewer or a reviewer whose attention is temporarily distracted. With our proposed pathology prioritization, that single pathological frame will be identified and sorted near the beginning of the image sequence thus greatly increasing the likelihood of detection by the reviewer.  Specifically for Phase I, we plan to investigate and develop different algorithms for classifying image frames and recognizing pathological and normal frames, and, algorithms for ranking frames by severity of pathology. Following the implementation of a working prototype, we will further test the clinical utility of these algorithms with human clinical capsule endoscopy videos.      PUBLIC HEALTH RELEVANCE: Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.           Capsule Endoscopy (CE) is widely used for assessing the small intestine in obscure gastrointestinal bleeding. Experienced gastroenterologists miss 2-3% of pathologies in part due to fatigue from reviewing 50,000 frames per CE video. Less experienced reviewers miss up to 20%. We propose to reduce the risk of false negatives by developing clinical image processing software to automatically re-order the CE video frames, ranking them by the probability they contain pathology.         ",PATHOLOGY MISS RATE RISK REDUCTION IN DIAGNOSTIC SMALL BOWEL CAPSULE ENDOSCOPY,8057895,R43DK091083,"['Affect', 'Algorithms', 'American', 'Attention', 'Blood', 'Categories', 'Classification', 'Classification Scheme', 'Clinical', 'Community Physician', 'Computer software', 'Crohn&apos', 's disease', 'Data', 'Data Set', 'Databases', 'Deformity', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Diagnostic Imaging', 'Diagnostic Procedure', 'Disease', 'Endoscopy', 'Evaluation', 'Family', 'Fatigue', 'Gastroenterologist', 'Gastrointestinal tract structure', 'Goals', 'Hemorrhage', 'Hour', 'Human', 'Image', 'Imagery', 'Lesion', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Methodology', 'Methods', 'Metric', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Phase', 'Physicians', 'Polyps', 'Population', 'Probability', 'Procedures', 'Process', 'Readability', 'Reader', 'Reading', 'Research', 'Risk', 'Risk Reduction', 'Severities', 'Small Intestines', 'Sorting - Cell Movement', 'Speed', 'Staging', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Training Support', 'Ulcer', 'Work', 'base', 'capsule', 'clinically relevant', 'clinically significant', 'cost', 'experience', 'gastrointestinal', 'image processing', 'improved', 'innovation', 'interest', 'prospective', 'prototype', 'tumor']",NIDDK,IKONA MEDICAL CORPORATION,R43,2011,176778,0.003031358171577324
"Digital image analysis for quantitative and qualitative assessment of pig islets    DESCRIPTION (provided by applicant): The demonstration by the Edmonton group that human islet transplantation can be successfully used to manage adult type 1 diabetes patients with refractory hypoglycemia has led to increased funding of clinical trials and further research to extend the scope of this therapy by using porcine islets in place of human islets. Significant advances have been made in improving immunosuppression treatment regimens so that results obtained from treating adult diabetic patients with human islet transplants are similar to those obtained after pancreas transplantation. The major hurdle to move this therapy from clinical research to routine clinical practice is to improve the yield and quality of islets recovered from human or porcine pancreas. Presently, there are no standardized methods that can accurately assess the number or quality of islets that are used in the islet transplantation procedures so that results between laboratories can be objectively evaluated. This grant is focused on developing a robust, islet image analysis software to objectively analyze the number and quality of porcine islets recovered from the pancreas. The two major aims of the project are first to develop an improved image analysis software program that will provide a standardized measurement of the number and mass of porcine islets in a cell preparation. And second, enhance the capabilities of the software program by correlating the image signatures of each porcine islet to an artificial category. Porcine islets of similar size will be handpicked and sorted into three categories based on the shape, border, integrity, or uniformity of dithizone staining. The first software enhancement will find those features in the images that can be used to distinguish the different categories of islets. The second enhancement will assess the feasibility of using machine learning methods to correlate these features with data recovered from the images but also other discrete or continuous variables that are used to characterize the porcine islet preparations. If successful, the ability to use a rapid and objective image analysis methodology will improve the assessment of the number and quality of islets within and between laboratories; correlate image features with success of transplantation as measured by graft survival and insulin independence; and improve the islet isolation methods to achieve favorable islet image scores that are determined by retrospective analysis. The ability of a commercial firm focused on improving islet yields by focusing on tissue dissociation with a leading academic laboratory that has sophisticated expertise in developing software algorithms from microscopic images provides a fresh approach to a difficult medical that needs to be resolved to realize the full potential of islet transplantation to treat adult type 1 diabetic patients.      PUBLIC HEALTH RELEVANCE: An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.           An objective, reliable and accurate method for the assessment of islet quantity and quality is paramount to the standardization and subsequent success of islet transplantation as a treatment for type 1 diabetes. Conventional manual methods for determining islet yields using an optical microscope with a calibrated eyepiece reticule are subjective, time consuming and often overestimate islet mass due to sampling errors and erroneous assumptions in the conversion of islet numbers to islet equivalents. The research proposed will utilize recent advances in digital image analysis, including machine learning and pattern recognition, to develop a software algorithm for the rapid characterization of islets destined for transplantation procedures.         ",Digital image analysis for quantitative and qualitative assessment of pig islets,8058009,R43DK091103,"['Address', 'Adoption', 'Adult', 'Algorithms', 'Biochemical', 'Biological', 'Biological Assay', 'Caliber', 'Categories', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computer Assisted', 'Computer software', 'Data', 'Data Collection', 'Development', 'Dissociation', 'Dithizone', 'Drops', 'Enzymes', 'Family suidae', 'Feasibility Studies', 'Funding', 'Genetic', 'Glucose', 'Graft Survival', 'Grant', 'Human', 'Hypoglycemia', 'Image', 'Image Analysis', 'Immunosuppression', 'In Vitro', 'Insulin', 'Insulin-Dependent Diabetes Mellitus', 'Islet Cell', 'Islets of Langerhans Transplantation', 'Laboratories', 'Liver', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Microscope', 'Microscopic', 'Modification', 'Optics', 'Organ', 'Outcome', 'Pancreas', 'Pancreas Transplantation', 'Pathway interactions', 'Patients', 'Pattern Recognition', 'Pattern Recognition Systems', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Portal vein structure', 'Predictive Value', 'Preparation', 'Procedures', 'Proteomics', 'Protocols documentation', 'Recovery', 'Refractory', 'Reporting', 'Research', 'Sampling', 'Sampling Errors', 'Scientist', 'Screening procedure', 'Shapes', 'Sorting - Cell Movement', 'Staining method', 'Stains', 'Standardization', 'Statistical Models', 'Stress', 'Structure', 'Survival Rate', 'System', 'Techniques', 'Time', 'Tissues', 'Transplantation', 'Treatment Protocols', 'base', 'cell preparation', 'clinical practice', 'diabetic patient', 'digital', 'digital imaging', 'improved', 'indexing', 'innovation', 'islet', 'programs', 'software development', 'standardize measure', 'success', 'tool', 'type I diabetic']",NIDDK,"VITACYTE, LLC",R43,2011,232329,0.04279220747741019
"Developing a Platform for Prediction of Metastasis Using Multiplexed QD-imaging    DESCRIPTION (provided by applicant): Multiplexed biomarker analysis is more powerful in reflecting the biological behaviors of a tumor than single biomarker analysis, but its standardization and quantification is still a challenge. Furthermore, most computer software does not provide methods for imaging and analyzing subcellular localization of biomarkers and correlating them with biological and clinical information. The objective of this project is to develop a platform which combines imaging and quantification of multiplexed immunostaining plus bioinformatics for the prediction of lymph node metastases (LNM) from the primary tumor (PT) of squamous cell carcinoma of the head and neck (SCCHN). LNM of SCCHN is a precisely defined biological phenomenon which is an ideal model to be utilized to develop this multiplexed biomarker platform (MBP). Based on our preliminary studies, we aim to test the hypothesis that that the MBP can be developed to identify the subcellular distribution and expression of multiple metastasis-related biomarkers simultaneously in PTs. Accurate quantification of these biomarkers will facilitate the prediction of metastasis from PTs. Three emerging technologies, quantum dot (QD)-based immunohistofluorescence (IHF), multispectral imaging, and machine learning will be used to test this hypothesis. Using these approaches, a platform that combines quantifying multiplexed immunostaining with biostatistics will be developed and tested for its sensitivity, specificity, and prediction power for use in the clinic. Therefore, this project fits appropriately to the scope of the NCI program announcement ""Developmental Research in Cancer Prognosis and Prediction"" (PA-09-159).  Three aims are proposed in the study. (1) To develop a multiplexed biomarker system and method based on a bulk tissue model for prediction of LNM in SCCHN PT tissues. This Aim will establish and validate an analysis methodology for multiplexed quantification of membrane and cytoplasmic staining using a new function in InForm software where subcellular localization of certain biomarkers will be specifically analyzed. Prediction of LNM based on this bulk tissue model will be achieved. (2) To develop a per-cell quantification method based on a sub-population model for prediction of LNM in SCCHN PT tissue.  The per-cell analysis results will quantified as the percentage of high risk cells from the multiplexed biomarker analyses in the same PTs. The high risk population will be correlated with LNM. The sensitivity and specificity of the prediction by the sub-population model will be compared with that of the bulk tissue model. (3) To develop and validate a nomogram with software combining clinical characterizations of metastasis as a working platform for the prediction of LNM. While the primary endpoint of Aim 1 and 2 is to correlate the three biomarkers with metastasis, other clinical factors such as differentiation status, tumor stage, and site, etc. may also correlate with LNM. The most predictive biomarker set combined with relevant clinical factors will constitute a platform with computer software that will be validated in an additional 100 SCCHN samples for prediction of LNM.      PUBLIC HEALTH RELEVANCE: Imaging and quantifying expression and subcellular localization of multiplexed biomarkers is currently a challenge in cancer research and clinical application. This project aims to develop a platform which combines imaging and quantifying multiplexed biomarkers plus their correlation with lymph node metastasis of squamous cell carcinoma of the head and neck. This platform can be used for an assessment of LNM which is paramount for appropriate treatment planning.           Imaging and quantifying expression and subcellular localization of multiplexed biomarkers is currently a challenge in cancer research and clinical application. This project aims to develop a platform which combines imaging and quantifying multiplexed biomarkers plus their correlation with lymph node metastasis of squamous cell carcinoma of the head and neck. This platform can be used for an assessment of LNM which is paramount for appropriate treatment planning.         ",Developing a Platform for Prediction of Metastasis Using Multiplexed QD-imaging,8177540,R33CA161873,"['Behavior', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Phenomena', 'Biometry', 'Breast Cancer Cell', 'Cancer Prognosis', 'Cell membrane', 'Cells', 'Clinic', 'Clinical', 'Color', 'Colorectal Cancer', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnostic Neoplasm Staging', 'Disseminated Malignant Neoplasm', 'E-Cadherin', 'Emerging Technologies', 'Epidermal Growth Factor Receptor', 'Epithelial', 'Flow Cytometry', 'Head and Neck Squamous Cell Carcinoma', 'Human', 'Image', 'Image Analysis', 'Immunohistochemistry', 'Literature', 'Lung', 'Machine Learning', 'Mesenchymal', 'Methodology', 'Methods', 'Modeling', 'NIH Program Announcements', 'Neoplasm Metastasis', 'Nomograms', 'Operative Surgical Procedures', 'Outcome', 'Population', 'Primary Neoplasm', 'Production', 'Quantum Dots', 'Reaction', 'Receiver Operating Characteristics', 'Research', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Site', 'Specificity', 'Specimen', 'Staining method', 'Stains', 'Standardization', 'System', 'Technology', 'Testing', 'Tissue Model', 'Tissues', 'Tumor Tissue', 'Tumor stage', 'Work', 'aldehyde dehydrogenases', 'anticancer research', 'base', 'cancer cell', 'cancer stem cell', 'clinical application', 'high risk', 'lymph nodes', 'model development', 'nanoparticle', 'neoplastic cell', 'novel', 'outcome forecast', 'tool', 'treatment planning', 'tumor']",NCI,EMORY UNIVERSITY,R33,2011,308241,-0.028399594951218583
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",8100386,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'Structure', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2011,220839,-0.013922011263367425
"An automated high throughput phenotypic screen for schistosomiasis drug discovery    DESCRIPTION (provided by applicant): Schistosomiasis is a tropical parasitic disease infecting over 200 million people. Treatment relies on a single drug, praziquantel (PZQ). In the absence of back-up drugs with PZQ's therapeutic spectrum, the risk of resistance to PZQ and eventual drug failure is a major concern. Traditional phenotypic screens, using adult- stage S. mansoni, are low-throughput and incompatible with modern high-throughput screen (HTS) systems. In keeping with the NIAID's mission, the present proposal aims to turn a newly developed, moderate- throughput phenotypic screen (MTS), into a fully automated, quantitative HTS to accelerate drug discovery for this infectious disease. The proposal involves three PIs with ongoing collaborations and respective biological, screening-technology and bio-computational skills who are focused on just this goal. As a first research track for this proposal, we will utilize in-house automation and a high-content screening (HCS) system to significantly increase throughput over our published MTS approach. The proposal will involve; expanding robotic plating of the parasite, developing protocols for bright-field and fluorescence-based microscopy and adapting commercial image-analysis software to identify (segment), quantitatively describe and track the motion of parasites with a view to prioritizing compounds for further pre-clinical development. Because commercial HCS analysis tools are not likely optimized for recording the complex and dynamic phenotypes displayed by this multicellular parasite, we will also pursue a second and parallel track of research. Specifically, we will develop de novo an automated image-analysis screening technology to define, identify, and quantify the range of phenotypic responses (morphological and behavioral) possible in this parasite. Ultimately, both the experimental and computation tracks will together produce a standardized HTS protocol and a comprehensive, quantitative suite of image-analysis programs to categorize parasite phenotypes. Such rigor will facilitate the screening of large numbers of potential compounds and their prioritization into the secondary and tertiary screening assays available in-house. We also intend to make the algorithmic framework including its methods and implementations, publicly available.      PUBLIC HEALTH RELEVANCE: The major goal of the project is to turn a moderate-throughput phenotypic screen (MTS) system for schistosomiasis, into a fully automated, quantitative high-throughput screen (HTS). By so doing, the rate of discovery of drugs to treat this global tropical disease will be increased.           Project Narrative The major goal of the project is to turn a moderate-throughput phenotypic screen (MTS) system for schistosomiasis, into a fully automated, quantitative high-throughput screen (HTS). By so doing, the rate of discovery of drugs to treat this global tropical disease will be increased.",An automated high throughput phenotypic screen for schistosomiasis drug discovery,8072723,R01AI089896,"['Address', 'Adult', 'Algorithms', 'Area', 'Automation', 'Back', 'Behavioral', 'Biological', 'Biological Assay', 'Characteristics', 'Classification', 'Clinical', 'Clinical Drug Development', 'Collaborations', 'Collection', 'Color', 'Communicable Diseases', 'Complex', 'Computer software', 'Computers', 'Descriptor', 'Development', 'Disease', 'Economic Development', 'Failure', 'Fluorescence', 'Foundations', 'Goals', 'Housing', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Left', 'Life', 'Liquid substance', 'Machine Learning', 'Manuals', 'Methods', 'Microscope', 'Microscopy', 'Mission', 'Motion', 'Movement', 'Parasites', 'Parasitic Diseases', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Praziquantel', 'Praziquantel resistance', 'Protocols documentation', 'Publishing', 'Research', 'Risk', 'Robotics', 'San Francisco', 'Schistosoma mansoni', 'Schistosome Parasite', 'Schistosomiasis', 'Screening procedure', 'Shapes', 'Social Development', 'Staging', 'System', 'Techniques', 'Technology', 'Texture', 'Therapeutic', 'Thick', 'Time', 'Tropical Disease', 'Universities', 'World Health Organization', 'assay development', 'base', 'chemotherapy', 'computerized tools', 'design', 'drug development', 'drug discovery', 'high throughput screening', 'neglect', 'novel', 'pre-clinical', 'programs', 'protocol development', 'public health relevance', 'response', 'skills', 'success', 'tool', 'transmission process']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2011,423139,-0.015927019809355087
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,8139155,R44RR024094,"['AIDS/HIV problem', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cell physiology', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2011,449663,-0.016320205313207353
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,8143297,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Area', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'animal tissue', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'phase 1 study', 'programs', 'public health relevance', 'validation studies']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2011,132786,-2.9224635111742023e-05
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8147701,U19ES019528,[' '],NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2011,1090598,-0.02353623117659017
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,8123240,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Clinical Research', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost effective', 'digital imaging', 'image archival system', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'two-dimensional', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2011,677070,0.009535499703550472
"Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis    DESCRIPTION (provided by applicant): All people with diabetes have the risk of developing diabetic retinopathy, a vision-threatening complication. Despite advances in diabetes care over the years, diabetic retinopathy remains a potentially devastating complication. Early detection and timely intervention or treatment can reduce the incidence of blindness due to diabetic retinopathy. Recent years, diagnosis based on digital retinal imaging has become an alternative to traditional face-to-face evaluation. The potential benefits of automated analysis of digital images of diabetic retinopathy have been shown in existing studies. However, no current computer-based systems can achieve the same level of performance of human experts. This application takes a new perspective in developing a computer-aided system for improved diagnosis of diabetic retinopathy, by exploring novel computational methods for retrieving clinically-relevant images from archived database with prior diagnosis information, for a given novel image. Images are considered as being clinically relevant if they contain the same types of lesions with similar severity levels. Research and development on content-based retinal image search/retrieval is still in its infancy, with only limited success, largely due to the challenge of explicitly coding expert-knowledge into a computational algorithm. To deal with the challenge, this research project takes a distinctly different approach engaging a machine-learning approach, where a labeled image set is used to train a computer algorithm for analyzing other new images, with the focus of training on similarity in clinical relevance instead of image features. The training is enabled in part by the investigators' existing research on computer-based lesion simulation. One specific aim of the research is to build a content-based image retrieval system that can provide a clinician with instant reference to archival images that are clinically relevant to the image under diagnosis. This is an innovative way of exploiting vast expert knowledge hidden in libraries of previously-diagnosed digital images of diabetic retinopathy for a clinician's improved performance in diagnosis. Another specific aim is to build an image information management system for diabetic retinopathy that supports the deployment of the retrieval system in a realistic clinical setting. In addition to the retrieval system, the direct outcome of the research also includes automated evaluation algorithms for diabetic retinopathy images with potentially improved performance compared with existing methods. In particular, the design of the proposed work allows different configurations of the resultant system according to the specific needs of a physician.      PUBLIC HEALTH RELEVANCE: This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.           This project develops a computer-based system for improved diagnosis of diabetic retinopathy, a vision- threatening complication in people with diabetes. Early detection and timely intervention or treatment can reduce the incidence of blindness, and the computer-based system can potentially improve not only the speed but also the accuracy in diagnosing or screening patients with diabetic retinopathy.         ",Exploring Clinically-relevant Image Retrieval for Diabetic Retinopathy Diagnosis,8192056,R21HS019792,[' '],AHRQ,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R21,2011,148255,-0.024743415115513256
"Clinical Image Retrieval: User needs assessment, toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a","Clinical Image Retrieval: User needs assessment, toolbox development & evaluation",7921476,K99LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Arts', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Institutes', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Modeling', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,K99,2010,110591,0.018695566067959184
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8146748,U19ES019528,"['Biological Availability', 'Biology', 'Biometry', 'Cells', 'Cellular Structures', 'Cellular biology', 'Computer Simulation', 'Cytolysis', 'Data', 'Dose', 'Engineering', 'Fibrosis', 'Future', 'Generations', 'Goals', 'Health', 'Image', 'In Vitro', 'Inflammation', 'Inhalation Exposure', 'Injury', 'Lead', 'Libraries', 'Link', 'Lung', 'Lytic', 'Machine Learning', 'Mathematics', 'Membrane', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Multivariate Analysis', 'Mus', 'Organ', 'Outcome', 'Oxidative Stress', 'Pathway interactions', 'Performance', 'Play', 'Pneumonia', 'Property', 'Rattus', 'Research Project Grants', 'Risk', 'Rodent', 'Role', 'Science', 'Screening procedure', 'Signal Pathway', 'Signal Transduction', 'Silicon Dioxide', 'Structure', 'Tissues', 'Toxic effect', 'Toxicology', 'base', 'cellular imaging', 'chemical property', 'combinatorial', 'computer science', 'cytotoxicity', 'hazard', 'high throughput screening', 'in vivo', 'mathematical model', 'metal oxide', 'multidisciplinary', 'nano', 'nanobiology', 'nanomaterials', 'nanoparticle', 'predictive modeling', 'statistics']",NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2010,27441,-0.02353623117659017
"Continued development of CellProfiler cell image analysis software Most laboratories studying biological processes and human disease use light/fluorescence microscopes to image cells and other biological samples. There is strong and growing demand for software to analyze these images, as automated microscopes collect images faster than can be examined by eye and the information sought from images is increasingly quantitative and complex.  We have begun to address this demand with CellProfiler, a versatile, open-source software tool for quantifying data from biological images, particularly in high-throughput experiments (www.cellprofiler.org). CellProfiler can extract valuable biological information from images quickly while increasing the objectivity and statistical power of assays. In the three years since its release, it has become widely used, having been downloaded more than 8,000 times by users in over 60 countries. Using CellProfiler's point-and-click interface, researchers build a customized chain of image analysis modules to identify and measure biological objects in images. The software evolved in an intensely collaborative and interdisciplinary research environment with dozens of ongoing projects and has been successfully applied to a wide range of biological samples and assays, from counting cells to scoring complex phenotypes by machine learning.  To enable further biological imaging research, meet the needs of the growing user base, and expand the community that benefits from CellProfiler, we propose to improve its capabilities, interface, and support:  First, we will add user-requested capabilities, leveraging existing open-source projects by interoperating with them where feasible. These new features will include object tracking in time-lapse movies, compatibility with additional file formats, new image processing algorithms, and expanded tools for quality control, performance evaluation, cluster computing, and workflow management.  Second, we will improve the interface, increase processing speed, and simplify the addition of new features by refactoring and porting the MATLAB-based code to an open-source language and instituting proven software development practices.  Third, we will provide user, educator, and developer support and outreach for CellProfiler. These activities will facilitate research in the scientific community and help guide usability improvements.  These improvements to the only open-source software for modular, high-throughput biological image analysis will enable hundreds of NIH-funded laboratories to make high-impact biological discoveries from cell images across all disciplines within biology. Most laboratories studying biological processes and human disease use microscopy to analyze cells and  other samples. We will enable these researchers to rapidly and accurately extract numerical data from  microscopy images by continuing to develop and support our user-friendly, open-source cell image  analysis software, CellProfiler (www.cellprofiler.org).",Continued development of CellProfiler cell image analysis software,7761085,R01GM089652,"['Address', 'Algorithms', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Code', 'Communities', 'Complex', 'Computer software', 'Country', 'Data', 'Databases', 'Dependence', 'Development', 'Discipline', 'Educational Curriculum', 'Educational workshop', 'Electronic Mail', 'Environment', 'Evaluation', 'Eye', 'Funding', 'Grant', 'Image', 'Image Analysis', 'Institutes', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Study', 'Language', 'Libraries', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Metric', 'Microscope', 'Microscopy', 'Modeling', 'Paper', 'Performance', 'Persons', 'Phenotype', 'Process Measure', 'Quality Control', 'Reading', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'Speed', 'Staining method', 'Stains', 'Testing', 'Time', 'United States National Institutes of Health', 'Whole Organism', 'base', 'cellular imaging', 'cluster computing', 'file format', 'fluorescence microscope', 'human disease', 'image processing', 'improved', 'interoperability', 'meetings', 'movie', 'open source', 'outreach', 'processing speed', 'public health relevance', 'repository', 'research study', 'resource guides', 'software development', 'tool', 'usability', 'user-friendly', 'web interface']",NIGMS,"BROAD INSTITUTE, INC.",R01,2010,463608,0.06360101775535158
"Integrating Quantitative Histological Image and Vascular Density Patterns for Pro    DESCRIPTION (provided by applicant):       With increasing detection of early CaP with improved diagnostic methodologies, it has become important to predict biologic behaviors and ""aggressivity"" to identify patients who might benefit from a ""wait and watch policy"" as opposed to those who need more aggressive strategies. Traditionally, T-stage, amount of cancer in the core biopsy, the Gleason grade, and PSA at diagnosis has been used to evaluate the prognosis in localized CaP. While the Gleason score is currently assumed to be the strongest prognostic marker for CaP, there is often considerably high inter-, intra-observer variability associated with Gleason grade determination by pathologists. While some newer markers have recently shown promise, none of these methods have individually proven to be accurate enough to serve routinely as a prognostic marker for CaP.  Recently, there has been a call to combine multiple prognostic markers to create an integrated meta-marker, with potentially greater accuracy in predicting CaP recurrence compared to any individual marker. While it is apparent that prognostic information resides in histopathology imagery in terms of the arrangement of nuclei and glands, sophisticated graph, and computerized image analysis algorithms are required to quantitatively model and characterize the architectural appearance of prostate cancer histopathology and thus provide a marker that is accurate and reproducible (unlike Gleason grade). In addition, while tumor micro-vascular density has been correlated to CaP outcome, prognostic information may also potentially reside in the specific spatial architectural arrangement of the micro-vascular network. The objective of the proposed work is to develop an integrated quantitative prognostic marker that combines information based on architectural arrangement of nuclear, glandular, and micro-vasculature network patterns on whole mount histology sections (WMHS) obtained via radical prostatectomy (RP) to predict prostate cancer recurrence.  The proposed work comprises a total of 3 specific aims. For this project we will digitize approximately 100 annonymized WMHS obtained via RP that have been matched for Gleason score, stage, PSA, but with different clinical outcomes (half the patients having undergone cancer recurrence and the other not, following RP). Under Aim 1, segmentation algorithms will be developed to automatically identify cancerous nuclei, glands and tumor microvasculature (MV), stained immuno-histochemically via CD31. Under Aim 2 we will apply graph based image analysis algorithms to quantitatively characterize the architectural arrangement of CaP nuclei, glands and the MV network. These graph-based features will be integrated via a computerized machine learning algorithm to yield a numerical image based risk score (IbRiS) reflecting the CaP prognosis (disease recurrence or non-recurrence) of the patient. IbRiS will be evaluated in terms of its ability to distinguish between CaP progressors and non-progressors (matched for stage, Gleason grade, PSA), in a cohort of 50 independent studies (test set) for which survival and outcome data is available.  This project will be a collaboration between investigators at Rutgers University (RU) and the University of Pennsylvania (UPENN). Data accrual will be done at UPENN while algorithmic development for computerized image analysis and classification will be carried out at RU.             The broad long term goal of this project is to develop an integrated image based histological biomarker for  predicting  prostate  cancer  (CaP)  survival  and  outcome  by  integrating  quantitative  image  signatures  that  define  tissue  architecture  and  vascular  density  patterns.  Sophisticated  image  analysis  and  graph  based  algorithms will be developed to yield an image based risk score (IbRis) to predict whether or not a CaP patient  will  have  disease  recurrence  following  treatment.  Our  hypothesis  is  that  IbRis  will  prove  to  be  a  better  prognostic marker compared to such traditional markers as Gleason score and PSA.   ",Integrating Quantitative Histological Image and Vascular Density Patterns for Pro,7941833,R03CA143991,"['Algorithms', 'Appearance', 'Architecture', 'Area', 'Behavior', 'Biological Markers', 'Blood Vessels', 'Cancerous', 'Cell Nucleus', 'Classification', 'Clinical', 'Collaborations', 'Computers', 'Core Biopsy', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'E-Cadherin', 'Early Diagnosis', 'Gland', 'Gleason Grade for Prostate Cancer', 'Goals', 'Graph', 'Histocytochemistry', 'Histology', 'Histopathology', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intraobserver Variability', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Nuclear', 'Outcome', 'Output', 'PECAM1 gene', 'Pathologist', 'Patients', 'Pattern', 'Pennsylvania', 'Policies', 'Prognostic Marker', 'Protocols documentation', 'Radical Prostatectomy', 'Randomized', 'Recurrence', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Scheme', 'Slide', 'Specimen', 'Staging', 'Staining method', 'Stains', 'Structure', 'TP53 gene', 'Testing', 'Tissues', 'Training', 'Tumor stage', 'Universities', 'Validation', 'Work', 'base', 'cancer recurrence', 'cohort', 'computerized', 'density', 'digital', 'imaging Segmentation', 'improved', 'novel marker', 'outcome forecast', 'prognostic', 'repository', 'tumor', 'vector']",NCI,"RUTGERS, THE STATE UNIV OF N.J.",R03,2010,81236,-0.07003553914349751
"A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets    DESCRIPTION (provided by applicant):       A decade ago when microarray was first invented, it was hailed as ""an array of hope"" in Nature Genetics and has received a considerable amount of attention in biomedicine. Subsequently it has been called ""an array of problems"" in Nature Review. An inherent problem with microarray gene expression is that structural information is missing, which limits its ability in biological discovery. To overcome the poor reproducibility and accuracy of microarray imaging, there needs to be a shift in fundamental paradigms to those able to incorporate complementary and multiscale structural imaging information into microarray imaging. Fortunately, the latest progress in high resolution biomolecular imaging probe development coupled with advanced image analysis makes integrative and systematic studies of cellular systems possible. A cell can be labeled using multiscale and multimodality imaging, providing both structural and functional information. With multiscale imaging spreadsheets now available, there is an overwhelming need within the life sciences community to manage this information effectively, to analyze it comprehensively, and to apply the resulting knowledge in the understanding of the genetic system of a cell. However, the management and mining of this large-scale imaging information is limited by today's computational approaches and knowledge-sharing infrastructure. These problems represent a major impediment to progress in the emerging area of bio-molecular image informatics. Therefore, the goal of this project is to develop a unique genomic image management and mining system that can allow geneticists to search, correlate and integrate this multiscale and multi-modality imaging information in an easily operable fashion and further enable new biological discovery. In particular, this system will fill a void left in the current image database systems such as Open Microscope Environment (OME), e.g., the lack of analytic tools for integrative data analysis. To realize this goal, we are bringing together a strong interdisciplinary team consisting of imaging engineers, geneticists and industrial imaging scientists. Building on our diverse and complementary expertise, we are able to provide innovative and interdisciplinary approaches that combine the latest progress in image processing, imaging database design and machine learning with the development of high resolution and high throughput molecular imaging probes in genomics. More specifically, we will accomplish the following specific aims. First, we will develop a suite of algorithms for content extraction and information retrieval from high resolution fluorescence in situ hybridization (FISH) images. This visual system will effectively manage imaging phenotype information, facilitating knowledge discovery such as identifying visually similar subtypes. Second, we will correlate quantitative traits extracted from FISH imaging with genomic structural rearrangements and gene expression patterns. Finally, we will develop a data integration approach to fuse disparate information from multi-modality imaging databases for improved characterization of biological systems.               Public Health Relevance Statement The anticipated outcome of the project will include a publicly accessible imaging database analysis system to facilitate multiscale genomic image information integration and knowledge mining. The proposed approach challenges the current paradigm by the integration of high resolution structural imaging with functional information, which promises to overcome the poor accuracy and reproducibility problems plagued with microarray imaging. Given the ubiquitous use of microarray imaging in biomedicine, the project is thus expected to be of great impact on the biomedical community.",A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets,7845601,R21LM010042,"['Address', 'Affect', 'Algorithms', 'Area', 'Attention', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Sciences', 'Biology', 'Blast Cell', 'Cells', 'Chromosome abnormality', 'Comb animal structure', 'Communities', 'Complex', 'Computational Biology', 'Coupled', 'DNA Sequence', 'DNA Sequence Rearrangement', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Functional Imaging', 'Gene Expression', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Hybridization Array', 'Image', 'Image Analysis', 'Informatics', 'Information Retrieval', 'Karyotype', 'Knowledge', 'Label', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Microscope', 'Mining', 'Modality', 'Molecular', 'Nature', 'Organ', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plague', 'Prevention', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resolution', 'Retrieval', 'Scientist', 'Specimen', 'Staging', 'System', 'Systems Analysis', 'Systems Biology', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Visual', 'Visual system structure', 'Work', 'base', 'bioimaging', 'biological systems', 'complex biological systems', 'data integration', 'database design', 'disease diagnosis', 'disorder prevention', 'gene function', 'genome sequencing', 'image processing', 'imaging informatics', 'imaging modality', 'imaging probe', 'improved', 'innovation', 'interdisciplinary approach', 'knowledge of results', 'molecular imaging', 'multimodality', 'mutant', 'public health relevance', 'structural genomics', 'tool', 'trait', 'visual map']",NLM,TULANE UNIVERSITY OF LOUISIANA,R21,2010,186306,0.03826281994408961
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7754089,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2010,2037327,0.011613976352124066
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",7877019,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Java', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'Structure', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2010,223070,-0.013922011263367425
"An automated high throughput phenotypic screen for schistosomiasis drug discovery    DESCRIPTION (provided by applicant): Schistosomiasis is a tropical parasitic disease infecting over 200 million people. Treatment relies on a single drug, praziquantel (PZQ). In the absence of back-up drugs with PZQ's therapeutic spectrum, the risk of resistance to PZQ and eventual drug failure is a major concern. Traditional phenotypic screens, using adult- stage S. mansoni, are low-throughput and incompatible with modern high-throughput screen (HTS) systems. In keeping with the NIAID's mission, the present proposal aims to turn a newly developed, moderate- throughput phenotypic screen (MTS), into a fully automated, quantitative HTS to accelerate drug discovery for this infectious disease. The proposal involves three PIs with ongoing collaborations and respective biological, screening-technology and bio-computational skills who are focused on just this goal. As a first research track for this proposal, we will utilize in-house automation and a high-content screening (HCS) system to significantly increase throughput over our published MTS approach. The proposal will involve; expanding robotic plating of the parasite, developing protocols for bright-field and fluorescence-based microscopy and adapting commercial image-analysis software to identify (segment), quantitatively describe and track the motion of parasites with a view to prioritizing compounds for further pre-clinical development. Because commercial HCS analysis tools are not likely optimized for recording the complex and dynamic phenotypes displayed by this multicellular parasite, we will also pursue a second and parallel track of research. Specifically, we will develop de novo an automated image-analysis screening technology to define, identify, and quantify the range of phenotypic responses (morphological and behavioral) possible in this parasite. Ultimately, both the experimental and computation tracks will together produce a standardized HTS protocol and a comprehensive, quantitative suite of image-analysis programs to categorize parasite phenotypes. Such rigor will facilitate the screening of large numbers of potential compounds and their prioritization into the secondary and tertiary screening assays available in-house. We also intend to make the algorithmic framework including its methods and implementations, publicly available.      PUBLIC HEALTH RELEVANCE: The major goal of the project is to turn a moderate-throughput phenotypic screen (MTS) system for schistosomiasis, into a fully automated, quantitative high-throughput screen (HTS). By so doing, the rate of discovery of drugs to treat this global tropical disease will be increased.           Project Narrative The major goal of the project is to turn a moderate-throughput phenotypic screen (MTS) system for schistosomiasis, into a fully automated, quantitative high-throughput screen (HTS). By so doing, the rate of discovery of drugs to treat this global tropical disease will be increased.",An automated high throughput phenotypic screen for schistosomiasis drug discovery,7947512,R01AI089896,"['Address', 'Adult', 'Algorithms', 'Area', 'Automation', 'Back', 'Behavioral', 'Biological', 'Biological Assay', 'Characteristics', 'Classification', 'Clinical', 'Clinical Drug Development', 'Collaborations', 'Collection', 'Color', 'Communicable Diseases', 'Complex', 'Computer software', 'Computers', 'Descriptor', 'Development', 'Disease', 'Economic Development', 'Failure', 'Fluorescence', 'Foundations', 'Goals', 'Housing', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Left', 'Life', 'Liquid substance', 'Machine Learning', 'Manuals', 'Methods', 'Microscope', 'Microscopy', 'Mission', 'Motion', 'Movement', 'Parasites', 'Parasitic Diseases', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Population', 'Praziquantel', 'Praziquantel resistance', 'Protocols documentation', 'Publishing', 'Research', 'Risk', 'Robotics', 'San Francisco', 'Schistosoma mansoni', 'Schistosome Parasite', 'Schistosomiasis', 'Screening procedure', 'Shapes', 'Staging', 'Stifle joint', 'System', 'Techniques', 'Technology', 'Texture', 'Therapeutic', 'Thick', 'Time', 'Tropical Disease', 'Universities', 'World Health Organization', 'assay development', 'base', 'chemotherapy', 'computerized tools', 'design', 'drug development', 'drug discovery', 'high throughput screening', 'neglect', 'novel', 'pre-clinical', 'programs', 'protocol development', 'public health relevance', 'response', 'skills', 'social', 'success', 'tool', 'transmission process']",NIAID,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2010,494669,-0.015927019809355087
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,7941984,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Animals', 'Area', 'Arts', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'phase 1 study', 'programs', 'public health relevance', 'validation studies', 'vector']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2010,303186,-2.9224635111742023e-05
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): Flow cytometry is used to rapidly gather large quantities of data on cell type and function. The manual process of classifying hundreds of thousands of cells forms a bottleneck in diagnostics, high-throughput screening, clinical trials, and large-scale research experiments. The process currently requires a trained technician to identify populations on a digital graph of the data by manually drawing regions. As the complexity of the data increases, this gating task becomes more lengthy and laborious, and it is increasingly clear that minimizing human processing is essential to increasing both throughput and consistency. In clinical tests and diagnostic environments, automated gating would eliminate a complex set of human instructions and decisions in the Standard Operating Procedure (SOP), thereby reducing error and speeding results to the doctor. In many cases, the software will be able to recognize the need for additional tests before the doctor has an opportunity to look at the first report. Currently no software is available to perform complex multi-parameter analyses in an automated and rigorously validated manner. FlowDx will fill an important gap in the evolution of the technology and pave the way for ever larger phenotypic studies and for the translation of this research process to a clinical environment. Specific Aims 1) Fully define the experimental protocol, whereby a researcher can compare two or more classifications of identical data sets to study the differences, biases and effectiveness of human and algorithmic classifiers. 2) Describe and evaluate metrics that compare the performance of classification algorithms. 3) Conduct analytical experiments on our identified use cases, illustrating the potential of this technique to affect clinical analysis. 4) Iteratively implement the tools to automate these experiments, improve the experimental capabilities, and collaborate in new use cases. These aims will be satisfied while maintaining quantitative standards of software quality, establishing measurements in system uptime, throughput and robustness to set the baseline for subsequent iterations.      PUBLIC HEALTH RELEVANCE: FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project 1) Fits the ""translational medicine"" model of the NIH Roadmap 2) Reduces error in the diagnosis of cancer and other diseases 3) Speeds results to physicians. Patients learn the outcome more quickly. Therapeutic intervention is faster. 4) Accommodates large-scale research by allowing greater volumes of complex data to be much more quickly examined, compared, and quantified 5) Reduces the expense of cell analysis by as much as 50% 6) Conforms to 21CFR Part 11 guidance           Narrative FlowDx, a Clinical Cytometry Analysis Software Project is designed to create a new, more efficient, and more effective way of analyzing cells for the presence of cancer, HIV/ AIDS, and other diseases, using a fully automated software system. Using Magnetic Gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural Networks, and Support Vector Machines (SVM), Tree Star software will analyze the cell samples from patients at a much faster rate and with fewer false positives and negatives than the manual method now in use. The FlowDx Project  � Fits the ""translational medicine"" model of the NIH Roadmap  � Reduces error in the diagnosis of cancer and other diseases  � Speeds results to physicians. Patients learn the outcome more quickly.  Therapeutic intervention is faster.  � Accommodates large-scale research by allowing greater volumes of complex data  to be much more quickly examined, compared, and quantified  � Reduces the expense of cell analysis by as much as 50%  � Conforms to 21CFR Part 11 guidance",Clinical Cytometry Analysis Software with Automated Gating,7999420,R44RR024094,"['Acquired Immunodeficiency Syndrome', 'Affect', 'Algorithms', 'Architecture', 'Authorization documentation', 'Automation', 'Biological Assay', 'Biological Neural Networks', 'Biomedical Research', 'Cells', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Cluster Analysis', 'Code', 'Complex', 'Computer software', 'Computers', 'Consensus', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Documentation', 'Effectiveness', 'Environment', 'Evolution', 'Flow Cytometry', 'Foundations', 'Graph', 'Grouping', 'HIV', 'Hospitals', 'Human', 'Institution', 'Instruction', 'Label', 'Language', 'Learning', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Medical center', 'Methods', 'Metric', 'Modeling', 'Outcome', 'Patients', 'Performance', 'Physicians', 'Population', 'Probability', 'Procedures', 'Process', 'Protocols documentation', 'Quality Control', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Security', 'Services', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Trees', 'United States National Institutes of Health', 'Universities', 'Work', 'abstracting', 'cancer diagnosis', 'cell type', 'commercial application', 'data integrity', 'design', 'digital', 'encryption', 'high throughput screening', 'improved', 'operation', 'patient privacy', 'public health relevance', 'repository', 'research study', 'response', 'software systems', 'technological innovation', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R44,2010,449663,-0.016320205313207353
"Computational Photography Project for Pill Identification (C3PI) In a national effort to promote patient safety, the National Library of Medicine (NLM) proposes to create a comprehensive, public digital image inventory of the nation's commercial prescription solid dose medications. The primary intention of this effort is create a test data collection for the advancement of automatic pharmaceutical identification through computer analysis from photographic data. NLM expects to promote computer-based image research applied to the domain of content-based information retrieval (CBIR) of solid-dose pharmaceuticals, and anticipates the need for generating a test environment, including variations of photographs of the same drug or sample under different environments. n/a",Computational Photography Project for Pill Identification (C3PI),8174192,76201000698P,"['Algorithms', 'Collection', 'Color', 'Computer Analysis', 'Computer Vision Systems', 'Computers', 'Data', 'Data Collection', 'Dose', 'Environment', 'Equipment', 'Equipment and supply inventories', 'Image', 'Imagery', 'Information Retrieval', 'Intention', 'Measurement', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Photography', 'Research', 'Resolution', 'Sampling', 'Shapes', 'Solid', 'Structure', 'Surface Properties', 'Testing', 'Text', 'United States National Library of Medicine', 'Variant', 'base', 'digital imaging', 'patient safety', 'pill']",NLM,"MEDICOS CONSULTANTS, LLC",N03,2010,500000,0.0019455779945732076
"Center for Nanobiology and Predictive Toxicology    DESCRIPTION (provided by applicant):  The Center for Nanobiology and Predictive Toxicology has assembled a multidisciplinary team with expertise in nanomaterial science, toxicology, cell biology, high throughput screening, biostatistics, mathematics and computer science with the overall goal of gaining fundamental understanding of how the physical and Chemical properties of carefully selected ENM libraries relate to interactions with cells and cellular structures, including how these bio-physicochemical interactions at the nano-bio interface may lead to pulmonary toxicity. This goal will be executed through the acquisition, synthesis and characterization of compositional and combinatorial ENM libraries that focus on the major physicochemical properties of nominated metal, metal oxide and silica nanoparticles {Scientific Core), hypothesized to play a role in pulmonary toxicity through the generation of oxidative stress, inflammation, signal pathway activation and membrane lysis. These efforts will be assisted by in silico modeling that use heatmaps, mathematical models and machine learning to perform hazard ranking and risk prediction. The major objectives of the Center are: (i) To establish an overarching predictive toxicological paradigm, which is defined as the assessment of in vivo toxic potential of ENM based on in vitro and in silico methods (integrated center effort); (ii) To establish rapid throughput cellular screening and conduct imaging to identify compositional and combinatorial ENM properties that lead to bioavailability and engagement of the injury pathways discussed above (Project 1); (iii) To establish through the performance of instillation and inhalation exposures in the rodent lung how the structure-property relationships linking ENM to in vitro injury mechanisms may be predictive of pulmonary inflammation, fibrosis and cytotoxicity in a dose-dependent fashion (Project 2); (iv) To develop in silico toxicity models that utilize multivariate analysis of the rapid throughput screening and cellular imaging data to show the relationships that can be used to develop ""nano-QSARs"" for probabilistic risk ranking (Project 3).        We propose a center to study how properties of engineered nanomaterials may lead to lung health effects by creating harmful interactions in cells and tissues that will come into contact with these materials. This will be accomplished by a multi-disciplinary team who will use their expertise in nanomaterial science, biology, toxicology, imaging, statistics and computer science to integrate above goals into a predictive model that projects from what is happening in cells to what may happen in the lung.",Center for Nanobiology and Predictive Toxicology,8016739,U19ES019528,[' '],NIEHS,UNIVERSITY OF CALIFORNIA LOS ANGELES,U19,2010,1144284,-0.02353623117659017
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7936871,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost', 'digital imaging', 'image archival system', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2010,805328,0.009535499703550472
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7560409,R01NS051826,"['Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Back', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Development', 'Disease', 'Disease Progression', 'Evaluation', 'Fetal Growth Retardation', 'Goals', 'Gold', 'Human', 'Image', 'Imagery', 'Intuition', 'Knowledge', 'Learning', 'Machine Learning', 'Measures', 'Medical', 'Methods', 'Modeling', 'Neonatal', 'Normal Range', 'Operative Surgical Procedures', 'Patients', 'Population', 'Population Study', 'Process', 'Research', 'Schizophrenia', 'Shapes', 'Statistical Distributions', 'Structure', 'System', 'Techniques', 'Testing', 'Training', 'Variant', 'base', 'computer studies', 'disease classification', 'feeding', 'improved', 'neonate', 'nervous system disorder', 'normal aging', 'novel', 'shape analysis', 'tool']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2009,280500,-0.0044530889883200595
"Clinical Image Retrieval: User needs assessment, toolbox development & evaluation    DESCRIPTION (provided by applicant):       Advances in digital imaging technologies have led to a substantial growth in the number of digital images being created and stored in hospitals, medical systems, and on the Internet in recent years. Effective medical image retrieval systems can play an important role in teaching, research, diagnosis and treatment. Images were historically retrieved using text-based methods. The quality of annotations associated with images can reduce the effectiveness of text-based image retrieval. Despite recent advances, purely content- based image retrieval techniques lag significantly behind their textual counterparts in their ability to capture the semantic essence of the user's query. Preliminary research suggests that a more promising approach is to adaptively combine these complementary techniques to suit the user and their information needs. However, for these approaches to succeed, the researcher needs to enhance her computational skills in addition to acquiring a comprehensive understanding of the relevant clinical domain. This Pathway to Independence (K99/R00) grant application describes a training and career development plan that will allow the candidate, an NLM postdoctoral fellow in Medical Informatics at Oregon Health & Science University to achieve these objectives. The training component will be carried out under the mentorship of Dr. W. Hersh with Dr. Gorman (user studies). Dr. Fuss (radiation medicine) and Dr. Erdogmus (machine learning) providing additional mentoring in their areas of expertise.       The long-term goal of this Pathway to Independence (K99/R00) project is to improve visual information retrieval by better understanding user needs and proposing adaptive methodologies for multimodal image retrieval that will close the semantic gap. During the award period, activities will be focused on the following specific aims: (1) Understand the image retrieval needs of novice and expert users in radiation oncology and develop gold standards for evaluation; (2) Develop algorithms for semantic, multimodal image retrieval; (3) Perform user based evaluation of adaptive image retrieval in radiation oncology; (4) Extend the techniques developed to create a multimodal image retrieval system in pathology          n/a","Clinical Image Retrieval: User needs assessment, toolbox development & evaluation",7739714,K99LM009889,"['Accounting', 'Address', 'Affinity', 'Algorithms', 'Anatomy', 'Applications Grants', 'Archives', 'Area', 'Arts', 'Award', 'Back', 'Characteristics', 'Clinical', 'Communication', 'Communities', 'Computer software', 'Data', 'Development', 'Development Plans', 'Diagnosis', 'Diagnostic Imaging', 'Diffusion', 'Distance Learning', 'Education', 'Educational process of instructing', 'Effectiveness', 'Evaluation', 'Feedback', 'Goals', 'Gold', 'Growth', 'Head and Neck Cancer', 'Health Sciences', 'Healthcare', 'Hospitals', 'Image', 'Image retrieval system', 'Imaging technology', 'Information Retrieval', 'Institutes', 'Internet', 'Interview', 'Judgment', 'Learning', 'Libraries', 'Link', 'Lung', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Measures', 'Medical', 'Medical Imaging', 'Medical Informatics', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Metric System', 'Modeling', 'Multimodal Imaging', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Needs Assessment', 'Online Systems', 'Ontology', 'Oregon', 'Output', 'Participant', 'Pathology', 'Pathology Report', 'Pathway interactions', 'Patients', 'Performance', 'Play', 'Postdoctoral Fellow', 'Principal Investigator', 'Process', 'Property', 'Quality Control', 'Radiation', 'Radiation Oncology', 'Recruitment Activity', 'Reporting', 'Research', 'Research Personnel', 'Retrieval', 'Role', 'Semantics', 'Site', 'Staging', 'Structure', 'Students', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Text', 'Training', 'United States National Institutes of Health', 'Universities', 'Visual', 'Vocabulary', 'Work', 'Writing', 'base', 'biomedical informatics', 'cancer site', 'care delivery', 'career development', 'data mining', 'digital imaging', 'experience', 'follow-up', 'image processing', 'improved', 'meetings', 'oncology', 'open source', 'satisfaction', 'skills', 'success', 'tool', 'treatment planning', 'visual information']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,K99,2009,104963,0.018695566067959184
"Integrating Quantitative Histological Image and Vascular Density Patterns for Pro    DESCRIPTION (provided by applicant):       With increasing detection of early CaP with improved diagnostic methodologies, it has become important to predict biologic behaviors and ""aggressivity"" to identify patients who might benefit from a ""wait and watch policy"" as opposed to those who need more aggressive strategies. Traditionally, T-stage, amount of cancer in the core biopsy, the Gleason grade, and PSA at diagnosis has been used to evaluate the prognosis in localized CaP. While the Gleason score is currently assumed to be the strongest prognostic marker for CaP, there is often considerably high inter-, intra-observer variability associated with Gleason grade determination by pathologists. While some newer markers have recently shown promise, none of these methods have individually proven to be accurate enough to serve routinely as a prognostic marker for CaP.  Recently, there has been a call to combine multiple prognostic markers to create an integrated meta-marker, with potentially greater accuracy in predicting CaP recurrence compared to any individual marker. While it is apparent that prognostic information resides in histopathology imagery in terms of the arrangement of nuclei and glands, sophisticated graph, and computerized image analysis algorithms are required to quantitatively model and characterize the architectural appearance of prostate cancer histopathology and thus provide a marker that is accurate and reproducible (unlike Gleason grade). In addition, while tumor micro-vascular density has been correlated to CaP outcome, prognostic information may also potentially reside in the specific spatial architectural arrangement of the micro-vascular network. The objective of the proposed work is to develop an integrated quantitative prognostic marker that combines information based on architectural arrangement of nuclear, glandular, and micro-vasculature network patterns on whole mount histology sections (WMHS) obtained via radical prostatectomy (RP) to predict prostate cancer recurrence.  The proposed work comprises a total of 3 specific aims. For this project we will digitize approximately 100 annonymized WMHS obtained via RP that have been matched for Gleason score, stage, PSA, but with different clinical outcomes (half the patients having undergone cancer recurrence and the other not, following RP). Under Aim 1, segmentation algorithms will be developed to automatically identify cancerous nuclei, glands and tumor microvasculature (MV), stained immuno-histochemically via CD31. Under Aim 2 we will apply graph based image analysis algorithms to quantitatively characterize the architectural arrangement of CaP nuclei, glands and the MV network. These graph-based features will be integrated via a computerized machine learning algorithm to yield a numerical image based risk score (IbRiS) reflecting the CaP prognosis (disease recurrence or non-recurrence) of the patient. IbRiS will be evaluated in terms of its ability to distinguish between CaP progressors and non-progressors (matched for stage, Gleason grade, PSA), in a cohort of 50 independent studies (test set) for which survival and outcome data is available.  This project will be a collaboration between investigators at Rutgers University (RU) and the University of Pennsylvania (UPENN). Data accrual will be done at UPENN while algorithmic development for computerized image analysis and classification will be carried out at RU.             The broad long term goal of this project is to develop an integrated image based histological biomarker for  predicting  prostate  cancer  (CaP)  survival  and  outcome  by  integrating  quantitative  image  signatures  that  define  tissue  architecture  and  vascular  density  patterns.  Sophisticated  image  analysis  and  graph  based  algorithms will be developed to yield an image based risk score (IbRis) to predict whether or not a CaP patient  will  have  disease  recurrence  following  treatment.  Our  hypothesis  is  that  IbRis  will  prove  to  be  a  better  prognostic marker compared to such traditional markers as Gleason score and PSA.   ",Integrating Quantitative Histological Image and Vascular Density Patterns for Pro,7792785,R03CA143991,"['Algorithms', 'Appearance', 'Architecture', 'Area', 'Behavior', 'Biological Markers', 'Blood Vessels', 'Cancerous', 'Cell Nucleus', 'Classification', 'Clinical', 'Collaborations', 'Computers', 'Core Biopsy', 'Data', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'E-Cadherin', 'Early Diagnosis', 'Gland', 'Gleason Grade for Prostate Cancer', 'Goals', 'Graph', 'Histocytochemistry', 'Histology', 'Histopathology', 'Hospitals', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Individual', 'Intraobserver Variability', 'Learning', 'Machine Learning', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Nuclear', 'Outcome', 'Output', 'PECAM1 gene', 'Pathologist', 'Patients', 'Pattern', 'Pennsylvania', 'Policies', 'Prognostic Marker', 'Protocols documentation', 'Radical Prostatectomy', 'Randomized', 'Recurrence', 'Research', 'Research Personnel', 'Resolution', 'Risk', 'Scheme', 'Slide', 'Specimen', 'Staging', 'Staining method', 'Stains', 'Structure', 'TP53 gene', 'Testing', 'Tissues', 'Training', 'Tumor stage', 'Universities', 'Validation', 'Work', 'base', 'cancer recurrence', 'cohort', 'computerized', 'density', 'digital', 'imaging Segmentation', 'improved', 'novel marker', 'outcome forecast', 'prognostic', 'repository', 'tumor', 'vector']",NCI,"RUTGERS, THE STATE UNIV OF N.J.",R03,2009,79576,-0.07003553914349751
"A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets    DESCRIPTION (provided by applicant):       A decade ago when microarray was first invented, it was hailed as ""an array of hope"" in Nature Genetics and has received a considerable amount of attention in biomedicine. Subsequently it has been called ""an array of problems"" in Nature Review. An inherent problem with microarray gene expression is that structural information is missing, which limits its ability in biological discovery. To overcome the poor reproducibility and accuracy of microarray imaging, there needs to be a shift in fundamental paradigms to those able to incorporate complementary and multiscale structural imaging information into microarray imaging. Fortunately, the latest progress in high resolution biomolecular imaging probe development coupled with advanced image analysis makes integrative and systematic studies of cellular systems possible. A cell can be labeled using multiscale and multimodality imaging, providing both structural and functional information. With multiscale imaging spreadsheets now available, there is an overwhelming need within the life sciences community to manage this information effectively, to analyze it comprehensively, and to apply the resulting knowledge in the understanding of the genetic system of a cell. However, the management and mining of this large-scale imaging information is limited by today's computational approaches and knowledge-sharing infrastructure. These problems represent a major impediment to progress in the emerging area of bio-molecular image informatics. Therefore, the goal of this project is to develop a unique genomic image management and mining system that can allow geneticists to search, correlate and integrate this multiscale and multi-modality imaging information in an easily operable fashion and further enable new biological discovery. In particular, this system will fill a void left in the current image database systems such as Open Microscope Environment (OME), e.g., the lack of analytic tools for integrative data analysis. To realize this goal, we are bringing together a strong interdisciplinary team consisting of imaging engineers, geneticists and industrial imaging scientists. Building on our diverse and complementary expertise, we are able to provide innovative and interdisciplinary approaches that combine the latest progress in image processing, imaging database design and machine learning with the development of high resolution and high throughput molecular imaging probes in genomics. More specifically, we will accomplish the following specific aims. First, we will develop a suite of algorithms for content extraction and information retrieval from high resolution fluorescence in situ hybridization (FISH) images. This visual system will effectively manage imaging phenotype information, facilitating knowledge discovery such as identifying visually similar subtypes. Second, we will correlate quantitative traits extracted from FISH imaging with genomic structural rearrangements and gene expression patterns. Finally, we will develop a data integration approach to fuse disparate information from multi-modality imaging databases for improved characterization of biological systems.               Public Health Relevance Statement The anticipated outcome of the project will include a publicly accessible imaging database analysis system to facilitate multiscale genomic image information integration and knowledge mining. The proposed approach challenges the current paradigm by the integration of high resolution structural imaging with functional information, which promises to overcome the poor accuracy and reproducibility problems plagued with microarray imaging. Given the ubiquitous use of microarray imaging in biomedicine, the project is thus expected to be of great impact on the biomedical community.",A New Paradigm for Integrated Analysis of Multiscale Genomic Imaging Datasets,7641582,R21LM010042,"['Address', 'Affect', 'Algorithms', 'Area', 'Attention', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biological Models', 'Biological Sciences', 'Biology', 'Blast Cell', 'Cells', 'Chromosome abnormality', 'Classification', 'Comb animal structure', 'Communities', 'Complex', 'Computational Biology', 'Coupled', 'DNA Sequence', 'DNA Sequence Rearrangement', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Environment', 'Exhibits', 'Fluorescent in Situ Hybridization', 'Functional Imaging', 'Gene Expression', 'Genetic', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human Genome', 'Hybridization Array', 'Image', 'Image Analysis', 'Informatics', 'Information Retrieval', 'Karyotype', 'Knowledge', 'Label', 'Lead', 'Left', 'Machine Learning', 'Malignant Neoplasms', 'Medicine', 'Microscope', 'Mining', 'Modality', 'Molecular', 'Nature', 'Organ', 'Organism', 'Outcome', 'Pattern', 'Phenotype', 'Plague', 'Prevention', 'Reproducibility', 'Research', 'Research Infrastructure', 'Resolution', 'Retrieval', 'Scientist', 'Specimen', 'Staging', 'System', 'Systems Analysis', 'Systems Biology', 'Tissues', 'United States National Institutes of Health', 'Variant', 'Visual', 'Visual system structure', 'Work', 'base', 'bioimaging', 'biological systems', 'complex biological systems', 'data integration', 'database design', 'disease diagnosis', 'disorder prevention', 'gene function', 'genome sequencing', 'image processing', 'imaging informatics', 'imaging modality', 'imaging probe', 'improved', 'innovation', 'interdisciplinary approach', 'knowledge of results', 'molecular imaging', 'multimodality', 'mutant', 'public health relevance', 'structural genomics', 'tool', 'trait', 'visual map']",NLM,UNIVERSITY OF MISSOURI KANSAS CITY,R21,2009,219972,0.03826281994408961
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7582301,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool', 'working group']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2009,2057843,0.011613976352124066
"Accurate detection of chromosomal abnormalities with multi-color image processing    DESCRIPTION (provided by applicant): The combination of high resolution assays in genomics with microscopic imaging has been used for the detection of complex chromosomal rearrangements, a significant but difficult problem in prenatal and postnatal diagnosis, birth defect detection and cancer research. As a recently developed molecular cytogenetic technique, multiplex fluorescence in situ hybridization (M-FISH) imaging has provided rapid and high resolution detection of chromosomal abnormalities associated with cancer and genetic disorders. However, the technique is currently limited to research use and only serves as an adjunct tool to the G-banding based monochromatic chromosomal karyotyping in a clinical laboratory. A primary barrier of the technique is the lower classification accuracy when classifying chromosomes from multi-color microscopic imaging data. Therefore, the goal of this R15 project is to develop innovative multi-spectral image processing and machine learning techniques for M-FISH image analysis so that chromosomal rearrangement detection can be made more reproducible, robust, and faster, thereby significantly increasing the ability and efficacy of this newly developed cellular imaging technique. Our proposed approaches such as multiscale feature extraction, nonlinear manifold analysis and adaptive fuzzy clustering are able to target specific features of multi-spectral imaging data, promising a significant improvement over the current techniques. In order to validate the technique and bring it into clinical use, we will partner with a clinical geneticist, Dr. Merlin Butler, and a cytogeneticist, Dr. Diane Persons both at Kansas University Medical Center. In addition, we will collaborate with an industrial scientist, Dr. Kenneth Castleman, who is the pioneer in developing and commercializing cytogenetic imaging products. Through our interdisciplinary research and collaboration, we will accomplish the following specific aims: 1) develop image normalization approaches to improve the acquisition of multi-color FISH images; 2) develop multiscale dimension analysis to extract features from multi-color images; 3) design adaptive fuzzy clustering and incorporate contextual information to improve the pixel-wise classification of chromosomes; and 4) validate computational approaches with clinical testing in collaboration with medical and industrial partners. This research project will also enhance our research infrastructure in biomedical image informatics and provide undergraduate and graduate students opportunities to touch the frontier of molecular and cellular imaging by participating in the proposed research activities. PUBLIC HEALTH RELEVANCE: Unraveling complex rearrangements using cytogenetic approaches such as M-FISH imaging has been extremely useful in prenatal, postnatal and cancer diagnoses. Our proposed approaches have the potential to significantly improve the reliability of the newly developed M-FISH imaging technique, making it feasible for clinical use. This will in turn benefit the health of human beings. Furthermore, the developed computational techniques can be applicable to a wide range of multi-color bio-imaging problems, thereby having a broad impact on the biomedical community.           Project Narrative Unraveling complex rearrangements using cytogenetic approaches such as M-FISH imaging has been extremely useful in prenatal, postnatal and cancer diagnoses. Our proposed approaches have the potential to significantly improve the reliability of the newly developed M-FISH imaging technique, making it feasible for clinical use. This will in turn benefit the health of human beings. Furthermore, the developed computational techniques can be applicable to a wide range of multi-color bio-imaging problems, thereby having a broad impact on the biomedical community.",Accurate detection of chromosomal abnormalities with multi-color image processing,7727717,R15GM088802,"['Academic Medical Centers', 'Academic Research Enhancement Awards', 'Address', 'Algorithms', 'Biological Assay', 'Cells', 'Chromosomal Rearrangement', 'Chromosome abnormality', 'Chromosomes', 'Chromosomes, Human, Pair 4', 'Cities', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Color', 'Communities', 'Complex', 'Computational Technique', 'Congenital Abnormality', 'Cytogenetic Analysis', 'Cytogenetics', 'DNA Sequence Rearrangement', 'Data', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Dimensions', 'Engineering', 'Environment', 'Figs - dietary', 'Fluorescent in Situ Hybridization', 'G-Banding', 'Genetic', 'Genomics', 'Goals', 'Health Benefit', 'Hereditary Disease', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Imaging problem', 'Interdisciplinary Study', 'Kansas', 'Karyotype', 'Karyotype determination procedure', 'Laboratories', 'Learning', 'Machine Learning', 'Masks', 'Medical', 'Methods', 'Microscopic', 'Missouri', 'Molecular Probes', 'Neurofibromin 2', 'Patients', 'Persons', 'Research', 'Research Activity', 'Research Infrastructure', 'Research Project Grants', 'Resolution', 'Resources', 'Schools', 'Scientist', 'Signal Transduction', 'Spectral Karyotyping', 'Techniques', 'Technology', 'Time', 'Touch sensation', 'Training', 'United States National Institutes of Health', 'Universities', 'anticancer research', 'assay development', 'base', 'bioimaging', 'cancer diagnosis', 'cancer genetics', 'cellular imaging', 'clinical application', 'clinical effect', 'design', 'experience', 'frontier', 'graduate student', 'high throughput screening', 'image processing', 'imaging informatics', 'improved', 'innovation', 'leukemia', 'meetings', 'molecular/cellular imaging', 'multidisciplinary', 'novel', 'postnatal', 'prenatal', 'prevent', 'programs', 'public health relevance', 'research clinical testing', 'response', 'tool']",NIGMS,UNIVERSITY OF MISSOURI KANSAS CITY,R15,2009,229519,0.01476783879954208
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",7664924,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Java', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'Structure', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2009,225323,-0.013922011263367425
"National Alliance-Medical Imaging Computing (NAMIC)(RMI) The National Alliance for Medical Imaging Computing (NAMIC) is a multiinstitutional, interdisciplinary team of  computer scientists, software engineers, and medical investigators who develop computational tools for the  analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure  and environment for the development of computational algorithms and open source technologies, and then  oversee the training and dissemination of these tools to the medical research community. This world-class  software and development environment serves as a foundation for accelerating the development and  deployment of computational tools that are readily accessible to the medical research community. The team  combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state  of the art software engineering techniques (based on ""extreme"" programming techniques in a distributed,  open-source environment) to enable computational examination of both basic neurosience and neurologicat  disorders. In developing this infrastructure resource, the team will significantly expand upon proven open  systems technology and platforms. The driving biological projects will come initially from the study of  schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open  systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures  and connectivity patterns in the brain, derangements of which have long been thought to play a role in the  etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range  of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially  including microscopic, genomic, and other image data. It will apply to image data from individual  )atients,and to studies executed across large poplulations. The data will be taken from subjects across a  Nide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs. n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7915998,U54EB005149,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Area', 'Arts', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Data', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Environment', 'Etiology', 'Foundations', 'Functional disorder', 'Genomics', 'Goals', 'Healthcare', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Life', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Morphology', 'Neurons', 'Organ', 'Patients', 'Pattern', 'Physiological', 'Play', 'Population', 'Positron-Emission Tomography', 'Process', 'Property', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Software Engineering', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Time', 'Tissues', 'Training', 'Visible Radiation', 'Vision', 'Vision research', 'Work', 'base', 'computerized tools', 'cost', 'disability', 'egg', 'insight', 'mathematical model', 'neuroimaging', 'open source', 'programs', 'receptor', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2009,3720664,0.055003853900926665
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7850408,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'discount', 'drug discovery', 'empowered', 'fluorescence imaging', 'genome-wide', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,R01,2009,26557,-0.009809337408150348
"A Fully Automatic System For Verified Computerized Stereoanalysis    DESCRIPTION (provided by applicant):  A Fully Automatic System For Verified Computerized Stereoanalysis SUMMARY The requirement for a trained user to interact with tissue and images is a long-standing impediment to higher throughput analysis of biological microstructures using unbiased stereology, the state-of-the-art method for accurate quantification of biological structure. Phase 1 studies addressed this limitation with Verified Computerized Stereoanalysis (VCS), an innovative approach for automatic stereological analysis that improves throughput efficiency by 6-9 fold compared to conventional computerized stereology. Work in Phase 2 integrated VCS into the Stereologer"", an integrated hardware-software-microscopy system for stereological analysis of tissue sections and stored images. Validation studies of first-order stereological parameters. i.e., volume, surface area, length, number, confirmed that the color-based detection methods in the VCS approach achieve accurate results for automatic stereological analysis of high S:N biological microstructures. These studies indicate that fully automatic stereological analysis of tissue sections and stored images can be realized by elimination of two remaining barriers, which will be addressed in this Phase II Continuation Competing Renewal. In Aim 1, applications for feature extraction and microstructure classification, developed in part with funding from the Office of Naval Research, will be integrated into the VCS program. The new application (VCS II) will use these approaches to automatically detect and classify polymorphic microstructures of biological interest using a range of feature calculations, including size, color, border, shape, and texture, with support from active learning and Support Vector Machines. Work in Aim 2 will eliminate physical handling of glass slides during computerized stereology studies by equipping the Stereologer system with automatic slide loading/unloading technology controlled by the Stereologer system. This technology will approximately double the throughput efficiency of the current VCS program and support ""human-in-the-loop"" interaction for sample microstructures on the border between two or more adjacent classes. The studies in Aim 3 will rigorously test the hypothesis that fully automatic VCS can quantify first- and second-order stereological parameters, without a loss of accuracy compared to the current gold-standard - non-automatic computerized stereology, e.g., manual Stereologer. If these studies validate the accuracy of VCS II, then commercialization of the fully automatic program will facilitate the throughout efficiency for testing scientific hypotheses in a wide variety of biomedical research projects; reduce labor costs for computerized stereology studies; hasten the growth of our understanding of biological processes that underlie health, longevity, and disease; and accelerate the development of novel approaches for the therapeutic management of human disease. Solid evidence that the SRC and its strategic partners can effectively commercialize this technology is demonstrated by their worldwide sales and support of the Stereologer system for the past 13 years. Key personnel and participating institutions: 7 Peter R. Mouton, Ph.D. (PI), Stereology Resource Center, Chester, MD. 7 Dmitry Goldgof, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Larry Hall, Ph.D., University of South Florida Coll. Engineering, Tampa, Fl. 7 Joel Durgavich, MS, Systems Planning and Analysis, Alexandria, VA. 7 Kurt Kramer, MS, Computer Programmer, University of South Florida, Coll. Engineering, Tampa, Fl. 7 Michael E. Calhoun, Ph.D., Sinq Systems, Columbia, MD        PUBLIC HEALTH RELEVANCE: Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.           PROJECT NARRATIVE Many fields of scientific research require a trained expert to make tedious and repetitive measurements of microscopic changes in animal and human tissues. This project will produce a computer program that performs these measurements with equal accuracy to a trained expert, but with dramatic savings in time and costs. Allowing scientists to complete more research in less time will accelerate our understanding of the factors that promote health and longevity, and hasten progress toward the development of new treatments for human diseases.",A Fully Automatic System For Verified Computerized Stereoanalysis,7804332,R44MH076541,"['Active Learning', 'Address', 'Algorithms', 'Animals', 'Area', 'Arts', 'Biological', 'Biological Process', 'Biomedical Research', 'Blood capillaries', 'Cell Volumes', 'Classification', 'Color', 'Communities', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Databases', 'Detection', 'Development', 'Disease', 'Doctor of Philosophy', 'Educational workshop', 'Engineering', 'Florida', 'Funding', 'Glass', 'Goals', 'Gold', 'Grant', 'Growth', 'Health', 'Histology', 'Human', 'Human Resources', 'Image', 'Institution', 'International', 'Length', 'Libraries', 'Longevity', 'Machine Learning', 'Manuals', 'Marketing', 'Measurement', 'Methodology', 'Methods', 'Microscopic', 'Microscopy', 'Noise', 'Performance', 'Phase', 'Phase I Clinical Trials', 'Probability', 'Research', 'Research Project Grants', 'Resources', 'Sales', 'Sampling', 'Savings', 'Scientist', 'Shapes', 'Signal Transduction', 'Slide', 'Small Business Innovation Research Grant', 'Solid', 'Staining method', 'Stains', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Texture', 'Therapeutic', 'Time', 'Tissue Stains', 'Tissues', 'Training', 'United States National Institutes of Health', 'Universities', 'Update', 'Vendor', 'Work', 'base', 'capillary', 'commercialization', 'computer program', 'computerized', 'cost', 'digital imaging', 'high throughput analysis', 'human disease', 'human tissue', 'improved', 'innovation', 'interest', 'novel strategies', 'novel therapeutic intervention', 'programs', 'public health relevance', 'validation studies', 'vector']",NIMH,"STEREOLOGY RESOURCE CENTER, INC.",R44,2009,363247,-2.9224635111742023e-05
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7563977,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug candidate', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2009,355016,0.015476702635257253
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7686733,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Structure', 'Surface', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'clinical care', 'computerized', 'cost', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2009,819428,0.009535499703550472
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7351765,R01NS051826,"['Affect', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Anatomy', 'Area', 'Back', 'Class', 'Computer Simulation', 'Computer Vision Systems', 'Data', 'Development', 'Diffuse Pattern', 'Disease', 'Disease Progression', 'Evaluation', 'Fetal Growth Retardation', 'Goals', 'Gold', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Intuition', 'Knowledge', 'Learning', 'Localized', 'Machine Learning', 'Measurement', 'Measures', 'Medical', 'Medical Research', 'Methods', 'Modeling', 'Morphology', 'Neonatal', 'Neuroanatomy', 'Normal Range', 'Operative Surgical Procedures', 'Pathology', 'Patients', 'Population', 'Population Study', 'Process', 'Range', 'Research', 'Schizophrenia', 'Shapes', 'Standards of Weights and Measures', 'Statistical Distributions', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'base', 'computer studies', 'desire', 'disease classification', 'feeding', 'imaging Segmentation', 'improved', 'neonate', 'nervous system disorder', 'neurosurgery', 'normal aging', 'novel', 'shape analysis', 'tool']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2008,281588,-0.0044530889883200595
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7367958,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'Work', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2008,2037396,0.011613976352124066
"Heterogeneous in situ data: Kernals, Distances and Trees    DESCRIPTION (provided by applicant): This project aims to provide biologists with new tools to help them understand complex systems for which they have different sources of heterogeneous 'in situ' data. These data present many levels of heterogeneity and come concurrently with spatio-temporal and prior information that need to be incorporated into integrated data structures.  This collaboration starts with the design of the collection process and provides tools for data integration and analysis written around the statistics package R and an interactive image analysis program GEMEDENT written in JAVA.  The project concentrates on two specific types of heterogeneous data: metagenomic data and sequence mixtures provided by the new pyrosequencing machines and cell image data provided by automated microscopes.  The first type of heterogeneous data are microbial soil sample data collected by Alfred Spormann from Civil and Environmental Engineering at Stanford. The proposal focuses on applying Bayesian computations in the design of sample locations and number of sequences collected and then using spectral multivariate methods to analyze diversity indices as tables (instead of summaries), thus incorporating the data structure into the decompositions. These methods will also be useful in the study of mixture data from pyrosequencing HIV, bacteria, viruses and cancer cells.  The second study focuses on the interaction between immune cells and breast cancer in a collaboration with Peter Lee, hematologist at Stanford. We will analyze data from microscope images of stained lymph nodes. An integrated image analysis system enables the automatic detection of the location and size of many different cell types from stained images. Random forests have been incorporated into the image analysis system and an effective interactive boosting component provides the user with the possibility to iterate the learning process until a desired level of accuracy is attained. These data enable us to infer the spatial and dynamic interaction between the tumors and the immune cells. A postdoctoral fellow will be in charge of combining the cell data with the clinical history and the micro-array expression data from the same patient. The heterogeneity will be dealt with by using exploratory multivariate techniques based on spectral analysis, kernel methods and graphical representations.          n/a","Heterogeneous in situ data: Kernals, Distances and Trees",7596500,R01GM086884,"['Bacteria', 'Breast Cancer Cell', 'Cells', 'Charge', 'Clinical', 'Collaborations', 'Collection', 'Complex', 'Data', 'Data Analyses', 'Detection', 'Environmental Engineering technology', 'HIV', 'Hematologist', 'Heterogeneity', 'Image', 'Image Analysis', 'Immune', 'In Situ', 'Java', 'Learning', 'Location', 'Machine Learning', 'Metagenomics', 'Methods', 'Microscope', 'Numbers', 'Patients', 'Postdoctoral Fellow', 'Process', 'Recording of previous events', 'Sampling', 'Source', 'Staining method', 'Stains', 'System', 'Techniques', 'Trees', 'Virus', 'Writing', 'base', 'cancer cell', 'cell type', 'cellular imaging', 'data integration', 'data structure', 'design', 'desire', 'forest', 'indexing', 'lymph nodes', 'microbial', 'programs', 'size', 'soil sampling', 'statistics', 'tool', 'tumor']",NIGMS,STANFORD UNIVERSITY,R01,2008,225323,-0.013922011263367425
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7471355,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genome', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Numbers', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Rate', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'day', 'discount', 'drug discovery', 'fluorescence imaging', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,R01,2008,411777,-0.009809337408150348
"National Alliance-Medical Imaging Computing (NAMIC)(RMI) The National Alliance for Medical Imaging Computing (NAMIC) is a multiinstitutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state of the art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neurosience and neurologicat disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual )atients,and to studies executed across large poplulations. The data will be taken from subjects across a Nide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs. n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7688808,U54EB005149,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Area', 'Arts', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Class', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Data', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Environment', 'Etiology', 'Foundations', 'Functional disorder', 'Future', 'Genomics', 'Goals', 'Healthcare', 'Heart', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Life', 'Link', 'Localized', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Morphology', 'Neurons', 'Operative Surgical Procedures', 'Organ', 'Patients', 'Pattern', 'Physiological', 'Play', 'Polishes', 'Population', 'Positron-Emission Tomography', 'Principal Investigator', 'Process', 'Property', 'Purpose', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Services', 'Software Engineering', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Textiles', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'Visible Radiation', 'Vision', 'Vision research', 'Work', 'base', 'bioimaging', 'computerized tools', 'cost', 'disability', 'egg', 'insight', 'mathematical model', 'neuroimaging', 'open source', 'programs', 'receptor', 'response', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2008,100000,0.055003853900926665
"National Alliance-Medical Imaging Computing (NAMIC)(RMI) The National Alliance for Medical Imaging Computing (NAMIC) is a multiinstitutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state of the art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neurosience and neurologicat disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual )atients,and to studies executed across large poplulations. The data will be taken from subjects across a Nide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs. n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7688368,U54EB005149,"['Affect', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Area', 'Arts', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Class', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computational algorithm', 'Computer Vision Systems', 'Computers', 'Computing Methodologies', 'Data', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Elements', 'Environment', 'Etiology', 'Foundations', 'Functional disorder', 'Future', 'Genomics', 'Goals', 'Healthcare', 'Heart', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Life', 'Link', 'Localized', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Morphology', 'Neurons', 'Operative Surgical Procedures', 'Organ', 'Patients', 'Pattern', 'Physiological', 'Play', 'Polishes', 'Population', 'Positron-Emission Tomography', 'Process', 'Property', 'Purpose', 'Range', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Services', 'Software Engineering', 'Source', 'Structure', 'System', 'Techniques', 'Technology', 'Textiles', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'Visible Radiation', 'Vision', 'Vision research', 'Work', 'base', 'bioimaging', 'computerized tools', 'cost', 'disability', 'egg', 'insight', 'mathematical model', 'neuroimaging', 'open source', 'programs', 'receptor', 'response', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2008,50000,0.055003853900926665
"Detection of Drug Effects in Small Groups Using PET    DESCRIPTION (provided by applicant): The objective of this project is to develop optimized image analysis pipelines for pharmaceutical evaluation based on functional neuroimaging, in particular based on positron emission tomography (PET). Strength of drug effect will be assessed using statistical measures of detection power, reproducibility of spatial activation patterns, and regional power estimates. Spatial parametric images will be computed for each of the prediction models investigated. A wide range of predictive models, including many that are new to the functional neuroimaging field, will be implemented and evaluated within a sophisticated statistical resampling framework. A grid-aware software package will be developed based on the results obtained. This software is intended to be run in-house in a distributed computing environment at Predictek to provide state-of-the-art optimized image analysis services to its customers. A scaled-down user-friendly Java implementation of some of the best- performing methods (based on evaluations performed in the project) will also be developed for distribution to end users wishing to perform advanced analyses themselves. The proposed project is expected to yield significant research findings, in addition to augmenting Predictek's neuroimage analysis business.          n/a",Detection of Drug Effects in Small Groups Using PET,7405144,R44MH073204,"['Academia', 'Adverse effects', 'Aging', 'Anti-Anxiety Agents', 'Antidepressive Agents', 'Antipsychotic Agents', 'Arts', 'Biological Markers', 'Biology', 'Brain', 'Businesses', 'Central Nervous System Agents', 'Cerebrum', 'Code', 'Communities', 'Complex', 'Computer software', 'Condition', 'Data', 'Data Analyses', 'Data Set', 'Deoxyglucose', 'Detection', 'Development', 'Disease', 'Drug Industry', 'Effectiveness', 'Elements', 'Engineering', 'Environment', 'Evaluation', 'Functional Magnetic Resonance Imaging', 'Goals', 'Heart', 'Housing', 'Image', 'Image Analysis', 'Java', 'Journals', 'Learning', 'Letters', 'Licensing', 'Light', 'Literature', 'Machine Learning', 'Marketing', 'Measurable', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Metric', 'Modeling', 'Multivariate Analysis', 'Neuraxis', 'Numbers', 'Outcome', 'Oxybutynin chloride', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phase I Clinical Trials', 'Placebos', 'Play', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Progress Reports', 'Range', 'Reporting', 'Reproducibility', 'Research', 'Research Institute', 'Research Subjects', 'Role', 'Running', 'Savings', 'Services', 'Site', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Tools', 'Software Validation', 'Spatial Distribution', 'Techniques', 'Testing', 'Therapeutic Agents', 'Training', 'Universities', 'Urinary Incontinence', 'Variant', 'Work', 'base', 'cluster computing', 'cost', 'drug market', 'drug testing', 'experience', 'glucose metabolism', 'image processing', 'neuroimaging', 'predictive modeling', 'professor', 'success', 'tool', 'user friendly software', 'user-friendly', 'vector']",NIMH,"PREDICTEK, LLC.",R44,2008,394557,0.015476702635257253
"Clinical Cytometry Analysis Software with Automated Gating    DESCRIPTION (provided by applicant): The proposed Clinical Cytometry Analysis Software Project described in this grant application is designed to create a new, more efficient and effective way of analyzing cells for the presence of cancer, HIV/AIDS and other disease, using a fully automated software system. Using modern data mining techniques (pattern recognition, feature recognition, image analysis) we will design software which will analyze data (the cell samples from patients) at a much faster rate and with fewer false positives and negatives than the manual method now in use. Objectives: Assemble and validate algorithms in software that can automatically classify regions of interest in flow cytometry data. We will demonstrate that the particular populations required by our use cases can be validly, rigorously and repeatably identified automatically. Develop and validate graphical and statistical results that satisfy FDA requirements for medical device software, simplify regulatory compliance by the clinical user, and automatically deliver analysis results to diagnostic expert systems and/or LIMS systems. Satisfy the  translational medicine  goals outlined in the NIH Roadmap. This software will bring the clinician streamlined testing currently only available in research labs. Methods: Four use cases have been selected, one employing synthetic data and three clinical data; Leukemia/Lymphoma test, Analysis of longitudinal Graft vs. Host Disease (GvHD) in bone marrow transplant specimens for predictive markers and HIV/AIDS - Gag-specific T cell cytokine response profile assay. For each we have access to a substantial body of existing data, analyzed by experts. Beginning with the autogating routines in our own FlowJo software, we will test and expand the application of Magnetic gating, Probability Clustering, Subtractive Cluster Analysis, Artificial Neural and Support Vector Machines (SVM). Using a sampling of human operators to establish a control range, we will test each of these five techniques against the four use cases in cooperation with our collaborators. Events in the manually classified samples are given a weighted score based on the frequency with which they are included by all the operators. A single operator's score or the gating algorithm's score is compared with the cumulative score of the expert group and a match rating is computed. Additional validation techniques include combinatory validation on internal measures with respect to Pareto optimality, and Predictive Power/Stability self consistency checks using resampled or perturbed data measured with external indices such as the adjusted Rand index and the Variation of Information index.  PUBLIC HEALTH RELEVANCE: By eliminating the operator's time, we estimate that the cost of clinical flow cytometry analysis can be reduced to half the current figure while delivering the results much faster. By eliminating the subjectivity and human error of manually created regions and reducing the range of variability of the so created, there would result fewer false positives and false negatives, improving the clinical outcome for those patients needing therapy but undetected by current methods. An order of magnitude increase in speed means faster therapeutic intervention.  A less expensive test improves outcome by making the test accessible to more patients.          n/a",Clinical Cytometry Analysis Software with Automated Gating,7482923,R43RR024094,"['AIDS/HIV problem', 'Algorithms', 'Applications Grants', 'B-Lymphocytes', 'Biological Assay', 'Biological Neural Networks', 'Bone Marrow Transplantation', 'Cells', 'Characteristics', 'Class', 'Classification', 'Clinical', 'Clinical Data', 'Cluster Analysis', 'Complex', 'Computer software', 'Computer-Assisted Image Analysis', 'Computers', 'Cytometry', 'Data', 'Data Analyses', 'Data Files', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Educational process of instructing', 'Environment', 'Evaluation', 'Event', 'Expert Systems', 'Facility Construction Funding Category', 'Flow Cytometry', 'Frequencies', 'Funding', 'Future', 'Gagging', 'Generations', 'Goals', 'Grant', 'Graph', 'Human', 'Image Analysis', 'Individual', 'Instruction', 'Knowledge', 'Legal patent', 'Life Cycle Stages', 'Machine Learning', 'Magnetism', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measures', 'Medical', 'Medical Device', 'Methods', 'Metric', 'Modeling', 'Monitor', 'Noise', 'Numbers', 'Outcome', 'Output', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Phase', 'Population', 'Probability', 'Process', 'Public Health', 'Publishing', 'Range', 'Rate', 'Regulation', 'Reporting', 'Research', 'Sample Size', 'Sampling', 'Scientist', 'Score', 'Software Design', 'Software Engineering', 'Software Tools', 'Solutions', 'Specific qualifier value', 'Specimen', 'Speed', 'Standards of Weights and Measures', 'Structure', 'System', 'T-Lymphocyte', 'Target Populations', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Tube', 'United States Food and Drug Administration', 'United States National Institutes of Health', 'Update', 'Validation', 'Variant', 'Voting', 'Weight', 'base', 'clinical Diagnosis', 'commercialization', 'cost', 'cytokine', 'data mining', 'design', 'improved', 'indexing', 'innovation', 'interest', 'leukemia/lymphoma', 'novel', 'predictive modeling', 'relating to nervous system', 'research study', 'response', 'software systems', 'statistics', 'tool', 'translational medicine']",NCRR,"TREE STAR, INC.",R43,2008,100854,-0.011107707094870353
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7479786,U54EB005149,[' '],NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2008,3534631,0.05445787139585971
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,7467385,U24RR021382,[' '],NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2008,5140823,0.00478710874917904
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7494022,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Compatible', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Condition', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Numbers', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Standards of Weights and Measures', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'computerized', 'cost', 'day', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2008,856688,0.009535499703550472
"Development and Dissemination of Robust Brain MRI Measurement Tools    DESCRIPTION (provided by applicant): Development and Dissemination of Robust Brain MRI Measurement Tools Abstract: This application responds to RFA: PAR-07-249, ""Collaborations with National Centers for Biomedical Computing"". The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods. The project will collaborate with the National Alliance for Medical Image Computing (NA-MIC) to develop the software using the NA-MIC Software Engineering Process, leverage the NA-MIC engineering infrastructure, and integrate this software into the 3D Slicer, a well-architected application environment being developed in NA-MIC. The particular software package will include both a brain image registration and warping algorithm, called HAMMER, and an algorithm for the segmentation of white matter lesions (WMLs), which can arise from a variety of pathologies including vascular pathology and multiple sclerosis. HAMMER received 2006 Best Paper Award from IEEE Signal Processing Society. HAMMER has been successfully applied to many large clinical research studies and clinical trials involving over 5,000 MR brain images and has been downloaded by 318 users from 102 institutions in over 20 countries. The WML segmentation algorithm has been successfully applied to ""Action to Control Cardiovascular Risk in Diabetes-Memory in Diabetes"" (ACCORD-MIND) sub- study, with data acquired from 4 centers on 650 patients over a period of 8 years. Designing an easy-to-use, robust software package for these two algorithms and incorporating it into the 3D Slicer will benefit a large community of end-users that need access to advanced image analysis methods in various neuroimaging studies. To increase the robustness of the algorithms to the highly variable quality and characteristics of clinical image data, further algorithm development is necessary. To increase ease of use by non-experts in computer analysis methods and integrate this software into the Slicer platform, significant software engineering efforts are planned. Three aims will be investigated. The first aim is to further develop and extend novel image analysis methods aiming at improving the robustness and performance of HAMMER registration and WML segmentation algorithms, so that they can be easily applied to various clinical research studies. The second and third aims are to design separate software modules for these two algorithms, and to incorporate them into the 3D Slicer. These two modules will be designed (1) with consistent cross-platform interactive and scripted interfaces, (2) allowing end-users to interactively explore the suitable parameters for their data, (3) enabling developers to add new functions. The robustness of these two modules will be extensively tested and improved by both software engineering tools and various clinical research data (acquired from different centers). The final software will be freely available in both source code and pre-compiled programs. PUBLIC HEALTH REVELANCE: The goal of this project is to develop and widely distribute a software package for robust measurement of brain structure in MR images by using computational neuroanatomy methods.          n/a",Development and Dissemination of Robust Brain MRI Measurement Tools,7556497,R01EB006733,"['Academia', 'Address', 'Adopted', 'Affect', 'Age', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Area', 'Arts', 'Attention', 'Automobile Driving', 'Award', 'Behavioral', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Blood Vessels', 'Brain', 'Brain imaging', 'Brain region', 'Budgets', 'California', 'Characteristics', 'Child', 'Class', 'Clinical', 'Clinical Data', 'Clinical Engineering', 'Clinical Research', 'Clinical Trials', 'Cocaine', 'Cognitive', 'Collaborations', 'Collection', 'Commit', 'Communities', 'Compatible', 'Complex', 'Computational algorithm', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computers', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Doctor of Medicine', 'Doctor of Philosophy', 'Documentation', 'Educational Materials', 'Educational process of instructing', 'Educational workshop', 'Elderly', 'Elements', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Etiology', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'General Hospitals', 'Genetic', 'Genomics', 'Goals', 'Government', 'Hand', 'Head', 'Health', 'Healthcare', 'Heavy Drinking', 'Hemoglobin', 'Histocompatibility Testing', 'Hormonal', 'Hospitals', 'Housing', 'Human', 'Image', 'Image Analysis', 'Imagery', 'Imaging Techniques', 'Individual', 'Industry', 'Information Technology', 'Institutes', 'Institution', 'International', 'Investigation', 'Knowledge', 'Laboratories', 'Learning', 'Lesion', 'Licensing', 'Life', 'Localized', 'Longitudinal Studies', 'Los Angeles', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Memory', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Mind', 'Modality', 'Modeling', 'Molecular Abnormality', 'Morphology', 'Multimodal Imaging', 'Multiple Sclerosis', 'National Center for Research Resources', 'Nature', 'Neuroanatomy', 'Neurobiology', 'Neurons', 'Neurosciences', 'Neurosciences Research', 'North Carolina', 'Numbers', 'Operative Surgical Procedures', 'Organ', 'Paper', 'Participant', 'Pathology', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Philosophy', 'Physiological', 'Play', 'Population', 'Positioning Attribute', 'Positron-Emission Tomography', 'Procedures', 'Process', 'Production', 'Property', 'Protocols documentation', 'Psychiatry', 'Public Health', 'Publications', 'Purpose', 'Radiology Specialty', 'Range', 'Recording of previous events', 'Records', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Running', 'Sampling', 'Schizophrenia', 'Science', 'Scientist', 'Secure', 'Series', 'Services', 'Simulate', 'Site', 'Societies', 'Software Engineering', 'Software Tools', 'Source', 'Source Code', 'Spatial Distribution', 'Speed', 'Structure', 'System', 'Talents', 'Techniques', 'Technology', 'Testing', 'Thinking', 'Time', 'Tissues', 'Today', 'Training', 'USA Georgia', 'United States National Institutes of Health', 'Universities', 'University Hospitals', 'Upper arm', 'Ursidae Family', 'Utah', 'Visible Radiation', 'Vision', 'Vision research', 'Western Asia Georgia', 'Woman', 'Women&apos', 's Health', 'Work', 'abstracting', 'base', 'bioimaging', 'biomedical scientist', 'cardiovascular risk factor', 'computerized data processing', 'computerized tools', 'cost', 'design', 'disability', 'egg', 'endophenotype', 'experience', 'follow-up', 'human disease', 'image registration', 'improved', 'innovation', 'mathematical model', 'medical schools', 'member', 'nervous system disorder', 'neuroimaging', 'next generation', 'novel', 'open source', 'outreach program', 'portability', 'professor', 'programs', 'receptor', 'repository', 'research and development', 'research study', 'scripting interface', 'software development', 'tool', 'usability', 'user-friendly', 'vector', 'vision development', 'water diffusion', 'web-enabled', 'white matter']",NIBIB,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2008,402999,0.014501450343178502
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7186695,R01NS051826,"['Accounting', 'Adult', 'Affect', 'Age', 'Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomic Models', 'Anatomic structures', 'Anatomy', 'Area', 'Atlases', 'Back', 'Biomechanics', 'Boston', 'Brain', 'Caring', 'Class', 'Classification', 'Clinical assessments', 'Clutterings', 'Collaborations', 'Competence', 'Computer Simulation', 'Computer Vision Systems', 'Computing Methodologies', 'Corpus Callosum', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diffuse Pattern', 'Discipline of obstetrics', 'Disease', 'Disease Progression', 'Effectiveness', 'Effectiveness of Interventions', 'Electroencephalography', 'Elements', 'Ensure', 'Evaluation', 'Evolution', 'Fetal Growth Retardation', 'General Hospitals', 'Genetic Markers', 'Goals', 'Gold', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Hospitals', 'Human', 'Image', 'Imagery', 'Imaging Device', 'Incidence', 'Individual', 'Infant', 'Intervention', 'Intuition', 'Invasive', 'Knowledge', 'Label', 'Learning', 'Learning Disabilities', 'Link', 'Localized', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Massachusetts', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphologic artifacts', 'Morphology', 'Motivation', 'Neonatal', 'Neuroanatomy', 'Neurosciences', 'Neurosurgeon', 'Noise', 'Normal Range', 'Operative Surgical Procedures', 'Outcome', 'Pathology', 'Patients', 'Pediatric Hospitals', 'Population', 'Population Characteristics', 'Population Study', 'Positioning Attribute', 'Premature Infant', 'Principal Investigator', 'Probability', 'Procedures', 'Process', 'Property', 'Psyche structure', 'Range', 'Rate', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Resolution', 'Rest', 'Role', 'Scanning', 'Schizophrenia', 'Shapes', 'Site', 'Specificity', 'Staging', 'Standards of Weights and Measures', 'Statistical Distributions', 'Statistical Models', 'Statistical Study', 'Statistically Significant', 'Structure', 'Surface', 'Surgeon', 'Surgical Instruments', 'System', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Tweens', 'Universities', 'Validation', 'Variant', 'Washington', 'Woman', 'base', 'cohort', 'computer studies', 'computerized tools', 'desire', 'deviant', 'disease classification', 'expectation', 'feeding', 'healthy aging', 'imaging Segmentation', 'improved', 'instrument', 'interest', 'mortality', 'neonate', 'nervous system disorder', 'neuroimaging', 'neurosurgery', 'normal aging', 'novel', 'programs', 'radiologist', 'reconstruction', 'relating to nervous system', 'research clinical testing', 'response', 'shape analysis', 'statistics', 'tool', 'tumor']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2007,282619,-0.0044530889883200595
"Spectral imaging for automated malignant blast counting    DESCRIPTION (provided by applicant):    We propose to extend our successful development of an agile spectral light source for light microscopy, funded through the NCI-IMAT initiative, into FDA trials. The SpectraLamp(tm) device enables the automated and quantitative analysis of double-immunostained samples in brightfield (non-fluorescence-based) microscopy, with particular utility for hematopathology applications. A clinically compelling area is the enumeration of malignant blasts in bone marrow biopsy specimens of patients with acute leukemias, myelodysplastic syndromes and chronic myleloproliferative diseases for the purpose of staging and evaluating therapeutic responses. Current methods are inadequate due to poor sampling (typical of bone marrow aspirates) or difficulty in identifying true blasts (bone marrow biopsies and single-color immunohistochemical phenotyping). Double-immunophenotyping permits largely unambiguous detection, but such labeling strategies are not supported by standard (non-multispectral) color imaging systems. To overcome this limitation, we will combine our multispectral imaging system with a high-speed slide-scanning platform that can scan an entire bone-marrow biopsy at high resolution in under 3 minutes. Machine-learning software tools and spectral imaging will identify blasts, combining morphology parameters and double or even triple immunophenotyping to ensure accuracy and precision. After blasts are identified, flow-cytometrylike software will present the data in histograms and other modalities, allowing the user to ""gate"" on particular cellular populations and pull up panels of cell images for confirmation.      Time-line: Final equipment-related tasks will be accomplished in the first year and preliminary testing of the instrumentation and software features will occur in the second year, as will development of qualified panels of immunoreagents and staining protocols (by DAKOCytomation). FDA-sanctioned clinical trials will be conducted in the third year, leading to submission of an application for a 510(k) clearance.         n/a",Spectral imaging for automated malignant blast counting,7278340,R44CA088684,"['Acute leukemia', 'Antibodies', 'Area', 'Aspirate substance', 'Biopsy Specimen', 'Blast Cell', 'Bone Marrow', 'Bone marrow biopsy', 'Cells', 'Chronic', 'Clinical', 'Clinical Trials', 'Collaborations', 'Color', 'Compatible', 'Computer software', 'Count', 'Data', 'Data Set', 'Detection', 'Development', 'Devices', 'Disease', 'Dysmyelopoietic Syndromes', 'Ensure', 'Equipment', 'Evaluation', 'Evaluation Reports', 'Event', 'Experimental Designs', 'Florida', 'Fluorescence', 'Funding', 'Future', 'Generations', 'Goals', 'Grant', 'Hematopathology', 'Histology', 'Image', 'Image Analysis', 'Immunophenotyping', 'Label', 'Laboratories', 'Legal patent', 'Light', 'Lighting', 'Machine Learning', 'Malignant - descriptor', 'Manuals', 'Mechanics', 'Medical Device', 'Methodology', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Morphology', 'Myelodysplastic/Myeloproliferative Disease', 'Optics', 'Pathologist', 'Pathology', 'Patients', 'Pattern', 'Phenotype', 'Population', 'Procedures', 'Protocols documentation', 'Public Health Schools', 'Purpose', 'Qualifying', 'Range', 'Reagent', 'Reporting', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Series', 'Side', 'Slide', 'Small Business Funding Mechanisms', 'Small Business Innovation Research Grant', 'Software Engineering', 'Software Tools', 'Software Validation', 'Source', 'Speed', 'Staging', 'Staining method', 'Stains', 'Standards of Weights and Measures', 'System', 'Testing', 'Therapeutic', 'Time', 'United States Food and Drug Administration', 'Universities', 'Validation', 'Washington', 'Work', 'base', 'cellular imaging', 'design', 'experience', 'innovation', 'instrument', 'instrumentation', 'leukemia', 'light microscopy', 'novel', 'programs', 'research study', 'response', 'software development']",NCI,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R44,2007,1006481,0.02518496710952242
"The CardioVascular Research Grid    DESCRIPTION (provided by applicant):       We are proposing to establish the Cardiovascular Research Grid (CVRG). The CVRG will provide the national cardiovascular research community a collaborative environment for discovering, representing, federating, sharing and analyzing multi-scale cardiovascular data, thus enabling interdisciplinary research directed at identifying features in these data that are predictive of disease risk, treatment and outcome. In this proposal, we present a plan for development of the CVRG. Goals are: To develop the Cardiovascular Data Repository (CDR). The CDR will be a software package that can be downloaded and installed locally. It will provide the grid-enabled software components needed to manage transcriptional, proteomic, imaging and electrophysiological (referred to as ""multi-scale"") cardiovascular data. It will include the software components needed for linking CDR nodes together to extend the CVRG To make available, through community access to and use of the CVRG, anonymized cardiovascular data sets supporting collaborative cardiovascular research on a national and international scale To develop Application Programming Interfaces (APIs) by which new grid-enabled software components, such as data analysis tools and databases, may be deployed on the CVRG To: a) develop novel algorithms for parametric characterization of differences in ventricular shape and motion in health versus disease using MR and CT imaging data; b) develop robust, readily interpretable statistical learning methods for discovering features in multi-scale cardiovascular data that are predictive of disease risk, treatment and outcome; and c) deploy these algorithms on the CVRG via researcher-friendly web-portals for use by the cardiovascular research community To set in place effective Resource administrative policies for managing project development, for assuring broad dissemination and support of all Resource software and to establish CVRG Working Groups as a means for interacting with and responding to the data management and analysis needs of the cardiovascular research community and for growing the set of research organizations managing nodes of the CVRG. (End of Abstract).          n/a",The CardioVascular Research Grid,7246847,R24HL085343,"['Algorithms', 'Cardiovascular system', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Development Plans', 'Disease', 'Environment', 'Goals', 'Health', 'Image', 'Interdisciplinary Study', 'International', 'Internet', 'Link', 'Machine Learning', 'Methods', 'Motion', 'Policies', 'Proteomics', 'Research', 'Research Personnel', 'Resources', 'Shapes', 'Treatment outcome', 'Ventricular', 'Work', 'abstracting', 'data management', 'disorder risk', 'novel', 'programs', 'tool']",NHLBI,JOHNS HOPKINS UNIVERSITY,R24,2007,2183988,0.011613976352124066
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,7269383,R01RR014477,[' '],NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2007,307022,-0.021527848529205702
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7264516,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genome', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Numbers', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Rate', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'day', 'discount', 'drug discovery', 'fluorescence imaging', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2007,387827,-0.009809337408150348
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7494181,U54EB005149,"['Address', 'Affect', 'Alcohols', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Anisotropy', 'Appearance', 'Area', 'Atlases', 'Automobile Driving', 'Behavioral Research', 'Biological', 'Biology', 'Biomedical Computing', 'Brain', 'Budgets', 'Cells', 'Characteristics', 'Clinical', 'Clinical Data', 'Cognitive', 'Collaborations', 'Collection', 'Commit', 'Complex', 'Computational algorithm', 'Computer software', 'Computer-Assisted Image Analysis', 'Computing Methodologies', 'Coupling', 'Data', 'Data Correlations', 'Data Sources', 'Development', 'Diffusion Magnetic Resonance Imaging', 'Disease', 'Electroencephalography', 'Elements', 'Ensure', 'Epilepsy', 'Feedback', 'Fiber', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Functional disorder', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Heart', 'Hemoglobin', 'Hippocampus (Brain)', 'Histocompatibility Testing', 'Image', 'Image Analysis', 'Image-Guided Surgery', 'Imagery', 'Imaging Techniques', 'Individual', 'Knowledge', 'Life', 'Link', 'Localized', 'Location', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Metabolic', 'Metabolism', 'Methodology', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modification', 'Morphology', 'Multiple Sclerosis', 'Neurons', 'Neurosciences', 'Operative Surgical Procedures', 'Organ', 'Other Imaging Modalities', 'Output', 'Participant', 'Patients', 'Pattern', 'Performance', 'Physiological', 'Polishes', 'Population', 'Positron-Emission Tomography', 'Process', 'Property', 'Range', 'Recording of previous events', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Sampling', 'Scanning', 'Schizophrenia', 'Science', 'Services', 'Shapes', 'Software Engineering', 'Source', 'Specific qualifier value', 'Staging', 'Statistical Distributions', 'Structure', 'Syndrome', 'System', 'Systems Analysis', 'Techniques', 'Testing', 'Textiles', 'Time', 'Tissues', 'Today', 'USA Georgia', 'Utah', 'Visible Radiation', 'Vision', 'Western Asia Georgia', 'Work', 'base', 'bioimaging', 'computerized tools', 'cost', 'design', 'disability', 'experience', 'image registration', 'insight', 'interest', 'mathematical model', 'neuroimaging', 'novel', 'prenatal', 'research study', 'response', 'shape analysis', 'software development', 'tool', 'vector', 'vision development', 'water diffusion', 'white matter']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2007,87500,0.05445787139585971
"National Alliance for Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance for Medical Imaging Computing (NAMIC)(RMI),7271955,U54EB005149,[' '],NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2007,3888915,0.05445787139585971
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,7253351,U24RR021382,[' '],NCRR,MASSACHUSETTS GENERAL HOSP,U24,2007,5123449,0.00478710874917904
"Computer analysis of optic disc images in glaucoma    DESCRIPTION (provided by applicant): Glaucoma diagnosis, management and research depend on complex judgments of the optic disc (or optic nerve head), visual field and intraocular pressure. The current standard of optic disc evaluation requires qualitative observer judgments of stereoscopic photographs of the optic disc, a less than optimal method. Despite much research, no methods have yet conclusively improved over this conventional Approach: Contemporary optic disc analyzers typically use instrument-specific image capture methods and derive quantitative estimates for various anatomical features of the optic disc. Our goal is to improve the methods of optic disc diagnosis by applying advanced image analysis methods from computer engineering to the essential diagnostic problem in glaucoma - detecting change or stability in optic disc images over time. Expertise at the University of Pennsylvania in clinical glaucoma, translational research (R. Stone, PI; E. Miller, J. Piltz-Seymour and others) and biostatistics (M. Maguire, G.-S. Ying) is merged with engineering expertise in computer image analysis at Sarnoff Corporation (B. Hanna, H. Sawhney, and others) in a Bioengineering Research Partnership with four Specific Aims: 1) Develop and validate robust registration algorithms for automatic alignment of optic disc images; 2) Develop an automated multiple-view analysis approach to extract relative, local change parameters from optic disc stereo images; 3) Develop interactive tools to assist in observer grading of optic disc images and in clinical interpretation of the automated change detection and stereoscopic algorithms; and 4) Conduct initial validation studies of the optic disc change detection tools. Our plan to address stereo primarily differs from other approaches to optic nerve analysis, but it offers many advantages for validation, clinical care and research not possible with the instrument-specific formats of contemporary fundus analyzers. Requiring only a personal computer and software to analyze optic disc images, our approach is clinically intuitive, can accommodate improvements in software and camera technology, is compatible with many image formats, permits use of archived fundus photos and is cost-effective. The refined approach to stereo recovery will permit robust detection of optic disc stability or change, and it offers great promise for advancing optic nerve diagnosis in glaucoma.          n/a",Computer analysis of optic disc images in glaucoma,7289973,R01EY017299,"['Accounting', 'Address', 'Algorithms', 'Archives', 'Biomedical Engineering', 'Biometry', 'Blindness', 'Calculi', 'Calibration', 'Caring', 'Clinical', 'Clinical Engineering', 'Compatible', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Condition', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease Progression', 'Engineering', 'Ensure', 'Equipment', 'Evaluation', 'Eye', 'Fundus', 'Glaucoma', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Investigation', 'Judgment', 'Measurement', 'Methods', 'Modeling', 'Monitor', 'Numbers', 'Optic Atrophy', 'Optic Disk', 'Optic Nerve', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Personal Computers', 'Physiologic Intraocular Pressure', 'Positioning Attribute', 'Process', 'Provider', 'Recovery', 'Relative (related person)', 'Research', 'Research Personnel', 'Residual state', 'Shapes', 'Solutions', 'Standards of Weights and Measures', 'Structure', 'Surface', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Validation', 'Vision', 'Visual Fields', 'base', 'computerized', 'cost', 'day', 'digital imaging', 'image registration', 'improved', 'instrument', 'novel diagnostics', 'programs', 'stereoscopic', 'tool', 'validation studies']",NEI,UNIVERSITY OF PENNSYLVANIA,R01,2007,853883,0.009535499703550472
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,7111722,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2006,314029,-0.021527848529205702
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,7015019,R01NS051826,"['Alzheimer&apos', 's disease', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain morphology', 'human data', 'image enhancement', 'image guided surgery /therapy', 'magnetic resonance imaging', 'mathematical model', 'prenatal growth disorder']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2006,289590,-0.0044530889883200595
"Spectral imaging for automated malignant blast counting    DESCRIPTION (provided by applicant):    We propose to extend our successful development of an agile spectral light source for light microscopy, funded through the NCI-IMAT initiative, into FDA trials. The SpectraLamp(tm) device enables the automated and quantitative analysis of double-immunostained samples in brightfield (non-fluorescence-based) microscopy, with particular utility for hematopathology applications. A clinically compelling area is the enumeration of malignant blasts in bone marrow biopsy specimens of patients with acute leukemias, myelodysplastic syndromes and chronic myleloproliferative diseases for the purpose of staging and evaluating therapeutic responses. Current methods are inadequate due to poor sampling (typical of bone marrow aspirates) or difficulty in identifying true blasts (bone marrow biopsies and single-color immunohistochemical phenotyping). Double-immunophenotyping permits largely unambiguous detection, but such labeling strategies are not supported by standard (non-multispectral) color imaging systems. To overcome this limitation, we will combine our multispectral imaging system with a high-speed slide-scanning platform that can scan an entire bone-marrow biopsy at high resolution in under 3 minutes. Machine-learning software tools and spectral imaging will identify blasts, combining morphology parameters and double or even triple immunophenotyping to ensure accuracy and precision. After blasts are identified, flow-cytometrylike software will present the data in histograms and other modalities, allowing the user to ""gate"" on particular cellular populations and pull up panels of cell images for confirmation.      Time-line: Final equipment-related tasks will be accomplished in the first year and preliminary testing of the instrumentation and software features will occur in the second year, as will development of qualified panels of immunoreagents and staining protocols (by DAKOCytomation). FDA-sanctioned clinical trials will be conducted in the third year, leading to submission of an application for a 510(k) clearance.         n/a",Spectral imaging for automated malignant blast counting,7096660,R44CA088684,"['bioimaging /biomedical imaging', 'biomedical equipment development', 'biopsy', 'blood cell count', 'bone marrow', 'bone marrow exam', 'cell morphology', 'cell population study', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'flow cytometry', 'hematopoietic stem cells', 'high throughput technology', 'histopathology', 'human tissue', 'image enhancement', 'immunocytochemistry', 'leukemia', 'light emission', 'light microscopy', 'lighting', 'molecular /cellular imaging', 'neoplasm /cancer diagnosis', 'spectrometry']",NCI,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R44,2006,1029373,0.02518496710952242
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),7104243,U54EB005149,"['NIH Roadmap Initiative tag', 'bioimaging /biomedical imaging', 'bioinformatics', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2006,3809481,0.05445787139585971
"Tomographic Imaging of Cochlear Micromechanical Motions DESCRIPTION (provided by applicant): The cochlea is a remarkable sensor: a living cochlea can reliably detect sounds that cause motions of the stapes on the order of picometers, is capable of high-quality frequency analysis (Q10dB > 600), and compresses the large dynamic range (120 dB) of hearing into the considerably smaller dynamic range (20- 50 dB) of neurons. It is now widely accepted that an active mechanical amplification process underlies these remarkable properties. However, there is considerable debate about the nature of the amplifier. While information on the cellular and molecular basis of hearing is increasing rapidly, there is still little understanding of how the components interoperate to generate the remarkable properties of hearing.       To date, the most successful experimental studies of cellular motions in living cochleae have used optical methods. However, current methods, such as laser Doppler vibrometry and video microscopy are limited by the low reflectivities of cochlear structures and the limited optical access provided by the intact cochea. The objective of this grant is to develop and apply a new tomographic imaging and motion measurement technique capable of determining the three-dimensional motions of all structures in a living, intact cochlea. Optical coherence tomography (OCT) will be used to obtain high-resolution images of the cochlea. Images will be acquired through a narrow opening similar to that used in laser Doppler vibrometry methods, or possibly directly through bone. Sequences of stroboscopic images will be generated with synchronous demodulation of the OCT detector signal during acoustic stimulation. Computer vision algorithms (similar to those used in video microscopy methods) will be used to determine motions with nanometer resolution. This technique will be applied to image and measure three-dimensional motions of the internal microstructure of an intact cochlea, including the basilar membrane, reticular lamina, tectorial membrane, and outer hair cells. n/a",Tomographic Imaging of Cochlear Micromechanical Motions,6985366,R21DC007111,"['animal tissue', 'auditory stimulus', 'biomechanics', 'cochlea', 'computer program /software', 'ear hair cell', 'guinea pigs', 'image processing', 'measurement', 'neuroimaging', 'optical tomography', 'organ of Corti', 'retina', 'technology /technique development', 'three dimensional imaging /topography', 'vibration', 'video microscopy']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2006,183324,0.011848825521747352
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,7078667,U24RR021382,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational biology', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data management', 'human subject', 'imaging /visualization /scanning', 'information systems', 'magnetic resonance imaging', 'method development', 'molecular biology information system', 'morphometry', 'neurogenetics', 'neuroimaging', 'neuropsychology']",NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2006,5010926,0.00478710874917904
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7125565,R01EB006200,"['NIH Roadmap Initiative tag', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'biotechnology', 'charge coupled device camera', 'computer program /software', 'computer system hardware', 'high throughput technology', 'image enhancement', 'robotics']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2006,399410,-0.009809337408150348
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6916483,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2005,321788,-0.021527848529205702
"Computational Modeling of Anatomical Shape Distributions    DESCRIPTION (provided by applicant): Segmentation of detailed, patient-specific models from medical imagery can provide invaluable assistance for surgical planning and navigation. Current segmentation methods often make errors when confronted with subtle intensity boundaries. Adding knowledge of expected shape of a structure, and the range of normal variations in shape, can greatly improve segmentation, by guiding it towards the most likely shape consistent with the image information. The resulting segmentations can be used to plan surgical procedures, and when registered to the patient, can provide navigational guidance around critical structures. Many neurological diseases, such as Alzheimer's, schizophrenia, and Fetal Growth Restriction, affect the shape of specific anatomical areas. To understand the development and progression of these diseases, as well as to develop methods for classifying instances into diseased or normal classes, 1 needs methods that capture differences in shape distributions between populations. Our goal is to develop and validate methods for learning from images concise representations of anatomical shape and its variability, Modeling shape distributions will improve segmentation algorithms by biasing the search towards more likely shapes. It will also enable quantitative analysis based on shape in population studies, where imaging is used to study differences in anatomy between populations, as well as changes within a population, for example with age. The proposed research builds on prior methods for segmentation and shape analysis, using tools from computer vision and machine learning applied to questions of shape representation, shape based segmentation and shape analysis for population studies. We plan to further develop the methods and to validate them with our collaborators in several different applications, including surgical planning, neonatal imaging and image-based studies of aging and Alzheimer's disease.            n/a",Computational Modeling of Anatomical Shape Distributions,6916728,R01NS051826,"['Alzheimer&apos', 's disease', 'bioimaging /biomedical imaging', 'brain imaging /visualization /scanning', 'brain morphology', 'human data', 'image enhancement', 'image guided surgery /therapy', 'magnetic resonance imaging', 'mathematical model', 'prenatal growth disorder']",NINDS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R01,2005,292728,-0.0044530889883200595
"Multiresolution Autofocusing for Automated Microscopy    DESCRIPTION (provided by applicant): This project will further develop and refine an innovative digital auto-focus technology for automated microscopy. Auto-focusing is essential to automated microscope imaging. Currently available techniques rely on various algorithms of focus computation at a single image resolution and suffer from inherent performance limitations, which affect their success and utilization in clinical and research applications. Auto-focusing for fluorescence microscopy, for example, represents a serious challenge to existing methods for desired accuracy, reliability and speed since in this case the images have very low signal-to-noise ratio and narrow depth-of-fields while specimen exposure to fluorescent excitation must be minimized to avoid photo-bleaching and formation of undesirable substances such as free radicals and singlet oxygen. We propose a novel multi-resolution image analysis approach to microscope auto-focusing, based on the recently developed mathematical theory of wavelet transform. The new approach overcomes a number of inherent limitations of currently available techniques, and holds the promise to make the measurement of the microscope focus function and the detection of best-focus imaging position considerably more accurate, reliable, and fast. This innovative technology will significantly increase the ability and efficacy of automated microscope instruments for a wide range of clinical and research applications where a large number of specimens need to be imaged and quantitatively analyzed on a routine basis. During the Phase 1 project we investigated the feasibility of the proposed technology for fluorescence microscopy. We developed software to implement the algorithms for multi-resolution focus function measurements and for in-focus imaging position search. We evaluated the new approach in software simulation on a variety of sample image stacks of cytogenetic FISH specimens, and compared it with all current best-performing methods for microscope auto-focusing using the criteria of (1) accuracy, (2) range, (3) robustness, and (4) speed. The Phase 1 results suggest that, by using a proper wavelet-based auto-focus function, the new multi-resolution method significantly outperforms all competing methods in each of the aforementioned performance categories, and clearly exceeds the Phase 1 feasibility criteria. In the Phase 2 project, we will further develop, refine, integrate, and validate the new technology in real-time operation environment. We plan to build a prototype system with multi-resolution auto-focusing capabilities for both fluorescence and bright-field microscope imaging. We will evaluate the system extensively for a variety of applications including genetics, pathology, and cytology. We will beta test the new system and technology in routine clinical laboratory environment and optimize the technology as end user input and feedbacks are gathered. Once fully developed and qualified, this new technology will be patented and incorporated into future IRIS automated imaging cytometry instruments. It will also be made commercially available to Applied Imaging Corporation and other manufacturers of automated microscope instruments through licensing agreements and partnerships.           n/a",Multiresolution Autofocusing for Automated Microscopy,6951446,R44RR016817,"['artificial intelligence', 'bioimaging /biomedical imaging', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'flow cytometry', 'fluorescence microscopy', 'fluorescent in situ hybridization', 'human data', 'image enhancement', 'image processing', 'mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2005,318350,0.0293732927125767
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by applicant):    The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47 percent to 58 percent of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy; 8 percent stated that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better informed treatment decisions, and facilitate coping when it occurs.            n/a",Computer Imaging to Diminish Alopecia Distress,6935840,R44CA099873,"['Internet', 'alopecia', 'anxiety', 'artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'breast neoplasms', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'coping', 'desensitization psychotherapy', 'drug adverse effect', 'female', 'human subject', 'imaging /visualization /scanning', 'neoplasm /cancer chemotherapy', 'patient oriented research', 'psychological aspect of cancer', 'quality of life', 'women&apos', 's health']",NCI,"BARRON ASSOCIATES, INC.",R44,2005,399984,-0.015349745657668414
"Spectral imaging for automated malignant blast counting    DESCRIPTION (provided by applicant):    We propose to extend our successful development of an agile spectral light source for light microscopy, funded through the NCI-IMAT initiative, into FDA trials. The SpectraLamp(tm) device enables the automated and quantitative analysis of double-immunostained samples in brightfield (non-fluorescence-based) microscopy, with particular utility for hematopathology applications. A clinically compelling area is the enumeration of malignant blasts in bone marrow biopsy specimens of patients with acute leukemias, myelodysplastic syndromes and chronic myleloproliferative diseases for the purpose of staging and evaluating therapeutic responses. Current methods are inadequate due to poor sampling (typical of bone marrow aspirates) or difficulty in identifying true blasts (bone marrow biopsies and single-color immunohistochemical phenotyping). Double-immunophenotyping permits largely unambiguous detection, but such labeling strategies are not supported by standard (non-multispectral) color imaging systems. To overcome this limitation, we will combine our multispectral imaging system with a high-speed slide-scanning platform that can scan an entire bone-marrow biopsy at high resolution in under 3 minutes. Machine-learning software tools and spectral imaging will identify blasts, combining morphology parameters and double or even triple immunophenotyping to ensure accuracy and precision. After blasts are identified, flow-cytometrylike software will present the data in histograms and other modalities, allowing the user to ""gate"" on particular cellular populations and pull up panels of cell images for confirmation.      Time-line: Final equipment-related tasks will be accomplished in the first year and preliminary testing of the instrumentation and software features will occur in the second year, as will development of qualified panels of immunoreagents and staining protocols (by DAKOCytomation). FDA-sanctioned clinical trials will be conducted in the third year, leading to submission of an application for a 510(k) clearance.         n/a",Spectral imaging for automated malignant blast counting,6938339,R44CA088684,"['bioimaging /biomedical imaging', 'biomedical equipment development', 'biopsy', 'blood cell count', 'bone marrow', 'bone marrow exam', 'cell morphology', 'cell population study', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'flow cytometry', 'hematopoietic stem cells', 'high throughput technology', 'histopathology', 'human tissue', 'image enhancement', 'immunocytochemistry', 'leukemia', 'light emission', 'light microscopy', 'lighting', 'molecular /cellular imaging', 'neoplasm /cancer diagnosis', 'spectrometry']",NCI,CAMBRIDGE RESEARCH AND INSTRUMENTATION,R44,2005,1000582,0.02518496710952242
"National Alliance-Medical Imaging Computing (NAMIC)(RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance-Medical Imaging Computing (NAMIC)(RMI),6950028,U54EB005149,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2005,3800000,0.05445787139585971
"Tomographic Imaging of Cochlear Micromechanical Motions DESCRIPTION (provided by applicant): The cochlea is a remarkable sensor: a living cochlea can reliably detect sounds that cause motions of the stapes on the order of picometers, is capable of high-quality frequency analysis (Q10dB > 600), and compresses the large dynamic range (120 dB) of hearing into the considerably smaller dynamic range (20- 50 dB) of neurons. It is now widely accepted that an active mechanical amplification process underlies these remarkable properties. However, there is considerable debate about the nature of the amplifier. While information on the cellular and molecular basis of hearing is increasing rapidly, there is still little understanding of how the components interoperate to generate the remarkable properties of hearing.       To date, the most successful experimental studies of cellular motions in living cochleae have used optical methods. However, current methods, such as laser Doppler vibrometry and video microscopy are limited by the low reflectivities of cochlear structures and the limited optical access provided by the intact cochea. The objective of this grant is to develop and apply a new tomographic imaging and motion measurement technique capable of determining the three-dimensional motions of all structures in a living, intact cochlea. Optical coherence tomography (OCT) will be used to obtain high-resolution images of the cochlea. Images will be acquired through a narrow opening similar to that used in laser Doppler vibrometry methods, or possibly directly through bone. Sequences of stroboscopic images will be generated with synchronous demodulation of the OCT detector signal during acoustic stimulation. Computer vision algorithms (similar to those used in video microscopy methods) will be used to determine motions with nanometer resolution. This technique will be applied to image and measure three-dimensional motions of the internal microstructure of an intact cochlea, including the basilar membrane, reticular lamina, tectorial membrane, and outer hair cells. n/a",Tomographic Imaging of Cochlear Micromechanical Motions,6850297,R21DC007111,"['animal tissue', 'auditory stimulus', 'biomechanics', 'cochlea', 'computer program /software', 'ear hair cell', 'guinea pigs', 'image processing', 'measurement', 'neuroimaging', 'optical tomography', 'organ of Corti', 'retina', 'technology /technique development', 'three dimensional imaging /topography', 'vibration', 'video microscopy']",NIDCD,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R21,2005,172385,0.011848825521747352
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,6952714,U24RR021382,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational biology', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data management', 'human subject', 'imaging /visualization /scanning', 'information systems', 'magnetic resonance imaging', 'method development', 'molecular biology information system', 'morphometry', 'neurogenetics', 'neuroimaging', 'neuropsychology']",NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2005,5013536,0.00478710874917904
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7012638,R01EB006200,"['bioimaging /biomedical imaging', 'biomedical equipment development', 'biotechnology', 'charge coupled device camera', 'computer program /software', 'computer system hardware', 'high throughput technology', 'image enhancement', 'robotics']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2005,363523,-0.009809337408150348
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6799187,R01RR014477,"['X ray crystallography', 'artificial intelligence', 'automated data processing', 'chemical structure', 'computer human interaction', 'computer program /software', 'computer system design /evaluation', 'crystallization', 'data collection methodology /evaluation', 'image processing', 'mathematics', 'method development', 'protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2004,321983,-0.021527848529205702
"Multiresolution Autofocusing for Automated Microscopy    DESCRIPTION (provided by applicant): This project will further develop and refine an innovative digital auto-focus technology for automated microscopy. Auto-focusing is essential to automated microscope imaging. Currently available techniques rely on various algorithms of focus computation at a single image resolution and suffer from inherent performance limitations, which affect their success and utilization in clinical and research applications. Auto-focusing for fluorescence microscopy, for example, represents a serious challenge to existing methods for desired accuracy, reliability and speed since in this case the images have very low signal-to-noise ratio and narrow depth-of-fields while specimen exposure to fluorescent excitation must be minimized to avoid photo-bleaching and formation of undesirable substances such as free radicals and singlet oxygen. We propose a novel multi-resolution image analysis approach to microscope auto-focusing, based on the recently developed mathematical theory of wavelet transform. The new approach overcomes a number of inherent limitations of currently available techniques, and holds the promise to make the measurement of the microscope focus function and the detection of best-focus imaging position considerably more accurate, reliable, and fast. This innovative technology will significantly increase the ability and efficacy of automated microscope instruments for a wide range of clinical and research applications where a large number of specimens need to be imaged and quantitatively analyzed on a routine basis. During the Phase 1 project we investigated the feasibility of the proposed technology for fluorescence microscopy. We developed software to implement the algorithms for multi-resolution focus function measurements and for in-focus imaging position search. We evaluated the new approach in software simulation on a variety of sample image stacks of cytogenetic FISH specimens, and compared it with all current best-performing methods for microscope auto-focusing using the criteria of (1) accuracy, (2) range, (3) robustness, and (4) speed. The Phase 1 results suggest that, by using a proper wavelet-based auto-focus function, the new multi-resolution method significantly outperforms all competing methods in each of the aforementioned performance categories, and clearly exceeds the Phase 1 feasibility criteria. In the Phase 2 project, we will further develop, refine, integrate, and validate the new technology in real-time operation environment. We plan to build a prototype system with multi-resolution auto-focusing capabilities for both fluorescence and bright-field microscope imaging. We will evaluate the system extensively for a variety of applications including genetics, pathology, and cytology. We will beta test the new system and technology in routine clinical laboratory environment and optimize the technology as end user input and feedbacks are gathered. Once fully developed and qualified, this new technology will be patented and incorporated into future IRIS automated imaging cytometry instruments. It will also be made commercially available to Applied Imaging Corporation and other manufacturers of automated microscope instruments through licensing agreements and partnerships.           n/a",Multiresolution Autofocusing for Automated Microscopy,6833120,R44RR016817,"['artificial intelligence', 'bioimaging /biomedical imaging', 'biomedical automation', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'digital imaging', 'flow cytometry', 'fluorescence microscopy', 'fluorescent in situ hybridization', 'human data', 'image enhancement', 'image processing', 'mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2004,427818,0.0293732927125767
"Optimized Retinal Camera DESCRIPTION (provided by applicant):  A low-cost, high-resolution, high-contrast color digital camera optimized for ophthalmology will be demonstrated. This Optimized Retinal Camera will be specifically tested for its effectiveness in meeting the image quality requirements for the screening and assessment of pre-proliferative and proliferative diabetic retinopathy in both traditional clinical settings and in telemedicine. The proposed device exploits recent technological advances in high sensitivity charge coupled device (CCD) cameras and digital signal processing electronics. Today's CCD cameras do not have the dynamic range to image the human retina. The human retina is characterized by regions of high reflectivity (20-40 percent), such as the optic disc, and very low reflectivity (<2 percent), such as the macula and fovea. Further, these existing digital cameras treat each of the color channels in the same manner and do not consider the special, red-saturated characteristics of the retina. The approach builds on existing fundus imaging technology developed by Kestrel for the National Eye Institute. The proposed Optimized Retinal Camera will be shown to offer significant improvement over existing digital color cameras by addressing each of the deficiencies mentioned above. Joslin Diabetes Center, the University of Iowa Department of Opthalmology, and the University of New Mexico Health Sciences Center will provide independent, ""masked"" evaluation of the optimized digital retinal images. n/a",Optimized Retinal Camera,6752819,R44EY013038,"['artificial intelligence', 'bioengineering /biomedical engineering', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'charge coupled device camera', 'clinical research', 'computer program /software', 'computer system design /evaluation', 'diabetic retinopathy', 'digital imaging', 'human subject', 'image processing', 'ophthalmoscopy', 'thermodynamics']",NEI,KESTREL CORPORATION,R44,2004,340158,0.01084355364627661
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by applicant):    The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47 percent to 58 percent of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy; 8 percent stated that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better informed treatment decisions, and facilitate coping when it occurs.            n/a",Computer Imaging to Diminish Alopecia Distress,6834860,R44CA099873,"['Internet', 'alopecia', 'anxiety', 'artificial intelligence', 'behavioral /social science research tag', 'bioimaging /biomedical imaging', 'breast neoplasms', 'clinical research', 'clinical trials', 'computer assisted patient care', 'computer human interaction', 'computer program /software', 'computer simulation', 'computer system design /evaluation', 'coping', 'desensitization psychotherapy', 'drug adverse effect', 'female', 'human subject', 'imaging /visualization /scanning', 'neoplasm /cancer chemotherapy', 'patient oriented research', 'psychological aspect of cancer', 'quality of life', 'women&apos', 's health']",NCI,"BARRON ASSOCIATES, INC.",R44,2004,350214,-0.015349745657668414
"National Alliance for Medical Imaging Computing (RMI)    DESCRIPTION (provided by applicant):   The National Alliance for Medical Imaging Computing (NAMIC) is a multi-institutional, interdisciplinary team of computer scientists, software engineers, and medical investigators who develop computational tools for the analysis and visualization of medical image data. The purpose of the center is to provide the infrastructure and environment for the development of computational algorithms and open source technologies, and then oversee the training and dissemination of these tools to the medical research community. This world-class software and development environment serves as a foundation for accelerating the development and deployment of computational tools that are readily accessible to the medical research community. The team combines cutting-edge computer vision research (to create medical imaging analysis algorithms) with state-of-the-art software engineering techniques (based on ""extreme"" programming techniques in a distributed, open-source environment) to enable computational examination of both basic neuroscience and neurological disorders. In developing this infrastructure resource, the team will significantly expand upon proven open systems technology and platforms. The driving biological projects will come initially from the study of schizophrenia, but the methods will be applicable to many other diseases. The computational tools and open systems technologies and platforms developed by NAMIC will initially be used to study anatomical structures and connectivity patterns in the brain, derangements of which have long been thought to play a role in the etiology of schizophrenia. The overall analysis will occur at a range of scales, and will occur across a range of modalities including diffusion MRI, quantitative EGG, and metabolic and receptor PET, but potentially including microscopic, genomic, and other image data. It will apply to image data from individual patients, and to studies executed across large populations. The data will be taken from subjects across a wide range of time scales and ultimately apply to a broad range of diseases in a broad range of organs.             n/a",National Alliance for Medical Imaging Computing (RMI),6847712,U54EB005149,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational neuroscience', 'computer system design /evaluation', 'cooperative study']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,U54,2004,100000,0.05445787139585971
"Morphometry Biomedical Informatics Research Network    DESCRIPTION (provided by applicant):     Technological advances in imaging have revolutionized the biomedical investigation of illness. The tremendous potential that this methodology brings to advancing diagnostic and prognostic capabilities and in treatment of illnesses has as yet remained largely an unfulfilled promise. This potential has been limited by a number of technological impediments that could be in large part overcome by the availability of a federated imaging database and the attendant infrastructure. Specifically, the ability to conduct clinical imaging studies across multiple sites, to analyze imaging data with the most powerful software regardless of development site, and to test new hypotheses on large collections of subjects with well characterized image and clinical data would have a demonstrable and positive impact on progress in this field. The Morphometry BIRN (mBIRN), established in October 2001, has made substantial progress in the development of this national infrastructure to develop a data and computational network based on a federated data acquisition and database across seven sites in the service of facilitating multi-site neuroanatomic analysis. Standardized structural MRI image acquisition protocols have been developed and implemented that demonstrably reduce initial sources of inter-site variance. Data structure, transmission, storage and querying aspects of the federated database have been implemented. In this continuation of the mBIRN efforts, we propose three broad areas of work:   1) continuing structural MRI acquisition optimization, calibration and validation to include T2 and DTI; 2) translation of site specific state-of-the-art image analysis, visualization and machine learning technologies to work in the federated, multi-site BIRN environment; and 3) extension of data management and database query capabilities to include additional imaging modalities, clinical disorders and individualized human genetic covariates. These broad areas of work will come together in through key collaborations that will ensure utilization promotion by facilitating data entry into the federated database and creation of database incentive functionality. Our participating sites include MGH (PI), BWH, UCI, Duke, UCLA, UCSD, John Hopkins, and newly added Washington University and MIT. We have made a concerted effort to bridge the gap that can exist between biomedical and computational sciences by recruiting to our group leaders in both of these domains. Our efforts will be coordinated with those of the entire BIRN consortium in order to insure that acquisition and database functionality, and application-based disorder queries are interoperable across sites and designed to advance the capabilities to further knowledge and understanding of health and disease.         n/a",Morphometry Biomedical Informatics Research Network,6909355,U24RR021382,"['bioimaging /biomedical imaging', 'bioinformatics', 'clinical research', 'computational biology', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'cooperative study', 'data management', 'human subject', 'imaging /visualization /scanning', 'information systems', 'magnetic resonance imaging', 'method development', 'molecular biology information system', 'morphometry', 'neurogenetics', 'neuroimaging', 'neuropsychology']",NCRR,MASSACHUSETTS GENERAL HOSPITAL,U24,2004,3821536,0.00478710874917904
"Artificial Intelligence Methods for Crystallization DESCRIPTION (provided by applicant): It is widely believed that crystallization is the rate-limiting step in most X-ray structure determinations. We have therefore been developing computational tools to facilitate this process, including the XtalGrow suite of programs. Here we propose to improve the power and scope of these tools along two fronts: 1. Initial screening, the (iterative) set of experiments that hopefully, yields one or more preliminary ""hits"" (crystalline material that is demonstrably protein); and 2. Optimization experiments that begin with an initial hit and end with diffraction-quality crystals. A central concept of this proposal is that this tool building requires a knowledge-based foundation. Therefore, one of the broad goals of the proposal is to develop a framework for the acquisition and encoding of knowledge in computationally tractable forms; specifically, forms that will yield more effective crystallization procedures. We are interested in how the data interact and how that can be used to improve the crystallization process. While available data, both in the literature and from other projects in the laboratory will continue to be used wherever possible, our analysis has also demonstrated the need to be pro-active i.e. to gather selected data required to complete the knowledge base. We propose to do this by: I. Deepening the data representations is several areas including additional protein characteristics, incorporating a hierarchy of chemical additives and acquiring detailed response data. 11. Improving the efficiency of crystallization screens: Initial crystallization screens would be improved by applying inductive reasoning to the refinement of Bayesian belief nets; procedures would also be developed for dealing with the absence of promising results by identifying unexplored regions of the parameter space and using additional measurements, such as dynamic light scattering and cloud point determinations to further refine the Bayesian belief nets and steer experimentation in more promising directions. Optimization screens would be improved by applying Case-Based and Bayesian methods here as well as by further developments of automated image analysis. III. Improving the ""user friendliness,"" integration and automation of the entire system. n/a",Artificial Intelligence Methods for Crystallization,6682996,R01RR014477,"['X ray crystallography', ' artificial intelligence', ' automated data processing', ' chemical structure', ' computer human interaction', ' computer program /software', ' computer system design /evaluation', ' crystallization', ' data collection methodology /evaluation', ' image processing', ' mathematics', ' method development', ' protein structure function']",NCRR,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2003,298672,-0.021527848529205702
"MicroSeer, Analysis software for microscopy imagery  DESCRIPTION (provided by applicant): This project will create new pattern recognition software to improve the analysis and interpretation of in vivo  biomedical imagery. Currently, researchers can get remarkably detailed images of living cells and their  constituent proteins using molecular genetic and microscopy-based approaches in conjunction with  sophisticated microscopy hardware. Available image analysis techniques and software, however, lag behind  the power of this new imaging equipment to visualize the microscopic world.  This phase I SBIR project will apply existing technology in spatial analysis of satellite image data to microscopy data, create new statistical techniques specific to the study of spatial association of proteins in  cells, and create software that implements these statistics for use in the analysis of spatial association timeslice in vivo biomedical imagery.   n/a","MicroSeer, Analysis software for microscopy imagery",6581125,R43EB000575,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer data analysis', ' computer graphics /printing', ' computer program /software', ' computer system design /evaluation', ' image processing', ' statistics /biometry', ' structural biology']",NIBIB,BIOMEDWARE,R43,2003,177261,0.03246363669110291
"Vessel Segmentation/Registration from Ultrasound Images    DESCRIPTION (provided by applicant):    Ultrasound is widely used for imaging of blood vessels as it is non-invasive, real-time, and relatively inexpensive. This proposal focuses on segmentation of abdominal aortic aneurysms (AAA) from ultrasound images with extension to other vascular imaging applications in the long term. Reliable quantitative evaluation of AAAs plays a pivotal role in diagnoses and frequent follow-up studies needed to avoid life-threatening rupture. These studies require vessel segmentation (for size analysis) and registration between serial studies (for monitoring the progression of the disease before and/or after vascular repair). AAA evaluation is routinely carried out for both high-risk patient populations and those treated with endovascular repair. Currently, AAA management is primarily based on measurements from two-dimensional (2-D) slices in CT scans. AAA monitoring and follow-up could be improved by 1) measurement from 3-D reconstructions, and 2) use of ultrasound imaging to minimize radiation exposure and reduce costs. 3-D ultrasound reconstructions provide accuracy comparable to that of CT. However, large inter-observer variability and long processing times preclude routine clinical use of 3-D image information. This research aims to develop software solutions for improved ultrasound-based AAA monitoring and other vascular diseases (in the long term). The tools used will be based on advanced image segmentation and registration algorithms involving curvature-driven image processing techniques and deformable models. The goal of the Phase I study is to establish feasibility of the proposed methods by demonstrating an improvement in the repeatability and accuracy of measurements and reduction in delineation time.         n/a",Vessel Segmentation/Registration from Ultrasound Images,6641019,R43HL069540,"['abdomen', ' aorta aneurysm', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer program /software', ' computer system design /evaluation', ' gastrointestinal circulation disorder', ' gastrointestinal imaging /visualization', ' human data', ' mathematics', ' three dimensional imaging /topography']",NHLBI,INSIGHTFUL CORPORATION,R43,2003,99621,0.009831748893643784
"Optimized Retinal Camera DESCRIPTION (provided by applicant):  A low-cost, high-resolution, high-contrast color digital camera optimized for ophthalmology will be demonstrated. This Optimized Retinal Camera will be specifically tested for its effectiveness in meeting the image quality requirements for the screening and assessment of pre-proliferative and proliferative diabetic retinopathy in both traditional clinical settings and in telemedicine. The proposed device exploits recent technological advances in high sensitivity charge coupled device (CCD) cameras and digital signal processing electronics. Today's CCD cameras do not have the dynamic range to image the human retina. The human retina is characterized by regions of high reflectivity (20-40 percent), such as the optic disc, and very low reflectivity (<2 percent), such as the macula and fovea. Further, these existing digital cameras treat each of the color channels in the same manner and do not consider the special, red-saturated characteristics of the retina. The approach builds on existing fundus imaging technology developed by Kestrel for the National Eye Institute. The proposed Optimized Retinal Camera will be shown to offer significant improvement over existing digital color cameras by addressing each of the deficiencies mentioned above. Joslin Diabetes Center, the University of Iowa Department of Opthalmology, and the University of New Mexico Health Sciences Center will provide independent, ""masked"" evaluation of the optimized digital retinal images. n/a",Optimized Retinal Camera,6583366,R44EY013038,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' diabetic retinopathy', ' digital imaging', ' human subject', ' image processing', ' ophthalmoscopy', ' thermodynamics']",NEI,KESTREL CORPORATION,R44,2003,431799,0.01084355364627661
"Computer Imaging to Diminish Alopecia Distress    DESCRIPTION (provided by investigator):  The goal of the research proposed herein is to develop a low-cost, user-friendly, computer-based imaging system for use by women to reduce anxiety and distress relating to alopecia (hair loss) prior to or following chemotherapy. It has been reported that 47% to 58% of women with cancer cite the likelihood of alopecia as the most disturbing anticipated aspect of receiving chemotherapy, with 8% stating that they seriously considered refusing treatment due to this possibility. Utilizing advanced graphical processing techniques, the proposed ""Help for Alopecia through Image Representations"" (HAIR) system will permit cancer patients of all races and ethnicities to interactively visualize, using their own image, the process of hair loss, accessorization options (e.g., wigs, head scarves, hats, etc.), and the corresponding stages of hair regrowth. ""Scripting"" (i.e., rehearsing) the side-effects of chemotherapy and potential patient responses will significantly reduce the anxiety caused by the prospect of alopecia. This will serve to desensitize women to alopecia, allow them to make better-informed treatment decisions, and facilitate coping when it occurs.         n/a",Computer Imaging to Diminish Alopecia Distress,6586963,R43CA099873,"['alopecia', ' artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted patient care', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' coping', ' desensitization psychotherapy', ' drug adverse effect', ' female', ' imaging /visualization /scanning', ' psychological aspect of cancer', ' quality of life', "" women's health""]",NCI,"BARRON ASSOCIATES, INC.",R43,2003,99973,-0.015574211017362932
"Novel Methods for Automated Key Image Selection    DESCRIPTION (provided by the applicant):  Significant new knowledge about human behavior and the brain has come to light in recent years, due in part to rapid technical developments in imaging. As the role of imaging becomes increasingly important in neurosciences, effective methods for managing and retrieving images will become even more critical; without such advances, further progress will be hindered. The goal of this proposal is the automated summarization of large imaging sets. Image summarization proffers a method to compress imaging studies by selecting only pertinent image slices that objectively document a patient's condition; as such, its applications include multimedia electronic medical records, telemedicine, and teaching files. In Phase I, development is focused on a customizable brain atlas used for registering patient imaging studies in order to select key images. This phase addresses selection of images from ""normal"" studies and studies with only subtle morphological changes, as typical of most patients with psychiatric disorders. Automatic techniques for customizing the atlas to imaging study acquisition parameters are developed, in addition to registration methods for mapping the atlas to the patient's original study. Building from this initial work, Phase II expands to encompass selection of images from ""abnormal"" studies that exhibit gross morphological changes through principle component analysis, further customization of the atlas for different age groups (e.g., pediatric), and incorporation of structured data entry (SDE) and natural language processing (NLP) of medical reports to help guide automatic selection of key images. The resultant product will be a fully automated software system that can select relevant images from any imaging study. Initial evaluation in Phase I will examine the performance of the contrast customizable atlas and summarization/relevant slice selection, as compared to human experts.         n/a",Novel Methods for Automated Key Image Selection,6583176,R43MH065764,"['archives', ' biomedical automation', ' clinical research', ' computer data analysis', ' computer program /software', ' computer system design /evaluation', ' data management', ' human data', ' image processing', ' method development']",NIMH,MEDAXIS CORPORATION,R43,2003,93365,0.020414021238035703
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6636516,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2003,374063,0.008522652948295958
"Rare Cell Analysis by Multi-Spectral Flow Imaging The ability to detect and analyze rare malignant cells in body fluids has profound implications for the early detection of malignancy as well as for monitoring of residual disease and metastases. Current methodologies for accurately detecting abnormal cells within a population of normal cells are limited. Amnis' ImageStream technology combines the high-resolution imaging performance of microscopy and the high-speed cellular analysis and sorting capabilities of flow cytometry in a single platform. ImageStream employs time delay integration detection, resulting in up to a 1000 fold increase in signal collection over conventional instrument designs. The goal of this Phase I study is to optimize algorithms, electronics, and assays for the detection and analysis of rare exfoliated cells in body fluids. The image segmentation algorithm will be redesigned to operate with brightfield imagery as well as fluorescence and implemented on high-speed image computing hardware. A morphological feature set will be developed to discriminate epithelial cells. Ultimately, it is expected that instrumentation based on ImageStream technology will find application in the biological research laboratory, drug discovery arena, and in the clinical setting as a screening system for he early detection of cancer. PROPOSED COMMERCIAL APPLICATIONS: Amnis' ImageStream technology represents an entirely new class of cellular analysis instrumentation with numerous opportunities for commercialization. It is expected that ImageStream will find application in drug discovery, biological research, genomics and proteomics, non- invasive prenatal diagnostics and early-stage cancer detection. n/a",Rare Cell Analysis by Multi-Spectral Flow Imaging,6446577,R43CA094590,"['artificial intelligence', ' bioimaging /biomedical imaging', ' cell line', ' cell population study', ' cell type', ' computer program /software', ' computer system design /evaluation', ' cytology', ' fluorescence microscopy', ' fluorescent dye /probe', ' human tissue', ' image processing', ' imaging /visualization /scanning']",NCI,AMNIS CORPORATION,R43,2002,124380,-0.020011071488882627
"Multiresolution Autofocusing for Automated Cytogenetics The goal of this project is to develop innovative digital microscope autofocusing techniques for automated cytogenetics applications.  We propose a novel multi-resolution image analysis approach to focus measurement and detection, based on the recently developed mathematical theory of wavelet transform.  In comparison to currently available single-resolution techniques, the proposed method overcomes their fundamental limitations and promises considerably more accurate, reliable and faster means to compute and determine in-focus image position for image acquisition.  This will significantly increase the ability and efficacy of automated scanning microscope instruments for clinical and cancer cytogenetics applications. In Phase 1 we will investigate the feasibility of the proposed method based on its utilization in fluorescence microscopy.  We will develop and implement the algorithm and software for multi-resolution focus function computation and in-focus position determination.  We will test and evaluate the new method against the current best-performing algorithms by comparing (1) Accuracy; (2)  Range; (3)  Insensitivity to other parameters; and (4)  Speed. If the new approach achieves superior performance, in Phase 2 the technique will be further developed and extended to bright-field microscopy applications.  When fully developed, the new technology will be made available to Applied Imaging (AIC) for integration into the PowerGene cytogenetics automation products. PROPOSED COMMERCIAL APPLICATIONS: As soon as the new techniques are developed and qualified for routine application, they will be made available to AIC for incorporation into the PowerGene product line of cytogenetics automation equipment, both in new systems sold and as an upgrade to existing systems already in use in cytogenetics labs, thus commercializing the technology quickly. n/a",Multiresolution Autofocusing for Automated Cytogenetics,6443502,R43RR016817,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical automation', ' clinical research', ' computer program /software', ' computer system design /evaluation', ' cytogenetics', ' digital imaging', ' fluorescence microscopy', ' fluorescent in situ hybridization', ' human data', ' image enhancement', ' image processing', ' mathematical model']",NCRR,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R43,2002,91727,0.01933773282166272
"Deployment Framework for Medical Imaging Applications DESCRIPTION (provided by applicant): There are many reasons for the relatively slow proliferation of advanced medical image processing methods but a significant reason is the present paradigm for providing access: most applications are still tied to proprietary software and hardware environments that carry significant up-front costs. The ultimate intent of this work is leverage commodity computing technologies to develop an open, extensible framework for deploying medical image processing applications in the heterogeneous, networked computing environment of today. The framework will provide clinicians and researchers access to state-of-the-art image processing applications regardless of their particular computing platform or locally available computing resources connecting them with federated database resources, with high-end computing resources, or even with their colleagues in a peer-to-peer computing environment. The aims for Phase I of this project are: (1) Demonstrate that the framework provides access to image processing applications to an extent that is largely independent of local computing resources. (2) Demonstrate that the framework is general in that the same components can be reused for deploying a wide variety of medical imaging applications. (3) Demonstrate that the framework is customizable both by third-party developers and by end-users allowing power-users to both create and deploy new applications. Work in Phase II will extend the framework and develop two-demonstration applications--computer aided diagnosis (CAD) for mammography and multimodality image fusion. The ultimate goal is to obtain key partnerships and the private equity investment necessary for commercialization, which will proceed by launching revenue-generating versions of the CAD and image fusion applications. n/a",Deployment Framework for Medical Imaging Applications,6494576,R44EB000149,"['artificial intelligence', ' bioimaging /biomedical imaging', ' clinical research', ' computed axial tomography', ' computer assisted diagnosis', ' computer human interaction', ' computer network', ' computer program /software', ' computer system design /evaluation', ' human data', ' image processing', ' mammography', ' mathematics', ' positron emission tomography', ' telemedicine']",NIBIB,"FRONTIER MEDICAL, LLC",R44,2002,143577,-0.009418962457735658
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6520333,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2002,363261,0.008522652948295958
"ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR Imaging detectors for 10 to 150 keV photons have many uses in medical technology, including tumor imaging, SPECT, and radiography. Digital output is particularly useful since it allows image enhancement, analysis, transmission and storage. In Phase I we proposed a new technology that could capture images with 100 microm spatial resolution and 1 keV energy resolution or better. This capability would facilitate entirely new classes of medical diagnostic procedures, particularly for transgenic small animal imaging. Our Phase I work demonstrated the feasibility of this approach. In this Phase II effort, collaborating with Paul Luke at LBNL, we will construct 1 cm thick crossed-strip HPGe detectors having 10 x 10 strips, each 2 mm x 20 mm. We will develop cooled FET preamplifiers having low noise and large bandwidth properties specifically required by this approach. We will also develop analog filtering electronics to condition the detector's novel signals and employ digital pulse processing electronics to acquire these signals at rates up to 10/6 cps. Finally, we will devise procedures to test the detector's linearity and develop processing algorithms to perfect this quality. Phase II will conclude with a working and tested prototype. Phase III will entail primarily production engineering efforts. PROPOSED COMMERCIAL APPLICATION: As an energy resolved digital detector with 100 microm spatial resolution, the proposed detector technology could find many medical applications, including SPECT, energy resolved angiography for small mammals, bone densitometry on rodent bones, and small, hand-held gamma cameras. Non-medical applications would include non-destructive testing, astrophysical gamma imaging, nuclear cleanup uses, and x-ray diffraction detectors.  n/a",ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR,6376544,R44CA075844,"['X ray', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' cadmium', ' clinical biomedical equipment', ' digital imaging', ' gamma radiation', ' tellurium', ' zinc']",NCI,X-RAY INSTRUMENTATION ASSOCIATES,R44,2001,373949,0.00899995806971588
"Simulation Algorithms for Spatial Pattern Recognition   DESCRIPTION (provided by applicant): A new generation of satellites is imaging       the earth's surface with unprecedented spatial and spectral resolution. With         the ability to identify local features related to environmental exposures, this      high-resolution imagery is gong to revolutionize health risk assessment. The         realization of this potential depends critically on our ability to recognize         spatial patterns on these large images. This project will develop fast spatial       null models for use in statistical pattern recognition, and will accomplish 4        aims.                                                                                                                                                                     (1) Implement fast simulation algorithms conditioned on properties of the data,      and on spatial functions;                                                            (2) Assess project feasibility by evaluating the performance of these                algorithms on existing high-resolution, hyperspectral imagery;                       (3) Implement the simulation algorithms in 2 commercial spatial analysis             software packages;                                                                   (4) Apply the software and methods to demonstrate the approach and unique            benefits for risk assessment.                                                                                                                                             The phase 1 research will address the first two aims; aims three and four will       be accomplished in phase 2 once feasibility is demonstrated. The technologic         and scientific innovations from this project are expected to greatly enhance         our ability to extract knowledge from high resolution imagery.                       PROPOSED COMMERCIAL APPLICATION:  The imminent launch of over a dozen satellites capable of high-resolution imagery is giving  health researchers powerful new data for relating environmental features to health   outcomes, but existing software packages cannot undertake spatial analysis of these  extraordinarly large data sets.   The fast simulation algorithms from this research will  be incorporated into 2 commercial software packages, providing advanced spatial  analysis for large imagery.                                                                                     n/a",Simulation Algorithms for Spatial Pattern Recognition,6401389,R43CA092807,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data management', ' image processing', ' imaging /visualization /scanning', ' statistics /biometry']",NCI,BIOMEDWARE,R43,2001,170490,0.009409436807498863
"COMPUTER-ASSISTED CHEST RADIOGRAPH READER The long term objective of this phase is to provide a means for reducing inter- and intra- reader variability in diagnosing interstitial lung diseases in chest radiographs through a computer-based system for analyzing digital images. The Computer-assisted Chest Radiograph Reader System (CARRS) applies recognized principles in the psychophysics of human vision, incorporates neural network-based image analysis and integrates these with a graphical user interface. Advances in digital image processing, and classification techniques have made CARRS feasible for meeting screening, research arid development, and clinical requirements. CARRS will implement the International Labor Organization (ILO) classification procedures. The specific aims of this project are to implement enhancements to  the CARRS prototype developed in Phase I and to validate the advanced version with several hundred chest radiographs. PROPOSED COMMERCIAL APPLICATION: Today, there exists a need for an automated chest radiograph diagnostic system to screen the thousands of images collected daily at radiological service centers and hospitals worldwide and throughout the United States. A computer-based system that eliminates or reduces inter- and intra-reader variability significantly is required to improve the management and early diagnosis of the disease. CARRS would be marketed and sold to most radiological services centers and hospitals worldwide and throughout the U.S.  n/a",COMPUTER-ASSISTED CHEST RADIOGRAPH READER,6445973,R44OH003595,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical biomedical equipment', ' computer assisted diagnosis', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mass screening', ' thoracic radiography']",NIOSH,KESTREL CORPORATION,R44,2001,354009,-0.0041157187704731445
"MAX-ENTROPY CONTROL FOR HIGH QUALITY DIGITAL IMAGING   A low-cost, high-resolution, high-contrast color digital camera optimized        for ophthalmology will be demonstrated. The maximum entropy camera         will be tested for its effectiveness in meeting the image quality requirements       for telemedicine and for remote screening of pre-proliferative and                   proliferative diabetic retinopathy. The proposed device exploits recent              technological advances in high sensitivity CCD cameras and digital signal            processing electronics. Today's low cost 8-bit CCD cameras do not have the           dynamic range to image the human retina, which is characterized by regions of        high reflectivity (20-40 percent), such as the optic disc, and very low              reflectivity (<2 percent), such as the macula and fovea. Existing digital            cameras used in ophthalmology are not designed to deal with the high dynamic         range and do not consider the special re-saturated characteristics of the            retina. The proposed device will be shown to offer significant improvement over      existing digital color cameras by addressing each of the deficiencies                mentioned.                                                                           PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                     n/a",MAX-ENTROPY CONTROL FOR HIGH QUALITY DIGITAL IMAGING,6292349,R43EY013038,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' charge coupled device camera', ' computer program /software', ' computer system design /evaluation', ' diabetic retinopathy', ' digital imaging', ' image processing', ' ophthalmoscopy', ' thermodynamics']",NEI,KESTREL CORPORATION,R43,2001,107706,0.008446762402132681
"INFORMATION PROCESSING IN MEDICAL IMAGING CONFERENCE This application is a request for support of the July 2001 meeting on Information Processing in Medical Imaging (IPMI'01) to be held on the campus of the University of California, Davis. During 16 previous meetings, this biennial workshop-style conference has traditionally concentrated on the latest advancements in the acquisition, processing, analysis, display, and perception of medical images. At the 2001 meeting, we intend to continue this tradition while encouraging contributions from young investigators, specifically advanced graduate students, postdoctoral fellows, and junior faculty. The emphasis is on applied mathematical techniques in computer vision, microimaging techniques, and information technology. Advances reported at this meeting are especially important in the study of neurological disorders, cardiovascular disease and cancer, although applications in the area of functional genomics, orthopedics and soft tissue biomechanics are also represented. The conference attracts researchers from a broad range of disciplines, particularly computer scientists, neuroscientists, electrical engineers, cardiologists, mathematicians, oncologists, and physicists. All share an interest in improving the quality of health care through the extraction and presentation of diagnostic information from medical image data. Approximately 130 individuals will be invited to attend; there will be approximately 25-30 speakers and 25-30 poster presentations. Papers are accepted based on peer review by a 25 member scientific committee of 15-20 page manuscripts. Selected papers will be published in proceedings that will be available at the conference.  n/a",INFORMATION PROCESSING IN MEDICAL IMAGING CONFERENCE,6231502,R13RR015416,"['bioimaging /biomedical imaging', ' biomechanics', ' cardiovascular disorder', ' computer data analysis', ' diagnosis design /evaluation', ' functional /structural genomics', ' image processing', ' informatics', ' mathematics', ' meeting /conference /symposium', ' neoplasm /cancer', ' nervous system disorder', ' orthopedics']",NCRR,UNIVERSITY OF CALIFORNIA DAVIS,R13,2001,5000,0.010868682248033664
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6484619,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2001,337739,0.008522652948295958
"ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR Imaging detectors for 10 to 150 keV photons have many uses in medical technology, including tumor imaging, SPECT, and radiography. Digital output is particularly useful since it allows image enhancement, analysis, transmission and storage. In Phase I we proposed a new technology that could capture images with 100 microm spatial resolution and 1 keV energy resolution or better. This capability would facilitate entirely new classes of medical diagnostic procedures, particularly for transgenic small animal imaging. Our Phase I work demonstrated the feasibility of this approach. In this Phase II effort, collaborating with Paul Luke at LBNL, we will construct 1 cm thick crossed-strip HPGe detectors having 10 x 10 strips, each 2 mm x 20 mm. We will develop cooled FET preamplifiers having low noise and large bandwidth properties specifically required by this approach. We will also develop analog filtering electronics to condition the detector's novel signals and employ digital pulse processing electronics to acquire these signals at rates up to 10/6 cps. Finally, we will devise procedures to test the detector's linearity and develop processing algorithms to perfect this quality. Phase II will conclude with a working and tested prototype. Phase III will entail primarily production engineering efforts. PROPOSED COMMERCIAL APPLICATION: As an energy resolved digital detector with 100 microm spatial resolution, the proposed detector technology could find many medical applications, including SPECT, energy resolved angiography for small mammals, bone densitometry on rodent bones, and small, hand-held gamma cameras. Non-medical applications would include non-destructive testing, astrophysical gamma imaging, nuclear cleanup uses, and x-ray diffraction detectors.  n/a",ENERGY RESOLVED DIGITAL HPGE X OR Y-RAY IMAGING DETECTOR,6211037,R44CA075844,"['X ray', ' artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' cadmium', ' clinical biomedical equipment', ' digital imaging', ' gamma radiation', ' tellurium', ' zinc']",NCI,X-RAY INSTRUMENTATION ASSOCIATES,R44,2000,416478,0.00899995806971588
"COMPUTER-ASSISTED CHEST RADIOGRAPH READER The long term objective of this phase is to provide a means for reducing inter- and intra- reader variability in diagnosing interstitial lung diseases in chest radiographs through a computer-based system for analyzing digital images. The Computer-assisted Chest Radiograph Reader System (CARRS) applies recognized principles in the psychophysics of human vision, incorporates neural network-based image analysis and integrates these with a graphical user interface. Advances in digital image processing, and classification techniques have made CARRS feasible for meeting screening, research arid development, and clinical requirements. CARRS will implement the International Labor Organization (ILO) classification procedures. The specific aims of this project are to implement enhancements to  the CARRS prototype developed in Phase I and to validate the advanced version with several hundred chest radiographs. PROPOSED COMMERCIAL APPLICATION: Today, there exists a need for an automated chest radiograph diagnostic system to screen the thousands of images collected daily at radiological service centers and hospitals worldwide and throughout the United States. A computer-based system that eliminates or reduces inter- and intra-reader variability significantly is required to improve the management and early diagnosis of the disease. CARRS would be marketed and sold to most radiological services centers and hospitals worldwide and throughout the U.S.  n/a",COMPUTER-ASSISTED CHEST RADIOGRAPH READER,6210821,R44OH003595,"['artificial intelligence', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' clinical biomedical equipment', ' computer assisted diagnosis', ' diagnosis quality /standard', ' digital imaging', ' image processing', ' mass screening', ' thoracic radiography']",NIOSH,KESTREL CORPORATION,R44,2000,395990,-0.0041157187704731445
"IMAGE PATTERN BASED WAVELET COMPRESSION FOR RADIOLOGY DESCRIPTION:  The research and development of teleradiology and telemedicine     systems has progressed through many technical and clinical endeavors.  When      dealing with large volume image transmission and storage, image data             compression is an outstanding issue in medical applications to which current     techniques were not designed to address.  The technical objectives of this       project are to develop optimized error-free as well as error-controllable        methods for medical image compression based on wavelet transform and             associated methods.  In this project, we employ both advanced artificial         intelligent and compression techniques to achieve these goals.                                                                                                    Our recent research outcomes include:  (a) development of a mathematics          approach to unify prediction, subband, and wavelet transforms, (b)               development of convolution neural network training methods to obtain             optimized wavelet kernel, (c) development of a data splitting technique to       improve edge accuracy and to provide error-control methods, and (d)              development of an integer implementation method for all wavelet transforms,      etc.  Based on the above technical advances, we propose to use integer form      of an adaptive (optimized) wavelets in conjunction with newly developed          coding methods such as ""partitioning in hierarchical trees"" (PHT) for            lossless compression.  For error-controllable approaches, we propose to use      adaptive wavelets coupled with optimized neural network prediction methods       in this study.  Since lossless compression is a part of the error -              controllable method, both systems can be implemented in the same scheme          which is a breakthrough approach in the field.  We will compare the              compression results (i.e., compression ratio and speed) of the proposed          compression methods with those of the current wavelet techniques using the       embedded zero-tree coding method.  At the end of the project, we will            deliver a software package for the radiological society.  Hence, the             evaluation for various clinical applications using the proposed methods can      be performed by the investigators.                                                                                                                                As the field of telemedicine is rapidly growing, we believe that development     of a dedicated compression module for economical storage and fast                communication of patient data (particularly for patient images) is               necessary.  This project is designed to address the related technical issues     with a strong clinical consideration.                                             n/a",IMAGE PATTERN BASED WAVELET COMPRESSION FOR RADIOLOGY,6173899,R01CA079139,"['artificial intelligence', ' bioimaging /biomedical imaging', ' charge coupled device camera', ' computational neuroscience', ' computer program /software', ' computer system design /evaluation', ' digital imaging', ' human data', ' image processing', ' radiology', ' telemedicine']",NCI,GEORGETOWN UNIVERSITY,R01,2000,176034,0.016166661787736333
"DEVELOPMENT OF A KNOWLEDGE-BASED IMAGE REPORTING SYSTEM We have constructed a prototype structured reporting system that replaces conventional dictation and transcription for medical image reporting. Key design features include reporting speed, generation of graphical reports, structured storage of imaging findings, and the use of existing lexicons. Pilot timing data suggest that a radiologist using our system can generate a report more rapidly than with conventional reporting methods or speech recognition systems. Support is sought to refine the prototype, and to conduct feasibility testing. The specific aims are (1) to augment and refine a hierarchical test lexicon of imaging terms (2) to develop methods for the representation and reporting of imaging findings and their logical relationships, (3) to evaluate the system's performance on clinical imaging reports, and (4) to assess the completeness of existing lexicons for imaging. The project is supported by a Technical Advisory Committee comprised of experts in key methodological areas. A successful Phase I will lead (in Phase II) to testing of the approach for cross-sectional imaging, to adoption, augmentation, and use of an existing lexicon, to construction of real-time decision support techniques based on the knowledge base of imaging findings generated by the system, and to system evaluation in a clinical setting. PROPOSED COMMERCIAL APPLICATIONS: Our structured reporting system is appealing to radiologists because it speeds up the reporting process compared to conventional dictation/transcription or speech recognition. In addition, the system eliminates the costs, delays, inaccuracies, and other organizational problems associated with transcription services, thereby improving patient care. Therefore, time-efficient, speech-augmented structured reporting systems will likely capture a significant segment of the $1.2 billion annual market for radiology transcription services.  n/a",DEVELOPMENT OF A KNOWLEDGE-BASED IMAGE REPORTING SYSTEM,6073984,R43LM006837,"['artificial intelligence', ' bioimaging /biomedical imaging', ' computer assisted medical decision making', ' computer system design /evaluation', ' data management', ' imaging /visualization /scanning', ' information systems', ' vocabulary', ' vocabulary development for information system']",NLM,"EDICT SYSTEMS, INC.",R43,2000,98563,-0.057447213208772795
"WAVELET ENHANCEMENT OF CHROMOSOME BANDING PATTERNS This project aims to develop and commercialize significantly improved software for digital enhancement of the detail of chromosome banding patterns in microscopic images. These investigators have developed an innovative technique for this application, based upon wavelet transforms and multiresolution image analysis. Used with modern computerized chromosome analysis the proposed technique promises significantly improved enhancement of chromosome banding patterns and more effective visual detection of subtle rearrangements. This will help clinicians and researchers detect previously invisible or sub-visible band pattern alterations in conventional and high resolution banding. It will significantly increase the ability of automated instruments to assist the evaluation of chromosome alterations in clinical samples and in normal and neoplastic mammalian cells. During Phase I we implemented and tested three wavelet transforms with desirable mathematical properties. We developed a prototype multiresolution image processing system for chromosome enhancement. We obtained extremely encouraging results, strongly suggesting that these techniques offer considerably improved enhancement capability over conventional methods. and clearly demonstrating the feasibility of this approach. In Phase II we will complete the implementation and refinement of the software. We will implement several wavelet design approaches and evaluate many wavelet transform basis function sets that potentially can bring out relevant detail in chromosome banding patterns. PROPOSED COMMERCIAL APPLICATIONS: As soon as the new enhancement techniques are developed and qualified for routine application, they will be incorporated into PSII's PowerGene products, both in new systems sold and as an upgrade to existing systems.  n/a",WAVELET ENHANCEMENT OF CHROMOSOME BANDING PATTERNS,6181715,R44HD033658,"['artificial intelligence', ' bioengineering /biomedical engineering', ' bioimaging /biomedical imaging', ' chromosome aberrations', ' chromosomes', ' computer data analysis', ' computer program /software', ' computer simulation', ' cytogenetics', ' digital imaging', ' image enhancement', ' image processing', ' molecular dynamics']",NICHD,"ADVANCED DIGITAL IMAGING RESEARCH, LLC",R44,2000,260552,0.01771618718827725
"AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY Molecular microscopy has become an increasingly important tool for structural biology but the methodology is very labor intensive and very slow.  It is generally recognized that the development of improved capabilities for three-dimensional electron microscopy are critical for progress in emerging integrative research in molecular cell biology.  We aim to develop a system for rapid routine structure determination of macromolecular assemblies.  Our ultimate goal is to develop an integrated system that can produce a three-dimensional electron density map of a structure within a few hours of inserting a specimen in the electron microscope.  The motivation for this work is to provide answers to interesting biological questions. We will initially use our work on motor-microtubule complexes and actomyosin as the driver for the development of the integrated system.  By tightly coupling the development of the new system with its implementation in a laboratory whose primary goal is answering fundamental questions in cell biology, we will obtain immediate and invaluable feedback as to how the system is used in practice. Developing this system will involve devising new approaches and integrating the results of several ongoing research projects. The primary specific aims are:  (1) To remove the requirement for using film to acquire the high magnification electron micrographs.  This will require the development of feature recognition algorithms and new imaging strategies that take into account the characteristics of currently available digital cameras.  (2) Improve and automate our existing software for helical image analysis.  We will incorporate new methods for determining the helical parameters of an unknown specimen, methods for improving the resolution, and methods for analyzing non-helical specimens.  (3) Integration of the acquisition and the analysis steps.  This will require incorporation of machine learning techniques to produce a system that is highly efficient in terms of throughput and data quality. The general framework for integrated acquisition and analysis to be developed will be readily extendible to other specimens (helical tubes, single particles, two-dimensional crystals). Thus, once the system has been successfully implemented it will be made generally available to the scientific community.  The system we plan to develop has the potential to revolutionize the field of three-dimensional electron microscopy and make this approach accessible to a wide community.  n/a",AN INTEGRATED SYSTEM FOR MOLECULAR MICROSCOPY,6193019,R01GM061939,"['actins', ' bioimaging /biomedical imaging', ' biomedical equipment development', ' digital imaging', ' electron density', ' electron microscopy', ' image processing', ' microtubules', ' myosins', ' structural biology']",NIGMS,UNIVERSITY OF ILLINOIS URBANA-CHAMPAIGN,R01,2000,478050,0.008522652948295958
"TOPIC #411 - PHASE I SBIR CONTRACT - DE-IDENTIFICATION SOFTWARE TOOLS FOR CANCER IMAGING RESEARCH Developing artificial intelligence technology for medical imaging applications requires training models on large and diverse datasets.  Currently, aggregation of large data repositories, including radiology and pathology images, is limited by concerns around patient privacy.  In order to successfully share medical images, an institution must be able to quickly and accurately de-identify large numbers of images in batches.  This process is currently manual and time-consuming. We propose a pipeline to remove PHI from both radiology DICOM images and pathology whole slide images by leveraging machine learning, natural language processing, and compartmentalized workflow techniques to significantly reduce the human intervention needed to anonymize medical images.  In addition to examining header data in the images, we will use optical character recognition and computer vision algorithms to detect text in any location or orientation in the image, then automatically record and subsequently purge these regions. These techniques will be configured to work on a variety of image types (CT, MRI, radiograph, etc) and cover multiple OEM vendors for both radiology and pathology images. This phase I statement of work will construct the software tools, methods, and datasets necessary to facilitate a phase II where the complex algorithms needed for autonomous deidentification will be developed.  This phase II processing will be referred to throughout this document as the workflow. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - DE-IDENTIFICATION SOFTWARE TOOLS FOR CANCER IMAGING RESEARCH,10274086,5N91020C00023,"['Algorithms', 'Artificial Intelligence', 'Complex', 'Computer Vision Systems', 'Consumption', 'Contracts', 'Data', 'Data Set', 'Digital Imaging and Communications in Medicine', 'Elements', 'Excision', 'Head', 'Human', 'Image', 'Ingestion', 'Institution', 'Intervention', 'Location', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Maps', 'Medical Imaging', 'Medical Technology', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Pathology', 'Phase', 'Process', 'Radiology Specialty', 'Research', 'Sampling', 'Slide', 'Small Business Innovation Research Grant', 'Software Tools', 'Source', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'Vendor', 'Work', 'cancer imaging', 'data ingestion', 'data warehouse', 'file format', 'optical character recognition', 'pathology imaging', 'patient privacy', 'purge', 'radiological imaging', 'whole slide imaging']",NCI,"BIODATA CONSORTIUM, LLC",N43,2020,386526,0.011430906692189002
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10224492,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,233900,0.02894739615476008
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10017950,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data warehouse', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2020,513041,0.02894739615476008
"SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections Automated monitoring and screening of various physiological signals is an indispensable tool in modern medicine. However, despite the  preponderance of long-term monitoring and screening modalities for certain vital signals, there are a significant number of applications for  which no automated monitoring or screening is available. For example, patients in need of urinary catheterization are at significant risk of  urinary tract infections, but long-term monitoring for a developing infection while a urinary catheter is in place typically requires a caregiver to  frequently collect urine samples which then must be transported to a laboratory facility to be tested for a developing infection. Disruptive  technologies at the intersection of lens-free imaging, fluidics, image processing, computer vision and machine learning offer a tremendous  opportunity to develop new devices that can be connected to a urinary catheter to automatically monitor urinary tract infections. However, novel  image reconstruction, object detection and classification, and deep learning algorithms are needed to deal with challenges such as low image  resolution, limited labeled data, and heterogeneity of the abnormalities to be detected in urine samples. This project brings together a multidisciplinary team of computer scientists, engineers and clinicians to design, develop and test a system that integrates lens-free imaging, fluidics, image processing, computer vision and machine learning to automatically monitor urinary tract infections. The system will take a urine sample as an input, image the sample with a lens-free microscope as it flows through a fluidic channel, reconstruct the images using advanced holographic reconstruction algorithms, and detect and classify abnormalities, e.g., white blood cells, using advanced computer vision and machine learning algorithms. Specifically, this project will: (1) design fluidic and optical hardware to appropriately sample urine from patient lines, flow the sample through the lens-free imager, and capture holograms of the sample; (2) develop holographic image reconstruction algorithms based on deep network architectures constrained by the physics of light diffraction to produce high quality images of the specimen from the lens-free holograms; (3) develop deep learning algorithms requiring a minimal level of manual supervision to detect various abnormalities in the fluid sample that might be indicative of a developing infection (e.g., the presence of white bloods cells or bacteria); and (4) integrate the above hardware and software developments into a system to be validated on urine samples obtained from patient discards against standard urine monitoring and screening methods. RELEVANCE (See instructions):  This project could lead to the development of a low-cost device for automated screening and monitoring of urinary tract infections (the most  common hospital and nursing home acquired infection), and such a device could eliminate the need for patients or caregivers to manually collect  urine samples and transport them to a laboratory facility for testing and enable automated long-term monitoring and screening for UTIs. Early  detection of developing UTIs could allow caregivers to preemptively remove the catheter before the UTI progressed to the point of requiring  antibiotic treatment, thus reducing overall antibiotic usage. The technology to be developed in this project could also be used for screening  abnormalities in other fluids, such as central spinal fluid, and the methods to detect and classify large numbers of cells in an image could lead to  advances in large scale multi-object detection and tracking for other computer vision applications. n/a",SCH: A Computer Vision and Lens-Free Imaging System for Automatic Monitoring of Infections,10019459,R01AG067396,"['Algorithms', 'Antibiotic Therapy', 'Antibiotics', 'Bacteria', 'Bacteriuria', 'Caregivers', 'Catheters', 'Cations', 'Cells', 'Cerebrospinal Fluid', 'Classification', 'Clinical', 'Computer Vision Systems', 'Computers', 'Data', 'Detection', 'Development', 'Devices', 'Diagnostic', 'Diffusion', 'Early Diagnosis', 'Engineering', 'Erythrocytes', 'Evaluation', 'Goals', 'Hospital Nursing', 'Image', 'Infection', 'Instruction', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Leukocytes', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Microscope', 'Modality', 'Modern Medicine', 'Monitor', 'Nursing Homes', 'Optics', 'Patients', 'Performance', 'Physics', 'Physiological', 'Prevalence', 'Principal Investigator', 'Procedures', 'Process', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specimen', 'Supervision', 'Surface', 'System', 'Technology', 'Testing', 'Training', 'Urinalysis', 'Urinary Catheterization', 'Urinary tract infection', 'Urine', 'base', 'biological heterogeneity', 'classification algorithm', 'cost', 'deep learning algorithm', 'design', 'diffraction of light', 'heterogenous data', 'hologram', 'image processing', 'image reconstruction', 'imager', 'imaging system', 'laboratory facility', 'lens', 'machine learning algorithm', 'multidisciplinary', 'network architecture', 'novel', 'particle', 'reconstruction', 'screening', 'software development', 'tool', 'urinary']",NIA,JOHNS HOPKINS UNIVERSITY,R01,2020,291252,-0.025576597257699778
"A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney Project Summary  Despite the widespread prevalence of ultrasound imaging in hospitals today, the clinical utility of ultrasound guidance is severely hampered by clutter and reverberation artifacts that obscure structures of interest and com- plicate anatomical measurements. Clutter is particularly problematic in overweight and obese individuals, who account for 78.6 million adults and 12.8 million children in North America. Similarly, interventional procedures of- ten require insertion of one or more metal tools, which generate reverberation artifacts that obfuscate instrument location, orientation, and geometry, while obscuring nearby tissues, thus additionally hampering ultrasound im- age quality. Although artifacts are problematic, ultrasound continues to persist primarily because of its greatest strengths (i.e., mobility, cost, non-ionizing radiation, real-time visualization, and multiplanar views) in comparison to existing image-guidance options, but it would be signiﬁcantly more useful without problematic artifacts.  Our long-term project goal is to use state-of-the-art machine learning techniques to provide interventional radiologists with artifact-free ultrasound-based images. We will initially develop a new framework alternative to the ultrasound beamforming process that removes needle tip reverberations and acoustic clutter caused by multipath scattering in near-ﬁeld tissues when guiding needles to the kidney to enable removal of painful kidney stones. Our ﬁrst aim will test convolutional neural networks (CNNs) that input raw channel data and output human readable images with no artifacts caused by multipath scattering and reverberations. A secondary goal of the CNNs is to learn the minimum number of parameters required to create these new CNN-based images. Our second aim will validate the trained algorithms with ultrasound data from experimental phantom and ex vivo tissue. Our third aim will extend our evaluation to ultrasound images of in vivo porcine kidneys. This work is the ﬁrst to propose bypassing the entire beamforming process and replacing it with machine learning and computer vision techniques to remove traditionally problematic noise artifacts and create a fundamentally new type of artifact-free, high-contrast, high-resolution, ultrasound-based image for guiding interventional procedures.  This work combines the expertise of an imaging scientist, a computer scientist, and an interventional ra- diologist to explore an untapped, understudied area that is only recently made feasible through improvements in computing power, advances in computer vision capabilities, and new knowledge about dominant sources of image degradation. Translation to in vivo cases is enabled by our clinical collaboration with the Department of Radiology at the Johns Hopkins Hospital. With support from the NIH Trailblazer Award, our team will be the ﬁrst to develop these tools and capabilities to eliminate noise artifacts in interventional ultrasound, opening the door to a new paradigm in ultrasound image formation, which will directly beneﬁt millions of patients with clearer, easier-to-interpret ultrasound images. Subsequent R01 funding will customize our innovation to addi- tional application-speciﬁc ultrasound procedures (e.g., breast biopsies, cancer detection, autonomous surgery). Project Narrative Artifacts in ultrasound images, speciﬁcally artifacts caused by multipath scattering and acoustic reverberations (which occur when imaging through the abdominal tissue of overweight and obese patients or visualizing metallic surgical tools), remain as a major clinical challenge. There are no existing solutions to eliminate these artifacts based on today's signal processing techniques. The goal of this project is to step away from conventional signal processing models and instead learn from raw data examples with state-of-the-art machine learning techniques that differentiate artifacts from true signals, and thereby deliver clearer, easier-to-interpret images.",A Machine Learning Alternative to Beamforming to Improve Ultrasound Image Quality for Interventional Access to the Kidney,9913520,R21EB025621,"['Abdomen', 'Acoustics', 'Adolescent', 'Adult', 'Affect', 'Age', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Award', 'Back', 'Biopsy', 'Breast biopsy', 'Bypass', 'Cancer Detection', 'Cardiac', 'Child', 'Clinical', 'Collaborations', 'Computer Vision Systems', 'Computer software', 'Computers', 'Custom', 'Cyst', 'Data', 'Diagnosis', 'Diagnostic', 'Elements', 'Environment', 'Evaluation', 'Excision', 'Family suidae', 'Fatty Liver', 'Funding', 'Geometry', 'Goals', 'Hospitals', 'Human', 'Image', 'Image-Guided Surgery', 'Imaging Phantoms', 'Individual', 'Intervention', 'Interventional Ultrasonography', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Learning', 'Liver diseases', 'Location', 'Machine Learning', 'Measurement', 'Measures', 'Metals', 'Methodology', 'Methods', 'Modeling', 'Morphologic artifacts', 'Needles', 'Network-based', 'Noise', 'Nonionizing Radiation', 'North America', 'Obesity', 'Operative Surgical Procedures', 'Output', 'Overweight', 'Pain', 'Patients', 'Prevalence', 'Procedures', 'Process', 'Radiology Specialty', 'Readability', 'Resolution', 'Retroperitoneal Space', 'Scientist', 'Signal Transduction', 'Source', 'Structure', 'Surgical Instruments', 'Techniques', 'Testing', 'Thick', 'Time', 'Tissues', 'Training', 'Translations', 'Ultrasonography', 'United States', 'United States National Institutes of Health', 'Variant', 'Visualization', 'Work', 'algorithm training', 'base', 'clinical effect', 'convolutional neural network', 'cost', 'deep learning', 'fetal', 'image guided', 'image guided intervention', 'imaging scientist', 'improved', 'in vivo', 'innovation', 'instrument', 'interest', 'lens', 'machine learning algorithm', 'metallicity', 'novel', 'radiologist', 'signal processing', 'tool']",NIBIB,JOHNS HOPKINS UNIVERSITY,R21,2020,235027,0.027429427818161798
"Artificial Intelligence for Assessment of Stargardt Macular Atrophy Project Abstract Stargardt disease is the most frequent form of inherited juvenile macular degeneration. Fundus autofluorescence (FAF) is a widely available imaging technique which may aid in the diagnosis of Stargardt disease and is commonly used to monitor its progression. FAF imaging provides an in vivo assay of the retinal layers, but is only an indirect measure. Spectral-domain optical coherence tomography (SD-OCT), in contrast, provides three-dimensional visualization of the retinal microstructure, thereby allowing it to be assessed directly and individually in eyes with Stargardt disease. At a retinal disease endpoints meeting with the Food and Drug Administration (FDA) in November of 2016, a reliable measure of the anatomic status of the integrity of the ellipsoid zone (EZ) in the retina, was proposed to be a potential suitable regulatory endpoint for therapeutic intervention clinical trials. Manual segmentation/identification of the EZ band, particularly in 3-D OCT images, has proven to be extremely tedious, time-consuming, and expensive. Automated objective segmentation techniques, such as an approach using a deep learning - artificial intelligence (AI) construct, would be of significant value. Moreover, Stargardt disease may cause severe visual loss in children and young adults. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. Thus, this proposal develops an AI-based approach for automated Stargardt atrophy segmentation and the prediction of atrophy progression in FAF and OCT images. More specifically, we first register the longitudinal FAF and OCT enface images respectively, and register the cross-sectional FAF to OCT image. We then develop a 2-D approach for Stargardt atrophy segmentation from FAF images using an AI approach and a 3-D approach for EZ band segmentation from OCT images using a 3-D graph-based approach. Finally, an AI-based approach is developed to predict subsequent development of new Stargardt atrophy or progression of existing atrophy from the OCT EZ band thickness and intensity features of the current patient visit. Project Narrative Stargardt disease is an inherited juvenile-onset macular dystrophy that may cause severe visual loss in children and young adults, thereby causing enormous morbidity with economic, psychological, emotional, and social implications. Early prediction of Stargardt disease progression may facilitate new therapeutic trials. This research proposal describes a novel artificial intelligence approach for automatically assessing macular damage due to Stargardt disease and predicting its progression.",Artificial Intelligence for Assessment of Stargardt Macular Atrophy,9895214,R21EY029839,"['3-Dimensional', 'Adolescent', 'Adult', 'Affect', 'Anatomy', 'Area', 'Artificial Intelligence', 'Atrophic', 'Biological Assay', 'Blindness', 'Child', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Economics', 'Emotional', 'Eye', 'Foundations', 'Fundus', 'Future', 'Goals', 'Graph', 'Image', 'Imaging Techniques', 'Individual', 'Inherited', 'Lifting', 'Light', 'Lipofuscin', 'Macular degeneration', 'Manuals', 'Maps', 'Measures', 'Modality', 'Monitor', 'Morbidity - disease rate', 'Multimodal Imaging', 'Natural History', 'Optical Coherence Tomography', 'Patients', 'Penetration', 'Phenotype', 'Photoreceptors', 'Population', 'Process', 'Prospective Studies', 'Reading', 'Research', 'Research Proposals', 'Retina', 'Retinal Diseases', 'Retrospective Studies', 'Scheme', 'Signal Transduction', 'Stargardt&apos', 's disease', 'Structure of retinal pigment epithelium', 'Surface', 'System', 'Techniques', 'Testing', 'Therapeutic Intervention', 'Therapeutic Trials', 'Thick', 'Time', 'United States Food and Drug Administration', 'Visit', 'Work', 'automated algorithm', 'automated segmentation', 'base', 'clinical practice', 'convolutional neural network', 'cost', 'deep learning', 'experience', 'fighting', 'high risk', 'image registration', 'imaging Segmentation', 'imaging study', 'in vivo', 'macula', 'macular dystrophy', 'meetings', 'multidisciplinary', 'multimodality', 'novel', 'novel therapeutics', 'preservation', 'psychologic', 'research study', 'social implication', 'three-dimensional visualization', 'transmission process', 'young adult']",NEI,DOHENY EYE INSTITUTE,R21,2020,235500,-0.015549508094766035
"Learning an Optimized Variational Network for Medical Image Reconstruction Project Summary We propose a novel way of reconstructing medical images rooted in deep learning and computer vision that models the process how human radiologists are using years of experience from reading thousands of cases to recognize anatomical structures, pathologies and image artifacts. Our approach is based on the novel idea of a variational network, which embeds a generalized compressed sensing concept within a deep learning framework. We propose to learn a complete reconstruction procedure, including filter kernels and penalty functions to separate between true image content and artifacts, all parameters that normally have to be tuned manually as well as the associated numerical algorithm described by this variational network. The training step is decoupled from the time critical image reconstruction step, which can then be performed in near-real-time without interruption of clinical workflow. Our preliminary patient data from accelerated magnetic resonance imaging (MRI) acquisitions suggest that our learning approach outperforms the state-of-the-art of currently existing image reconstruction methods and is robust with respect to the variations that arise in a daily clinical imaging situation. In our first aim, we will test the hypothesis that learning can be performed such that it is robust against changes in data acquisition. In the second aim, we will answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications. Finally, we will perform a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee. We will compare our proposed approach to a clinical standard reconstruction. Our hypothesis is that our approach will lead to the same clinical diagnosis and patient management decisions when using a 5min exam. The immediate benefit of the project is to bring accelerated imaging to an application with wide public-health impact, thereby improving clinical outcomes and reducing health-care costs. Additionally, the insights gained from the developments in this project will answer the currently most important open questions in the emerging field of machine learning for medical image reconstruction. Finally, given the recent increase of activities in this field, there is a significant demand for a publicly available data repository for raw k-space data that can be used for training and validation. Since all data that will be acquired in this project will be made available to the research community, this project will be a first step to meet this demand. Project Narrative The overarching goal of the proposal is to develop a novel machine learning-based image reconstruction approach and validate it for accelerated magnetic resonance imaging (MRI). The approach is able to learn the characteristic appearance of clinical imaging datasets, as well as suppression of artifacts that arise during data acquisition. We will test the hypotheses that learning can be performed such that it is robust against changes in data acquisition, answer the question if it is possible to learn a single reconstruction procedure for multiple MR imaging applications, and validate our approach in a clinical reader study for 300 patients undergoing imaging for internal derangement of the knee.",Learning an Optimized Variational Network for Medical Image Reconstruction,9997914,R01EB024532,"['Acceleration', 'Affect', 'Algorithms', 'Anatomy', 'Appearance', 'Area', 'Blinded', 'Characteristics', 'Clinical', 'Clinical Protocols', 'Communities', 'Computer Vision Systems', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Environment', 'Evaluation Studies', 'Goals', 'Health Care Costs', 'Human', 'Image', 'Individual', 'Interruption', 'Joints', 'Knee', 'Learning', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Motivation', 'Musculoskeletal', 'Neurologic', 'Noise', 'Outcome', 'Pathologic', 'Pathology', 'Patients', 'Pattern', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Public Health', 'Reader', 'Reading', 'Research', 'Sampling', 'Scanning', 'Signal Transduction', 'Step training', 'Structure', 'Testing', 'Time', 'Touch sensation', 'Training', 'Validation', 'Variant', 'base', 'clinical Diagnosis', 'clinical imaging', 'clinical translation', 'conditioning', 'cost', 'data acquisition', 'data space', 'data warehouse', 'deep learning', 'experience', 'image reconstruction', 'imaging modality', 'improved', 'indexing', 'insight', 'learning strategy', 'novel', 'pathology imaging', 'patient population', 'performance tests', 'prospective', 'radiologist', 'reconstruction', 'research clinical testing']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2020,498014,-0.007050063976913783
"TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT This Fast Track SBIR aims to implement comprehensive image anonymization within an enterprise imaging informatics platform built on XNAT.  Our vision is for this platform to provide large healthcare enterprises with tools to generate secure research databases at scale that mirror their clinical image archives.  These databases would then provide local academic and industry collaborators with a rich resource for clinical research and development of AI-powered applications. Thus, our proposed anonymization services are designed to be scalable, risk-based, and verifiable. The platform's AI-powered image anonymization will include automated detection of PHI using a deep learning based natural language processing engine and automated detection of PHI in image content using a convolutational neural network.  The anonymization services will be integrated into Radiologics enterprise and clinical trial XNAT products. n/a",TOPIC #411 - PHASE I SBIR CONTRACT - INTELLIGENT IMAGE ANONYMIZATION WITH XNAT,10274066,5N91020C00025,"['Clinical Research', 'Clinical Trials', 'Computer software', 'Contracts', 'Data', 'Database Management Systems', 'Databases', 'Detection', 'Healthcare', 'Image', 'Industry Collaboration', 'Intelligence', 'Natural Language Processing', 'Phase', 'Radiology Specialty', 'Research', 'Resources', 'Risk', 'Secure', 'Services', 'Small Business Innovation Research Grant', 'Vision', 'base', 'clinical imaging', 'deep learning', 'design', 'image archival system', 'imaging informatics', 'neural network', 'prototype', 'research and development', 'tool']",NCI,"RADIOLOGICS, INC.",N43,2020,399691,0.01162020693814961
"Novel machine learning approaches for improving structural discrimination in cryo-electron tomography Project Summary Cellular cryo-electron tomography (Cryo-ET) has made possible the observation of cellular organelles and macromolecular complexes at nanometer resolution with native conformations. The rapid increasing amount of Cryo-ET data available however brings along some major challenges for analysis which we will timely ad- dress in this proposal. We will design novel data-driven machine learning algorithms for improving structural discrimination and resolution. In particular, we have the following speciﬁc aims: (1) We will develop a novel Autoencoder and Iterative region Matching (AIM) algorithm for marker-free alignment of image tilt-series to re- construct tomograms with improved resolution; (2) We will develop a saliency-based auto-picking algorithm for better detecting macromolecular complexes, and combine it with an innovative 2D-to-3D framework to further improve structure detection accuracy; (3) We will design an end-to-end convolutional model for pose-invariant clustering of subtomograms. This model will produce an initial clustering which will be reﬁned by a new subto- mogram averaging algorithm that automatically down-weights subtomograms of noise and little contribution; (4) We will perform experimental evaluations by using previously reported bacterial secretion systems and mito- chondrial ultrastructures datasets to improve the ﬁnal resolution. Implementing algorithms in Aims 1-3, we will develop a user-friendly open-source graphical user interface -tom to directly beneﬁt the scientiﬁc community.  -tom will be systematically compared with existing software including IMOD, EMAN2, and Relion on simulated and benchmark datasets. To facilitate distribution, -tom will be integrated into existing software platforms Sci- pion and TomoMiner. Our data-driven algorithms and software not only will facilitate and accelerate the future use of Cryo-ET, but also can be readily used on analyzing the existing large amounts of Cryo-ET data to im- prove our understanding of the structure, function, and spatial organization of macromolecular complexes in situ. Project Narrative This project will create a system of machine learning algorithms to accelerate and facilitate the use and re-use of the rapidly accumulating Cryo-ET datasets. For easy use, we will develop an open-source GUI -Tom (to be disseminated into the Scipion and TomoMiner software platforms) that streamlines the new approaches from the initial tomogram reconstruction step to the ﬁnal subtomogram averaging step. We will validate the performance of our system by applying it on published Cryo-ET datasets and monitor the improvement of the ﬁnal results.",Novel machine learning approaches for improving structural discrimination in cryo-electron tomography,9973462,R01GM134020,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Back', 'Benchmarking', 'Biological Process', 'Cells', 'Communities', 'Computer Analysis', 'Computer software', 'Cryo-electron tomography', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Discrimination', 'Evaluation', 'Future', 'Gaussian model', 'Group Structure', 'Hour', 'Image', 'In Situ', 'Knowledge', 'Laplacian', 'Literature', 'Machine Learning', 'Macromolecular Complexes', 'Manuals', 'Methods', 'Mitochondria', 'Modeling', 'Molecular Conformation', 'Monitor', 'Neurophysiology - biologic function', 'Noise', 'Organelles', 'Performance', 'Process', 'Publishing', 'Reporting', 'Resolution', 'Series', 'Signal Transduction', 'Structure', 'System', 'Techniques', 'Testing', 'Time', 'Tomogram', 'Weight', 'Work', 'autoencoder', 'automated algorithm', 'base', 'deep learning', 'design', 'falls', 'feature detection', 'graphical user interface', 'improved', 'innovation', 'insight', 'machine learning algorithm', 'nano', 'nanometer resolution', 'novel', 'novel strategies', 'open source', 'particle', 'pi-Mesons', 'programs', 'reconstruction', 'success', 'user-friendly']",NIGMS,CARNEGIE-MELLON UNIVERSITY,R01,2020,342970,0.01739405958536012
"A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes PROJECT SUMMARY  There is a massive amount of clinical three-dimensional (3D) cardiac image data available today in numerous hospitals, but such data has been considerably underutilized in both clinical and engineering analyses of cardiac function. These 3D data offers unique and valuable information, allowing researchers to develop innovative, personalized approaches to treat diseases. Furthermore, using these 3D datasets as input to computational models can facilitate a population-based analysis that can be used to quantify uncertainty in treatment procedures, and can be utilized for virtual clinical trials for innovative device development. However, there are several critical technical bottlenecks preventing simulation-based clinical evaluation a reality: 1) difficulty in automatic 3D reconstruction of thin complex structures such as heart valve leaflets from clinical images, 2) computational models are constructed without mesh correspondence, which makes it challenging to run batch simulations and conduct large patient population data analyses due to inconsistencies in model setups, and 3) computing time is long, which inhibits prompt feedback for clinical use.  A potential paradigm-changing solution to the challenges is to incorporate machine learning algorithms to expedite the geometry reconstruction and computational analysis procedures. Therefore, the objective of this proposal is to develop a novel computing framework, using advanced tissue modeling and machine learning techniques, to automatically process pre-operative clinical image data and predict post-operative clinical outcomes. Transcatheter aortic valve replacement (TAVR) intervention will serve as a testbed for the modeling methods. In Aim 1, we will develop novel shape dictionary learning (SDL) based methods for automatic reconstruction of TAVR patient aortic valves. Through the modeling process, mesh correspondence will be established across the patient geometric models. The distribution and variation of TAVR patient geometries will be described by statistical shape models (SSMs). In Aim 2, population-based FE analysis of the TAVR procedure will be conducted on thousands of virtual patient models generated by the SSMs (Aim 1). A deep neural network (DNN) will be developed and trained to learn the relationship between the TAVR FE inputs and outputs. Successful completion of this study will result in a ML-FE surrogate for TAVR analysis, combining the automated TAVR patient geometry reconstruction algorithms and the trained DNN, to provide fast TAVR biomechanics analysis without extensive re-computing of the model. Furthermore, the algorithms developed in this study can be generalized for other applications and devices. PROJECT NARRATIVE Current clinical image modalities can be utilized to develop patient-specific computational models to pre-operatively plan transcatheter aortic valve replacement (TAVR) procedures. However, the computational modeling and simulation processes are time-consuming, which limits clinical translatability. Thus, the objective of this proposal is to develop algorithms using machine learning techniques to rapidly process and predict TAVR computational simulation outcomes directly from clinical image data.",A novel computing framework to automatically process cardiac valve image data and predict treatment outcomes,9973167,R01HL142036,"['3-Dimensional', 'Adverse event', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Biomechanics', 'Biomedical Computing', 'Clinical', 'Clinical Engineering', 'Complex', 'Computer Analysis', 'Computer Models', 'Computer Simulation', 'Consumption', 'Coronary Occlusions', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Device Designs', 'Device or Instrument Development', 'Devices', 'Dictionary', 'Disease', 'Elements', 'Evaluation', 'Extravasation', 'Feedback', 'Finite Element Analysis', 'Generations', 'Geometry', 'Goals', 'Guidelines', 'Heart Valves', 'Hospitals', 'Hour', 'Human', 'Image', 'Intervention', 'Laboratories', 'Language', 'Learning', 'Left ventricular structure', 'Machine Learning', 'Manuals', 'Methods', 'Mitral Valve', 'Modeling', 'Outcome', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Postoperative Period', 'Problem Sets', 'Procedures', 'Process', 'Property', 'Research Personnel', 'Response Elements', 'Running', 'Rupture', 'Sampling', 'Shapes', 'Statistical Data Interpretation', 'Stents', 'Structure', 'Techniques', 'Testing', 'Thinness', 'Time', 'Tissue Model', 'Training', 'Translations', 'Treatment outcome', 'Uncertainty', 'Variant', 'X-Ray Computed Tomography', 'algorithm training', 'aortic valve', 'aortic valve replacement', 'ascending aorta', 'base', 'calcification', 'clinical application', 'clinical imaging', 'clinical practice', 'clinically translatable', 'deep learning', 'deep neural network', 'heart function', 'heart imaging', 'imaging modality', 'improved', 'innovation', 'machine learning algorithm', 'models and simulation', 'novel', 'patient population', 'personalized approach', 'population based', 'prevent', 'reconstruction', 'research clinical testing', 'simulation', 'speech recognition', 'time resolved data', 'two-dimensional', 'virtual', 'virtual clinical trial']",NHLBI,GEORGIA INSTITUTE OF TECHNOLOGY,R01,2020,383601,-0.002069720488149189
"Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images ABSTRACT The goal of this R03 Small Grant Program for NIDDK is to provide additional funding for Dr. Kline to expand upon his work on his K award and apply his expertise to new image acquisitions and problems related to renal imaging. Dr. Kline’s work has piqued the interest of many internal and external investigators and has led to recent collaborations with Drs. Rule, Denic, and Kim. Together with Dr. Erickson, this new research team has prepared this R03 proposal which takes advantage of the unique expertise of each team member. The focus of this proposal is to bridge the gap between microscopic observations and those assessable non-invasively by radiological imaging. To do this, we have established a unique dataset of renal CT imaging data and corresponding biopsy measured nephron densities. We have also generated a large database of gold-standard segmentation data of kidneys, cortical regions, and medullary pyramids. Using this existing data, we propose to: (i) develop tools for segmentation of kidneys, segmentation of individual medullary pyramids, and imputing missing parts of the kidneys outside of the imaged field-of-view in the CT image, and (ii) to establish imaging biomarkers of early CKD, and correlate macroscopic imaging findings to underlying microscopic structure. This research will be facilitated by Mayo Clinic’s outstanding clinical and research environment dedicated to improving patient care, as well as the Aging Kidney Anatomy Study (PI: Rule), which led to the generation of this unique and well characterized dataset. Dr. Kline’s background in imaging technologies and image processing makes him particularly well suited to perform this research. In addition to the above aims, near the end of this research project Dr. Kline will submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of renal imaging biomarkers. Obtaining this R03 Award will greatly facilitate Dr. Kline’s transition into a prosperous independent researcher focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. Narrative Non-invasive methods for characterizing micro-structural changes of the kidney during aging as well as in health and disease are currently not possible. This research program proposes to use our existing database of renal imaging and renal biopsy data to bridge the gap between macroscopic radiological findings on computed tomography images to those assessable in microscopic images of renal biopsies. This program will develop new automated methods for performing measurements on the images, as well as use machine/deep learning methods to search for new imaging biomarkers that relate to nephron density and size, as well as establish their usefulness for early chronic kidney disease detection and transplant planning.",Artificial Intelligence-Based Approaches for Renal Structure Characterization in Computed Tomography Images,10040835,R03DK125632,"['Abdomen', 'Affect', 'Aging', 'Albuminuria', 'Anatomy', 'Area', 'Arteries', 'Artificial Intelligence', 'Autosomal Dominant Polycystic Kidney', 'Award', 'Biopsy', 'Chronic Kidney Failure', 'Clinic', 'Clinical Research', 'Collaborations', 'Communities', 'Computer Vision Systems', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrosis', 'Funding', 'Generations', 'Goals', 'Gold', 'Grant', 'Health', 'Hepatic Cyst', 'Hour', 'Hypertension', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'K-Series Research Career Programs', 'Kidney', 'Kidney Diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Methods', 'Microscopic', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrons', 'Organ', 'Outcome', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Polycystic Kidney Diseases', 'Radiologic Finding', 'Renal Blood Flow', 'Reproducibility', 'Research', 'Research Personnel', 'Research Project Grants', 'Research Proposals', 'Resources', 'Risk', 'Scanning', 'Semantics', 'Services', 'Stenosis', 'Structure', 'Surveys', 'Techniques', 'Technology', 'Time', 'Transplantation', 'Tubular formation', 'Visit', 'Work', 'X-Ray Computed Tomography', 'automated analysis', 'automated image analysis', 'automated segmentation', 'base', 'clinical decision-making', 'clinical practice', 'deep learning', 'density', 'early detection biomarkers', 'graft failure', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'interest', 'interstitial', 'kidney biopsy', 'learning strategy', 'living kidney donor', 'member', 'microscopic imaging', 'non-invasive imaging', 'novel', 'novel imaging technology', 'personalized decision', 'precision medicine', 'prognostic value', 'programs', 'radiological imaging', 'research clinical testing', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,R03,2020,113350,-0.010712818258274243
"Advancing algorithms for image-based profiling Project Summary    Most laboratories studying biological processes and human disease use microscopes to image samples.  Whether in small­ or large­scale microscopy experiments, biologists increasingly need software to identify and  measure cells and other biological entities in images, to improve speed, objectivity, and/or statistical power.   The principal investigator envisions bringing transformative image analysis and machine learning algorithms  and software to a wide swath of biomedical researchers. In a decade, researchers will tackle fundamentally  new problems with quantitative image analysis, using seamless imaging workflows that have dramatic new  capabilities going beyond the constraints of human vision.  To this end, the PI will collaborate with biologists on important quantitative imaging projects that also yield  major advancements to their open­source image analysis software, CellProfiler. This versatile, user­friendly  software is indispensable for biomedical research. Launched 125,000+ times/year worldwide, it is cited in  3,400+ papers from 1,000+ laboratories, impacting a huge variety of biomedical fields via assays from counting  cells to scoring complex phenotypes by machine learning. CellProfiler evolves in an intensely collaborative and  interdisciplinary research environment that has yielded dozens of discoveries and several potential drugs.  Still, many biologists are missing out on the quantitative bioimaging revolution due to lack of effective  algorithms and usable software for their needs. In addition to maintaining and supporting CellProfiler, the team  will implement biologist­requested features, algorithms, and interoperability to cope with the changing land­  scape of microscopy experiments. Challenges include increases in scale (sometimes millions of images), size  (20+ GB images), and dimensionality (time­lapse, three­dimensional, multi­spectral). Researchers also need to  accommodate a variety of modalities (super­resolution, single­molecule, and others) and integrate image  analysis into complex workflows with other software for microscope control, cloud computing, and data mining.   The PI will also pioneer novel algorithms and approaches changing the way images are used in biology,  including: (1) a fundamental redesign of the image processing workflow for biologists, leveraging revolutionary  advancements in deep learning, (2) image analysis for more physiologically relevant systems, such as model  organisms, human tissue samples, and patient­derived cultures, and (3) data visualization and interpretation  software for high­dimensional single­cell morphological profiling. In profiling, subtle patterns of morphological  changes in cells are detected to identify causes and treatments for various diseases. We will also (4) integrate  multiple profiling data types: morphology with gene expression, epigenetics, and proteomics. Ultimately, we  aim to make perturbations in cell morphology as computable as other large­scale functional genomics data.  Overall, the laboratory’s research will yield high­impact discoveries from microscopy images, and its  software will enable hundreds of other NIH­funded laboratories to do the same, across all biological disciplines.          Public Health Relevance/Narrative    Modern microscopy experiments are increasing in scale and scope; the research will result in pioneering  computational techniques and software that will change the way microscopy images are used in biology.  Biologists will use the resulting software to tackle fundamentally new problems using quantitative image  analysis, including detecting changes in the appearance of cells that are overlooked by human vision and  studying intact organisms and human tissue rather than isolated cells. The methods will be developed in the  context of dozens of projects addressing important fundamental biological questions and world health  problems, and the resulting new functionality will be added to the team’s popular, user­friendly, open­source  image analysis software, CellProfiler.          ",Advancing algorithms for image-based profiling,9952370,R35GM122547,"['3-Dimensional', 'Address', 'Algorithmic Software', 'Algorithms', 'Animal Model', 'Appearance', 'Biological', 'Biological Assay', 'Biological Process', 'Biology', 'Biomedical Research', 'Cell Count', 'Cells', 'Cellular Morphology', 'Cloud Computing', 'Complex', 'Computational Technique', 'Computer software', 'Data', 'Data Analyses', 'Dimensions', 'Discipline', 'Disease', 'Environment', 'Epigenetic Process', 'Funding', 'Gene Expression', 'Human', 'Image', 'Image Analysis', 'Interdisciplinary Study', 'Laboratories', 'Laboratory Research', 'Laboratory Study', 'Machine Learning', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Modality', 'Modernization', 'Morphology', 'Organism', 'Paper', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Principal Investigator', 'Proteomics', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Speed', 'System', 'Time', 'Tissue Sample', 'United States National Institutes of Health', 'Vision', 'World Health', 'base', 'bioimaging', 'data mining', 'data visualization', 'deep learning', 'experimental study', 'functional genomics', 'genomic data', 'high dimensionality', 'human disease', 'human tissue', 'image processing', 'improved', 'interoperability', 'machine learning algorithm', 'microscopic imaging', 'novel', 'open source', 'public health relevance', 'quantitative imaging', 'single molecule', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",R35,2020,695400,0.06437222279711453
"Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches Project Summary The form (or shape) and function relationship of anatomical structures is a central theme in biology where abnor- mal shape changes are closely tied to pathological functions. Morphometrics has been an indispensable quan- titative tool in medical and biological sciences to study anatomical forms for more than 100 years. Recently, the increased availability of high-resolution in-vivo images of anatomy has led to the development of a new generation of morphometric approaches, called statistical shape modeling (SSM), that take advantage of modern computa- tional techniques to model anatomical shapes and their variability within populations with unprecedented detail. SSM stands to revolutionize morphometric analysis, but its widespread adoption is hindered by a number of sig- niﬁcant challenges, including the complexity of the approaches and their increased computational requirements, relative to traditional morphometrics. Arguably, however, the most important roadblock to more widespread adop- tion is the lack of user-friendly and scalable software tools for a variety of anatomical surfaces that can be readily incorporated into biomedical research labs. The goal of this proposal is thus to address these challenges in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM), which automat- ically constructs optimal statistical landmark-based shape models of ensembles of anatomical shapes without relying on any speciﬁc surface parameterization. The proposed research will provide an automated, general- purpose, and scalable computational solution for constructing shape models of general anatomy. In Aim 1, we will build computational and machine learning algorithms to model anatomies with complex surface topologies (e.g., surface openings and shared boundaries) and highly variable anatomical populations. In Aim 2, we will introduce an end-to-end machine learning approach to extract statistical shape representation directly from im- ages, requiring no parameter tuning, image pre-processing, or user assistance. In Aim 3, we will provide intuitive graphical user interfaces and visualization tools to incorporate user-deﬁned modeling preferences and promote the visual interpretation of shape models. We will also make use of recent advances in cloud computing to enable researchers with limited computational resources and/or large cohorts to build and execute custom SSM work- ﬂows using remote scalable computational resources. Algorithmic developments will be thoroughly evaluated and validated using existing, fully funded, large-scale, and constantly growing databases of CT and MRI images lo- cated on-site. Furthermore, we will develop and disseminate standard workﬂows and domain-speciﬁc use cases for complex anatomies to promote reproducibility. Efforts to develop the proposed technology are aligned with the mission of the National Institute of General Medical Sciences (NIGMS), and its third strategic goal: to bridge biology and quantitative science for better global health through supporting the development of and access to computational research tools for biomedical research. Our long-term goal is to increase the clinical utility and widespread adoption of SSM, and the proposed research will establish the groundwork for achieving this goal. Project Narrative This project will develop general-purpose, scalable, and open-source statistical shape modeling (SSM) tools, which will present unique capabilities for automated anatomy modeling with less user input. The proposed tech- nology will introduce a number of signiﬁcant improvements to current SSM approaches and tools, including the support for challenging modeling problems, inferring shapes directly from images (and hence bypassing the seg- mentation step), parallel optimizations for speed, and new user interfaces that will be much easier and scalable than the current tools. The proposed technology will constitute an indispensable resource for the biomedical and clinical communities that will enable new avenues for biomedical research and clinical investigations, provide new ways to answer biologically related questions, allow new types of questions to be asked, and open the door for the integration of SSM with clinical care.","Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches",9969467,R01AR076120,"['Address', 'Adoption', 'Age', 'Algorithms', 'Anatomic Models', 'Anatomic Surface', 'Anatomy', 'Area', 'Biological', 'Biological Process', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Brain', 'Bypass', 'Cardiology', 'Cessation of life', 'Clinical', 'Clinical Data', 'Cloud Computing', 'Collection', 'Communities', 'Complex', 'Complex Analysis', 'Computational Technique', 'Computer Models', 'Computer software', 'Computers', 'Custom', 'Data', 'Databases', 'Development', 'Disease', 'Felis catus', 'Funding', 'Generations', 'Geometry', 'Goals', 'Human', 'Ice', 'Image', 'Imagery', 'Injury', 'Intuition', 'Laboratory Research', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematical Computing', 'Measures', 'Medical', 'Medicine', 'Mission', 'Modeling', 'Modernization', 'Modification', 'Morphogenesis', 'National Institute of General Medical Sciences', 'Occupations', 'Online Systems', 'Organism', 'Orthopedics', 'Pathologic', 'Population', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Science', 'Scientist', 'Shapes', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Speed', 'Statistical Data Interpretation', 'Structure', 'Supervision', 'Surface', 'Techniques', 'Technology', 'Time', 'Training', 'Variant', 'Visual', 'Visualization software', 'Work', 'algorithm development', 'base', 'biomedical resource', 'clinical care', 'clinical investigation', 'clinically relevant', 'cohort', 'computerized tools', 'computing resources', 'deep learning', 'experience', 'flexibility', 'global health', 'graphical user interface', 'image archival system', 'image processing', 'imaging Segmentation', 'in vivo imaging', 'innovation', 'large datasets', 'machine learning algorithm', 'model development', 'multidisciplinary', 'open source', 'particle', 'preference', 'software development', 'tool', 'usability', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2020,614363,0.0016624964909503917
"International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) 2020 Project summary  The Medical Image Computing and Computer Assisted Interventions (MICCAI) society is dedicated to the promotion, preservation and facilitation of research and education in the fields of medical image computing and computer assisted interventions, including biomedical imaging and robotics. This aim is achieved through the organization and operation of regular international conferences of the highest quality, and publications that promote and foster the exchange and dissemination of advanced knowledge, expertise and experience by leading institutions and outstanding scientists, physicians, and educators around the world. MICCAI Conferences have their origin in three separate but related conferences beginning in early 1990s--Visualization in Biomedical Computing, Computer Vision and Virtual Reality in Robotics and Medicine, and Medical Robotics and Computer Assisted Surgery--, which merged into a single annual conference in 1998. MICCAI Conferences have defined new scientific disciplines over the years and have become the premier meeting in the field. The conference proceedings have an impact factor comparable to high-impact computational journals. Conference topics include, computer vision & medical image processing, computer-aided diagnosis, interventions & surgery, machine learning in medical imaging, guidance systems & robotics, visualization and virtual reality, bioscience and biology applications, imaging systems and new biomedical imaging applications, spanning disciplines such as radiology, pathology, surgery, oncology, cardiology, physiology, and psychiatry.  The MICCAI conference includes three days of oral presentations and poster sessions. The quality and importance of poster presentations are considered to be on a par with those of oral presentations, with both undergoing a rigorous double-blinded peer-review (~30% acceptance). Selected presented papers became landmark publications over the years with up to 2,000 citations. The conference series includes satellite events like community-driven software challenges, workshops and tutorials just before and/or after the main conference. These events focus on the current status and advances in topics relevant to MICCAI and are very well attended. The MICCAI Conferences span the entire globe and are usually rotated among the American, European, and Asian continents. Attendees are typically from over 45 countries, with strong student representation (>40%). The MICCAI 2020 Conference will be held in Lima, Peru in October 4th-8th, 2020. Since 2018, a Mentorship Program to connect students and young investigators with established mentors from academia and industry is also part of the conference. Along with the Mentorship Program and mission of the “Women in MICCAI” Committee, this proposal requests funds to support student and early investigator travel awards to enhance diversity in conference attendance (including women, underrepresented minorities, students with disabilities, and people from disadvantaged backgrounds) and provide minority groups with a unique opportunity to reach an international audience for career development and collaborations. Project narrative The Medical Image Computing and Computer Assisted Intervention (MICCAI) 2020 Conference will be held in Lima, Peru, October 4th-8th, 2020. MICCAI is the premier meeting in the medical image computing and computer assisted intervention communities, having introduced landmark papers and providing a springboard for young scientists to establish themselves in the field. This proposal requests funds to provide travel awards for students and early investigators to present their work at MICCAI 2020--with focus on minority groups and underrepresented populations--providing them with an opportunity to attend the meeting, foster professional development and identify collaborations in an established international community.",International Conference on Medical Image Computing and Computer Assisted Interventions (MICCAI) 2020,10070479,R13EB030422,"['Academia', 'Academy', 'American', 'Asians', 'Award', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Cardiology', 'Collaborations', 'Communities', 'Computer Assisted', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Computer-Assisted Surgery', 'Costs and Benefits', 'Country', 'Development', 'Disabled Persons', 'Disadvantaged', 'Discipline', 'Double-Blind Method', 'Education', 'Educational workshop', 'Ensure', 'European', 'Event', 'Female', 'Fostering', 'Funding', 'Goals', 'Grant', 'Growth', 'Healthcare', 'Industrialization', 'Industry', 'Institution', 'International', 'Intervention', 'Journals', 'Knowledge', 'Machine Learning', 'Medical', 'Medical Imaging', 'Medicine', 'Mentors', 'Mentorship', 'Minority Groups', 'Mission', 'Oncology', 'Operative Surgical Procedures', 'Oral', 'Paper', 'Pathology', 'Peer Review', 'Peru', 'Physicians', 'Physiology', 'Policies', 'Postdoctoral Fellow', 'Psychiatry', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Request for Proposals', 'Research', 'Research Personnel', 'Robotics', 'Role', 'Scientist', 'Series', 'Societies', 'Students', 'Training', 'Translating', 'Travel', 'Underrepresented Groups', 'Underrepresented Populations', 'United States National Institutes of Health', 'Visualization', 'Woman', 'Women&apos', 's Group', 'Work', 'base', 'bioimaging', 'career', 'career development', 'community intervention', 'community organizations', 'cost', 'disabled students', 'early-career faculty', 'experience', 'graduate student', 'image guided', 'image processing', 'imaging system', 'innovation', 'interest', 'meetings', 'operation', 'posters', 'preservation', 'programs', 'racial and ethnic', 'robotic system', 'social', 'student participation', 'success', 'supportive environment', 'symposium', 'underrepresented minority student', 'virtual reality', 'women faculty']",NIBIB,CHILDREN'S RESEARCH INSTITUTE,R13,2020,9850,0.033713063189086706
"Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease Project Summary/Abstract New treatments have been revolutionary in improving outcomes over the last 30 years, yet cardiovascular disease still exerts a $320B annual burden on the US economy. Increasing evidence is showing that Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides. Currently available solutions do not overcome the barriers – a new approach is needed. Elucid Bioimaging has developed an image analysis software product vascuCAP (CAP stands for Computer Aided Phenotyping) to accurately quantify structural and morphological characteristics of plaque tissues linked to plaque rupture vulnerability. Fundamental to our approach is validated, objective quantitative accuracy; vascuCAP enjoys the most robust and well documented analytic validation of any plaque morphology software available. vascuCAP is the only system to mitigate specific issues in CT reconstruction known to effect accurate measurement of atherosclerotic plaque composition in routinely acquired CTA; it is the only system to effectively leverage objective tissue characterization validated by histology across multiple arterial beds; it achieves an effective resolution with routinely acquired CTA in the same ballpark as IVUS VH, based on solid mathematics principles that respect the Nyquist-Shannon sampling theorem; and it innovates by novel reporting that expresses the findings in a manner that fits efficiently into existing clinical workflows. vascuCAP has been implemented in a client-server model supporting SaaS. Working from our strong current device clearances, this research strategy is developed based on approved meeting notes from the FDA pre-submission process Phenotype classification claims to be cleared through direct De Novo pathway on the basis of accurately determining the class from in vivo CTA data relative to pathologist annotation on ex vivo specimen data. Risk prediction claims: validate ability to predict adverse events at one year, adding the IFU according to the direct De Novo pathway, One does not strictly depend on the other.This proposal is innovative in dealing with two fundamental limitations of the application of artificial intelligence and deep learning to the analysis of atherosclerosis imaging data. This proposal maximizes use of available retrospective data while putting in place the necessary structure for prospective validation and scale up. This proposal further develops vascuCAP as a tool that may reduce cost and length of clinical trials. While out of scope for this grant, it is important to also note that vascuCAP is innovative in its ability to support multi-scale modeling across cellular/molecular-level analyses and macroscopic manifestation. Also, vascuCAP’s quantitative ability makes it ideal for analysis of more advanced CT imaging protocols. These attributes complement and support the proposed objectives. Project Narrative Coronary CT Angiography (CCTA) may be an ideal modality to fill gaps in understanding the extent and rate of progression coronary artery disease. But despite the apparent promise of CCTA, there are barriers that prevent realizing the improvement that it theoretically provides which currently available solutions do not overcome. Elucid Bioimaging has developed an image analysis software product vascuCAP that overcomes these barriers to provide truly effective non-invasive diagnostic power to fill gaps in treating at-risk patients.",Plaque Risk Stratification Using Routinely Available CCTA to Optimize Therapeutic Decision-making in Patients with Known or Suspected Coronary Artery Disease,9929633,R44HL126224,"['Adverse event', 'Angiography', 'Applications Grants', 'Arterial Fatty Streak', 'Artificial Intelligence', 'Atherosclerosis', 'Beds', 'Biological', 'Caliber', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Categories', 'Characteristics', 'Classification', 'Client', 'Clinical', 'Clinical Trials', 'Collection', 'Complement', 'Computer Assisted', 'Computer software', 'Consensus', 'Consumption', 'Coronary', 'Coronary Arteriosclerosis', 'Data', 'Data Set', 'Decision Making', 'Detection', 'Devices', 'Diagnosis', 'Digital Imaging and Communications in Medicine', 'Electronic Health Record', 'Event', 'Goals', 'Grant', 'Histologic', 'Histology', 'Image', 'Image Analysis', 'Individual', 'Industry', 'Label', 'Length', 'Lesion', 'Link', 'Lipids', 'Manuals', 'Mathematics', 'Measurement', 'Methods', 'Modality', 'Modeling', 'Molecular', 'Morphology', 'Nature', 'Necrosis', 'Pathologist', 'Pathway interactions', 'Patients', 'Performance', 'Phenotype', 'Procedures', 'Process', 'Protocols documentation', 'Reader', 'Reporting', 'Research', 'Resolution', 'Retrospective cohort', 'Risk', 'Risk stratification', 'Rupture', 'Sampling', 'Secondary to', 'Severities', 'Solid', 'Specimen', 'Speed', 'Stenosis', 'Structure', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Translating', 'Validation', 'X-Ray Computed Tomography', 'base', 'bioimaging', 'biomarker panel', 'cohort', 'convolutional neural network', 'cost', 'deep learning', 'improved', 'improved outcome', 'in vivo', 'innovation', 'meetings', 'multi-scale modeling', 'noninvasive diagnosis', 'novel', 'novel strategies', 'novel therapeutics', 'prevent', 'prospective', 'quantitative imaging', 'reconstruction', 'research clinical testing', 'risk prediction model', 'scale up', 'software as a service', 'standard of care', 'success', 'tool']",NHLBI,ELUCID,R44,2020,1011405,0.0011828964357037536
"AI platform for microscopy image restoration and virtual staining AI Platform for Microscopy Image Restoration and Virtual Staining Project Summary:  Fluorescence microscopy has enabled many major discoveries in biomedical sciences. Despite the rapid advancements in optics, lasers, probes, cameras and novel techniques, major factors such as spatial and temporal resolution, light exposure, signal-to-noise, depth of penetration and probe spectra continue to limit the types of experiments that are possible. Deep learning (DL) algorithms are well suited for image-based problems like SNR/super-resolution restoration and virtual staining, which have great enabling potentials for microscopy experiments. Previously impossible experiments could be realized such as achieving high signal-to-noise and/or spatial-temporal resolution without photobleaching/phototoxicity; simultaneously observing many image channels without interfering with native processes, etc. This could pave the way for a quantum leap forward in microscopy-based discoveries that elucidate biological functions and the mechanisms of disorders, and enable new diagnostics and therapies for human diseases.  However, these new methods have not been widely translated to new microscopy experiments. The delay is due to several practical hurdles and challenges such as required expertise, computing and trust. In order to accelerate the adoption of DL in microscopy, novel AI platform tailored for biologists are needed for training, applying and validating DL models and outputs.  The present project aims to develop an AI platform for microscopy image restoration and virtual staining called AI for Restoring and Staining (AIRS) platform. With our collaborator, Dr. Hari Shroff (National Institute of Biomedical Imaging and Bioengineering) we have successfully created DL models for SNR restoration, super-resolution restoration and virtual staining for a variety of imaging conditions and organelles in our preliminary studies. The AIRS platform intends to (1)provide a comprehensive suite of validated DL models for microscopy restoration and virtual staining applications including SNR restoration, super-resolution restoration, spatial deconvolution, spectral unmixing, prediction of 3d from 2d images, organelle virtual staining and analysis; (2)provide plug and play for common microscopy experiments; (3)provide semi-automatic update training to tailor DL models to match advanced microscopy experiments; (4)provide user friendly support for new DL model training for pioneering microscopy experiments; (5)provide confidence scores to assess the output results by a DL model, (6) provide DL models that avoid image artifact (hallucination) and allow continuous learning and evolution; (7) and be able to access the required computing infrastructure and database connection. Project Narrative Deep learning (DL) algorithms have great enabling potentials for microscopy experiments. Previously impossible experiments could now be realized. This could pave the way for a quantum leap forward in microscopy-based discoveries.  Powered by deep learning and DRVision innovations and collaborating with Dr. Hari Shroff and 7 additional labs, this project aims to create an AI platform for microscopy image restorations and virtual staining called AI for restoring and staining (AIRS). The tool will be integrated with DRVision’s flagship product Aivia for commercialization to accelerate the adoption of DL in microscopy.",AI platform for microscopy image restoration and virtual staining,9909318,U44GM136091,"['3-Dimensional', 'Active Learning', 'Adoption', 'Artificial Intelligence', 'Biological Process', 'Data', 'Databases', 'Disease', 'Evaluation', 'Evolution', 'Feedback', 'Fluorescence Microscopy', 'Government', 'Hallucinations', 'Image', 'Infrastructure', 'Lasers', 'Libraries', 'Light', 'Manuals', 'Methods', 'Microscopy', 'Modeling', 'Morphologic artifacts', 'National Institute of Biomedical Imaging and Bioengineering', 'Noise', 'Optics', 'Organelles', 'Output', 'Penetration', 'Performance', 'Persons', 'Phase', 'Photobleaching', 'Phototoxicity', 'Play', 'Process', 'Resolution', 'Science', 'Signal Transduction', 'Stains', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Training', 'Translating', 'Trust', 'Update', 'Validation', 'base', 'commercialization', 'deep learning', 'deep learning algorithm', 'experience', 'experimental study', 'human disease', 'improved', 'innovation', 'learning progression', 'microscopic imaging', 'novel', 'novel diagnostics', 'novel therapeutics', 'prototype', 'quantum', 'restoration', 'temporal measurement', 'tool', 'usability', 'user-friendly', 'virtual']",NIGMS,"DRVISION TECHNOLOGIES, LLC",U44,2020,172359,-0.009254326545417805
"Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry PROJECT SUMMARY  Cellular interactions with the environment form the basis of health and disease for all organisms. Exposure to nutrients, toxins, and neighboring cells trigger coordinated molecular responses that impact cell function and metabolism in a beneficial, adaptive, or detrimental manner. Although the benefits of multicellularity for the formation of complex tissue structures or the function of entire organ systems has been long appreciated, it has only recently been understood that microbial inhabitants of vertebrates also have a tremendous impact on host cell function and dysfunction. Despite this, an understanding of these interactions has not moved beyond simple associations, and there are virtually no molecular technologies available that adequately define how a complex microbial ecosystem impacts host cell function, or how the host response to microbial colonization affects the bacterial community. This gap in knowledge is striking when one considers the broad and significant impact that microbes have on human health. In this application, we propose to expressly fill this knowledge gap through development of a novel multimodal imaging pipeline that will provide 3-dimensional information on the molecular heterogeneity of microbial communities and the immune response at the host-pathogen interface.  This proposal combines our expertise in immunology, infection biology, mass spectrometry, small animal imaging, machine learning, and computer vision to develop an integrated multimodal visualization method for studying infectious disease. Our unique approach will computationally combine ultra-high speed (~50px/s) MALDI-TOF images, ultra-high mass resolution (>200,000 resolving power) MALDI FTICR IMS, metal imaging by LA-ICP-IMS, high-spatial resolution optical microscopy, and MR imaging using data-driven image fusion. This strategy will enable 3-D molecular images to be generated for thousands of elements, metabolites, lipids, and proteins with an unprecedented combination of chemical specificity and spatial fidelity more than 50x faster than is currently possible. We will use this next-generation imaging capability to (i) define the heterogeneous microbial subpopulations throughout the 3-D volume of a S. aureus community, (ii) uncover the host molecules that form the abscess and accumulate to restrict microbial growth in murine models, and (iii) elucidate molecular markers that differentiate in vivo biofilms at the host-pathogen interface, between abscesses at various stages of progression, and under distinct degrees of nutrient stress. These studies will uncover new targets for therapeutic intervention and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research. PROJECT NARRATIVE This proposal will enable detailed views of the molecular components of infectious disease with unprecedented resolution through the development of a multimodal, 3-dimensional imaging platform. The proposed technologies will improve throughput and molecular specificity, enable automated high-precision and high-accuracy image alignment, and allow for descriptions of molecular signals in 3-D through the fusion of multi-modal imaging data. These studies will uncover targets for therapeutic intervention and antibiotic development and the techniques developed as a result of this proposal will be broadly applicable to all physiologically relevant processes, profoundly impacting biomedical research.",Molecular mapping of microbial communities at the host-pathogen interface by multi-modal 3-dimensional imaging mass spectrometry,9989025,R01AI138581,"['3-Dimensional', 'Abscess', 'Affect', 'Animal Model', 'Animals', 'Anterior nares', 'Antibiotics', 'Antibodies', 'Architecture', 'Awareness', 'Bacteria', 'Bacterial Infections', 'Bacterial Proteins', 'Behavior', 'Biology', 'Biomedical Research', 'Cell Differentiation process', 'Cell physiology', 'Cells', 'Cellular Metabolic Process', 'Chemicals', 'Communicable Diseases', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Computer Vision Systems', 'Custom', 'Data', 'Development', 'Diagnosis', 'Differentiation Antigens', 'Dimensions', 'Disease', 'Ecosystem', 'Elements', 'Environment', 'Exposure to', 'Fourier transform ion cyclotron resonance', 'Functional disorder', 'Genus staphylococcus', 'Glean', 'Growth', 'Health', 'Health Promotion', 'Heterogeneity', 'Histology', 'Human', 'Image', 'Imaging technology', 'Immune', 'Immune response', 'Immunology', 'Imprisonment', 'Individual', 'Infection', 'Infectious Diseases Research', 'Integration Host Factors', 'Knowledge', 'Label', 'Lesion', 'Lipids', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Mass Spectrum Analysis', 'Metals', 'Methodology', 'Methods', 'Microbe', 'Microbial Biofilms', 'Modality', 'Modeling', 'Molecular', 'Multimodal Imaging', 'Nutrient', 'Optics', 'Organism', 'Pathogenesis', 'Physiological', 'Population', 'Process', 'Proteins', 'Reagent', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Spatial Distribution', 'Specificity', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Speed', 'Staphylococcus aureus', 'Stress', 'Structure', 'Techniques', 'Technology', 'Therapeutic Intervention', 'Three-Dimensional Imaging', 'Three-dimensional analysis', 'Tissues', 'Toxin', 'Vertebrates', 'Visualization', 'Work', 'animal imaging', 'bacterial community', 'base', 'body system', 'commensal bacteria', 'experimental study', 'host colonization', 'imaging capabilities', 'imaging detection', 'imaging modality', 'imaging platform', 'improved', 'in vivo', 'innovation', 'interest', 'microbial', 'microbial colonization', 'microbial community', 'microscopic imaging', 'molecular imaging', 'molecular marker', 'mouse model', 'multimodality', 'neutrophil', 'new therapeutic target', 'next generation', 'novel', 'pathogen', 'protein expression', 'response', 'supervised learning', 'targeted treatment', 'virtual']",NIAID,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2020,612684,0.0038379778672275916
"2021 International Workshop on Pulmonary Imaging SUMMARY This application requests funding to support the 2021 International Workshop on Pulmonary Imaging, a three- day meeting to be held from February 25-27, 2021, which will be the seventh of its kind hosted by the University of Pennsylvania. The requested funds will primarily be used to cover travel and lodging for junior researchers who will be presenting at the workshop: undergraduate, graduate and junior faculty. Some funds may also be allocated to help pay for live webcasting and publication costs related to workshop materials. As with previous meetings, we intend to stream each session of the meeting in real-time, allowing those who are interested in the proceedings but unable to attend in person to access them online for free. As mortalities associated with pulmonary disease continue to rise worldwide, innovative imaging techniques capable of both diagnosing and helping to treat these pathologies are becoming an increasingly important. As a field, pulmonary imaging currently encompasses a wider range of techniques for the structural, functional and molecular assessment of lung disorders than at any time in its history. What is more, these techniques are being developed and optimized by researchers across an increasingly diverse set of fields such as biology, chemistry, physics, engineering, computer science and medicine. Given the field's rapidly-evolving nature, the existence of a regular forum in which scientists and clinicians can communicate their ideas with each other is of the utmost importance. Given the absence of other scientific meetings with a similarly focused agenda, our previous workshops have succeeded in providing just such a forum—allowing a diverse group of pulmonary imaging researchers to come together for the kind of rigorous, collaborative exchange that can continue to advance the field. The specific aims of the proposed workshop are as follows: (1) host a one-day workshop on pulmonary inflammation; (2) inform the pulmonary imaging community of the latest advances in structural, functional and molecular lung imaging; (3) explore the use of pulmonary imaging to evaluate therapeutic response, the inherent obstacles to doing so, and strategies to overcome them; (4) investigate new approaches for integrating deep learning and pulmonary imaging techniques to more accurately diagnose and phenotype disease and predict injury progression; (5) broadcast the entire workshop live online, thereby enabling interested parties not in attendance to access the proceedings in real-time, free of charge. Based on the uniformly positive feedback in response to our one-day boot camp on pulmonary physiology prior to the 2019 workshop, we intend to hold another boot camp before the 2021 meeting, this time focused on pulmonary inflammation. This boot camp will consist of ~5 longer presentations (approximately 1 hour each) on topics related to this central theme, with significant time devoted to question and answer after each, and a final discussion panel aimed at synthesizing the most important issues covered over the course of the day. In addition to this exciting addition to the format, the 2021 workshop will again seek a more equitable balance between functional, structural and molecular imaging approaches to pulmonary disease across the invited talks, while also continuing to expand our recent focus on the topics of imaging assessments of treatment response and the integration of imaging techniques with machine learning. Finally, the 2021 workshop add a session on bridging the gap between current clinical practice and innovative imaging technologies. NARRATIVE This application requests funding to support the 2021 International Workshop on Pulmonary Imaging at the University of Pennsylvania. This recurring workshop provides a necessary and valuable opportunity for researchers working in the fields of functional, structural, and molecular imaging technique development for assessing lung diseases such as lung cancer, COPD, IPF and ARDS to come together in order to discuss and share their work. The full workshop proceedings will be streamed live online, allowing those unable to attend in person the opportunity to both watch and participate in the meeting.",2021 International Workshop on Pulmonary Imaging,10070932,R13HL154586,"['Address', 'Adult Respiratory Distress Syndrome', 'Anatomy', 'Biology', 'Characteristics', 'Charge', 'Chemistry', 'Chronic Obstructive Airway Disease', 'Classification Scheme', 'Clinical', 'Collaborations', 'Communication', 'Communities', 'Development', 'Diagnosis', 'Disease', 'Disease Progression', 'Educational workshop', 'Engineering', 'Equilibrium', 'Faculty', 'Feedback', 'Functional Imaging', 'Funding', 'Future', 'Gases', 'Heart', 'Hour', 'Image', 'Imaging Techniques', 'Imaging technology', 'Injury', 'International', 'Learning', 'Location', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant neoplasm of lung', 'Medicine', 'Molecular', 'Movement', 'Nature', 'Pathology', 'Pennsylvania', 'Persons', 'Phenotype', 'Physics', 'Physiology', 'Positron-Emission Tomography', 'Process', 'Protons', 'Public Health', 'Publications', 'Pulmonary Inflammation', 'Pulmonology', 'Radiology Specialty', 'Recording of previous events', 'Request for Applications', 'Research', 'Research Personnel', 'Scientist', 'Stream', 'Structure', 'Techniques', 'Time', 'Travel', 'Treatment Efficacy', 'Universities', 'Update', 'Work', 'accurate diagnosis', 'base', 'clinical practice', 'computer science', 'cost', 'deep learning', 'density', 'disease phenotype', 'graduate student', 'imaging approach', 'imaging biomarker', 'imaging modality', 'improved', 'innovation', 'interest', 'lung imaging', 'meetings', 'molecular imaging', 'mortality', 'non-invasive imaging', 'novel', 'novel strategies', 'programs', 'response', 'single photon emission computed tomography', 'technique development', 'treatment response', 'undergraduate student']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R13,2020,29805,-0.03431633271293877
"An Integrated Software Platform for Accelerating Image-Driven Ophthalmic Research and Driving New Insights and Endpoints to the Clinic ABSTRACT More than 20 million patients suffer from age-related macular degeneration, diabetic retinopathy, or glaucoma. These degenerative eye diseases develop over decades, and their prevalence is increasing. Retinal imaging technologies such as optical coherence tomography and adaptive optics ophthalmoscopy are essential tools in the investigation and management of eye disease. New quantitative biomarkers derived from these and other imaging modalities are critical to the clinical translation of emerging ophthalmic innovations. However, biomarker development in the era of artificial intelligence requires large volumes of annotated images and transparent, reproducible processes, which places new demands on the management of living subjects research, data sharing, and algorithm development. Unfortunately, current software platforms are not effective in integrating these data in a manner that meets specific requirements in ophthalmology, Our goal in this Direct-to-Phase II SBIR, consistent with objectives of the NIH Strategic Plan for Data Science, is to create an integrated platform (PaaS) for the collection, curation, analysis, and sharing of ocular images and data. We will extend the capabilities of systems developed by the Advanced Ocular Imaging Program (AOIP), Medical College of Wisconsin (MCW), which include: (a) LATTICE - a software solution that reduces costs, reduces errors, and improves communications in the management of living-subjects research; (b) MOSAIC - an image processing platform and algorithm library with traditional and AI-trained algorithms; and (c) The AOIP Image Bank - a Repository that houses images and data on 1578 fully-consent human research subjects. To create the integrative platform, we will address four aims: (a) Extend LATTICE to meet the workflow requirements of academic and sponsored research in local and multisite environments, including the extensible direct integration of data relevant to ocular studies; (b) Design and implement a hybrid (local + cloud) REPOSITORY architecture, data schema, knowledge ontology, and query architecture for Owners and Readers of data.; (c) Integrate and demonstrate LATTICE, REPOSITORY and MOSAIC into a continuous ocular science workflow and (d) integrate and demonstrate Lattice, Repository and Mosaic into a continuous ocular science workflow. Our Integrated Translational Imaging platform will enable ophthalmic innovators to translate sight-saving insights and interventions to the clinic faster, with less frustration, and greater confidence. Our proposal fills an important technology gap in the field of ophthalmic data science and biomarker development. While the number and type of imaging devices continues to grow, the tools to develop and deploy new biomarkers and clinical endpoints using these exquisite imaging devices has not kept pace. With this program we will enable a new generation of image-driven innovation to find its way to the clinic. Project Narrative With more than 20 million patients suffering from age-related macular degeneration, diabetic retinopathy, or glaucoma, it is crucial to develop non-invasive biomarkers as early predictors of eye disease and reliable tests of the safety and efficacy of new preventative and restorative therapies. To meet the unmet need for rapid access and analysis of ophthalmic research data for the discovery of these biomarkers, we will create an integrated platform (PaaS) for the collection, curation, sharing, and analysis of ocular images and data. If we meet our objectives, our platform will reduce the cost of clinical research and increase the speed of translating critical research insights to saving the sight of millions of patients.",An Integrated Software Platform for Accelerating Image-Driven Ophthalmic Research and Driving New Insights and Endpoints to the Clinic,9908389,R44EY031198,"['Address', 'Age related macular degeneration', 'Algorithms', 'Architecture', 'Artificial Intelligence', 'Automobile Driving', 'Biological Markers', 'Blindness', 'Clinic', 'Clinical', 'Clinical Research', 'Collection', 'Communication', 'Computer software', 'Consent', 'Data', 'Data Discovery', 'Data Science', 'Diabetic Retinopathy', 'Docking', 'Economics', 'Environment', 'Eye diseases', 'Foundations', 'Frustration', 'Funding', 'Glaucoma', 'Goals', 'Housing', 'Human Subject Research', 'Hybrids', 'Image', 'Imaging Device', 'Imaging technology', 'Influentials', 'Intervention', 'Investigation', 'Knowledge', 'Libraries', 'Mosaicism', 'Ontology', 'Ophthalmology', 'Ophthalmoscopy', 'Optical Coherence Tomography', 'Patients', 'Phase', 'Policies', 'Prevalence', 'Process', 'Reader', 'Research', 'Research Subjects', 'Savings', 'Science', 'Site', 'Small Business Innovation Research Grant', 'Speed', 'Strategic Planning', 'Structure', 'System', 'Technology', 'Translating', 'Translations', 'United States National Institutes of Health', 'Validation', 'Vision', 'Wisconsin', 'adaptive optics', 'algorithm development', 'algorithm training', 'application programming interface', 'biomarker development', 'biomarker discovery', 'clinical translation', 'cost', 'data access', 'data exchange', 'data integration', 'data sharing', 'data warehouse', 'deep learning', 'design', 'efficacy testing', 'experience', 'fighting', 'image processing', 'image reconstruction', 'imaging modality', 'imaging platform', 'imaging program', 'improved', 'innovation', 'insight', 'medical schools', 'microsystems', 'ocular imaging', 'process repeatability', 'programs', 'repository', 'retinal imaging', 'safety testing', 'software systems', 'structured data', 'tool', 'verification and validation', 'vision science']",NEI,"TRANSLATIONAL IMAGING INNOVATIONS, INC.",R44,2020,743347,0.03033600415978901
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9989196,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'automated algorithm', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2020,222618,0.014609831988362904
"Neuroimaging Analysis Center (NAC) Project Summary/Abstract The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the pos- sibility for a new era in neuroimaging, disease understanding, and patient treatment. To unlock the full medical potential made possible by these new technologies, new algorithms and clinically-relevant techniques must be developed by close collaboration between computer scientists, physicians, and medical researchers. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and exten- sive collaboration. The overarching theme for this P41 renewal is the discovery and analysis of novel imaging phenotypes to characterize disease. We use the term imaging phenotypes to describe patterns or features of disease that can be detected through imaging (predominantly MRI) followed by machine learning, statistical analysis, feature detection, and correlation with other indicators of disease such as structured patient infor- mation. The three proposed Technology Research & Development (TR&D) projects address this common question us- ing a variety of complementary approaches and clinical testbeds. TR&D 1 addresses microstructure of tissue, including novel imaging methods to detect tumor microstructure. TR&D 2 investigates rich spatial patterns of disease extracted from clinical imaging with a focus on cerebrovascular and neurodegenerative conditions such as stroke. Finally, TR&D 3 proposes novel image and connectivity-based features that can be correlated with a variety of diseases, with a clinical emphasis on pediatric brain development. Technical innovation will be driven by intense collaboration between the TR&Ds and key collaborators in neurosurgery, neurology, and pe- diatrics. The TR&Ds will leverage recent important developments in the fields of image acquisition, machine learning, and data science to identify and exploit novel imaging phenotypes of disease. Building on our long history of developing clinically-relevant methods, each TR&D includes a translational and clinical validation aim to ensure our work is clinically relevant and effective at meeting the driving clinical goals. NAC's proven software engi- neering, translation, and dissemination infrastructure, along with its established network of academic, medical, and industrial partners, enhance the center's value as a national resource. Project Narrative The Neuroimaging Analysis Center is a research and technology center with the mission of advancing the role of neuroimaging in health care. The ability to access huge cohorts of patient medical records and radiology data, the emergence of ever-more detailed imaging modalities, and the availability of unprecedented computer processing power marks the possibility for a new era in neuroimaging, disease understanding, and patient treatment. We are excited to propose a national resource center with the goal of finding new ways of extracting disease characteristics from advanced imaging and computation, and to make these methods available to the larger medical community through a proven methodology of world-class research, open-source software, and extensive collaboration.",Neuroimaging Analysis Center (NAC),9997917,P41EB015902,"['Address', 'Algorithmic Analysis', 'Algorithms', 'Automobile Driving', 'Biomedical Technology', 'Biotechnology', 'Brain', 'Characteristics', 'Childhood', 'Clinical', 'Collaborations', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Science', 'Development', 'Disease', 'Educational process of instructing', 'Ensure', 'Goals', 'Healthcare', 'Image', 'Industrialization', 'Infrastructure', 'Machine Learning', 'Magnetic Resonance Imaging', 'Medical', 'Methodology', 'Methods', 'Mission', 'National Institute of Biomedical Imaging and Bioengineering', 'Nerve Degeneration', 'Neurobiology', 'Neurology', 'Patients', 'Pattern', 'Pediatrics', 'Phenotype', 'Physicians', 'Radiology Specialty', 'Recording of previous events', 'Research', 'Research Personnel', 'Resources', 'Role', 'Scientist', 'Software Engineering', 'Software Framework', 'Statistical Data Interpretation', 'Stroke', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Training', 'Translations', 'Validation', 'Work', 'algorithmic methodologies', 'base', 'cerebrovascular', 'clinical application', 'clinical imaging', 'clinically relevant', 'cohort', 'disease phenotype', 'feature detection', 'imaging modality', 'innovation', 'meetings', 'neuroimaging', 'neurosurgery', 'new technology', 'novel', 'novel imaging technique', 'open source', 'patient health information', 'response', 'technology research and development', 'tumor']",NIBIB,BRIGHAM AND WOMEN'S HOSPITAL,P41,2020,1339073,0.030470984244431152
"IEEE Medical Imaging Conference Abstract  The IEEE Medical Imaging Conference (MIC) is the leading international scientific meeting bringing together a broad community interested in the physics, engineering and mathematical aspects of medical imaging, with special emphasis on nuclear medicine and multi-modal systems. The MIC runs in conjunction with the IEEE Nuclear Science Symposium (NSS) and the Workshop on Room Temperature Semiconductor X-ray and Gamma-ray Detectors (RTSD).  The purpose of the MIC is to disseminate and foster new research in physics and bio-engineering methods in medical imaging. While the traditional topics of primary interest are related to nuclear medicine techniques such as positron emission tomography (PET) and single photon emission computerized tomography (SPECT), increasing space will be also given to recently evolving imaging modalities such as X-ray, CT, optical, MR, with special emphasis on their multi-modal combination with nuclear medical imaging. Recently there has also been additional interest in employing deep learning and AI to enhance the field medical imaging. The conference provides a well-established forum of scientific exchange and dialogue between researchers in academia, industry, and government as well as education of the public, with special emphasis on young generations. This is reflected by the large spectrum of educational refresher sessions and short courses. One of the major objectives of the conference is the education of young investigators, and therefore this NIH R13 proposal seeks $10,000 in funding for each of the next three years to provide 20 trainee grants of $500 each to partially cover costs of MIC conference registration, housing and/or short course fees for graduate students and postdoctoral fellows based at US institutions.  We anticipate that the main impact of this grant program will be to increase attendance of students and postdocs at the 2020 meeting, especially those typically underrepresented, as well as to support their participation in educational activities. It is important to bring young generations, especially women, minorities, and those with disabilities, into the medical imaging field, where they could become main actors in the coming years. They will attend plenary and oral presentations given by many of the world leaders in the nuclear medical imaging instrumentation, image processing, and quantitative analysis fields. Moreover, they will be given the unique opportunity of direct personal interaction through the short courses and dedicated poster presentations. In turn their work will be exposed to the other participants for critical evaluation, constructive suggestions and dissemination. Furthermore, many of these trainees will likely continue in this field, thereby contributing to advancing technology with high societal relevance as being increasingly used in the clinical management of disease and therapeutic interventions. Narrative  The IEEE Medical Imaging Conference (MIC) has the purpose to disseminate and foster new research in physics and bio-engineering methods in medical imaging. The conference covers a variety of medical imaging topics including quantitative imaging, PET/SPECT techniques, image reconstruction, imaging in radiation therapy, portable imaging, multi-modality systems, new medical imaging technologies, CT/MR/optical/ultrasound, parametric/kinetic image modeling, and signal/image processing and modeling. One of the major objectives of the conference is the education and encouragement of young investigators, and therefore this NIH R13 proposal seeks funding to provide twenty grants for each of the next three years to graduate students and postdoctoral fellows based at US institutions to partially cover costs of MIC conference registration and short course fees.",IEEE Medical Imaging Conference,10071524,R13EB030423,"['Academia', 'Animals', 'Area', 'Artificial Intelligence', 'Attention', 'Award', 'Biological', 'Biomedical Engineering', 'Brain', 'Clinical Management', 'Collaborations', 'Communities', 'Complement', 'Computer software', 'Computing Methodologies', 'Detection', 'Development', 'Diagnosis', 'Disabled Persons', 'Discipline of Nuclear Medicine', 'Disease Management', 'Education', 'Educational Activities', 'Educational workshop', 'Emission-Computed Tomography', 'Engineering', 'Evaluation', 'Exposure to', 'Fees', 'Fostering', 'Funding', 'Gamma Rays', 'Generations', 'Government', 'Grant', 'Housing', 'Image', 'Image Analysis', 'Imaging technology', 'Industrialization', 'Industry', 'Institution', 'International', 'Italy', 'Japan', 'Joints', 'Kinetics', 'Lead', 'Learning', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Care Costs', 'Medical Imaging', 'Medical Technology', 'Methods', 'Minority', 'Modeling', 'Modernization', 'Monitor', 'Multimodal Imaging', 'Nuclear', 'Optics', 'Oral', 'Participant', 'Photons', 'Physics', 'Positron-Emission Tomography', 'Postdoctoral Fellow', 'Radiation therapy', 'Research', 'Research Personnel', 'Research Project Grants', 'Resolution', 'Roentgen Rays', 'Running', 'Scientist', 'Semiconductors', 'Signal Transduction', 'Students', 'Suggestion', 'System', 'Techniques', 'Technology', 'Temperature', 'Therapeutic Intervention', 'Time', 'Tracer', 'Translations', 'Ultrasonography', 'Underrepresented Groups', 'United States National Institutes of Health', 'Woman', 'Work', 'base', 'clinical imaging', 'clinical practice', 'cost', 'deep learning', 'design', 'detector', 'disability', 'graduate student', 'image processing', 'image reconstruction', 'imaging modality', 'innovation', 'instrumentation', 'interest', 'kinetic model', 'meetings', 'member', 'models and simulation', 'multidisciplinary', 'multimodality', 'nanoparticle', 'novel', 'nuclear science', 'parametric imaging', 'portability', 'posters', 'programs', 'public education', 'quantitative imaging', 'radiation detector', 'reconstruction', 'signal processing', 'statistics', 'symposium', 'theranostics']",NIBIB,MASSACHUSETTS GENERAL HOSPITAL,R13,2020,10000,0.012249472039403748
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10016840,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data resource', 'data warehouse', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2020,330502,0.008295017354278128
"Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data This project aims to develop NeuroManager™, an innovative neuroinformatics platform for advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data. A core technology that we will develop in NeuroManager will be Image Content Analysis for Retrieval Using Semantics (ICARUS), a novel, intelligent neuroimage curation system that will enable image retrieval based on visual appearance or by semantic concept. ICARUS will use machine learning applied to content-based image retrieval - (CBIR) to build and refine models that summarize microscopic and macroscopic image appearance and automatically assign semantic concepts to neuroimages. Neuroscience research generates extensive, multifaceted data that is considerably under-utilized because access to original raw data is typically maintained by the source lab. On the other hand, there are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results. Unfortunately, none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. To solve this problem, NeuroManager will include the following distinct, significant innovations: (i) versatility for handling two-dimensional (2D) and three-dimensional neuroimaging data sets from animal models and humans; (ii) functionality to share complex datasets that extends secure, privacy-controlled paradigms from institutional, laboratory-based and even public domains; (iii) flexibility to implement NeuroManager within an institute’s IT infrastructure, or on most cloud-based virtualized environments including Azure, Google Cloud Services and Amazon Web Services; (iv) and most importantly, the ICARUS technology for CBIR in neuroimaging data sets. The benefit of NeuroManager for the neuroscience research community, pharmacological and biotechnological R&D, and society in general will be to foster collaboration between scientists and institutions, promoting innovation through combined expertise in an interdisciplinary atmosphere. This will open new horizons for better understanding the neuropathology associated with several human neuropsychiatric and neurological conditions at various levels (i.e., macroscopically, microscopically, subcellularly and functionally), ultimately leading to an improved basis for developing novel treatment and prevention strategies for complex brain diseases. In Phase I we will prove feasibility of this novel technology by developing prototype software that will perform CBIR on 2D whole slide images of coronal sections of entire mouse brains from ongoing research projects of our collaborators. Work in Phase II will focus on developing the commercial software product that will include all of the innovations mentioned above. A competing technology with comparable functionality, addressing the full breadth of needs for modern neuroscience research, is currently not available commercially or otherwise. There are many advantages in sharing complex image data in neuroscience research, including the opportunity for separate analysis of raw data by other scientists from another perspective and improved reproducibility of scientific studies and their results; however none of the neuroscience data sharing options that exist today fulfill all the needs of neuroscientists. This project commercializes an innovative software for sophisticated advanced parsing, storing, aggregating, analyzing and sharing of complex neuroscience image data, including a novel, intelligent neuroimage curation system that will enable content-based neuroscience image search powered by machine learning, thereby opening new horizons in neuroscience research collaborations. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.",Neuroinformatics platform using machine learning and content-based image retrieval for neuroscience image data,9989186,R44MH118815,"['3-Dimensional', 'Address', 'Amygdaloid structure', 'Animal Model', 'Appearance', 'Archives', 'Biotechnology', 'Brain', 'Brain Diseases', 'Brain imaging', 'Chicago', 'Cloud Service', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Aggregation', 'Data Files', 'Data Provenance', 'Data Set', 'Data Sources', 'Digital Imaging and Communications in Medicine', 'Dimensions', 'Fostering', 'Human', 'Image', 'Information Systems', 'Infrastructure', 'Institutes', 'Institution', 'Intelligence', 'Laboratories', 'Machine Learning', 'Manuals', 'Microscopic', 'Modeling', 'Modernization', 'Mus', 'National Institute of Mental Health', 'Neurologic', 'Neurosciences', 'Neurosciences Research', 'New York', 'Notification', 'Pharmacology', 'Phase', 'Prevention strategy', 'Privacy', 'Problem Solving', 'Production', 'Public Domains', 'Records', 'Regenerative Medicine', 'Reproducibility', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Retrieval', 'Schools', 'Scientist', 'Secure', 'Semantics', 'Societies', 'Source', 'System', 'Technology', 'Testing', 'Universities', 'Validation', 'Visual', 'Work', 'application programming interface', 'base', 'cloud based', 'collaborative environment', 'data access', 'data format', 'data sharing', 'data warehouse', 'fighting', 'flexibility', 'hands-on learning', 'improved', 'innovation', 'interest', 'neuroimaging', 'neuroinformatics', 'neuropathology', 'neuropsychiatry', 'new technology', 'novel', 'prevent', 'prototype', 'research and development', 'stem cells', 'treatment strategy', 'two-dimensional', 'usability', 'virtual environment', 'web services', 'whole slide imaging']",NIMH,"MICROBRIGHTFIELD, LLC",R44,2020,749716,0.0345035717739992
"Nobrainer: A robust and validated neural network tool suite for imagers There is an increasing need for efficient and robust software to process, integrate, and offer insight across the diversity of population imaging efforts underway across the BRAIN Initiative and other projects. Advances in statistical learning offer a set of technologies that can address many research applications using the extensive and varied data being produced by the projects. This can transform how we analyze and integrate new data. We propose using Nobrainer, an open source Python library that leverages these new learning technologies, as a platform that greatly simplifies integrating deep learning into neuroimaging research. Using this library, we are building and distributing user-friendly and cloud enabled end-user applications for the neuroimaging community. In Aim 1, we provide neural network models. We will create robust, pre-trained neural networks for brain segmentation and time series processing using brain scans from over 65000 individuals. Once trained, these models can then be used as the basis for many other applications, especially in reducing time of processing. We will subsequently use these base networks to perform image processing, image correction, and quality control. In Aim 2, we address the ability to train on private datasets. We will use Bayesian neural network models, which support principled use of prior information. We will use these networks to help detect when the models are expected to fail on an input, and provide visualizations to better understand how the model is working. In Aim 3, we focus on the engineering needed to maintain the software infrastructure, improve efficiency, and increase the scalability of our training methods. Here, we will extend, maintain, and disseminate Nobrainer, our open source software framework, together with training materials and ready to use, cloud-friendly, applications. We will also create much faster, neural network equivalents of time consuming image processing tasks (e.g., registration, segmentation, and annotation). The Nobrainer tools developed through these aims will allow users to find and apply the most pertinent applications and developers to extend the framework to support new architectures and disseminate new models and applications. We expect these tools to be used by any neuroimaging researcher through integration with BRAIN archives and popular software packages. These tools will significantly reduce data processing and new model development time, thus allowing faster exploration of hypotheses using public data and increase reusability of data through greater trust in model outputs. 9/11/2019 ResearchPlan - Google Docs The proposal will create artificial intelligence software for scientists to analyze, integrate, and visualize data from large brain imaging projects, which inform our understanding of brain structure, function, and development. Open and reusable software helps to increase collaboration and benefits researchers, but can also be used by citizen scientists and students in high schools and colleges. An open collection of neural network tools will facilitate scientific communities and has the potential to accelerate scientific discoveries about the nervous system. https://docs.google.com/document/d/11s9ZRzy8tHs6NguzpnJdJUWRgLvdkXpEYjZchtJXSmY/edit# 2/23",Nobrainer: A robust and validated neural network tool suite for imagers,10021957,RF1MH121885,"['Address', 'Adolescent', 'Architecture', 'Archives', 'Artificial Intelligence', 'BRAIN initiative', 'Bayesian neural network', 'Brain', 'Brain imaging', 'Brain scan', 'Cognitive', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Consumption', 'Data', 'Data Set', 'Data Sources', 'Development', 'Diagnosis', 'Disease', 'Educational workshop', 'Engineering', 'Ethics', 'Evaluation', 'Failure', 'Human', 'Image', 'Individual', 'Informatics', 'Institution', 'Label', 'Learning', 'Legal', 'Libraries', 'Longevity', 'Memory', 'Mental Health', 'Methods', 'Modeling', 'Nervous system structure', 'Network-based', 'Neural Network Simulation', 'Output', 'Pattern', 'Population', 'Population Heterogeneity', 'Privacy', 'Privatization', 'Process', 'Psychological Transfer', 'Pythons', 'Quality Control', 'Research', 'Research Personnel', 'Sampling', 'Scientist', 'Series', 'Software Engineering', 'Software Framework', 'Structure', 'Students', 'Technology', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Training', 'Training Support', 'Trust', 'Uncertainty', 'Visualization', 'Work', 'algorithm training', 'base', 'citizen science', 'cognitive development', 'college', 'computerized data processing', 'connectome', 'data reuse', 'deep learning', 'distributed data', 'diverse data', 'high school', 'image processing', 'imager', 'improved', 'insight', 'large datasets', 'learning strategy', 'model development', 'network models', 'neural network', 'neuroimaging', 'neurophysiology', 'open source', 'software infrastructure', 'statistical learning', 'tool', 'user-friendly']",NIMH,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,RF1,2020,419908,-0.013655327684345542
"SBIR Phase I Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring This project aims to develop an interpretable, physician-in-the-loop AI-aided software that accurately delineates glioma boundaries in MRIs, computes volumetric curves, and statistically quantifies the tumor growth in longitudinal studies. The current clinical practice of visually analyzing and manually contouring tumors is subjective, time-consuming, and often inconsistent. The novelty of MRIMath's explainable, trustworthy, and physician-in-the-loop AI system is multi-fold. First, we introduce a multi-scale feature extraction framework using the inception modules in contracting and expanding paths of the U-Net image segmentation neural network architecture. Second, we propose a new loss function based on the modified Dice similarity coefficient. Third, we train and test the AI system using two learning regimes: learning to segment intra-tumoral structures and learning to segment glioma sub-regions. Finally, we produce heat maps to visualize the features extracted by the AI, thus offering physicians a view of AI's attention patterns and activation maps that were triggered during AI's decision-making. An intuitive and interactive User Interface will allow the physician to review contouring results, make adjustments and approve contours, visualize AI's explanations and volumetric measurements, and finally review the results of the statistical analysis. Any modifications made by the physician will be used later to re-train AI. n/a","SBIR Phase I Topic 402 -  Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring",10269837,5N91020C00049,"['Artificial Intelligence', 'Attention', 'Computer software', 'Consumption', 'Contracts', 'Data', 'Data Sources', 'Decision Making', 'Diagnosis', 'Glioma', 'Human', 'Intuition', 'Learning', 'Longitudinal Studies', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Measurement', 'Modality', 'Modification', 'Monitor', 'Pattern', 'Phase', 'Physicians', 'Small Business Innovation Research Grant', 'Specificity', 'Statistical Data Interpretation', 'Structure', 'System', 'Testing', 'Time', 'TimeLine', 'Training', 'base', 'cancer imaging', 'cancer prevention', 'clinical practice', 'design', 'feature extraction', 'imaging Segmentation', 'imaging software', 'imaging system', 'loss of function', 'neural network architecture', 'prototype', 'tumor', 'tumor growth', 'usability']",NCI,"MRIMATH, LLC",N43,2020,400000,-0.02831562796798546
"SBIR Phase I Topic 402: Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring Image-based evaluation of lymph nodes is an essential step in cancer diagnosis, treatment and monitoring. Current clinical practice mostly uses qualitative or semi-quantitative measures in evaluation and thus suffers from inaccuracy due to intra- and inter-observer variability and increased human efforts. This becomes a more serious issue in head and neck cancers due to the large number of clinically relevant lymph nodes. In this project an AI-based automatic segmentation software will be developed for quantitative cervical lymph node evaluation to increase the accuracy and reduce the cost. However, there are a few challenges in developing and deploying such a software due to different clinical practices such as usage of different modalities (MRI and/or CT) and complex clinical workflow. To address these challenges, a novel AI algorithm that can handle the variability in imaging modalities and support incremental learning using site-specific data to enhance its robustness will be developed; a private-cloud-based software framework with high usability will then be developed to incorporate this algorithm and provide advanced visualization and reporting for clinical usage. This software will have high impact on all stages of patient care for head and neck cancers and can be further extended to other cancers. n/a","SBIR Phase I Topic 402: Artificial Intelligence-Aided Imaging for Cancer Prevention, Diagnosis, and Monitoring",10269836,5N91020C00048,"['Address', 'Algorithms', 'Artificial Intelligence', 'Cervical lymph node group', 'Clinical', 'Complex', 'Computer software', 'Data', 'Detection', 'Diagnosis', 'Evaluation', 'Head and Neck Cancer', 'Human', 'Image', 'Interobserver Variability', 'Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Measures', 'Modality', 'Monitor', 'Patient Care', 'Performance', 'Phase', 'Privatization', 'Reporting', 'Site', 'Small Business Innovation Research Grant', 'Software Framework', 'Visualization', 'automated segmentation', 'base', 'cancer diagnosis', 'cancer imaging', 'cancer prevention', 'clinical practice', 'clinically relevant', 'cloud based', 'cost', 'imaging modality', 'lymph nodes', 'novel', 'segmentation algorithm', 'usability']",NCI,"CARINA MEDICAL, LLC",N43,2020,400000,-0.002486602197523777
"THE XNAT IMAGING INFORMATICS PLATFORM PROJECT SUMMARY This proposal aims to continue the development of XNAT. XNAT is an imaging informatics platform designed to facilitate common management and productivity tasks for imaging and associated data. We will develop the next generation of XNAT technology to support the ongoing evolution of imaging research. Development will focus on modernizing and expanding the current system. In Aim 1, we will implement new web application infrastructure that includes a new archive file management system, a new event bus to manage cross-service orchestration and a new Javascript library to simplify user interface development. We will also implement new core services, including a Docker Container service, a dynamic scripting engine, and a global XNAT federation. In Aim 2, we will implement two innovative new capabilities that build on the services developed in Aim 1. The XNAT Publisher framework will streamline the process of data sharing by automating the creation and curation of data releases following best practices for data publication and stewardship. The XNAT Machine Learning framework will streamline the development and use of machine learning applications by integrating XNAT with the TensorFlow machine learning environment and implementing provenance and other monitoring features to help avoid the pitfalls that often plague machine learning efforts. For both Aim 1 and 2, all capabilities will be developed and evaluated in the context of real world scientific programs that are actively using the XNAT platform. In Aim 3, we will provide extensive support to the XNAT community, including training workshops, online documentation, discussion forums, and . These activities will be targeted at both XNAT users and developers. RELEVANCE Medical imaging is one of the key methods used by biomedical researchers to study human biology in health and disease. The imaging informatics platform described in this application will enable biomedical researchers to capture, analyze, and share imaging and related data. These capabilities address key bottlenecks in the pathway to discovering cures to complex diseases such as Alzheimer's disease, cancer, and heart disease.",THE XNAT IMAGING INFORMATICS PLATFORM,10002330,R01EB009352,"['Address', 'Administrator', 'Alzheimer&apos', 's Disease', 'Architecture', 'Archives', 'Area', 'Automation', 'Biomedical Research', 'Brain', 'Cardiology', 'Categories', 'Classification', 'Communities', 'Complex', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Docking', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Evolution', 'Goals', 'Health', 'Heart Diseases', 'Human', 'Human Biology', 'Image', 'Individual', 'Informatics', 'Infrastructure', 'Instruction', 'Internet', 'Libraries', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Modality', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Newsletter', 'Optics', 'Paper', 'Pathway interactions', 'Peer Review', 'Persons', 'Plague', 'Positron-Emission Tomography', 'Principal Investigator', 'Process', 'Productivity', 'Publications', 'Publishing', 'Radiology Specialty', 'Research', 'Research Personnel', 'Security', 'Services', 'System', 'Technology', 'TensorFlow', 'Training', 'Validation', 'base', 'biomedical resource', 'computer framework', 'computing resources', 'data curation', 'data sharing', 'design', 'distributed data', 'educational atmosphere', 'hackathon', 'imaging informatics', 'imaging program', 'improved', 'informatics tool', 'innovation', 'next generation', 'online tutorial', 'open source', 'outreach program', 'pre-clinical', 'programs', 'skills', 'symposium', 'tool', 'virtual', 'web app']",NIBIB,WASHINGTON UNIVERSITY,R01,2020,653481,0.01988654969198593
"Center for Advanced Imaging Innovation and Research (CAI2R) Overall Project Summary  The Center for Advanced Imaging Innovation and Research (CAI2R) pursues a mission of bringing people together to create new ways of seeing. The work of our Center has been focused on creating new paradigms for the acquisition, reconstruction, and interpretation of biomedical images, and on implementing new collaboration models in order to translate these developments rapidly into clinical practice.  The world of biomedical imaging is changing, and CAI2R has been at the forefront of that change. Tasks that were once the sole domain of meticulously-engineered imaging hardware are now beginning to be accomplished in software, increasingly informed by diverse arrays of inexpensive auxiliary sensors. Information once pursued through the laborious acquisition of carefully separated image datasets is now being derived from newly integrated, and richly quantitative, data streams. In keeping with these themes, our Center will be organized around the following four Technology Research and Development (TR&D) projects going forward: 1. Reimagining the Future of Scanning: Intelligent image acquisition, reconstruction, and analysis. 2. Unshackling the Scanners of the Future: Flexible, self-correcting, multisensor machines. 3. Enriching the Data Stream: MRI and PET in concert. 4. Revealing Microstructure: Biophysical modeling and validation for discovery and clinical care.  In each of these projects, we aim to push medical imaging technology to the next level, both in hardware and in software. Having made great strides in developing rapid, continuous imaging data streams, we will next aim to add key new information to those streams, both from physics-driven microstructural modeling and from data- driven machine learning. Having focused on the development of robust tools for image acquisition and reconstruction, we will extend the pipeline to image interpretation, using the results of human- or machine- derived evaluations of image content as feedback for the further improvement of acquisition strategies and sensor designs. We will also aim to close the loop between diagnostic sensing and therapeutic intervention, exploring new ways to guide therapy with continuously-acquired information about tissue bioeffects.  Our Center has an explicit translational focus, which is reflected in the day-to-day operation of TR&D projects as well as in the topics of Collaborative Projects (CPs) and Service Projects (SPs), which are focused on three general areas of high public health impact: cancer, musculoskeletal disease, and neurologic disease.  In keeping with this translational emphasis, CAI2R is also be driven by an embedded collaboration model in which basic scientists, clinicians, and industry developers sit down together regularly at the scanners for interactive technology development and assessment. With early involvement of clinical stakeholders and industry partners, we aim to make CAI2R technologies widely available, for the advancement of biomedical knowledge and for the benefit of patients and the physicians who care for them. Overall Project Narrative  The Center for Advanced Imaging Innovation and Research (CAI2R) develops novel imaging techniques and technologies for the improved diagnosis and management of cancer, musculoskeletal disease, neurological disease and other disorders with a profound impact on human health. By exploiting connections between imaging modalities such as MRI and PET, we aim to advance the fundamental capabilities of each, so as to expand biomedical knowledge and improve the care of patients.",Center for Advanced Imaging Innovation and Research (CAI2R),9996604,P41EB017183,"['Adopted', 'Area', 'Artificial Intelligence', 'Biology', 'Caring', 'Clinical', 'Collaborations', 'Color', 'Computer software', 'Country', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Doctor of Philosophy', 'Engineering', 'Feedback', 'Funding', 'Future', 'Goals', 'Health', 'Human', 'Image', 'Image Analysis', 'Imagination', 'Imaging Device', 'Imaging technology', 'Industrial Product', 'Industry', 'Institution', 'Intelligence', 'Knowledge', 'Legal patent', 'Machine Learning', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Medical Imaging', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Musculoskeletal Diseases', 'Patient Care', 'Patients', 'Performance', 'Philosophy', 'Physicians', 'Physics', 'Positron-Emission Tomography', 'Process', 'Productivity', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Scanning', 'Scientist', 'Services', 'Software Tools', 'Stream', 'Technology', 'Technology Assessment', 'Testing', 'Therapeutic Intervention', 'Time', 'Tissues', 'Training', 'Translating', 'Ursidae Family', 'Validation', 'Visit', 'Work', 'bioimaging', 'biophysical model', 'cancer imaging', 'clinical care', 'clinical practice', 'data acquisition', 'data streams', 'design', 'flexibility', 'image reconstruction', 'imaging approach', 'imaging modality', 'imaging scientist', 'improved', 'industry partner', 'innovation', 'interest', 'medical schools', 'multidisciplinary', 'musculoskeletal imaging', 'nervous system disorder', 'neuroimaging', 'novel imaging technique', 'open source', 'operation', 'radio frequency', 'reconstruction', 'sensor', 'technology development', 'technology research and development', 'tool', 'web site']",NIBIB,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,P41,2020,1198860,0.013860942663691483
"Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues PROJECT SUMMARY/ABSTRACT The overall goal of the proposed project is to develop open-source software and algorithms for 3-D reconstruc- tion and multi-scale mapping of normal tissues. Another significant goal is to evaluate effects of aging and envi- ronmental factors on molecular and structural architecture of skin. We will leverage our mature (TRL8) technol- ogy for multiplexed 2-D imaging (Cell DIVE™), and our vast experience in 2-D image analytics and machine learning. We have selected normal skin as the organ to develop these tools for several reasons, a) clinical sam- ples from different age groups are more readily available, b) it is a good model to independently capture changes in extracellular matrix (ECM) due to age and normal exposure to environmental factors as well as a variety of pathogenic insults. While the ECM, cellular and intracellular molecular composition varies considerably among various organs, we believe many of the tools developed under this program will be applicable to reconstruct and map other organ models at high (cellular/subcellular) resolution. This proposal will focus on developing algo- rithms and a framework for multi-scale mapping of 3-D tissue images, which will address HuBMAP priorities around quantitative 3-D image analysis/mapping, including automated 3-D image segmentation, feature ex- traction, and image annotation. High-resolution (subcellular) mapping of biomolecules will be implemented us- ing 2-D multiplexed images that are used to reconstruct the 3-D tissue and linked to a lower resolution 3-D opti- cal coherence tomography (OCT) image of the normal tissue. Other cell-level omic data (e.g., RNA FISH) will be mapped in the same way. The low-resolution image is mapped back to a higher-level landmark (e.g., organ) as defined by the HuBMAP common coordinate framework (CCF). As outlined, our proposed technologies will in- clude several key features that are significant and complimentary to existing HuBMAP consortium projects and will advance the state of the art in 3-D tissue analysis. The proposed algorithms will have several key innova- tions that will advance the state of the art in 3-D multiplexed tissue image analysis. First, given the large vol- umes to be analyzed, high throughput will be a key requirement of each image analysis algorithm. This will be supported by our extensive experience in parallelizing single cell analysis pipelines. Second, the proposed algo- rithms will segment the images at multiple scales. The third area of innovation will focus on efficient multi- channel analysis. The proposed project will include creation of an easy-to-use software tool for assembling and visualizing multiscale tissue data called Tissue Atlas Navigation Graphical Overview (TANGO). PROJECT NARRATIVE Composition and organization of cells and the extracellular matrix (ECM) they are embedded in, controls the function of different organs in human body. Alterations in any of these can lead to onset and progression of var- ious diseases. The proposed project will develop image analytics algorithms and open source software for high- resolution 3-D mapping of skin, the largest organ in the human body, and evaluate molecular and architectural changes due to aging and UV exposure.",Multi-Scale 3-D Image Analytics for High Dimensional Spatial Mapping of Normal Tissues,10246250,UH3CA246594,"['3-Dimensional', 'Address', 'Age', 'Aging', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Architecture', 'Area', 'Artificial Intelligence', 'Atlases', 'Back', 'Biological Markers', 'Biopsy', 'California', 'Cells', 'Cellular biology', 'Chemistry', 'Clinical', 'Collaborations', 'Computer software', 'Coupled', 'Data', 'Data Collection', 'Disease', 'Environment', 'Environmental Risk Factor', 'Exposure to', 'Extracellular Matrix', 'Funding', 'Generations', 'Genome', 'Goals', 'Government', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Institutes', 'Lead', 'Link', 'Location', 'Machine Learning', 'Maps', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Multiomic Data', 'Normal tissue morphology', 'Optics', 'Organ', 'Organ Model', 'Outcome', 'Pathogenicity', 'Proteomics', 'RNA', 'Recording of previous events', 'Research', 'Resolution', 'Sampling', 'Skin', 'Skin Aging', 'Skin Tissue', 'Software Tools', 'Solid', 'Technology', 'Three-Dimensional Image', 'TimeLine', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Traction', 'UV Radiation Exposure', 'United States National Institutes of Health', 'Universities', 'Visualization', 'Work', 'age effect', 'age group', 'analysis pipeline', 'data integration', 'data visualization', 'experience', 'extracellular', 'high dimensionality', 'image visualization', 'imaging Segmentation', 'imaging platform', 'innovation', 'member', 'multidimensional data', 'multidisciplinary', 'multiple omics', 'multiplexed imaging', 'multiscale data', 'open source', 'programs', 'reconstruction', 'sample collection', 'single cell analysis', 'software development', 'task analysis', 'three-dimensional visualization', 'tomography', 'tool']",NCI,GENERAL ELECTRIC GLOBAL RESEARCH CTR,UH3,2020,750000,0.03945153688851724
"Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells ABSTRACT Antibiotic resistance has become a significant public health threat. To combat the problem, a rapid pathogen identification (ID) and antimicrobial susceptibility testing (AST) technology is needed to provide timely diagno- sis of resistant infections and delivery of accurate antibiotic treatment at primary health-care settings, includ- ing hospitals and point-of-care (POC). The present project aims to develop a point-of-care AST (POCASTTM) technology based on a large-image-volume microscopy technique that enables direct detection of individual bacterial cells in clinical samples without culturing or pathogen isolation, and a machine-learning model that allows fast determination of pathogen and susceptibility. To establish the technology, the project will focus on urinary tract infections (UTIs). UTIs affect millions of people annually, and the pathogens that usually cause UTIs are the organisms that pose the highest threat of antimicrobial resistance, including carbapenem- resistant Enterobacteriaceae (CRE) and extended spectrum β-lactamase (ESBL)-producing Enterobacteri- aceae. This project will focus on: 1) developing the large-image-volume microscopy and machine learning model for simultaneous tracking of multi-phenotypic features of single bacterial cells directly in patient urine sample, and performing rapid automatic pathogen ID and AST for UTIs; 2) building prototype instrument, and 3) validating the instrument for UTIs using large scale clinical samples. Successful development and validation of the tech- nology will enable precise antibiotic prescription on the same day of patient visit. The project will be carried out by a multidisciplinary team with expertise in biosensors (Biodesign Center for Bioelectronics and Biosensors, ASU), microbiology and infectious diseases (Biodesign Center for Immuno- therapy, Vaccines and Virotherapy, ASU), biomedical instrument development and production (Biosensing Instrument Inc.), and clinical testing (Clinical Microbiology Laboratory, Mayo Clinic). ! PROJECT NARRATIVE This project will develop a culture-independent technology for point-of-care diagnosis of antimicrobial-resistant bacteria in urinary tract infections within 3 hours, by imaging urine samples directly with an innovative large- image-volume imaging technique and analyzing the data with a machine-learning model. Successful devel- opment of the technology will enable precise antibiotic prescriptions and accurate treatment of the patient on the same day of visit. !",Point-of-care antimicrobial susceptibility testing based on simultaneous tracking of multi-phenotypic features of single bacterial cells,9970170,R01AI138993,"['Address', 'Affect', 'Agreement', 'Algorithms', 'Antibiotic Resistance', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial Resistance', 'Antimicrobial susceptibility', 'Arizona', 'Bacterial Infections', 'Biosensing Techniques', 'Biosensor', 'Blood Cells', 'Care Technology Points', 'Categories', 'Cells', 'Clinic', 'Clinical', 'Clinical Microbiology', 'Communicable Diseases', 'Computer software', 'Crystallization', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Diagnosis', 'Enterobacteriaceae', 'Extended-spectrum β-lactamase', 'Face', 'Growth', 'Hospitals', 'Hour', 'Image', 'Imaging Techniques', 'Immunotherapy', 'Individual', 'Infection', 'Laboratories', 'Machine Learning', 'Measures', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Modeling', 'Morphology', 'Motion', 'Optics', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Phenotype', 'Pilot Projects', 'Predisposition', 'Primary Health Care', 'Production', 'Protocols documentation', 'Public Health', 'Research Personnel', 'Resistance', 'Risk', 'Sampling', 'Specificity', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Urinary tract infection', 'Urine', 'Vaccines', 'Validation', 'Virotherapy', 'Visit', 'Work', 'antimicrobial', 'automated algorithm', 'bacterial resistance', 'base', 'carbapenem-resistant Enterobacteriaceae', 'clinical Diagnosis', 'clinically relevant', 'combat', 'density', 'design', 'health care settings', 'image processing', 'innovation', 'instrument', 'light scattering', 'machine learning algorithm', 'multidisciplinary', 'pathogen', 'point of care', 'prototype', 'research clinical testing', 'technology development', 'technology validation']",NIAID,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R01,2020,991540,0.014572111361328419
"mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II 1 Project Summary NIH is increasing its investment in large, multi-center brain MRI studies via projects such as the recently announced BRAIN initiative. The success of these studies depends on the quality of MRIs and the resulting image measurements, regardless of sample size. Even though quality control of MRIs and corresponding measurements could be outsourced, most neuroscience studies rely on in-house procedures that combine automatically generated scores with manually guided checks, such as visual inspection. Implementing these procedures typically requires combining several software systems. For example, the NIH NIAAA- and BD2K- funded Data Analysis Resource (DAR) of the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA) uses XNAT to consolidate the structural, diffusion, and functional MRIs acquired across five sites, and has also developed their own custom software package to comply with study requirements for a multi-tier, quality control (QC) workflow. However, these custom, one-off tools lack support for the multi-site QC workflows that will come with the unified platform that MIQA represents: a design that supports collaboration and sharing, and strong cohesion between technologies. To improve the effectiveness of QC efforts specific to multi-center neuroimaging studies, we will develop a widely accessible and broadly compatible software platform that simplifies the creation of custom QC workflows in compliance with study requirements, provides core functionality for performing QC of medical images, and automatically generates documentation compliant with the FAIR principle, i.e., making scientific results findable, accessible, interoperable, and reusable.  Specifically, our multi-site, web-based software platform for Medical Image Quality Assurance (MIQA) will enable efficient and accurate QC processing by leveraging open-source, state-of-the-art web interface technologies, such as a web-based dataset caching system and machine learning to aid in QC processes. Users will be able to configure workflows that not only reflect the specific requirements of medical imaging studies but also minimize the time spent on labor-intensive operations, such as visually reviewing scans. Issue tracking technology will enhance communication between geographically-distributed team members, as they can easily share image annotations and receive automated notifications of outstanding QC issues. The system will be easy to deploy as it will be able to interface with various imaging storage backends, such as local file systems and XNAT. While parts of this functionality have been developed elsewhere, MIQA is unique as it provides a unified, standard interface for efficient QC setup, maintenance, and review for projects analyzing multiple, independently managed data sources.  The usefulness of this unique QC system will be demonstrated on increasing the efficiency of the diverse QC team of the multi-center NCANDA study. Narrative The goal of this proposal is to develop a web-based, multi-site, open-source platform for Medical Image Quality Assurance (MIQA) to address the QC needs of geographically diverse teams using small and large medical image-based studies alike. MIQA will enable efficient and accurate QC processing by levering state-of-the-art machine learning, data management, and web interface technologies. Our effort will minimize the time spent on labor-intensive reviews and analysis operations by supporting team-oriented reviewing that is guided by highly customizable workflows seamlessly interacting with existing data management systems.",mIQa: A Highly Scalable and Customizable Platform for Medical Image Quality Assessment - Phase II,10010814,R44MH119022,"['3-Dimensional', 'Active Learning', 'Address', 'Adolescence', 'Alcohols', 'Archives', 'Area', 'BRAIN initiative', 'Big Data to Knowledge', 'Brain', 'Brain imaging', 'Classification', 'Collaborations', 'Communication', 'Computer software', 'Custom', 'Data', 'Data Analyses', 'Data Management Resources', 'Data Provenance', 'Data Set', 'Data Sources', 'Detection', 'Diffusion', 'Documentation', 'Effectiveness', 'Ensure', 'Evaluation', 'Evaluation Studies', 'FAIR principles', 'Four-dimensional', 'Funding', 'Generations', 'Geography', 'Goals', 'Human', 'Image', 'Intelligence', 'Internet', 'Investments', 'Iowa', 'Label', 'Learning', 'Licensing', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Manuals', 'Measurement', 'Medical Imaging', 'Modeling', 'Monitor', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences', 'Notification', 'Online Systems', 'Peer Review', 'Phase', 'Procedures', 'Process', 'Publications', 'Quality Control', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Scanning', 'Site', 'Structure', 'System', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'Update', 'Visual', 'Visualization', 'Work', 'Writing', 'annotation  system', 'base', 'cohesion', 'computing resources', 'cost', 'data management', 'deep learning', 'design', 'dexterity', 'image archival system', 'imaging study', 'improved', 'innovation', 'learning algorithm', 'learning strategy', 'member', 'nervous system disorder', 'neurodevelopment', 'neuroimaging', 'open source', 'operation', 'quality assurance', 'research study', 'software systems', 'success', 'three-dimensional visualization', 'tool', 'web interface']",NIMH,"KITWARE, INC.",R44,2020,819293,0.04160081112317393
"Super-multiplexed fluorescence nanoscopy for imaging-based proteomics PROJECT SUMMARY In situ immunofluorescence imaging is a powerful method to study the locations, expression levels and structures of proteins in cells and tissues. In particular, multiplexed imaging reveals the interaction networks of proteins, which allows us to understand the underlying mechanisms of many diseases. However, it has been challenging to perform multiplexed immunofluorescence imaging due to its extremely time-consuming process, high cost and lack of signal amplification. The limited spatial resolution achievable with confocal microscopy often fails to reveal complex spatial organization and to determine localizations of proteins. Here we propose super-multiplexed immunofluorescence nanoscopy that is capable of imaging more than twenty different proteins in 24 hours with nanoscale resolution. We will employ DNA-barcoded secondary nanobodies that are monovalent, open-source and designed for quantitative labeling. Repeated introduction and washing of fluorescent DNA imagers will generate highly multiplexed images. Moreover, we will develop unprecedentedly fast stimulated emission depletion (STED) microscopy that employs a parallelized line array of doughnut beams. It will feature a large imaging area and excellent optical sectioning capability. Photon reassignment, hyperspectral imaging and deep-learning will further facilitate rapid super-resolution-based protein profiling. Our new biochemical and optical tools will play crucial roles in diverse biomedical areas including brain proteomics and cancer profiling. PROJECT NARRATIVE We propose to develop highly multiplexed immunofluorescence super-resolution imaging tools. Our approach is fast, low cost and readily accessible, which will facilitate nanoscale imaging-based proteomics in cells and tissues.",Super-multiplexed fluorescence nanoscopy for imaging-based proteomics,10028050,R35GM138039,"['Area', 'Bar Codes', 'Biochemical', 'Brain', 'Cells', 'Complex', 'Confocal Microscopy', 'Consumption', 'DNA', 'Disease', 'Fluorescence', 'Hour', 'Image', 'Imaging Device', 'Immunofluorescence Immunologic', 'In Situ', 'Label', 'Location', 'Malignant Neoplasms', 'Methods', 'Microscopy', 'Nanoscopy', 'Optics', 'Photons', 'Play', 'Process', 'Proteins', 'Proteomics', 'Resolution', 'Role', 'Signal Transduction', 'Structural Protein', 'Time', 'Tissues', 'base', 'cost', 'deep learning', 'design', 'imager', 'multiplexed imaging', 'nanobodies', 'nanoscale', 'open source', 'protein profiling', 'tool']",NIGMS,UNIVERSITY OF CENTRAL FLORIDA,R35,2020,267626,0.005307567841794294
"Automated Object Contouring Methods & Software for Radiotherapy Planning Abstract In 2015, 1,658,370 new cancer cases are estimated to occur in the US, where nearly two-thirds will have radiation therapy (RT). Given that there are over 2,300 RT centers in the US, and current systems for contouring organs at risk (OARs) rely mostly on manual methods, there is a strong commercial opportunity for producing a software system that can contour OARs in medical images at a high degree of automation and for impacting current practice of RT planning. Encouraged by our strong Phase I results in thoracic and head and neck (H&N) body regions compared to current industry systems, we seek the accuracy, efficiency, and clinical acceptance of the contours output by our software product to significantly exceed those of existing systems. Our overall aim for Phase II is to advance the algorithms and prototype software developed in Phase I into a leading commercial software product, and demonstrate its efficacy in multiple medical centers across the country with diverse populations. Phase II specific aims are three-fold: (1) Further advance the automatic anatomy recognition algorithms from Phase I using advanced deep learning techniques. (2) Develop a cloud-based software auto contouring service. (3) Perform clinical evaluation of the new software on H&N and thoracic cases. Aim 1 will be accomplished in three stages: (a) Automating the process of defining the body region on given patient CT studies, which is currently done manually in our system, via a new concept of virtual landmarks using deep learning techniques. (b) Improving object recognition/ localization accuracy from the current 2 voxels for “good” quality data sets to 1 voxel and from 4-5 voxels for “poor” quality data sets to 2-3 voxels by using virtual landmarks to learn object relationships. (c) Improving object delineation by combining object localization methods with deep learning techniques applied to the vicinity of the localized objects to bring boundary distance accuracy within 1 voxel. Aim 2 will be achieved by developing a cloud-based Software-as-a-Service model to implement the software that incorporates the algorithms. To accomplish Aim 3, an evaluation study involving four academic RT centers will be undertaken to assess the efficiency, accuracy, and acceptability of the contours output by the new software. To assess efficiency, contouring time taken by the current clinical process will be compared to the time taken by the new software method plus any manual adjustment needed. Accuracy will be assessed by comparing software output to carefully prepared ground truth contours. Acceptability will be determined by conducting a blinded reader study, where an acceptability score (1-5) is given by radiation oncologists to software produced contours, ground truth contours, and contours produced by the normal clinical process, and comparing these scores. Expected clinical outcomes are significantly improved clinical efficiency/ acceptability of contouring compared to current practice. There is a strong commercial opportunity for producing a software system that can contour organs at risk in medical images at a high degree of automation for impacting current practice of radiation therapy planning. Encouraged by strong competitive results from the Phase I part of this project, in this grant, further technical advances and a cloud-based software service are proposed. A multicenter clinical evaluation of the new product is also planned to assess the clinical efficacy of the system.",Automated Object Contouring Methods & Software for Radiotherapy Planning,10241562,R42CA199735,"['Adoption', 'Algorithms', 'Anatomy', 'Automation', 'Back', 'Blinded', 'Body Regions', 'Chest', 'Clinical', 'Collaborations', 'Computer software', 'Country', 'Data Set', 'Development', 'Digital Imaging and Communications in Medicine', 'Evaluation', 'Evaluation Studies', 'Grant', 'Head and neck structure', 'Health Personnel', 'Image', 'Industry', 'Inferior', 'Investigation', 'Investments', 'Learning', 'Location', 'Malignant Neoplasms', 'Malignant neoplasm of thorax', 'Manuals', 'Medical Imaging', 'Medical center', 'Methods', 'Modeling', 'Morphologic artifacts', 'Names', 'Object Attachment', 'Organ', 'Outcome', 'Output', 'Pathology', 'Patients', 'Phase', 'Population Heterogeneity', 'Process', 'Protocols documentation', 'Radiation Oncologist', 'Radiation therapy', 'Reader', 'Research', 'Risk', 'Scanning', 'Service delivery model', 'Services', 'Slice', 'Specific qualifier value', 'System', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Visualization', 'Work', 'base', 'clinical efficacy', 'cloud based', 'deep learning', 'image processing', 'improved', 'interest', 'learning network', 'learning strategy', 'neural network', 'novel strategies', 'object recognition', 'prototype', 'research clinical testing', 'software as a service', 'software development', 'software systems', 'treatment center', 'treatment planning', 'virtual']",NCI,"QUANTITATIVE RADIOLOGY SOLUTIONS, LLC",R42,2020,2500,-0.02035267935184431
"Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality Over the past 15 years, new imaging technologies and methods for high throughput imaging have revolutionized structural biology by extending the resolution and scale of collected images in 3 dimensions. The resulting image volumes are more typically hundreds of GB to even tens of TB and in some cases approach PB sizes. These file sizes pose challenges for image acquisition, image analysis, and communication of a representative set of raw data and quantification. Image acquisition runs can be lengthy and expensive, and often errors are not identified until after the completion of scanning. Large files contain many structures, and require machine learning (ML) strategies in a context that permits error correction. Scientific communication requires tools for ready access to raw data, and more efficient methods to communicate the rapidly accumulating sets of scientific information. We propose to leverage virtual reality (VR) and verbal communication within the VR environment, to streamline each of these stages of scientific work, by capitalizing on the more natural abilities for stereoscopic vision and hearing to process scenes and language. Based upon the tool base and direct volume rendering of large files that we have established in our VR software, called syGlass, we will first integrate VR into the microscope controls for tuning the microscope and then efficiently inspecting images in 3D as they are acquired (Aim 1). Next, we will introduce novel domain adaptation techniques in the ML field to scale up 3D image quantification capabilities for current acquisition sizes, by coupling them with user-optimized experiences that do not require ML expertise, and yet provide automated and accurate results (Aim 2). Finally, we will provide tools to efficiently generate narrated scientific presentations in VR for use in the lab setting, as manuscript publications, and for production of educational materials (Aim 3). In each of these activities, we will introduce paradigm shifts in the management of experiments, analysis of the resulting data, and publication of manuscripts and materials to other scientists and the general public. The goal of this project is to speed the pipeline from image acquisition to communication of analyzed data for large image files (big data). We propose to leverage virtual reality to change the way users interact with their microscope, provide new methods for more accurate quantification and make scientific data more transparent, and more accessible to specialists and the general public. These new paradigms are applicable to basic, pre-clinical and clinical research, and serve the goals of big data projects to generate more reliable and encompassing scientific conclusions.","Streamlining Volumetric Imaging, Analysis and Publication Using Immersive Virtual Reality",10011054,R44MH125238,"['3-Dimensional', '3D virtual reality', '4D Imaging', 'Address', 'Awareness', 'Basic Science', 'Big Data', 'Clinical Research', 'Collection', 'Communication', 'Communities', 'Computer software', 'Coupling', 'Data', 'Data Analyses', 'Data Collection', 'Depth Perception', 'Educational Materials', 'Foundations', 'General Population', 'Goals', 'Hearing', 'Hour', 'Image', 'Image Analysis', 'Imaging Device', 'Imaging technology', 'Information Distribution', 'Ingestion', 'Instruction', 'Investments', 'Journals', 'Language', 'Lasers', 'Lighting', 'Machine Learning', 'Manuals', 'Manuscripts', 'Marketing', 'Methods', 'Microscope', 'Microscopy', 'Modeling', 'Modernization', 'Monitor', 'Neurosciences', 'Pathway interactions', 'Positioning Attribute', 'Process', 'Production', 'Publications', 'Publishing', 'Reporting', 'Resolution', 'Resort', 'Running', 'Scanning', 'Science', 'Scientist', 'Services', 'Specialist', 'Speed', 'Structure', 'Techniques', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Training', 'Visual', 'Visualization', 'Work', 'adaptation algorithm', 'base', 'data dissemination', 'data exploration', 'experience', 'experimental study', 'feature detection', 'field study', 'image processing', 'imaging modality', 'improved', 'large datasets', 'learning strategy', 'machine learning algorithm', 'movie', 'novel', 'optogenetics', 'pre-clinical research', 'scale up', 'software development', 'structural biology', 'tool', 'virtual reality', 'virtual reality environment']",NIMH,ISTOVISR,R44,2020,1159612,0.014354864430394194
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,9910382,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2020,510157,0.011455911327308596
"S10 Shared Instrument Grant - Leica Aperio Digital Scanner GT450 This application is requesting funds to purchase the Aperio™ GT-450 digital pathology slide scanner from Leica Biosystems. The requested instrumentation will be located in the Pathology and Biobanking Core of the Lester and Sue Smith Breast Center at Baylor College of Medicine (BCM). The predominant use of the Aperio scanner will be research-based whole slide imaging (WSI) and analysis of patient specimens, patient-derived xenograft (PDX) cancer models, and pre-clinical investigations on various animal- and cell-line model systems. All user projects have large sample cohorts that require high throughput, high-resolution scanning and image analysis. High capacity and improved scanning with dynamic focusing makes the GT-450 microscope scanner well-suited and the most cost-effective for use in the proposed projects. An underlying theme in the studies selected for Aperio scanner-supported services integrates novel biomarker and molecular pathway discovery with spatial morphological characterization, a necessary process to investigate heterogeneity in disease states. This instrument leverages high-throughput scanning capability with open-source, fully customizable machine-learning analytics to meet the evolving needs of investigators at Baylor College of Medicine, in particular faculty groups studying mechanisms of cancer cell dynamics and the development of new therapeutic targets. Expansion of systems biology and precision medicine research is an essential component of the college’s strategic roadmap. The Aperio GT-450 is critically needed as we modernize our laboratory offerings and capabilities; the acquisition of this digital scanner will strengthen existing research programs underway and establish new, collaborative research opportunities and directions within Baylor College of Medicine and surrounding institutions. To address the growing demand for integrating quantitative spatial assessment of biomarkers with molecular pathway discovery, we request funding for the Leica Aperio GT-450 digital microscope scanner. This instrument will facilitate research that seeks to better understand molecular mechanisms of tumorigenesis in the context of its spatial environment and will be critical for the development of clinically correlative biomarkers for next generation precision medicine research initiatives at Baylor College of Medicine.",S10 Shared Instrument Grant - Leica Aperio Digital Scanner GT450,9940426,S10OD028671,"['Animals', 'Biological Models', 'Breast', 'Cancer Model', 'Cell Line', 'Development', 'Disease', 'Faculty', 'Funding', 'Grant', 'Heterogeneity', 'Image Analysis', 'Institution', 'Laboratories', 'Machine Learning', 'Medicine', 'Microscope', 'Modernization', 'Molecular', 'Morphology', 'Pathology', 'Pathway interactions', 'Patients', 'Process', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Services', 'Slide', 'Specimen', 'Systems Biology', 'Xenograft procedure', 'base', 'biobank', 'cancer cell', 'clinical investigation', 'cohort', 'college', 'cost effective', 'digital', 'digital pathology', 'improved', 'instrument', 'instrumentation', 'new therapeutic target', 'novel marker', 'open source', 'pre-clinical', 'precision medicine', 'programs', 'whole slide imaging']",OD,BAYLOR COLLEGE OF MEDICINE,S10,2020,477043,-0.0006721439250531053
"SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env PROJECT SUMMARY (See instructions): Chronic wounds affect 6.5 million patients in the U.S., with an estimated treatment cost of $25 billion. Our team proposes research to advance our existing NSF-funded smartphone wound analysis system, which helps patients monitor their diabetic foot ulcers, providing them with instant feedback on healing progress. Our wound system analyzes a smartphone image of the patients' wound, detects the wound area and tissue composition, and generates a proprietary healing score by comparing the current image with a past image. Our envisioned chronic wound assessment system will support evidence-based decisions by the care team while visiting patients, and move wound care toward digital objectivity. We define digital objectivity as the synthesis of wound assessment metrics that are extracted autonomously from images in order to generate objective actionable feedback, enabling clinicians not trained as wound specialists to deliver ""standardized wound care"". Digital objectivity contrasts with the current practice of subjective, visual inspection of wounds based on physician experience. The first aim will develop image processing algorithms to mitigate wound analysis errors caused by non-ideal lighting in some clinical or home settings, and when the wound is photographed from arbitrary camera angles and distance. While our previous wound system worked well in ideal conditions, non-ideal lighting caused large errors and healthy skin was detected as the wound area in extreme cases. The second aim extends our existing wound analysis system that targets only diabetic wounds to handle arterial, venous and pressure ulcers, expanding the potential user. The third aim will synthesize algorithms that autonomously generate actionable wound decision rules that are learned from decisions taken by actual wound clinicians. This research is joint work of Worcester Polytechnic Institute (WPI) (technical expertise in image processing, machine learning and smartphone programming) and University of Massachusetts Medical School (UMMS) (clinical expertise on wounds, and wound patient recruitment to validate our work) RELEVANCE (See instructions): We propose research to advance our existing smartphone wound analysis system, which detects the wound area and tissue composition, and generates a proprietary healing score from a wound image. Our wound assessment system will give patients instant, actionable feedback and enable clinicians not trained as wound specialists to make objective, evidence-based wound care decisions and deliver standardized care.",SCH:Smartphone Wound Image Parameter Analysis and Decision Support in Mobile Env,9823881,R01EB025801,"['Affect', 'Algorithms', 'Area', 'Caring', 'Cellular Phone', 'Clinical', 'Diabetic Foot Ulcer', 'Feedback', 'Funding', 'Home environment', 'Image', 'Institutes', 'Instruction', 'Joints', 'Lighting', 'Machine Learning', 'Massachusetts', 'Patient Monitoring', 'Patient Recruitments', 'Patient imaging', 'Patients', 'Physicians', 'Research', 'Skin', 'Specialist', 'Standardization', 'System', 'Systems Analysis', 'Technical Expertise', 'Tissues', 'Treatment Cost', 'Universities', 'Varicose Ulcer', 'Visit', 'Visual', 'Work', 'base', 'chronic wound', 'decubitus ulcer', 'diabetic ulcer', 'digital', 'evidence base', 'experience', 'healing', 'image processing', 'medical schools', 'standardized care', 'wound', 'wound care']",NIBIB,WORCESTER POLYTECHNIC INSTITUTE,R01,2020,401916,0.017980046765402758
"Groundwork for a Synchrotron MicroCT Imaging Resource for Biology (SMIRB) Project Summary Each major human disease is associated with a specific range of morphological changes to cells and tissues in the micron scale. Normal and abnormal structure was discovered and is still characterized using histology - a microscopic technique that depends on physical tissue slices. Presently, histology’s use in systems biology is limited by its largely descriptive and two-dimensional nature. Making histology quantitative and three-dimensional would be potentially transformational for research and diagnostics, but has been impractical. Accordingly, we have now created a 3D form of histology by customizing X-ray microtomography (micro-CT) of fixed and stained, millimeter-scale, whole organisms and tissue samples. We used fixed and metal-stained, whole zebrafish because they contain a full range of tissues within the size range currently studied histologically. The result is the first practical way to create virtual histology-like “sections” in any plane. Three-dimensional, complete histological phenotyping has potential use in genetic and chemical screens, and in clinical and toxicological tissue diagnostics. Here, we propose the next steps needed to enable high-throughput, quantitative, 3D histological phenotyping of whole, millimeter-scale animals. The proposed work applies the principles of chemistry, physics, and computer science to improve image resolution, throughput, and analytics, organized into three specific aims. Specific Aim 1 will build on our developments in this project and further improve imaging volume and resolution by upgrading imaging array, optics, and sub-pixel shifting, and to throughput by changes in sample embedding, loading geometry and mechanics, helical CT scanning, scintillator material, and to data sharing by improvements to the ViewTool infrastructure and user interface. Specific Aim 2 will yield reference images to define the range of normal phenotypic variation and to obtain samples related to a range of potential applications. Specific Aim 3 will apply the power of machine learning to segmentation, annotation, and analytics. Together, this work will establish a practical foundation for large-scale genetic and chemical screens involving mm-scale, whole organisms based on 3-dimensional, quantitative, histological phenotyping. The instrumentation and analytics will be state-of-the-art in its combination of resolution, field-of-view, pancellularity, image quality, analytical potential, throughput, sample stability, and reproducibility and largely usable with both tube and synchrotron X-ray sources. The voxel resolution will be at least 0.5 μm across fields-of-view of up to 1 cm. Representation of every cell type make the images suitable for cross-referencing across imaging modalities. Potential applications will be explored, “wild-type” will begin to be defined, and training sets for automated segmentation generated. The potential impact will encompass the missions of most NIH Institutes and Centers. The whole-animal genetic and chemical screens enabled are expected to impact drug development, diagnostics, and our basic understanding of how genes and environment define phenotype. Project Narrative Our group has established the only three-dimensional form of histology that is suitable for histopathology and quantitative tissue phenotyping, tissue X-ray microtomography (micro-CT). We outline here a plan to establish mechanisms for increasing resolution and field-of-view, to add sample multiplexing, to simply sample preparation, and to explore machine learning mechanisms for defining normal and abnormal structure towards whole-organism complete tissue phenotyping. The resulting tools will allow the community to comprehensively and computationally determine the roles of genes and environment in defining phenotype, which has implications in drug development, biomedical research, and medicine.",Groundwork for a Synchrotron MicroCT Imaging Resource for Biology (SMIRB),9991958,R24OD018559,"['3-Dimensional', 'Adolescent', 'Age', 'Animal Genetics', 'Animals', 'Biological', 'Biological Models', 'Biology', 'Biomedical Research', 'Body measure procedure', 'Caenorhabditis elegans', 'Cells', 'Cellular Structures', 'Cesium', 'Chemicals', 'Chemistry', 'Communities', 'Custom', 'Data', 'Development', 'Diagnostic', 'Drosophila genus', 'Embryo', 'Environment', 'Fishes', 'Foundations', 'Genes', 'Genetic', 'Geometry', 'Goals', 'Histologic', 'Histology', 'Histopathology', 'Image', 'Infrastructure', 'Institutes', 'Iodides', 'Machine Learning', 'Measures', 'Mechanics', 'Medicine', 'Metals', 'Microscopic', 'Mission', 'Morphology', 'Mus', 'Mutation', 'Nature', 'Nerve', 'Normal Range', 'Online Systems', 'Optics', 'Organ', 'Output', 'Pharmaceutical Preparations', 'Phenotype', 'Physics', 'Preparation', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Robotics', 'Roentgen Rays', 'Role', 'Sampling', 'Scanning', 'Series', 'Siblings', 'Signal Transduction', 'Slice', 'Source', 'Spiral Computed Tomography', 'Stains', 'Structural defect', 'Structure', 'Synchrotrons', 'Systems Biology', 'Techniques', 'Testing', 'Texture', 'Time', 'Tissue Sample', 'Tissue imaging', 'Tissues', 'Training', 'Travel', 'Tube', 'United States National Institutes of Health', 'Variant', 'Whole Organism', 'Work', 'Writing', 'X-Ray Computed Tomography', 'Zebrafish', 'automated segmentation', 'base', 'bone', 'cell type', 'clinical toxicology', 'computer science', 'computerized tools', 'crowdsourcing', 'data dissemination', 'data sharing', 'detector', 'disease phenotype', 'drug development', 'feature detection', 'histological studies', 'human disease', 'imaging modality', 'improved', 'instrumentation', 'microCT', 'millimeter', 'mutant', 'programs', 'supervised learning', 'tool', 'two-dimensional', 'unsupervised learning', 'virtual']",OD,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,R24,2020,655482,0.004267741239769954
"A robust platform for multiplexed, subcellular proteomic imaging in human tissue Project Summary Multiplexed Ion Beam Imaging by Time of Flight (MIBI-TOF) uses secondary ion mass spectrometry and metal conjugated primary antibodies to simultaneously visualize dozens of proteins at subcellular resolution in a single tissue section. This technology is back compatible with archival formalin fixed, paraffin embedded tissue (FFPE) and has been used in peer-reviewed work to simultaneously visualize and quantify 36 proteins in retrospective human tissue cohorts. In line with the stated goals of the HuBMAP consortium to develop both “High-sensitivity, high-resolution imaging techniques that can rapidly provide spectral data over large areas of tissue” and “Quantitative imaging analysis tools, including automated 3D image segmentation, feature extraction, and image annotation,” the work outlined here will create a standardized, high throughput, and user-friendly workflow for using MIBI-TOF in basic and translational research to gain insight into how single cell phenotype and tissue structure are functionally-linked in health and disease. To achieve this, we will validate 100 FFPE antibodies and optimize ready-to-use multiplexed staining panels in lyophilized format that will permit storage for at least two years. Protocols and reagents for multiplexed signal amplification of protein and mRNA targets will be further refined, while next generation instrumentation will increase sample throughput to permit full tissue section imaging of up to 40 proteins in 1 hour. Standardized reagents and more robust instrumentation will be accompanied by an automated computational pipeline that utilizes a standard set of segmentation markers and machine learning to accurately identify nuclei and cell borders in any non-neural human tissue. This data will be used to cluster single cell events into functionally distinct populations according to morphology, protein expression, and histological distribution. The reagents and computational pipeline proposed here synergize with existing HuBMAP-funded platforms and could be readily generalized to virtually any high dimensional imaging modality. Thus, this work will not only provide a practical, back compatible imaging platform for high throughput multiplexed imaging, but will also accelerate development of other complimentary imaging technologies as well. Project Narrative Multiplexed ion beam imaging by time of flight (MIBI-TOF) is a new technology for visualizing dozens of proteins in standard clinical tissue biopsies at high resolution. The work outlined here will create a standardized, high throughput, and user-friendly workflow for using MIBI-TOF in basic and translational research to gain insight into how single cell phenotype and tissue structure are functionally-linked in health and disease.","A robust platform for multiplexed, subcellular proteomic imaging in human tissue",10231018,UH3CA246633,"['Allergic', 'Antibodies', 'Archives', 'Area', 'Back', 'Basic Science', 'Biopsy', 'Cell Nucleus', 'Cells', 'Clinical', 'Cloud Computing', 'Communities', 'Data', 'Data Set', 'Decidua', 'Development', 'Disease', 'Equipment', 'Event', 'Extramural Activities', 'Feedback', 'First Pregnancy Trimester', 'Formalin', 'Foundations', 'Freeze Drying', 'Funding', 'Goals', 'Granuloma', 'Health', 'Hippocampus (Brain)', 'Histologic', 'Hour', 'Human', 'Human BioMolecular Atlas Program', 'Image', 'Imaging Techniques', 'Imaging technology', 'Immune', 'Immunosuppression', 'Individual', 'Institutes', 'Ions', 'Letters', 'Link', 'Machine Learning', 'Medical center', 'Messenger RNA', 'Metals', 'Morphology', 'Multiplexed Ion Beam Imaging', 'Noninfiltrating Intraductal Carcinoma', 'Optics', 'Organ', 'Paraffin Embedding', 'Pathology', 'Peer Review', 'Phenotype', 'Population', 'Proteins', 'Proteomics', 'Protocols documentation', 'Pulmonary Tuberculosis', 'Readiness', 'Reagent', 'Reproducibility', 'Resolution', 'Resources', 'Sampling', 'Scanning', 'Signal Transduction', 'Site', 'Spectrometry, Mass, Secondary Ion', 'Stains', 'Standardization', 'Structure', 'Technology', 'Three-Dimensional Image', 'Time', 'Tissue Embedding', 'Tissues', 'Translational Research', 'United States National Institutes of Health', 'Work', 'cancer immunotherapy', 'cohort', 'computational pipelines', 'computational platform', 'computerized tools', 'design', 'feature extraction', 'graphical user interface', 'high dimensionality', 'high resolution imaging', 'human imaging', 'human tissue', 'imaging Segmentation', 'imaging modality', 'imaging platform', 'insight', 'instrumentation', 'ion source', 'machine learning method', 'multiplexed imaging', 'new technology', 'next generation', 'protein expression', 'quantitative imaging', 'reagent standardization', 'technology validation', 'tool', 'tumor microenvironment', 'user-friendly', 'virtual']",NCI,STANFORD UNIVERSITY,UH3,2020,700000,-0.008347531142005512
"Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients ABSTRACT The prevalence of obesity in the United States has risen to record levels over the past 40 years, putting strain on the healthcare system and creating difficult challenges for medical imaging. We propose to overcome the challenges that obesity poses to ultrasound imaging by (1) developing novel image-quality improvement techniques, and (2) implementing them on pulse-echo ultrasound imaging systems to yield high-quality images of the liver. Ultrasound imaging is uniquely affected by the presence of additional connective tissue and thick subcutaneous fat layers in overweight and obese patients; these additional subcutaneous layers greatly exacerbate reverberation and phase-aberration of the acoustic wave, leading to high levels of clutter, degraded resolution, and overall poor-quality ultrasound images. Our proposed methods will determine the local speed-of-sound in abdominal tissue layers and use this information to accomplish distributed phase-aberration correction. We also apply machine learning techniques to model and suppress the effects of reverberation clutter and speckle noise. The combination of these techniques is expected to achieve significant improvements in liver image quality. These image-quality improvement methods will be implemented on a real-time ultrasound scanner and will be evaluated in clinical imaging tasks of overweight and obese patients undergoing ultrasound surveillance of hepatocellular carcinoma. Successful development of the proposed technology will not only enable high-quality ultrasound imaging of the liver in otherwise difficult-to-image overweight and obese patients, but also facilitate improved image quality across nearly all ultrasound imaging applications, for all populations. NARRATIVE This proposal aims to develop and test several new techniques to overcome the current limitations of ultrasound to make high-quality images in overweight and obese individuals. These novel ultrasound techniques will be initially applied to improve liver imaging in overweight and obese patients in a pilot study, though the benefits of this new high-quality imaging technology will extend to all other areas of clinical ultrasound imaging.",Improving Liver Ultrasound Image Quality in Difficult-to-Image Patients,9885175,R01EB027100,"['Abdomen', 'Acoustics', 'Affect', 'American', 'Architecture', 'Area', 'Attenuated', 'Body mass index', 'Cardiac', 'Cirrhosis', 'Clinical', 'Computer software', 'Connective Tissue', 'Data', 'Development', 'Diffuse', 'Disease', 'Fatty acid glycerol esters', 'Goals', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Image', 'Imaging technology', 'Individual', 'Lesion', 'Liver', 'Liver diseases', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Noise', 'Obesity', 'Output', 'Overweight', 'Patient imaging', 'Patients', 'Performance', 'Phase', 'Physiologic pulse', 'Pilot Projects', 'Population', 'Prevalence', 'Primary carcinoma of the liver cells', 'Resolution', 'Risk Factors', 'Signal Transduction', 'Source', 'Speed', 'Subcutaneous Tissue', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Thick', 'Thyroid Gland', 'Time', 'Tissues', 'Ultrasonography', 'United States', 'Weight', 'clinical imaging', 'elastography', 'epidemiology study', 'fetal', 'imaging system', 'improved', 'in vivo', 'liver imaging', 'neural network', 'novel', 'patient population', 'prototype', 'radio frequency', 'simulation', 'sound', 'subcutaneous']",NIBIB,STANFORD UNIVERSITY,R01,2020,590183,0.030348471743764305
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,10026443,UH3CA255132,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Human BioMolecular Atlas Program', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'automated analysis', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'preservation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NCI,PURDUE UNIVERSITY,UH3,2020,630000,0.006973012843499094
"Opera Phenix High-Content Imaging System for Drug Discovery PROJECT SUMMARY The University of Pittsburgh Drug Discovery Institute (UPDDI) is requesting funds to purchase the Perkin Elmer OPERA PHENIX high speed, high resolution spinning disk confocal High-Content Screening (HCS) device. The Opera Phenix will replace two Molecular Devices ImageXpress Ultra high content readers purchased in 2008, which are critical to multiple NIH-, DoD-, and Foundation-funded projects at the University of Pittsburgh, but are no longer supported by the manufacturer and have been decommissioned. We have determined that one Opera Phenix instrument can replace the two IXUs. The Phenix is a third generation HCS instrument that will be essential to satisfy the diverse needs of users that the UPDDI serves. No comparable instruments exist at the University of Pittsburgh, the University of Pittsburgh Medical Center, and Carnegie Mellon University. Over the last decade, HCS has become a standard in the pharmaceutical industry for target identification, phenotypic screening, as well as toxicology, and in academia for large-scale biological studies, where cell-by- cell quantitation is critical. The UPDDI has been an academic pioneer in the application of HCS and serves an extensive number of collaborators across campus that require and rely on HCS, ranging from neurodegeneration, organ regeneration, cancer, liver diseases, organotypic model development, and traumatic brain injury. Our diverse user groups’ needs emphasize discovery models of physiological relevance and high complexity, and therefore require fast, high resolution 2D, 3D, and kinetic imaging and maximum flexibility in image analysis. The large number of HCS users working in the UPDDI further demands a fast system to permit effective sharing of instrument time, and an integrated database with off-site user access to perform off- line analysis. Key requirements for an HCS imager therefore are superior speed in acquiring z-series of images at high resolution of thick specimens in aqueous matrices, mature yet flexible image algorithms, and seamless integration of instrument software with system, public,and custom-developed UPDDI databases. The only instrument that meets all of these criteria is the Opera Phenix because it has 1) fast laser-based illumination and the ability to acquire multiple channels simultaneously 2) water immersion objectives that eliminate non-matching refractive indices, which limit spherical aberrations of air and oil objectives at longer working distances and require adjustment of correction collars depending on imaging depth; 3) a powerful suite of user-friendly yet flexible image analysis routines including a 3D module, advanced texture and morphology analysis, and intuitive and user-friendly machine learning; and 4) the ability to perform seamless “adaptive high-resolution imaging”, i.e., pre-scanning a large area at low magnification, followed by automated “on-the- fly” switching to higher magnification to acquire high resolution images of user-defined regions of interest. The Opera Phenix is the only instrument on the market that is capable of fulfilling the demands of the University of Pittsburgh’s diverse drug discovery community. PROJECT NARRATIVE Modern drug discovery increasingly demands better and more disease relevant models and the ability to analyze them. High-content screening (HCS) has become indispensable in the analysis of such models as it permits the analysis of cells, their constituents, and interactions in their proper biological context. The third generation HCS instrument, Opera Phenix, produces the quality and quantity of data from cells, tissues and experimental animals that are required for computational and systems biological investigations, while at the same time providing the throughput needed for automated screening.",Opera Phenix High-Content Imaging System for Drug Discovery,9935240,S10OD028450,"['3-Dimensional', 'Academia', 'Air', 'Algorithms', 'Area', 'Biological', 'Cells', 'Communities', 'Computer software', 'Custom', 'Databases', 'Devices', 'Drug Industry', 'Foundations', 'Funding', 'Generations', 'Image', 'Image Analysis', 'Immersion', 'Institutes', 'Intuition', 'Kinetics', 'Lasers', 'Lighting', 'Liver diseases', 'Machine Learning', 'Malignant Neoplasms', 'Manufacturer Name', 'Medical center', 'Molecular', 'Morphology', 'Nerve Degeneration', 'Oils', 'Phenotype', 'Reader', 'Refractive Indices', 'Resolution', 'Scanning', 'Series', 'Site', 'Specimen', 'Speed', 'System', 'Texture', 'Thick', 'Time', 'Toxicology', 'Traumatic Brain Injury', 'United States National Institutes of Health', 'Universities', 'Water', 'aqueous', 'base', 'drug discovery', 'flexibility', 'high resolution imaging', 'imager', 'imaging system', 'instrument', 'interest', 'model development', 'organ regeneration', 'physiologic model', 'screening', 'user-friendly']",OD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,S10,2020,1010594,0.01574999171920272
"Imaging Mass Spectrometry for metabolome mapping SUMMARY In response to NOT-GM-20-013, we are requesting a supplement to our R01 5R01GM120033-04 for an MALDI imaging source unit to be attached to an existing Q ExactiveMass Spectrometer (Ultra-High Mass Range Hybrid Quadrupole-Orbitrap™) for spatial mapping of metabolites in thin tissue sections. Within our R01 award, to analyze NMR metabolome data we are developing two novel, powerful, and automated algorithms that capitalize on recent developments in machine learning. We have coded these algorithms and tested their sensitivity and specificity on both synthesized and real data. We then applied these methods to human disease models and identified putative biomarkers. To validate these biomarkers, we have developed methods to analyze animal tissues and human brain organoids using imaging mass spectrometry (IMS), which permits spatial localization of metabolites without labeling. This targeted IMS metabolic phenotyping approach complements our untargeted NMR methods: it allows us to determine whether the individual metabolites identified by NMR represent bona fide biomarkers and to develop metabolic hypotheses for their association with disease. We submit this request for imaging mass spectrometer hardware because a nearby IMS facility on which we have relied has closed and no other IMS facility exists in greater Houston area. Performing the IMS studies ourselves, with the help of collaborators, will accelerate our discovery about the role small molecules and metabolites play in health and disease. This instrument will help us better i) perform metabolome screens to identify the effects of SARS-CoV-2 on neural cell types in human brain organoid models; ii) perform high-throughput drug screening to stimulate neural stem cells to produce new neurons in the brain organoid models to regenerate damaged tissue; and iii) use our NMR algorithms to develop a protocol for quantitative imaging. None of these studies will be possible without the imaging mass spectrometer. Given our access to state-of-the-art equipment, data-collection expertise, and new analytical algorithms that are especially sensitive and specific to NMR spectral data, we are uniquely positioned to advance biomarker and diagnostics tools and screening methods for metabolites and synthetic small molecules. Using an imaging mass spectrometer to map metabolite distribution may help us discover diagnostic and prognostic biomarkers not only for SARS-CoV-2, but for a broad spectrum of brain disorders that lead to neurodegeneration. Such broad usage of our platform would be transformative for neuroscientists, neurologists, and their patients. NARRATIVE The metabolome is a dynamic and sensitive biological system that reflects both innate processes and environmental influences, and can therefore tell us much about an organism's health and homeostasis. In our R01, we are developing two novel, powerful, and automated algorithms to analyze NMR metabolome data. We are requesting an MALDI imaging source unit to attach to an existing Q ExactiveMass Spectrometer (Ultra- High Mass Range Hybrid Quadrupole-Orbitrap™) to validate our ongoing NMR studies and accelerate the translation of our biomarker discoveries to the clinical realm.",Imaging Mass Spectrometry for metabolome mapping,10175695,R01GM120033,"['2019-nCoV', 'Algorithms', 'Area', 'Award', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Code', 'Complement', 'Data', 'Data Collection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Equipment', 'Health', 'Homeostasis', 'Human', 'Hybrids', 'Image', 'Individual', 'Label', 'Lead', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Metabolic', 'Methods', 'Modeling', 'Nerve Degeneration', 'Neurologist', 'Neurons', 'Organism', 'Organoids', 'Patients', 'Play', 'Positioning Attribute', 'Process', 'Prognostic Marker', 'Protocols documentation', 'Role', 'Sensitivity and Specificity', 'Source', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Testing', 'Thinness', 'Tissues', 'Translations', 'animal tissue', 'automated algorithm', 'biological systems', 'biomarker discovery', 'cell type', 'diagnostic biomarker', 'high-throughput drug screening', 'human disease', 'instrument', 'mass spectrometer', 'metabolic phenotype', 'metabolome', 'nerve stem cell', 'novel', 'quantitative imaging', 'response', 'screening', 'small molecule', 'targeted imaging', 'tissue regeneration', 'tool']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,209619,-0.04069994101685752
"Center for Open Bioimage Analysis Project Summary  The Center for Open Bioimage Analysis will serve the cell biology community’s growing need for sophisticated software for light microscopy image analysis. Quantitative image analysis has become an indispensable tool for biologists using microscopy throughout basic biological and biomedical research.  Quantifying images is now a critical, widespread need as imaging experiments continue to grow in scale, size, dimensionality, scope, modality, and complexity. Many biologists are missing out on the quantitative bioimaging revolution due to lack of effective algorithms and/or usable software for their needs, or lack of access to training. The Center brings together the Carpenter laboratory at the Broad Institute and the Eliceiri laboratory at the University of Wisconsin­Madison, and in doing so brings together the two most popular open source bioimage analysis projects, ImageJ (including ImageJ2 and FIJI) and CellProfiler. Through the collaborative development and dissemination of open source image analysis software, as well as training events and resources, the Center will empower thousands of researchers to apply advanced analytics in innovative ways to address new experimental areas.  Building on the team’s expertise developing algorithms and user­friendly software for use in biology under real­world conditions, the Center will focus on two Technology Research and Development (TR&D) projects: deep learning­based image processing, and accessibility of image­processing algorithms for biologists. This work will not occur in isolation at the Center; rather, the Center will nucleate a larger community working on these two areas and serve as a catalyst and organizing force to create software and resources shared by all.  The Driving Biological Projects (DBPs) will serve a major role in driving the TR&D work: our teams are accustomed to working deeply and iteratively on problems side by side and with frequent feedback from biologists. This will ensure that important cell biological problems drive the work of the Center. The DBPs reflect tremendous variety in terms of biological questions, model systems, imaging modalities, and researcher expertise and will ensure robustness of our tools for the widest possible impact on the community. Continuing the teams’ track record with ImageJ and CellProfiler, two mature open source bioimage analysis software projects critical to the work of biologists worldwide, the Center will also assist and train biologists in applying the latest computational techniques to important biological problems involving images.  In short, the need for robust, accurate, and readily usable software is more urgent than ever. The Center for Open Bioimage Analysis will serve as a hub for pioneering new computational strategies for diverse biological problems, translating them into user­friendly software, further developing ImageJ and CellProfiler, and training the biological community to apply advanced software to important and diverse problems in cell biology. Project Narrative Biologists studying a huge variety of diseases and basic biological processes need software to measure cells, tissues, and organisms in microscopy images. We will create the Center for Open Bioimage Analysis which will catalyze the scientific community, creating resources, free software, and training that allow biologists to analyze images using deep learning and other new image processing algorithms, offering improved accuracy, convenience, and reproducibility.",Center for Open Bioimage Analysis,9855767,P41GM135019,"['Address', 'Algorithmic Software', 'Algorithms', 'Area', 'Automobile Driving', 'Benchmarking', 'Biological', 'Biological Models', 'Biological Process', 'Biology', 'Biomedical Research', 'Cells', 'Cellular Structures', 'Cellular biology', 'Characteristics', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computers', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Ensure', 'Event', 'Feedback', 'Hand', 'Image', 'Image Analysis', 'Infrastructure', 'Institutes', 'International', 'Laboratories', 'Measures', 'Microscopy', 'Mission', 'Modality', 'Modeling', 'Modernization', 'Organism', 'Organoids', 'Reproducibility', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Role', 'Savings', 'Scientist', 'Side', 'Software Engineering', 'System', 'Technology', 'Time', 'Tissues', 'Training', 'Translating', 'Universities', 'Wisconsin', 'Work', 'advanced analytics', 'algorithmic methodologies', 'base', 'bioimaging', 'biological research', 'biological systems', 'catalyst', 'deep learning', 'experimental study', 'hackathon', 'image processing', 'imaging modality', 'improved', 'innovation', 'light microscopy', 'microscopic imaging', 'next generation', 'novel', 'open source', 'quantitative imaging', 'research and development', 'skills', 'symposium', 'technology research and development', 'tool', 'user friendly software', 'user-friendly']",NIGMS,"BROAD INSTITUTE, INC.",P41,2020,1835520,0.04006450636845643
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10052188,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'combat', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2020,347094,0.008367030072458282
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",10023935,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'automated segmentation', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2020,256578,0.01914485285717326
"In vivo Macroscopic Fluorescence Lifetime Molecular Optical Imaging In vivo Macroscopic Fluorescence Lifetime Molecular Optical Imaging ABSTRACT There is still great need in better characterizing new targeted therapies in vivo, especially prior to clinical translation. In this regard, preclinical molecular imaging is a central tool in the targeted drug development pipeline. However, there is still a lack of integrated imaging platforms that can enable longitudinal (multiple time points) and spatially-resolved monitoring of complex fingerprints including molecular, metabolic and functional signatures in the same tumor/subject. This new integrated multiplexing imaging platform will play a crucial role in the development of the next generation of targeted drugs and elucidating (multi-) drug resistance mechanisms. Recently, we have demonstrated the unique capabilities of optical imaging in quantifying receptor-target engagement in live subjects by leveraging fluorescence lifetime. This outstanding achievement was realized thanks to the combination of instrumental, algorithmic and biochemical innovations to enable, for the first time, whole-body time-resolved optical imaging based on structured light for 2D or 3D Förster resonance energy transfer (FRET) imaging in live subjects. Herein, we will further impact the field of optical preclinical imaging and drug delivery assessment by 1) integrating a cutting-edge high-resolution, time-resolved SPAD array imager for improved photon collection efficiency, spatial resolution, and portability; 2) we will harness the latest developments in Deep Learning (DL) for ultra-fast, quantitative, but fitting/iterative inverse solver-free image formation, in both 2D and 3D providing image formation/processing solutions to facilitate multiplexed imaging; 3) we will implement new functionalities in our imaging platform to enable the concurrent longitudinal imaging of multiple clinically relevant target-receptor interactions (e.g. HER receptor family members involved in many cancers) as well as metabolic and functional status across the whole-tumor region in live intact animals. NARRATIVE Following an ever increased focus on personalized medicine, there is a continuing need to develop preclinical molecular imaging modalities to guide the development and optimization of targeted therapies. This research program will combine novel time-resolved cameras as well as deep learning techniques to broaden the impact of macroscopic lifetime imaging with the overarching goal to facilitate multiplexed imaging for a comprehensive assessment of cellular delivery efficacy of multiple clinically relevant drugs (e.g. HER receptor family members involved in many cancers) as well as drug response via metabolic and functional status across the whole-tumor region in live intact animals.",In vivo Macroscopic Fluorescence Lifetime Molecular Optical Imaging,9997447,R01CA250636,"['3-Dimensional', 'Achievement', 'Algorithms', 'Animals', 'Biochemical', 'Biological', 'Biological Assay', 'Blood Vessels', 'Cancer Biology', 'Cells', 'Collection', 'Complex', 'Data', 'Detection', 'Development', 'Drug Delivery Systems', 'Drug Targeting', 'ERBB2 gene', 'Electronics', 'Epidermal Growth Factor Receptor', 'Family member', 'Fingerprint', 'Fluorescence', 'Fluorescence Microscopy', 'Fluorescence Resonance Energy Transfer', 'Foundations', 'Functional Imaging', 'Goals', 'Hemoglobin', 'Human', 'Image', 'Image-Guided Surgery', 'Imaging ligands', 'Immunohistochemistry', 'Light', 'Longitudinal Studies', 'Malignant Neoplasms', 'Mammary Neoplasms', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Molecular', 'Molecular Probes', 'Molecular Target', 'Monitor', 'Multi-Drug Resistance', 'Optical Tomography', 'Optics', 'Oxygen', 'Penetration', 'Performance', 'Pharmaceutical Preparations', 'Photons', 'Physiological', 'Play', 'Reporter Genes', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Side', 'Signal Transduction', 'Structure', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'base', 'bioimaging', 'clinical translation', 'clinically relevant', 'cost effective', 'deep learning', 'design', 'detector', 'drug development', 'drug efficacy', 'fluorescence lifetime imaging', 'functional status', 'imager', 'imaging agent', 'imaging modality', 'imaging platform', 'imaging study', 'improved', 'in vivo', 'innovation', 'metabolic imaging', 'molecular imaging', 'multiplexed imaging', 'new technology', 'new therapeutic target', 'next generation', 'novel', 'optical imaging', 'personalized medicine', 'portability', 'pre-clinical', 'preclinical imaging', 'preclinical study', 'programs', 'quantitative imaging', 'receptor', 'resistance mechanism', 'response', 'serial imaging', 'targeted treatment', 'technological innovation', 'tomography', 'tool', 'treatment response', 'tumor', 'tumor xenograft', 'user-friendly']",NCI,RENSSELAER POLYTECHNIC INSTITUTE,R01,2020,637634,-0.02435311705268392
"ShapeWorks in the Cloud Project Summary This application is submitted in response to NOT-OD-20-073 as an administrative supplement to the parent award R01AR076120 titled: ""Anatomy Directly from Imagery: General-purpose, Scalable, and Open-source Machine Learning Approaches."" The form (or shape) of anatomies is the clinical language that describes abnormal mor- phologies tied to pathologic functions. Quantifying such subtle morphological shape changes requires parsing the anatomy into a quantitative description that is consistent across the population in question. For more than 100 years, morphometrics has been an indispensable quantitative tool in medical and biological sciences to study anatomical forms. But its representation capacity is limited to linear distances, angles, and areas. Sta- tistical shape modeling (SSM) is the computational extension of classical morphometric techniques to analyze more detailed representations of complex anatomy and their variability within populations The parent award ad- dresses existing roadblocks for the widespread adoption of SSM computational tools in the context of a ﬂexible and general SSM approach termed particle-based shape modeling (PSM) and its associated suite of open-source software tools, ShapeWorks. ShapeWorks enables learning population-level shape representation via automatic dense placement of homologous landmarks on image segmentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread applicability and impact to medicine and biology are hindered by computational barriers that most existing shape modeling packages face. The goal of this supplement award is to provide supplemental support for Aim 3 of the parent award to leverage best practices in software development and advances in cloud computing to enable researchers with limited computational resources and/or large-scale cohorts to build and execute custom SSM workﬂows us- ing remote scalable computational resources. To achieve this goal, we have developed a plan to enhance the design, implementation, and cloud-readiness of ShapeWorks and augmented our scientiﬁc team to add senior, experienced software engineers/developers who have extensive experience in professional programming, code refactoring, and scientiﬁc computing. This award will provide our team with the support necessary to (Aim 1) de- sign ShapeWorks as a collection of modular and reusable services, (Aim 2) decouple ShapeWorks services from explicitly encoded data sources, and (Aim 3) refactor ShapeWorks to scale efﬁciently on the cloud. All software development will be performed in adherence to software engineering practices and design principles, including coding style, documentation, and version control. The proposed efforts will be released as open-source software in a manner consistent with the principles of reproducible research and the practices of open science. Our long- term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein in addition to the parent award will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. The impact and scientiﬁc value of ShapeWorks have been recognized in a range of applications, including psychology, biological phenotyping, car- diology, and orthopedics. If funded, this supplement will provide support to revise, refactor, and redeploy Shape- Works to take advantage of new cloud computing paradigms, to be robust, sustainable, scalable, and accessible to a broader community, and to address the growing need for shape modeling tools to handle large collections of clinical data and to obtain sufﬁcient statistical power for large shape studies.",ShapeWorks in the Cloud,10166337,R01AR076120,"['Address', 'Adherence', 'Administrative Supplement', 'Adoption', 'Anatomy', 'Applied Research', 'Architecture', 'Area', 'Award', 'Biological', 'Biological Sciences', 'Biology', 'Cardiology', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cloud Computing', 'Cloud Service', 'Code', 'Collection', 'Communication', 'Communities', 'Complex', 'Complex Analysis', 'Computer Models', 'Computer software', 'Computers', 'Coupled', 'Custom', 'Data', 'Data Sources', 'Databases', 'Disabled Persons', 'Documentation', 'Environment', 'Face', 'Funding', 'Goals', 'Image', 'Imagery', 'Language', 'Learning', 'Machine Learning', 'Mathematics', 'Medical', 'Medicine', 'Methods', 'Modeling', 'Morphology', 'Occupations', 'Online Systems', 'Orthopedics', 'Parents', 'Pathologic', 'Phenotype', 'Population', 'Privatization', 'Psychology', 'Readiness', 'Reproducibility', 'Research', 'Research Personnel', 'Running', 'Scientist', 'Services', 'Shapes', 'Software Design', 'Software Engineering', 'Software Tools', 'Source Code', 'Speed', 'Standardization', 'System', 'Techniques', 'Technology', 'Testing', 'Work', 'base', 'cohort', 'computational platform', 'computerized tools', 'computing resources', 'data management', 'design', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'large datasets', 'model development', 'open data', 'open source', 'particle', 'response', 'scientific computing', 'shape analysis', 'software development', 'statistics', 'tool', 'user-friendly']",NIAMS,UNIVERSITY OF UTAH,R01,2020,210000,0.018935698864645266
"Computational and Statistical Framework to Model Tissue Shape and Mechanics PROJECT SUMMARY  The morphologic and mechanical characteristics of a tissue are fundamental to understanding the development, homeostasis, and pathology of the human body. During the previous period of funding, we developed statistical shape modeling (SSM) methods and applied these to the study of structural hip disease. We also developed the initial framework to integrate SSM with finite element (FE) analysis to enable the study of shape and mechanics together. If incorporated into clinical practice, SSM and FE analysis could identify features of the anatomy likely responsible for injury, remodeling, or repair. Geometry needed for SSM and FE models is typically generated by segmentation of volumetric imaging data. This step can be painstakingly slow, error prone, and cost prohibitive, which hampers clinical application of these computational techniques. We have created a deep machine learning algorithm ‘DeepSSM’ that uses a convolutional neural network to establish the correspondence model directly from unsegmented images. In Aim 1 we will apply DepSSM to improve clinical understanding of structural hip disease by characterizing differences in anatomy between symptomatic and asymptomatic individuals; these morphometric comparisons will identify anatomic features most telling of disease, thereby guiding improvements in diagnosis. Computational advancements have simplified the process to generate patient-specific FE models, enabling clinically focused research. However, there is no framework to collectively visualize, compare, and interpret (i.e., post-process) results from multiple FE models. Currently, inter-subject comparisons require oversimplifications such as averaging results over subjectively defined regions. In Aim 2 we will develop new post-processing methods to collectively visualize, interpret and statistically analyze FE results across multiple subjects and study groups. We will map FE results to synthetic anatomies representing statistically meaningful distributions using the correspondence model. Statistical parametric mapping will be applied to preserve anatomic detail through statistical testing. We will use our published FE models of hip joint mechanics as the test system. Finally, volumetric images provide a wealth of information that is delivered to physicians in a familiar format. Yet, tools are not available to interpret model data with clinical findings from volumetric images. In Aim 3, we will develop methods that evaluate relationships between shape, mechanics, and clinical findings gleaned from imaging through integrated statistical tests and semi-automatic medical image annotation tools that utilize standard ontologies. Quantitative CT and MRI images of the hip, which estimate bone density and cartilage ultrastructure, respectively, will be evaluated as test datasets. To impart broad impact, we will disseminate our methods to the community as open source software that will call core functionality provided by existing, open source software that has a large user base (FEBio, ShapeWorks). PROJECT NARRATIVE The proposed technology will provide the methodologies necessary to increase the clinical acceptance and applicability of computer models. These models measure three-dimensional tissue shape and estimate tissue mechanics, providing information that cannot be measured conventionally. We will implement these methods into software that can be used by the public free-of-charge.",Computational and Statistical Framework to Model Tissue Shape and Mechanics,9972694,R01EB016701,"['3-Dimensional', 'Adoption', 'Algorithms', 'Anatomy', 'Architecture', 'Bone Density', 'Cardiology', 'Cartilage', 'Characteristics', 'Charge', 'Clinical', 'Communities', 'Computational Technique', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Deformity', 'Development', 'Diagnosis', 'Disease', 'Elements', 'Finite Element Analysis', 'Foundations', 'Funding', 'Geometry', 'Glean', 'Grooming', 'Hip Joint', 'Hip region structure', 'Homeostasis', 'Human Pathology', 'Human body', 'Image', 'Individual', 'Injury', 'Intuition', 'Libraries', 'Magnetic Resonance Imaging', 'Maps', 'Measurement', 'Measures', 'Mechanics', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Morphology', 'Neurology', 'Ontology', 'Orthopedics', 'Pathology', 'Patient imaging', 'Patients', 'Performance', 'Physicians', 'Procedures', 'Process', 'Publishing', 'Quantitative Evaluations', 'Research', 'Resources', 'Scheme', 'Shapes', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Tissue Model', 'Tissues', 'Training', 'Validation', 'X-Ray Computed Tomography', 'annotation  system', 'base', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data modeling', 'disease diagnosis', 'improved', 'in vivo', 'machine learning algorithm', 'novel', 'open source', 'predictive modeling', 'preservation', 'relating to nervous system', 'repaired', 'shape analysis', 'simulation', 'three-dimensional modeling', 'tool']",NIBIB,UNIVERSITY OF UTAH,R01,2020,563658,0.0012895771590876435
"Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software. Abstract (Proposal title: Neuroscience Gateway to Enable Dissemination of Computational and Data Processing Tools and Software.): This proposal presents a focused plan for expanding the capabilities of the Neuroscience Gateway (NSG) to meet the evolving needs of neuroscientists engaged in computationally intensive research. The NSG project began in 2012 with support from the NSF. Its initial goal was to catalyze progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists faced in large scale modeling projects involving tools and software which require and run efficiently on high performance computing (HPC) resources. NSG's success is reflected in the facts that (1) its base of registered users has grown continually since it started operation in early 2013 (more than 800 at present), (2) every year the NSG team successfully acquires ever larger allocations of supercomputer time (recently more than 10,000,000 core hours/year) on academic HPC resources of the Extreme Science and Engineering Discovery (XSEDE – that coordinates NSF supercomputer centers) program by writing proposals that go through an extremely competitive peer review process, and (3) it has contributed to large number of publications and Ph.D thesis. In recent years experimentalists, cognitive neuroscientists and others have begun using NSG for brain image data processing, data analysis and machine learning. NSG now provides over 20 tools on HPC resources for modeling, simulation and data processing. While NSG is currently well used by the neuroscience community, there is increasing interest from that community in applying it to a wider range of tasks than originally conceived. For example, some are trying to use it as an environment for dissemination of lab-developed tools, even though NSG is not suitable for that use because of delays from the batch queue wait times of production HPC resources, and lack of features and resources for an interactive, graphical, and collaborative environment needed for tool development, benchmarking and testing. “Forced” use of NSG for development and dissemination makes NSG's operators a “person-in-the-middle” bottleneck in the process. Another issue is that newly developed data processing tools require high throughput computing (HTC) usage mode, as opposed to HPC, but currently NSG does not provide access to compute resources suitable for HTC. Additionally, data processing workflows require features such as the ability to transfer large size data, process shared data, and visualize output results, which are not currently available on NSG. The work we propose will enhance NSG by adding the features that it needs to be a suitable and efficient dissemination environment for lab-developed neuroscience tools to the broader neuroscience community. This will allow tool developers to disseminate their lab-developed tools on NSG taking advantage of the current functionalities that are being well served on NSG for the last six years such as a growing user base, an easy user interface, an open environment, the ability to access and run jobs on powerful compute resources, availability of free supercomputer time, a well-established training and outreach program, and a functioning user support system. All of these well-functioning features of NSG will make it an ideal environment for dissemination and use of lab-developed computational and data processing neuroscience tools. The Neuroscience Gateway (NSG) was first implemented to enable large scale computational modeling of brain cells and circuits used to study neural function in health and disease. This new project extends NSG's utility to support development, dissemination and use of new tools by the neuroscience community for analyzing enormous data sets produced by advanced experimental methods in neuroscience.",Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software.,10019388,U24EB029005,"['Behavioral', 'Benchmarking', 'Brain imaging', 'Cells', 'Cognitive', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Development', 'Disease', 'Education', 'Education and Outreach', 'Educational workshop', 'Electroencephalography', 'Engineering', 'Environment', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Hour', 'Human Resources', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurosciences Research', 'Occupations', 'Output', 'Peer Review', 'Persons', 'Process', 'Production', 'Psychologist', 'Publications', 'Reaction Time', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Software Tools', 'Students', 'Support System', 'System', 'Testing', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Wait Time', 'Work', 'Workload', 'Writing', 'base', 'bioimaging', 'brain cell', 'collaborative environment', 'computational neuroscience', 'computerized data processing', 'computing resources', 'data sharing', 'image processing', 'interest', 'models and simulation', 'open data', 'operation', 'outreach program', 'programs', 'response', 'success', 'supercomputer', 'tool', 'tool development', 'trend', 'webinar']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2020,381282,0.002315022993873414
"Development of a Fast Large Area Multiphoton Exoscope (FLAME) Summary. Our long-term goal is to develop a powerful tool based on multiphoton microscopy (MPM) for non- invasive human skin imaging in order to improve clinical diagnosis, guide effective treatment and advance clinical and cosmetic/pharmaceutical research by providing access to dynamic cellular and molecular processes during therapy. MPM is a nonlinear optical imaging technique that provides unique structural and molecular contrast based on endogenous signals such as second harmonic generation from collagen and two- photon excited fluorescence from NADH/FAD+, keratin, melanin and elastin fibers. This contrast allows MPM to provide multi-color, rich molecular information content images that can enhance diagnostic accuracy. MPM overcomes fundamental limitations of existing optical imaging technologies for sub-surface skin imaging and extends the area of applicability beyond skin lesions that can be diagnosed through morphological assessment alone. Validation of the clinical potential of this technology has been facilitated over the past 10 years by a device developed by Jenlab in Germany, currently the only clinical MPM system on the market. This device has technical limitations in terms of field-of-view (FOV), imaging speed, complexity and cost, which are major barriers to clinical adoption. The goal of this Phase I proposal is to develop and test the technical feasibility for in vivo human skin imaging of a MPM system that is highly optimized for rapid, label-free, macroscopic imaging of human skin with microscopic resolution. The Fast Large Area Multiphoton Exoscope (FLAME) imaging platform will incorporate the innovative optical engine of a benchtop prototype developed at BLI. InfraDerm will innovate on this design to transform it into a compact, portable device, suitable for human skin imaging in clinical setting. Key innovations include: 1) a compact engineering design based on integrating a compact fs fiber laser into the imaging head along with a customized folded optical design to reduce complexity and cost and enhance portability; 2) hardware and software strategies that include a customized patient interface and a combination of optical and mechanical scanning mechanisms with deep learning image restoration to allow millimeter-to-centimeter scale imaging within minutes while maintaining sub-micron resolution. This approach will expand the in vivo imaging area from mm to cm scale, which will be scanned within minutes with sub- cellular resolution. In Aim 1 we will develop the FLAME prototype that incorporates these features. In Aim 2 we will test its technical feasibility for in vivo human skin imaging by evaluating potential effects of motion artifacts. In Aim 3, we will demonstrate the FLAME system potential for non-invasive assessment of melanin content, an ability with potential impact in differential diagnosis and early assessment of treatment efficacy of pigmentary skin disorders, such as melasma. Phase II will refine the technological approach and will test the device feasibility in a first clinical application, differential diagnosis of patients with melasma, a long time dermatology challenge and a particular interest for pharma companies developing therapies for this skin condition. Narrative  InfraDerm LLC proposes to develop and test the technical feasibility for in vivo human skin imaging of a laser scanning microscope based on multiphoton microscopy (MPM) that addresses fundamental and technical limitations of existing optical imaging technologies for sub-surface skin imaging, extending the area of applicability beyond skin lesions that can be diagnosed through morphological assessment alone. The proposed Fast Large Area Multiphoton Exoscope (FLAME) prototype will be highly optimized for rapid, label- free, macroscopic imaging of human skin with microscopic resolution. An MPM clinical platform, uniquely equipped with this combination of features would embody an innovative and commercially viable product that will broadly impact clinical diagnosis and research in dermatology as well as in cosmetic and pharmaceutical research.",Development of a Fast Large Area Multiphoton Exoscope (FLAME),10153566,R43EB030931,"['3-Dimensional', 'Address', 'Adoption', 'Alopecia', 'Appearance', 'Area', 'Automobile Driving', 'Biopsy', 'Cell physiology', 'Chloasma', 'Clinic', 'Clinical', 'Clinical Research', 'Collagen', 'Color', 'Computer software', 'Cosmetics', 'Custom', 'Dermatology', 'Development', 'Devices', 'Diagnosis', 'Differential Diagnosis', 'Disclosure', 'Elastin', 'Elastin Fiber', 'Excision', 'Extracellular Matrix', 'Face', 'Fiber', 'Fluorescence', 'Generations', 'Germany', 'Goals', 'Head', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Imaging technology', 'Individual', 'Institutes', 'Keratin', 'Label', 'Laboratories', 'Lasers', 'Legal patent', 'Lesion', 'Mechanics', 'Medical', 'Medical Device', 'Melanins', 'Microscope', 'Microscopic', 'Molecular', 'Morphologic artifacts', 'Morphology', 'Motion', 'NADH', 'Nevus', 'Operative Surgical Procedures', 'Optics', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pharmacologic Substance', 'Phase', 'Physiological', 'Pigments', 'Process', 'Publications', 'Research', 'Resolution', 'Scalp structure', 'Scanning', 'Signal Transduction', 'Skin', 'Speed', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Treatment Efficacy', 'Validation', 'base', 'cellular imaging', 'clinical Diagnosis', 'clinical application', 'cost', 'cost effective', 'deep learning', 'design', 'diagnostic accuracy', 'effective therapy', 'engineering design', 'human imaging', 'image guided', 'image guided therapy', 'imaging platform', 'improved', 'in vivo', 'in vivo imaging', 'innovation', 'insight', 'interest', 'millimeter', 'multiphoton imaging', 'multiphoton microscopy', 'optical imaging', 'portability', 'prototype', 'response', 'restoration', 'second harmonic', 'skin disorder', 'skin lesion', 'submicron', 'therapy development', 'tool', 'two-photon']",NIBIB,"INFRADERM, LLC",R43,2020,263074,-0.003975473837076721
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE MC-IU effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing, exploration, and download of different types of tissue and individual cell data. The CCF will use different visual interfaces in order to exploit human and machine intelligence to improve data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, biology, and biomedical data standards. The goal is to develop a highly accurate and extensible multidimensional spatial basemap of the human body with associated data overlays. This basemap will be designed for online exploration as an atlas of tissue maps composed of diverse cell types, developed in close collaboration with the HIVE MC-NYGC team. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across multiple levels (whole body, organ, tissue, cells). MC-IU will work in close collaboration with the HIVE Infrastructure and Engagement Component (IEC) and tools components (TCs) to connect and integrate further computational, analytical, visualization, and biometric resources driven by spatial context. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an extensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spatial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high-resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector and Meta Datasets",10148333,OT2OD026671,"['Anatomy', 'Artificial Intelligence', 'Atlases', 'Biology', 'Biometry', 'Cataloging', 'Catalogs', 'Cells', 'Collaborations', 'Communication', 'Data', 'Data Set', 'Ecosystem', 'Goals', 'Human', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Individual', 'Infrastructure', 'Maps', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Organ', 'Resolution', 'Resources', 'Tissues', 'Visual', 'Visualization', 'Work', 'base', 'cell type', 'data exploration', 'data standards', 'design', 'human imaging', 'improved', 'interoperability', 'tool', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2020,1000000,-0.01693254103072441
"Multi-Resolution Docking Methods for Electron Microscopy Summary In the past decade, we have witnessed a revolutionary progress in camera technology and the attainable resolution of macromolecular assemblies via cryogenic electron microscopy (cryo-EM) and in the development of computational algorithms that relate the resulting 3D maps to atomic resolution structures. Whereas single- particle cryo-EM today is capable of directly solving atomic structures of biomolecular assemblies in isolation, electron tomography (ET) in unstained frozen-hydrated samples is widely used to capture the 3D organization of supramolecular complexes in their native (organelle, cell, or tissue) environments. We have identified three inter-related research areas where our computational modeling experience (historically rooted in pre-revolution multi-scale approaches) offers the biggest value to today's post-revolution EM community: (1) medium resolution cryo-EM modeling, (2) the segmentation and denoising of cryo-ET data, and (3) the validation of atomic models and their corresponding maps. The first aim is an extension of promising new ideas in flexible fitting as well as secondary structure prediction for medium resolution maps, which have been our key research areas in the past. medium resolution (5-10Å) maps are still widely used in EM and can be of significant biological importance. This is particularly true in the case of cryo-ET maps, which are harder to read than single particle cryo-EM maps because they often exhibit considerable noise, anisotropic resolution, and anisotropic density variations due to the low dose requirements and the missing wedge in the Fourier space. In the case of tightly packed or crowded macromolecular structures, the fusion of nearby biomolecular densities prevents an automated segmentation of geometric shapes, requiring a labor-intensive manual tracing by human experts. We are currently developing novel computational approaches to provide a more objective strategy for missing wedge correction in homogeneous specimen areas of tomograms. Our hybrid approach combines deconvolution and denoising with template matching in a unified mathematical framework that allows modeling constraints to be imposed in a least-squares optimization process. Our approach can also be extended to the flexible refinement of atomic structures using our damped dynamics flexible fitting approach by tuning the internal point-spread functions to the missing wedge of the ET data. To support these aims, we will quantitatively measure the fitness of an atomic model in local density regions and characterize the fitness of maps with reliable reference structures. The collaborative efforts supported by this grant will include the refinement of cytoskeletal filaments, molecular motors, bacterial chemoreceptor arrays, and hair cell stereocilia. The algorithmic and methodological developments will be distributed freely through the established Internet-based mechanisms used by the Situs and Sculptor packages and as plugins for the popular UCSF Chimera graphics program. Project Narrative This project will help biological electron microscopists bridge a broad range of resolution levels, from the atomic to the living organism. Macromolecular assemblies are the basic functional units of biological cells; they furnish targets for drug design because deficiencies in macromolecular assembly architecture are frequently linked to health problems. The results of our fundamental research will be new computer codes for modeling macromolecular assemblies, the structures of which facilitate the prediction of medically relevant functions.",Multi-Resolution Docking Methods for Electron Microscopy,10120245,R01GM062968,"['3-Dimensional', 'Algorithms', 'Architecture', 'Area', 'Biological', 'Cells', 'Characteristics', 'Chemoreceptors', 'Chimera organism', 'Collaborations', 'Communities', 'Complement', 'Complex', 'Computational algorithm', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Crowding', 'Cryo-electron tomography', 'Cryoelectron Microscopy', 'Cytoskeletal Filaments', 'Data', 'Databases', 'Deposition', 'Detection', 'Development', 'Docking', 'Dose', 'Drug Design', 'Drug Targeting', 'Educational workshop', 'Electron Microscopy', 'Electrons', 'Elements', 'Environment', 'Equilibrium', 'Exhibits', 'Feedback', 'Filament', 'Freezing', 'Funding', 'Goals', 'Grant', 'Hair Cells', 'Health', 'Human', 'Hybrids', 'Hydration status', 'Internet', 'Laboratories', 'Least-Squares Analysis', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Mathematics', 'Measures', 'Medical', 'Methods', 'Microscope', 'Modeling', 'Modernization', 'Molecular Motors', 'Molecular Structure', 'Morphologic artifacts', 'Nature', 'Noise', 'Organelles', 'Organism', 'Pattern', 'Plant Roots', 'Research', 'Resolution', 'Sampling', 'Shapes', 'Specimen', 'Structure', 'Techniques', 'Technology', 'Tissues', 'Tomogram', 'Training', 'Validation', 'Variant', 'Visualization software', 'Work', 'algorithmic methodologies', 'automated segmentation', 'base', 'beta pleated sheet', 'computer code', 'cryogenics', 'data warehouse', 'deep learning', 'denoising', 'density', 'electron tomography', 'experience', 'feature detection', 'fitness', 'flexibility', 'fundamental research', 'heuristics', 'high standard', 'image reconstruction', 'improved', 'interest', 'learning network', 'macromolecular assembly', 'novel', 'particle', 'prevent', 'process optimization', 'programs', 'reconstruction', 'structured data', 'theories', 'tool']",NIGMS,OLD DOMINION UNIVERSITY,R01,2020,313572,-0.013893151384056932
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and affect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable of discovering local and global alteration of matter without the need to apriori select an anatomical region of interest. The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image datasets is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focuses on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10139715,R42MH118845,"['Affect', 'Algorithmic Software', 'Algorithms', 'Anatomy', 'Blood flow', 'Brain', 'Clinical', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Data Set', 'Databases', 'Detection', 'Deterioration', 'Diffuse', 'Disease', 'Drug Screening', 'Goals', 'Grain', 'HIV', 'Image', 'Image Analysis', 'Internet', 'Joints', 'Label', 'Lead', 'Machine Learning', 'Measures', 'Medical Imaging', 'Metabolic', 'Methodology', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Nerve Degeneration', 'Neurodegenerative Disorders', 'Neurologic', 'Neurologic Effect', 'Neurosurgeon', 'Online Systems', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Analysis', 'Population Study', 'Positioning Attribute', 'Process', 'Questionnaires', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Software Validation', 'Source', 'Statistical Data Interpretation', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Variant', 'Visualization', 'Washington', 'analysis pipeline', 'base', 'data access', 'data infrastructure', 'deep learning', 'experience', 'gray matter', 'high throughput screening', 'image registration', 'imaging capabilities', 'improved', 'insight', 'interest', 'metabolic rate', 'morphometry', 'nervous system disorder', 'neurodegenerative dementia', 'novel', 'programs', 'prototype', 'regional difference', 'research and development', 'shape analysis', 'software development', 'software infrastructure', 'task analysis', 'tool', 'usability', 'web app', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R42,2020,456359,0.0037937599386936908
"Multimodal mass spectrometry imaging of mouse and human liver We propose to develop a multimodal mass spectrometry imaging pipeline with novel desorption sources and data integration that will enable simultaneously mapping of biomolecule abundance in 3-dimensions in biological tissues at high spatial resolution (micron to submicron) and high speed (>10 ms/pixel) in a near-native environment. This would provide previously inaccessible information on cellular and tissue organization, and how homeostasis and disease intersect at the level of tissue physiology. A major challenge for performing multi- omics using mass spectrometry imaging has been the (i) lack of universal ionization methods, (ii) limited sample preparation protocols for preserving chemical gradients, (iii) low sensitivity, and (iv) limited tools for integration of large quantities of data. Our laboratories are developing systematic MS imaging for high sensitivity and high resolution analysis of diverse tissues. We discovered that water-based gas cluster ion beams (H2O-GCIB) operating at high energy yield ionization enhancements of multiple biomolecules (e.g., metabolites, lipids, and peptides/protein fragments) with high sensitivity at 1 µm lateral resolution and without labeling or complicated sample preparation. Coupled with unique Secondary Ion Mass Spectrometry (SIMS) instrumentation and cryogenic sample handling, we have imaged biomolecules directly in cells and tissues in a near-native state (i.e., frozen-hydration) with feature resolution of 1-10 µm. Low concentration biomolecules (e.g. cardiolipin and metabolites) that were impossible to localize in single cells previously are now visible with 3-dimensional localization. Moreover, the sufficient signal per pixel, we can use automated data analysis to characterize biologically active functional sites within 1 µm2 and areas of interest in single cells. We further developed data integration methods to combine imaging data from adjacent sections to create a multi-model imaging data sets. We propose to develop a pipeline for MS imaging analysis of biomolecules, and to elucidate molecular heterogeneity in tissues using multimodal imaging. To support the multi-modal analysis pipeline, we will develop an integrated data analysis platform. Integration of multiomics remains challenging, particularly spatially localize multiple biomolecules at single cell level. The direct visualization of cellular contents provides information on biomolecular composition, interactions and functions. This network of biomolecules is the driving force of specific behavior of cells in physiological states. Despite this, a comprehensive grasp of these interactions at cellular level has not moved beyond segregated methods. Our efforts will result in an integrated multimodal imaging platform to summon the best characteristics of each image form, acquiring a complete picture the biomolecular network at spatial resolution of 1 µm. With this direct visualization, we will address how metabolism links with functional biomarkers that stem from metabolism-associated protein complexes and phase-separated membrane-less organelles at the subcellular level, and how this drive different cell death modalities, including different modes of cell death. We propose to develop a new mass spectrometry imaging pipeline that will enable mapping of biomolecules in in biological tissues at high spatial resolution. This will provide previously inaccessible information on cellular and tissue organization, and how homeostasis and disease intersect at the level of tissue physiology.",Multimodal mass spectrometry imaging of mouse and human liver,10118811,UG3CA256962,"['3-Dimensional', 'Active Sites', 'Address', 'Age', 'Algorithms', 'Apoptosis', 'Area', 'Atlases', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Blood', 'Brain', 'Cardiolipins', 'Cell Death', 'Cells', 'Characteristics', 'Chemicals', 'Chemistry', 'Computer Vision Systems', 'Coupled', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Electrospray Ionization', 'Environment', 'Eosine Yellowish', 'Freezing', 'Gases', 'Genetic Transcription', 'Health', 'Heart', 'Heterogeneity', 'Homeostasis', 'Human', 'Hydration status', 'Image', 'Immunohistochemistry', 'Individual', 'Ions', 'Kidney', 'Knowledge', 'Label', 'Laboratories', 'Lateral', 'Link', 'Lipids', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Mass Spectrum Analysis', 'Membrane', 'Messenger RNA', 'Metabolic Marker', 'Metabolism', 'Methods', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Morphology', 'Multimodal Imaging', 'Mus', 'Optics', 'Organelles', 'Peptides', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physiological', 'Physiology', 'Preparation', 'Primary carcinoma of the liver cells', 'Protein Fragment', 'Protocols documentation', 'Resolution', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Spectrometry, Mass, Secondary Ion', 'Speed', 'Technology', 'Time', 'Tissue imaging', 'Tissues', 'Transcript', 'Visualization', 'Water', 'analysis pipeline', 'base', 'cell behavior', 'cell type', 'cryogenics', 'data analysis pipeline', 'data integration', 'data mining', 'data visualization', 'driving force', 'experimental study', 'grasp', 'high resolution imaging', 'human tissue', 'image reconstruction', 'imaging platform', 'improved', 'insight', 'instrumentation', 'interest', 'ionization', 'ionization technique', 'molecular imaging', 'multimodality', 'multiple omics', 'novel', 'preservation', 'protein complex', 'reconstruction', 'single-cell RNA sequencing', 'stem', 'submicron', 'tool', 'tumorigenesis']",NCI,COLUMBIA UNIV NEW YORK MORNINGSIDE,UG3,2020,300000,-0.040252660304415044
"Human Tumor Atlas Network: Data Coordinating Center Supplement This proposal is a collaboration with the HTAN Data Coordination Center DCC and describes an Image Data Project aimed at developing and deploying the technology needed for storage, distribution and basic analysis of cell and tissue images collected by multiple HTAN Centers. Multiplexed tissue images are an important type of data for nearly all of the centers contributing to the HTAN (second only to single cell sequencing data in number of centers collecting data). However, the software needed to visualize, analyze, manage, and share multiplexed images of tissues and tumors is underdeveloped. The initial availability of SARDANA images has highlighted the challenges faced by HTAN, including the DCC, in deploying an infrastructure for distributing large and complex images. We therefore propose a two-year HTAN Image Data Project (IDP) led by the DCC and HMS PCA focused on the rapid development and deployment of image informatic systems and computational resources for image management and analysis. Our goal is to put in place a functional first-generation system no later than summer 2020 and to then steadily refine the system so that it becomes the backbone of cross-functional HTAN atlases. As a matter of necessity, we will start with informatic systems and software that are either available today or in a relatively advanced state of development. However, we expect to evaluate these choices throughout the IDP and change course as necessary to incorporate potentially superior approaches. We will also support the diverse needs and formats of centers using different data collection methods. Aim 1 will focus on the deployment and progressive improvement of a cloud-based database for image management based on the OMERO standard as well as a parallel system for access to primary data. Aim 2 will develop and deploy software for visualizing HTAN image data by the general public. The IDP will use the existing MCWG and DAWG mechanisms for oversight and reporting, and all centers will be invited to participate. Within IDP, the HMS PCA will take primary responsibility for initial deployment of image informatics software. The DCC and HMS will jointly undertake software development and code hardening, and the DCC will take the lead in user assistance and software deployment, particularly in year two. Images of tumor specimens obtained from biopsy or surgery are one of the primary ways in which cancer is diagnosed and staged by pathologists, but such images have typically lacked molecular detail. The highly multiplexed tissue images being collected by HTAN will fundamentally change this, and it is therefore essential that the data be efficiently and widely distributed. The HTAN Image Data Project IDP will address an acute need for software for data dissemination and visualization.",Human Tumor Atlas Network: Data Coordinating Center Supplement,10206514,U24CA233243,"['Acute', 'Address', 'Atlases', 'Bioinformatics', 'Biopsy', 'Client', 'Code', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Coordinating Center', 'Databases', 'Development', 'Diagnosis', 'European', 'General Population', 'Generations', 'Goals', 'Human', 'Image', 'Imaging Device', 'Informatics', 'Infrastructure', 'Institutes', 'Lead', 'Malignant Neoplasms', 'Manuscripts', 'Methods', 'Modeling', 'Molecular', 'Operative Surgical Procedures', 'Output', 'Pathologist', 'Performance', 'Reporting', 'Side', 'Slide', 'Software Tools', 'Specimen', 'System', 'Technology', 'Testing', 'Tissue imaging', 'Tissues', 'Vertebral column', 'Visualization', 'base', 'cancer imaging', 'cellular imaging', 'cloud based', 'computing resources', 'data dissemination', 'data management', 'data resource', 'data visualization', 'imaging Segmentation', 'imaging informatics', 'improved', 'machine learning algorithm', 'multiplexed imaging', 'programs', 'relational database', 'single cell sequencing', 'software development', 'supervised learning', 'tumor']",NCI,DANA-FARBER CANCER INST,U24,2020,926364,0.025165635174849578
"Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets Project Summary  Morphometric analysis is a primary algorithmic tool to discover disease and drug related effects on brain anatomy. Neurological degeneration and disease manifest in subtle and varied changes in brain anatomy that can be non-local in nature and effect amounts of white and gray matter as well as relative positioning and shapes of local brain anatomy. State-of-the-art morphometry methods focus on local matter distribution or on shape variations of apriori selected anatomies but have difficulty in detecting global or regional deterioration of matter; an important effect in many neurodegenerative processes. The proposal team recently developed a morphometric analysis based on unbalanced optimal transport, called UTM, that promises to be capable to discover local and global alteration of matter without the need to apriori select an anatomical region of interest.  The goal of this proposal is to develop the UTM technology into a software tool for automated high-throughput screening of large neurological image data sets. A more sensitive automated morphometric analysis tool will help researchers to discover neurological effects related to disease and lead to more efficient screening for drug related effects. Project Narrative  Describing anatomical differences in neurological image data set is a key technology to non-invasively discover the effects of disease processes or drug treatments on brain anatomy. Current morphometric analysis focus on local matter composition and on the shape of a priori defined regions of interest. The goal of this proposal is to extend the capabilities of image based morphometric analysis to be able to discover regionally varying deterioration and alteration of matter without the need for fine-grained segmentations and a priori definitions of regions of interest.",Enhanced Software Tools for Detecting Anatomical Differences in Image Data Sets,10115288,R41MH118845,"['Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Calibration', 'Clinical', 'Clinical Research', 'Cluster Analysis', 'Computer software', 'Data Set', 'Databases', 'Dementia', 'Deterioration', 'Development', 'Diffuse', 'Disease', 'Drug Screening', 'Early Diagnosis', 'Foundations', 'Goals', 'Grain', 'Image', 'Image Analysis', 'Internet', 'Lead', 'Location', 'Machine Learning', 'Medical Imaging', 'Methodology', 'Methods', 'Modality', 'Nature', 'Nerve Degeneration', 'Neurologic', 'Neurologic Effect', 'Online Systems', 'Outcome', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phase', 'Population Study', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Research', 'Research Personnel', 'Services', 'Shapes', 'Software Tools', 'Structure', 'Technology', 'Temporal Lobe', 'Testing', 'Validation', 'Variant', 'Visualization', 'autism spectrum disorder', 'base', 'clinical Diagnosis', 'experience', 'frontal lobe', 'gray matter', 'high throughput screening', 'image processing', 'image registration', 'imaging capabilities', 'improved', 'interest', 'machine learning method', 'morphometry', 'nervous system disorder', 'predict clinical outcome', 'predictive modeling', 'programs', 'research and development', 'shape analysis', 'software development', 'task analysis', 'tool', 'web services', 'white matter']",NIMH,"KITWARE, INC.",R41,2020,99860,0.004470445256050238
"SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING EMAN is one of the most well-established and widely used scientific image processing suites targeting the rapidly growing CryoEM/CryoET community worldwide. In turn, the CryoEM and CryoET studies which it enables permit determination of the structures of interacting macromolecules both in-vitro and in-vivo, and are being used to better understand the biochemical processes taking place in cells, to better identify potential drug targets and develop novel diagnostics. With the higher resolutions now possible in this field, direct drug interaction structural studies are now possible, and being used to gain insight into the mode of action of drugs within the cell. Unlike many newer tools in the field, such as Relion, CisTEM and CryoSparc, which focus on specific refinement tasks, EMAN is a versatile, modular suite capable of performing a variety of image processing tasks with hundreds of algorithms supporting virtually all of the standard file formats and mathematical conventions used in the field, as well as other related imaging fields. It provides an ideal platform for prototyping fundamental new algorithm developments, while still able to achieve data-limited resolution in single particle reconstruction. While high resolution single particle refinement has become routine in recent years, thanks largely to the dramatic data quality improvements provided by new detector technology, there remain significant opportunities for improvements in mitigating model bias, efficient use of data, and analysis of complexes with compositional or conformational variability. Some of the most important problems from a biological perspective involve the sort of compositional and conformational variability which remain challenging problems. The field also remains susceptible to problems of initial model bias, which are exacerbated in systems exhibiting structural variability, and as a result many structures are still published with exaggerated resolution claims. The standard protocols used by many in the field typically involve discarding a very large fraction of the raw data (as much as 80-90% in some cases), often based on qualitative assessments, raising questions related to rigor and reproducibility of structural results. In this proposal, we will develop or adapt image processing techniques to help resolve these issues, based on developments or unrealized concepts from mathematics and computer science. CryoEM and CryoET are used to study the structures of interacting biomolecules in the cell at resolutions 100x better than the best possible light microscope. This methodology permits new insights into the biomolecules which underlie disease, can shed light on structural changes in diseased cells and provide direct information on how drugs interact with the molecules they target. This grant develops the software used to turn noisy 2-D electron microscope images into reliable 3-D structures of individual molecules extending to near-atomic resolution.",SUPPORT AND DEVELOPMENT OF EMAN FOR ELECTRON MICROSCOPY IMAGE PROCESSING,10021685,R01GM080139,"['3-Dimensional', 'Algorithms', 'Appearance', 'Biochemical Process', 'Biological', 'Cells', 'Classification', 'Communities', 'Complex', 'Cryoelectron Microscopy', 'Data', 'Data Analyses', 'Data Reporting', 'Development', 'Disease', 'Drug Interactions', 'Drug Targeting', 'Electron Microscope', 'Electron Microscopy', 'Exhibits', 'Grant', 'Image', 'In Vitro', 'Individual', 'Light', 'Light Microscope', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Modeling', 'Molecular Conformation', 'Nature', 'Pathway interactions', 'Pharmaceutical Preparations', 'Process', 'Protocols documentation', 'Publishing', 'Reproducibility', 'Resolution', 'Roentgen Rays', 'Rotation', 'Scheme', 'Structure', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'algorithm development', 'artificial neural network', 'autoencoder', 'base', 'case-based', 'computer science', 'data quality', 'deep learning', 'denoising', 'detector', 'drug action', 'file format', 'image processing', 'improved', 'in vivo', 'insight', 'macromolecule', 'mathematical sciences', 'microscopic imaging', 'neural network', 'novel diagnostics', 'particle', 'prototype', 'reconstruction', 'software development', 'symposium', 'three dimensional structure', 'tool', 'virtual']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,344862,0.01436356976787397
"3-D Imaging Flow Cytometry PROJECT SUMMARY This project aims to develop and test two innovative platforms and related software for 3-D imaging flow cytometry of fluorescent or absorbing (stained) samples. These systems will allow 3-D structural and functional imaging of many single cells at a subcellular resolution and at a scale that used to be available only in flow cytometry or recently in 2-D imaging. Thereby, the proposed methods have the potential to fundamentally change the ways cultured cells, patient-derived samples, and small experimental organisms are studied. Automated classification based on the 3-D features will enable the diagnosis of hematologic disorders at single-cell precision. Existing 3-D microscopy methods can provide the same information at higher resolution; however, by relying on a scanning mechanism they cannot be applied to suspending cells, especially in a flow configuration, which is essential for high-speed interrogation. Snapshot 3-D microscopy techniques have been developed to address this challenge, but they have insufficient spatial resolution for single-cell imaging and suffer from long data processing time. We overcome these limitations by combining two novel snapshot techniques developed by the PI with the most rigorous optical imaging theories and cutting-edge component technologies. We will use an array of lenslets, which simultaneously records many projection images corresponding with different viewing angles. The use of pupil phase masks, designed using wavefront coding and a theory of 3-D high-numerical-aperture optical imaging, will increase the resolution of each projection image to the theoretical limit given by the objective-lens numerical aperture. The target resolution is 0.5 µm, which is comparable to existing 2-D imaging flow cytometry systems. The target imaging throughputs based on current component technologies are 120 volumes/sec for fluorescence imaging and 700 volumes/sec for absorption imaging, which are higher than 100 volumes/sec of cutting-edge 3-D optical microscopy for stationary specimens. The vast amount of data acquired by these 3-D imaging systems imposes a serious challenge to data processing. The developed systems record true projection images, which obviate iterative deconvolution process, thereby allowing much faster tomographic reconstruction than in existing snapshot techniques. Using general-purpose graphics processing units and optical diffraction tomography, which includes the diffraction of light by subcellular organelles, our tomographic reconstruction algorithm will be faster yet more accurate than existing approaches. Further, we will explore the feasibility of applying a deep convolutional neural network to the images acquired by the developed systems for accurate single-cell classification based on 3-D features. PROJECT NARRATIVE This project aims to develop 3-D imaging flow cytometry platforms for fluorescent or absorbing (stained) cells at high resolution and high throughput in a flow configuration. The developed systems will be built upon two novel snapshot 3-D techniques developed by the PI in combination with most rigorous 3-D optical imaging theories and cutting-edge component technologies. The proposed methods have the potential to fundamentally change the ways that biological specimens are examined by allowing 3-D structural and functional imaging of suspending cells at a scale that used to be available only in flow cytometry or 2-D imaging.",3-D Imaging Flow Cytometry,10023268,R21GM135848,"['3-Dimensional', 'Address', 'Adopted', 'Algorithms', 'Biological', 'Blood', 'Blood specimen', 'Cells', 'Classification', 'Code', 'Computer software', 'Cultured Cells', 'Data', 'Diagnosis', 'Dimensions', 'Flow Cytometry', 'Functional Imaging', 'Geometry', 'Hematological Disease', 'Holography', 'Image', 'Laboratory Organism', 'Leukocytes', 'Lifting', 'Lighting', 'Masks', 'Methods', 'Microscope', 'Microscopy', 'Optical Tomography', 'Optics', 'Organelles', 'Patients', 'Phase', 'Process', 'Pupil', 'Records', 'Resolution', 'Sampling', 'Scanning', 'Specimen', 'Speed', 'Stains', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Time', 'Work', 'absorption', 'base', 'cellular imaging', 'commercialization', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'diffraction of light', 'digital', 'feature extraction', 'fluorescence imaging', 'imaging system', 'innovation', 'lens', 'novel', 'optical imaging', 'reconstruction', 'software development', 'targeted imaging', 'theories', 'three dimensional structure', 'tomography']",NIGMS,UNIVERSITY OF WISCONSIN MILWAUKEE,R21,2020,155784,-0.0023948602634060504
"2020 OSA Optical Coherence Tomography Meeting NIBIB PROPOSAL – ABSTRACT 2020 OSA Optical Coherence Tomography Meeting  Biophotonics technologies have clear medical and clinical applications. However, the transformation and translation from the research lab to the clinic, and then to market is a complex process. The 2020 OSA Optical Coherence Tomography meeting will be held on 20-23 April 2020 in Fort Lauderdale, Florida, in parallel with other four topical meetings (Clinical and Translational Biophotonics, Optical Tomography and Spectroscopy, Microscopy, Histopathology and Analytics, Optics and the Brain) within the same congress, the 2020 OSA Biophotonics Congress: Biomedical Optics. The ultimate objective of this conference is to disseminate recent developments in the field of optical coherence tomography (OCT) and inspire new ideas through various forms of interactions within a broad audience that includes engineers, natural scientists (physicists, biologists, chemists, etc.), clinical researchers, industrial R&D and market experts. The meeting will report on the latest advances in this field and discuss how the OCT field can be advanced in the near future. In addition to addressing the use of adaptive optics to improve image quality, emphasis will be placed on advanced techniques to use OCT for functional imaging, real time volumetric imaging and rendering, and imaging for diagnostic and surgical guidance applications. New topics to be covered are the development and application of advanced image processing algorithms to interpret to imaging data.  A unique advantage of co-locating this meeting within a congress and presenting joint plenary sessions is the extended cross-fertilization between experts in in the distinct but synergic fields. Technical sessions that include innovative methods such as campfire, fishbowl sessions or unconference, and special programming will ensure the meetings' success as the leading forum for presenting the latest advances, while providing an ideal setting to learn. This meeting will provide an opportunities for students and early career professionals to present their work, participate in professional development activities, hear from and network with internationally-renowned speakers and participate in special programming. Ultimately, holding high-quality scientific and technical meeting, where best-in-class research is presented and discussed will advance knowledge in the field of biomedical optics and biophotonics and propel technological development forward, while augmenting standard academic training and presenting opportunities for career advancement, especially for students and early career professionals. NIBIB PROPOSAL – PROJECT NARRATIVE 2020 OSA Optical Coherence Tomography Meeting The 2020 OSA Optical Coherence Tomography Meetings will bring together many of the leaders in the OCT field, who will report on the latest advances in this field and discuss how the OCT field can be advanced in the near future, including developing and evaluating new imaging approaches to solve important clinical problems. In addition to addressing the use of adaptive optics to improve image quality, emphasis will be placed on advanced techniques to use OCT for functional imaging, real time volumetric imaging and rendering, and imaging for diagnostic and surgical guidance applications. These meeting will bring together researchers working in all aspects of this field and will serve as a forum for discussion of existing and emerging techniques as well as future directions.",2020 OSA Optical Coherence Tomography Meeting,9914797,R13EB029301,"['Academic Training', 'Address', 'Algorithms', 'Area', 'Biomedical Engineering', 'Biomedical Research', 'Biomedical Technology', 'Biophotonics', 'Brain', 'Career Mobility', 'Clinic', 'Clinical', 'Collaborations', 'Complex', 'Congresses', 'Data', 'Development', 'Diagnostic Imaging', 'Engineering', 'Ensure', 'Equilibrium', 'Event', 'Fertilization', 'Florida', 'Functional Imaging', 'Future', 'Goals', 'Hearing', 'Histopathology', 'Image', 'Industrialization', 'Industry', 'International', 'Joints', 'Knowledge', 'Learning', 'Machine Learning', 'Medical', 'Methods', 'Microscopy', 'National Institute of Biomedical Imaging and Bioengineering', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optical Tomography', 'Optics', 'Paper', 'Participant', 'Peer Review', 'Performance', 'Physicians', 'Process', 'Published Comment', 'Reporting', 'Research', 'Research Personnel', 'Scientist', 'Services', 'Special Event', 'Spectrum Analysis', 'Students', 'Techniques', 'Technology', 'Time', 'Translating', 'Translational Research', 'Translations', 'Work', 'academic standard', 'adaptive optics', 'bioimaging', 'career', 'clinical application', 'design', 'graduate student', 'image processing', 'imaging approach', 'improved', 'innovation', 'lectures', 'meetings', 'novel', 'posters', 'programs', 'research and development', 'success', 'symposium', 'tool']",NIBIB,OPTICAL SOCIETY OF AMERICA,R13,2020,10000,0.00939069405487733
"A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing Project Summary: Neurotoxicological evaluation of new compounds intended for human use or of potential human exposure is mandated by international regulatory bodies and largely relies on lethality testing in higher-order vertebrate animals. High screening costs, long experimental times, and legislative requirements to reduce dependence on animal testing have led many industries to search for alternative technologies. In vitro toxicology testing uses isolated cells or monotypic cell culture and can only provide limited insight since these models lack biologically relevant intact multi-typic cellular network structures. While both technologies have been augmented by in silico technologies, there is still a non-trivial gap between what can be learned and translated from simple, fast, inexpensive in vitro methods versus longer, complex, and costly in vivo studies in higher order animals. Newormics’ approach to filling this gap is to enable in vivo neurotoxicological assessment in Caenorhabditis elegans, an accepted alternative invertebrate model organism, by developing neuron-specific toxicity assays, delivered via a proprietary high-density, large-scale microfluidic immobilization device for high-content, high throughput analysis. Building on advances made during Phase I and important market learnings from participation in the NIH I-Corps program, Phase II proposes several new elements of innovation to achieve our goals in 3 specific aims. In Aim 1, we will convert our first-generation microfluidic device to a high-density (384- well) vivoChip with improved microfabrication technologies, incorporate on-chip culture for transfer-less exposure and testing, and integrate automation for chip loading, imaging, and analysis. These measures will significantly increase test scale (from 80 compounds per chip to 280) and lower the consumable and labor costs per test. In Aim 2, building on our dopaminergic neurotox assay from Phase I, we will develop four neurotox assays with brightly fluorescently labeled dopaminergic, serotonergic, GABAergic, and cholinergic neurons providing the unprecedented ability to assess subtle phenotypic effects of chemicals on individual intact, functional neurons. To achieve real-time image processing, multi-parameter phenotyping, and managing the terabytes of image data generated per test, we will build a computational platform empowered by a graphic user interface. This platform will be used for image compilation, user-annotated phenotype definition and scoring, and automated report generation with appropriate statistical analysis. In Aim 3, with our industry partners, we will validate our platform and assays using reference chemicals. As more chemicals are tested, we will build a database which can be further mined. The outcome of this work will enable many industries to reduce lethal animal testing and get safer industrial and personal consumer products to market faster for economic benefit, reaching regulatory compliance for reduced animal use, and improved healthcare for neurological diseases. Narrative: The proposed work will enable the use of a small invertebrate model organism, C. elegans, for neuron-specific analysis of neurodegeneration phenotypes from high-resolution fluorescence images of individual neurons at high throughputs. The proposed imaging system and the neuron-specific assays will provide an unprecedented ability to assess developmental neurotoxicity in an intact, live, whole organism, down to a neuronal mechanism- of-action level. This project will fill the gap between in vitro and in vivo toxicology testing with an effective invertebrate model organism as alternate to vertebrate animal testing.",A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing,10082215,R44MH118841,"['3-Dimensional', 'Address', 'Animal Model', 'Animal Testing', 'Animals', 'Automation', 'Biological', 'Biological Assay', 'Caenorhabditis elegans', 'Cell Culture Techniques', 'Cells', 'Chemicals', 'Complement', 'Complex', 'Computer software', 'Data', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Devices', 'Dopamine', 'Eating', 'Economics', 'Elements', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Gel', 'Generations', 'Goals', 'Healthcare', 'Hour', 'Human', 'Image', 'Immobilization', 'In Vitro', 'Individual', 'Industrialization', 'Industry', 'Industry Standard', 'Innovation Corps', 'International', 'Invertebrates', 'Label', 'Learning', 'Liquid substance', 'Machine Learning', 'Manuals', 'Market Research', 'Measures', 'Methods', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Nerve Degeneration', 'Nervous system structure', 'Neurons', 'Neurotransmitters', 'Organoids', 'Outcome', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Protocol Compliance', 'Protocols documentation', 'Reporting', 'Research Activity', 'Resolution', 'Robotics', 'Serotonin', 'Services', 'Specificity', 'Speed', 'Statistical Data Interpretation', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Translating', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebrates', 'Whole Organism', 'Work', 'base', 'cholinergic neuron', 'computational platform', 'connectome', 'consumer product', 'cost', 'cost effective', 'density', 'design', 'developmental neurotoxicity', 'developmental toxicity', 'empowered', 'experimental study', 'exposed human population', 'fluorescence imaging', 'gamma-Aminobutyric Acid', 'graphical user interface', 'high resolution imaging', 'high throughput analysis', 'image processing', 'imaging platform', 'imaging system', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'in vivo Model', 'industry partner', 'innovation', 'insight', 'interest', 'nervous system disorder', 'neurotoxicity', 'neurotoxicology', 'programs', 'real-time images', 'reproductive toxicity', 'screening', 'small molecule libraries', 'success', 'terabyte', 'testing services', 'young adult']",NIMH,"NEWORMICS, LLC",R44,2020,749858,0.016025016364423293
"Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD ABSTRACT The goal of this NIDDK Mentored Research Scientist Development Award is to provide an organized scientific and educational environment for Dr. Timothy Kline to begin his transition into an independent research career focused on developing novel imaging technologies and image analysis techniques for abdominal organ pathologies. This proposal outlines a five-year training plan at Mayo Clinic under the primary mentorship of Dr. Bradley Erickson and a Mentoring Team comprised of accomplished researchers in the fields of: biology, nephrology, genetics, radiology, informatics; medical physics, biostatistics, image processing, and physiology. The focus of this proposal is to improve both research studies and disease prognosis for autosomal dominant polycystic kidney disease (ADPKD) patients through biomedical imaging techniques. It is well understood that imaging is essential for ADPKD diagnosis, monitoring, and outcome prediction. Clinical studies utilize total kidney volume (TKV) (as measured by MRI as an image-based biomarker) to follow the progression of ADPKD, as larger TKVs have been shown to correlate with worse prognosis in both human and animal-model studies. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming, costly, and poorly standardized. The introduction of automated approaches for measuring TKV will: greatly improve measurement throughput, significantly reduce costs associated with performing research studies, allow accurate and reproducible measurements to be obtained both within and across institutions; facilitate the search for new imaging biomarkers. The specific aims of this project are to: (i) develop and validate automated tools to characterize renal structure, such as TKV and cystic burden; (ii) explore new imaging biomarkers by image texture feature analysis and pattern recognition techniques; and (iii) develop a new technique to measure renal blood flow. This research will be facilitated by Mayo Clinic's outstanding clinical and research environment dedicated to improving patient care, as well as the Mayo Clinic Translational PKD Center, which focuses on translating basic science research into improvements in the management and treatment of ADPKD patients. Dr. Kline's background in imaging technologies and image processing makes him particularly suited to perform this research. In addition to the above aims, Dr. Kline will: 1) develop a strong knowledge base in both nephrology and radiology by attending relevant rounds, seminars, and national conferences; 2) enhance his knowledge of medical imaging, biology, physiology, genetics, and programming through coursework and mentoring; 3) attend workshops focused on grant and publication writing; and 4) submit a highly competitive R01 application expanding upon the findings from this research proposal. This proposal will lead to vast improvements to current analysis workflows, as well as an improved understanding of the prognostic power of new imaging biomarkers of ADPKD. Obtaining this K Award will greatly facilitate Dr. Kline's transition into a prosperous independent research career. Narrative Autosomal dominant polycystic kidney disease (ADPKD) is one of the most common monogenic disorders and is a leading cause of end-stage renal disease. Total kidney volume (TKV) has become the main image-based biomarker for following ADPKD progression. However, there are challenges with using TKV as a marker of disease progression. For one, it is a simplification of the disease state and does not inform on microscopic disease processes that are involved with piecemeal destruction of healthy renal tissue. In addition, measurements of TKVs are time consuming and costly. This project will develop automated tools to increase measurement throughput, and explore new image-based biomarkers that will significantly add to the assessment of patient prognosis, and will have the ability to more quickly judge the effectiveness of interventions.",Advanced MR Imaging and Image Analytics as a Precision Medicine Tool to Manage ADPKD,10011565,K01DK110136,"['3-Dimensional', 'Abdomen', 'Affect', 'Age', 'Anatomy', 'Animals', 'Architecture', 'Area', 'Autosomal Dominant Polycystic Kidney', 'Basic Science', 'Biological Markers', 'Biology', 'Biometry', 'Blood Vessels', 'Classification', 'Clinic', 'Clinical', 'Clinical Management', 'Clinical Research', 'Consumption', 'Cyst', 'Data', 'Databases', 'Disease', 'Disease Marker', 'Disease Progression', 'Educational workshop', 'Effectiveness of Interventions', 'End stage renal failure', 'Environment', 'FarGo', 'Fibrosis', 'Genetic', 'Genetic Programming', 'Geometry', 'Goals', 'Gold', 'Grant', 'Hepatic Cyst', 'Image', 'Image Analysis', 'Imaging Techniques', 'Imaging technology', 'Informatics', 'Institution', 'Intervention', 'K-Series Research Career Programs', 'Kidney', 'Knowledge', 'Liver', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical', 'Medical Imaging', 'Mendelian disorder', 'Mentored Research Scientist Development Award', 'Mentors', 'Mentorship', 'Microscopic', 'Monitor', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Nephrology', 'Organ', 'Pathology', 'Patient Care', 'Patient imaging', 'Patients', 'Pattern', 'Pattern Recognition', 'Performance', 'Perfusion', 'Phase', 'Phenotype', 'Physics', 'Physiologic pulse', 'Physiology', 'Polycystic Kidney Diseases', 'Process', 'Protocols documentation', 'Publications', 'Radiology Specialty', 'Renal Blood Flow', 'Renal Tissue', 'Renal function', 'Reproducibility', 'Research', 'Research Personnel', 'Research Proposals', 'Resolution', 'Spin Labels', 'Standardization', 'Structure', 'Study models', 'Suggestion', 'Techniques', 'Testing', 'Texture', 'Time', 'Training', 'Translating', 'Treatment Effectiveness', 'Writing', 'automated segmentation', 'base', 'bioimaging', 'career', 'clinical practice', 'cost', 'deep learning', 'disease diagnosis', 'educational atmosphere', 'functional decline', 'human model', 'image processing', 'imaging biomarker', 'imaging modality', 'improved', 'insight', 'interest', 'kidney vascular structure', 'knowledge base', 'novel imaging technology', 'outcome forecast', 'outcome prediction', 'precision medicine', 'pressure', 'prognostic value', 'radiological imaging', 'renal artery', 'research study', 'shear stress', 'symposium', 'tool']",NIDDK,MAYO CLINIC ROCHESTER,K01,2020,154915,-0.0008827937811928445
