text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Transcriptional Regulatory Networks of Craniofacial Development Abstract Human craniofacial development is a complex process and frequently goes awry to cause a major class of birth defects, orofacial clefting, which affects approximately 1 in 700 live births. Proper facial development in mouse and human requires three sets of paired facial prominences coming together by growth, morphogenesis, and fusion. Embryonic facial development is strikingly similar in human and mouse, making the mouse the best available model system for human. Previous studies have shown that the expression of many thousands of genes changes across tissue layer, age, and/or prominence, as well as cell population during early mouse facial development. However, we still only have a rudimentary understanding of how these changes are regulated by the interaction of transcriptional modulators in the developing face. To understand how genes are transcriptionally regulated during facial development, this research seeks to construct transcriptional regulatory networks in a temporospatial manner by in silico analysis of publicly available multi- omic datasets. Aim 1 will focus on the identification and verification of transcriptional regulatory networks operating in facial mesenchyme with a focus on super-enhancers. Aim 2 will adopt a similar approach to study the ectoderm which acts as a vital signaling center for the mesenchyme. Finally, in Aim 3 I will apply knowledge from Aims 1 and 2 to build transcriptional regulatory networks at the single cell level. These aims will take advantage of available RNA-seq, ATAC-seq, histone marker ChIP-seq, transcription factor ChIP-seq, bulk and single cell RNA-seq data from wild-type or mutant mice, as well as facial enhancer expression databases. Accomplishment of these studies will predict how genes are transcriptionally regulated in a temporospatial manner during facial development and discover sets of core transcription factors and super- enhancers controlling facial development. These transcriptional regulatory networks will be relevant to the genetic and molecular underpinnings of human orofacial clefting, and will provide clear testable predictions about transcription factor function and the consequences of aberrant expression. Performance and accomplishment of these Aims will also act as a major component of my career development plan, in which my goal is to obtain and independent tenure-track faculty position and serve as a mentor to the next generation of scientists. A major aspect of my career development plan is to build on my growing strength in bioinformatics by learning more advanced techniques in this specialty alongside new computational based approaches, such as machine learning. In this respect, my Aims and career development plan are aligned with a Notice of Special Interest (NOSI) of NIDCR in Supporting Dental, Oral, and Craniofacial Research Using Bioinformatic, Computational, and Data Science Approaches (NOT-DE-20-006) for which this application is targeted. I have recruited a mentorship team with specialties in craniofacial biology, bioinformatics, machine learning, and career development to help me achieve these goals. Project Narrative Human craniofacial development is a complex process and requires suites of genes to be switched on and off at appropriate times and spaces during formation of the embryo. There is now a wealth of data available in public databases concerning which genes are expressed when and where during mammalian facial development, including for the transcription factors which are the proteins that regulate these critical expression programs, but we have not yet begun to connect this information together to derive logical predictions about the critical networks responsible for craniofacial development. This proposal will address that gap using both computational and laboratory-based methods to derive and verify transcriptional regulatory networks relevant to the genetic and molecular underpinnings of normal facial development as well as how these are disrupted to cause defects such as human orofacial clefting.",Transcriptional Regulatory Networks of Craniofacial Development,10284443,K01DE030923,"['ATAC-seq', 'Address', 'Adopted', 'Affect', 'Age', 'Automobile Driving', 'Bioinformatics', 'Biological Assay', 'Biological Models', 'Biology', 'Cartilage', 'Cells', 'ChIP-seq', 'Complex', 'Computational Science', 'Computer Models', 'Congenital Abnormality', 'Data', 'Data Science', 'Data Set', 'Databases', 'Defect', 'Dental', 'Dependence', 'Development', 'Development Plans', 'Ectoderm', 'Embryo', 'Enhancers', 'Face', 'FaceBase', 'Faculty', 'Foundations', 'Future', 'Gene Expression', 'Genes', 'Genetic', 'Genetic Models', 'Genetic Transcription', 'Genome', 'Genomics', 'Goals', 'Growth', 'Histones', 'Human', 'Human Genetics', 'Instruction', 'Knowledge', 'Laboratories', 'Learning', 'Live Birth', 'Machine Learning', 'Mentors', 'Mentorship', 'Mesenchymal', 'Mesenchyme', 'Methods', 'Molecular', 'Morphogenesis', 'Mus', 'Muscle', 'Mutant Strains Mice', 'National Institute of Dental and Craniofacial Research', 'Oral', 'Pathology', 'Pattern', 'Performance', 'Population', 'Positioning Attribute', 'Process', 'Proteins', 'Regulatory Element', 'Research', 'Resources', 'Scientist', 'Signal Pathway', 'Signal Transduction', 'Solid', 'Study models', 'System', 'Techniques', 'Technology', 'Time', 'Tissues', 'Transcriptional Regulation', 'Transgenic Organisms', 'Validation', 'Wild Type Mouse', 'base', 'bone', 'career', 'career development', 'cell type', 'craniofacial', 'craniofacial development', 'critical period', 'design', 'differential expression', 'in silico', 'interest', 'medical specialties', 'mouse model', 'multiple omics', 'network models', 'next generation', 'orofacial cleft', 'programs', 'promoter', 'recruit', 'research and development', 'single-cell RNA sequencing', 'spatiotemporal', 'tenure track', 'transcription factor', 'transcriptome', 'transcriptome sequencing']",NIDCR,UNIVERSITY OF COLORADO DENVER,K01,2021,130135
"Computational and brain predictors of emotion cue integration The purpose of this project is to develop computational and brain-based models of emotion cue integration: people’s inferences about others’ emotions based on dynamic, multimodal cues. Observers often decide how targets feel based on cues such as facial expressions, prosody, and language. Such inferences scaffold healthy social interaction, and abnormal inference both marks and exacerbates social deficits in numerous psychiatric disorders. Psychologists and neuroscientists have studied emotion inference for decades, but the vast majority of this work employs simplified social cues, such as vignettes or static images of faces. By contrast, “real world” emotion cues are complex, dynamic, and multimodal. Cue integration—inference based on naturalistic emotion information—likely differs from simpler inference at cognitive and neural levels, but this phenomenon remains poorly understood. This means that scientists lack a clear model of how observers adaptively process complex emotion cues, and how that processing goes awry in mental illness. Especially lacking are mechanistic models that can describe the computations and brain processes involved in cue integration with sufficient precision to predict inference in new cases, observers, and samples. This project will merge tools from social psychology, computer science, and neuroscience to generate a novel and rigorous model of emotion cue integration. We have demonstrated that in the face of complex emotion cues, observers dynamically “weight” cues from each modality (e.g., visual, linguistic) over time, a process that (i) tracks shifts in brain activity and connectivity; and (ii) can be captured using Bayesian models. Here, we will expand this work in several ways. First, we will develop precise computational tools to isolate features of emotion cues—such as facial movements, prosody, and linguistic sentiment—that track observers’ use of each cue modality during integration. Second, we will develop multi-region “signatures” of brain activity and connectivity that track emotion inference in each modality. We will use these signatures in conjunction with machine learning to predict unimodal emotion inference and cue integration in new observers and samples, based on brain data alone. Third, we will explore the context-dependence of naturalistic emotion inference by testing whether reinforcement learning can bias observers’ cue integration and accompanying brain signatures. Finally, we will model computational and neural abnormalities associated with cue integration in patients with Major Depressive Disorder and Bipolar Disorder. At the level of basic science, these data will generate a fundamentally new—and more naturalistic—approach to the neuroscience of emotion inference. The computational and brain metrics we produce will also be made publically available to facilitate the open and cumulative study of emotion inference across labs. At a translational level, we will provide a mechanistic, rich account of abnormal emotion inference in mood disorders, paving the way for computational and brain markers that can be used to assess social dysfunction and treatment efficacy in these and other mental illnesses. PROJECT NARRATIVE The proposed research will use methods from social psychology, cognitive neuroscience, and computer science to (i) precisely model people’s inferences about others’ emotions based on complex, dynamic cues, (ii) generate multi-region, brain-based predictors of these inferences, and (iii) characterize abnormalities in inference among individuals with mood disorders. Several psychiatric and neurodevelopmental disorders are characterized by difficulties understanding others’ emotions, which in turn worsen social functioning in patients. In addition to providing new insights about social processes—a core target within the NIMH’s research domain criteria (RDoC) framework—the proposed research will offer powerful, novel computational and neural targets through which to assess and treat difficulties in emotion inference, and to eventually reduce the social burden faced by people with mental illness on a broad scale.",Computational and brain predictors of emotion cue integration,10138024,R01MH112560,"['Affect', 'Agreement', 'Base of the Brain', 'Basic Science', 'Bayesian Modeling', 'Bipolar Disorder', 'Brain', 'Brain region', 'Classification', 'Cognitive', 'Complex', 'Computer Models', 'Cues', 'Data', 'Dependence', 'Emotional', 'Emotional disorder', 'Emotions', 'Event', 'Exhibits', 'Face', 'Face Processing', 'Facial Expression', 'Functional Magnetic Resonance Imaging', 'Future', 'Image', 'Individual', 'Language', 'Lateral', 'Learning', 'Life', 'Linguistics', 'Machine Learning', 'Major Depressive Disorder', 'Measures', 'Mental disorders', 'Methods', 'Modality', 'Modeling', 'Mood Disorders', 'Moods', 'Movement', 'National Institute of Mental Health', 'Neurodevelopmental Disorder', 'Neurosciences', 'Observer Variation', 'Participant', 'Patients', 'Pattern', 'Perception', 'Process', 'Psychological reinforcement', 'Psychologist', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Running', 'Sampling', 'Scanning', 'Scientist', 'Sensory', 'Social Functioning', 'Social Interaction', 'Social Processes', 'Social Psychology', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Treatment Efficacy', 'Visual', 'Weight', 'Work', 'affective computing', 'base', 'brain abnormalities', 'cognitive neuroscience', 'computer science', 'computerized tools', 'executive function', 'insight', 'language comprehension', 'multimodality', 'neuroimaging', 'novel', 'recruit', 'relating to nervous system', 'response', 'scaffold', 'social', 'social deficits', 'tool']",NIMH,STANFORD UNIVERSITY,R01,2021,249264
"Unpacking Emotion Inflexibility and Prospective Prediction of Affective Disease PROJECT ABSTRACT/SUMMARY The prevalence of psychiatric disorders has reached nearly epidemic proportions. Rates of common affective diseases (unipolar depression, anxiety and stress disorders) are high across the lifespan and these diseases place a tremendous social and economic burden on the individual and society. Clear evidence indicates that most affective disorders emerge at the intersection of pre-existing vulnerability and significant, highly stressful, life-events. However, current models of emotion-related risk do not adequately account for this confluence of biological, historical, and situational factors. In this investigation, we build upon our prior work demonstrating broad associations between flexible emotion processing and psychological health and adjustment, and in-flexible emotion and psychological risk and affective disease. Specifically, we will recruit 400 adults in hospital following a potentially traumatic event (e.g., accident, violence, fire, etc.) in order to model the influence of early emotion processing on trajectories of adjustment. We focus our investigation on the super-ordinate construct of Emotion flexibility (EF) which encompasses the ability to generate or up-regulate emotions, as well as to shift or down-regulate emotions according to needs and/or environmental demands. EF is well-suited to inform models of emotion-related risk and adjustment as it characterizes an optimal balance of two biologically-based, constituent dimensions: “bottom-up” threat-related processing and “top-down” cognitive control increasingly recognized as central to all emotion processing. We propose rigorous methods to assess EF and related processing in-vivo in lab and via experience sampling. Moreover, we will follow participants to 18 months post event so as to effectively model the association between emotion processing and trajectories of adjustment, while also considering established influences such as physical health status, psychiatric history, childhood maltreatment, daily stress/hassles, and social support. In particular, we will incorporate recent developments in advanced statistical modelling to better characterize the complex and interactive influence of historical and contemporary factors on moment-level emotion processing, EF and adjustment. Broadly, this project is in line with the most recent NIMH strategic plan and will contribute to more complex models of the most common affective diseases, including facilitating the charting of illness trajectories to help determine when, where, and how to intervene. Moreover, this research will directly examine how variation in key systems can influence emotion-processing and adjustment to aversive life events, fitting complex influences more directly into models of risk for the most common and burdensome affective diseases. PUBLIC HEALTH RELEVANCE/NARRATIVE Emotion-related psychiatric disorders, including depression and anxiety, affect a considerable portion of adults in this country and rank as many of the most burdensome diseases worldwide. In this investigation, we will follow an at-risk sample of adults in order to better understand how one key pathway, relating to how individuals process emotion, influences risk for emotion-related diseases over time. In addition, we test the role by which certain other factors, both contemporary and historical (physical health, life stress, social support, psychiatric treatment history, or childhood experiences) may increase or decrease risk via this particular pathway.",Unpacking Emotion Inflexibility and Prospective Prediction of Affective Disease,10089147,R01MH113622,"['Accidents', 'Adult', 'Affect', 'Affective', 'Anxiety', 'Anxiety Disorders', 'Behavioral', 'Biological', 'Categories', 'Child Abuse and Neglect', 'Childhood', 'Clinical', 'Clinical Sciences', 'Complex', 'Country', 'Derivation procedure', 'Development', 'Diagnostic', 'Dimensions', 'Disease', 'Disease Progression', 'Early Intervention', 'Economic Burden', 'Emotions', 'Epidemic', 'Equilibrium', 'Event', 'Fire - disasters', 'Health', 'Health Status', 'Heritability', 'Hospitals', 'Individual', 'Inherited', 'Investigation', 'Life', 'Life Stress', 'Longevity', 'Mental Depression', 'Mental Health', 'Mental disorders', 'Methodology', 'Methods', 'Modeling', 'Mood Disorders', 'National Institute of Mental Health', 'Nature', 'Participant', 'Pathway interactions', 'Patients', 'Pattern', 'Phenotype', 'Post-Traumatic Stress Disorders', 'Prevalence', 'Process', 'Psychiatric therapeutic procedure', 'Psychological adjustment', 'Qualifying', 'Recording of previous events', 'Regulation', 'Research', 'Research Domain Criteria', 'Risk', 'Risk Adjustment', 'Risk Factors', 'Role', 'Sampling', 'Shapes', 'Sleep disturbances', 'Social support', 'Societies', 'Statistical Models', 'Strategic Planning', 'Stress', 'Symptoms', 'System', 'Testing', 'Time', 'Unipolar Depression', 'Variant', 'Violence', 'Work', 'base', 'childhood adversity', 'clinical diagnostics', 'clinically relevant', 'cognitive control', 'emotion regulation', 'experience', 'flexibility', 'improved', 'in vivo', 'indexing', 'laboratory experience', 'longitudinal design', 'machine learning method', 'negative mood', 'network models', 'physical conditioning', 'post-traumatic stress', 'prospective', 'psychologic', 'public health relevance', 'recruit', 'response', 'social', 'stress disorder', 'tool', 'traumatic event']",NIMH,KENT STATE UNIVERSITY,R01,2021,664089
"Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases ﻿    DESCRIPTION (provided by applicant): American Sign Language (ASL) grammar is specified by the manual sign (the hands) and by the nonmanual components, which include the face. Our general hypothesis is that nonmanual facial articulations perform significant semantic and syntactic functions by means of a more extensive set of facial expressions than that seen in other communicative systems (e.g., speech and emotion). This proposal will systematically study this hypothesis. Specifically, we will study the following three hypotheses needed to properly answer the general hypothesis stated above: First, we hypothesize (H1) that the facial muscles involved in the production of clause-level grammatical facial expressions in ASL and/or their intensity of activation are more extensive than those seen in speech and emotion. Second, we hypothesize (H2) that the temporal structure of these facial configurations are more extensive than those seen in speech and emotion. Finally, we hypothesize (H3) that eliminating these ASL nonmanual makers from the original videos, drastically reduces the chances of correctly identifying the clause type of the signed sentence. To test these three hypotheses, we define a highly innovative approach based on the design of computational tools for the analysis of nonmanuals in signing. In particular, we will examine the following three specific aims. In Aim 1, we will build a series of computer algorithms that allow us to automatically (i.e., without the need of any human intervention) detect the face, its facial features as well as the automatic detection of the movements of the facial muscles and their intensity of activation. These tools will be integrated into ELAN, a standard software used for linguistic analysis. These tools will then be used to test six specific hypotheses to successfully study H1. In Aim 2, we define computer vision and machine learning algorithms to identify the temporal structure of ASL facial configurations and examine how these compare to those seen in speech and emotion. We will study six specific hypotheses to successfully address H2. Alternative hypotheses are defined in both aims. Finally, in Aim 3 we define algorithms to automatically modify the original videos of facial expression in ASL to eliminate the identified nonmanual markers. Native users of ASL will complete behavioral experiments to examine H3 and test potential alternative hypotheses. Comparative analysis with non-signer controls will also be completed. These studies will thus further validate H1 and H2. We provide evidence of our ability to successfully complete the tasks in each of these aims. These aims address a critical need; at present, the study of nonmanuals must be carried out by hand. To be able to draw conclusive results, it is necessary to study thousands of videos. The proposed computational approach supposes at least a 50-fold reduction in time compared to methods done by hand. PUBLIC HEALTH RELEVANCE: Deafness limits access to information, with consequent effects on academic achievement, personal integration, and life-long financial situation, and also inhibits valuable contributions by Deaf people to the hearing world. The public benefit of our research includes: (1) the goal of a practical and useful device to enhance communication between Deaf and hearing people in a variety of settings; and (2) the removal of a barrier that prevents Deaf individuals from achieving their full potential. An understanding of the nonmanuals will also change how ASL is taught, leading to an improvement in the training of teachers of the Deaf, sign language interpreters and instructors, and crucially parents of deaf children.",Computational Methods for the Study of American Sign Language Nonmanuals Using Very Large Databases,9841303,R01DC014498,"['3-Dimensional', 'Academic achievement', 'Access to Information', 'Address', 'Agreement', 'Algorithms', 'American Sign Language', 'Articulation', 'Behavioral', 'Child', 'Code', 'Communication', 'Computational algorithm', 'Computer Vision Systems', 'Computer software', 'Computing Methodologies', 'Databases', 'Detection', 'Devices', 'Emotions', 'Excision', 'Face', 'Facial Expression', 'Facial Muscles', 'Goals', 'Hand', 'Head', 'Hearing', 'Human', 'Image', 'Individual', 'Intervention', 'Life', 'Linguistics', 'Logic', 'Machine Learning', 'Manuals', 'Methods', 'Movement', 'Parents', 'Pattern Recognition', 'Production', 'Research', 'Research Personnel', 'Science', 'Semantics', 'Series', 'Shapes', 'Sign Language', 'Signal Transduction', 'Specific qualifier value', 'Speech', 'Structure', 'System', 'Teacher Professional Development', 'Technology', 'Testing', 'Time', 'Visual', 'Visual system structure', 'base', 'body position', 'comparative', 'computerized tools', 'deaf', 'deafness', 'design', 'experience', 'experimental study', 'face perception', 'innovation', 'instructor', 'interest', 'machine learning algorithm', 'prevent', 'public health relevance', 'reconstruction', 'showing emotion', 'syntax', 'tool']",NIDCD,OHIO STATE UNIVERSITY,R01,2021,317844
"Neurocomputational Approaches to Emotion Representation Maintaining an adaptive balance of emotions is central to well-being, and dysregulated emotions contribute broadly to clinical disorders that impart high personal and societal burdens. Recognizing the transdiagnostic importance of emotion to mental health, the National Institute of Health's Research Domain Criteria (RDoC) matrix contains overarching domains of Negative Valence, Positive Valence, and Arousal. However, the matrix underspecifies how specific affective states like sadness, anxiety, or craving are organized within and across these domains, in part because it is unknown whether representations of discrete emotions are reliably differentiated. Other RDoC constructs, such as rumination and worry, modify the temporal parameters of emotions that confer psychopathology risk and exacerbate symptom maintenance. Nonetheless, it is unknown how these processes interface with emotional brain circuits to impact affect dynamics, particularly as they often occur spontaneously during mind wandering. The proposed research promises to improve the RDoC depiction of these emotion-related constructs by taking an affective computing approach. During combined recording of psychophysiology and functional magnetic resonance imaging (fMRI), adult participants will experience emotions to vignettes and movie clips spanning the arousal and valence dimensions, and will report on their spontaneous emotions during resting-state fMRI scans. Machine learning algorithms will decode emotion- specific signals across the levels of analysis, which will be integrated using Bayesian state-space modeling. An analysis of classifier errors will test competing predictions from emotion theories regarding the optimal structure of affective space. Using graph theoretic tools, we will characterize the neural network architecture of the discrete emotion representations to identify provincial and connector hubs that can be used as novel targets for future symptom-specific or co-morbid neuromodulation interventions, respectively. We will apply the emotion-specific maps to resting-state data from the same participants to create neurophysiological indices of spontaneous emotions and to relate their frequencies to measures of trait and state affect as a validation step. Using stochastic modeling of the resting-state data, we will derive temporal dynamics metrics to test the hypothesis that rumination and worry promote emotional inertia during mind wandering. Finally, we will use existing data repositories to demonstrate that our novel indices of affect dynamics transdiagnostically differentiate resting-state fMRI activity patterns in mental health disorders from healthy controls. The proposed research will improve upon current RDoC formulations of Negative Affect, Positive Affect, and Arousal domains by informing how discrete emotions are organized within and across these domains, by integrating emotion representations across multiple RDoC units of analysis, by informing how rumination and worry impact neurophysiological signatures of spontaneous emotions, and by establishing the clinical utility of computationally-derived metrics of emotion dynamics. PROJECT NARRATIVE  The overall goal of this project is to characterize how emotions are represented in the brain and autonomic nervous system. Computational modeling approaches will be applied to integrate the data across multiple sources and tasks, to test competing theories about how emotions are organized, and to derive new metrics of emotion dynamics. The outcome of the work will inform how emotions should be conceptualized within a broader research framework of mental health domains.",Neurocomputational Approaches to Emotion Representation,10227196,R01MH124112,"['Adult', 'Affect', 'Affective', 'Age', 'Anxiety', 'Arousal', 'Autonomic nervous system', 'Basic Science', 'Behavioral', 'Brain', 'Categories', 'Classification', 'Clinical', 'Clip', 'Code', 'Computer Models', 'Data', 'Depressed mood', 'Dimensions', 'Disease', 'Emotional', 'Emotions', 'Equilibrium', 'Exhibits', 'Formulation', 'Frequencies', 'Functional Magnetic Resonance Imaging', 'Future', 'Goals', 'Graph', 'Human', 'Individual', 'Individual Differences', 'Intervention', 'Link', 'Machine Learning', 'Maintenance', 'Maps', 'Measures', 'Mental Health', 'Mental disorders', 'Methods', 'Mind', 'Modeling', 'Negative Valence', 'Outcome', 'Participant', 'Patient Self-Report', 'Pattern', 'Personal Satisfaction', 'Physiological', 'Population', 'Positive Valence', 'Process', 'Psychopathology', 'Psychophysiology', 'Reporting', 'Research', 'Research Domain Criteria', 'Rest', 'Risk', 'Role', 'Signal Transduction', 'Source', 'Space Models', 'Structure', 'Symptoms', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Work', 'affective computing', 'anxious', 'anxious individuals', 'base', 'biobehavior', 'comorbidity', 'craving', 'data repository', 'experience', 'functional MRI scan', 'improved', 'indexing', 'machine learning algorithm', 'markov model', 'movie', 'negative affect', 'neural network architecture', 'neurophysiology', 'neuroregulation', 'novel', 'organizational structure', 'relating to nervous system', 'repository', 'theories', 'tool', 'trait']",NIMH,DUKE UNIVERSITY,R01,2021,774017
