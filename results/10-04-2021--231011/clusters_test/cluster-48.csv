text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"AI based system for longitudinal, repeated measure analyses of freely moving C. elegans worms Abstract This project aims to develop WormInvestigator™, a novel, highly innovative system for performing automated, high-throughput and longitudinal studies of the behavior of C. elegans worms freely moving and socially interacting on agar plates (hereafter: ""freely moving worms"") across multiple time points over extended times (e.g., multiple days) with repeated measures designs. Work in Phase I will focus on demonstrating feasibility of our novel, patent pending, WormRecognizer™ technology – the ability to perform automatic, image-based identification of individual C. elegans worms within a group of freely moving worms (""digital tagging of freely moving worms""). Work in Phase II will focus on creating the full functionality of WormInvestigator for the commercial release. The innovation inherent in WormRecognizer will serve as the basis for enabling a game- changing innovation in the field – the ability to perform high throughput longitudinal, repeated measures design analyses of locomotion and other behavior of freely moving C. elegans worms from discrete, non-continuous video sequences. Compared to study designs that have independent groups repeated measures designs offer more statistical power and the possibility to track an effect over time. Specifically, repeated measures designs for analyzing locomotion and other behavior of freely moving worms will allow researchers to definitively assess the likelihood that a particular behavior is associated with a prior behavior, which is impossible without repeated measures designs or impractical continuous imaging and tracking under constant illumination. WormRecognizer will leverage the Deep Convolutional Neural Network (CNN) architecture to perform automatic identification of the tracks of the same worm in videos of groups of freely moving worms recorded at different time points; encouraging pilot data were generated during preparation of this application. C. elegans is increasingly used as a model organism in research focusing on brain mechanisms underlying complex behaviors and pathological alterations thereof, including research into neurodevelopment, Alzheimer's disease, autism, schizophrenia and traumatic brain injury. Thus, WormInvestigator will enable significant advancements in various mental neuroscience applications that use C. elegans as a model organism. Specifically, the fact that C. elegans express many of the neurotransmitters and associated receptors that are found in higher eukaryotes, including humans, makes C. elegans highly attractive for the (high throughput) screening of next generation therapeutics for mental diseases such as Alzheimer's disease, as well as for disorders that rely on neurotransmitter release modulation such as next generation treatments for schizophrenia. We will perform extensive feasibility studies, product validation and usability studies of WormInvestigator in close collaboration with expert neuroscientists. Market research performed during preparation of this application indicated that WormInvestigator will expand the use of C. elegans as a model organism to many laboratories that do not currently use them. A competing technology is not available. We anticipate the global market size for WormInvestigator to be more than 300 systems. Narrative Performing longitudinal studies and repeated measures design analyses in both short-term and long-term experimental assays focusing on the analysis of locomotion and other behavior of multiple C. elegans worms holds the promise of profound progress in next-generation neuroscience studies such as understanding neurodevelopmental, neuropsychiatric and neurodegenerative disorders, as well as aging research, drug discovery and toxicology. Our proposed product will be a transformative technology, using new analytical methods based on artificial intelligence algorithms that, for the first time, will enable researchers to perform these data-rich longitudinal studies and, thus, repeated measures design analyses in assays using C. elegans as a model organism. This system will allow researchers to make new discoveries based on new studies that are currently not feasible, ultimately providing the basis for developing novel treatments to prevent and fight complex brain diseases.","AI based system for longitudinal, repeated measure analyses of freely moving C. elegans worms",10258638,R43MH126834,"['Acetylcholine', 'Address', 'Agar', 'Aging', 'Alzheimer&apos', 's Disease', 'Animal Behavior', 'Animal Model', 'Appearance', 'Artificial Intelligence', 'Behavior', 'Behavioral', 'Behavioral Research', 'Biological Assay', 'Biotechnology', 'Brain', 'Brain Diseases', 'Caenorhabditis elegans', 'Classification', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Development', 'Disease', 'Dopamine', 'Eukaryota', 'Feasibility Studies', 'Glutamates', 'Goals', 'Human', 'Image', 'Individual', 'Laboratories', 'Legal patent', 'Lighting', 'Locomotion', 'Longevity', 'Longitudinal Studies', 'Market Research', 'Massachusetts', 'Measures', 'Microscope', 'Molecular', 'Motion', 'Mus', 'Names', 'National Institute of Mental Health', 'Nematoda', 'Neurodegenerative Disorders', 'Neurodevelopmental Disorder', 'Neurosciences', 'Neurotransmitters', 'Pathologic', 'Pharmacologic Substance', 'Phase', 'Population Analysis', 'Preparation', 'Psyche structure', 'Rattus', 'Research', 'Research Design', 'Research Personnel', 'Rodent', 'Schizophrenia', 'Schools', 'Serotonin', 'Speed', 'Strategic Planning', 'System', 'Technology', 'Testing', 'Time', 'Toxicology', 'Traumatic Brain Injury', 'Validation', 'Visual Fields', 'Work', 'analytical method', 'autism spectrum disorder', 'base', 'behavioral study', 'convolutional neural network', 'design', 'digital', 'drug discovery', 'fighting', 'free behavior', 'gamma-Aminobutyric Acid', 'high throughput screening', 'innovation', 'intelligent algorithm', 'longitudinal analysis', 'neural network architecture', 'neurodevelopment', 'neuropsychiatric disorder', 'neurotransmitter release', 'next generation', 'novel', 'novel therapeutics', 'prevent', 'prototype', 'receptor', 'social', 'usability']",NIMH,"MICROBRIGHTFIELD, LLC",R43,2021,449987
"ARAGORN: Autonomous Relay Agent for Generation Of Ranked Networks We propose an Autonomous Relay Agent for Generation of Ranked Networks (ARAGORN), which will query Knowledge Providers (KPs) and synthesize answers relevant to user-specified questions, building upon algorithms and components developed as part of the ROBOKOP [1,2] application during the feasibility phase of Translator. The ARAGORN services represent the next generation of ROBOKOP component services, iterating and innovating in response to challenges exposed in the Translator feasibility phase. Based on that work, we have identified overarching issues that must be addressed to truly unleash the power of Translator. 1. ARAs must be able to operate in a federated knowledge environment effectively and efficiently. First-generation Translator tools assembled full data sets from which to extract answers, which were subsequently ranked. Second-generation tools must be able to efficiently operate on massive, distributed data, demanding a new approach. ARAGORN will act asynchronously, interleaving KP queries with partial scoring of answers, prioritizing search directions on-the-fly, and delivering early results that are updated over time in response to newly explored paths 2. ARAs must bridge the precision mismatch between data representations and algorithms that require specificity, and users who pose questions and prefer answers at a more abstract level. Biomedical scientists do not pose questions as database queries. Furthermore, even expert users of current biomedical databases such as ROBOKOP KG or RTX require exploration and experimentation to craft queries to express their intent. ARAGORN will employ multiple strategies to remove this barrier to asking questions effectively, from basic maintenance of a question library, to node generalization, query rewriting, and machine learning techniques such as capsule graph networks. ARAGORN will further use elements of specific answers to create gestalt explanations, clustering, and combining answers with similar content, revealing the commonalities and contradictions in answers. 3. ARAs must be able to generalize answer ranking to address a broader range of question formulations and data types, and to account for counterevidence. In the Translator implementation phase, we anticipate having access to many varied KPs and ARAs that provide diverse quantitative metadata regarding the confidence in assertions or strength of associations. There will be a pressing need to synthesize such data into scores for arbitrarily-shaped answer graphs, in order to filter and prioritize answers for further analysis or user digestion. ARAGORN will address this need by providing a novel scoring algorithm capable of (a) scoring arbitrary directed multi-hypergraphs, (b) accounting for heterogeneous quantitative metadata; and (c) leveraging relationship polarity to incorporate counterevidence. ARAGORN will provide access to this functionality, and connect to KPs using community-defined APIs and data models. The ARAGORN team has contributed to these community efforts during the Translator feasibility phase, and if funded will continue to work with the Standards and Reference Implementations (SRI) group, NCATS staff, and other awardees to continue to define and refine methods and models for data sharing and collaboration. The ARAGORN services will be created with collaboration in mind, such that they can be plugged into larger pipelining and architectural efforts. Most of the risks to the ARAGORN strategy are shared by the entire program; as standardization evolves, the ARAGORN team and other members of the Translator consortium will be required to spend effort updating components. ARAGORN will require access to ontology and similarity tools that we anticipate will be provided by KPs or shared infrastructure; if these do not materialize, the ARAGORN team will create the tools that it needs to accomplish its goals. Additionally, we are assuming the existence of fully translator-compliant KPs from which to draw data; if the program collectively decides that compliance is enforced in ARAs instead, we will draw on our work in ROBOKOP to implement the necessary normalization components in ARAGORN. n/a",ARAGORN: Autonomous Relay Agent for Generation Of Ranked Networks,10332268,OT2TR003441,"['Accounting', 'Address', 'Algorithms', 'Architecture', 'Collaborations', 'Communities', 'Data', 'Data Reporting', 'Data Set', 'Databases', 'Digestion', 'Elements', 'Environment', 'Formulation', 'Funding', 'Generations', 'Goals', 'Graph', 'Infrastructure', 'Knowledge', 'Libraries', 'Machine Learning', 'Maintenance', 'Metadata', 'Methods', 'Mind', 'Modeling', 'Ontology', 'Phase', 'Provider', 'Risk', 'Services', 'Specific qualifier value', 'Specificity', 'Standardization', 'Techniques', 'Time', 'Update', 'Work', 'arbitrary spin', 'base', 'biomedical scientist', 'capsule', 'data modeling', 'data sharing', 'database query', 'distributed data', 'innovation', 'member', 'next generation', 'novel', 'novel strategies', 'programs', 'response', 'tool']",NCATS,UNIV OF NORTH CAROLINA CHAPEL HILL,OT2,2021,1052712
"Biomedical Data Translator Development of Autonomous Relay Agent: ARAX This project would continue collaborative work within the Translator consortium by a multi-site team (“Team X-ray”) at Oregon State University (PI Stephen Ramsey) and at two partner institutions, Pennsylvania State University (PI Koslicki) and the Institute for Systems Biology (PI Eric Deutsch; Co-I Jared Roach). Team X-ray was highly productive in Translator's feasibility assessment phase and the team brings critical expertise to Translator (see Resources). Component type: We propose to create, validate, and integrate an autonomous relay agent (ARA) called ARAX . ARAX will be a middleware component in the new Translator architecture that will extend significantly beyond the capabilities of the prototype reasoning tool (RTX) that we created in the feasibility assessment phase. Depending on the input request, ARAX's main output will be ranked subgraphs with clearly explained ranking basis. ARAX will leverage code and algorithms from RTX and will have an explicit application focus area, as described below. Main problems that ARAX is trying to address: Connections within a biomedical knowledge graph have highly variable degrees of (i) confidence (due to ambiguous predicates and/or due to highly variable degrees of reliability of knowledge types) and (ii) potential relevance to the user's query. Such edge-significance variability leads to both incorrect and difficult-to-interpret results which together pose a significant problem for creating broadly useful tools for computer-based biomedical reasoning. We propose to address this problem by explicitly accounting for these two types of edge variability in the reasoning algorithms–spanning a broad range of biomedical query types–that ARAX will provide to Translator. In addition to these broad capabilities, as described in the Project Plan, we will incorporate advanced algorithms in ARAX for responding to queries relating to disease therapy, including (1) drug repositioning for known disease, leveraging knowledge about the disease’s pathogenesis [1] ; and (2) therapeutic recommendations for rare diseases based on symptoms and the putative causal genetic variant. Plan for implementation of the project: In our Project Plan we describe a five-year timeline for creating, validating, and integrating ARAX within Translator, beginning with a three-month sprint leading to a prototype of ARAX by mid-March 2020. Key components of the plan include: (1) leveraging the BioThings Explorer software framework to enable ARAX to dynamically map between compounds, proteins, pathways, variants, phenotypes, and diseases based on knowledge source application programming interfaces in the Translator registry; (2) leveraging COHD and related Translator resources to obtain biomedical semantic distance information; (3) leveraging an application programming interface endpoint for the RTX biomedical knowledge graph, KG2; and (4) implementing probabilistic reasoning algorithms leveraging provenance information and dynamically determined edge relevance scores to improve reasoning. We will systematically use machine-learning to align ranking scores with measures of output quality. Collaboration strengths of our team include (i) developing technical standards for communications between Translator software agents (leveraging PI Deutsch’s extensive past experience); (ii) developing knowledge graph standards (leveraging PI Ramsey’s and PI Koslicki’s expertise); and (iii) deriving use-case vignettes that speak to the transformative potential of Translator (leveraging Co-I Roach’s and PI Ramsey’s expertise). In the development phase, our team would continue to collaborate with other teams and with NIH stakeholders in an adaptive, high-bandwidth, and team-boundary-agnostic fashion, as detailed in the Project Plan. Key challenges to building the proposed system are (1) the need to be able to ""chain"" together analytical steps between tools and (2) the need for cooperative development of standards that enable Translator components to interact; we address them in detail in the Project Plan. n/a",Biomedical Data Translator Development of Autonomous Relay Agent: ARAX,10333468,OT2TR003428,"['Accounting', 'Address', 'Algorithms', 'Architecture', 'Area', 'Code', 'Collaborations', 'Communication', 'Computer software', 'Computers', 'Data', 'Development', 'Disease', 'Institutes', 'Institution', 'Knowledge', 'Machine Learning', 'Maps', 'Measures', 'Oregon', 'Output', 'Pathogenesis', 'Pathway interactions', 'Pennsylvania', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Proteins', 'Rare Diseases', 'Recommendation', 'Registries', 'Resources', 'Roentgen Rays', 'Semantics', 'Site', 'Software Framework', 'Source', 'Symptoms', 'System', 'Systems Biology', 'Therapeutic', 'TimeLine', 'United States National Institutes of Health', 'Universities', 'Variant', 'Work', 'application programming interface', 'base', 'experience', 'genetic variant', 'improved', 'knowledge graph', 'middleware', 'prototype', 'tool']",NCATS,OREGON STATE UNIVERSITY,OT2,2021,897051
"Genetic determinants of thoracic aortic stiffness and remodeling Project Summary / Abstract This is an application for a K24 mentoring award for patient-oriented research (POR) from Julio Chirinos, MD, PhD, Associate Professor of Medicine at the Perelman School of Medicine at the University of Pennsylvania (Penn). Dr. Chirinos‘ long-term goals are to: (1) Substantially contribute to our understanding and approaches to the prevention and treatment of aortic aging and its associated disease burden, and; (2) to mentor the next generation of investigators interested in the epidemiology of aortic aging and its consequences in human health. This mid-career development award will be critical to help him achieve these goals via dedicated/protected time for mentoring activities, research and development of new skills that are anticipated to greatly enhance the applicant’s impact in this field throughout the rest of his career, as well as the impact and success of his trainees. The candidate has a strong record of mentorship, leadership, and research productivity. His research program encompasses epidemiologic, translational and POR studies of arterial aging and its role in Heart Failure with Preserved Ejection Fraction (HFpEF) and other conditions that afflict our aging population. The scientific goal of this proposal is to investigate the genetic determinants of age-related thoracic aortic stiffening and elongation using large available biobanks with associated genomic and aortic imaging data. These include the UK Biobank and the Penn Medicine Biobank. The projects will include the application of a novel method for quantification of aortic pulse wave velocity that can, for the first time, be applied retrospectively in widely available clinical imaging studies. Deep learning for high-throughput aortic phenotyping will play an important role in this research. The mentoring goals of this application are to engage and support the training of Penn fellows and junior faculty to conduct POR in arterial aging. The career development goal of this application is to support the candidate’s professional development and acquisition of new skills for POR research in aging, specifically: (1) genomics (genome-wide association studies, next generation sequencing, and Mendelian Randomization); (2) Applied deep learning to leverage large banks of imaging data in order to accomplish accurate high-throughput phenotyping of aortic aging. This will be achieved through formal training courses and engaging in sustained collaboration experiences with experts in these topics. The candidate will also engage in career development and promotion of arterial aging research through convening scientific meetings on aortic aging research and improving the national network of POR research in arterial aging through existing professional societies. The institutional environment for clinical and translational science at Penn is outstanding. The Department of Medicine at Penn has made a substantial commitment, including protected time and dedicated space, toward the candidate’s sustained success as a patient-oriented researcher responsible for training a new generation of junior investigators who conduct research in older participants. Project Narrative Dr. Chirinos proposes to augment his scientific skills and program building, continue to develop the local environment for mentoring new clinical investigators who perform patient-oriented research about arterial aging and HFpEF, and conduct studies that will impact our understanding of the genetic determinants of aortic stiffness.",Genetic determinants of thoracic aortic stiffness and remodeling,10106219,K24AG070459,"['Address', 'Adoption', 'Adult', 'Age', 'Aging', 'Aorta', 'Aortic Segment', 'Award', 'Biological', 'Caliber', 'Chest', 'Clinical', 'Clinical Investigator', 'Clinical Sciences', 'Collaborations', 'Data', 'Deposition', 'Development', 'Distal', 'Doctor of Philosophy', 'EFRAC', 'Echocardiography', 'Elastin', 'Enrollment', 'Environment', 'Epidemiology', 'Equation', 'Equipment', 'Exhibits', 'Faculty', 'Failure', 'Fibrosis', 'Generations', 'Genetic Determinism', 'Genetic study', 'Genomics', 'Goals', 'Health', 'Heart failure', 'Heritability', 'Human', 'Image', 'Individual', 'K-Series Research Career Programs', 'Leadership', 'Left', 'Length', 'Location', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medicine', 'Mendelian randomization', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Muscle', 'Participant', 'Pathologic Processes', 'Patients', 'Pennsylvania', 'Phenotype', 'Physicians', 'Physiologic pulse', 'Play', 'Population', 'Population Study', 'Prevention approach', 'Process', 'Productivity', 'Professional Organizations', 'Research', 'Research Personnel', 'Resources', 'Respiratory Diaphragm', 'Rest', 'Role', 'Sample Size', 'Science', 'Scientist', 'Site', 'Surface', 'System', 'Thoracic aorta', 'Time', 'Training', 'Training Support', 'Translational Research', 'Ultrasonography', 'Universities', 'Ventricular', 'Work', 'age related', 'aging population', 'aortic valve', 'arterial tonometry', 'ascending aorta', 'base', 'biobank', 'burden of illness', 'calcification', 'career', 'career development', 'clinical imaging', 'clinical practice', 'deep learning', 'electric impedance', 'epidemiology study', 'exome', 'experience', 'genome wide association study', 'genomic data', 'hemodynamics', 'imaging study', 'improved', 'infancy', 'innovation', 'insight', 'interest', 'large datasets', 'medical schools', 'meetings', 'mid-career faculty', 'multidisciplinary', 'next generation', 'next generation sequencing', 'novel', 'patient oriented', 'patient oriented research', 'preservation', 'programs', 'prospective', 'research and development', 'research study', 'skills', 'success', 'time use']",NIA,UNIVERSITY OF PENNSYLVANIA,K24,2021,194955
"High-definition, wide field of view corneal imaging The cornea is the primary focusing structure of our visual system. Infections and diseases in the tissue can impair vision and lead to blindness, even in eyes with intact neurosensory function. Corneal disease is one of the leading causes of visual deficiency and blindness in the world. Tissue evaluation is an important step for assessing the health of the donor cornea and its appropriateness for different types of placement, yet this process suffers from high subjectivity. High-definition corneal imaging is needed to assist in selection of the most appropriate tissue for transplant. Progress on this front would greatly serve public need, as the cornea is the most commonly transplanted tissue worldwide, with nearly 185,000 transplants annually. Thus, a more sensitive and quantitative method for objective evaluation of tissue at eye banks is needed. We have developed a 3D high-definition imaging instrument based on Gabor-Domain Optical Coherence Microscopy (GDOCM). Our SBIR Phase I research successfully accomplished all Aims and demonstrated the feasibility of quantitative assessment of corneal tissue over a large field of view with GDOCM. Our Phase I results demonstrated that GDOCM has the following key advantages over existing corneal imaging techniques, which include specular and confocal microscopy: 1) improved accuracy of tissue qualification with 4-10x increase in field of view that reduces sampling error – this will provides a truer assessment of the overall tissue characteristics; 2) ability to simultaneously measure corneal thickness, quantify endothelial cell density, and identify morphological variations due to corneal disease – this will lead to complete corneal evaluation in a single instrument; 3) leveraging machine learning innovations to minimize variability induced by users – this will result in a more objective evaluation; 4) enhanced 3D cellular-level imaging of thin translucent endothelial cells – this will enable a detailed understanding of cell viability. The results of the proposed Phase studies II will demonstrate that GDOCM can provide high-definition, 3D visualization of corneal structures with immediate commercial application for qualification of donor tissue in eye banks, and with a path to in vivo clinical imaging of patients with corneal disease. Current corneal evaluation methods employed at eye banks have limited field of view and/or insufficient resolution, and their results suffer from high subjectivity. We propose to commercialize a Gabor-domain optical coherence microscope to enable non-invasive, high-definition, wide field of view imaging in 3D for eye banks.","High-definition, wide field of view corneal imaging",10172909,R44EY028827,"['3-Dimensional', 'Address', 'Area', 'Assessment tool', 'Blindness', 'Cell Count', 'Cell Density', 'Cell Survival', 'Cell Viability Process', 'Cellular Morphology', 'Characteristics', 'Clinic', 'Confocal Microscopy', 'Cornea', 'Corneal Diseases', 'Disease', 'Endothelial Cells', 'Evaluation', 'Eye', 'Eye Banks', 'Goals', 'Gold', 'Grant', 'Health', 'Human', 'Image', 'Imaging Device', 'Imaging Techniques', 'Industry', 'Infection', 'Innovation Corps', 'International', 'Lead', 'Legal patent', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Microscope', 'Microscopy', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Ophthalmology', 'Optics', 'Organ Transplantation', 'Patient imaging', 'Phase', 'Positioning Attribute', 'Process', 'Research', 'Resolution', 'Rights', 'Sampling', 'Sampling Errors', 'Small Business Innovation Research Grant', 'Standardization', 'Structure', 'Technology', 'Thick', 'Thinness', 'Time', 'Tissue Donors', 'Tissue Transplantation', 'Tissues', 'Training', 'Transplantation', 'United States National Institutes of Health', 'Universities', 'Variant', 'Visual', 'Visual impairment', 'Visual system structure', 'Visualization software', 'base', 'clinical development', 'clinical imaging', 'commercial application', 'density', 'image processing', 'improved', 'in vivo', 'in vivo regeneration', 'innovation', 'instrument', 'instrumentation', 'microscopic imaging', 'multidisciplinary', 'neurosensory', 'novel', 'phase 2 study', 'programs', 'prototype', 'screening', 'three-dimensional visualization', 'tool', 'trend']",NEI,LIGHTOPTECH CORPORATION,R44,2021,741958
"Enhancing the Utility of the Trend-in-Trend Research Design Patients, clinicians, and policymakers often need valid information about the real-world effects of drugs and other exposures for which there have been pronounced time-trends in use. For example, the rapid growth in the use of rofecoxib in the early 2000s and of exogenous testosterone from 2000–2013 was accompanied by an urgent need for knowledge about the cardiovascular effects of those drugs. Randomized trials seldom enroll a sufficient number of subjects, or follow them long enough, to examine associations with rare outcomes. Therefore, non-randomized studies are needed, even though they are susceptible to unmeasured confounding and other forms of bias. To address these limitations of available epidemiologic designs, we recently introduced the trend-in-trend design: a novel, hybrid epidemiologic-ecologic research design that is applicable when there is a prominent trend in the use of the study exposure. Substantial additional development is needed to realize the full public health impact of the trend-in-trend research design. Areas in most need of development include: evaluation of a sequential analysis extension for real-time post-marketing safety surveillance; evaluation of machine learning to specify the trend-in-trend design’s underlying cumulative probability of exposure model; evaluation of dose-response relationships; and evaluation of treatment effect heterogeneity based on baseline patient characteristics. For each of these methodologic needs, we propose an approach for which we will: 1) assess its statistical properties, in particular large-sample validity through asymptotics and finite sample statistical power; 2) evaluate its performance in thorough simulation studies; and 3) proof-test the approach using the known association between rofecoxib-acute myocardial infarction in healthcare data. Finally, we will apply these developments to the unresolved and highly important question of the cardiovascular, cerebrovascular, and thromboembolic effects of exogenous testosterone in men. This study will have broad scientific, clinical, and public health impact by greatly extending the utility of a novel epidemiologic research design with demonstrated validity and is applicable to a broad range of exposures with a prominent trend in use. It will also evaluate the safety of exogenous testosterone, a question of tremendous clinical and public health importance. Examining the safety of prescription drugs is one enormously important application of this design that has the potential to benefit many millions of people. As the trend-in-trend design is also applicable to non-drug exposures that have a pronounced time-trend (e.g., medical procedures, lifestyle factors, environmental exposures, etc.), its potential impact on the population is even broader. This project will enhance the utility of the trend-in-trend research design, a novel hybrid epidemiologic-ecologic design that is applicable to a broad range of exposures with a prominent trend in use. Further, we will leverage these methods developments to study the cardiovascular, cerebrovascular, and thromboembolic safety of exogenous testosterone, unanswered questions of tremendous clinical and public health importance for older adult males.",Enhancing the Utility of the Trend-in-Trend Research Design,10162467,R01AG064589,"['Acute myocardial infarction', 'Address', 'Adoption', 'Area', 'Calendar', 'Cardiovascular system', 'Characteristics', 'Clinical', 'Data', 'Deep Vein Thrombosis', 'Development', 'Dose', 'Drug Prescriptions', 'Effectiveness', 'Elderly', 'Enrollment', 'Environmental Exposure', 'Epidemiologic Research Design', 'Epidemiology', 'Evaluation', 'Healthcare', 'Heart Arrest', 'Heterogeneity', 'Hybrids', 'Hypoglycemia', 'Knowledge', 'Machine Learning', 'Marketing', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Non-Steroidal Anti-Inflammatory Agents', 'Observational Study', 'Odds Ratio', 'Outcome', 'Paper', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Population', 'Prevalence', 'Probability', 'Procedures', 'Property', 'Public Health', 'Pulmonary Embolism', 'Research Design', 'Rofecoxib', 'Safety', 'Sampling', 'Speed', 'Stroke', 'Testing', 'Testosterone', 'Time', 'Time trend', 'To specify', 'Ventricular Arrhythmia', 'base', 'cerebrovascular', 'cohort', 'cyclooxygenase 2', 'design', 'improved', 'lifestyle factors', 'male', 'men', 'method development', 'non-drug', 'novel', 'population health', 'prospective', 'randomized trial', 'rapid growth', 'response', 'safety outcomes', 'simulation', 'time use', 'treatment effect', 'trend', 'trend analysis', 'venous thromboembolism']",NIA,UNIVERSITY OF PENNSYLVANIA,R01,2021,561787
"Inferential methods for functional data from wearable devices Project Summary/Abstract This is a project to develop new statistical methods for comparing groups of subjects in terms of health outcomes that are assessed using data from wearable devices. Inexpensive wearable sensors for health monitoring are now capable of generating massive amounts of data collected longitudinally, up to months at a time. The project will develop inferential methods that can deal with the complexity of such data. A serious challenge is the presence of unmeasured time-dependent confounders (e.g., circadian and dietary patterns), making direct comparisons or borrowing strength across subjects untenable unless the studies are carried out in controlled experimental con- ditions. Generic data mining and machine learning tools have been widely used to provide predictions of health status from such data. However, such tools cannot be used for signiﬁcance testing of covariate effects, which is necessary for designing precision medicine interventions, for example, without taking the inherent model selection or the presence of the unmeasured confounders into account. To overcome these difﬁculties, a systematic de- velopment of inferential methods for functional outcome data obtained from wearable devices will be carried out. There are three speciﬁc aims: 1) Develop metrics for functional outcome data from wearable devices, 2) Develop nonparametric estimation and testing methods for activity proﬁles and a screening method for predictors of activity proﬁles, 3) Implement the methods in an R package and carry out two case studies using accelerometer data. For Aim 1, the approach is to reduce the sensor data to occupation time proﬁles (e.g., as a function of activity level), and formulate the statistical modeling in terms of these proﬁles using survival and functional data analytic meth- ods. This will have a number of advantages, the principal one being that time-dependent confounders become less problematic because the effect of differences in temporal alignment across subjects is mitigated. In addition, survival analysis methods can be applied by viewing the occupation time as a time-to-event outcome indexed by activity level. For Aim 2, nonparametric methods will be used to compare and order occupation time distributions between groups of subjects that are speciﬁed in terms of baseline covariate levels or treatment groups. Further, a new method of post-selection inference based on marginal screening for function-on-scalar regression will be developed to identify and formally test whether covariates are signiﬁcantly associated with activity proﬁles. Aim 3 will develop an R-package implementation, and as a test-bed for the proposed methods they will be applied to two Columbia-based clinical studies: to the study of physical activity in children enrolled in New York City Head Start, and to the study of experimental drugs for the treatment of mitochondrial depletion syndrome. Project Narrative The relevance of the project to public health is that it will develop statistical methods for the physiological eval- uation of patients on the basis of data collected by inexpensive wearable sensors (e.g., accelerometers). By introducing methods for the rigorous comparison of healthcare status among groups of patients observed longi- tudinally over time using such devices, treatment decisions that can beneﬁt targeted populations of patients in terms of continuously-assessed health outcomes will become possible.",Inferential methods for functional data from wearable devices,10135813,R01AG062401,"['Acceleration', 'Accelerometer', 'Beds', 'Bypass', 'Case Study', 'Characteristics', 'Child', 'Clinical Research', 'Computer software', 'Data', 'Data Analytics', 'Development', 'Devices', 'Dietary Practices', 'Drug Combinations', 'Enrollment', 'Evaluation', 'Event', 'Grant', 'Head Start Program', 'Health', 'Health Status', 'Healthcare', 'Intervention', 'Lead', 'Machine Learning', 'Measures', 'Methods', 'Mitochondria', 'Modeling', 'Molecular', 'Monitor', 'Motivation', 'Nature', 'New York City', 'Obesity', 'Occupations', 'Outcome', 'Outcome Measure', 'Patients', 'Pharmacotherapy', 'Physical activity', 'Physiological', 'Preschool Child', 'Process', 'Proxy', 'Public Health', 'Recording of previous events', 'Regimen', 'Signal Transduction', 'Specific qualifier value', 'Statistical Methods', 'Statistical Models', 'Stochastic Processes', 'Survival Analysis', 'Syndrome', 'Target Populations', 'Techniques', 'Testing', 'Time', 'Work', 'analytical method', 'base', 'circadian', 'data mining', 'design', 'experimental study', 'functional outcomes', 'indexing', 'interest', 'lower income families', 'novel', 'patient population', 'precision medicine', 'screening', 'sensor', 'theories', 'time use', 'tool', 'treatment group', 'wearable device', 'wearable sensor technology']",NIA,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,298890
"New Jersey Alliance for Clinical Translational Science: NJ ACTS Contact PD/PI: Panettieri, Reynold Alexander Project Summary/Abstract Overview Coordinated by Rutgers Biomedical and Health Sciences (RBHS), the New Jersey Alliance for Clinical and Translational Science (NJ ACTS) comprises a consortium with Rutgers and Princeton Universities (PU), NJ Institute for Technology (NJIT), medical, nursing, dental and public health schools, hospitals, community health centers, outpatient practices, industry, policymakers and health information exchanges. All Alliance universities and affiliates have provided substantial resources and contributed to the planning, development and leadership of the consortium. With access to ~7 million people, NJ ACTS serves as a ‘natural laboratory’ for translational and clinical research. With a state population of ~9 million, New Jersey ranks 11th in the US, 1st in population density and higher than average in racial and ethnic diversity. Surprisingly, NJ has no CTSA Hub to coordinate translational and clinical research. Our CTSA Hub focuses on two overarching themes: the heterogeneity of disease pathogenesis and response to treatment, and the value of linking large clinical databases with interventional clinical investigations to identify cause-and-effect and predict therapeutic responses. NJ ACTS will provide: innovative approaches to link information from large databases and electronic health records to inform clinical trial design, execution and analysis; and novel platforms for biomarker discovery using fluorescence in situ hybridization and machine learning to identify unique neural signatures of chronic illness. NJ ACTS will access a large health system with significant member diversity; a rich legacy of community engagement and community-based research platforms; and proven approaches to enhance workforce development in clinical research. With a substantial investment in streamlining research administration and IRB practices at Rutgers and with the inception of NJ ACTS, there exists an unparalleled opportunity for logarithmic growth in clinical research in New Jersey. To build our capacity for participant and clinical interactions as a CTSA Hub, the newly established Trial Accelerator and Recruitment Office will coordinate feasibility assessment, implementation, recruitment, and evaluation of clinical studies. Additionally, our organization of five clinical research units into a cohesive network provides extraordinary expertise in strategic locations to enhance participant recruitment from diverse communities with a particular focus on: children; the elderly; those with serious mental illness or substance abuse issues; low-income individuals served by Medicaid; those with HIV/AIDS; and people of all ages who are minorities, underserved, and victims of health and environmental disparities. With a history of collaboration, partners and affiliates share unique skills, expertise, training and mentoring capabilities that will be greatly amplified within the infrastructure of a CTSA Hub. Princeton and NJIT, without medical schools or hospital affiliates, seeks collaboration with Rutgers to provide clinical research platforms; Rutgers seeks the PU and NJIT expertise in novel informatics platforms, expertise in natural language and ontology, machine learning and cognitive neurosciences. Together NJ ACTS will provide an alliance that will catalyze clinical research and training across New Jersey to improve population health and contribute to the CTSA Consortium. In this revised application, the overall themes remain unchanged but Cores leadership and direction has been markedly refined. Page 337 Project Summary/Abstract Contact PD/PI: Panettieri, Reynold Alexander New Jersey Alliance for Clinical and Translational Science (NJ ACTS) Project Narrative The New Jersey Alliance for Clinical and Translational Science (NJ ACTS), as a member of the CTSA Consortium, unites Rutgers University, Princeton University, the New Jersey Institute of Technology, clinical, community and industry partners in a shared vision to make New Jersey a healthier state. Building on New Jersey’s already significant capabilities to promote and facilitate clinical and translational research, NJ ACTS will serve as a catalyst, inspiring new approaches to diagnose and manage disease, and fostering career development of the next generation of translational researchers, and promoting population health.",New Jersey Alliance for Clinical Translational Science: NJ ACTS,10360219,UL1TR003017,"['AIDS/HIV problem', 'Address', 'Affect', 'Age', 'Asian Indian', 'Behavioral', 'Biometry', 'Child', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cohort Studies', 'Collaborations', 'Communities', 'Cuban', 'Databases', 'Dental', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline of Nursing', 'Disease Management', 'Diverse Workforce', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Fluorescent in Situ Hybridization', 'Fostering', 'Foundations', 'Government', 'Growth', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitals', 'Image', 'Improve Access', 'Individual', 'Industry', 'Informatics', 'Infrastructure', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Investigation', 'Investments', 'Laboratories', 'Leadership', 'Life Style', 'Link', 'Location', 'Longevity', 'Low income', 'Machine Learning', 'Medicaid', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Minority', 'Minority Groups', 'Mission', 'Muslim population group', 'Neighborhood Health Center', 'New Jersey', 'Not Hispanic or Latino', 'Ontology', 'Oral health', 'Outpatients', 'Parents', 'Participant', 'Pathogenesis', 'Patient Recruitments', 'Perception', 'Population', 'Population Density', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Preventive Intervention', 'Process', 'Public Health', 'Public Health Schools', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'School Nursing', 'Science', 'Solid', 'South Asian', 'Special Populations Research', 'Substance abuse problem', 'Technology', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Universities', 'Vision', 'Workforce Development', 'analytical tool', 'base', 'biomarker discovery', 'career development', 'catalyst', 'clinical care', 'clinical database', 'clinical investigation', 'cognitive neuroscience', 'cohesion', 'community based participatory research', 'disease heterogeneity', 'ethnic diversity', 'ethnic minority population', 'experience', 'follower of religion Jewish', 'improved', 'industry partner', 'innovation', 'interdisciplinary approach', 'logarithm', 'medical schools', 'member', 'natural language', 'next generation', 'novel', 'novel strategies', 'population health', 'programs', 'racial diversity', 'racial minority', 'recruit', 'relating to nervous system', 'research clinical testing', 'response', 'severe mental illness', 'skills', 'success', 'tool', 'translational scientist', 'treatment response', 'trial design']",NCATS,RUTGERS BIOMEDICAL/HEALTH SCIENCES-RBHS,UL1,2021,1200946
"New Jersey Alliance for Clinical Translational Science: NJ ACTS Contact PD/PI: Panettieri, Reynold Alexander Project Summary/Abstract Overview Coordinated by Rutgers Biomedical and Health Sciences (RBHS), the New Jersey Alliance for Clinical and Translational Science (NJ ACTS) comprises a consortium with Rutgers and Princeton Universities (PU), NJ Institute for Technology (NJIT), medical, nursing, dental and public health schools, hospitals, community health centers, outpatient practices, industry, policymakers and health information exchanges. All Alliance universities and affiliates have provided substantial resources and contributed to the planning, development and leadership of the consortium. With access to ~7 million people, NJ ACTS serves as a ‘natural laboratory’ for translational and clinical research. With a state population of ~9 million, New Jersey ranks 11th in the US, 1st in population density and higher than average in racial and ethnic diversity. Surprisingly, NJ has no CTSA Hub to coordinate translational and clinical research. Our CTSA Hub focuses on two overarching themes: the heterogeneity of disease pathogenesis and response to treatment, and the value of linking large clinical databases with interventional clinical investigations to identify cause-and-effect and predict therapeutic responses. NJ ACTS will provide: innovative approaches to link information from large databases and electronic health records to inform clinical trial design, execution and analysis; and novel platforms for biomarker discovery using fluorescence in situ hybridization and machine learning to identify unique neural signatures of chronic illness. NJ ACTS will access a large health system with significant member diversity; a rich legacy of community engagement and community-based research platforms; and proven approaches to enhance workforce development in clinical research. With a substantial investment in streamlining research administration and IRB practices at Rutgers and with the inception of NJ ACTS, there exists an unparalleled opportunity for logarithmic growth in clinical research in New Jersey. To build our capacity for participant and clinical interactions as a CTSA Hub, the newly established Trial Accelerator and Recruitment Office will coordinate feasibility assessment, implementation, recruitment, and evaluation of clinical studies. Additionally, our organization of five clinical research units into a cohesive network provides extraordinary expertise in strategic locations to enhance participant recruitment from diverse communities with a particular focus on: children; the elderly; those with serious mental illness or substance abuse issues; low-income individuals served by Medicaid; those with HIV/AIDS; and people of all ages who are minorities, underserved, and victims of health and environmental disparities. With a history of collaboration, partners and affiliates share unique skills, expertise, training and mentoring capabilities that will be greatly amplified within the infrastructure of a CTSA Hub. Princeton and NJIT, without medical schools or hospital affiliates, seeks collaboration with Rutgers to provide clinical research platforms; Rutgers seeks the PU and NJIT expertise in novel informatics platforms, expertise in natural language and ontology, machine learning and cognitive neurosciences. Together NJ ACTS will provide an alliance that will catalyze clinical research and training across New Jersey to improve population health and contribute to the CTSA Consortium. In this revised application, the overall themes remain unchanged but Cores leadership and direction has been markedly refined. Page 337 Project Summary/Abstract Contact PD/PI: Panettieri, Reynold Alexander New Jersey Alliance for Clinical and Translational Science (NJ ACTS) Project Narrative The New Jersey Alliance for Clinical and Translational Science (NJ ACTS), as a member of the CTSA Consortium, unites Rutgers University, Princeton University, the New Jersey Institute of Technology, clinical, community and industry partners in a shared vision to make New Jersey a healthier state. Building on New Jersey’s already significant capabilities to promote and facilitate clinical and translational research, NJ ACTS will serve as a catalyst, inspiring new approaches to diagnose and manage disease, and fostering career development of the next generation of translational researchers, and promoting population health.",New Jersey Alliance for Clinical Translational Science: NJ ACTS,10115156,UL1TR003017,"['AIDS/HIV problem', 'Address', 'Affect', 'Age', 'Asian Indian', 'Behavioral', 'Biometry', 'Child', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Clinical Trials Design', 'Cohort Studies', 'Collaborations', 'Communities', 'Cuban', 'Databases', 'Dental', 'Development', 'Diagnosis', 'Diagnostic', 'Discipline of Nursing', 'Disease Management', 'Diverse Workforce', 'Elderly', 'Electronic Health Record', 'Evaluation', 'Fluorescent in Situ Hybridization', 'Fostering', 'Foundations', 'Government', 'Growth', 'Health', 'Health Insurance Portability and Accountability Act', 'Health Sciences', 'Health system', 'Healthcare', 'Hospitals', 'Image', 'Improve Access', 'Individual', 'Industry', 'Informatics', 'Infrastructure', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Investigation', 'Investments', 'Laboratories', 'Leadership', 'Life Style', 'Link', 'Location', 'Longevity', 'Low income', 'Machine Learning', 'Medicaid', 'Medical', 'Mentors', 'Methodology', 'Methods', 'Minority', 'Minority Groups', 'Mission', 'Muslim population group', 'Neighborhood Health Center', 'New Jersey', 'Not Hispanic or Latino', 'Ontology', 'Oral health', 'Outpatients', 'Parents', 'Participant', 'Pathogenesis', 'Patient Recruitments', 'Perception', 'Population', 'Population Density', 'Precision therapeutics', 'Prediction of Response to Therapy', 'Preventive Intervention', 'Process', 'Public Health', 'Public Health Schools', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Training', 'Resources', 'School Nursing', 'Science', 'Solid', 'South Asian', 'Special Populations Research', 'Substance abuse problem', 'Technology', 'Therapeutic Intervention', 'Training', 'Translational Research', 'Universities', 'Vision', 'Workforce Development', 'analytical tool', 'base', 'biomarker discovery', 'career development', 'catalyst', 'clinical care', 'clinical database', 'clinical investigation', 'cognitive neuroscience', 'cohesion', 'community based participatory research', 'disease heterogeneity', 'ethnic diversity', 'ethnic minority population', 'experience', 'follower of religion Jewish', 'improved', 'industry partner', 'innovation', 'interdisciplinary approach', 'logarithm', 'medical schools', 'member', 'natural language', 'next generation', 'novel', 'novel strategies', 'population health', 'programs', 'racial diversity', 'racial minority', 'recruit', 'relating to nervous system', 'research clinical testing', 'response', 'severe mental illness', 'skills', 'success', 'tool', 'translational scientist', 'treatment response', 'trial design']",NCATS,RUTGERS BIOMEDICAL/HEALTH SCIENCES-RBHS,UL1,2021,4648239
"Next-generation Monte Carlo eXtreme Light Transport Simulation Platform Project Summary/Abstract Abstract: The rapid evolution of the field of biophotonics has produced numerous emerging techniques for combatting diseases and addressing urgent human health challenges, offering safe, non-invasive, and portable light-based diagnostic and therapeutic methods, and attracting exponentially growing attention over the past decade. Rigorous, fast, versatile and publicly available computational tools have played pivotal roles in the success of these novel approaches, leading to breakthroughs in new instrumentation designs and extensive explorations of complex biological systems such as human brains. The Monte Carlo eXtreme (MCX, http://mcx.space) light transport simulation platform developed by our team has become one of the most widely disseminated biophotonics modeling platforms, known for its high accuracy, high speed and versatility, as attested to by its over 27,000 downloads and nearly 1,000 citations from a large (2,400+ registered users) world-wide user community. Over the past years, we have also been pushing the boundaries in cutting-edge Monte Carlo (MC) photon simulation algorithms by exploring modern GPU architectures, advanced anatomical modeling methods and systematic software optimizations. In this proposed project, we will build upon the strong momentum created in the initial funding period, and strive to further advance the state-of-the-art of GPU-accelerated MC light transport modeling with strong support from the world’s leading GPU manufacturers and experts, further expanding our platform to address a number of emerging challenges in biomedical optics applications. Specifically, we will further explore emerging GPU architecture and resources, such as ray- tracing cores, half- and mixed-precision hardware, and portable programming models, to further accelerate the MC modeling speed. We will also develop hybrid shape/mesh-based MC algorithms to dramatically advance the capability in simulating extremely complex yet realistic anatomical structures, such as porous tissues in the lung, dense vessel networks in the brain, and multi-scaled tissue domains. In parallel, we aim to make a break- through in applying deep-learning-based image denoising techniques to equivalently accelerate MC simulations by 2 to 3 orders of magnitudes, as suggested in our preliminary studies. In the continuation of this project, we strive to create a dynamic and community-engaging simulation environment by extending our software to allow users to create, share, browse, and reuse pre-configured simulations, avoiding redundant works in re-creating complex simulations and facilitating reproducible research. In addition, we will expand our well-received user training programs and widely disseminate our open-source tools via major Linux distributions and container images. At the end of this continued funding period, we will provide the community with a significantly accelerated, widely-available and well-supported biophotonics modeling platform that can handle multi-scaled tissue optical modeling ranging from microscopic to macroscopic domains. Project Narrative The Monte Carlo eXtreme (MCX) light transport modeling platform has quadrupled its user community and paper citation numbers during the initial funding period. Building upon this strong momentum, we aim to further explore computational acceleration enabled by emerging GPU architectures and resources, and spearhead novel Monte Carlo (MC) algorithms to address the emerging needs of a broad biophotonics research community. We also dedicate our efforts to the further dissemination, training and usability enhancement of our software, and provide timely support to our large (>2,400 registered users) and active (>300 mailing list subscribers) user community.",Next-generation Monte Carlo eXtreme Light Transport Simulation Platform,10228757,R01GM114365,"['Acceleration', 'Address', 'Adopted', 'Algorithms', 'Anatomic Models', 'Anatomy', 'Architecture', 'Attention', 'Benchmarking', 'Biophotonics', 'Brain', 'Communities', 'Complex', 'Computer software', 'Data', 'Development', 'Diagnostic', 'Disease', 'Documentation', 'Educational workshop', 'Environment', 'Evolution', 'Funding', 'Future Generations', 'Health', 'Human', 'Hybrids', 'Image', 'Industry', 'Letters', 'Libraries', 'Light', 'Linux', 'Lung', 'Manufacturer Name', 'Methods', 'Microscopic', 'Modality', 'Modeling', 'Modernization', 'Monte Carlo Method', 'Motivation', 'Online Systems', 'Optics', 'Output', 'Paper', 'Performance', 'Photons', 'Play', 'Readability', 'Reproducibility', 'Research', 'Resource Sharing', 'Resources', 'Role', 'Shapes', 'Speed', 'Techniques', 'Therapeutic', 'Time', 'Tissues', 'Tracer', 'Training', 'Training Programs', 'Training Support', 'United States National Institutes of Health', 'Work', 'base', 'complex biological systems', 'computerized tools', 'cost', 'data standards', 'deep learning', 'denoising', 'design', 'flexibility', 'graphical user interface', 'improved', 'instrumentation', 'interoperability', 'next generation', 'novel', 'novel strategies', 'open data', 'open source', 'portability', 'rapid growth', 'simulation', 'simulation environment', 'software development', 'success', 'tool', 'usability']",NIGMS,NORTHEASTERN UNIVERSITY,R01,2021,349146
"Academy of Aphasia Research and Training Symposium PROJECT SUMMARY/ABSTRACT The annual Academy of Aphasia meeting is the premier conference for researchers in the field of language processing and aphasia. Since the first meeting in 1963, this international meeting has brought together an interdisciplinary group of linguists, psychologists, neurologists, and speech-language pathologists to discuss the latest research in the field of aphasia, including theoretical, clinical, and rehabilitation aspects of this language disorder. The topics at the conference range widely but almost always cover all aspects of language processing including phonological processing, lexical-semantic processing, syntactic processing, orthographic processing, bilingualism, computational modeling, non-invasive and invasive brain imaging, language recovery, neuroplasticity, and rehabilitation. In this proposal, we aim to include two special initiatives that will take place during the annual academy of aphasia conference. The first initiative involves a formal mentoring program for young investigators entering the field of aphasia research. In this program, selected student/post-doctoral fellows from interdisciplinary backgrounds who are first authors at the conference are paired with a mentor. This mentor will provide specific feedback about the fellow's presentation and general mentorship to the fellow about research and academic careers. This program is currently occurring as part of the conference and has been growing at the annual meeting with very positive feedback. Additionally, a formal mentoring meeting will allow a structured format for discussion about a career in aphasia research. The second initiative will be a three hour seminar (New Frontiers in Aphasia Research) that covers the background and approach of a state of the art methodology (e.g., fNIRS, graph theoretical metric, machine learning approaches) that has an application to the study of aphasia. These workshops will be recorded and, consequently, uploaded to the academy website/youtube channel for dissemination to aphasia researchers and the public. This workshop will allow conference attendees to understand the conceptual and methodological aspect of a particular scientific approach that can be implemented in their study of aphasia. Given the highly interdisciplinary nature of aphasia research, these workshops will bridge the communication between aphasia researchers and scientists and experts who have developed new approaches to study the brain. This meeting already allows a valuable opportunity for cross-pollination of research ideas and will now provide a platform for the training the next generation of scientists interested in pursuing the nature of aphasia and associated language disorders in adults. PROJECT NARRATIVE Approximately 100,000 individuals suffer from aphasia each year. The academy of aphasia is an organization of clinicians, scientists and practitioners who study this communication disorder and develop interventions to treat individuals with aphasia. The members comprise a very interdisciplinary group of linguists, psychologists, speech and language clinicians, neurologists and neuroscientists. The annual academy of aphasia meeting is the premier venue to share state of the art methodologies for application in the study of aphasia to improve the research in the development of diagnosis and treatment approaches to alleviate aphasia. This conference is also the ideal venue to educate and train the next generation of aphasia researchers who are well trained from a theoretical, technical and clinical standpoint and are committed to expand the impact of research in aphasia.",Academy of Aphasia Research and Training Symposium,10194459,R13DC017375,"['Academy', 'Adult', 'Aphasia', 'Brain', 'Brain imaging', 'Chicago', 'Clinical', 'Collaborations', 'Committee Membership', 'Communication', 'Communication impairment', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Discipline', 'Educational workshop', 'Feedback', 'Fellowship', 'Fostering', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Governing Board', 'Grant', 'Graph', 'Hour', 'Image', 'Individual', 'International', 'Intervention', 'Language', 'Language Disorders', 'Learning', 'Lesion', 'Linguistics', 'Machine Learning', 'Manuscripts', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Mission', 'National Institute on Deafness and Other Communication Disorders', 'Nature', 'Neurologic', 'Neurologist', 'Neuronal Plasticity', 'Neurosciences', 'Non-aphasic', 'Orthography', 'Outcome', 'Pathologist', 'Positioning Attribute', 'Postdoctoral Fellow', 'Production', 'Psychologist', 'Psychology', 'Publishing', 'Reading', 'Recovery', 'Rehabilitation therapy', 'Research', 'Research Personnel', 'Research Support', 'Research Training', 'Rest', 'Retrieval', 'Scientist', 'Secure', 'Speech', 'Speech Pathologist', 'Speech Perception', 'Stroke', 'Structure', 'Students', 'Symptoms', 'Techniques', 'Testing', 'Time', 'Training', 'Training and Education', 'Transcranial magnetic stimulation', 'Travel', 'Videotape', 'Work', 'Writing', 'base', 'bilingualism', 'career', 'career networking', 'experience', 'frontier', 'improved', 'improved outcome', 'interest', 'language processing', 'lexical', 'meetings', 'member', 'neuroimaging', 'next generation', 'novel', 'novel strategies', 'outcome forecast', 'phonology', 'programs', 'relating to nervous system', 'semantic processing', 'success', 'symposium', 'syntax', 'tenure track', 'web site']",NIDCD,BOSTON UNIVERSITY (CHARLES RIVER CAMPUS),R13,2021,39939
"Detection and characterization of critical under-immunized hotspots Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots,10197938,R01GM109718,"['Affect', 'Bayesian Method', 'Behavioral Model', 'California', 'Characteristics', 'Communicable Diseases', 'Communities', 'Computer Models', 'Computing Methodologies', 'Country', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Disease model', 'Economic Burden', 'Economics', 'Epidemic', 'Epidemiology', 'Exhibits', 'Funding', 'Geography', 'Growth', 'Health', 'Health Personnel', 'Herd Immunity', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Individual', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Measles-Mumps-Rubella Vaccine', 'Medical', 'Methodology', 'Methods', 'Minnesota', 'Modeling', 'New Jersey', 'New York', 'Oregon', 'Outcome', 'Pathway interactions', 'Policies', 'Policy Maker', 'Population', 'Population Analysis', 'Privatization', 'Public Health', 'Records', 'Registries', 'Resolution', 'Resource Allocation', 'Resources', 'Risk', 'Scanning', 'Schools', 'Science', 'Source', 'System', 'Systems Analysis', 'Techniques', 'Time', 'Uncertainty', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Washington', 'Work', 'base', 'data mining', 'demographics', 'diverse data', 'economic cost', 'economic outcome', 'health care delivery', 'health disparity', 'health organization', 'improved', 'interest', 'novel', 'novel strategies', 'population based', 'provider networks', 'public health intervention', 'social', 'social media', 'spatiotemporal', 'statistics', 'tool', 'transmission process', 'vaccine hesitancy']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,321062
"Development of assistive self-care robot technologies for people with disabilities Towards Autonomy in Daily Living: A Formalism for Intelligent Assistive Feeding Systems  Applicant PI, Tapomayukh Bhattacharjee Overview We propose to develop a design space framework and co-design methodology for the development of assistive self-care robot technologies that are informed by the social model of disability. Our model of assistive robots in the domain of self-care considers an individual's social and environmental context, coping processes and other factors that can affect independent functioning. Our design methods utilize embedded sensing to intelligently respond to these con- siderations. We speciﬁcally focus on assistive feeding tasks, proposing a formalism that enables a robotic system to feed a person with upper-extremity disability. Our guiding principle is that human-level interaction is feasible only if the robot itself relies on human-level semantics. We im- plement this principle by relying on data to learn and develop object-dependent control policies and timing models for acquiring and transferring a bite to a user at a proper time. The system's ob- server detects world states and arbitrator invokes different control policies based on these states. The tangible result will be an intelligent assistive feeding robot whose performance can generalize to different activities, adapt to user preferences, and recover from failures. Objectives and Relevance to NIH A design framework for assistive robots would provide for- malisms that let us address the fundamental challenge of designing robots that are responsive to context of use and support assisted self-care in a variety of social settings. We combine method- ologies from human-robot interaction, cognitive science, machine learning, robotics and haptics with user studies and our formalism to address the following research questions: (Q1) Mechanics of Feeding-Control Policies: How can control policies be designed for dexterous non-prehensile manipu- lation of deformable objects such as food? (Q2) Social Aspects of Feeding-Bite Timing: How should an assistive feeding robot decide the right timing for feeding a user? (Q3) Human-in-the-Loop: How can human-directed feedback be added into the loop for an autonomous assistive feeding system?  The proposed work will allow users with upper-arm disabilities to use this system for intelli- gent assistance with daily feeding tasks. This can in turn help them increase their independence and autonomy making eating easier and more enjoyable. While we presently focus on this spe- ciﬁc application, the tools and insights we gain can generalize to the ﬁelds of robotic assistance and human-robot interaction across other activities of daily living and instrumental activities of daily living. Thus, our work is clearly motivated by the intent to improve the quality of health and life of the aging population and is very relevant to the theme of NIH. 1 Towards Autonomy in Daily Living: A Formalism for Intelligent Assistive Feeding Systems  Applicant PI, Tapomayukh Bhattacharjee  The proposed work will allow users with upper-arm disabilities to use this system for intelli- gent assistance with daily feeding tasks, potentially increasing their independence and autonomy making eating easier and more enjoyable. The long-term promise of this research is to have robots in society that are able to seamlessly and ﬂuently perform complex manipulation tasks in dynamic human environments in real homes which could impact individuals with other disabilities as well as able-bodied individuals. Through improved access to independent living and customizing to the unique needs and preferences of users, the results of this project can positively impact mil- lions of people worldwide, especially given the vast variability in our target population by being transformational in the scalability of assistive robotics for self-care. 1",Development of assistive self-care robot technologies for people with disabilities,10232054,F32HD101192,"['Activities of Daily Living', 'Address', 'Affect', 'Aging', 'Bathing', 'Bite', 'Caregiver Burden', 'Caring', 'Child', 'Cognitive Science', 'Communities', 'Complex', 'Cues', 'Custom', 'Data', 'Development', 'Disabled Persons', 'Eating', 'Emotional', 'Environment', 'Expert Systems', 'Failure', 'Family', 'Feedback', 'Food', 'Generations', 'Health', 'Home environment', 'Human', 'Improve Access', 'Independent Living', 'Individual', 'Intelligence', 'Learning', 'Life', 'Machine Learning', 'Mechanics', 'Mental Depression', 'Methodology', 'Methods', 'Modeling', 'Panthera leo', 'Parents', 'Performance', 'Persons', 'Play', 'Policies', 'Population', 'Process', 'Quality of life', 'Research', 'Robot', 'Robotics', 'Role', 'Self Care', 'Semantics', 'Societies', 'Sterile coverings', 'System', 'Target Populations', 'Taxonomy', 'Technology', 'Time', 'Tweens', 'United States National Institutes of Health', 'Upper Extremity', 'Upper arm', 'Work', 'aging population', 'assistive robot', 'base', 'care recipients', 'coping', 'design', 'disability', 'experience', 'experimental study', 'feeding', 'haptics', 'human subject', 'human-in-the-loop', 'human-robot interaction', 'improved', 'insight', 'instrumental activity of daily living', 'intergenerational', 'kinematics', 'patient oriented', 'peer', 'preference', 'robot assistance', 'robotic system', 'social', 'social model', 'tool']",NICHD,UNIVERSITY OF WASHINGTON,F32,2021,68562
"Effects of Lifetime Noise Exposure Viewed Through the Brainstem Reflex Bifocals: Middle Ear Muscle Reflex and Medial Olivocochlear Reflex Project Summary Noise-induced hearing loss (NIHL) affects nearly one in four adults in the United States. With recent discov- eries pertaining to cochlear synaptopathy and outer hair cell (OHC) loss in the extended high frequencies, it is clear that much of the early NIHL remains `hidden' under traditional audiological scrutiny. Without early de- tection and intervention, such damage can progress into more severe hearing loss. Thus a critical window for therapeutics/lifestyle changes may go unutilized. However, there are currently no feasible tools that can identify early hearing damage. Prior studies that test the integrity of the auditory afferent pathway have not produced conclusive results. However, short- and long-term noise exposure-related peripheral damage are correlated with changes in the auditory efferent system. Speciﬁcally, hyperactivity in the medial olivocochlear reﬂex (MOCR) and threshold elevation of the middle ear muscle reﬂex (MEMR) have been reported. Given the protective roles of the MOCR and the MEMR through inhibition of peripheral inputs, and their differential changes with damage, we argue that a combined assay of MOCR and MEMR may serve as a marker for early hearing damage in humans.  Using a novel otoacoustic emission (OAE)-based efferent assay, in the proposed studies we aim to (1) eval- uate long-term age-speciﬁc changes in efferent and afferent function due to noise exposure and (2) evaluate short-term changes in efferent and afferent function due to noise exposure. We will investigate the concurrent working of the two reﬂexes across a wide age range (18-50 years) and noise exposure by recruiting individuals from high noise exposure (musicians, veterans, construction workers, farmer) and low noise exposure occupa- tions (students, professors). To evaluate short-term changes due to noise exposure, we will test participants before and after their typical work day. For reliable exposure stratiﬁcation, noise exposure will be objectively quantiﬁed using 5-day sound dosimetry. We will also use the most sensitive afferent measures to allow compari- son with efferent measures. Machine learning approaches will be employed to ascertain relationships among the cochlear, afferent, and efferent function for short- and long-term noise exposures.  Findings from project 1 will reveal if the combined MOCR and MEMR metrics can delineate noise exposure effects from aging, and highlight the relationships among cochlear, afferent, and efferent measures. Findings from project 2 will reveal if long-term noise exposure predicts short-term changes following noise exposure and vice- versa. A better understanding of short- and long-term changes in the auditory system following noise exposure will aid in the development of (1) an objective rapid screening test of the auditory efferents capable of detecting noise exposure-related hearing damage and (2) a statistical model to enable predicting impending damage based on efferent function. Together, these tools will contribute to early detection and promote hearing conservation. Project Narrative This study will investigate the role of the auditory efferents, the medial olivocochlear reﬂex (MOCR) and the middle ear muscle reﬂex (MEMR), in short- and long-term noise exposure-related changes in the auditory system. Additionally, statistical models will be developed to understand the relationship between efferent and afferent candidate measures of hearing damage. The outcomes of this study will lay the foundation for a screening test of early hearing damage based on the integrity of the auditory efferent system.",Effects of Lifetime Noise Exposure Viewed Through the Brainstem Reflex Bifocals: Middle Ear Muscle Reflex and Medial Olivocochlear Reflex,10204332,R21DC018108,"['Accounting', 'Adult', 'Affect', 'Afferent Pathways', 'Age', 'Auditory', 'Auditory system', 'Behavioral', 'Bilateral', 'Biological Assay', 'Brain Stem', 'Clinical', 'Cochlea', 'Cohort Studies', 'Control Groups', 'Data', 'Development', 'Early Diagnosis', 'Exposure to', 'Foundations', 'Frequencies', 'Goals', 'Growth', 'Hearing', 'Hearing Protection', 'Hearing Tests', 'Human', 'Hyperactive behavior', 'Individual', 'Intervention', 'Kinetics', 'Legal patent', 'Life Style', 'Long-Term Effects', 'Machine Learning', 'Measures', 'Medial', 'Methodology', 'Methods', 'Noise', 'Noise-Induced Hearing Loss', 'Occupational', 'Occupational Noise', 'Occupations', 'Outcome Study', 'Outer Hair Cells', 'Participant', 'Peripheral', 'Protocols documentation', 'Rapid screening', 'Reflex action', 'Reporting', 'Role', 'Screening procedure', 'Statistical Models', 'Stratification', 'Students', 'System', 'Temporary Threshold Shift', 'Testing', 'Time', 'United States', 'Veterans', 'Work', 'age effect', 'age group', 'age related', 'base', 'clinically translatable', 'cochlear synaptopathy', 'conditioning', 'demographics', 'dosimetry', 'ear muscle', 'farmer', 'hearing impairment', 'middle ear', 'musician', 'normal hearing', 'novel', 'otoacoustic emission', 'professor', 'recruit', 'response', 'screening', 'sound', 'therapeutic lifestyle change', 'tool']",NIDCD,UNIVERSITY OF WISCONSIN-MADISON,R21,2021,155333
"Data-Driven Learning Framework for Fast Quantitative Knee Joint Mapping PROJECT SUMMARY Osteoarthritis (OA), a leading cause of chronic disability in the elderly population, occurs with the degradation of the extracellular matrix of articular cartilage, mainly composed of proteoglycan, collagen fibers, and water. Early diagnosis of cartilage degeneration requires the detection of changes in proteoglycan concentration and collagen integrity, preferably non-invasively and before any morphological changes occur. Spin-spin relaxation time (T2) and spin-lattice relaxation time in the rotating frame (T1ρ) can provide quantitative information about the structure and biochemical composition of the cartilage before morphological changes occur. Mono-exponential (ME) models can characterize the T2 and T1ρ relaxation processes and map it for articular cartilage in the knee joint. A recent meta-analysis showed that T1ρ provides more discrimination than T2 for OA. However, the ME model alone cannot provide distinct information from different compartments of the cartilage. Recent studies have shown that T1ρ relaxation might have bi-exponential (BE) components, following the hypothesis of the multi- compartmental structure of the cartilage. BE T2 relaxation has shown better diagnostic performance than ME for OA and can show the dispersion of the relaxation times, reflecting the heterogeneity in the macromolecular environment of water in the cartilage. BE analysis of cartilage typically requires a larger number of acquisitions with different spin-lock times (TSLs) or echo times (TEs), resulting in long scan time. High spatial resolution is also needed to visualize the thin and curved cartilage and fine structures in the knee joint. As a result, in vivo application of BE three-dimensional (3D) T1ρ and T2 mapping techniques is still very limited. Compressed sensing (CS) combined with parallel imaging (PI) can accelerate acquisition and reduce the scan time required for ME 3D T1ρ and T2 mappings. T1ρ scans can be reduced from 30 min to ~3 min with an error smaller than 6.5%. However, the error is two to three times larger for BE mapping. This problem can be potentially solved by optimizing the sampling times (TSLs for T1ρ and TEs for T2) and the free parameters of the CS approach (k- space sampling pattern, regularization function, regularization parameter, and minimization algorithm parameters) using fully sampled 3D knee joint datasets, supported by machine learning tools. The overarching goal of this proposal is to develop, optimize, and translate a high-spatial-resolution, rapid 3D magnetic resonance imaging sequence using data-driven learning-based CS for assessment of the human knee joint and using ME and BE 3D T1ρ (T2) mapping for improved biochemical characterization of cartilage and menisci on a standard clinical 3T scanner. PROJECT NARRATIVE Osteoarthritis of the knee is a leading cause of disability in elderly people, and no curative treatments exist. Early detection of osteoarthritis might help delay or prevent the onset of disability later in life. We propose a rapid and robust approach for the quantitative multi-compartment assessment of knee cartilage without using either exogenous contrast agent or hardware modifications as an early screening tool for osteoarthritis.",Data-Driven Learning Framework for Fast Quantitative Knee Joint Mapping,10296235,R01AR078308,"['3-Dimensional', 'Acceleration', 'Affect', 'Algorithms', 'Biochemical', 'Biological Models', 'Cartilage', 'Chronic', 'Clinical', 'Clinical Protocols', 'Collagen', 'Collagen Fiber', 'Contrast Media', 'Data', 'Data Set', 'Degenerative polyarthritis', 'Detection', 'Diagnostic', 'Discrimination', 'Early Diagnosis', 'Elderly', 'Evaluation', 'Extracellular Matrix', 'Extracellular Matrix Degradation', 'Future', 'Goals', 'Heterogeneity', 'Human', 'Hydration status', 'Image', 'Imaging Techniques', 'Knee', 'Knee Osteoarthritis', 'Knee joint', 'Learning', 'Life', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maps', 'Meniscus structure of joint', 'Meta-Analysis', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Musculoskeletal', 'Pathologic Processes', 'Patients', 'Pattern', 'Performance', 'Population', 'Process', 'Proteoglycan', 'Protocols documentation', 'Relaxation', 'Research Personnel', 'Resolution', 'Sampling', 'Scanning', 'Screening procedure', 'Slice', 'Structure', 'T2 weighted imaging', 'Techniques', 'Therapeutic Agents', 'Thick', 'Thinness', 'Time', 'Tissue Engineering', 'Tissues', 'Translating', 'Validation', 'Water', 'articular cartilage', 'base', 'cartilage degradation', 'curative treatments', 'design', 'disability', 'early screening', 'efficacy evaluation', 'healing', 'human data', 'improved', 'in vivo', 'learning algorithm', 'macromolecule', 'prevent', 'reconstruction', 'repaired', 'tool', 'water environment']",NIAMS,NEW YORK UNIVERSITY SCHOOL OF MEDICINE,R01,2021,531779
"Longer term effects of a natural disaster on health and socio-economic status Abstract Exposures to extreme events are increasingly common in many parts of the globe as a function of changes in weather patterns combined with rising sea levels, but there is a paucity of data to support scientific research on the implications of such exposures for population health and well-being over the long-term. STAR, the Study of the Tsunami Aftermath and Recovery, is a unique exception. We have interviewed respondents from 10 months before the December 2004 Indian Ocean earthquake and tsunami for 10 years. This project will follow up the same respondents 15 years after the tsunami. The pre-tsunami baseline is a population-representative survey of 27,000 individuals who were living along the coast of Aceh and North Sumatra, Indonesia. The tsunami constitutes a large-scale, unanticipated natural disaster in an area that was not thought to be prone to tsunamis. Moreover, its impacts were spatially idiosyncratic across the study area. Whether a particular community was inundated by the waves depended on a combination of the wave direction, seabed and shoreline topography. Of 368 baseline communities, about a fifth were devastated, a third were somewhat damaged and the rest were not directly affected. These features of the natural experiment provide the basis for identifying causal impacts of this major natural disaster which killed 170,000 people in the study area. The baseline and six post-tsunami waves collected during the prior phase of this project provide detailed information about exposure to and experience of the disaster and the evolution of health and wellbeing, broadly defined, for baseline respondents who survived the tsunami plus new household members. In each follow-up, we have interviewed 95% of all baseline survivors. In this continuation we will re-interview all baseline survivors and their household members fifteen years after the tsunami. We will place these data in the public domain, adding to prior waves of STAR already in the public domain to create an unparalleled data resource for the scientific community. Focusing on those who were exposed to the tsunami as children (age <12y and in utero at the time), we will investigate the impacts of tsunami exposure on the evolution of health, education and cognitive performance, linking outcomes to changes in material and psycho-social resources at the family level as well as community level resources. The latter will be measured combining administrative data and information extracted from satellite imagery using machine learning. Longer-term impacts, fifteen years after the tsunami, will exploit innovative human capital measures including biomarkers, executive function and emotional reactivity. Loss of one or both parents is among the most extreme exposures. We will explore the causal effects of orphanhood by comparing children who lost parents in the tsunami with those in the same community who did not. Project Narrative This project will field the fifteen year follow up of the Study of the Tsunami Aftermath and Recovery (STAR), a large-scale longitudinal study of individuals differentially exposed to the 2004 Indian Ocean tsunami. The data provide unique information on the evolution of population health of a group of 27,000 individuals first interviewed before the tsunami, including biomarker measurements and integrated information on environmental change.",Longer term effects of a natural disaster on health and socio-economic status,10250551,R01HD052762,"['Adolescence', 'Affect', 'Age', 'Area', 'Attention', 'Behavioral', 'Biological Markers', 'Categories', 'Censuses', 'Cessation of life', 'Characteristics', 'Child', 'Child Health', 'Child Welfare', 'Cicatrix', 'Cognition', 'Collection', 'Communities', 'Community Surveys', 'Data', 'Disasters', 'Documentation', 'Earthquakes', 'Education', 'Emotional', 'Event', 'Evolution', 'Exposure to', 'Family', 'Follow-Up Studies', 'Frequencies', 'Health', 'Health education', 'Height', 'Heterogeneity', 'Household', 'Imagery', 'Indian Ocean', 'Individual', 'Indonesia', 'Infusion procedures', 'Interview', 'Life', 'Life Cycle Stages', 'Link', 'Literature', 'Long-Term Effects', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Measures', 'Natural Disasters', 'Natural experiment', 'Outcome', 'Outcome Measure', 'Parents', 'Pathway interactions', 'Personal Satisfaction', 'Phase', 'Policies', 'Population', 'Privatization', 'Public Domains', 'Recovery', 'Research', 'Resources', 'Respondent', 'Rest', 'Science', 'Scientific Inquiry', 'Shock', 'Siblings', 'Socioeconomic Status', 'Stress', 'Sumatra', 'Surveys', 'Survivors', 'Time', 'Tsunami', 'Variant', 'Water', 'acetone hydrazone', 'adverse childhood events', 'behavioral response', 'cognitive performance', 'cohort', 'data resource', 'design', 'emerging adult', 'environmental change', 'executive function', 'experience', 'follow-up', 'health economics', 'human capital', 'in utero', 'innovation', 'member', 'physical conditioning', 'population health', 'programs', 'psychosocial', 'reconstruction', 'resilience', 'sea level rise', 'success', 'tool', 'weather patterns', 'young adult']",NICHD,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,498320
"Device to control circadian-effective light in Alzheimer's disease environments Project Summary This proposed project will develop and field-test a device that accurately monitors and controls the circadian stimulus (CS) for Alzheimer disease (AD) and Alzheimer-disease-related dementia (ADRD) patients in nursing homes. Human biology has evolved to have two distinct optical systems: the visual system, by which we see and process images, and the circadian system, which regulates our biological clock and associated biological systems. These two systems have significantly different spectral and temporal responses to optical input. Specifically, circadian stimulation peaks at 460 nm and responds after several minutes of optical activation, while the visual system peaks at 555 nm and responds nearly instantaneously to inputs. All lighting systems are designed and installed in buildings with consideration only given to the photopic (visual) system and all light meters used to characterize lighting buildings are calibrated to measure photopic light, not CS. While a broad and growing body of research has documented the impacts of the circadian system on human health, including regulating sleep and improving cognition in AD/ADRD patients, research on the CS experienced by AD/ADRD patients is extremely limited. Researchers at the Lighting Research Center at Rensselaer Polytechnic Institute developed the Daysimeter, a calibrated light meter that measures circadian light and circadian stimulus. In Phase I of this project, researchers modified an existing workstation-based lighting control system they previously developed for the visual system to include Daysimeter technology, allowing this control system to record CS measurements. The accuracy of these CS measurements was confirmed in the laboratory and field-testing of 20 of devices is currently ongoing in AD/ADRD nursing homes. In this Phase II application, researchers propose adding control features to this device so that lighting can be controlled to optimize CS dosages in AD/ADRD patient environments. Machine learning-based lighting control algorithms will be driven by continuous light level and spectrum measurements as well as periodic (e.g., daily) patient health data. Data from these devices would be wirelessly transmitted to researchers via an Internet gateway and associated cloud-based data management systems. These data would be of immediate value for gaining a better understanding of AD/ADRD patients' CS exposure and could ultimately result in new lighting systems and/or building codes that consider both our visual and circadian systems. Following the development phase, 30 CS-enabled lighting control systems will be field tested over a 22-week test period. Researchers aim to commercialize this CS-enabled lighting control system shortly after the completion of this field test and the Phase II project specifically targeting AD/ADRD nursing home applications. Project Narrative A growing body of research has demonstrated how light impacts human circadian systems and how these impacts can affect sleep, alertness, cognition and agitation in people with Alzheimer's disease (AD) and Alzheimer's-disease-related dementia (ADRD). Still, significant knowledge gaps exist in determining how much circadian stimulation is typically provided to AD/ADRD patients and there are no commercial products designed to control lighting in AD/ADRD environments in ways that promote circadian-related health. This project aims to fill in these gaps by developing and testing a device specifically designed to measure and control the circadian stimulation experienced by AD/ADRD patients in nursing homes.",Device to control circadian-effective light in Alzheimer's disease environments,10312690,R44AG060857,"['Affect', 'Agitation', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Back', 'Behavior', 'Biological Clocks', 'Building Codes', 'Characteristics', 'Clinical Trials', 'Cognition', 'Data', 'Database Management Systems', 'Development', 'Device or Instrument Development', 'Devices', 'Dose', 'Effectiveness', 'Elderly', 'Environment', 'Feeds', 'Health', 'Hour', 'Human', 'Human Biology', 'Image', 'Institutes', 'Internet', 'Intervention', 'Knowledge', 'Laboratories', 'Light', 'Lighting', 'Machine Learning', 'Measurement', 'Measures', 'Monitor', 'Moods', 'Nursing Homes', 'Optics', 'Patients', 'Pattern', 'Performance', 'Periodicity', 'Phase', 'Phototherapy', 'Planet Earth', 'Population', 'Process', 'Reporting', 'Research', 'Research Personnel', 'Retina', 'Rotation', 'Running', 'Sleep', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Visual', 'Visual system structure', 'Wakefulness', 'Wireless Technology', 'Work', 'active control', 'alertness', 'appropriate dose', 'awake', 'base', 'biological systems', 'circadian', 'circadian pacemaker', 'cloud based', 'commercialization', 'design', 'dosage', 'effectiveness testing', 'experience', 'falls', 'field study', 'health data', 'improved', 'interest', 'meter', 'next generation', 'novel', 'prototype', 'residence', 'response', 'success', 'therapy design']",NIA,"ERIK PAGE AND ASSOCIATES, INC.",R44,2021,28487
"ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis Project Summary The morphology (or shape) of anatomical structures forms the common language among clinicians, where ab- normalities in anatomical shapes are often tied to deleterious function. While these observations are often quali- tative, ﬁnding subtle, quantitative shape effects requires the application of mathematics, statistics, and computing to parse the anatomy into a numerical representation that will facilitate testing of biologically relevant hypotheses. Particle-based shape modeling (PSM) and its associated suite of software tools, ShapeWorks, enable learning population-level shape representation via automatic dense placement of homologous landmarks on image seg- mentations of general anatomy with arbitrary topology. The utility of ShapeWorks has been demonstrated in a range of biomedical applications. Despite its obvious utility for the research enterprise and highly permissive open-source license, ShapeWorks does not have a viable commercialization path due to the inherent trade-off between development and maintenance costs, and a specialized scientiﬁc and clinical market. ShapeWorks has the potential to transform the way researchers approach studies of anatomical forms, but its widespread ap- plicability to medicine and biology is hindered by several barriers that most existing shape modeling packages face. The most important roadblocks are (1) the complexity and steep learning curve of existing shape modeling pipelines and their increased computational and computer memory requirements; (2) the considerable expertise, time, and effort required to segment anatomies of interest for statistical analyses; and (3) the lack of interoperable implementations that can be readily incorporated into biomedical research laboratories. In this project, we pro- pose ShapeWorksStudio, a software suite that leverages ShapeWorks for the automated population-/patient-level modeling of anatomical shapes, and Seg3D – a widely used open-source tool to visualize and process volumet- ric images – for ﬂexible manual/semiautomatic segmentation and interactive manual correction of segmented anatomy. In Aim 1, we will integrate ShapeWorks and Seg3D in a framework that supports big data cohorts to enable users to transparently proceed from image data to shape models in a straightforward manner. In Aim 2, we will endow Seg3D with a machine learning approach that provides automated segmentations within a statisti- cal framework that combines image data with population-speciﬁc shape priors provided by ShapeWorks. In Aim 3, we will support interoperability with existing open-source software packages and toolkits, and provide bindings to commonly used programming languages in the biomedical research community. To promote reproducibility, we will develop and disseminate standard workﬂows and domain-speciﬁc test cases. This project combines an interdisciplinary research and development team with decades of experience in statistical analysis and image understanding, and application scientists to conﬁrm that the proposed developments have a real impact on the biomedical and clinical research communities. Our long-term goal is to make ShapeWorks a standard tool for shape analyses in medicine, and the work proposed herein will establish the groundwork for achieving this goal. Project Narrative ShapeWorks is a free, open-source software tool that uses a ﬂexible method for automated construction of sta- tistical landmark-based shape models of ensembles of anatomical shapes. ShapeWorks has been effective in a range of applications, including psychology, biological phenotyping, cardiology, and orthopedics. If funded, this application will ensure the viability of ShapeWorks in the face of the ever-increasing complexity of shape datasets and support its availability to biomedical researchers in the future, as well as provide opportunities for use in a wide spectrum of new biological and clinical applications, including anatomy reconstruction from sparse/low- dimensional imaging data, large-scale clinical trials, surgical planning, optimal designs of medical implants, and reconstructive surgery.","ShapeWorksStudio: An Integrative, User-Friendly, and Scalable Suite for Shape Representation and Analysis",10173765,U24EB029011,"['Address', 'Adoption', 'Anatomic Models', 'Anatomy', 'Applied Research', 'Area', 'Big Data', 'Binding', 'Biological', 'Biological Sciences', 'Biological Testing', 'Biology', 'Biomedical Research', 'Cardiology', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communities', 'Complex', 'Complex Analysis', 'Computer software', 'Computers', 'Consensus', 'Data', 'Data Set', 'Development', 'Dimensions', 'Electronic Mail', 'Ensure', 'Exhibits', 'Face', 'Funding', 'Future', 'Goals', 'Image', 'Interdisciplinary Study', 'Laboratory Research', 'Language', 'Learning', 'Licensing', 'Machine Learning', 'Maintenance', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medicine', 'Memory', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Morphology', 'Normalcy', 'Operative Surgical Procedures', 'Orthopedics', 'Phenotype', 'Population', 'Process', 'Programming Languages', 'Psychology', 'Reconstructive Surgical Procedures', 'Reproducibility', 'Research', 'Research Personnel', 'Scientist', 'Shapes', 'Software Engineering', 'Software Tools', 'Statistical Data Interpretation', 'Supervision', 'Techniques', 'Technology', 'Testing', 'Time', 'Work', 'automated segmentation', 'base', 'clinical application', 'clinical care', 'clinical investigation', 'cohort', 'commercialization', 'computerized tools', 'cost', 'design', 'efficacy evaluation', 'experience', 'flexibility', 'imaging Segmentation', 'improved', 'innovation', 'interest', 'interoperability', 'medical implant', 'open source', 'outreach', 'particle', 'patient population', 'reconstruction', 'research and development', 'shape analysis', 'software development', 'statistics', 'tool', 'usability', 'user-friendly']",NIBIB,UNIVERSITY OF UTAH,U24,2021,256578
"Nathan Shock Center for Excellence in Basic Biology of Aging OVERALL—PROJECT SUMMARY Healthspan is a complex trait, influenced by many interacting polymorphic alleles and environmental factors that may accelerate or delay aging, reduce or increase disease risk, and/or promote extended lifespan. Thus, assessing the role of genetic variation in aging requires an experimental strategy capable of modeling the genetic and biological complexity of human populations while allowing for efficient identification and validation of candidate genes. With this proposal, the JAX NSC seeks support to further develop and disseminate the next generation of genetic, phenotyping, and information resources necessary to enable a systems-wide approach to understanding healthy aging. Over the past 15 years, The JAX NSC has transformed aging research both at JAX and across the geroscience community, providing central resources to support investigators that have resulted in 26 peer-reviewed publications in the last funding period. The Center has developed nascent regional and national resources for aging research, including aging mouse resources and tissues that support our numerous collaborations and external researchers. All JAX NSC data and tools are publicly disseminated on the Mouse Phenome Database and the JAX NSC website, thus ensuring that the resources generated and expertise acquired through the Center is readily available to the aging research community. In this renewal, we will advance towards our goal by providing unique resources, tools, and support to geroscience investigators while leveraging JAX's unparalleled expertise in the large-scale identification and functional validation of complex polygenic traits in mice. We will do this by providing effective Center administration and enhancing the utility of JAX NSC resources throughout the aging community (Aim 1); expanding the research focus on aging, healthspan and age-related diseases through a robust Research Development Core (Aim 2); increasing the diversity of mouse resources available for aging research, including a new study to, for the first time, investigate the effect of genetic variation on cellular senescence and treatment with senolytic drugs (Aim 3); strengthening the data and computational and support available to the aging community (Aim 4); expanding the use of machine learning technologies in interpretation of aging pathologies (Aim 5). The Center will be led by a highly experienced team of Principal Investigators and Core Leaders who, with oversight from an External Advisory Board, will provide effective management to facilitate the goals and objectives of the Center. The Center will leverage unparalleled institutional resources, facilities and expertise of The Jackson Laboratory, a globally renowned institution for mouse genetics research, to enhance its goals and the utility of the resources it generates for the aging research community. OVERALL—PUBLIC HEALTH RELEVANCE Human aging is influenced by genetic factors, whereby differences in longevity as well as changes in health and disease risk with time are linked to variation in individuals' genetic codes. The Jackson Laboratory Nathan Shock Center will develop resources to encourage the use of a wider range of mouse models in aging research. Resources—including aged mouse models that mirror human genetic variation, metabolic and microbiome data, and methods to reveal genetic factors tied to human aging—will be available to the scientific community, accelerating research to understand and ultimately prolong healthy human aging.",Nathan Shock Center for Excellence in Basic Biology of Aging,10261436,P30AG038070,"['Advisory Committees', 'Aging', 'Alleles', 'Animals', 'Biological', 'Biology of Aging', 'Candidate Disease Gene', 'Cell Aging', 'Collaborations', 'Communities', 'Complex', 'Computer Assisted', 'Data', 'Data Analyses', 'Databases', 'Disease', 'Educational workshop', 'Ensure', 'Environmental Risk Factor', 'Funding', 'Genes', 'Genetic', 'Genetic Code', 'Genetic Models', 'Genetic Research', 'Genetic Variation', 'Geroscience', 'Goals', 'Health', 'Heart', 'Histologic', 'Human', 'Human Genetics', 'Image Analysis', 'Inbred Strain', 'Individual', 'Information Resources', 'Institution', 'Joints', 'Laboratories', 'Leadership', 'Link', 'Liver', 'Longevity', 'Lung', 'Machine Learning', 'Maps', 'Mentorship', 'Metabolic', 'Methods', 'Mus', 'Pathology', 'Peer Review', 'Pharmaceutical Preparations', 'Phenotype', 'Physiological', 'Pilot Projects', 'Polygenic Traits', 'Population', 'Principal Investigator', 'Process', 'Protocols documentation', 'Publications', 'Quality Control', 'Research', 'Research Personnel', 'Resources', 'Role', 'Sampling', 'Shock', 'Statistical Methods', 'Structure', 'System', 'Technology', 'The Jackson Laboratory', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Validation', 'Variant', 'Visit', 'age related', 'aged', 'animal tissue', 'behavioral phenotyping', 'candidate validation', 'career development', 'data dissemination', 'data management', 'data tools', 'disorder risk', 'experience', 'healthspan', 'healthy aging', 'insight', 'microbiome', 'mouse genetics', 'mouse model', 'next generation', 'novel', 'open source', 'phenome', 'phenotypic data', 'programs', 'public health relevance', 'research and development', 'response', 'senescence', 'symposium', 'tool', 'trait', 'user-friendly', 'web site']",NIA,JACKSON LABORATORY,P30,2021,1069526
"TEMPORAL DIETARY PATTERNS: DEVELOPMENT AND EVALUATION AGAINST ADIPOSITY AND METABOLIC BIOMARKERS ABSTRACT There is a growing interest in dietary patterns that capture the overall quality of diet as well as its constituent foods and nutrients. Commonly used dietary patterns are a priori diet score/index based on a set of dietary recommendations for a healthy diet (e.g., Mediterranean diet, Healthy Eating Index) or data-driven dietary patterns (e.g., prudent diet, western diet). Numerous studies have shown that those dietary patterns were related to the risk of chronic diseases such as heart disease, diabetes, and cancer. However, none of these dietary patterns incorporates eating behavior such as when we eat (i.e., eating time) and how often we eat (i.e. eating frequency) during a day. Since the amount of foods and nutrients consumed at one eating occasion influences the food consumption at the subsequent eating occasion and overall intake of the day, eating time and frequency are integral parts of dietary patterns. Furthermore, several lines of evidence consistently suggest that eating time and frequency as well as a meal composition play roles in body weight regulation and metabolic health and also regulate circadian rhythms, all of which may lead to metabolic dysfunctions and ultimately chronic diseases. Given a clear need to expand the dietary patterns framework and close a gap in dietary patterns methodological work, we propose to 1) develop a “temporal” dietary patterns based on temporal distribution of eating time and frequency during a day; and 2) evaluate if the identified temporal dietary patterns are associated with i) overall diet quality and nutrient intakes, ii) adiposity (e.g., BMI, waist circumference), and iii) metabolic biomarkers (e.g., insulin, HOMA-IR, LDL-cholesterol, c-reactive protein). To overcome a limitation that a conventional statistical method cannot capture multidimensional aspects of temporal dietary patterns (e.g., 24-dimensional feature vectors, multivariate dietary intake time-series data), we will use a novel approach combining nutrition and systems science—machine learning method. The Interactive Diet and Activity Tracking in AARP (IDATA) study that repeatedly collected diet, anthropometry, and blood samples from 1,021 men and women, 50-74 years old will be used. During one year, the IDATA study collected 24-hour recalls with clock time for each eating occasion, every other month (total six 24-hour recalls); measured anthropometry three times (baseline and at month 6 and 12); and collected blood twice, 6-month apart. Successful completion of our proposed study will identify temporal dietary patterns that are related to diet quality and metabolic health and validate the utility of temporal dietary patterns as a new tool for future research on diet-health relations and prevention of chronic diseases. NARRATIVE Eating behaviors and its impact on health are complex and multidimensional. The proposed study provides an excellent opportunity to develop new dietary patterns that capture eating behaviors such as when we eat and how often we eat during a day. The findings of the study about healthy eating patterns will also improve dietary recommendations by adding messages on when and how often to eat during a day.",TEMPORAL DIETARY PATTERNS: DEVELOPMENT AND EVALUATION AGAINST ADIPOSITY AND METABOLIC BIOMARKERS,10053329,R01CA226937,"['Advisory Committees', 'Affect', 'Algorithms', 'Animals', 'Anthropometry', 'Biological Markers', 'Blood', 'Blood specimen', 'Body Weight', 'Body mass index', 'C-reactive protein', 'Calories', 'Cardiovascular Diseases', 'Characteristics', 'Chronic Disease', 'Circadian Rhythms', 'Complex', 'Consumption', 'Data', 'Development', 'Diabetes Mellitus', 'Diet', 'Diet Habits', 'Dietary Practices', 'Dietary intake', 'Dimensions', 'Eating', 'Eating Behavior', 'Energy Intake', 'Evaluation', 'Fasting', 'Fatty acid glycerol esters', 'Food', 'Frequencies', 'Health', 'Healthy Eating', 'Heart Diseases', 'Hour', 'Human', 'Individual', 'Insulin', 'Intake', 'LDL Cholesterol Lipoproteins', 'Lead', 'Macronutrients Nutrition', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mediterranean Diet', 'Metabolic', 'Metabolic dysfunction', 'Metabolic syndrome', 'Methodology', 'Modeling', 'Nutrient', 'Obesity', 'Outcome', 'Pattern', 'Persons', 'Physical activity', 'Play', 'Population', 'Positioning Attribute', 'Prevention', 'Recommendation', 'Regulation', 'Risk', 'Role', 'Science', 'Series', 'Statistical Methods', 'System', 'Techniques', 'Time', 'Waist-Hip Ratio', 'Weight maintenance regimen', 'Woman', 'Work', 'base', 'cardiovascular disorder risk', 'dietary', 'dietary guidelines', 'doubly-labeled water', 'epidemiology study', 'food consumption', 'good diet', 'improved', 'indexing', 'interest', 'machine learning method', 'men', 'novel', 'novel strategies', 'nutrient metabolism', 'nutrition', 'obesity risk', 'prudent diet', 'tool', 'vector', 'waist circumference', 'western diet']",NCI,WASHINGTON UNIVERSITY,R01,2021,224806
"Predicting Short- and Long-term Future Occurrence of Atrial Fibrillation from Single-Lead ECG in Normal Sinus Rhythm with an Explainable Deep Learning Model. Project Summary/Abstract More than 30 million individuals worldwide are diagnosed with atrial fibrillation (AF), however, another 13% of individuals with AF are left undiagnosed. People with AF have a five-fold increased risk of stroke with up to one-third of all strokes shown to be related to AF. Timely administration of appropriate preventative therapies, especially anticoagulants, can significantly decrease the complications of AF, including strokes, by 65% and mortality by 30%. Digital health technologies offer new approaches to identify individuals with undiagnosed AF, in particular paroxysmal AF (PAF), characterized by occasional episodes of limited duration, for whom a 10-second 12-lead electrocardiography (ECG) performed in the clinical setting is unlikely to overlap with an AF event. Continuous monitoring is promising, but still costly and burdensome for elderly individuals, who are at higher risk. To maximize the diagnostic yield of these technologies, we propose novel methods to predict the future occurrence of AF from a single-lead ECG during normal sinus rhythm. Only recently it was shown that it is possible to predict the future occurrence of AF from 12-lead ECGs in normal sinus rhythm collected in a clinical setting. Here, we propose to predict the occurrence of AF with commercially available single- lead ECG devices, which will enable a scalable alternative for early detection in a non-clinical setting. To achieve this goal, we will analyze retrospectively the raw single-lead ECG data of 10,000+ individuals with PAF over 14 days of monitoring. Validation work will then be carried out in a unique set of 1,718 asymptomatic individuals who participated in the prospective mSToPS clinical trial of AF screening (mean age 73), with full clinical information and co-morbidities. The three aims of this project are:  1. Compute the probability of a future AF event in the short-term for an individual in normal sinus rhythm using classic single-lead ECG features and representation learning based features.  2. Develop a method for long-term prediction of AF onset by evaluating individuals with AF detected in 1, 3, 6 and 12 months from the initial monitored period of normal sinus rhythm and by validating the algorithms using the mSToPS dataset with 3 years of clinical follow-up and annotated co-morbidities.  3. Develop a technique to provide a preliminary interpretation of representation learning features for time-series data applied to the short- and long-term prediction. This retrospective study will develop and optimize new predictive techniques from single-lead ECGs, available through consumer devices, with the goal of identifying individuals at high risk of developing AF. A future direction to build on from this study's results would include a prospective study of AF prediction using consumer single-lead ECG to improve clinical outcomes. Project Narrative In this project we propose novel methods to predict the future occurrence of AF from single-lead ECGs during normal sinus rhythm, collected from commercially available single-lead ECG devices, which will enable a scalable alternative for early detection in a non-clinical setting. To achieve this goal, we will analyze retrospectively the raw single-lead ECG data of 10,000+ individuals with paroxysmal AF over 14 days of monitoring and we will validate the developed modes using a unique set of 1,718 asymptomatic individuals who participated in the prospective mSToPS clinical trial of AF screening (mean age 73), with full clinical information and co- morbidities. This retrospective study will develop and optimize new predictive techniques from single-lead ECGs, available through consumer devices, with the goal of identifying individuals at high risk of developing AF.",Predicting Short- and Long-term Future Occurrence of Atrial Fibrillation from Single-Lead ECG in Normal Sinus Rhythm with an Explainable Deep Learning Model.,10195981,R21AG072349,"['Address', 'Algorithms', 'Anticoagulants', 'Atrial Fibrillation', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Data', 'Data Science', 'Data Set', 'Devices', 'Diagnosis', 'Diagnostic', 'EKG P Wave', 'Early Diagnosis', 'Early identification', 'Elderly', 'Electrocardiogram', 'Event', 'Future', 'Goals', 'Health', 'Health Technology', 'Home environment', 'Hour', 'Individual', 'Ischemic Stroke', 'Lead', 'Learning', 'Left', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Outcome', 'Participant', 'Persons', 'Photoplethysmography', 'Play', 'Population', 'Preventive therapy', 'Probability', 'Prospective Studies', 'Research Personnel', 'Retrospective Studies', 'Risk', 'Role', 'Series', 'Signal Transduction', 'Sinus', 'Stroke', 'Techniques', 'Technology', 'Time', 'Validation', 'Work', 'base', 'clinically relevant', 'cohort', 'comorbidity', 'cost', 'deep learning', 'design', 'diagnostic accuracy', 'digital health', 'follow-up', 'high risk', 'improved', 'learning strategy', 'mortality', 'novel', 'novel strategies', 'prospective', 'screening', 'smart watch', 'stroke risk', 'tool', 'uptake', 'wearable sensor technology']",NIA,SCRIPPS RESEARCH INSTITUTE,R21,2021,266250
"Noninvasive assessment of the cornea by diffusion OCT Keratoconus is a degenerative disease of the cornea that is a major cause of reduced vision-related quality of life in the United States, often leading to corneal transplantation. Ectasia after refractive surgery is a vision-threatening complication that can occur in apparently low-risk patients despite current screening technology. The biomechanical properties of the cornea play a central role in these diseases, but diagnostics are still rooted in shape measures because doctors lack direct measures of biomechanical change. While several methods have shown early promise for addressing this gap, most require contact with or perturbation of the cornea, cannot spatially resolve biomechanical properties, or involve expensive optical systems.  To address the need for direct biomechanical measurement of the cornea and the limitations of other approaches, we introduce phase-decorrelation OCT (phd-OCT). Phd-OCT makes use optical coherence tomography (OCT) to quantify random nanoscale mobility that is related to the strength and cohesion of the cornea. Preliminary results strongly support the rationale, feasibility and potential advantages of the approach. Our objectives are: (1) to refine our method to optimize detection sensitivity and speed, and (2) to determine if the technique is clinically useful. We will achieve these objectives through the following aims: 1. To develop and validate mobility-sensitive phd-OCT for corneal imaging. Spectral-domain OCT will be used for anterior segment phase-decorrelation imaging and the analysis algorithm will be optimized. The system will be validated using phantoms and torsional rheometry. 2. To investigate the potential influence of physiological factors (intraocular pressure (IOP), hydration, and temperature). Factorial design experiments in porcine and human donor globes will establish the sensitivity of phd-OCT measurements to potential confounders. 3. To develop and validate data acquisition and processing methods to enable clinical testing. GPU processing and machine learning will be configured to minimize processing time. Scan patterns will be optimized to minimize scan time and return clinically useful data. 4. To assess feasibility and preliminary diagnostic performance of clinical mobility-sensitive OCT imaging of the cornea. A first-in-human study will characterize repeatability and test the hypotheses that phd-OCT mobility measurements are increased in the region of a LASIK flap and decreased in CXL.  Expected Outcomes: The proposed studies will establish a new, non-contact method for imaging corneal biomechanical properties with the potential to address many shortcomings of current and emerging methods. Success could lead to earlier detection of of ectasia risk and allow more appropriate timing and customization of corneal treatments. Future integration of data into computational models has the potential to greatly impact the field by driving a shift from empirical planning and risk analysis to patient-specific strategies. The mechanical properties of the cornea, the transparent front of the eye, are important for diseases that affect vision as well as for corrective treatments like crosslinking therapy and LASIK. We have developed a new optical coherence tomography (OCT)-based method to detect and map corneal mechanical properties that has advantages that may make it readily translatable to clinical use. The objective of this proposal is to determine whether this technique is clinically feasible and useful by refining the technology, testing it in animal and human donor corneas, and performing studies in patients with corneal conditions of interest.",Noninvasive assessment of the cornea by diffusion OCT,10171859,R01EY028667,"['Achievement', 'Address', 'Affect', 'Algorithmic Analysis', 'Algorithms', 'Animals', 'Anterior', 'Automobile Driving', 'Biomechanics', 'Clinical', 'Clinical Research', 'Complication', 'Computational Technique', 'Computer Models', 'Cornea', 'Corneal Diseases', 'Custom', 'Data', 'Degenerative Disorder', 'Detection', 'Development', 'Diagnostic', 'Diffusion', 'Disease', 'Doctor of Philosophy', 'Early Diagnosis', 'Ensure', 'Exhibits', 'Eye', 'Family suidae', 'Feedback', 'Future', 'Human', 'Hydration status', 'Image', 'Keratoconus', 'Keratoplasty', 'Laser In Situ Keratomileusis', 'Lead', 'Life', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Methods', 'Operative Surgical Procedures', 'Optical Coherence Tomography', 'Optics', 'Outcome', 'Pathological Dilatation', 'Patients', 'Pattern', 'Performance', 'Phase', 'Physiologic Intraocular Pressure', 'Physiological', 'Plant Roots', 'Play', 'Procedures', 'Property', 'Proxy', 'Quality of life', 'Risk', 'Role', 'Scanning', 'Shapes', 'Speed', 'Structure', 'Surgical Flaps', 'Surgical incisions', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Torsion', 'United States', 'Validation', 'Vision', 'Visual impairment', 'base', 'clinical practice', 'cohesion', 'computerized data processing', 'crosslink', 'data acquisition', 'data integration', 'design', 'detection sensitivity', 'experimental study', 'first-in-human', 'human study', 'imaging modality', 'interest', 'mechanical properties', 'nanoscale', 'novel', 'outcome prediction', 'research clinical testing', 'screening', 'simulation', 'success', 'tool', 'treatment effect']",NEI,CASE WESTERN RESERVE UNIVERSITY,R01,2021,381543
"ICEES+ Knowledge Provider: Leveraging Open Clinical and Environmental Data to Accelerate and Drive Innovation in Translational Research and Clinical Care. As part of the feasibility phase of the Translator program, we have developed a disease-agnostic framework and approach for openly exposing clinical data that have been integrated at the patient- and visit-level with environmental exposures data: the Integrated Clinical and Environmental Exposures Service (ICEES). We have validated ICEES and demonstrated the service’s ability to replicate and extend published findings on asthma, while also supporting open team science, accelerated translational discovery, and integration with the broader Translator ecosystem. This proposal aims to move ICEES from prototype to development via creation of an ICEES+ Knowledge Provider (KP). Specifically, we aim to address three major challenges that we have identified through research and development (R&D) of the prototype ICEES in an effort to improve the quality, value, and impact of query answers and assertions. Specific Aim 1. Advance the rigor of insights and assertions that ICEES provides. Our prototype ICEES currently provides the ability to dynamically define cohorts and conduct simple statistical associations to examine bivariate relationships between feature variables. Recently, we have identified an approach to extend the bivariate functionalities to support multivariate analysis of the data. For the proposed work, we will apply multivariate analyses, including traditional statistical methods (e.g., regression models) and machine learning methods (e.g., bayesian neural network models, variational autoencoder models), and systematically quantify the extent of data loss and analytic bounds when algorithms are imposed on the ICEES+ KP open application programming interface (API) versus the Institutional Review Board (IRB)– protected, fully identified, pre-binned, underlying integrated feature tables. The overall goal is to provide users with more rigorous insights and estimates of the robustness, validity, accuracy, and specificity of knowledge and assertions generated via the ICEES+ KP OpenAPI. Specific Aim 2. Address issues related to space–time and causality. Clinical and environmental data are inherently spatiotemporal, with observations or events that are contingent on space and time and may be causally related. For the proposed work, we will evaluate and implement technical approaches (e.g., ICEES+ design modifications), spatiotemporal statistical algorithms (e.g., conditional auto-regression), recurrent neural network models, and causal inference models. As part of this effort, we will derive insights from and contribute real-world evidence to support Causal Activity Models and Adverse Outcome Pathways. We also will explore approaches for incorporating into ICEES+ nationwide public data on school exposures—data that will allow us to begin to address patient mobility. Specific Aim 3. Evaluate the security of the ICEES+ KP to ensure that patient privacy is preserved as new capabilities are enabled. ImPACT is an NSF-funded package of tools and services that provides end-to-end infrastructure and support for privacy-assured research and computation on sensitive data. Over the award period, we will implement and evaluate ImPACT security protocols, focusing initially on application of the ImPACT secure multiparty computation (SMC) algorithm as a method to support secure multi-institutional sharing of data on rare diseases and events—a functionality that is not currently supported by ICEES. In addition, we will evaluate other ImPACT security protocols, working under the guidance of a security advisor and in the context of driving use cases and capabilities developed under Specific Aims1 and 2. Importantly, the project aims will be driven by three use cases and associated high-value queries designed to complement and extend our asthma-focused work on the prototype ICEES: (1) an asthma cohort from the Environmental Polymorphism Registry (EPR) at the National Institute for Environmental Health Sciences (NIEHS); (2) a primary ciliary disease cohort (PCD) from the UNC PCD Registry; and (3) a drug-induced liver injury (DILI) cohort from the National DILI Network. These use cases will invoke new diseases, new data types, new organ systems, new institutions, and new queries, thereby stress-testing the ICEES framework and approach and moving it from prototype to development as the ICEES+ KP. n/a",ICEES+ Knowledge Provider: Leveraging Open Clinical and Environmental Data to Accelerate and Drive Innovation in Translational Research and Clinical Care.,10333478,OT2TR003430,"['Address', 'Algorithms', 'Asthma', 'Automobile Driving', 'Award', 'Bayesian neural network', 'Clinical', 'Clinical Data', 'Complement', 'Computational algorithm', 'Data', 'Data Analyses', 'Development', 'Disease', 'Ecosystem', 'Ensure', 'Environmental Exposure', 'Etiology', 'Event', 'Funding', 'Genetic Polymorphism', 'Goals', 'Infrastructure', 'Institution', 'Institutional Review Boards', 'Knowledge', 'Methods', 'Modeling', 'Modification', 'Multivariate Analysis', 'National Institute of Environmental Health Sciences', 'Neural Network Simulation', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Phase', 'Privacy', 'Protocols documentation', 'Provider', 'Publishing', 'Rare Diseases', 'Registries', 'Research', 'Schools', 'Science', 'Secure', 'Security', 'Services', 'Specificity', 'Statistical Algorithm', 'Statistical Methods', 'Stress Tests', 'Time', 'Translational Research', 'Variant', 'Visit', 'Work', 'adverse outcome', 'application programming interface', 'autoencoder', 'body system', 'clinical care', 'cohort', 'data sharing', 'design', 'improved', 'innovation', 'insight', 'liver injury', 'machine learning method', 'patient mobility', 'patient privacy', 'preservation', 'programs', 'prototype', 'recurrent neural network', 'research and development', 'spatiotemporal', 'tool']",NCATS,UNIV OF NORTH CAROLINA CHAPEL HILL,OT2,2021,982187
"The Network for Investigation of Delirium: Unifying Scientists (NIDUS)'s 9th-13th Annual Delirium Boot Camps: A Foundation for Future Exploration Delirium is a serious cognitive disorder associated with Alzheimer’s disease and related dementias (ADRD) that affects ~2.6 million older adults yearly. It is a frequent complication of acute illness, surgery and, now, of COVID-19 infection in older adults. Recognizing the relative dearth of delirium research, the National Institute for Aging (NIA) supported the establishment of the Network for Investigation of Delirium: Unifying Scientists (NIDUS), a collaborative interdisciplinary group of 28 investigators, from 27 institutions, to advance delirium research and develop network infrastructure. This included the creation of an annual “NIDUS bootcamp” conference, to bring together the growing national- and international delirium research community for networking and education. The bootcamp aims are to advance the science of the field and to provide junior investigators with intensive mentorship, through mock NIH application reviews, clinical and research lectures, breakout sessions, and post-bootcamp networking. Bootcamp alumni are provided guidance on: 1) using the NIDUS Delirium Research Hub, Measurement resources and Bibliography, 2) submitting proposals to the NIDUS Pilot Program (13 one-year $50,000 grants awarded), NIA GEMSSTAR/CLINSTAR, the Alzheimer’s Association, and other foundations, 3) attending Mentoring webinars, 4) participating in Junior Faculty Working Groups, and 5) submitting research abstracts to the American Delirium Society (ADS) Annual Meeting. As PIs, 94 alumni have received 46 grants, of which 18 (40%) were NIH-funded, and published 265 original peer- reviewed articles. NIDUS has jumpstarted the careers of many young investigators, particularly bootcamp alumni, enabling them to launch independent programs in delirium research. The goal of this application is to support continuation of a yearly, themed Delirium Bootcamp Conference (DBC), to ensure that the progress of this active research community is sustained. The first-year theme will be the inter-relationship between delirium and ADRD. The Specific Aims are to: (1) Engage and support junior investigators in delirium research through mentorship and access to the NIDUS resources/network (2) Boost the researchers’ funding success (3) Facilitate publication of delirium research and provide ongoing mentorship, and (4) Facilitate networking among junior, mid-career, and senior researchers during and after DBC. As the pool of delirium investigators expands, there is a critical need for a conference focused on addressing cutting-edge research methods in all areas of delirium research, including the relationship with ADRD, “-Omics” research, machine learning and big data, innovations in randomized trials, animal models and mechanistic research, and clinical practice improvement. The DBC will provide an unparalleled opportunity to advance cutting-edge delirium research through interactive didactic sessions and in-depth guidance on complex and nuanced research methods essential for the highest caliber and most impactful delirium research. Delirium is a serious, yet understudied, cognitive disorder that affects millions of elder Americans, and is closely related to Alzheimer’s disease and related dementias (ADRD). The NIA-supported (2015-2020) Network for Investigation of Delirium Unifying Scientists (NIDUS), a collaborative international network of delirium investigators, developed a successful, annual “NIDUS Bootcamp” conference, laying the foundation for this proposal. The new Delirium Bootcamp (DBC) will convene junior investigators and senior faculty in an annual conference with innovations including: 1) a new thematic focus each year, with the 2021 theme highlighting ADRD; 2) focus on high-impact, state-of-the-art methodologies to advance the field in new directions; 3) finding optimal methods to address the unique challenges of delirium research, and 4) developing collaborative interdisciplinary papers to be initiated at the DBC and completed in ongoing groups; thus, fostering the training, career development and success of the next generation of delirium investigators.",The Network for Investigation of Delirium: Unifying Scientists (NIDUS)'s 9th-13th Annual Delirium Boot Camps: A Foundation for Future Exploration,10237513,R13AG072860,"['Acute', 'Acute Disease', 'Address', 'Affect', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'American', 'Animal Model', 'Area', 'Attention', 'Award', 'Bibliography', 'Big Data', 'COVID-19', 'Caliber', 'Clinical', 'Clinical Research', 'Cognition', 'Cognition Disorders', 'Collaborations', 'Communities', 'Community Networks', 'Complex', 'Complication', 'Delirium', 'Discipline', 'Education', 'Elderly', 'Ensure', 'Epidemiology', 'Faculty', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'Grant', 'Health Expenditures', 'Infrastructure', 'Institution', 'International', 'Investigation', 'Knowledge', 'Laboratories', 'Machine Learning', 'Measurement', 'Mentors', 'Mentorship', 'Methodology', 'Methods', 'Monoclonal Antibody R24', 'National Institute on Aging', 'Network Infrastructure', 'Operative Surgical Procedures', 'Paper', 'Participant', 'Peer Review', 'Pilot Projects', 'Public Health', 'Publications', 'Publishing', 'Reporting', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'SARS-CoV-2 infection', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Series', 'Societies', 'Study Section', 'Training', 'United States National Institutes of Health', 'Writing', 'career', 'career development', 'clinical practice', 'cost', 'innovation', 'interdisciplinary collaboration', 'lectures', 'meetings', 'multidisciplinary', 'neglect', 'next generation', 'patient population', 'peer', 'programs', 'randomized trial', 'response', 'secondary analysis', 'senior faculty', 'skill acquisition', 'success', 'support network', 'symposium', 'systematic review', 'webinar', 'working group']",NIA,UNIV OF NORTH CAROLINA CHAPEL HILL,R13,2021,50000
"A knowledge graph framework for automated gating analysis of cytometry data Project Summary / Abstract Flow and mass cytometry provide multiparametric single-cell data critical for understanding the cellular heterogeneity in various biological systems. Modern polychromatic flow cytometers simultaneously measure about 16 parameters routinely. The next-generation mass cytometry (CyTOF) technology allows for the simultaneous measurement of 50 or more parameters. Even as the cytometry technology is rapidly advancing, approaches for analyzing such complex data remain inadequate. The widely-used manual gating analysis is knowledge-driven and easy-to- interpret, but it is subjective, labor-intensive, and not scalable to handle the increasing complexity of the data. Recent developments of automated data-driven algorithms are able to address the issues of manual gating, but the results from data-driven algorithms are often not intuitive for biology experts to interpret. These limitations create a critical bottleneck for flow and mass cytometry analysis. The overall objective of this application is to develop a novel framework that combines both knowledge-driven and data-driven approaches to achieve automated gating analysis of flow cytometry and CyTOF data. The specific aims are: (1) build knowledge graphs to capture existing knowledge of manual gating analysis, (2) develop algorithms for automated gating analysis, and (3) validate the knowledge graph framework using large-scale studies in ImmPort. The proposed research is significant because it will enable efficient and reproducible gating analysis and provide visualizations that are easy-to-interpret, both of which are critically important to the research community. Such contributions will fundamentally impact single-cell analysis of cellular heterogeneity in diverse fields including immunology, infectious diseases, cancer, AIDS, among others. Project Narrative The proposed research is relevant to public health because it is expected to develop novel computational methods for automated analysis and interpretation of single-cell analysis by flow and mass cytometry. Such contributions will impact single-cell analysis of cellular heterogeneity in diverse fields such as immunology, infectious diseases, cancer, AIDS, among others.",A knowledge graph framework for automated gating analysis of cytometry data,10172842,UH2AI153028,"['Acquired Immunodeficiency Syndrome', 'Address', 'Adopted', 'Adoption', 'Algorithm Design', 'Algorithmic Analysis', 'Algorithms', 'Biological', 'Biological Sciences', 'Biology', 'Cells', 'Clinical', 'Clinical Research', 'Communicable Diseases', 'Communities', 'Computer software', 'Computing Methodologies', 'Cytometry', 'Data', 'Data Set', 'Database and Analysis Portal', 'Development', 'Dimensions', 'Flow Cytometry', 'Graph', 'Heterogeneity', 'Human', 'Immune system', 'Immunology', 'Individual', 'Intuition', 'Knowledge', 'Literature', 'Logic', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Measurement', 'Measures', 'Modeling', 'Modernization', 'Mus', 'Online Systems', 'Outcome', 'Public Health', 'Publishing', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Technology', 'Thinking', 'Visualization', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'cell type', 'complex data', 'data and analysis portal', 'data resource', 'deep learning', 'design', 'diverse data', 'graphical user interface', 'high dimensionality', 'informatics tool', 'knowledge graph', 'multidimensional data', 'next generation', 'novel', 'protein biomarkers', 'single cell analysis', 'stem', 'user-friendly', 'web based interface']",NIAID,GEORGIA INSTITUTE OF TECHNOLOGY,UH2,2021,237082
"Ultrasonic Imaging of Bone Graft Healing in Extraction Sockets for Precise and Personalized Implant Therapy Abstract Socket augmentation after tooth extraction by placing either allograft or xenograft bone particulates in the socket is frequently applied to reduce jawbone volume shrinkage for subsequent implant placement. Socket healing after the augmentation varies largely, ranging from uneventful healing to infection, failure of bone graft integration and severe bone loss due to bacterial infection and/or local/systemic conditions. The healing duration, which dictates the timing of implant placement, is widely different as well. Currently, an arbitrary waiting time of 6 months after socket augmentation is adopted, when a 2-dimensional (2D) or 3D radiograph, along with a visual examination is performed to assess hard- and soft-tissue healing to determine the readiness and strategy for the subsequent implant surgery. However, 3D radiographs are not recommended for longitudinal use to monitor socket healing due to radiation concerns. They have lower image resolution (250-500 µm), which limits their ability to evaluate bone surface healing, and inferior soft tissue contrast. A non-radiation and point-of-care method that can evaluate both hard- and soft-tissue longitudinally is much needed for a definitive, accurate, and timely diagnosis of socket healing pathologies. A high-frequency and miniature-sized intraoral ultrasound probe that can operate on an off-the-shelf scanner has been manufactured in collaboration with industry (see support letter) by our research team. Research conducted by our group demonstrated accuracy of this probe in measuring various oral and dental structures. The central hypothesis is to develop ultrasound-based imaging to characterize and grade socket healing lesions in determining the extent and severity of disease. To test this hypothesis, two aims are proposed: Aim 1. Evaluate the diagnostic value of ultrasonic images for bone grafting procedures of dental extraction sockets in a longitudinal clinical study (from -2 months to +6 months of graft placement). We will compare other imaging and clinical diagnostic tools for assessing hard- and soft tissue, anatomical and physiological status throughout the longitudinal study time-course. Aim 2. Develop an extended-view scan-mode for acquiring large field- of-view jawbone images and determine buccal (facial) to lingual tissue morphology. We will engage the manufacturer (see support letter) to modify the existing scanner for this dental specific application. Design goals will include the creation of an extended, large angle, field-of-view to visualize the buccal to lingual jaw bone surface and to create machine learning based measurement tools, including soft- and hard-tissue thickness and surface analysis. Successful execution of the proposed aims will result in an imaging-based tool for longitudinal socket augmentation evaluation that is based on soft- and hard-tissue features and will allow the care provider to choose deviation from current clinical procedures where indicated. This would be investigated subsequently in a specifically designed clinical trial. Narrative The goals of this investigation are to follow dental patients that require bone grafts before their dental implant is placed and to demonstrate the diagnostic opportunities that ultrasound adds to the current standard of clinical dental care. 3",Ultrasonic Imaging of Bone Graft Healing in Extraction Sockets for Precise and Personalized Implant Therapy,10427073,R56DE030872,"['3-Dimensional', 'Adopted', 'Allografting', 'Anatomy', 'Atrophic', 'Bacterial Infections', 'Blood', 'Blood flow', 'Bone Surface', 'Bone Transplantation', 'Chronic', 'Clinical', 'Clinical Research', 'Clinical Trials Design', 'Collaborations', 'Dental', 'Dental Care', 'Dental Implants', 'Dental caries', 'Diagnosis', 'Diagnostic', 'Disease', 'Evaluation', 'Face', 'Failure', 'Frequencies', 'Goals', 'Gold', 'Image', 'Implant', 'Implantation procedure', 'Industry', 'Infection', 'Inferior', 'Inflammation', 'Investigation', 'Ionizing radiation', 'Jaw', 'Lateral', 'Lesion', 'Letters', 'Longitudinal Studies', 'Machine Learning', 'Manufacturer Name', 'Measurement', 'Measures', 'Methods', 'Miniaturization', 'Monitor', 'Morphology', 'Operative Surgical Procedures', 'Oral', 'Oral cavity', 'Organ Transplantation', 'Outcome', 'Particulate', 'Pathology', 'Patients', 'Perfusion', 'Physiological', 'Procedures', 'Process', 'Quality of life', 'Radiation', 'Readiness', 'Research', 'Resolution', 'Roentgen Rays', 'Scanning', 'Severities', 'Severity of illness', 'Site', 'Structure', 'Surface', 'Testing', 'Thick', 'Time', 'Time Study', 'Tissues', 'Tooth Extraction', 'Ultrasonography', 'United States', 'Visual', 'Wait Time', 'base', 'bone', 'bone healing', 'bone loss', 'bone xenograft', 'care providers', 'clinical diagnostics', 'cone-beam computed tomography', 'dental structure', 'design', 'experience', 'graft failure', 'graft healing', 'healing', 'improved', 'oral care', 'point of care', 'soft tissue', 'targeted treatment', 'tool', 'two-dimensional']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R56,2021,642438
"Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software. Abstract (Proposal title: Neuroscience Gateway to Enable Dissemination of Computational and Data Processing Tools and Software.): This proposal presents a focused plan for expanding the capabilities of the Neuroscience Gateway (NSG) to meet the evolving needs of neuroscientists engaged in computationally intensive research. The NSG project began in 2012 with support from the NSF. Its initial goal was to catalyze progress in computational neuroscience by reducing technical and administrative barriers that neuroscientists faced in large scale modeling projects involving tools and software which require and run efficiently on high performance computing (HPC) resources. NSG's success is reflected in the facts that (1) its base of registered users has grown continually since it started operation in early 2013 (more than 800 at present), (2) every year the NSG team successfully acquires ever larger allocations of supercomputer time (recently more than 10,000,000 core hours/year) on academic HPC resources of the Extreme Science and Engineering Discovery (XSEDE – that coordinates NSF supercomputer centers) program by writing proposals that go through an extremely competitive peer review process, and (3) it has contributed to large number of publications and Ph.D thesis. In recent years experimentalists, cognitive neuroscientists and others have begun using NSG for brain image data processing, data analysis and machine learning. NSG now provides over 20 tools on HPC resources for modeling, simulation and data processing. While NSG is currently well used by the neuroscience community, there is increasing interest from that community in applying it to a wider range of tasks than originally conceived. For example, some are trying to use it as an environment for dissemination of lab-developed tools, even though NSG is not suitable for that use because of delays from the batch queue wait times of production HPC resources, and lack of features and resources for an interactive, graphical, and collaborative environment needed for tool development, benchmarking and testing. “Forced” use of NSG for development and dissemination makes NSG's operators a “person-in-the-middle” bottleneck in the process. Another issue is that newly developed data processing tools require high throughput computing (HTC) usage mode, as opposed to HPC, but currently NSG does not provide access to compute resources suitable for HTC. Additionally, data processing workflows require features such as the ability to transfer large size data, process shared data, and visualize output results, which are not currently available on NSG. The work we propose will enhance NSG by adding the features that it needs to be a suitable and efficient dissemination environment for lab-developed neuroscience tools to the broader neuroscience community. This will allow tool developers to disseminate their lab-developed tools on NSG taking advantage of the current functionalities that are being well served on NSG for the last six years such as a growing user base, an easy user interface, an open environment, the ability to access and run jobs on powerful compute resources, availability of free supercomputer time, a well-established training and outreach program, and a functioning user support system. All of these well-functioning features of NSG will make it an ideal environment for dissemination and use of lab-developed computational and data processing neuroscience tools. The Neuroscience Gateway (NSG) was first implemented to enable large scale computational modeling of brain cells and circuits used to study neural function in health and disease. This new project extends NSG's utility to support development, dissemination and use of new tools by the neuroscience community for analyzing enormous data sets produced by advanced experimental methods in neuroscience.",Neuroscience Gateway to Enable Dissemination of Computational And Data Processing Tools And Software.,10186744,U24EB029005,"['Behavioral', 'Benchmarking', 'Brain imaging', 'Cells', 'Cognitive', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Correlations', 'Data Science', 'Data Set', 'Development', 'Disease', 'Education', 'Education and Outreach', 'Educational workshop', 'Electroencephalography', 'Engineering', 'Environment', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Funding', 'Future', 'Goals', 'Health', 'High Performance Computing', 'Hour', 'Human Resources', 'Image', 'Machine Learning', 'Magnetic Resonance Imaging', 'Methods', 'Modeling', 'Neurophysiology - biologic function', 'Neurosciences', 'Neurosciences Research', 'Occupations', 'Output', 'Peer Review', 'Persons', 'Process', 'Production', 'Psychologist', 'Publications', 'Reaction Time', 'Research', 'Research Personnel', 'Resources', 'Running', 'Science', 'Software Tools', 'Students', 'Support System', 'System', 'Testing', 'Time', 'Training', 'Training Programs', 'United States National Institutes of Health', 'Wait Time', 'Work', 'Workload', 'Writing', 'base', 'bioimaging', 'brain cell', 'collaborative environment', 'computational neuroscience', 'computerized data processing', 'computing resources', 'data sharing', 'image processing', 'interest', 'models and simulation', 'open data', 'operation', 'outreach program', 'programs', 'response', 'success', 'supercomputer', 'tool', 'tool development', 'trend', 'webinar']",NIBIB,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",U24,2021,377473
"Flexible Piezoelectric Array for Cardiovascular MonitoringDuring Cardiac Arrest Project Summary In situations of out of hospital cardiac arrest, it is critical to quickly detect the performance of adequate cardiopulmonary resuscitation (CPR) through clinically acceptable pulse rate and blood pressure (BP). However, the detection of adequate CPR can be difficult for someone not trained in first aid. Currently the standard for measuring BP noninvasively is using cuff-based oscillometeric approaches. Attempts at developing these into wearable devices for automated and continuous measurements have proven difficult and so researchers have looked at other methods. However, these methods have not met the criteria for flexibility, accuracy, and low power consumption. This project aims to develop a flexible patch for accurate detection of pulse rate and blood pressure superficially through the radial, brachial, carotid, and/or femoral arteries. Piezoelectric polymers, are inherently flexible and have been used in many applications for pressure sensing, offering great potential for use as a patch-like sensor for monitoring of cardiovascular function. However, in the standard form, the material is not sensitive enough to accurately detect blood pressure. In our lab we have developed a core-shell nanofiber structure of conductive and piezoelectric nanofibers, respectively. The core-shell nanostructure shows a 4.5 times improvement in pressure sensitivity when compared to standard piezoelectric nanofibers and a nearly 40 times improvement when compared to piezoelectric polymer thin films. This improvement in pressure sensitivity should allow for a wearable device composed of these materials to exceed the necessary 35 dB signal to noise ratio required for the accurate detection of pulse wave velocity, a cardiovascular parameter used to determine blood pressure. Coupled with inkjet printing patterning techniques of conductive polymers developed in our lab, we propose to fabricate a novel core-shell nanofiber piezoelectric array in a wearable patch form for cardiovascular monitoring. In order to test this piezoelectric array and develop data-driven algorithms for the detection of blood pressure, testing will occur on a controllable simulated cardiovascular system capable of replicating a human’s diastolic and systolic blood pressures, pulse rates, and arterial mechanical properties. The blood pressure attainable by the simulated system falls within the AAMI standard benchmark for accuracy and precision for noninvasive blood pressure monitoring of 5 ± 8 mmHg. We will train various regression models using the data generated from this system to relate the detected pulse wave velocities to blood pressure and we will compare the outcomes to commonly used correlation equations. We propose that the fabrication methods we will develop, when coupled together with data-driven algorithms, will allow for the development of a low- power, flexible patch, capable of detecting pulse rate and blood pressure, giving feedback on the adequacy of CPR. Project Narrative This project plans to develop a patch-like sensor for detecting cardiovascular signals including pulse rate and blood pressure for situations of out of hospital cardiac arrest. The proposed research couples a novel core-shell piezoelectric nanostructure with an inkjet printing method for fabricating flexible arrays, to create a new class of wearable patch-like sensors for cardiovascular monitoring. Testing these sensors on a controllable simulated cardiovascular system, will allow for the development of data-driven algorithms to improve the accuracy of these devices, leading to highly accurate, patch-like cardiovascular sensing.",Flexible Piezoelectric Array for Cardiovascular MonitoringDuring Cardiac Arrest,10288237,R21EB032056,"['Algorithms', 'Arteries', 'Benchmarking', 'Biosensing Techniques', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood flow', 'Cardiopulmonary Resuscitation', 'Cardiovascular Physiology', 'Cardiovascular system', 'Caring', 'Carotid Arteries', 'Clinical', 'Complex', 'Consumption', 'Coupled', 'Couples', 'Data', 'Deposition', 'Detection', 'Development', 'Device Designs', 'Devices', 'Electrocardiogram', 'Electrodes', 'Equation', 'Feedback', 'Film', 'First Aid', 'Goals', 'Harvest', 'Heart Arrest', 'Human', 'Individual', 'Ink', 'Liquid substance', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Monitor', 'Nanostructures', 'Noise', 'Outcome', 'Output', 'Pattern', 'Performance', 'Photoplethysmography', 'Physiologic pulse', 'Polymers', 'Printing', 'Property', 'Protocols documentation', 'Pulse Pressure', 'Pulse Rates', 'Research', 'Research Personnel', 'Signal Transduction', 'Skin', 'Sphygmomanometers', 'Structure', 'Sulfur', 'System', 'Techniques', 'Technology', 'Testing', 'Thinness', 'Time', 'Training', 'Work', 'base', 'brachial artery', 'detection method', 'falls', 'femoral artery', 'first responder', 'flexibility', 'human subject', 'improved', 'mechanical properties', 'nanofiber', 'novel', 'out-of-hospital cardiac arrest', 'polyvinylidene fluoride', 'pressure', 'pressure sensor', 'pulse pressure wave', 'radial artery', 'random forest', 'sensor', 'spatiotemporal', 'standard measure', 'wearable device']",NIBIB,DARTMOUTH COLLEGE,R21,2021,232061
"COVID-19 detection through scent analysis with a compact GC device Recent studies, including ours, have suggested that breath may allow us to diagnose COVID-19 infection and even monitor its progress. As compared to immunological and genetic based methods using sample media like blood, nasopharyngeal swab, and saliva, breath analysis is non-invasive, simple, safe, and inexpensive; it allows a nearly infinite amount of sample volume and can be used at the point-of-care for rapid detection. Fundamentally, breath also provides critical metabolomics information regarding how human body responds to virus infection and medical intervention (such as drug treatment and mechanical ventilation). The objectives of the proposed SCENT project are: (1) to refine automated, portable, high-performance micro-gas chromatography (GC) device and related data analysis / biomarker identification algorithms for rapid (5-6 minutes), in-situ, and sensitive (down to ppt) breath analysis and (2) to conduct breath analysis on up to 760 patients, and identify and validate the COVID-19 biomarkers in breath. Thus, in coordination with the RADx-rad Data Coordination Center (DCC), we will complete the following specific aims. (1) Refine 5 automated micro-GC devices to achieve higher speed and better separation capability. We will construct 5 new automated and portable one-dimensional micro-GC devices that require only ~6 minutes of assay time (improved from current 20 minutes) at the ppt level sensitivity (Sub-Aim 1a). Then the devices will be upgraded to 2-dimensional micro-GC to significantly increase the separation capability (Sub-Aim 1b). In the meantime, we will optimize and automate our existing data processing and biomarker identification algorithms and codes to streamline the workflow so that the GC device can automatically process and analyze the data without human intervention (Sub-Aim 1c). (2) Identify breath biomarkers that distinguish COVID-19 positive (symptomatic and asymptomatic) and negative patients. We will recruit a training cohort of 380 participants, including 190 COVID-19 positive patients (95 symptomatic and 95 asymptomatic) and 190 COVID-19 negative patients from two hospitals (Michigan Medicine – Ann Arbor and the Henry Ford Hospital – Detroit). We will conduct breath analysis using machine learning to identify VOC patterns that match each COVID-19 diagnostic status. (3) Validate the COVID-19 biomarkers using our refined micro-GC devices. Using the refined 2-D micro-GC devices from Sub-Aim 1b, we will recruit a new validation cohort of 380 participants (190 COVID-19 positive patients and 190 COVID-19 negative patients) to validate the biomarkers identified in Aim 2.  We will leverage existing engineering, data science, clinical, regulatory, and commercialization resources throughout the project to hit our milestones, ensuring a high likelihood of rapid patient impact. Upon completion of this work, we will have a portable micro-GC device and accompanying automated algorithms that can detect and monitor COVID-19 status for people in a variety of clinical and community settings. Narrative  Our team of engineers, clinicians, and data scientists has developed a portable, high performance breath analyzer that can be used to detect certain diseases. In this project, we will adapt and refine our existing device and algorithms so they can be used for rapid, safe, and non- invasive COVID-19 detection. People will simply breath into the device and it will quickly provide results, meaning that it can be used in a variety of everyday settings to help fight against the COVID-19 pandemic.",COVID-19 detection through scent analysis with a compact GC device,10266206,U18TR003812,"['Acute', 'Agreement', 'Algorithms', 'Biological Assay', 'Biological Markers', 'Biotechnology', 'Blood', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnosis', 'COVID-19 diagnostic', 'COVID-19 monitoring', 'COVID-19 pandemic', 'COVID-19 patient', 'Cessation of life', 'Clinical', 'Code', 'Critical Care', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Science', 'Data Scientist', 'Devices', 'Diagnosis', 'Dimensions', 'Disease', 'Engineering', 'Ensure', 'Gas Chromatography', 'Genetic', 'Health', 'Hospitals', 'Human', 'Human body', 'Immunologics', 'In Situ', 'Institutes', 'Institutional Review Boards', 'Intervention', 'Licensing', 'Machine Learning', 'Mechanical ventilation', 'Medical', 'Medicine', 'Methods', 'Michigan', 'Monitor', 'Participant', 'Patients', 'Pattern', 'Performance', 'Pharmacotherapy', 'Process', 'Production', 'RADx Radical', 'Research', 'Resources', 'Respiratory Failure', 'SARS-CoV-2 infection', 'SARS-CoV-2 negative', 'SARS-CoV-2 positive', 'Saliva', 'Sampling', 'Savings', 'Services', 'Severities', 'Speed', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Virus Diseases', 'Work', 'automated algorithm', 'base', 'biomarker identification', 'cohort', 'commercialization', 'community setting', 'computerized data processing', 'cost', 'design', 'fight against', 'fighting', 'global health', 'improved', 'metabolomics', 'multidisciplinary', 'nasopharyngeal swab', 'outcome forecast', 'pandemic disease', 'point of care', 'portability', 'rapid detection', 'recruit', 'respiratory hypoxia', 'screening', 'severe COVID-19', 'two-dimensional']",NCATS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,U18,2021,999775
"Integrating multidimensional genomic data to discover clinically-relevant predictive models The goal of this NIH Pathway to Independence award is to provide Dr. Brittany Lasseigne with an extensive training program to prepare her to be an effective independent investigator who uses computational genomics to study complex human diseases. We propose a formal one-year training and mentoring program in genomics, computer science, statistics, and career development to build on her 8+ years of hands-on training, followed by a three-year structured and independent research program. Research will focus on the integration of multidimensional genomic data sets in the context of complex human diseases. A critical barrier in genomic research is the complexity of data integration: the ability to leverage overlapping and unique information captured by different genomic assays would improve our understanding of data integration and generate clinically relevant genomic signatures. To meet this need, we propose to integrate a combination of genomic data we generated with public data to (1) infer genomic instability signatures from different data types, (2) improve clinically relevant phenotype prediction by building multi-omics machine learning classifiers and reducing phenotype heterogeneity, and (3) create a cloud-enabled R package and associated Shiny application to accelerate future research. The proposed work will advance our understanding of data integration, allow inference of genomic instabilities across data sets, and generate high performance classifiers for assessing clinically relevant phenotypes in both cancer and psychiatric disease using frameworks that will be broadly applicable across other complex diseases. It will also facilitate prioritization of experiments in future studies by informing on the orthogonality of genomic assays, thereby allowing more efficient study designs to capture as much information as possible within a given sample size or scope of experimentation. Collectively, this additional training will allow Dr. Lasseigne to develop new multidimensional data integration approaches and translational questions applicable across complex diseases when independent. Dr. Richard Myers (HudsonAlpha) and Dr. Gregory Cooper (HudsonAlpha), leaders in applying genetics and genomics to complex human diseases, and an Advisory Committee of additional experts including Dr. Barbara Wold (Caltech), Dr. Eddy Yang (UAB), and Dr. Timothy Reddy (Duke), will provide mentoring throughout this award. The mentored phase will take place at the HudsonAlpha Institute for Biotechnology, an ideal environment for this training with extensive translational science collaborations, expert faculty and staff, and state-of-the art computational and laboratory resources devoted to genomics. This combination will maximize Dr. Lasseigne's training program, facilitating her transition to an independent, tenure-track investigator at a university with a strong commitment to data-driven approaches to complex human disease research, i.e. strong genomics research programs with clinical collaborators, ideally at, or affiliated with, an academic medical center. Project Narrative The major outcome of this project will be a scientist with the necessary research, mentoring, teaching, and career development training to run an independent research program in computational genomics. The research proposed will apply novel strategies to further develop integrative machine learning analyses of multidimensional genomic data, discover clinically relevant predictive models, and create computational tools to accelerate future research.",Integrating multidimensional genomic data to discover clinically-relevant predictive models,10131237,R00HG009678,"['Academic Medical Centers', 'Advisory Committees', 'Award', 'Bioconductor', 'Biological', 'Biological Assay', 'Biotechnology', 'Budgets', 'Cancer Etiology', 'Cell Proliferation', 'Cells', 'Characteristics', 'Chemotherapy-Oncologic Procedure', 'Chromosomal Instability', 'Chromosomes', 'Classification', 'Clinical', 'Clinical Data', 'Collaborations', 'Complex', 'Copy Number Polymorphism', 'Coupling', 'CpG Island Methylator Phenotype', 'DNA', 'DNA Methylation', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Educational process of instructing', 'Environment', 'Faculty', 'Future', 'Gene Expression', 'Gene Proteins', 'Genes', 'Genetic', 'Genomic Instability', 'Genomics', 'Goals', 'Heterogeneity', 'Individual', 'Institutes', 'Instruction', 'Laboratories', 'Lasso', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Mental disorders', 'Mentors', 'Methodology', 'Methylation', 'MicroRNAs', 'Microsatellite Instability', 'Modeling', 'Molecular Profiling', 'Neurons', 'Outcome', 'Pathway interactions', 'Performance', 'Phase', 'Phenotype', 'Procedures', 'Regulatory Element', 'Reproducibility', 'Research', 'Research Design', 'Research Personnel', 'Resources', 'Running', 'Sample Size', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Signal Transduction', 'Structure', 'Systems Biology', 'Techniques', 'Testing', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'Variant', 'Visualization', 'Work', 'Yang', 'biomarker performance', 'career development', 'clinically relevant', 'computer science', 'computerized tools', 'data framework', 'data integration', 'data reduction', 'data standards', 'experimental study', 'genomic data', 'genomic signature', 'human disease', 'improved', 'insight', 'learning classifier', 'multidimensional data', 'multiple omics', 'novel strategies', 'predictive modeling', 'programs', 'promoter', 'protein metabolite', 'response', 'single cell sequencing', 'statistics', 'tenure track', 'tool']",NHGRI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R00,2021,249000
"An Unobtrusive Continuous Cuff-less Blood Pressure Monitor for Nocturnal Hypertension PROJECT SUMMARY/ABSTRACT The objective of this project is to create an unobtrusive, wrist-worn, cuff-less blood pressure monitor for measurement and identification of nocturnal nondipping hypertension. The investigation includes extensive validation with state-of-the-art ambulatory blood pressure monitors at nighttime in presence of heterogeneous treatment paradigms. Cardiovascular disease (CVD) is one of the major causes of ailments worldwide. Hypertension alone affects one in three adults according to the World Health Organization. Therefore, monitoring blood pressure has become a critical part of healthcare as it is known to be linked to many CVDs. Traditionally, clinical practitioners have relied on the mercury-based (or digital equivalent) inflatable cuff-based sphygmomanometer. However, the nature of the device allows for only infrequent measurements and its somewhat invasive nature and associated discomfort prohibits additional nocturnal measurements. There is certainly a value to measuring blood pressure continuously in the natural context of the user’s environment, in particular during sleep, without being disturbed by the instrument. Our proposed technology can provide a wealth of information to physicians, help identify certain short-term dynamics/variations of blood pressure, and allow effective monitoring of response to medication, among other things. Nocturnal measurements provide additional prognostic value in identifying risk. Despite these benefits, no wearable, non-invasive device for continuous blood pressure monitoring exists on the market simply because none have been reliable enough to be considered clinical grade. This project aims to develop a robust and reliable blood pressure monitor in the form of a wrist-worn device that uses bio-impedance sensors, and for the first time, demonstrate clinical grade reliability. These sensors measure pulse wave velocity (PWV) along with several other derivatives for cardiovascular parameters including heart rate and blood volume changes in arteries, which correlate with the blood pressure. The system will incorporate clever hardware design to localize underlying vasculature and focus on arterial sites for enhanced accuracy. The device will include a motion sensor to take into account the user’s movements and motion artifacts, the contact quality, and reliability of the measurements. Advanced machine learning techniques, leveraging both general and personalized models, will be developed to convert bio-impedance measurements to blood pressure. This project aims to then validate the system and analytics in both a healthy patient cohort and a hypertensive cohort, learning the impact that nocturnal ‘nondipping’ hypertension and anti-hypertensive treatments have on PWV/other cardiovascular correlates and blood pressure estimates. After decades of relying on the inflatable cuff- based technique, this system could represent a significant change in how we measure blood pressure. PROJECT NARRATIVE Continuous monitoring of nocturnal blood pressure can help early diagnosis of developing cardiac conditions, reveal short term blood pressure variations, and also help the physician monitor differences in variations in response to medication for hypertensive patients. Moreover, the comfort and convenience of a wearable monitor would allow measurement in the natural context of daily life, including important nocturnal measurements, and reduce the burden of adherence on the user. The system will also provide feedback on quality of measurements to allow the users or care-givers to gauge reliability.",An Unobtrusive Continuous Cuff-less Blood Pressure Monitor for Nocturnal Hypertension,10166912,R01HL151240,"['Adherence', 'Adult', 'Affect', 'Age', 'Ambulatory Blood Pressure Monitoring', 'Antihypertensive Agents', 'Arteries', 'Awareness', 'Biometry', 'Blood Pressure', 'Blood Pressure Monitors', 'Blood Volume', 'Blood flow', 'Calibration', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular system', 'Caregivers', 'Characteristics', 'Clinical', 'Data', 'Data Collection', 'Development', 'Devices', 'Early Diagnosis', 'Environment', 'FDA approved', 'Feedback', 'Future', 'Gold', 'Healthcare', 'Heart Rate', 'Home environment', 'Hour', 'Human', 'Hypertension', 'Investigation', 'Learning', 'Legal patent', 'Life', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mercury', 'Methods', 'Microfabrication', 'Modeling', 'Monitor', 'Morphologic artifacts', 'Motion', 'Movement', 'Nature', 'Organ', 'Outcome', 'Outcomes Research', 'Participant', 'Patient Monitoring', 'Patient risk', 'Patients', 'Pattern', 'Penetration', 'Pharmaceutical Preparations', 'Physicians', 'Physiologic pulse', 'Physiology', 'Positioning Attribute', 'Proxy', 'Reading', 'Recording of previous events', 'Regimen', 'Research', 'Risk', 'Risk Factors', 'Science', 'Signal Transduction', 'Site', 'Skin', 'Sleep', 'Sleep Deprivation', 'Sphygmomanometers', 'Structural Models', 'Supine Position', 'System', 'Techniques', 'Technology', 'Time', 'Uncertainty', 'Validation', 'Variant', 'Work', 'World Health Organization', 'Wrist', 'advanced analytics', 'analytical method', 'arterial stiffness', 'base', 'cohort', 'comorbidity', 'design', 'digital', 'effectiveness validation', 'electric impedance', 'insight', 'instrument', 'model development', 'monitoring device', 'motion sensor', 'multidisciplinary', 'novel', 'novel strategies', 'patient stratification', 'patient subsets', 'performance tests', 'prognostic value', 'response', 'sensor', 'sex', 'sleep position', 'supine sleep', 'wearable device', 'wearable sensor technology', 'willingness']",NHLBI,TEXAS ENGINEERING EXPERIMENT STATION,R01,2021,678001
"Acoustofluidic Separation of Placental Nanovesicle Subpopulations in Obstetrical Diseases The placenta is essential for fetal development and growth, maternal homeostasis, and broadly, pregnancy health. Yet, our ability to non-invasively probe placental health during human pregnancy is hampered by its deep intrauterine location and its highly vascular composition, rendering the placenta largely inaccessibly for safe and dynamic investigation. Whereas placental research has been advanced by cell culture, ex vivo systems, animal models, and postpartum analyses, these indirect approaches provide ex post facto information about placental health. Placental imaging has revolutionized the field of placental medicine, but resolution at the molecular, cellular, or metabolic level remains limited. To address these challenges, we and others have focused on the release of extracellular vesicles (EVs) from placental trophoblasts, which, in humans, are directly bathed in maternal blood. We focused on exosomes (now termed small EVs or sEVs), microvesicles, and apoptotic blebs, which are continuously and abundantly released from trophoblasts into the maternal circulation and are accessible throughout pregnancy by peripheral blood tests. Among these EVs, we focus mainly on placental sEVs, which harbor messages that are seldom expressed by any other cell types and execute unique placental biological functions, such as an antiviral response. While informative, recent data indicate that sEVs are not a uniform population of vesicles, but comprise several subgroups, defined as large sEVs, small sEVs, and exomeres. In addition to their size, these sEV subtypes are characterized by distinctive cargo. Although the recent discovery of sEV subpopulations has excited researchers due to their potential to revolutionize the field of non-invasive diagnostics, sEV subpopulations have yet to be utilized in clinical settings. This is largely due to the difficulties associated with separation and isolation the nano-sized sEV subpopulations. Our group has now developed advanced acoustofluidic technologies designed to effectively, reproducibly, and rapidly isolate sEVs from blood. We show that we can separate placental sEVs into their specific subpopulations, which has not been previously accomplished. Our proposed investigation therefore focuses on the production of human placental sEV subpopulations, along with their RNA and proteome cargo. We posit that, by profiling these analytes from sEV subpopulations, we can illuminate a unique landscape of bioactive molecules that are relevant to placental health. To reduce data complexity, we propose a machine learning pipeline that will be used to probe the sub-sEV spectra during normal and pathological pregnancies. Further, we will improve our ability to purify sEV subpopulations from lipoproteins, and generate a single, integrated device that can reliably separate vesicles in real time across human gestation. We believe that our automated acoustofluidic approach to separating sEV subpopulations in a high-yield, biocompatible manner is critical to unlocking the clinical utility of sEVs. Insights gained from our investigation will improve non-invasive diagnostics during pregnancy and may uncover new targets for personalized placental therapeutics. Our proposal centers on the discovery and analysis of previously unrecognized nanovesicle subpopulations that are produced by placental cells and are released to the maternal-fetal circulation. By studying these nanovesicle subpopulations in health and diseases of human pregnancy and by innovating new technologies to efficiently, rapidly, and reproducibly purify these nanovesicles from the blood and other biological media, we enable pioneering tools to interrogate the placenta in real time and improve clinical care during pregnancy.",Acoustofluidic Separation of Placental Nanovesicle Subpopulations in Obstetrical Diseases,10099051,R01HD103727,"['Address', 'Animal Model', 'Antiviral Response', 'Apoptotic', 'Biological', 'Biological Process', 'Biology', 'Blood', 'Blood Circulation', 'Blood Tests', 'Blood Vessels', 'Bulla', 'Cell Culture Techniques', 'Cells', 'Clinical', 'Communication', 'Culture Media', 'Data', 'Devices', 'Diagnostic', 'Dimensions', 'Discipline of obstetrics', 'Disease', 'Fetal Development', 'Fetal Growth Retardation', 'Field Flow Fractionation', 'Functional disorder', 'Funding', 'Genomics', 'Glean', 'Grant', 'Growth Factor', 'Growth and Development function', 'Health', 'Health Status', 'Homeostasis', 'Hormones', 'Human', 'Image', 'Inherited', 'Injury', 'Investigation', 'Lipoproteins', 'Location', 'MLLT2 gene', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuscripts', 'Maternal-Fetal Exchange', 'Medicine', 'Metabolic', 'MicroRNAs', 'Modification', 'Molecular', 'National Institute of Child Health and Human Development', 'Nature', 'Pathologic', 'Pathway interactions', 'Physiological', 'Placenta', 'Placenta Diseases', 'Placental Biology', 'Plasma', 'Population', 'Positioning Attribute', 'Postpartum Period', 'Pre-Eclampsia', 'Pregnancy', 'Production', 'Proteins', 'Proteome', 'Proteomics', 'RNA', 'Reporting', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Signal Transduction', 'Source', 'Subgroup', 'Surface', 'System', 'Technology', 'Therapeutic', 'Time', 'Tissues', 'Ultrasonography', 'Uterus', 'Vesicle', 'Woman', 'bioinformatics tool', 'biomaterial compatibility', 'cell type', 'clinical care', 'clinically relevant', 'design', 'differential expression', 'epigenomics', 'exosome', 'extracellular vesicles', 'fetal', 'first responder', 'human disease', 'improved', 'in vivo', 'innovation', 'insight', 'liquid biopsy', 'microvesicles', 'molecular diagnostics', 'nanosized', 'nanovesicle', 'new technology', 'noninvasive diagnosis', 'novel', 'peripheral blood', 'response', 'tool', 'trait', 'transcriptome', 'transcriptomics', 'trophoblast', 'vesicular release']",NICHD,MAGEE-WOMEN'S RES INST AND FOUNDATION,R01,2021,542123
"Mitochondrial regulation of stress reactivity in humans Chronic dysregulation of physiological systems manifests systemically as allostatic load (AL) and in abnormal stress reactivity profiles, which are features of psychopathological conditions that increase future disease risk. But the biological basis underlying inter-individual differences in stress regulation and reactivity remains unknown. Even among populations of healthy individuals exposed to standardized laboratory challenges, such as the Trier social stress test (TSST), there are substantial differences in the magnitude of responses in multiple physiological systems, including but not limited to the hypothalamic-pituitary-adrenal (HPA) axis, the autonomic nervous system (ANS) and cardiovascular system, metabolic changes, and immune and pro-inflammatory systems. One common factor to all stress systems is their dependence on energy supply, which fuels every aspect of the stress response including molecular, cellular, systemic and cognitive/psychological functioning. At the cellular level, energy is provided by mitochondria, unique organelles that populate the cell cytoplasm and contain their own genome, the mitochondrial DNA (mtDNA), that is essential to mitochondrial health. MtDNA defects cause dysregulation of multiple aspects of mitochondrial structure and function, known as mitochondrial allostatic load (MAL). Three main lines of evidence suggest that MAL contributes to AL and regulates stress responses in humans: i) we recently discovered that the mtDNA is released following psychological stress in humans (PNEC 2019), ii) experimentally-induced MAL in animals caused specific alterations in the multisystem physiological responses to psychological stress (PNAS 2015), and iii) mitochondria are the source of stress hormones, including cortisol that is synthesized in mitochondria within the adrenal glands (Nat Genetics 2012). Together, this evidence suggests that MAL may alter both baseline AL and stress reactivity profiles, potentially providing new insight into the source of interindividual differences in stress regulation and health in general. In this project, we perform the first comprehensive assessment of MAL, systemic AL, multisystem stress reactivity to a laboratory challenge (TSST) in three groups of individuals who have rare genetic mtDNA defects that selectively causes different forms of MAL and in a healthy control group. Multisystem stress biomarker profiling under fasting baseline and stress reactive conditions will provide a comprehensive test of pathways linking MAL to stress physiology in humans. The resulting high-dimensionality data will be treated using integrative data analytic approaches and classifying algorithms, including cross-validated machine learning models, to identify resting and stress-reactive biomarker signatures responsive to MAL. In parallel, assessments of executive function and key domains of psychosocial functioning including mood, stress, anxiety, depressive symptoms, and well-being will contribute to provide a comprehensive picture of novel mitochondrial psychobiological pathways. NARRATIVE There are large unexplained inter-individual differences in systemic allostatic load and stress reactivity, which may in part be explained by mitochondria. Here we study the effects of chronic dysregulation of mitochondrial function – mitochondrial allostatic load (MAL) – on multisystem stress regulation in humans. This project will establish the influence of MAL on baseline AL as well as multisystem stress reactivity profiles, defining novel psychobiological pathways by which mitochondria may contribute to the maintenance of health and resilience, and to disease risk.",Mitochondrial regulation of stress reactivity in humans,10145795,R01MH122706,"['Adrenal Glands', 'Algorithms', 'Animals', 'Anxiety', 'Autonomic nervous system', 'Biological', 'Biological Markers', 'Biology', 'Blood', 'Blood Pressure', 'Brain', 'Cardiovascular system', 'Catecholamines', 'Cells', 'Chronic', 'Clinical', 'Clinical Data', 'Cognitive', 'Control Groups', 'Cytoplasm', 'Data', 'Data Analytics', 'Defect', 'Dependence', 'Disease', 'Disease Pathway', 'Energy Supply', 'Esthesia', 'Executive Dysfunction', 'Exhibits', 'Exposure to', 'Fasting', 'Fatigue', 'Foundations', 'Future', 'Galvanic Skin Response', 'Gatekeeping', 'Generations', 'Genetic', 'Genome', 'Glucocorticoids', 'Hair', 'Health', 'Heart', 'Hematology', 'Hormones', 'Hour', 'Human', 'Hydrocortisone', 'Hypothalamic structure', 'IL6 gene', 'Immune', 'Immune system', 'Individual', 'Individual Differences', 'Inflammatory', 'Inherited', 'Laboratories', 'Leukocytes', 'Link', 'Machine Learning', 'Maintenance', 'Maps', 'Measures', 'Mental Depression', 'Metabolic', 'Methods', 'Mitochondria', 'Mitochondrial DNA', 'Modeling', 'Molecular', 'Monitor', 'Moods', 'Mus', 'National Institute of Mental Health', 'Neuropsychology', 'Neurosecretory Systems', 'Organelles', 'Participant', 'Pathway interactions', 'Personal Satisfaction', 'Phenotype', 'Physiological', 'Physiology', 'Pituitary Gland', 'Ploidies', 'Population', 'Positioning Attribute', 'Process', 'Protocols documentation', 'Psychological Stress', 'Psychophysiology', 'Psychosocial Factor', 'Recovery', 'Regulation', 'Respiratory Chain', 'Rest', 'Role', 'Saliva', 'Signal Transduction', 'Source', 'Specificity', 'Standardization', 'Stress', 'Structure', 'System', 'Testing', 'Time', 'Translating', 'Trier Social Stress Test', 'allostatic load', 'base', 'biological adaptation to stress', 'biomarker signature', 'cognitive function', 'cytokine', 'depressive symptoms', 'disorder risk', 'epigenome', 'executive function', 'experience', 'heart rate variability', 'hypothalamic-pituitary-adrenal axis', 'indexing', 'insight', 'instrument', 'mouse model', 'multidimensional data', 'negative affect', 'negative mood', 'novel', 'personalized predictions', 'pre-clinical', 'preclinical study', 'psychobiologic', 'psychologic', 'psychosocial', 'resilience', 'respiratory', 'response', 'stress reactivity', 'trait', 'urinary']",NIMH,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,764882
"The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets Project Summary/Abstract The ultimate goal of the HIVE MC-IU effort is to develop a common coordinate framework (CCF) for the healthy human body that supports the cataloguing, exploration, and download of differenttypes of tissue and individual cell data. The CCF will use different visual interfaces in order to exploit human and machine intelligence to improve data exploration and communication. The proposed effort combines decades of expertise in data and network visualization, scientific visualization, biology, and biomedical data standards. The goal is to develop a highly accurate and extensible multidimensional spatial basemap of the human body with associated data overlays. This basemap will be designed for online exploration as an atlas of tissue maps composed of diverse cell types, developed in close collaboration with the HIVE MC-NYGC team. To implement this functionality, we will develop methods to map and connect metadata, pixel/voxel data, and extracted vector data, allowing users to “navigate” across multiple levels (whole body, organ, tissue, cells). MC-IU will work in close collaboration with the HIVE Infrastructure and Engagement Component (IEC) and tools components (TCs) to connect and integrate further computational, analytical, visualization, and biometric resources driven by spatial context. Project Narrative This project will create a high-resolution, functional mapping of voxel, vector, and meta datasets in support of integration, interoperability, and visualization of biomedical HuBMAP data and models. We will create an extensible common coordinate framework (CCF) to facilitate the integration of diverse image-based data at spatial scales ranging from the molecular to the anatomical. This project will work in close coordination with the HuBMAP consortium to help drive an ecosystem of useful resources for understanding and leveraging high-resolution human image data and to compile a human body atlas.","The Human Body Atlas: High-Resolution, Functional Mapping of Voxel, Vector, and Meta Datasets",10397321,OT2OD026671,"['Anatomy', 'Artificial Intelligence', 'Atlases', 'Biology', 'Biometry', 'Cataloging', 'Cells', 'Collaborations', 'Communication', 'Data', 'Data Set', 'Ecosystem', 'Goals', 'Human', 'Human BioMolecular Atlas Program', 'Human body', 'Image', 'Individual', 'Infrastructure', 'Maps', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Organ', 'Resolution', 'Resources', 'Tissues', 'Visual', 'Visualization', 'Work', 'base', 'cell type', 'data exploration', 'data standards', 'design', 'human imaging', 'improved', 'interoperability', 'tool', 'vector']",OD,INDIANA UNIVERSITY BLOOMINGTON,OT2,2021,1500000
"Carolina Population Center PROJECT SUMMARY/ABSTRACT The Carolina Population Center requests infrastructure support that will advance population dynamics research at CPC by increasing research impact, innovation, and productivity, supporting the development of junior scientists, and reducing the administrative burden on scientists. Infrastructure support will advance science in three primary research areas: Sexuality, Reproduction, Fertility, and Families; Population, Health, and the Environment; and Inequality, Mobility, Disparities, and Well-Being. Much of the research at CPC draws on large publicly available longitudinal data sets that our faculty have designed and collected, including the National Longitudinal Study of Adolescent to Adult Health, the China Health and Nutrition Survey, newer surveys associated with the Transfer Project, and the Study of the Tsunami Aftermath and Recovery, all of which will continue to be important in work related to our primary research areas over the next five years. These projects embody several themes that have guided research at CPC since the Center's inception. These themes, which will continue to shape our work, are the importance of life course processes and longitudinal data, multi-level processes and measurement of context, interventions and natural experiments as means of learning about causal processes, and the relevance of sociodemographic variables such as age, gender, race- ethnicity, and socioeconomic status for disparities in health and well-being. By embedding these themes, our projects provide data that enable us to address barriers that otherwise impede progress in the population sciences generally, and in our primary research areas in particular. We request support for three cores which in combination will provide an institutional infrastructure that will push populations dynamics research forward by empowering CPC faculty to tackle challenging questions using state of the art measurement techniques and methods. The Administrative Core plans activities that maintain a stimulating intellectual community, streamlines administrative processes so that scientists can focus on research, coordinates activities of the Cores so that services are offered efficiently, and communicates information about research and data more broadly. The Development Core supports early stage investigators and other faculty with exciting new ideas through multiple mechanisms: workshops, access to technical expertise in measurement, and seed grants. The Research Services Core enables scientists to address complex and important population research issues by providing access to state-of-the-art research tools and professional support for programming, survey development, and analysis. NARRATIVE This project will provide infrastructure support for a cutting edge program of research on population dynamics at the Carolina Population Center. Research at the Center will analyze state-of-the art data to address fundamental questions regarding fertility, adolescent health, and links between the environment and health. Special attention will be paid to factors creating health disparities.",Carolina Population Center,10136647,P2CHD050924,"['Address', 'Adolescent', 'Adopted', 'Adult', 'Age', 'Applications Grants', 'Area', 'Attention', 'Biological Markers', 'China', 'Cognitive', 'Collaborations', 'Communication', 'Communities', 'Complex', 'Computer Vision Systems', 'Creativeness', 'Data', 'Data Collection', 'Development', 'Diffuse', 'Educational workshop', 'Environment', 'Ethnic Origin', 'Extramural Activities', 'Faculty', 'Family', 'Fertility', 'Fostering', 'Funding', 'Gender', 'Genetic', 'Grant', 'Hand', 'Health', 'Health Surveys', 'Home environment', 'Inequality', 'Infrastructure', 'Intervention', 'Journals', 'Learning', 'Life Cycle Stages', 'Link', 'Longitudinal Studies', 'Machine Learning', 'Mainstreaming', 'Measurement', 'Mentors', 'Methods', 'Natural experiment', 'Nutrition Surveys', 'Personal Satisfaction', 'Phase', 'Policy Making', 'Population', 'Population Dynamics', 'Population Research', 'Population Sciences', 'Postdoctoral Fellow', 'Process', 'Production', 'Productivity', 'Publishing', 'Race', 'Recovery', 'Reproduction', 'Research', 'Research Design', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resources', 'Schools', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Seeds', 'Services', 'Sexuality', 'Shapes', 'Socioeconomic Status', 'Structure', 'Students', 'Surveys', 'Talents', 'Teacher Professional Development', 'Technical Expertise', 'Techniques', 'Training Programs', 'Tsunami', 'Universities', 'Work', 'adolescent health', 'career', 'collaborative environment', 'cost', 'data access', 'design', 'empowered', 'experience', 'faculty support', 'health disparity', 'innovation', 'interdisciplinary collaboration', 'longitudinal dataset', 'novel strategies', 'population health', 'privacy protection', 'programs', 'research and development', 'response', 'sociodemographic variables', 'success', 'tool']",NICHD,UNIV OF NORTH CAROLINA CHAPEL HILL,P2C,2021,766127
"Mentoring and Patient Oriented Research in Cardiovascular Health and Digital Data Science Project Summary/Abstract Cardiovascular associated Advances the sensor exposures. easily analyzing conducting integrate issues focus and who and graduate, objectives workforce.” ability K24 data phenotypes health (CV) disease affects nearly half of all adult Americans. Although achieving “ideal CV health” i s  with lower mortality nd morbidity, many individuals struggle with modifying CV health behaviors. in precision medicine offer promise in better targeting these behaviors to improve CV health. Over past decade, there has been exponential growth in digital data (e.g. social media, online search, remote measures) generated by individuals which reflects their health behaviors, attitudes, and environmental These data sources however are often not linked with validated measures, unprocessed, and not interpretable for use in research or clinical practice. My research portfolio has focused on collecting and CV focused digital data for insights, prediction, and clinical applications. My career focus is on high-impact atient-oriented research (POR) t o better understand how to best access, analyze and these data in a way that is patient-centered and highly applied. This includes work which focuses on related to privacy, security, and patient preferences. This K24 award will support protected time for me i ntently on: 1) implementing a research program to advance POR in CV health and digital data science 2) training a pipeline of investigators who are well trained in methodologies for conducting this work and will be future POR leaders i n this area of study. This proposal focuses on necessary steps for developing executing a comprehensive and structured mentorship program that will support mentees (undergraduate, fellow, faculty) for research and career development. This focus aligns with NHLBIs overarching in “data science” and “further developing, diversifying and sustaining a NHLBI focused scientific This proposal builds on my current NHLBI R01, R21, and Foundation grants and will support my to pursue career-oriented training in clinical trials, social media ethics, and academic leadership. This will also support two new areas of research: 1) building computational models using large digital media sets for population-level surveillance of modifiable CV health behaviors in real time, 2) developing patient reflecting use and engagement which can inform digital interventions to address modifiable CV behaviors. a p , The environment for this K24 is the University of Pennsylvania-a world renowned institution with extensive resources to support research at the intersection of medicine, computer science, communication, and engineering—fields critical for advancing this research and supporting interdisciplinary trainees. The areas of focus for this K24 represent new frontiers in precision medicine and digital phenotyping for CV health that can be advanced and led by well-trained interdisciplinary POR researchers. Narrative Cardiovascular disease is the leading cause of morbidity in the United States and many Americans struggle with modifying health behaviors which could improve their overall health and life-expectancy. This K24 proposal focuses on using new and emerging digital data sources and methodologies (e.g. big data analytics, machine learning, natural language processing) to better phenotype health behaviors which can be modified to improve cardiovascular health. Through this K24, Dr. Merchant will develop and implement 1) a successful and high-impact research program focused on advancing CV health and digital data science and 2) a successful and enduring mentorship program focused on training and supporting the next generation of patient-oriented researchers who can advance this field to improve the CV health of individuals and communities.",Mentoring and Patient Oriented Research in Cardiovascular Health and Digital Data Science,10188779,K24HL157621,"['Address', 'Adult', 'Affect', 'Age', 'American', 'Area', 'Attitude', 'Behavior', 'Big Data Methods', 'Blood Pressure', 'Caliber', 'Cardiovascular Diseases', 'Cardiovascular system', 'Cellular Phone', 'Cholesterol', 'Clinical', 'Clinical Trials', 'Communication', 'Communities', 'Competence', 'Complement', 'Complex', 'Computer Models', 'Computers', 'Coupled', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Development', 'Devices', 'Diet', 'Disease', 'Engineering', 'Environment', 'Ethics', 'Event', 'Foundations', 'Funding', 'Future', 'Gender', 'Geography', 'Glucose', 'Grant', 'Growth', 'Health', 'Health behavior', 'Human', 'Income', 'Individual', 'Institution', 'Internet', 'Intervention', 'Investigation', 'Knowledge', 'Leadership', 'Life Expectancy', 'Link', 'Machine Learning', 'Measures', 'Medicine', 'Mentors', 'Mentorship', 'Methodology', 'Mid-Career Clinical Scientist Award (K24)', 'Mining', 'Morbidity - disease rate', 'National Heart, Lung, and Blood Institute', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Patient Education', 'Patient Preferences', 'Patients', 'Pennsylvania', 'Phenotype', 'Physical activity', 'Population', 'Privacy', 'Process', 'Race', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Support', 'Resources', 'Safety', 'Scientist', 'Security', 'Smoking', 'Source', 'Structure', 'System', 'Time', 'Training', 'Training Programs', 'Training Support', 'Underrepresented Minority', 'United States', 'United States National Institutes of Health', 'Universities', 'Weight', 'Work', 'burden of illness', 'cardiovascular disorder risk', 'cardiovascular health', 'cardiovascular risk factor', 'career', 'career development', 'clinical application', 'clinical practice', 'computer science', 'data streams', 'demographics', 'digital', 'digital health', 'digital intervention', 'digital media', 'disorder risk', 'experience', 'faculty research', 'frontier', 'human capital', 'improved', 'improved outcome', 'insight', 'mortality', 'next generation', 'novel', 'patient oriented', 'patient oriented research', 'phenotypic data', 'precision medicine', 'programs', 'recruit', 'research and development', 'response', 'risk prediction', 'sensor', 'social media', 'tool', 'training opportunity', 'undergraduate student', 'uptake']",NHLBI,UNIVERSITY OF PENNSYLVANIA,K24,2021,122986
Engineering a diagnostic platform for rapid breath-based respiratory pathogen identification and treatment monitoring No abstract available n/a,Engineering a diagnostic platform for rapid breath-based respiratory pathogen identification and treatment monitoring,10331914,R00EB028311,"['Acute respiratory infection', 'Aftercare', 'Amides', 'Amines', 'Animals', 'Antibiotic Therapy', 'Antibiotics', 'Antimicrobial susceptibility', 'Bacteria', 'Bacterial Pneumonia', 'Bar Codes', 'Biological Assay', 'Blinded', 'Blood', 'Classification', 'Clinical', 'Data', 'Detection', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Drug resistance', 'Early Diagnosis', 'Engineering', 'Enzymes', 'Fingerprint', 'Fluorocarbons', 'Goals', 'Immune response', 'In Vitro', 'Infection', 'Inhalation', 'Leukocyte Elastase', 'Ligands', 'Lung', 'Mass Spectrum Analysis', 'Measures', 'Mentors', 'Methods', 'Monitor', 'Mus', 'Peptide Hydrolases', 'Peptides', 'Pharmaceutical Preparations', 'Phase', 'Predisposition', 'Pseudomonas aeruginosa', 'Randomized', 'Reporter', 'Research Personnel', 'Resistance', 'Sensitivity and Specificity', 'Signal Transduction', 'Specificity', 'Sputum', 'Survival Rate', 'System', 'Testing', 'Time', 'Tissues', 'Validation', 'Work', 'antimicrobial drug', 'base', 'classification algorithm', 'cohort', 'diagnostic platform', 'extracellular', 'in vivo', 'in-vivo diagnostics', 'mouse model', 'nanoparticle', 'nanosensors', 'outcome forecast', 'pathogen', 'pathogenic bacteria', 'pathogenic fungus', 'pathogenic virus', 'portability', 'random forest', 'resistant strain', 'respiratory pathogen', 'response', 'urinary', 'ventilator-associated pneumonia', 'volatile organic compound']",NIBIB,GEORGIA INSTITUTE OF TECHNOLOGY,R00,2021,249000
"Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome Addiction is a highly complex disease with risk factors that include genetic variants and differences in development, sex, and environment. The long term potential of precision medicine to improve drug treatment and prevention depends on gaining a much better understanding how genetics, drugs, brain cells, and neuronal circuitry interact to influence behavior. There are serious technical barriers that prevent researchers and clinicians from incorporating more powerful computational and predictive methods in addiction research. The purpose of the NIDA P30 Core Center of Excellence in Omics, Systems Genetics, and the Addictome is to empower and train researchers supported by NIH, NIDA, NIAAA, and other federal and state institutions to use more quantitative and testable ways to analyze genetic, epigenetic, and the environmental factors that influence drug abuse risk and treatment. In the Transcriptome Informatics and Mechanisms research core we assemble and upgrade hundreds of large genome (DNA) and transcriptome (RNA) datasets for experimental rodent (rat) models of addiction. In the Systems Analytics and Modeling research core, we are using innovative systems genetics methods (gene mapping) to understand the linkage between DNA differences, environmental risks such as stress, and the differential risk of drug abuse and relapse. Our Pilot core is catalyzing new collaborations among young investigator in the field of addiction research. In sum the Center is a national resource for more reproducible research in addiction. We are centralizing, archiving, distributing, analyzing and integrating high quality data, metadata, using open software systems in collaboration with many other teams of researchers. Our goal is to help build toward an NIDA Addictome Portal that will include all genomic research relevant to addiction research. PROJECT NARRATIVE The NIDA Core Center of Excellence in Omics, Systems Genetics, and the Addictome (OSGA) provides genomic and computational support to a large number of research scientists working on mechanisms and treatment of addiction. The two main research cores of OSGA are providing support for transcriptome, epigenome, and metagenome studies of rat models of addiction at many levels of analysis. We are also creating open access tools and a powerful web portal to catalyze more effective and replicable use of massive datasets generated by programs in addiction biology and treatment.","Overall NIDA Core ""Center of Excellence"" in Transcriptomics, Systems Genetics and the Addictome",10177978,P30DA044223,"['Archives', 'Bayesian Modeling', 'Behavior', 'Behavioral', 'Bioinformatics', 'Biology', 'Biometry', 'Cellular Assay', 'Chromosome Mapping', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Computing Methodologies', 'Consult', 'DNA', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Interactions', 'Drug abuse', 'Educational workshop', 'Ensure', 'Environment', 'Environmental Risk Factor', 'Epigenetic Process', 'Foundations', 'Funding', 'Future', 'Genes', 'Genetic', 'Genetic Variation', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Human', 'Hybrids', 'Image', 'Informatics', 'Institution', 'Joints', 'Leadership', 'Machine Learning', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'National Institute of Drug Abuse', 'National Institute on Alcohol Abuse and Alcoholism', 'Neurosciences Research', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Population', 'Prevention', 'Proteome', 'Publications', 'Publishing', 'Quantitative Genetics', 'Quantitative Trait Loci', 'RNA', 'Rattus', 'Relapse', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Risk Factors', 'Rodent', 'Role', 'Scientist', 'Site', 'Standardization', 'Statistical Models', 'Stress', 'Sum', 'System', 'Systems Analysis', 'Testing', 'Training', 'Translations', 'United States National Institutes of Health', 'Update', 'Variant', 'Visualization', 'Work', 'addiction', 'archive data', 'archived data', 'base', 'behavior influence', 'brain cell', 'career', 'cohort', 'computerized tools', 'computing resources', 'data integration', 'data modeling', 'data repository', 'data tools', 'deep learning', 'digital imaging', 'drug relapse', 'epigenome', 'experience', 'genetic analysis', 'genetic variant', 'genomic variation', 'graphical user interface', 'health record', 'high dimensionality', 'image archival system', 'improved', 'innovation', 'insight', 'metagenome', 'mouse model', 'multiple omics', 'neurogenomics', 'neuronal circuitry', 'novel', 'precision medicine', 'prevent', 'programs', 'ranpirnase', 'rat genome', 'sex', 'single cell analysis', 'software systems', 'tool', 'transcriptome', 'transcriptomics', 'web portal']",NIDA,UNIVERSITY OF TENNESSEE HEALTH SCI CTR,P30,2021,744955
"Statistical methods for structural and functional integration in multi-modal neuroimaging data Abstract Neuropsychiatric disorders, such as autism and schizophrenia, affect millions of people worldwide and place a considerable burden on both patients and family members. Existing treatments for these disorders have limited efficacy, in part due the varied clinical manifestations, and to our narrow understanding of the impacted neural processes, particularly at the system (i.e., network) level. Two key elements of networks are the underlying infrastructure or physical connections between elements and the functional signaling between entities that rides on top of this infrastructure. Recent advancements in noninvasive imaging have given us the ability to quantify structural and functional relationships in the brain via diffusion MRI, resting-state functional MRI, respectively. The size and scope of datasets measuring network structure and function are increasing in neuroimaging, and other domains, which heightens the need for new statistical frameworks that make full use of the data. Our goal is to develop frameworks for the analysis of structure-function integration in large-scale and complex networks, applied to neuroimaging studies, but also broadly applicable. This proposal will introduce three analytic paradigms: Bayesian network modeling that uses a priori structure-function knowledge for simultaneous network anomaly detection and clinical severity prediction; density regression using optimal transport theory; and end-to-end prediction using deep neural networks. In our application, infrastructure will be measured via dMRI, while function will be measured rs-fMRI. Each of our frameworks will provide a unique means to integrate these distinct imaging modalities, while also respecting the unique information provided by each data type. We also propose a unique software development effort that creates an application program interface to core software and implementations as software as as a service hosted on cloud platforms. Project narrative: We propose to develop fully specified Bayesian models, novel adaptations of density regression and deep learning for the study of multi-modal neuroimaging data in the student of developmental disorders.",Statistical methods for structural and functional integration in multi-modal neuroimaging data,10296729,R01EB029977,"['Adoption', 'Affect', 'Bayesian Method', 'Bayesian Modeling', 'Biological Markers', 'Brain', 'Clinical', 'Cognitive', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Set', 'Detection', 'Diffusion', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Disease Outcome', 'Disease model', 'Dropout', 'Elements', 'Family member', 'Functional Magnetic Resonance Imaging', 'Goals', 'Impaired cognition', 'Individual', 'Infrastructure', 'Intuition', 'Joints', 'Knowledge', 'Learning', 'Magnetic Resonance Imaging', 'Measures', 'Medical', 'Meta-Analysis', 'Methodology', 'Methods', 'Modality', 'Modeling', 'Neurons', 'Neurosciences', 'Pathway Analysis', 'Patients', 'Pattern', 'Performance', 'Procedures', 'Process', 'Research', 'Rest', 'Route', 'Schizophrenia', 'Selection Criteria', 'Services', 'Severities', 'Signal Transduction', 'Specific qualifier value', 'Statistical Data Interpretation', 'Statistical Methods', 'Structure', 'Students', 'System', 'Techniques', 'Training', 'Weight', 'Work', 'application programming interface', 'autism spectrum disorder', 'base', 'behavioral outcome', 'behavioral phenotyping', 'biomarker discovery', 'cloud platform', 'cost', 'data framework', 'deep learning', 'deep neural network', 'density', 'developmental disease', 'direct application', 'feature extraction', 'flexibility', 'imaging modality', 'interest', 'model building', 'motor impairment', 'multimodality', 'network models', 'neuroimaging', 'neuroimaging marker', 'neuropsychiatric disorder', 'non-invasive imaging', 'novel', 'organizational structure', 'patient variability', 'programs', 'relating to nervous system', 'socioeconomics', 'software development', 'theories', 'user-friendly']",NIBIB,JOHNS HOPKINS UNIVERSITY,R01,2021,505937
"A Multigenerational Longitudinal Panel for Aging Research Summary/Abstract This project will construct a Multigenerational Longitudinal Panel (IPUMS-MLP) of unprecedented scale and scope. Using cutting-edge automatic record linkage technology and drawing on complete count U.S. census data available from IPUMS for the period 1850 to 1940, the project will construct millions of individual life histories and trace millions of families over multiple generations. This infrastructure will provide the most comprehensive view of long-run changes in life-course dynamics available for any place in the world and will transform our understanding of processes of population aging. The work will require significant innovation and new technical infrastructure to accommodate the massive scale of the database. These data will allow investigators to directly observe changes in aging processes and life-course transitions during the period in which U.S. society was being transformed by industrialization, urbanization, immigration, demographic transition, and economic collapse. Investigators will be able to follow individuals over time to evaluate the impact of early-life conditions on later outcomes, trace life-course transitions into adulthood and old age, and observe family change over multiple generations. IPUMS-MLP will enrich existing aging surveys by providing data on multiple generations of forebears of survey respondents; likewise, it will enrich existing historical databases by enabling them to connect with descendants across multiple generations. Leveraging billions of dollars of federal investments in census data and transactional records from a variety of administrative sources, this project is a highly cost-effective use of scarce resources to develop shared infrastructure for research, education, and policy-making on health and aging. Project Narrative The proposed work is directly relevant to the core mission of the Population and Social Processes branch of NIA: the new data will advance fundamental knowledge about the causes and consequences of changes in health and well-being of the older population and will support research on the effects of public policies, social institutions, and environmental conditions on the health, well-being, and functioning of people, both over the life course and in their later years. For example, the data will enable examinations of the impact of lead exposure to late onset Alzheimer’s disease, the socioeconomic and health effects of early-life income support, intergenerational transmission of health and wellbeing over multiple generations, and the impact of early-life cognitive capacity on later-life health and economic outcomes.",A Multigenerational Longitudinal Panel for Aging Research,10174657,R01AG057679,"['Adult', 'Aging', 'Big Data', 'Censuses', 'Characteristics', 'Communities', 'Custom', 'Data', 'Data Security', 'Databases', 'Demographic Transitions', 'Economics', 'Education', 'Elderly', 'Exposure to', 'Family', 'Family member', 'Future', 'Genealogy', 'Generations', 'Health', 'Household', 'Immigration', 'Income', 'Individual', 'Industrialization', 'Infrastructure', 'Institution', 'Investments', 'Knowledge', 'Late Onset Alzheimer Disease', 'Life', 'Life Cycle Stages', 'Link', 'Metadata', 'Methods', 'Military Personnel', 'Mission', 'Names', 'Neighborhoods', 'Older Population', 'Outcome', 'Personal Satisfaction', 'Persons', 'Policy Making', 'Population', 'Population Process', 'Process', 'Public Policy', 'Records', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Support', 'Resources', 'Respondent', 'Running', 'Sampling', 'Selection Bias', 'Social Processes', 'Social Security', 'Societies', 'Source', 'Structure', 'Surveys', 'Technology', 'Time', 'Urbanization', 'War', 'Weight', 'Woman', 'Work', 'aging population', 'base', 'cognitive capacity', 'cost effective', 'data curation', 'data integration', 'data quality', 'economic outcome', 'experience', 'health economics', 'human old age (65+)', 'improved', 'innovation', 'intergenerational', 'lead exposure', 'life history', 'longitudinal dataset', 'machine learning algorithm', 'machine learning method', 'novel', 'parallel processing', 'social', 'socioeconomics', 'tool', 'transmission process']",NIA,UNIVERSITY OF MINNESOTA,R01,2021,672964
"Development of a Bio-tissue Oxygenation Nanophosphor Enabled Sensing (BONES) system for Quantifying Hypoxia in Bone Marrow Project Summary/Abstract Low oxygen (hypoxic) environments are known to be important for maintaining the small number of adult stem cells in the human body, such as in bone marrow. These conditions are also believed to enable dormant cancer cells to survive and metastasize years or decades after the original tumor has been destroyed and the reason why bone marrow is one of the most common sites of cancer metastasis. Understanding of these conditions can drive the development of 3D cellular scaffolds for growing stem cells ex vivo, thus reducing the burden on requiring bone marrow transplants, and for developing therapeutics that prevent cancer relapse. This project proposes to develop the first quantitative oxygen tomographic imaging system called BONES (Bio-tissue Oxygenation Nanophosphor Enabled Sensing) to address the critical need for high resolution imaging of oxygen concentrations in hypoxic (low oxygen) tissues such as bone marrow. The technique is based on developments in x-ray luminescence computed tomography, an emerging molecular imaging technique capable of achieving cellular level resolution and high sensitivities. The approach uses x-rays to excite oxygen-sensitive nanophosphors that emit near-infrared photons to finally enable 3D oxygen measurements in deep bone marrow. Because the technique requires a multidisciplinary team with x-ray expertise, nanophosphor expertise, near-infrared detection expertise, and algorithms for quantifying the concentrations and minimizing dose, this STTR fast-track proposal involves several institutions with deep expertise in their respective domains. The proposed Phase I 6-month project is a proof-of- principle demonstration of a breadboard system used on nanophosphors in low oxygen solutions and embedded in bone. The proposed Phase II 24-month project is to develop a complete prototype system and experimentally verify its performance. Project Narrative This project proposes to develop the first quantitative oxygen tomographic imaging system called BONES (Bio-tissue Oxygenation Nanophosphor Enabled Sensing) to address the critical need for high resolution imaging of oxygen concentrations in hypoxic (low oxygen) tissues such as bone marrow. Local oxygen microenvironments and changes to oxygen tensions over only tens of micrometers are known to be important for maintaining stem cell growth and are suspected to also enable cancer metastases, but are poorly understood because there are no methods with the resolution and sensitivity required. The proposed solution will finally enable 3D oxygen measurements in deep bone marrow based on a newly developed technique called x- ray luminescence computed tomography (XLCT) and oxygen-sensitive nanophosphors for 10 to 100 µm imaging of oxygen concentrations.",Development of a Bio-tissue Oxygenation Nanophosphor Enabled Sensing (BONES) system for Quantifying Hypoxia in Bone Marrow,10255544,R42GM142394,"['3-Dimensional', 'Address', 'Affect', 'Algorithms', 'Area', 'Biomedical Research', 'Biopsy', 'Blood', 'Bone Marrow', 'Bone Marrow Transplantation', 'Cancer Patient', 'Cancer Relapse', 'Cells', 'Chemicals', 'Chronic Kidney Failure', 'Clinical', 'Collaborations', 'Data', 'Detection', 'Development', 'Disease', 'Dose', 'Environment', 'Fiber', 'Film', 'Heterogeneity', 'Human body', 'Hypoxia', 'Image', 'Imaging Techniques', 'Institution', 'Light', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measurement', 'Measures', 'Metastatic Neoplasm to the Bone', 'Methods', 'Microscopy', 'Modality', 'Molecular', 'Monitor', 'Morphology', 'Nature', 'Neoplasm Metastasis', 'Noise', 'Organ Transplantation', 'Oxygen', 'Penetration', 'Performance', 'Phase', 'Photons', 'Production', 'Radiation Dose Unit', 'Resolution', 'Roentgen Rays', 'Sampling', 'Scanning', 'Signal Transduction', 'Site', 'Small Business Technology Transfer Research', 'Spatial Design', 'Surface', 'System', 'Techniques', 'Therapeutic', 'Thick', 'Time', 'Tissues', 'Visible Radiation', 'X-Ray Computed Tomography', 'adult stem cell', 'base', 'bone', 'cancer cell', 'cancer site', 'deep learning', 'deep learning algorithm', 'denoising', 'design and construction', 'detector', 'high resolution imaging', 'image processing', 'image reconstruction', 'imaging system', 'improved', 'insight', 'luminescence', 'malignant breast neoplasm', 'molecular imaging', 'multidisciplinary', 'phosphorescence', 'pre-clinical', 'prevent', 'prototype', 'quantum', 'response', 'scaffold', 'stem cell growth', 'stem cells', 'therapeutic effectiveness', 'tissue oxygenation', 'tomography', 'transmission process', 'tumor', 'two-photon']",NIGMS,"SIGRAY, INC.",R42,2021,252113
"Novel Approaches to Advance Coordinated Registry Networks (CRNs). Project Summary The technological transformation of US health care with the explosion of new devices and iterative changes mandates the acquisition of real-world evidence (RWE) to study devices and technologies pragmatically. The US Food and Drug Administration (FDA) has spearheaded the RWE framework development in the pursuit of sufficient evidence that is required for regulatory decision-making such as device approvals and surveillance. With regulatory support since the launch of the National Medical Device Registry Task Force in 2015, the Medical Device Epidemiology Network (MDEpiNet) created 15 national and international coordinated registry networks (CRNs), which develop or link well-curated national RWE sources such as registries, administrative, and electronic health records (EHRs) data. The MDEpiNet is a key partner of the National Evaluation System of Technologies (NEST) coordinating center and is an international public-private partnership focusing on building global infrastructure and methodologies to advance the use of RWE for medical device evaluation. CRNs not only focus on prevention of harms but also the promotion of safer device innovation through the development of study designs that expedites patient recruitment at lower costs than traditional clinical research. MDEpiNet developed a maturity model for CRNs with various levels of achievements in seven key domains: 1) device identification, 2) quality improvement, 3) total product life-cycle, 4) data quality, 5) efficiency, 6) governance and sustainability, 7) patient engagement. This proposal focuses on the creation of innovative tools and methods necessary to achieve maturation of the networks through efficient curation of robust RWE. We will capitalize on established partnerships with registries, professional societies, integrated health systems, and many academic institutions to advance this critical national infrastructure as a foundational component of NEST. We will facilitate advancements of RWE through stakeholder roundtables, patient-facing mobile app development, and continued innovative methods development to link registries with Medicare, commercial, statewide, and EHR data to enable better research and surveillance for devices. Our specific aims facilitate stakeholder engagement for device-specific core minimum data development in women's health, prostate cancer, orthopedics, vascular disease, robot-assisted surgery, and temporomandibular joints. We will also advance and enrich linked data capacities in vascular disease, hernia repair, breast implant, prostate cancer, Women's Health, and gastrointestinal cancer CRNs. Finally, we conduct advanced analytics to determine gender disparities in device outcomes and use machine learning and active surveillance methods in hernia repair, orthopedics, stroke treatment, vascular disease, and Women's health CRNs. The CRN community of practice will enable centralized knowledge sharing to support cross-specialty and technology learning and applications. Through this, we advance the CRNs using innovative, scalable, and dynamic approaches and help them become foundational components of NEST. Narrative Medical Device Epidemiology Network will advance the research and surveillance capabilities of coordinated registry networks through stakeholder roundtables, patient-facing mobile app development, and linkages of real-world data sources. We will also conduct advanced analytics to determine gender disparities, use machine learning for risk predictions, and implement active surveillance for devices and technologies.",Novel Approaches to Advance Coordinated Registry Networks (CRNs).,10209943,U01FD006936,[' '],FDA,WEILL MEDICAL COLL OF CORNELL UNIV,U01,2021,50000
"University of Buffalo Clinical and Translational Science Institute Contact PD/PI: Murphy, Timothy F The Buffalo Translational Consortium (BTC), which includes the University at Buffalo (UB) health sciences schools, the major healthcare institutions in our region, four key research institutes and five influential community partners, have embarked on a comprehensive strategic plan to build a strong foundation for clinical and translational research in response to our community needs. Buffalo is the second most populous city in New York State and has a rich cultural history. The proportion of underrepresented minorities in Buffalo in 2018 (50%) parallels that projected for the US in 2050, making Buffalo a microcosm of what the US will look like in 30 years. A similar proportion of our population experiences health disparities. The vision for our CTSA hub is to perform innovative research across the translational spectrum to improve the health of our community and the nation. We will develop, test and share novel approaches to engage difficult-to-engage populations and reduce health disparities in our community, which represents a “population of the future”. Guided by our vision, the CTSA has catalyzed a transformation of our environment since our CTSA was first funded in August 2015 with remarkable growth in clinical and translational research. Further, in just the past year, the UB medical school has moved into a spectacular new building and our clinical partner, Kaleida Health, the largest healthcare system in the region, opened the new Oishei Children’s Hospital, both on the Buffalo Niagara Medical Campus and connected to the Clinical and Translational Research Center devoted entirely to clinical and translational research that opened in 2012. This rapid and continuing trajectory of growth in healthcare and research in the region has resulted in a new 21st century Academic Health Center with healthcare, medical education and clinical and translational research on one campus in the heart of Buffalo, creating a foundation to enhance the impact of our CTSA even further. While launching our CTSA, we have prioritized participation in the national consortium through hosting and testing Innovation Labs as a team science tool, working with multiple hubs on initiatives to solve translational research barriers and sharing tools that we have developed with the CTSA consortium, including novel health informatics tools. Our CTSA has five ambitious but achievable aims, including: 1) Accelerate innovative translational research with teams that engage communities, regional stakeholders and the national consortium; 2) Train an excellent, diverse workforce to advance translation of discoveries; 3) Enhance inclusion of special populations across the lifespan and difficult-to-engage populations; 4) Streamline clinical research processes focusing on quality and efficiency with emphasis on multisite studies; 5) Develop, test and share biomedical informatics tools to integrate data from multiple sources to speed translation. Guided by our vision to perform research to improve the health of our community and the nation, we will continue our momentum to expand translational research, train our diverse workforce, streamline processes, engage our community, and actively contribute to the national consortium. Page 243 Project Summary/Abstract Contact PD/PI: Murphy, Timothy F The University at Buffalo Clinical and Translational Science Institute (CTSI) is the coordinating center of the Buffalo Translational Consortium, which includes the region's premier research, educational and clinical institutions with influential community partners. The vision of the CTSI is to perform innovative clinical and translational research to reduce health disparities and improve the health of our community and the nation. We engage our community as research partners to create a shared environment to bring discoveries in the laboratory, clinic and community to benefit individual and public health. Page 244 The University at Buffalo Clinical and Translational Science Institute (CTSI) is the coordinating center of the Buffalo Translational Consortium, which includes the region's premier research, educational and clinical institutions with influential community partners. The vision of the CTSI is to perform innovative clinical and translational research to reduce health disparities and improve the health of our community and the nation. We engage our community as research partners to create a shared environment to bring discoveries in the laboratory, clinic and community to benefit individual and public health.",University of Buffalo Clinical and Translational Science Institute,10103865,UL1TR001412,"['Achievement', 'Address', 'Adopted', 'African American', 'Buffaloes', 'Center for Translational Science Activities', 'Cities', 'Clinic', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Clinical Trials', 'Collaborations', 'Communities', 'Community Health', 'County', 'Coupled', 'Cultural Backgrounds', 'Data', 'Diverse Workforce', 'Ensure', 'Environment', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'Growth', 'Health', 'Health Care Research', 'Health Personnel', 'Health Professional', 'Health Sciences', 'Healthcare', 'Healthcare Systems', 'Heart', 'Image', 'Imaging technology', 'Individual', 'Influentials', 'Informatics', 'Institutes', 'Institution', 'Knowledge', 'Laboratories', 'Learning', 'Life Expectancy', 'Longevity', 'Medical', 'Medical Education', 'Medical center', 'Methods', 'Natural Language Processing', 'New York', 'Outcomes Research', 'Participant', 'Pediatric Hospitals', 'Phenotype', 'Population', 'Poverty', 'Process', 'Program Development', 'Prospective Studies', 'Public Health', 'Public Health Informatics', 'Recording of previous events', 'Recruitment Activity', 'Refugees', 'Research', 'Research Institute', 'Research Personnel', 'Research Training', 'Resources', 'Schools', 'Science', 'Sensitivity and Specificity', 'Site', 'Special Population', 'Speed', 'Strategic Planning', 'System', 'Testing', 'Training', 'Translational Research', 'Translations', 'Underrepresented Minority', 'Universities', 'Vision', 'Work', 'Workforce Development', 'base', 'biomedical informatics', 'clinical center', 'clinical data repository', 'community partnership', 'data sharing', 'education research', 'experience', 'health care disparity', 'health disparity', 'imaging genetics', 'improved', 'informatics tool', 'innovation', 'interoperability', 'medical schools', 'multidisciplinary', 'multiple data sources', 'novel', 'novel strategies', 'recruit', 'response', 'sharing platform', 'skills', 'social health determinants', 'structured data', 'tool', 'translational impact', 'translational pipeline', 'translational scientist', 'unstructured data']",NCATS,STATE UNIVERSITY OF NEW YORK AT BUFFALO,UL1,2021,3826724
"Meta-analysis in human brain mapping This is the competing renewal of the R01 (MH074457-14) which sustains the BrainMap Project (www.brainmap.org). BrainMap is a neuroimaging research resource facilitating cognitive neuroscience and disease-biomarker discovery via coordinate-based meta-analysis (CBMA). BrainMap provides its end-user community with: curated 3-D coordinate data and experimental metadata from peer-reviewed publications; extensively validated computational tools for CBMA; CBMA-derived tools for data interpretation (e.g., functional property and disease loadings by location) and data analysis (e.g., via CBMA-derived disease models); instructional materials and on-site and on-line venues for learning CBMA methods; and, on-going end-user support. At present, BrainMap.org hosts two coordinate-based databases: task-activation (TA DB) and voxel- based morphometry (VBM DB). A voxel-based physiology database (VBP DB) is in the planning and piloting phase. BrainMap maintains an integrated pipeline of cross-platform (Java) tools for data coding (Scribe), filtered retrieval (Sleuth), activation-likelihood estimation (ALE) CBMA (GingerALE), data visualization (Mango), and data interpretation (CBMA-derived Mango plugins). Multiple network-modeling approaches have been successfully applied to BrainMap data – independent components analysis (ICA), author-topic modeling (ATM), graph-theory modeling (GTM), structural equation modeling (SEM), connectivity-based parcellation (CBP), and meta-analytic connectivity modeling (MACM) – but none are yet optimized and “pipelined” for general use. Utilization of BrainMap resources is substantial: our software, data and meta-data have been used in >1,000 peer-reviewed articles. Of these, > 500 were published in the current funding cycle (2015- 2020). Four aims are proposed, to maintain and extend this high-impact research resource.  Aim 1. Voxel-based Physiology DataBase (VBP DB) with Analysis Exemplars. Aim 2. BrainMap Community Portal for Multivariate Modeling with Applications & Exemplars. Aim 3. Large-scale Parameter Estimations. Aim 4. BrainMap Pipeline Enhancements and Community Support. The overall goal of the BrainMap Project is to provide the human neuroimaging community with curated data sets, metadata, computational tools, and related resources that enable coordinate-based meta-analyses (CBMA), meta-analytic connectivity modeling (MACM), meta-data informed interpretation (“decoding”) of imaging results, and meta-analytic priors for mining (including machine learning) primary (per-subject) neuroimaging data.",Meta-analysis in human brain mapping,10157292,R01MH074457,"['3-Dimensional', 'Address', 'Brain Mapping', 'Categories', 'Code', 'Cognition Disorders', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Disease', 'Disease model', 'Educational workshop', 'Equation', 'Funding', 'Goals', 'Guidelines', 'Human', 'Image', 'Java', 'Learning', 'Location', 'Machine Learning', 'Mango - dietary', 'Manuals', 'Mental disorders', 'Meta-Analysis', 'Metabolic', 'Metadata', 'Methods', 'Mining', 'Modeling', 'Multivariate Analysis', 'Output', 'Peer Review', 'Phase', 'Physiology', 'Property', 'Publications', 'Publishing', 'Research Domain Criteria', 'Resources', 'Retrieval', 'Site', 'Software Framework', 'Structure', 'Surface', 'Symptoms', 'Taxonomy', 'Texas', 'Training', 'Uncertainty', 'Validation', 'base', 'biomarker discovery', 'case control', 'cognitive neuroscience', 'cohort', 'computerized tools', 'connectome', 'data submission', 'data tools', 'data visualization', 'design', 'experimental study', 'graph theory', 'hemodynamics', 'independent component analysis', 'learning materials', 'lectures', 'morphometry', 'network models', 'neuroimaging', 'simulation', 'webinar']",NIMH,UNIVERSITY OF TEXAS HLTH SCIENCE CENTER,R01,2021,637306
"Development of a novel method for cryopreservation of Drosophila melanogaster PROJECT SUMMARY This proposal seeks to develop a resource for the preservation of the fruit fly, Drosophila melanogaster. This insect is a foundational model organism for biological research. Over a century of work, an enormous number of fly strains harboring different mutant alleles or transgenic constructs have been generated. However, one limitation of working with flies is that there is as yet no practical method for cryopreservation of Drosophila strains. Conventional methods of vitrifying Drosophila were developed in the early 1990s and were never widely adopted due to the difficulty in performing the protocols. This is a problem from a practical perspective since all these strains need to be individually maintained in continuous culture at substantial cost and labor, and also from a scientific perspective, since in the process of continuous culture mutations can accumulate and contamination can occur, degrading the value of these resources for future experiments. A novel approach for cryopreservation of Drosophila is proposed for this R24 resource center. Isolated embryonic nuclei, rather than intact embryos, will be cryopreserved and then nuclear transplantation via microinjection will be used to create clones derived from the cryopreserved nuclei. This approach avoids the issues associated with the impermeability of embryonic membranes that have prevented the use of conventional cryopreservation approaches that have been used with other organisms. Embryonic nuclei will be cryopreserved using a naturally inspired approach. Diverse biological systems (plants, insects, etc.) survive dehydration, drought, freezing temperatures and other stresses through the use of osmolytes. On an applied level, the proposed investigation has the potential to transform preservation of Drosophila lines by 1) preserving subcellular components (specifically nuclei) as opposed to embryos; and 2) automating much of the workflow. In the long- term, the goal of this resource center is to develop a robust and scalable protocol for cryopreservation of Drosophila, thus reducing the cost and improving the quality of long-term strain maintenance. PROJECT NARRATIVE The fruit fly, Drosophila melanogaster, is a very important model organism for biomedical research. The goal of this resource center is to develop effective methods of preserving fruit flies in order to lower the costs and improve the quality of stock maintenance. The approach leverages recent scientific advances to develop a new, highly automated approach for preserving fruit flies.",Development of a novel method for cryopreservation of Drosophila melanogaster,10160982,R24OD028444,"['Adopted', 'Algorithms', 'Alleles', 'Animal Model', 'Automation', 'Biological', 'Biomedical Research', 'Cell Nucleus', 'Cells', 'Cellular biology', 'Communities', 'Cryopreservation', 'Dehydration', 'Development', 'Developmental Biology', 'Drosophila genus', 'Drosophila melanogaster', 'Droughts', 'Embryo', 'Engineering', 'Evolution', 'Formulation', 'Foundations', 'Freezing', 'Future', 'Genetic', 'Genome', 'Genotype', 'Goals', 'Image', 'Individual', 'Insecta', 'Investigation', 'Machine Learning', 'Maintenance', 'Mechanics', 'Membrane', 'Methods', 'Microinjections', 'Molecular Biology', 'Monoclonal Antibody R24', 'Mutation', 'Neurosciences', 'Nuclear', 'Organism', 'Plants', 'Process', 'Protocols documentation', 'Raman Spectrum Analysis', 'Recovery', 'Resources', 'Robotics', 'Scientific Advances and Accomplishments', 'Spectrum Analysis', 'Stress', 'System', 'Techniques', 'Temperature', 'Testing', 'Transgenic Organisms', 'Work', 'biological research', 'biological systems', 'cold temperature', 'cost', 'epigenome', 'experimental study', 'fly', 'genetic technology', 'high throughput screening', 'improved', 'individual response', 'mutant', 'novel', 'novel strategies', 'nuclear transfer', 'preservation', 'prevent', 'tool']",OD,UNIVERSITY OF MINNESOTA,R24,2021,575125
"Digital Melt Curve Analysis Platform for Longitudinal Cancer Patient Monitoring Abstract  Building on its commercially available Absolute Q digital PCR platform, during the 24-month Phase 2 SBIR project, Combinati will complete the development of the first Digital Melt Curve Analysis (DMCA) platform to the market to further advance the adoption of digital genomics for highly accurate, sensitive and reproducible nucleic acid quantification for longitudinal patient monitoring. To provide the “whole product” solution and prove the function, we will demonstrate the DMCA platform with Luminex’s 11- plex ESR1 (Estrogen Receptor 1) assay and conduct Beta testing at Dana Farber Cancer Institute: 1. Three beta instruments and the analysis software capable of digital melt curve analysis. 2. Complete dMCA validation internally with commercially available melt calibration kits. 3. Demonstrate <0.1% Mutation Allele Frequency of 11 cell-free DNA targets using Luminex  Corporation’s discrete melt assay. 4. Beta testing at Dana Farber Cancer Institute Narrative  Since PCR was invented back in 1983, it has become the gold standard for applications requiring quantification of nucleic acids. The continuous evolution of the technology enables PCR to be more quantitative (qPCR), more accurate, precise and reproducible (digital PCR). In parallel, with the invention of melt curve analysis in 1997, it opens another dimension in melt temperatures for applications requiring simple and inexpensive genotyping, high degree qualitative multiplexing without sequencing, and assay optimization. Despite that there is a handful of dPCR platforms in the market, none of them supports Melt Curve Analysis. By combining melt curve analysis with digital PCR, Combinati strives to accelerate the adoption of digital genomics for all nucleic acid quantification needs in research and clinical markets.",Digital Melt Curve Analysis Platform for Longitudinal Cancer Patient Monitoring,10256226,R44CA261523,"['Adopted', 'Adoption', 'Architecture', 'Back', 'Biological Assay', 'Blinded', 'Breast Cancer Patient', 'Calibration', 'Cancer Patient', 'Chemistry', 'Clinical', 'Collection', 'Color', 'Computer software', 'Computers', 'DNA', 'Dana-Farber Cancer Institute', 'Data', 'Data Analyses', 'Development', 'Dimensions', 'ESR1 gene', 'Evolution', 'Gene Frequency', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Image', 'Image Analysis', 'Journals', 'Letters', 'Light', 'Mainstreaming', 'Manuscripts', 'Mechanics', 'Memory', 'Metastatic breast cancer', 'Microfluidics', 'Monitor', 'Mutation', 'Nucleic Acids', 'Optics', 'Oranges', 'Patient Monitoring', 'Patients', 'Peer Review', 'Performance', 'Phase', 'Process', 'Protocols documentation', 'Publications', 'Reagent', 'Reproducibility', 'Research', 'Resolution', 'Risk', 'Running', 'Sampling', 'Science', 'Small Business Innovation Research Grant', 'Source', 'Speed', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Training', 'Validation', 'cell free DNA', 'clinically relevant', 'cost', 'cyanine dye 5', 'data exchange', 'design', 'detection limit', 'digital', 'fluorescence imaging', 'graphical user interface', 'image processing', 'improved', 'instrument', 'invention', 'lens', 'liquid biopsy', 'machine learning algorithm', 'meetings', 'melting', 'multidimensional data', 'mutant', 'mutation assay', 'neural network', 'product development', 'sensor', 'simulation']",NCI,"COMBINATI, INC.",R44,2021,772720
"Shape Analysis Toolbox: From medical images to quantitative insights of anatomy PROJECT SUMMARY Three-dimensional shape lies at the core of understanding the physical objects that surround us. The Shape AnaLysis Toolbox (SALT) was created to be a dissemination vehicle for advanced shape modeling and analysis methodology as an open-source, comprehensive and freely distributed software. Over the past four years, we have been successful in increasing the ease of use and effectiveness of state-of-the-art shape analysis methodology for biomedical researchers in need of such techniques. We now propose necessary and novel enhancements to our methods and our dissemination model in order to continue maximizing the success of SALT. We will also modify the architecture of SALT to better integrate biomedical imaging research workflows by improving the efficiency and scripting capabilities so SlicerSALT can be deployed in batch mode for large-scale sequential computations. We will also shift our focus from shape modeling into state-of-the-art statistical shape analysis methodologies, necessary to serve clinical applications and to increase the interpretability of shape biomarkers. We will continue to disseminate novel example applications that best demonstrate how to use our tools to perform impactful research and will provide fully digital documentation for user support. The ultimate goal of SlicerSALT is to maximize the potential benefits of the geometric information contained in medical data and to expand its use beyond simple visualization to support clinical research. PROJECT NARRATIVE Slicer Shape AnaLysis Toolbox (SALT) was developed as an open-source, free comprehensive software that allows biomedical scientists to precisely locate shape changes in their imaging studies. This proposal is designed to increase the continued success of SALT by recognizing that shape models and dynamic anatomical changes are challenging to interpret despite quantification of the geometry of physical objects. We will address this need by incorporating state-of-the-art and interpretable shape statistics methodology into SALT and new driving biological problems to illustrate their utility while continuing to provide effective user support.",Shape Analysis Toolbox: From medical images to quantitative insights of anatomy,10426508,R56EB021391,"['3-Dimensional', 'Accounting', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Automobile Driving', 'Biological', 'Biological Markers', 'Biomedical Research', 'Brain', 'Classification', 'Clinical Research', 'Communities', 'Complex', 'Computer software', 'Consultations', 'Data', 'Development', 'Disease', 'Documentation', 'Educational workshop', 'Ensure', 'Event', 'Fostering', 'Funding', 'Geometry', 'Goals', 'Image Analysis', 'Infrastructure', 'Longitudinal Studies', 'Measures', 'Medical', 'Medical Imaging', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Nature', 'Online Systems', 'Pediatric cardiology', 'Phase', 'Population', 'Process', 'Publications', 'Research', 'Research Design', 'Research Personnel', 'Shapes', 'Software Tools', 'Statistical Methods', 'Structure', 'Surveys', 'Techniques', 'Testing', 'Three-Dimensional Image', 'Time', 'Training', 'Ultrasonography', 'Use Effectiveness', 'Variant', 'Visualization', 'base', 'bioimaging', 'biomedical scientist', 'clinical application', 'complex data', 'computer science', 'deep learning', 'design', 'digital', 'efficacy evaluation', 'fetal', 'geometric structure', 'imaging study', 'improved', 'innovation', 'insight', 'large scale data', 'longitudinal analysis', 'new technology', 'novel', 'open source', 'outreach', 'shape analysis', 'statistics', 'success', 'tool', 'usability', 'web site']",NIBIB,"KITWARE, INC.",R56,2021,436264
"Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences Abstract A major approach in causal inference literature aimed at mitigating bias due to unmeasured confounding is the so- called instrumental variable (IV) design which relies on identifying a variable which (i) influences the treatment process, (ii) has no direct effect on the outcome other than through the treatment, and (iii) is independent of any unmeasured confounder. IV methods are very well developed and widely used in social and health science, although validity of IV inferences may not be reliable if any of required assumptions (i)-(iii) is violated. This proposal aims to develop (a) new IV methods robust to violation of any of (i)-(iii); (b) New negative control methods that can be used to detect and sometimes to nonparametrically account for unmeasured confounding bias; (c) New bracketing methods for partial inference about causal effects in comparative interrupted time series studies. The proposed methods will be used to address current scientific queries in three major substantive public health areas:(1) to understand the health effects of air pollution; (2) to quantify the causal effects of modifiable risk factors for Alzheimer's disease and related disorders; (3) To uncover the mechanism by which a randomized package of interventions produced a substantial reduction of HIV incidence in a recent major cluster randomized trial of treatment as prevention in Botswana, Africa. Our proposal will provide the best available analytical methods to date to resolve confounding concerns in these high impact public health applications and more broadly in observational studies in the health sciences. Summary This proposal aims to develop new causal inference methods to tame bias due to hidden confounding factors in obser- vational studies as well as in randomized experiments subject to non-adherence. The proposed methods are firmly grounded in modern semiparametric theory which will be used to obtain more robust and efficient inferences about causal effects in a broad range of public health applications including in Epidemiology of Aging, Environmental Health Epidemiology and HIV/AIDS Prevention.",Novel Designs and Methods to Remove Hidden Confounding Bias in Health Sciences,10159821,R01AG065276,"['AIDS prevention', 'Address', 'Adherence', 'Africa', 'Aging', 'Air Pollution', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease risk', 'Area', 'Blood Pressure', 'Body mass index', 'Botswana', 'Cluster randomized trial', 'Data', 'Diabetes Mellitus', 'Disease', 'Environmental Health', 'Epidemiology', 'Genetic', 'HIV', 'Health', 'Health Sciences', 'Incidence', 'Interruption', 'Intervention', 'Learning', 'Linkage Disequilibrium', 'Literature', 'Machine Learning', 'Masks', 'Mendelian randomization', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Observational Study', 'Outcome', 'Participant', 'Process', 'Public Health', 'Public Health Applications Research', 'Randomized', 'Research Design', 'Research Personnel', 'Risk Factors', 'Series', 'Social Sciences', 'Testing', 'Thromboplastin', 'Time', 'ambient air pollution', 'analytical method', 'c new', 'comparative', 'design', 'experimental study', 'genetic variant', 'high dimensionality', 'intervention effect', 'modifiable risk', 'mortality', 'novel', 'pleiotropism', 'semiparametric', 'simulation', 'theories', 'treatment as prevention', 'treatment effect', 'uptake', 'user friendly software']",NIA,UNIVERSITY OF PENNSYLVANIA,R01,2021,468961
"The plasticity of well-being:  A research network to define, measure and promote human flourishing PROJECT SUMMARY/ABSTRACT This U24 application is written in response to RFA-AT-20-003 to establish a high-priority research network on emotional well-being (EWB). While psychological research on well-being has dramatically increased over the past 15 years, virtually all of this work has been descriptive and has not emphasized the “how” of well-being: How might well-being be cultivated? In addition, virtually all of the extant work on the correlates of individual differences in well-being has used responses on retrospective questionnaires as the primary tool to assess well-being. While there have been exciting findings, particularly relating individual differences in well-being to various indices of physical health, many questions remain and methodological limitations plague the validity of this work. This U24 network will assemble a highly multi-disciplinary group of 10 investigators across 3 (or more in the future) institutions to significantly advance our understanding of the “how” of EWB, identify the core plastic constituents of EWB, specify and/or develop robust measures of these constituents at biological, behavioral and experiential levels of analysis and characterize the plasticity of these constituents. The measurement strategy will ultimately focus on the development of technology-based passive measures of EWB that require no explicit user input and are highly scalable. The network will also focus its efforts on the development and evaluation of programs to train EWB and will assess whether such programs might serve as prevention strategies. The network will consist of scientists and scholars from a broad range of fields including psychology, neuroscience, electrical and computer engineering, population health and biology, computer science and the humanities. These scientists and scholars will focus on the following major aims: Aim 1: To arrive at a core consensus of the minimal set of constituents that can be described and measured at biological, behavioral and experiential levels that constitute the plastic elements of EWB and to specify already existing measures and /or develop novel measures of each of these constructs at each level of analysis. Aim 2: Using the active measures described in Aim 1, to develop passive measures using digital technologies of at least two of the core constituents of well-being. Aim 3: To develop pilot projects specifically focusing on prevention strategies for learning well-being in various samples. The network will train new investigators and bring established investigators into this new field, disseminate a framework for understanding the plasticity of well- being, a toolbox of measures for assessing the plasticity of components of well-being, and several pilot datasets that showcase the novel passive and field-friendly biological measures. In these ways, the network will dramatically accelerate progress in the nascent field of EWB. PROJECT NARRATIVE This U24 network on emotional well-being (EWB) will catalyze the emerging field of the plasticity of well-being and will showcase how well-being can be learned and the consequences of such skill development on physical and emotional health and on prevention of disease. A framework for understanding how well-being can be learned along with measures of the core components of well-being that can be learned will be developed and disseminated. The network will also train new investigators in this area and will engage established investigators to contribute to this field.","The plasticity of well-being:  A research network to define, measure and promote human flourishing",10151850,U24AT011289,"['Area', 'Attention', 'Awareness', 'Behavior', 'Behavioral', 'Biological', 'Cellular Phone', 'Communities', 'Computers', 'Consensus', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Development', 'Distal', 'Drug abuse', 'Elements', 'Emotional', 'Engineering', 'Face', 'Future', 'Gold', 'Grant', 'Health', 'Human', 'Humanities', 'Individual Differences', 'Institution', 'Interruption', 'Literature', 'Measurement', 'Measures', 'Mental Depression', 'Methodology', 'Mind', 'Modernization', 'Neurosciences', 'Outcome', 'Patient Self-Report', 'Personal Satisfaction', 'Pilot Projects', 'Plague', 'Population Biology', 'Prevention strategy', 'Program Evaluation', 'Psychology', 'Publications', 'Questionnaires', 'Randomized Controlled Trials', 'Regulation', 'Research', 'Research Personnel', 'Research Priority', 'Risk', 'Sampling', 'Scientist', 'Signal Transduction', 'Specific qualifier value', 'Subgroup', 'Techniques', 'Technology', 'To specify', 'Training', 'Well in self', 'Work', 'base', 'computer science', 'cost', 'digital', 'disorder prevention', 'indexing', 'learning strategy', 'mHealth', 'machine learning algorithm', 'meetings', 'member', 'mindfulness meditation', 'multidisciplinary', 'novel', 'physical conditioning', 'population health', 'prevent', 'programs', 'psychologic', 'response', 'skill acquisition', 'social', 'standard measure', 'technology development', 'tool', 'virtual', 'web site']",NCCIH,UNIVERSITY OF WISCONSIN-MADISON,U24,2021,30000
"Modeling the Incompleteness and Biases of Health Data Modeling the Incompleteness and Biases of Health Data Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. Existing efforts for missing health data imputation often focus on only cross-sectional correlation (e.g., correlation across subjects or across variables) but neglect autocorrelation (e.g., correlation across time points). Moreover, they often focus on modeling incompleteness but neglect the biases in health data. Modeling both the incompleteness and bias may contribute to better understanding of health data and better support clinical decision making. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets. Aim 1 introduces the MICA framework to jointly consider cross-sectional correlation and auto-correlation. In Aim 2, we will augment MICA to be bias-aware (hence BAMICA) to account for biases stemmed from multiple roots such as healthcare process and use them as features in imputing missing health data. This augmentation is achieved by a novel recurrent neural network architecture that keeps track of both evolution of health data variables and bias factors. In Aim 3, we will supplement unstructured clinical notes to structured health data for modeling incompleteness and biases using a novel architecture of graph neural network on top of memory network. We will apply graph neural networks to process clinical notes in order to learn proper representations as input to the memory networks for imputation and downstream predictive modeling tasks. Depending on the clinical problem and data availability, not all modules may be needed. Thus our proposed BAMICA framework is designed to be flexible and consists of selectable modules to meet some or all of the above needs. In summary, our proposal bridges a key knowledge gap in jointly modeling incompleteness and biases in health data and utilizes unstructured clinical notes to supplement and augment such modeling in order to better support predictive modeling and clinical decision making. We will demonstrate generalizability by experimenting on four large clinical and cohort study datasets, and by scaling up to the eMERGE network spanning 11 institutions nationwide. We will disseminate the open-source framework. The principled and flexible framework generated by this project will bring significant methodological advancement and have a direct impact on enhancing discovery from health data. Researchers are increasingly working to “mine” health data to derive new medical knowledge. Unlike experimental data that are collected per a research protocol, the primary role of clinical data is to help clinicians care for patients, so the procedures for its collection are not often systematic. Thus, missing and/or biased data can hinder medical knowledge discovery and data mining efforts. We propose a novel framework of Bias-Aware Missing data Imputation with Cross-sectional correlation and Autocorrelation (BAMICA), and leverage clinical notes to better inform the methods that will otherwise rely on structured health data only. In addition to evaluating its imputation accuracy, we will apply the proposed framework to assist in downstream tasks such as predictive modeling for multiple outcomes across a diverse range of clinical and cohort study datasets.",Modeling the Incompleteness and Biases of Health Data,10168611,R01LM013337,"['Adoption', 'Algorithms', 'Architecture', 'Awareness', 'Clinical', 'Clinical Data', 'Clinical Research', 'Cohort Studies', 'Collection', 'Communities', 'Computer software', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Dependence', 'Derivation procedure', 'Development', 'Diagnostic', 'Diagnostic tests', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Evolution', 'Functional disorder', 'General Hospitals', 'Goals', 'Graph', 'Health', 'Healthcare', 'Healthcare Systems', 'Hospitals', 'Hour', 'Individual', 'Inpatients', 'Institution', 'Intuition', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Learning', 'Measurement', 'Medical', 'Memory', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Plant Roots', 'Procedures', 'Process', 'Protocols documentation', 'Regimen', 'Research', 'Research Personnel', 'Resources', 'Role', 'Schedule', 'Structure', 'Symptoms', 'System', 'Test Result', 'Testing', 'Time', 'Training', 'Validation', 'clinical decision support', 'clinical decision-making', 'data mining', 'data quality', 'design', 'experimental study', 'flexibility', 'health care service utilization', 'health data', 'improved', 'lifetime risk', 'machine learning algorithm', 'neglect', 'neural network', 'neural network architecture', 'novel', 'open source', 'patient population', 'personalized diagnostics', 'personalized therapeutic', 'predictive modeling', 'recurrent neural network', 'scale up', 'social health determinants', 'stem', 'structured data', 'text searching', 'tool', 'trait']",NLM,NORTHWESTERN UNIVERSITY AT CHICAGO,R01,2021,315727
"Estimating Mediation Effects in Prevention Studies The purpose of this competing continuation grant proposal is to develop, evaluate and apply  methodological and statistical procedures to investigate how prevention programs change outcome  variables. These mediation analyses assess the link between program effects on the constructs targeted  by a prevention program and effects on the outcome. As noted by many researchers and federal  agencies, mediation analyses identify the most effective program components and increase  understanding of the underlying mechanisms leading to changing outcome variables. Information from  mediation analysis can make interventions more powerful, more efficient, and shorter. The P. I. of this grant received a one-year NIDA small grant and four multi-year grants to develop and evaluate mediation  analysis in prevention research. This work led to many publications and innovations. The proposed  five-year continuation focuses on the further development and refinement of exciting new mediation  analysis statistical developments. Four statistical topics represent next steps in this research and include  analytical and simulation research as well as applications to etiological and prevention data. The work expands on our development of causal mediation and Bayesian mediation methods that hold great promise for mediation analysis. In Study 1, practical causal mediation and Bayesian mediation analyses  for research designs are developed and evaluated. This approach will clarify methods and develop  approaches for dealing with violation of testable and untestable assumptions. Study 2 investigates  important measurement issues for the investigation of mediation. This work will focus on methods to identify critical facets of mediating variables, approaches to understanding whether mediators and  outcomes are redundant, and develop methods for studies with big data. Study 3 continues the development and evaluation of new longitudinal mediation methods for ecological momentary assessment data and other studies with massive data collection. These new methods promise to more accurately model change over time for both individuals and groups of individuals. Study 4 develops methods to  uncover subgroups in mediation analysis including causal mediation methods, multilevel models, and new  approaches based on residuals for identifying individuals for whom mediating processes differ in  effectiveness from other individuals. For each study, we will investigate unique issues with mediation analysis of prevention data including methods for small N and also massive data collection (big data), the RcErLitEicVaANl rCoEle(Soeef imnsetruacstiounrse):ment for mediating mechanisms, and the application of the growing literature on  causal methods and Bayesian methods. Study 5 applies new statistical methods to data from several NIH  The project further develops a method, statistical mediation analysis, that extracts more information from  funded prevention studies providing important feedback about the usefulness of the methods. Study 6  research. Mediation analysis explains how and why prevention and treatments are successful. Mediation  disseminates new information about mediation analysis through our website and other media, by  analysis improves prevention and treatment so that their effects are greater and even cost less. communication with researchers, and publications from the project. n/a",Estimating Mediation Effects in Prevention Studies,10168488,R37DA009757,"['Address', 'Applications Grants', 'Bayesian Method', 'Behavioral Mechanisms', 'Big Data', 'Biological Models', 'Communication', 'Complex', 'Consultations', 'Data', 'Data Analyses', 'Data Collection', 'Development', 'Ecological momentary assessment', 'Educational workshop', 'Effectiveness', 'Etiology', 'Evaluation', 'Feedback', 'Funding', 'Grant', 'Individual', 'Individual Differences', 'Intervention', 'Investigation', 'Link', 'Literature', 'Machine Learning', 'Measurement', 'Measures', 'Mediating', 'Mediation', 'Mediator of activation protein', 'Meta-Analysis', 'Methodology', 'Methods', 'Modeling', 'National Institute of Drug Abuse', 'Outcome', 'Persons', 'Prevention', 'Prevention Research', 'Prevention program', 'Principal Investigator', 'Procedures', 'Process', 'Psychometrics', 'Publications', 'Randomized', 'Recommendation', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Residual state', 'Statistical Data Interpretation', 'Statistical Methods', 'Subgroup', 'Testing', 'Time', 'Translating', 'United States National Institutes of Health', 'Work', 'base', 'computer program', 'cost', 'data space', 'design', 'dynamic system', 'improved', 'innovation', 'interest', 'longitudinal design', 'model design', 'multilevel analysis', 'novel strategies', 'programs', 'simulation', 'substance use treatment', 'successful intervention', 'theories', 'therapy design', 'tool', 'treatment research', 'web site']",NIDA,ARIZONA STATE UNIVERSITY-TEMPE CAMPUS,R37,2021,360584
"Scalable platform for optimizing human cardiac tissue engineering via optical pacing and on-demand oxygenation PROJECT SUMMARY Induced pluripotent stem cell-derived cardiomyocytes (iPS-CM) are emerging as an invaluable in vitro human experimental platform for disease modeling, drug discovery, cardiotoxicity screening, gene editing and functional genomics. For the first time, cardiac electrophysiology has access to a scalable human experimental model, which, currently, offers the only path to personalized (cardiac) medicine as patient-derived iPS-CMs can be generated on a progressively faster time scale. The clear potential of this technology motivates efforts to address the main criticisms facing iPS-CMs, namely the need for further maturation and reduction of phenotype heterogeneity. As multiple approaches are being pursued to improve iPS-CM maturation and to approximate the functionality of the adult human myocardium, we argue that combinatorial optimizations necessitate new high-throughput (HT) technology and automation. The overall goal of this project is to develop and validate a scalable platform for optimizing cardiac tissue engineering via chronic reconfigurable optical pacing and “on-demand” oxygenation for gaining mechanistic insights into cardiac metabolism and electrophysiology, a platform we call ChROME. Chronic electrical stimulation is a viable lead to iPS-CM maturation, yet it has remained under-explored, specifically as related to the role of mass transport and oxygenation during such stimulation. Leveraging our expertise in the theoretical and experimental use of optogenetic tools for cardiac applications (Entcheva) and automation (Kostov, Li, Entcheva, Kay), we propose to design and validate the first-generation HT-ChROME platform, that will integrate continuous monitoring of key physiological parameters. Our team’s expertise in optical oxygen sensing (Kostov), in-house manufacturing of “on-demand” oxygenation nanocarriers (perfluorocarbons, PFC) (Kay) and metabolic characterization (Kay, Beard) will be applied to address the increased metabolic demands during stimulation. The ability to quantify “functional maturation” by relevant measures (voltage, calcium, contraction) in a high-throughput manner (Entcheva) in 2D and 3D cardiac tissue constructs (Vunjak-Novakovic), using our automated platform OptoDyCE (all-optical dynamic cardiac electrophysiology) is critical in this undertaking. Employing these HT tools and other imaging and omics modalities (Popratiloff, Horvath), we will elucidate the spectrum of responses triggered by chronic stimulation of iPS-CMs: beneficial/maturation effects vs. pathological overload effects, depending on load and oxygenation conditions. The proposed HT-ChROME platform represents a critical step in resolving issues impeding progress with iPS-CMs to accelerate their wide-spread adoption in basic and translational applications. The obtained large-scale data will inform a new generation of biophysical models linking human cardiac metabolism and electrophysiology. PROJECT NARRATIVE Recent advances in stem-cell technology enable patient-derived cells to be turned into functional heart cells, and this is an exciting direction towards personalized medicine; yet, there are many challenges in optimizing these cardiomyocytes to better mimic the real heart – a problem that the proposed engineering tools will help resolve.",Scalable platform for optimizing human cardiac tissue engineering via optical pacing and on-demand oxygenation,10093123,R01HL144157,"['3-Dimensional', 'Address', 'Adoption', 'Adult', 'Affect', 'Automation', 'Biological', 'Calcium', 'Cardiac', 'Cardiac Electrophysiologic Techniques', 'Cardiac Myocytes', 'Cardiotoxicity', 'Cells', 'Chronic', 'Combinatorial Optimization', 'Data', 'Disease model', 'Electric Stimulation', 'Engineering', 'Event', 'Experimental Models', 'Fluorocarbons', 'Frequencies', 'Future', 'Generations', 'Genes', 'Goals', 'Heart', 'Heterogeneity', 'Hip region structure', 'Human', 'Human Engineering', 'Image', 'In Vitro', 'Incubators', 'Lead', 'Light', 'Link', 'Longitudinal Studies', 'Measures', 'Mechanics', 'Mediating', 'Medicine', 'Metabolic', 'Metabolism', 'Mitochondria', 'Modality', 'Modeling', 'Monitor', 'Myocardium', 'NADH', 'Optics', 'Oxygen', 'Oxygen Consumption', 'Pathologic', 'Patients', 'Phenotype', 'Physiologic pulse', 'Physiological', 'Regression Analysis', 'Role', 'Site', 'Technology', 'Testing', 'Time', 'Tissue Engineering', 'Tissues', 'Transcriptional Regulation', 'Viral', 'Work', 'biophysical model', 'cardiac tissue engineering', 'design', 'drug discovery', 'functional genomics', 'heart cell', 'heart metabolism', 'high throughput technology', 'improved', 'induced pluripotent stem cell', 'insight', 'large scale data', 'machine learning algorithm', 'nanocarrier', 'optogenetics', 'personalized medicine', 'programs', 'response', 'screening', 'side effect', 'stem cell technology', 'tool', 'transcriptomics', 'voltage']",NHLBI,GEORGE WASHINGTON UNIVERSITY,R01,2021,621465
"Shear stress and light-field to elucidate the initiation of cardiac outflow tract Shear Stress and Light-Field to Elucidate the Initiation of Cardiac Outflow Tract Biomechanical forces modulate cardiac morphogenesis, and mutations in mechano-sensitive signaling pathways result in congenital heart defects. During the previous funding cycle, our team custom-built a Light- Sheet Fluorescence Microscopy (LSFM) with sub-voxel resolution to enhance axial resolution needed to provide a large field-of-view. This laser optical system allowed for imaging pulsatile vs. oscillatory shear stress- mediated Notch signaling to initiate endocardial trabeculation. We demonstrated that spatial (/x) and temporal (/t) variations in shear stress modulates Notch-EphrinB2-Neureguilin-1 signaling in the endocardium to activate erb-B2 receptor tyrosine kinase (ErbB2) that promotes proliferation of trabeculation. By integrating LSFM, computation, and transgenic models, we further established that trabeculation dissipates intracardiac shear stress-generated kinetic energy; thus, mitigating ventricular remodeling. However, it remains unclear what would be the consequences of reduced myocardial contractility or altered intracardiac flow dynamics on valve morphogenesis. Thus, we seek to integrate light-sheet (Bessel-Gaussian beam arrays) with a new 2) light-field (microlens array). The former provides non-diffracting illumination, and the latter provides volumetric detection as a paradigm shift to image both myocardial contractility and intracardiac flow dynamics in the outflow tract (OFT). Our preliminary study reveals that shear-mediated Notch1b expression in the endocardium of OFT regulates endothelial-to-mesenchymal transition (EndoMT); however, the mechanotransduction causation whereby myocardial contractility and intracardiac shear stress reciprocally interact to form bicuspid valves and subsequent remodeling to multi-cuspid valves remains elusive. Thus, our hypothesis is that integration of the new light-field system with imaging computation enhances spatiotemporal resolution needed to decouple myocardial contraction from intracardiac flow dynamics that modulates Notch1b-EndoMT to mediate valve morphogenesis in the OFT. In Aim 1, we plan to integrate light-sheet with the new light-field system for 4-D volumetric imaging of valve formation in the OFT. Our goal is to capture myocardial contractility and intracardiac shear stress at one snapshot. In Aim 2, we will demonstrate the interaction between intracardiac shear stress and myocardial contractility underlying valve morphogenesis. Our goal is to decouple hemodynamic shear from contractile forces that mediate Notch1b-mediated EndoMT. In Aim 3, we will determine the relative role of shear stress and contractility underlying Notch1b-mediated EndoMT. Our goal is to elucidate the relative role of contractility and intracardiac stress to transmit Notch1b- EndoMT signaling underlying bicuspid-valve formation. Overall, our team aims to establish the micro- environment in which intracardiac flow dynamics and myocardial contractility interact to modulate OFT valve formation, with clinical significance to aortic valvular disease. Project Narrative Cardiac outflow tract (OFT) defects, including aortic valves and the greater arteries, are estimated to cause approximately 30% of these congenital heart diseases, and they are treated with surgical correction and/or replacement. It remains unclear what would be the consequences of reduced cardiac contractility or altered intracardiac flow dynamics on valve morphogenesis, including aortic stenosis, bicuspid or tricuspid aortic valves. To understand the mechanotransduction causation downstream of blood flow and shear stress sensing, we have assembled a multi-disciplinary team to integrate advanced laser optics, imaging computation, and genetic models to decouple intracardiac flow dynamics from myocardial contractility that modulates Notch1b-mediated endothelial-to-mesenchymal transition (EndoMT) with translational implication to aortic valve disease.",Shear stress and light-field to elucidate the initiation of cardiac outflow tract,10146767,R01HL129727,"['4D Imaging', 'Aortic Valve Stenosis', 'Arteries', 'Bicuspid', 'Biomechanics', 'Blood flow', 'Cardiac', 'Computer Models', 'Congenital Heart Defects', 'Coupled', 'Cuspid', 'Custom', 'Data Reporting', 'Defect', 'Detection', 'ERBB2 gene', 'Endocardium', 'Endothelium', 'Etiology', 'Fluorescence Microscopy', 'Funding', 'Gaussian model', 'Genes', 'Genetic Models', 'Genetic Recombination', 'Goals', 'Heart', 'Image', 'Kinetics', 'Lasers', 'Light', 'Lighting', 'Liquid substance', 'Machine Learning', 'Mediating', 'Mesenchymal', 'Microscopy', 'Mitral Valve', 'Morphogenesis', 'Mutation', 'Myocardial', 'Myocardial Contraction', 'Neuregulin 1', 'Operative Surgical Procedures', 'Optics', 'Receptor Protein-Tyrosine Kinases', 'Reporter', 'Resolution', 'Role', 'Signal Pathway', 'Signal Transduction', 'Stress', 'Structure', 'System', 'Testing', 'Time', 'Transgenic Model', 'Transgenic Organisms', 'Variant', 'Ventricular', 'Ventricular Remodeling', 'aortic valve', 'aortic valve disorder', 'automated segmentation', 'base', 'clinically significant', 'congenital heart disorder', 'erbB-2 Receptor', 'hemodynamics', 'imaging Segmentation', 'mechanotransduction', 'multidisciplinary', 'notch protein', 'optical imaging', 'response', 'shear stress', 'simulation', 'single-cell RNA sequencing', 'spatiotemporal', 'transcriptomics']",NHLBI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,459651
"Personalized 3D avatar tool development for measurement of body perception across gender identities Abstract Public awareness of the diversity of experiences of gender identities has climbed sharply. The specific issues of those with gender dysphoria (GD) related to self-identity, body image, and medical interventions are challenges for the 21st century, particularly given the high risk of suicide. Gender identity is tightly linked to one’s bodily features, particularly readily observable sexual characteristics. For transgender and nonbinary individuals with GD, the incongruence between their body associated with their birth-assigned sex – what they see in the mirror before any treatment – and the internalized representation of their gender-identified body is a key defining part of their experience and contributes to their dysphoria. Currently, no clinical or research tool exists to capture and quantify the diverse experiences of one’s current body and one’s gender-identified body (which may be distinct from their current body), across a range of gender identities. Measuring the internalized representation of one’s body could be facilitated by technology to visually represent this on a three-dimensional avatar. The technology needed to scan and analyze the human figure is now available and cost efficient. It is now possible to scan individuals to create personalized 3D visualizations, or “avatars,” with which they can interact on mobile and desktop devices to represent internal representation of their bodies. This can allow individuals to see and manipulate their own 3D avatar with a high degree of flexibility. The goal of this project is to create a novel, visually based digital tool to measure, understand, and quantify individuals’ experiences of their bodies. We will develop, validate, and test in transgender, nonbinary, and cisgender adults a personalized avatar tool to represent internalized gender-identified bodies in order to quantify incongruence between this and one’s current body. This tool – “GD Somatomap” – will be an advancement over existing self-report questionnaires to capture visual representations of internalized body image, cross-sectionally and dynamically over time. It will be flexible enough to characterize the heterogenous experiences of a range of gender identities including binary transgender, gender fluid, nonbinary, and cisgender. It can be used in clinical and clinical research applications to track outcomes of cross-hormone and gender-affirming surgical treatments. It can potentially improve clinical outcomes by identifying specific sets of body parts as targets for treatments to improve body congruence. Further, it will provide a unique means to measure own-body perceptual accuracy; understanding differences in perceptual accuracy and what potentially modifiable factors contribute to this may have prognostic significance for treatments to address body incongruence. It could also be used in future studies to investigate functional and structural neurobiological correlates of body perception and internal body representation, and at what point in neurodevelopment these emerge for those with different gender identities. PROJECT NARRATIVE The internalized, conscious experience of one’s body is not easily communicated, much less measured and quantified. This is especially relevant for those with gender dysphoria, whose internal, gender-identified body representation is incongruent with their current body. We will develop and test an innovative technological solution, making use of 3D image reconstruction and advanced 3D modeling, to create personalized avatars to measure body incongruence for research and clinical applications in those with gender dysphoria.",Personalized 3D avatar tool development for measurement of body perception across gender identities,10111313,R21EB030851,"['3-Dimensional', 'Address', 'Adult', 'Area', 'Awareness', 'Birth', 'Body Image', 'Body measure procedure', 'Body part', 'Breast', 'Characteristics', 'Clinical', 'Clinical Research', 'Computer software', 'Conscious', 'Data', 'Development', 'Devices', 'Discriminant Analysis', 'Distress', 'Future', 'Gender', 'Gender Identity', 'Goals', 'Gonadal Steroid Hormones', 'Grouping', 'Hormonal', 'Hormones', 'Human body', 'Individual', 'Intervention', 'Least-Squares Analysis', 'Link', 'Measurement', 'Measures', 'Medical', 'Monitor', 'Neurobiology', 'Operative Surgical Procedures', 'Outcome', 'Patient Self-Report', 'Physical shape', 'Problem Solving', 'Questionnaires', 'Reporting', 'Research', 'Scanning', 'Sex Characteristics', 'Shapes', 'Specific qualifier value', 'Structure', 'Techniques', 'Technology', 'Testing', 'Three-Dimensional Image', 'Time', 'Validation', 'Visual', 'Waist-Hip Ratio', 'base', 'body dissatisfaction', 'cisgender', 'clinical application', 'cost efficient', 'digital', 'dysphoria', 'experience', 'flexibility', 'follow-up', 'gender dysphoria', 'gender fluid', 'high risk', 'image reconstruction', 'improved', 'innovation', 'neurodevelopment', 'novel', 'prognostic significance', 'sex', 'suicidal risk', 'three-dimensional modeling', 'three-dimensional visualization', 'tool', 'tool development', 'transgender', 'unsupervised learning']",NIBIB,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,203647
"MUFA-SIRT1 signaling as a central node regulating healthspan PROJECT SUMMARY Macronutrients serve a multitude of roles beyond provision of energy, with numerous nutrients and/or their downstream metabolites acting as signaling molecules to coordinate cellular metabolism and function. Indeed, numerous nutrient sensing pathways (e.g. mTOR, AMPK and sirtuins) have evolved allowing us to respond to specific nutrients/metabolites, which in turn impacts healthspan. Sirtuins are largely thought to be driven by redox, whereby high levels of NAD, a cofactor in the sirtuin reaction and indicator of low energy charge, drives sirtuin-catalyzed deacylation of target proteins. SIRT1, the most-studied sirtuin, is a key nutrient sensing node that regulates a plethora of cellular functions to promote lifespan extension and healthy aging. As a result, there is immense interest in the use of SIRT1 activating compounds (STACs) to prevent or treat a wide range of aging-related disease. The links between dietary macronutrients, nutrient sensing and healthspan have historically focused upon caloric or protein restriction with limited attention given to dietary lipids. However, a small and growing body of literature has linked monounsaturated fatty acids (MUFAs) to improved healthspan. In addition to positive effects on lifespan and healthy aging in model organisms, dietary MUFAs have been linked to wide-ranging health benefits in epidemiological studies and, since they are a primary constituent of olive oil, thought to contribute to the benefits of the Mediterranean Diet. Despite these studies, little is known about the biological underpinnings through which MUFAs elicit their beneficial health effects. We have previously shown that lipid droplet catabolism (i.e. lipolysis) increases SIRT1 and downstream PGC-1a/PPAR- a signaling as a means to increase mitochondrial biogenesis and function during times of nutrient deprivation. Our preliminary data show for the first time that MUFAs released specifically from lipolysis are trafficked to the nucleus where they allosterically activate SIRT1 towards select acetylated peptide substrates. This discovery makes MUFAs the first-known endogenous allosteric activators of SIRT1. Moreover, we show that MUFAs activate SIRT1 through a similar mechanism to resveratrol suggesting that MUFA signaling may modulate the response to exogenous SIRT1 activators. Based on these preliminary data, the objective of this application is to further characterize the role of MUFAs as endogenous SIRT1 activators. We hypothesize that MUFAs selectively activate SIRT1 to modulate the response to numerous dietary interventions known to impact healthspan. To test our objective, we propose the following aims: Aim 1: To define how MUFAs modulate SIRT1 substrate selectivity. Aim 2: To characterize the SIRT1-dependent effects of MUFAs/olive oil on healthspan. Aim 3: To determine the contribution of MUFAs in mediating the response to STACs or caloric restriction. Upon completion of the proposes studies, we will have further expanded our understanding of SIRT1 biology allowing for refined approaches to activate SIRT1 to promote healthy aging. NARRATIVE The proposed studies will advance our understanding into the underlying biology linking dietary factors to healthspan. The data gleaned from these studies will help refine therapeutic or nutritional avenues to modulate lifespan and aging-related diseases resulting in a direct, positive impact on human health.",MUFA-SIRT1 signaling as a central node regulating healthspan,10263268,R01AG069768,"['Aging', 'Animal Model', 'Animals', 'Attention', 'Biogenesis', 'Biological', 'Biology', 'Caloric Restriction', 'Catabolism', 'Cell Nucleus', 'Cell physiology', 'Charge', 'Clinical Trials', 'Data', 'Deacetylation', 'Development', 'Diet', 'Dietary Factors', 'Dietary Fats', 'Dietary Intervention', 'Disease', 'Dose', 'FRAP1 gene', 'Fasting', 'Glean', 'Gold', 'Health', 'Health Benefit', 'Human', 'Link', 'Lipids', 'Lipolysis', 'Literature', 'Longevity', 'Machine Learning', 'Macronutrients Nutrition', 'Maps', 'Mediating', 'Mediterranean Diet', 'Metabolism', 'Mitochondria', 'Modeling', 'Monounsaturated Fatty Acids', 'Mus', 'Nutrient', 'Nutritional', 'Oils', 'Olive oil preparation', 'Olives - dietary', 'Outcome', 'Oxidation-Reduction', 'PPAR alpha', 'Pathway interactions', 'Peptides', 'Pharmacologic Substance', 'Proteins', 'Proteomics', 'Reaction', 'Research', 'Resveratrol', 'Role', 'SIRT1 gene', 'Signal Transduction', 'Signaling Molecule', 'Sirtuins', 'Source', 'Testing', 'Therapeutic', 'Time', 'Work', 'analog', 'base', 'cofactor', 'deacylation', 'detection of nutrient', 'dietary', 'epidemiology study', 'healthspan', 'healthy aging', 'improved', 'innovation', 'interest', 'middle age', 'mutant mouse model', 'novel', 'nutrient deprivation', 'polyphenol', 'prevent', 'red wine', 'response']",NIA,UNIVERSITY OF MINNESOTA,R01,2021,317579
"Shape up! Kids Project Summary/Abstract Of all markers of pediatric health, the most intuitive is body shape. Human and animal studies indicate that weight loss/gain correlates closely with increasing/decreasing insulin sensitivity, respectively. Anthropometry and regional composition measures such as waist circumference, waist to hip ratio (WHR), and visceral adipose tissue area are better predictors of obesity-related diseases and mortality risk than pediatric body mass index Z-score. Dual-energy X-ray absorptiometry can quantify regional adiposity in more detail than these measures but is underutilized for many reasons including the sensitivity to children to ionizing radiation, cost, and training. A study is needed to take advantage of rapid technological developments in optical technology to better describe phenotypes of pediatric body shape and its relation to metabolic risks (obesity, “failure to thrive”) and bone density and size. If successful, sophisticated obesity phenotype profiles could be constructed to clarify the underlying associations of body composition with disease, genetics, lifestyle exposures, metabolomics, and be highly assessable using self-assessment technology. The long term goal of the Shape Up! Kids Study is 1) to provide pediatric phenotype descriptors of health using body shape, and 2) to provide the tools to visualize and quantify body shape in research, clinical practice, and personal health assessment. Our overall approach is to first derive predictive models of how body shape relates to regional and total body composition (subcutaneous fat, visceral fat, muscle mass, lean mass, and percent fat) and bone mineral density (BMD) over a wide range of ages (5 to 18 years), weights and heights, stratified by sex, and ethnicity. Our central hypothesis is that optical estimates with shape classification of soft tissue composition and bone density better predict fracture and metabolic risk factors than anthropometry (WC, WHR, and BM) alone. The Investigators will highly leverage existing data from the National Health and Nutrition Examination Survey and Bone Mineral Density in Children Study. Our specific aims are: 1) Identify the unique associations of body shape to body composition and bone density indices in a pediatric population that represents the variance found in the US population, 2) Describe the precision and accuracy of optical scans to monitor change in body composition, bone density, 3) Estimate the level of association of optical scans to common health indicators including metabolic risk factors. Our exploratory aim is to investigate holistic, high-resolution descriptors of 3D body shape as direct predictors of body composition and metabolic risk using statistical shape models and Latent Class Analysis. By the end of this study, we expect to have models of the shape and composition suitable for self-assessment technologies that are capable of representing over 95% of the shape variance in the US pediatric population, and to define how these models relate to important metabolic status indicators. The positive impact of these outcomes will be the immediate applicability to other researcher studies and clinicians using the automated tools and models developed here for 3D optical images. PROJECT NARRATIVE  The proposed research is relevant to public health because they have the potential to provide a better understanding of what children are at high risk of metabolic consequences of obesity. Thus, the advances proposed are expected to have a high impact to the health and wellbeing of all US citizens because metabolic diseases, such as obesity and its complications, are currently the number one killers of adults, and are becoming epidemic in children as well. This is relevant to the part of NIH's mission which focuses on the prevention of disease by supporting research in the diagnosis of human diseases.",Shape up! Kids,10109111,R01DK111698,"['3-Dimensional', 'Adipose tissue', 'Adult', 'Age', 'Algorithms', 'Animals', 'Anthropometry', 'Area', 'Blood Pressure', 'Body Composition', 'Body Surface', 'Body Weight decreased', 'Body mass index', 'Body measure procedure', 'Bone Density', 'Child', 'Childhood', 'Classification', 'Clinical', 'Computer Vision Systems', 'Data', 'Descriptor', 'Development', 'Diabetes Mellitus', 'Diagnosis', 'Disease', 'Dual-Energy X-Ray Absorptiometry', 'Epidemic', 'Epidemiology', 'Ethnic Origin', 'Failure to Thrive', 'Fatty acid glycerol esters', 'Fracture', 'Gender', 'Genetic', 'Glucose', 'Goals', 'Health', 'High Density Lipoprotein Cholesterol', 'Human', 'Image', 'Imaging technology', 'Insulin Resistance', 'International', 'Intervention', 'Intuition', 'Ionizing radiation', 'Life Style', 'Liver', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Diseases', 'Methodology', 'Mission', 'Modeling', 'Monitor', 'Movement', 'Muscle', 'National Health and Nutrition Examination Survey', 'Obesity', 'Obesity associated disease', 'Optics', 'Outcome', 'Pediatric Radiology', 'Personal Satisfaction', 'Phenotype', 'Population', 'Public Health', 'Race', 'Research', 'Research Personnel', 'Research Support', 'Resolution', 'Risk', 'Risk Factors', 'Safety', 'Scanning', 'Self Assessment', 'Shapes', 'Technology', 'Technology Assessment', 'Thinness', 'Three-Dimensional Imaging', 'Training', 'Triglycerides', 'United States National Institutes of Health', 'Visceral', 'Visceral fat', 'Waist-Hip Ratio', 'Weight', 'bone', 'clinical practice', 'cost', 'disorder prevention', 'disorder risk', 'handheld mobile device', 'health assessment', 'high risk', 'human disease', 'indexing', 'insulin sensitivity', 'metabolomics', 'mortality', 'mortality risk', 'muscle form', 'optical imaging', 'predictive modeling', 'sensor', 'sex', 'soft tissue', 'subcutaneous', 'tool', 'waist circumference']",NIDDK,UNIVERSITY OF HAWAII AT MANOA,R01,2021,582917
"National Alzheimer's Coordinating Center Project summary/abstract NACC (as U01 AG016976, at University of Washington) has been active since 1999. The existing NACC infrastructure is described in the Facilities and Resources Section of this application. The broad goals of the past funding cycles are consistent with those of the current U24 RFA — that is, to serve as: a.) the central hub for organizing and enabling communication within and outside of the ADRC program, including annual meetings and steering committees; b.) a national data resource, collecting data from the Alzheimer's Disease Research Centers (ADRCs) as well as affiliated data and sample repositories; and c.) a facilitator of current and future AD/ADRD research. NACC has considerable experience and success in reaching these goals, and is positioned for continued success in a rapidly advancing field. New data and methods are appearing in areas such as biomarkers, neuropathology, and tests for early detection. Through the strategic adoption of technological advances, we will build on these accomplishments at an accelerated pace. Building on our already significant capabilities, we will: promote and broaden communication within and outside of the ADRC program; expand informatics capabilities of NACC consistent with FAIR principles; conduct and support methodologic and applied research, leveraging deep expertise in biostatistics and data science; and support early-career research scientists by providing peer-reviewed competitive funding for several “junior investigators” each year. We aim to continue to improve our approach in each arena by combining time-tested approaches with the new tools and innovations we are developing to meet the changing scientific, technological, and communication needs of the NIA ADRC program and the field. Narrative NACC (as U01 AG016976, at University of Washington — now seeking renewal as a U24) has been active since 1999, and has established a standardized, longitudinal clinical database of over 42,000 individuals (with neuropathology data on over 6,100), as well as cross-sectional, retrospective data on roughly 66,000 individuals seen at ADRCs between 1984 and 2005. NACC has made these data freely available to researchers worldwide, resulting in hundreds of publications. We will modernize and intensify our informatics approach, making data access and use more efficient; will grow communication and coordination capabilities with the ADRCs and collaborating NIA projects; will develop and apply big-data research tools for the field; and will provide competitive, peer-reviewed research support for several new investigators each year. Together with the field’s leaders, NACC will innovate, develop, and drive solutions to meet the changing needs of the field as well as the NIA ADRC program.",National Alzheimer's Coordinating Center,10204491,U24AG072122,"['Achievement', 'Adoption', 'Age', 'Alzheimer disease prevention', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Applied Research', 'Area', 'Award', 'Big Data', 'Biological Markers', 'Biometry', 'Collaborations', 'Communication', 'Complex', 'Consultations', 'Contracts', 'Data', 'Data Collection', 'Data Coordinating Center', 'Data Science', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Dementia', 'Early Diagnosis', 'Enrollment', 'Environment', 'Faculty', 'Funding', 'Future', 'Genetic', 'Genetic Diseases', 'Genomics', 'Goals', 'Heterogeneity', 'Individual', 'Informatics', 'Infrastructure', 'Institutes', 'Lead', 'Leadership', 'Link', 'Medicine', 'Methodology', 'Methods', 'Mission', 'Modernization', 'Peer Review', 'Positioning Attribute', 'Publications', 'Recording of previous events', 'Research', 'Research Peer Review', 'Research Personnel', 'Research Support', 'Resources', 'Risk Factors', 'Sampling', 'Scientist', 'Secure', 'Services', 'Site', 'Source', 'Specimen', 'Standardization', 'Techniques', 'Technology', 'Testing', 'Time', 'Translational Research', 'Universities', 'Washington', 'base', 'career', 'clinical database', 'clinical examination', 'cohort', 'community center', 'data access', 'data resource', 'data sharing', 'data visualization', 'deep learning', 'digital', 'disease heterogeneity', 'e-science', 'experience', 'high standard', 'imaging biomarker', 'improved', 'innovation', 'instrument', 'interest', 'interoperability', 'meetings', 'neuroimaging', 'neuropathology', 'novel', 'programs', 'repository', 'social media', 'success', 'tool', 'translational health science', 'trend', 'web site']",NIA,UNIVERSITY OF WASHINGTON,U24,2021,6979612
"Microdata for Analysis of Early Life Conditions, Health, and Population Project Summary This project will enhance and develop the only source of data that provides core information about work, education, income, and migration for the entire U.S. population. This unique resource allows us to observe today's late-life population when they were young. This allows a prospective view of the impact of early-life environments and socioeconomic status on health and well-being in later life. The massive database describes the characteristics of all 133 million persons who resided in the United States in 1940. The data have been available for only a brief period, but are already having a profound impact on scientific research. They are the primary data source for at least 19 sponsored projects, including nine funded by NIH and seven funded by NSF. Through May 2017, 104 investigators had produced 95 papers based on the data, including 22 articles, four books, three PhD dissertations, and 66 working papers. This project will improve the quality and usability of the database by correcting transcription errors; improving the coding, editing, and allocation of key variables; and introducing new data dissemination tools designed to simplify access to the data. The project will undertake three major activities to meet these objectives. 1. Incorporate new verified census information on name, age, sex, family relationship, race, marital status,  birthplace, and residence five years ago. 2. Improve coding, editing, and allocation for geographic variables, migration, occupation, and numerically-  coded variables such as income. 3. Apply new technologies to democratize access to the data through new data access tools and a virtual data  enclave for a restricted version of the data that contains names. This project is a highly cost-effective use of scarce resources to develop shared infrastructure for research, education, and policy-making on health and aging. The proposed improvement of data quality is urgent, and will provide a resource of unprecedented power for understanding the effects of public policies, social institutions, and environmental conditions on the health, well-being, and functioning of people, both over the life course and in their later years. Narrative This project will develop data for prospective analysis of the impact of early-life circumstances and environment on health outcomes in late life, including Alzheimer's disease. The proposed improvement of data quality is urgent, and will provide a resource of unprecedented power for understanding the effects of public policies, social institutions, and environmental conditions on the health, well-being, and functioning of people, both over the life course and in their later years. The proposed work is directly relevant to the core mission of the Population and Social Processes branch of NIA, since the data will allow us to observe today's late-life population when they were young.","Microdata for Analysis of Early Life Conditions, Health, and Population",10138934,R01AG041831,"['Age', 'Aging', 'Alzheimer&apos', 's Disease', 'American', 'Arbitration', 'Books', 'Censuses', 'Characteristics', 'Church of Jesus Christ of Latter-day Saints', 'Code', 'County', 'Data', 'Data Sources', 'Databases', 'Demography', 'Doctor of Philosophy', 'Economics', 'Education', 'Elderly', 'Ensure', 'Environment', 'Family Relationship', 'Funding', 'Future', 'Genealogy', 'Genetic Transcription', 'Geography', 'Handwriting', 'Health', 'Income', 'Institution', 'Investments', 'Journals', 'Life', 'Life Cycle Stages', 'Link', 'Machine Learning', 'Marital Status', 'Methods', 'Mission', 'Names', 'Occupational', 'Occupations', 'Outcome', 'Paper', 'Personal Satisfaction', 'Persons', 'Policy Making', 'Population', 'Population Process', 'Privatization', 'Process', 'Public Policy', 'Publications', 'Race', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Resources', 'Science', 'Social Processes', 'Socioeconomic Status', 'Sociology', 'Source', 'Techniques', 'Technology', 'Time', 'United States', 'United States National Institutes of Health', 'Work', 'arm', 'base', 'blind', 'cost', 'cost effective', 'data access', 'data dissemination', 'data enclave', 'data quality', 'design', 'experimental study', 'improved', 'migration', 'new technology', 'prospective', 'residence', 'sex', 'social', 'tool', 'usability', 'virtual']",NIA,UNIVERSITY OF MINNESOTA,R01,2021,551550
"Improving Glycemic Management in Patients with Type 1 Diabetes Using a Context-aware Automated Insulin Delivery System Project Summary Automated insulin delivery (AID) systems offer substantial opportunities for helping people with type 1 diabetes (T1D) to improve glucose control and lower HbA1c. However, the AID has only shown a benefit during the nighttime when meals, exercise, and stress do not significantly challenge the AID. Furthermore, hypoglycemia (<70 mg/dL) remains a common occurrence in people with type 1 diabetes and continues to occur even in the setting of AID, particularly with exercise. Integrating context awareness into an AID has the potential to improve glycemic time in range (70-180 mg/dL) during the daytime and reduce and possibly eliminate hypoglycemia. Contextual information can include inferred food intake, insulin dosing, inferred exercise type and duration, as well as movement patterns. An AID can be designed to recognize contextual patterns that relate to poor glycemic responses to meals and hypoglycemia and then adjust insulin dosing in response to these patterns in advance and help mitigate these problems. In this grant, we will explore how contextual information may be used within an AID to help (1) avoid hypoglycemia and (2) reduce postprandial dysglycemia. We will first conduct a data gathering study whereby we will collect a rich data set from people with T1D who will use sensor augmented pump therapy to manage their glucose. Data will be collected from these 30 patients over 28 days; data will include multivariable contextual information including continuous glucose monitoring (CGM) data, insulin data, food data, physical activity data (heart rate and accelerometry), as well as indoor/outdoor contextual movement patterns gathered using a novel beacon-based context-aware sensing system called MotioWear developed by our group in collaboration with our industry partner MotioSens. Next, we will utilize this contextual data set to construct a Bayesian glucose prediction algorithm. This will include a clustering algorithm that will group contextual sequences that are similar with each other and which lead to similar glycemic outcomes. This context-aware glucose prediction algorithm will be integrated into an adaptive, personalized, smartwatch-based context-aware AID (CA-AID) system. Contextual patterns that have a high likelihood of leading to hypoglycemia or postprandial dysglycemia will inform an insulin dosing aggressiveness factor to be adjusted for similar contextual sequences observed in the future (i.e. the CA-AID will reduce insulin for contextual sequences with high likelihood of hypoglycemia such as aerobic exercise). We expect that integrating context awareness into an AID will lead to significant improvements in time in target range during the day and will help reduce time in hypoglycemia. The CA-AID will be evaluated for safety in a small pilot study. We will then evaluate the CA-AID within a 6 week clinical study in 40 adults with type 1 diabetes on insulin pump therapy. Twenty will receive the CA-AID while the other 20 will receive a standard (non-context-aware) AID. The primary outcome measures of this study is the percent time in range. We hypothesize that the CA-AID will increase time in range by 10% as compared with a non-context aware AID. Project Narrative Diabetes is the leading cause of blindness, kidney failure, and non-traumatic amputations. While automated insulin delivery systems can help people with type 1 diabetes better manage their glucose levels during the night, improved glycemic control during the day has not been demonstrated and hypoglycemia continues to be a problem, especially during exercise. We propose to develop and evaluate in a clinical study a context-aware automated insulin delivery system that learns patterns of daily living, meal patterns, glucose patterns, insulin dosing patterns, and physical activity patterns that relate to dysglycemia and adapts the gains within the AID to improve postprandial time in target range (70-180 mg/dL) and reduce hypoglycemia.",Improving Glycemic Management in Patients with Type 1 Diabetes Using a Context-aware Automated Insulin Delivery System,10147069,R01DK122583,"['Accelerometer', 'Adult', 'Aerobic Exercise', 'Algorithms', 'Awareness', 'Beds', 'Behavior', 'Blindness', 'Calibration', 'Cellular Phone', 'Clinic', 'Clinical Research', 'Collaborations', 'Custom', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Diabetes Mellitus', 'Dose', 'Eating', 'Engineering', 'Event', 'Exercise', 'Fatty acid glycerol esters', 'Food', 'Future', 'Glucose', 'Glycosylated hemoglobin A', 'Grant', 'Heart Rate', 'Home environment', 'Hyperglycemia', 'Hypoglycemia', 'Insulin', 'Insulin Infusion Systems', 'Insulin-Dependent Diabetes Mellitus', 'Kidney Failure', 'Knowledge', 'Lead', 'Learning', 'Life', 'Maps', 'Measures', 'Movement', 'Outcome', 'Outcome Measure', 'Outpatients', 'Participant', 'Patients', 'Pattern', 'Physical activity', 'Physiological', 'Pilot Projects', 'Pump', 'Randomized', 'Randomized Clinical Trials', 'Restaurants', 'Risk', 'Running', 'Safety', 'Schedule', 'Stress', 'System', 'Tactile', 'Testing', 'Time', 'Wrist', 'arm', 'base', 'blood glucose regulation', 'cohort', 'design', 'effectiveness evaluation', 'expectation', 'fitbit', 'fitness', 'glucose monitor', 'glucose sensor', 'glycemic control', 'high risk', 'improved', 'industry partner', 'machine learning algorithm', 'novel', 'prediction algorithm', 'primary outcome', 'recruit', 'research clinical testing', 'response', 'sensor', 'smart watch', 'two-arm study', 'usability', 'wearable sensor technology']",NIDDK,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,561582
"Quantitative and Spectroscopic Imaging of Skeletal Muscle Changes in Sarcopenia at High Field Project Summary Sarcopenia, a condition characterized by loss of muscle mass and function in the elderly, is of increasing relevance in the United States due to its aging population. It is generally agreed that the weakening of the muscle in sarcopenia cannot be explained by loss of muscle mass alone, but the mechanisms behind this remain poorly understood. This is partly due to the lack of non-invasive techniques for observing muscle structure and composition in high detail. We propose to develop MRI techniques to measure muscle morphology, microstructure, and fat content to get a detailed view of the changes in muscle quantity and quality in patients with sarcopenia and how they relate to more easily attainable measurements of muscle function such as grip strength and gait speed. This would provide an important contribution to the ongoing debate about how such measurements could be used to define sarcopenia, which would pave the way for treatment development. We aim to develop novel methods to investigate the structure and composition of muscle using ultra-high-field MRI. Specifically, we aim to (1) obtain water-based images of skeletal muscle macro- and microstructure with unparalleled efficiency, image quality, and resolution; (2) obtain images of the spatial distribution of intramyocellular lipids in skeletal muscle, measuring both methyl and methylene to estimate saturation; and (3) to conduct a study comparing skeletal muscle structure and quality by looking at MR measurements of T2 relaxation rates, diffusivity (as proxies for inflammation and fiber size, respectively), fat fraction, and lipid composition, in subjects with sarcopenia and healthy controls and see how these quantities correlate to muscle function. This project has several innovative aspects. First, we will develop a method to estimate muscle morphology, T2 relaxation rates, and diffusivity with a single MRI sequence. Importantly, this will make the developed method easy to run at other MRI sites. Second, we will devise methods to perform robust, efficient imaging of intramyocellular lipid droplet distribution and saturation in human skeletal muscle in vivo at high field. Both of these methods will have unparalleled signal-to-noise ratio and robustness against image artifacts. The significance of this work is the investigation of the role of inflammation, fiber size, and lipid distribution in the weakening of muscle in sarcopenia and how these measurements are related to muscle function. The resulting conclusions and techniques may help establish a common standard for the definition of sarcopenia and aid in the development of future treatments for this condition. Project Narrative Sarcopenia, the loss of muscle mass and function with age, is a condition bound to increase in prevalence with an aging population. The muscle changes involved include not only reduction in mass but also changes in muscle quality not easily visualized with current methods. This work aims to develop efficient MRI techniques to investigate these changes in better detail, improving scientific understanding of the mechanisms of sarcopenia and how they relate to muscle function.",Quantitative and Spectroscopic Imaging of Skeletal Muscle Changes in Sarcopenia at High Field,10125507,K99AG066815,"['3-Dimensional', 'Affect', 'Age', 'Awareness', 'Biological Markers', 'Clinical', 'Communities', 'Consensus', 'Data', 'Development', 'Diagnostic', 'Diffuse', 'Diffusion', 'Elderly', 'Evaluation', 'Fatty acid glycerol esters', 'Fiber', 'Fracture', 'Frequencies', 'Future', 'Gait speed', 'Geriatrics', 'Goals', 'Hand Strength', 'Health', 'Health Personnel', 'Hospitalization', 'Human', 'Image', 'Imaging Techniques', 'Inflammation', 'Investigation', 'Life Expectancy', 'Lipids', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Measurement', 'Measures', 'Medical Imaging', 'Metabolic', 'Metabolic Marker', 'Methods', 'Morphologic artifacts', 'Morphology', 'Muscle', 'Muscle function', 'Muscular Atrophy', 'Noise', 'Patients', 'Phase', 'Physiologic pulse', 'Predisposition', 'Prevalence', 'Protons', 'Proxy', 'Relaxation', 'Research', 'Resolution', 'Role', 'Running', 'Signal Transduction', 'Site', 'Skeletal Muscle', 'Soleus Muscle', 'Spatial Distribution', 'Spectrum Analysis', 'Structure', 'Techniques', 'Testing', 'Time', 'Tissues', 'Treatment Effectiveness', 'United States', 'Water', 'Work', 'aging population', 'base', 'bone imaging', 'carbene', 'clinical biomarkers', 'design', 'falls', 'imaging biomarker', 'imaging modality', 'improved', 'in vivo', 'innovation', 'muscle form', 'muscle strength', 'muscular structure', 'novel', 'potential biomarker', 'quantitative imaging', 'radio frequency', 'recruit', 'sarcopenia', 'spectroscopic imaging', 'therapy development']",NIA,MASSACHUSETTS GENERAL HOSPITAL,K99,2021,114480
"Classifying Oral Lesions with Chip-on-tip Electrical Impedance Sensing ABSTRACT No real-time quantitative devices are clinically used to assess oral lesions during routine examination, making in-clinic diagnostic and longitudinal monitoring challenging. Instead, lesions are evaluated through visual inspection and then histopathological analysis of tissue samples extracted during biopsy. Identifying premalignant and malignant oral lesions early is critical to ensuring effective treatment is provided to patients with malignancies. Oral cancer currently has one of the lowest 5-year survival rates (50% or less) among major cancer types, largely due to the challenges in identifying premalignant and malignant lesions early. Clearly, a real-time in-clinic device able to classify oral lesions as benign, premalignant, or malignant has the potential to provide immediate impact to patient care. Significantly different electrical property signatures have been observed between benign and malignant tissues in a variety of organs, including tongue; since the bioelectrical properties are so dependent on tissue architecture and morphology, we hypothesize that sensing and imaging these properties in the context of oral lesions will enable us to accurately characterize and classify morphologically-different benign, premalignant, and malignant oral lesions. We have developed an endoscopic electrical impedance imaging (EII) device for use in intraoperative surgical margin assessment that we aim to optimize for in-clinic oral lesion assessment. We aim to take the significant step of translating our extensive experience in impedance imaging to develop an oral lesion imaging device that can be deployed safely, and in the clinic, to provide real-time feedback regarding oral lesion classification. We propose constructing a novel chip-on-tip EII probe to sense and image at near microscopic resolution oral lesions in an effort to provide clinicians with real-time, accurate classification of oral lesion pathology that can be used for diagnostic and longitudinal monitoring purposes. The probe will be evaluated on a series of in vivo human oral lesions and compared with histopathological analysis of biopsy samples. The low-cost of a device such as this makes it an ideal technology for low-resource settings and the safety and real-time capabilities of the system make it ideal for continuously following lesions. PROJECT NARRATIVE Visual inspection of oral lesions is not sufficient for accurately classifying lesions as benign, premalignant, or malignant. The electrical properties of oral lesion have the potential to be used as a contrast mechanism to accurately classify oral lesions so that optimal treatment can be provided to patients with malignant lesions. We intend to deploy a novel small field of view chip-on-tip electrical impedance imaging (EII) probe in a cohort of patients with oral lesions to evaluate the efficacy of using EII for oral lesion classification.",Classifying Oral Lesions with Chip-on-tip Electrical Impedance Sensing,10287597,R21DE031095,"['Architecture', 'Area', 'Benign', 'Biological Markers', 'Biopsy', 'Biopsy Specimen', 'Cancerous', 'Carcinoma', 'Carcinoma in Situ', 'Classification', 'Clinic', 'Clinical', 'Clinical Trials', 'Contralateral', 'Custom', 'Data', 'Decision Making', 'Devices', 'Diagnosis', 'Diagnostic', 'Dysplasia', 'Electrodes', 'Electronics', 'Ensure', 'Epithelial', 'Excision', 'Feedback', 'Frequencies', 'Hand', 'Histologic', 'Human', 'Hyperplasia', 'Image', 'Imaging Device', 'Ionizing radiation', 'Length', 'Lesion', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Malignant neoplasm of prostate', 'Measurement', 'Microscopic', 'Monitor', 'Morphology', 'Noise', 'Normal tissue morphology', 'Oral Characters', 'Oral cavity', 'Organ', 'Oropharyngeal', 'Pathology', 'Patient Care', 'Patients', 'Positioning Attribute', 'Procedures', 'Property', 'Research Design', 'Resolution', 'Resources', 'Safety', 'Sampling', 'Series', 'Signal Transduction', 'Site', 'Squamous Cell', 'Surgical margins', 'Survival Rate', 'System', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'Tongue', 'Translating', 'Visual', 'analog', 'base', 'bioelectricity', 'cancer type', 'cohort', 'cost', 'design', 'effective therapy', 'efficacy evaluation', 'electric impedance', 'electrical impedance tomography', 'electrical property', 'experience', 'extracellular', 'imaging probe', 'imaging properties', 'in vivo', 'interest', 'malignant mouth neoplasm', 'monitoring device', 'novel', 'optimal treatments', 'oral lesion', 'oral tissue', 'premalignant', 'pressure', 'pressure sensor', 'programs', 'response', 'soft tissue']",NIDCR,DARTMOUTH COLLEGE,R21,2021,191061
"Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0) OVERALL: ABSTRACT  The scope of regenerative medicine encompasses the repair, regeneration, and replacement of defective, injured, and diseased tissues and organs. The success of regenerative therapies is dependent, at least in part, on a favorable microenvironment in which the regenerative processes occur. Technological innovations and a deepened mechanistic understanding of how these microenvironmental signals influence tissue regeneration has drawn attention to the critical importance of the clinical field with foundations in the application of physical, thermal, and electrical stimuli to promote functional restoration—rehabilitation. We propose that the fields of regenerative medicine and rehabilitative science are inextricably intertwined, an intersection of disciplines that we and others have termed Regenerative Rehabilitation. To realize the full potential of Regenerative Rehabilitation, there is a need for formalized mechanisms that promote the interaction of basic scientists with rehabilitation specialists. During the initial funding cycle, the Alliance for Regenerative Rehabilitation Research & Training (AR3T) built a national network of investigators and programs that has helped to expand scientific knowledge, expertise and methodologies across the domains of regenerative medicine and rehabilitation. This proposal seeks funding for AR3T 2.0, in which we will build on successes achieved and lessons learned over the initial period of support with the goal of being even more responsive to the needs of the greater community. Six specific aims define a framework upon which we will achieve our goals. AR3T will provide education and drive the science underlying Regenerative Rehabilitation by: 1) Providing didactic programs that expose rehabilitation researchers to cutting-edge investigations and state-of-the-art technologies in the field of regenerative medicine (Didactic Aim); 2) Cultivating collaborative opportunities between renowned investigators in the fields of regenerative medicine and rehabilitation (Collaborations Aim); 3) Coordinating a pilot funding program to support novel lines of Regenerative Rehabilitation research (Pilot Funding Aim); 4) Developing and validating technologies to advance the measurement and use of the regenerative rehabilitation programs (Technology Aim); 5) Promoting our center’s expertise to a broad community of trainees, investigators, and clinicians (Promotion Aim); 6) Carefully monitoring and evaluating the effectiveness of our program will ensure that we are successful in achieving our goals (Quality Control Aim). Administrative note: In the preparation of this proposal, we made every effort to present a comprehensive and detailed plan for achieving our goals while minimizing redundancy. Therefore, in multiple places, we refer the reader to specific components of the application, rather than repeating text. We appreciate the time and effort the reviewers devote to the evaluation of the proposals.  Sincerely, Fabrisia, Tom and Mike PROJECT NARRATIVE  Regenerative Rehabilitation is the integration of principles and approaches across the fields of rehabilitation science and regenerative medicine. The integration of these two fields will increase the efficiency of interventions designed to optimize physical functioning to the benefit of a wide range of individuals with disabilities. The Alliance for Regenerative Rehabilitation Research & Training (AR3T) 2.0 will build on the momentum gained over the first cycle of funding with the goal of continuing to illuminate and seize opportunities to expand scientific knowledge, expertise and methodologies in the domain of Regenerative Rehabilitation.",Alliance for Regenerative Rehabilitation Research & Training 2.0 (AR3T 2.0),10210417,P2CHD086843,"['Accountability', 'Activities of Daily Living', 'Age', 'Attention', 'Awareness', 'Basic Science', 'Biocompatible Materials', 'Clinical', 'Collaborations', 'Communities', 'Congenital Abnormality', 'Country', 'Data Analyses', 'Development', 'Disabled Persons', 'Discipline', 'Disease', 'Documentation', 'Education', 'Effectiveness', 'Ensure', 'Evaluation', 'Feedback', 'Fostering', 'Foundations', 'Funding', 'Future', 'Goals', 'In Vitro', 'Incubators', 'Individual', 'Injury', 'Intervention', 'Investigation', 'Journals', 'Knowledge', 'Laboratories', 'Machine Learning', 'Marketing', 'Measurement', 'Mechanics', 'Mentors', 'Methodology', 'Methods', 'Mission', 'Monitor', 'Natural regeneration', 'Organ', 'Performance', 'Physical Function', 'Pre-Clinical Model', 'Preparation', 'Process', 'Quality Control', 'Reader', 'Regenerative Medicine', 'Rehabilitation therapy', 'Research', 'Research Design', 'Research Personnel', 'Research Training', 'Resources', 'Science', 'Scientist', 'Series', 'Signal Transduction', 'Specialist', 'Stimulus', 'Structure', 'Systems Analysis', 'Technology', 'Text', 'Time', 'Tissues', 'Training', 'Trauma', 'Treatment Efficacy', 'Update', 'career', 'effectiveness evaluation', 'falls', 'functional restoration', 'gait examination', 'healing', 'injured', 'innovation', 'interest', 'investigator training', 'multidisciplinary', 'new technology', 'novel', 'novel strategies', 'pre-clinical', 'programs', 'regenerative', 'regenerative rehabilitation', 'regenerative therapy', 'rehabilitation research', 'rehabilitation science', 'repaired', 'response', 'sabbatical', 'social media', 'success', 'symposium', 'technological innovation', 'therapy design', 'tissue regeneration', 'webinar']",NICHD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,P2C,2021,983634
"The chondrocranium in craniofacial development and disease Most investigations of craniosynostosis focus on the dermatocranium, the second cranial skeleton to form during embryogenesis that comprises the dermal bones of the cranial vault and facial skeleton. A completely separate cranial skeleton, the chondrocranium, develops before the dermatocranium to support the embryonic brain and other sense organs. Historically, the chondrocranium has been studied across the vertebrates and is recognized as fundamental to craniofacial development, but it is not well known to craniofacial biologists and has never been studied in the laboratory mouse until now. The chondrocranium is formed of cartilage and though parts of it ossify endochondrally, other portions begin to degenerate by about embryonic day 15-16 in the mouse. By careful analysis of whole mount and histological specimens, we have documented the synchronized deterioration of select chondrocranial elements with the appearance and superimposition of particular dermal bones of the growing dermatocranium. These observations signal the existence of a mechanism for the coordinated, localized expansion (dermal bones) and resorption (cartilage) of two developmentally and evolutionarily separate skeletal systems. Our project, supported by strong preliminary data of the mouse chondrocranium, is designed to test a central hypothesis: that the chondrocranium serves as a structural and functional scaffold for the later development of dermatocranial elements including the formation of cranial vault sutures. Based on the common finding that boundaries between different cell populations often serve as tissue organizers, we recognize the establishment and maintenance of stable boundaries that restrict the mixing of different cell populations as critical to proper development, and propose a research design that interrogates the chondrocranial/dermatocranial boundary as significant to the coordinated development of the skull. We will interrogate cells at specific sites to determine the processes that function to maintain the boundaries. Then using the Fgfr2c+/C342Y mouse model for craniosynostosis, we will investigate relevant chondrocranial/dermatocranial boundaries operative in the development of two craniosynostosis phenotypes: premature closure of the coronal suture and abnormal growth of the midface. That the chondrocranium is composed of irregularly shaped cartilages, many of which are short-lived, requires that we conceive new tools for analysis. We will complete development of an innovative system to dissect and reconstruct the chondrocranium in silico from micro computed tomography images with tight temporal control, precisely delineate chondrocranial anatomy in 3D over embryonic time, and establish the role of the chondrocranium in development of the dermatocranium. Achieving our goals will enrich textbook knowledge of craniofacial development by defining the role of the chondrocranium in the production of dermatocranial phenotypes, provide information relative to the pathophysiology of countless craniofacial anomalies, and reveal potential avenues for the development of novel therapeutics. Craniofacial anomalies are common birth defects that require comprehensive, sometimes repetitive corrective surgeries to manage individual cases. To ameliorate the financial and emotional burden on patients and their families, efforts are aimed at the development of preventative therapies but these require a thorough understanding of craniofacial development. We offer novel information about the chondrocranium, the first embryonic cranial skeleton to develop, and focus on mechanisms operating within boundaries between it and the dermatocranium that are critical to craniofacial development, in normal individuals and in craniofacial disease.",The chondrocranium in craniofacial development and disease,10087916,R01DE027677,"['3-Dimensional', 'Acids', 'Affect', 'Age', 'Anatomy', 'Apert-Crouzon syndrome', 'Apoptosis', 'Appearance', 'Awareness', 'Birth', 'Bone Resorption', 'Brain', 'Cartilage', 'Cell Lineage', 'Cell physiology', 'Cells', 'Cephalic', 'Chondrichthyes', 'Chondrocranium', 'Complex', 'Congenital Abnormality', 'Craniofacial Abnormalities', 'Craniosynostosis', 'Data', 'Dermal', 'Deterioration', 'Development', 'Discipline', 'Disease', 'Elements', 'Embryo', 'Embryonic Development', 'Embryonic Structures', 'Emotional', 'Ethnic group', 'Event', 'Face', 'Family', 'Functional disorder', 'Gene Expression', 'Goals', 'Graph', 'Growth', 'Image', 'Incidence', 'Individual', 'Investigation', 'Knowledge', 'Laboratories', 'Laboratory mice', 'Live Birth', 'Maintenance', 'Modernization', 'Morphology', 'Mus', 'Mutation', 'Nature', 'Operative Surgical Procedures', 'Osteoblasts', 'Pathway interactions', 'Patients', 'Phenotype', 'Play', 'Population', 'Preventive therapy', 'Procedures', 'Process', 'Production', 'Protocols documentation', 'Regulation', 'Reproducibility', 'Research', 'Research Design', 'Role', 'Sense Organs', 'Signal Transduction', 'Site', 'Skeletal system', 'Skeleton', 'Staging System', 'Stains', 'Structure', 'Surgical sutures', 'System', 'Techniques', 'Technology', 'Testing', 'Textbooks', 'Time', 'Tissues', 'Transgenic Mice', 'Vertebrates', 'base', 'bone', 'cleft lip and palate', 'coronal suture', 'craniofacial', 'craniofacial development', 'cranium', 'deep learning', 'design', 'fibroblast growth factor receptor 2c', 'histological specimens', 'imaging Segmentation', 'in silico', 'innovation', 'microCT', 'molecular marker', 'mouse model', 'novel', 'novel therapeutics', 'osteogenic', 'premature', 'reconstruction', 'scaffold', 'sex', 'spatiotemporal', 'three-dimensional modeling', 'tool']",NIDCR,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R01,2021,495785
"Research Resource for Complex Physiologic Signals PhysioNet, established in 1999 as the NIH-sponsored Research Resource for Complex Physiologic Signals, has attained a preeminent status among biomedical data and software resources. Its data archive was the first, and remains the world's largest, most comprehensive and widely used repository of time-varying physiologic signals. Its software collection supports exploration and quantitative analyses of its own and other databases by providing a wide range of well-documented, rigorously tested open-source programs that can be run on any platform. PhysioNet's team of researchers drive the creation and enrichment of: i) Data collections that provide comprehensive, multifaceted views of pathophysiology over long time intervals, such as the MIMIC (Medical Information Mart for Intensive Care) Databases of critical care patients; ii) Analytic methods for quantification of information encoded in physiologic signals relevant to risk stratification and health status assessment; iii) User interfaces, reference materials and services that add value and improve access to the resource’s data and software; and iv) unique annual Challenges focusing on high priority clinical problems, such as early prediction of sepsis, detection and quantification of sleep apnea syndromes from a single lead electrocardiogram (ECG), false alarm detection in the intensive care unit (ICU), continuous fetal ECG monitoring, and paroxysmal atrial fibrillation detection and prediction. PhysioNet is a proven enabler and accelerator of innovative research by investigators with a diverse range of interests, working on projects made possible by data that are otherwise inaccessible. The creation and development of PhysioNet were recognized with the 2016 highest honor of the Association for the Advancement of Medical Instrumentation (AAMI). PhysioNet's world-wide, growing community of researchers, clinicians, educators, trainees, and medical instrument and software developers retrieve about 380 GB of data per day and publish a yearly average of nearly 300 new scholarly articles. Over the next five years we aim to: 1) Enhance PhysioNet’s impact with new data and technology; 2) Develop new methods to quantify dynamical information in physiologic signals relevant for health status assessment, and for acute and chronic risk stratification, and 3) Harness the research community through our international Challenges that address key clinical problems and a new data annotation initiative. PhysioNet, the Research Resource for Complex Physiological Signals, maintains the world's largest, most comprehensive and most widely used repository of physiological data and data analysis software, making them freely available to the research community. PhysioNet is a proven enabler and accelerator of innovative biomedical research through its unique role in providing data and other resources that otherwise would be inaccessible.",Research Resource for Complex Physiologic Signals,10225620,R01EB030362,"['Acute', 'Address', 'Adult', 'Area', 'Arrhythmia', 'Atrial Fibrillation', 'Biological Markers', 'Biomedical Research', 'Cardiovascular system', 'Chronic', 'Clinical', 'Clinical Data', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computerized Medical Record', 'Coupling', 'Critical Care', 'Data', 'Data Analyses', 'Data Collection', 'Data Set', 'Databases', 'Detection', 'Development', 'Doctor of Philosophy', 'Documentation', 'Educational Background', 'Electrocardiogram', 'Entropy', 'Functional disorder', 'Funding', 'Future', 'Goals', 'Growth', 'Health Status', 'Heart failure', 'Image', 'Improve Access', 'Intensive Care', 'Intensive Care Units', 'International', 'Label', 'Lead', 'Legal patent', 'Life', 'Link', 'Machine Learning', 'Measures', 'Medical', 'Methods', 'Monitor', 'Neonatal', 'Operative Surgical Procedures', 'Outcome', 'Pathologic', 'Patient Care', 'Physiological', 'Publishing', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Running', 'Sepsis', 'Services', 'Signal Transduction', 'Sleep Apnea Syndromes', 'Source Code', 'Stroke', 'Students', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Time Series Analysis', 'United States National Institutes of Health', 'Visualization', 'Visualization software', 'Work', 'analytical method', 'base', 'clinical care', 'cloud based', 'data archive', 'data exploration', 'data resource', 'fetal', 'graphical user interface', 'high school', 'innovation', 'instrument', 'instrumentation', 'interest', 'open source', 'opioid use', 'programs', 'repository', 'response', 'risk stratification', 'time interval', 'tool']",NIBIB,BETH ISRAEL DEACONESS MEDICAL CENTER,R01,2021,707970
"Mechanisms of mechano-chemical rupture of blood clots and thrombi Mechanisms of mechano-chemical rupture of blood clots and thrombi Prashant K. Purohit, John L. Bassani, Valeri Barsegov and John W. Weisel The goal of this proposal is to explore and understand the fracture toughness of blood clots and thrombi, thus providing a mechanistic basis for life-threatening thrombotic embolization. A combination of experiments, theoretical modeling and computer simulations will reveal how mechanical stresses (due to blood flow) in synergy with enzymatic lysis induce structural damage from the molecular to continuum scales and affect the propensity of a clot to embolize. The specific aims of this proposal are: (1) Measure and model fracture toughness of fibrin gels in quasi-static conditions, (2) Investigate rate dependent dissipative effects on toughness of fibrin gels, and (3) Study the effects of blood cells, prothrombotic blood composition, and fibrinolysis on rupture of blood clots. In Specific Aim (SA) 1, we will measure toughness of fibrin clots and provide a structural basis for rupture at the micron and nanometer scales. In SA2, we will delve into the thermodynamics and rate-dependence of the fracture of fibrin gels, including fluid flow through pores and fluid drag on fibrin fibers to capture how energy dissipation increases toughness. In the translational SA3, we will investigate toughness of physiologically relevant clots with effects of platelets, red blood cells, and neutrophils in the absence and presence of the physiological fibrinolytic activator (tPA). We will also study the rupture of clots made from the blood of venous thromboembolism patients to explore the effects of (pro)thrombotic alterations of blood composition on clot mechanical stability. Our preliminary studies show that i) the toughness of cross-linked fibrin gels is in the range of those for synthetic hydrogels, ii) the addition of tPA to a crack tip reduces the loads for crack growth, iii) fibers are aligned and broken along the tensile direction at the crack tip, and iv) crack propagation results from the rupture of covalent and non-covalent bonds. We also developed v) dynamic force spectroscopy in silico to mechanically test fibrin fibers and fibrin networks using pulling simulations and vi) atomic stress approach to map the stress-strain fields using the output from simulations. We will use continuum and finite element models of swellable biopolymer hydrogels, and statistical mechanical models for the forced unfolding of fibrin molecules. We will employ multiscale computational modeling based on Molecular Dynamics simulations of atomic structures of fibrin fibers, and Langevin simulations of fibrin networks accelerated on Graphics Processing Units. The proposed experiments cover the whole gamut of macroscopic tensile tests, shear rheometry, electron microscopy and confocal microscopy to visualize and quantitate the structural alterations of ruptured blood clots. Our experiments and modeling will help us to understand the mechanisms of thrombotic embolization and will address the clinically important question: why is there a strong association between clot structure/mechanical properties and cardiovascular diseases? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering. Project Narrative The research objective of this proposal is to measure, model and predict the mechanisms of mechano-chemical rupture of blood clots and thrombi at the molecular and continuum length scales. Our experiments and modeling will help to understand the mechanisms of embolization and will address the clinically important question: why is there a strong correlation between clot structure/mechanical properties and cardiovascular disease? The new knowledge will also help to design new hydrogel-based biomaterials that are currently at the forefront of research in mechanics, materials science and bioengineering.",Mechanisms of mechano-chemical rupture of blood clots and thrombi,10165811,R01HL148227,"['Address', 'Affect', 'Biocompatible Materials', 'Biological', 'Biomedical Engineering', 'Biopolymers', 'Blood', 'Blood Cells', 'Blood Platelets', 'Blood coagulation', 'Blood flow', 'Cardiovascular Diseases', 'Cause of Death', 'Chemicals', 'Clinical', 'Clinical Medicine', 'Coagulation Process', 'Complex', 'Computer Models', 'Computer Simulation', 'Confocal Microscopy', 'Cytolysis', 'Dependence', 'Diagnosis', 'Disease', 'Electron Microscopy', 'Elements', 'Enzymes', 'Erythrocytes', 'Evolution', 'Fiber', 'Fibrin', 'Fibrinogen', 'Fibrinolysis', 'Fracture', 'Frustration', 'Gel', 'Glean', 'Goals', 'Growth', 'Hydrogels', 'Knowledge', 'Laws', 'Length', 'Life', 'Link', 'Liquid substance', 'Machine Learning', 'Maps', 'Measurement', 'Measures', 'Mechanical Stress', 'Mechanics', 'Methodology', 'Modeling', 'Molecular', 'Molecular Structure', 'Output', 'Patients', 'Physicians', 'Physiological', 'Plasma', 'Predisposition', 'Prevention', 'Process', 'Property', 'Prophylactic treatment', 'Proteins', 'Research', 'Research Proposals', 'Resistance', 'Resources', 'Rupture', 'Specimen', 'Spectrum Analysis', 'Stress', 'Structural Models', 'Structural defect', 'Structure', 'Testing', 'Theoretical Studies', 'Theoretical model', 'Therapeutic Embolization', 'Thermodynamics', 'Thick', 'Thrombin', 'Thromboembolism', 'Thrombosis', 'Thrombus', 'Traction', 'Work', 'base', 'crosslink', 'density', 'design', 'disability', 'experimental study', 'fiber cell', 'fluid flow', 'in silico', 'in vivo', 'insight', 'instrumentation', 'interdisciplinary approach', 'materials science', 'mechanical properties', 'models and simulation', 'molecular dynamics', 'molecular scale', 'multi-scale modeling', 'nanoscale', 'neutrophil', 'novel strategies', 'predictive modeling', 'prevent', 'response', 'simulation', 'synergism', 'theories', 'thrombotic', 'tool', 'venous thromboembolism', 'viscoelasticity']",NHLBI,UNIVERSITY OF PENNSYLVANIA,R01,2021,639595
"Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND) Project Summary/Abstract  This Phase III (P-III) COBRE project will extend the cores that have been successfully leveraged in our Phase I (P-I) and Phase II (P-II) COBRE projects and sustain these unique resources in New Mexico through the im- plementation of a business plan. Over the past eight years we have built up infrastructure and created a cutting edge brain imaging center, our P-II project is just over half-way through and is even more successful than our P- I was at this point in time. The Mind Research Network (MRN) houses an Elekta Neuromag 306-channel MEG System, a high density EEG lab, a 3T Siemens Trio MRI scanner, and a mobile 1.5T Siemens Avanto MRI scanner. Additional resources include a centralized neuroinformatics system, a strong IT management plan, and state-of-the-art image analysis expertise and tools. This P-III COBRE center will continue our momentum and move the cores we have developed into a position of long term sustainability. We will continue with the technical cores established during the P-II project including multimodal data acquisition (MDA), algorithm and data analy- sis (ADA), and biostatistics and neuro-informatics (BNI). These cores have begun to serve MRN and the greater community, as well as other institutions including extensive collaborations with IDeA funded projects in New Mexico and other states. We believe this P-III COBRE is extremely well-positioned to establish and sustain New Mexico as one of the premier brain imaging sites. We include an extensive pilot project program (PPP) that is built on the successful pilot programs implemented as part of the earlier COBRE phases. This includes an ex- tensive educational, mentoring, and faculty development program to carefully mentor and position faculty who use the cores to maximize their potential to successfully compete for external funding, thus fulfilling the ultimate goals of the COBRE program. 2 Narrative  This Phase III COBRE project is a natural extension of our Phase I and II COBRE projects which were cen- tered on mentoring individual researchers along with building the necessary infrastructure to support multimodal neuroimaging in mental illness. During this time, cutting-edge cores were developed that facilitated not only our local projects but also research at multiple institutions across New Mexico; the cores served as neuroimaging facilities and training centers for others to utilize. The Phase III project will ensure the sustainability of these cores as they transition to being fully funded by a broad cadre of users with various funding sources. We propose three technical cores including a multimodal data acquisition (MDA) core, an algorithm and data analysis (ADA) core, and a biostatistics and neuro-informatics (BNI) core. These cores have already shown their utility and have begun to be leveraged by users outside the COBRE. In addition, we propose a robust pilot project program (PPP) to continue to seed and enable new users of the cores to ultimately grow and sustain world class brain imaging research within our IDeA state, thus fulfilling the ultimate goals of the COBRE program. 1",Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND),10372242,P30GM122734,"['Algorithmic Analysis', 'Appointment', 'Area', 'Awareness', 'Biology', 'Biometry', 'Bipolar Depression', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Businesses', 'Centers of Research Excellence', 'Chemistry', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Core Facility', 'Data', 'Data Analyses', 'Department of Energy', 'Development', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Genetic', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Leadership', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Magnetoencephalography', 'Major Depressive Disorder', 'Mental Depression', 'Mental disorders', 'Mentors', 'Methods', 'Mind-Body Method', 'Mission', 'Multimodal Imaging', 'Neurobiology', 'Neurologic', 'Neurosciences', 'New Mexico', 'Paper', 'Patients', 'Peer Review', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Program Development', 'Psychiatry', 'Publications', 'Recording of previous events', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Role', 'Schizophrenia', 'Seeds', 'Site', 'Structure', 'System', 'Teacher Professional Development', 'Time', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Vision', 'base', 'cohesion', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'deep learning', 'density', 'design', 'distinguished professor', 'improved', 'independent component analysis', 'meetings', 'multimodal data', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'neuropsychiatric disorder', 'programs', 'tool']",NIGMS,LOVELACE BIOMEDICAL RESEARCH INSTITUTE,P30,2021,373857
"Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND) Project Summary/Abstract  This Phase III (P-III) COBRE project will extend the cores that have been successfully leveraged in our Phase I (P-I) and Phase II (P-II) COBRE projects and sustain these unique resources in New Mexico through the im- plementation of a business plan. Over the past eight years we have built up infrastructure and created a cutting edge brain imaging center, our P-II project is just over half-way through and is even more successful than our P- I was at this point in time. The Mind Research Network (MRN) houses an Elekta Neuromag 306-channel MEG System, a high density EEG lab, a 3T Siemens Trio MRI scanner, and a mobile 1.5T Siemens Avanto MRI scanner. Additional resources include a centralized neuroinformatics system, a strong IT management plan, and state-of-the-art image analysis expertise and tools. This P-III COBRE center will continue our momentum and move the cores we have developed into a position of long term sustainability. We will continue with the technical cores established during the P-II project including multimodal data acquisition (MDA), algorithm and data analy- sis (ADA), and biostatistics and neuro-informatics (BNI). These cores have begun to serve MRN and the greater community, as well as other institutions including extensive collaborations with IDeA funded projects in New Mexico and other states. We believe this P-III COBRE is extremely well-positioned to establish and sustain New Mexico as one of the premier brain imaging sites. We include an extensive pilot project program (PPP) that is built on the successful pilot programs implemented as part of the earlier COBRE phases. This includes an ex- tensive educational, mentoring, and faculty development program to carefully mentor and position faculty who use the cores to maximize their potential to successfully compete for external funding, thus fulfilling the ultimate goals of the COBRE program. 2 Narrative  This Phase III COBRE project is a natural extension of our Phase I and II COBRE projects which were cen- tered on mentoring individual researchers along with building the necessary infrastructure to support multimodal neuroimaging in mental illness. During this time, cutting-edge cores were developed that facilitated not only our local projects but also research at multiple institutions across New Mexico; the cores served as neuroimaging facilities and training centers for others to utilize. The Phase III project will ensure the sustainability of these cores as they transition to being fully funded by a broad cadre of users with various funding sources. We propose three technical cores including a multimodal data acquisition (MDA) core, an algorithm and data analysis (ADA) core, and a biostatistics and neuro-informatics (BNI) core. These cores have already shown their utility and have begun to be leveraged by users outside the COBRE. In addition, we propose a robust pilot project program (PPP) to continue to seed and enable new users of the cores to ultimately grow and sustain world class brain imaging research within our IDeA state, thus fulfilling the ultimate goals of the COBRE program. 1",Phase III COBRE:  Multimodal Imaging of Neuropsychiatric Disorders (MIND),10173820,P30GM122734,"['Algorithmic Analysis', 'Appointment', 'Area', 'Awareness', 'Biology', 'Biometry', 'Bipolar Depression', 'Bipolar Disorder', 'Brain', 'Brain Diseases', 'Brain imaging', 'Businesses', 'Centers of Research Excellence', 'Chemistry', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Computers', 'Core Facility', 'Data', 'Data Analyses', 'Department of Energy', 'Development', 'Devices', 'Diffusion Magnetic Resonance Imaging', 'Dimensions', 'Disease', 'Electroencephalography', 'Engineering', 'Ensure', 'Environment', 'Equipment', 'Faculty', 'Functional Magnetic Resonance Imaging', 'Funding', 'Funding Agency', 'Genetic', 'Goals', 'Grant', 'Image', 'Image Analysis', 'Imaging technology', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Leadership', 'Magnetic Resonance Imaging', 'Magnetic Resonance Spectroscopy', 'Magnetoencephalography', 'Major Depressive Disorder', 'Mental Depression', 'Mental disorders', 'Mentors', 'Methods', 'Mind-Body Method', 'Mission', 'Multimodal Imaging', 'Neurobiology', 'Neurologic', 'Neurosciences', 'New Mexico', 'Paper', 'Patients', 'Peer Review', 'Phase', 'Pilot Projects', 'Positioning Attribute', 'Principal Investigator', 'Program Development', 'Psychiatry', 'Publications', 'Recording of previous events', 'Research', 'Research Domain Criteria', 'Research Personnel', 'Research Project Grants', 'Research Training', 'Resources', 'Role', 'Schizophrenia', 'Seeds', 'Site', 'Structure', 'System', 'Teacher Professional Development', 'Time', 'Training', 'Training Programs', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Vision', 'base', 'cohesion', 'computer science', 'computerized data processing', 'data acquisition', 'data management', 'deep learning', 'density', 'design', 'distinguished professor', 'improved', 'independent component analysis', 'meetings', 'multimodal data', 'multimodality', 'neuroimaging', 'neuroinformatics', 'neuromechanism', 'neuropsychiatric disorder', 'programs', 'tool']",NIGMS,LOVELACE BIOMEDICAL RESEARCH INSTITUTE,P30,2021,1318547
"Novel Glucose Responsive Insulin for Improved Treatment of Diabetes SUMMARY/ABSTRACT. Diabetes is rapidly becoming a global health crisis. Depending on the type of statistical methodology used, the world-wide incidence of the most common type of diabetes, adult-onset or Type II, is estimated to be in the range of 285 million. In both Type I and Type II diabetics glycemic control is paramount as the inability to maintain glycemic control results in several secondary complications including neuropathy, nephropathy and retinopathy, that often lead to amputations, dialysis and blindness as well as increased risk of cardiovascular complications. For the majority of diabetics glycemic control requires constant vigilance and monitoring of blood glucose levels. The overarching goal of this project is the development of a novel glucose responsive insulin (GRI) with a reversible, glucose dependent response at the insulin receptor. The full realization of the GRI concept would most closely mimic the benefits of a healthy pancreas and maintain euglycemia, reduce/eliminate the need for constant monitoring, and ultimately, reduce/eliminate the complications of diabetes. The scope of this proposal is the design and testing of a series of analogs that can bind glucose allosterically and demonstrate differential response at the insulin receptor. This will be achieved through completion of three aims. In Aim 1 we will use a novel computational platform to design and produce a series of GRIs with glucose binding affinity in the physiological range. In Aim 2 we will determine the glucose binding affinity of the analogues produced in Aim 1. Finally, in Aim 3 we will measure the insulin receptor (IR) and insulin like growth factor (IGF-R1) affinity of the GRI’s in the presence of glucose at physiological concentrations. Completion of these Aims will result in the identification of several GRI lead candidates with glucose binding in the physiological range and reversible glucose dependent insulin receptor binding and absence of IGF-1R binding. NARRATIVE Diabetes is rapidly becoming a global health crisis. In both Type I and Type II diabetics glycemic control is paramount as the inability to maintain glycemic control results in a number of secondary complications including neuropathy, nephropathy and retinopathy, that often lead to amputations, dialysis and blindness. A reversible glucose responsive insulin (GRI) would represent a significant improvement in diabetes care for both T1D and T2D patients. The success of this project will result in clinical candidates that will ultimately supplant basal and prandial insulins while simultaneously improving glycemic control and reducing hypoglycemic incidences known to increase cardiovascular risk as well as secondary complications.",Novel Glucose Responsive Insulin for Improved Treatment of Diabetes,10250801,R43DK126521,"['Adult', 'Affinity', 'Amputation', 'Binding', 'Binding Sites', 'Biological Assay', 'Blindness', 'Blood Glucose', 'Calorimetry', 'Caring', 'Characteristics', 'Clinical Trials', 'Complications of Diabetes Mellitus', 'Computing Methodologies', 'Coupled', 'Cryoelectron Microscopy', 'Data', 'Development', 'Diabetes Mellitus', 'Dialysis procedure', 'Fructose', 'Glucose', 'Goals', 'Human', 'Hypoglycemia', 'IGF1 gene', 'Incidence', 'Insulin', 'Insulin Infusion Systems', 'Insulin Receptor', 'Insulin-Dependent Diabetes Mellitus', 'Kidney Diseases', 'Lead', 'Legal patent', 'Leucine', 'Ligand Binding', 'Ligands', 'Maintenance', 'Measures', 'Methodology', 'Methods', 'Molecular Conformation', 'Monitor', 'Mutation', 'Neuropathy', 'Non-Insulin-Dependent Diabetes Mellitus', 'Pancreas', 'Patients', 'Phase', 'Physiological', 'Process', 'Production', 'Property', 'Proteins', 'Quantitative Structure-Activity Relationship', 'Rapid screening', 'Retinal Diseases', 'Screening procedure', 'Series', 'Somatomedins', 'System', 'Testing', 'Thermodynamics', 'Time', 'Toxicology', 'Trees', 'Type 2 diabetic', 'Valine', 'Xylose', 'analog', 'base', 'biophysical properties', 'carbene', 'cardiovascular risk factor', 'clinical candidate', 'computational platform', 'computerized tools', 'design', 'diabetic', 'drug candidate', 'euglycemia', 'global health', 'glycemic control', 'healthy volunteer', 'improved', 'in silico', 'in vivo', 'insight', 'insulin Wakayama', 'lead candidate', 'lead series', 'machine learning algorithm', 'milligram', 'novel', 'pharmacokinetics and pharmacodynamics', 'phase 2 study', 'receptor', 'receptor binding', 'response', 'screening', 'small molecule', 'standard of care', 'success', 'type I diabetic', 'vigilance', 'web server']",NIDDK,"AMIDEBIO, LLC",R43,2021,183955
"BandPass: A Remote Monitoring System for Sarcopenia and Functional Decline ABSTRACT Clinical Need: As the US population ages, managing pathologies that largely affect older adults, including sarcopenia (e.g., loss of muscle mass and strength), represents a significant and growing clinical challenge. In addition to increased rates of sarcopenia with age, it is well-accepted that its incidence and impact increases after acute illness, placing persons at additional risk for functional decline, institutionalization, or death. Resistance-based exercises promote muscle regeneration and strength, and are an advised therapy for such patients. Yet, exercises are normally conducted either under direct clinical oversight, or unsupervised by patients at home, where compliance rates are low. Limitations: Current regimens rely on self-report diaries or verbal reports that may be inaccurate and subject to recall bias. Remote monitoring systems that measure, track, analyze, and provide patient-oriented feedback may overcome these limitations and enhance exercise regimen engagement. An at-home device that monitors and transmits exercise data to the user and clinician represents a potential solution to this clinical challenge. Our Product – BandPass is a remote-sensing, bluetooth-enabled resistance exercise band that will accurately gauge force through a potentiometric sensor rigidly fixed to elastic-tubing purposely designed for resistance training. The device is similar to currently available exercise bands familiar to clinicians and patients, with the significant novel addition of integrated force monitoring and internet-connectivity. A mobile app and cloud-based platform will provide computational resources for data visualization, storage and analysis, which will enable direct patient feedback, clinical monitoring of patient compliance and progress, and serve as a platform for more advanced operations such as automatic exercise-type classification to ease user burden (e.g., minimizing required interactions between the user and mobile device). We hypothesize that BandPass will provide clinically relevant data on compliance and use of exercise training with feedback that will be personalized. Specific Objectives: We specifically propose to design custom electronics and housing for BandPass and to perform in-lab validation studies of device accuracy, precision, and long-term stability. BandPass will be interfaced to a mobile app and cloud-based platform we will implement for data transmission, storage, and analysis. Finally, we will deploy BandPass in a human subjects pilot study to demonstrate usability and system stability in an at-home setting. Future Directions: SynchroHealth is a small company developing an mHealth platform that uses internet-connected devices to help improve quality of life in older adults. This device will complement our existing efforts. By the end of this Phase 1 effort, we will have demonstrated that BandPass is functional in a human population and we will have provided evidence that this approach can be deployed effectively in an at-home setting. This will position us for Phase 2 funding focused on optimizing our device for manufacturing, developing and optimizing a full suite of cloud-based analysis tools and mobile applications, conducting clinical trials aimed at demonstrating efficacy, and preparing to register this as a 510(k)-exempt device for marketing purposes and establishing Current Good Manufacturing Practices (CGMP). PROJECT NARRATIVE Clinical care for older adults that suffer from sarcopenia (e.g. loss of muscle mass and strength) typically involves the use of physical therapy regimens that rely on patients performing a series of at-home resistance-based exercises in order to retain or build muscle strength and prevent further atrophy. Resistance exercises using elastic bands has been a primary tool for clinicians, however remotely monitoring a patient’s compliance, confirming the quality of exercises performed, and tracking performance has been a significant challenge, with no tools currently available to provide this level of insight. Here, we propose to develop BandPass, an internet-enable resistance exercise band instrumented to automatically sense forces generated during exercise which will enable remote monitoring, compliance checking, and exercise classification and help to overcome the current shortcomings in clinical management of these patients.",BandPass: A Remote Monitoring System for Sarcopenia and Functional Decline,10152884,R41AG071290,"['Acute', 'Adult', 'Affect', 'Age', 'Algorithms', 'Android', 'Atrophic', 'Bluetooth', 'Boston', 'Businesses', 'Capital', 'Cessation of life', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Research', 'Cloud Computing', 'Cloud Service', 'Communities', 'Complement', 'Computer software', 'Conduct Clinical Trials', 'Custom', 'Data', 'Devices', 'Disease', 'Drops', 'Elderly', 'Electronics', 'Equipment', 'Exercise', 'Faculty', 'Feedback', 'Funding', 'Future', 'Health', 'Home environment', 'Housing', 'Human', 'Incidence', 'Infrastructure', 'Injury', 'Inpatients', 'Institutionalization', 'Internet', 'Interview', 'Legal patent', 'Machine Learning', 'Marketing', 'Measurement', 'Measures', 'Monitor', 'Muscular Atrophy', 'Non-Invasive Cancer Detection', 'Orthopedics', 'Participant', 'Pathology', 'Patient Care', 'Patient Monitoring', 'Patient Self-Report', 'Patients', 'Performance', 'Persons', 'Phase', 'Physical Function', 'Physical therapy', 'Pilot Projects', 'Population', 'Positioning Attribute', 'Procedures', 'Process', 'Quality of life', 'Recovery', 'Regimen', 'Reporting', 'Resistance', 'Resolution', 'Risk', 'Sampling', 'Self-Help Devices', 'Series', 'Services', 'Small Business Technology Transfer Research', 'Students', 'Surveys', 'Syndrome', 'System', 'Technology', 'Testing', 'Time', 'Validation', 'Wireless Technology', 'acceptability and feasibility', 'age-related muscle loss', 'base', 'clinical care', 'clinical development', 'clinically relevant', 'cloud based', 'commercialization', 'compliance behavior', 'computerized data processing', 'computing resources', 'cost', 'data exchange', 'data visualization', 'design', 'diaries', 'exercise regimen', 'exercise training', 'functional decline', 'handheld mobile device', 'human subject', 'improved', 'insight', 'instrument', 'mHealth', 'meetings', 'mobile application', 'monitoring device', 'muscle form', 'muscle regeneration', 'muscle strength', 'novel', 'operation', 'patient oriented', 'prevent', 'remote monitoring', 'remote sensing', 'resistance exercise', 'sarcopenia', 'sensor', 'strength training', 'tool', 'transmission process', 'usability', 'validation studies']",NIA,SYNCHROHEALTH LLC,R41,2021,224700
"HABIT DESIGN: TESTING A NOVEL BEHAVIORAL APPROACH TO CORPORATE WELLNESS IN THE CONTEXT OF METABOLIC SYNDROME Abstract Metabolic syndrome (MetS) is a constellation of risk factors– elevated triglycerides (TG), insufficient high- density lipoprotein cholesterol (HDL-C), elevated blood pressure (BP), elevated fasting blood glucose (FBG), and above-threshold waist circumference (WC)–that is associated with increased cardiovascular disease, type 2 diabetes mellitus, and some forms of cancer. Research suggests that addressing MetS through the workplace could significantly benefit employee health and employer healthcare costs. Habit Design, Inc., has developed an enhanced behavioral health coaching system called Habit Design (HD) that is the first to integrate habit formation, contingency management, and social learning approaches within a smartphone app to support to behavior change in corporate or employee health contexts. In this Fast Track project, we will adapt the HD approach to address MetS. In Phase I, we will 1) refine and extend existing functional prototypes of the HD app to support the latest versions of iOS and Android, 2) conduct usability testing with 8 targeted end users, and 3) prepare standard treatment manuals for the Phase II clinical trial. In Phase II, we will 1) make indicated changes to the HD app based on findings from the Phase I usability test and 2) evaluate the effectiveness of HD coaching compared to standard health coaching in a randomized trial with 424 corporate wellness program participants who have MetS, with follow-up spanning one year. Participants will employees of TriHealth in Cincinnati who have completed a health screening as part of their corporate wellness program and been identified as having at least 3/5 of the following: 1) TG ≥150 mg/dL), 2) HDL-C <40 mg/dL in males and <50 mg/dL in females, 3) BP ≥130/85 mm Hg, 4) FBG ≥100 mg/dl, and 5) WC ≥102 cm in males and ≥80 cm in females.. All participants will be coached to increase physical activity, which will be monitored with a waist-worn FitBit and Fitabase software. Additionally, participants will choose prior to randomization a goal of increasing fruit and vegetable intake or substituting water for sugar-sweetened beverages. Conditions will be stratified by choice of goal and gender. In both conditions coaching will be monitored for fidelity and delivered in 12 weekly in-person 30-minute sessions followed by one 30-minute maintenance session per month for 4 months. The primary outcome will be average daily step count measured over the course of at least one week at baseline, 4 months, 8 months, and 12 months. The secondary outcome will be standard units increase of fruit/vegetable intake or water intake, according to the participant's choice. Tertiary outcomes will consist of FBG, TG, HDL, BP, WC, and body mass index, measured at each time point. Additionally, we will conduct web-based assessment of self-reported physical activity, junk food, and sugar-sweetened beverage consumption; automaticity of exercise and fruit, vegetable, and water consumption; self-efficacy and social support for target behaviors; and health-related quality of life. Ratings of usability and satisfaction and app usage metrics will be examined. Analyses will be intent-to-treat assuming 15% loss to follow-up. Project Narrative/Relevance Metabolic syndrome is a major public health problem that affects over one in three American adults and increases the risk of cardiovascular disease, type 2 diabetes, and some forms of cancer. Habit Design, Inc., has developed an integrated health coaching system that uses a smartphone app to promote healthy behaviors. We will adapt it for metabolic syndrome and evaluate its effectiveness in a corporate health setting.",HABIT DESIGN: TESTING A NOVEL BEHAVIORAL APPROACH TO CORPORATE WELLNESS IN THE CONTEXT OF METABOLIC SYNDROME,10210291,R44HL142328,"['Address', 'Adherence', 'Adult', 'Affect', 'American', 'Android', 'Behavior', 'Behavioral', 'Behavioral Model', 'Blood Glucose', 'Blood Pressure', 'Body mass index', 'Cardiovascular Diseases', 'Central obesity', 'Chronic', 'Companions', 'Computer software', 'Consumption', 'Cues', 'Development', 'Effectiveness', 'Employee', 'Employee Health', 'Environment', 'Exercise', 'Fasting', 'Feedback', 'Female', 'Food', 'Fostering', 'Gender', 'Goals', 'Habits', 'Health', 'Health Care Costs', 'Health behavior', 'High Density Lipoprotein Cholesterol', 'High Density Lipoproteins', 'Hypertension', 'Hypertriglyceridemia', 'Intake', 'Intervention', 'Link', 'Location', 'Machine Learning', 'Maintenance', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Metabolic syndrome', 'Modeling', 'Monitor', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Outcome', 'Participant', 'Patient Self-Report', 'Persons', 'Phase', 'Phase II Clinical Trials', 'Physical activity', 'Psychological reinforcement', 'Psychology', 'Public Health', 'Randomized', 'Randomized Controlled Trials', 'Research', 'Rewards', 'Risk Factors', 'Science', 'Self Efficacy', 'Social support', 'System', 'Telephone', 'Test Result', 'Testing', 'Time', 'Translating', 'Triglycerides', 'Water', 'Water consumption', 'Wellness Program', 'Workplace', 'base', 'behavior change', 'behavioral health', 'cardiovascular disorder risk', 'contingency management', 'crowdsourcing', 'design', 'effectiveness evaluation', 'experience', 'financial incentive', 'fitbit', 'follow-up', 'fruits and vegetables', 'health related quality of life', 'improved', 'innovation', 'male', 'mobile computing', 'novel', 'peer coaching', 'peer support', 'primary outcome', 'programs', 'prototype', 'randomized trial', 'satisfaction', 'screening', 'secondary outcome', 'smartphone Application', 'social learning', 'standard care', 'sugar', 'sweetened beverage', 'usability', 'waist circumference', 'web-based assessment']",NHLBI,"HABIT DESIGN, INC.",R44,2021,725892
"Overall: Eunice Kennedy Shriver Intellectual and Developmental Disabilities Research Center at Vanderbilt Founded in 1965 as one of the original Intellectual and Developmental Disorders Research Centers (IDDRC), the Vanderbilt Kennedy Center (VKC) IDDRC serves as the central nexus across Vanderbilt for interdisciplinary research, communication, and training in intellectual and developmental disabilities (IDD). The VKC IDDRC serves as a trans-institutional institute that brings together over 200 faculty from 38 departments in 10 schools at Vanderbilt. The VKC’s mission to facilitate discoveries that inform best practices to improve the lives of people with IDD and their families. This mission is met by leveraging our outstanding institutional resources and support, partnering with disability communities, and capitalizing on synergistic interactions across the VKC’s federally-designated centers: the VKC IDDRC, a University Center of Excellence in Developmental Disabilities and a Leadership Education in Neurodevelopmental Disabilities program. The IDDRC as the centerpiece of the VKC is the foundational organizing structure that creates a “Center culture” wherein research and discovery permeates the VKC’s broader training and service activities, thus enhancing the translational research goals of the IDDRC. Demonstrable IDDRC success includes 976 investigator- authored publications and robust NIH funding to Vanderbilt to support IDD-related research ($52.6M in FY20). Harnessing and leveraging this trans-institutional strength to focus on unique challenges in IDD, the overarching goal of the next phase of the IDDRC is to develop precision care for IDD by providing infrastructure and scientific leadership to enable rapid translation of basic discoveries into high- impact IDD interventions and treatments. Three global Aims guide the IDDRC’s work. Aim 1 provides core services to enable and disseminate impactful research on individualizing treatments based upon the causes, mechanisms, and contributing co-morbid sequelae of IDD; Aim 2 focuses on incorporating innovative methods and approaches to enhance multidisciplinary IDD research; and Aim 3 proposes to conduct a signature research project to improve the precision use of antipsychotic medication in people with autism. Across these Aims and five Cores supported by the IDDRC (Administrative, Clinical Translational, Translational Neuroscience, Behavioral Phenotyping, and Data Sciences), three themes permeate our work: (1) recruitment of highly-skilled researchers not currently conducting IDD research (non-traditional researchers); (2) inclusion of IDD participants into research studies that currently do not include IDD (non-traditional subjects); and (3) incorporation of novel scientific approaches and methods (non-traditional approaches). Our IDDRC is ideally posed to enable rapid discovery of precision care approaches by supporting 50 investigators leading 70 research projects (15 from NICHD) and, as highlighted by the Signature Research Project, to promote and implement generative, novel, and impactful research directions, thus meeting the NICHD’s vision of applying newly evolved technologies and approaches to rapidly accelerate the prevention and/or amelioration of IDDs. PUBLIC HEALTH RELEVANCE: As a group, intellectual and developmental disabilities, including Down syndrome and autism spectrum disorder, have dramatic effects on affected people’s and their caregiver’s lives. Unfortunately, there remains a lack of understanding about what causes these disabilities and, critically, how to treat them with targeted therapies. The Vanderbilt Kennedy Center’s Intellectual and Developmental Disabilities Research Center serves as the hub for Vanderbilt’s research efforts focusing on improving the lives of people with intellectual and developmental disabilities by understanding the causes of these disorders and developing and testing therapies tailored to each individual’s precise needs.",Overall: Eunice Kennedy Shriver Intellectual and Developmental Disabilities Research Center at Vanderbilt,10229591,P50HD103537,"['Academic Medical Centers', 'Affect', 'Antipsychotic Agents', 'Basic Science', 'Behavioral', 'Biomedical Research', 'Caregivers', 'Caring', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Communication', 'Communities', 'Computerized Medical Record', 'Data', 'Data Science', 'Development', 'Developmental Disabilities', 'Diagnosis', 'Disease', 'Disease model', 'Down Syndrome', 'Education', 'Evaluation', 'Faculty', 'Family', 'Foundations', 'Funding', 'Future', 'Gap Junctions', 'Genotype', 'Goals', 'Image', 'Individual', 'Infrastructure', 'Institutes', 'Intellectual and Developmental Disabilities Research Centers', 'Intellectual functioning disability', 'Interdisciplinary Study', 'Intervention', 'Leadership', 'Longevity', 'Machine Learning', 'Medical Records', 'Methods', 'Mission', 'Modeling', 'National Institute of Child Health and Human Development', 'Neurodevelopmental Disability', 'Obesity', 'Outcome', 'Participant', 'Pharmaceutical Preparations', 'Pharmacogenetics', 'Phase', 'Pilot Projects', 'Policy Research', 'Prevention', 'Problem behavior', 'Publications', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Sampling', 'Schools', 'Series', 'Services', 'Structure', 'Techniques', 'Technology', 'Testing', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Universities', 'Vision', 'Weight Gain', 'Work', 'autism spectrum disorder', 'base', 'behavioral phenotyping', 'clinical translation', 'comorbidity', 'cost effective', 'developmental disease', 'disability', 'drug-induced weight gain', 'experience', 'image processing', 'implementation science', 'improved', 'individualized medicine', 'individuals with autism spectrum disorder', 'innovation', 'large datasets', 'lectures', 'meetings', 'multidisciplinary', 'novel', 'personalized approach', 'personalized care', 'personalized medicine', 'population based', 'pragmatic trial', 'predictive modeling', 'programs', 'public health relevance', 'recruit', 'research study', 'success', 'targeted treatment', 'translational neuroscience', 'trial comparing']",NICHD,VANDERBILT UNIVERSITY MEDICAL CENTER,P50,2021,1364066
"Effective, Reagent-free Detection of the Odor Signature of Covid-19 Infection Using a Nano-Enabled Sensor Array PROJECT SUMMARY COVID-19 presents a public health emergency: There is a critical need for rapid, not reagent intensive, non- invasive testing technologies. This program will lead to the production of a prototype system to diagnose COVID-19 infection using the body odor signature of the disease. Our goal is to maximize societal impact by creating a validated prototype that can be used in a community or workplace setting by minimally trained personnel for low-cost, on-the-spot diagnosis within minutes. The system will be developed in a manner that puts it on a pathway for rapid FDA approval. The Research Aims are: Aim 1. Optimization, assembly, and integration of a prototype system with the ability to odor signature of COVID-19 in samples of body odor. The system will be simple to use, pose essentially zero risk to the operator and the test subject, and report a result within minutes. The production cost at scale will be approximately $9,000 for the complete measurement system, with a per test cost of approximately $0.50. The design and construction of the prototype will be conducted by Novo Engineering, a leading firm with extensive experience in medical device development. Aim 2. Software development. Software for the system from VOC sampling to final diagnostic result will be developed to ensure error-free operation of the device. Our preliminary results suggest that simple linear discriminant analysis (LDA) does an excellent job of classifying VOCs from human body odor as COVID-19 positive or negative (92% sensitivity and 87% specificity). Optimization of the sensor array (Aim 1) and use of richer feature sets in our classifier models will lead to further performance improvements in the prototype system. Aim 3. System Benchmarking and Validation. We will benchmark the full prototype system against a number of VOC mixtures, with and without in vitro skin models. The system will undergo extensive testing against body odor samples from individuals with pathological conditions other than COVID-19 and other sources of potentially confounding VOCs. The prototype will be validated against 1000 samples drawn from the COVID-SAFE program at Penn. The screening will include all members of the Penn community, and represents incredible racial and ethnic diversity as well as a wide variance in age, sex, and gender. Aim 4. Regulatory Approval Plan The plan will be developed under the direction of Sr/Key personnel John Fuson, JD, an attorney at Crowell & Moring LLP and a former Associate Chief Counsel at FDA. Novo Engineering has extensive experience in guiding prototype design in alignment with the requirements for FDA approval. The proposed COVID-19 VOC-based testing device will be regulated by the FDA, likely as a Class I or II medical device. Because there is no clear predicate device to reference in this case, we intend to submit a direct de novo petition to FDA asking the agency to categorize and clear the proposed COVID-19 testing device as Class I or Class II without reference to any predicate. PROJECT NARRATIVE This program addresses the critical unmet need of an effective means to screen for COVID-19 infection, and potentially other novel virus infections, in a community setting based upon the body odor signature of the disease. The program will result in a validated prototype system, with a test time of minutes, a test cost of approximately $0.50, on a path to rapid FDA approval.","Effective, Reagent-free Detection of the Odor Signature of Covid-19 Infection Using a Nano-Enabled Sensor Array",10266403,U18TR003775,"['Address', 'Age', 'Astronomy', 'Benchmarking', 'COVID-19', 'COVID-19 diagnosis', 'COVID-19 screening', 'COVID-19 testing', 'Carbon Nanotubes', 'Centers for Disease Control and Prevention (U.S.)', 'Characteristics', 'Chemicals', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Collection', 'Communities', 'Computer software', 'Computers', 'Counseling', 'DNA', 'Data', 'Data Analyses', 'Detection', 'Development', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Discriminant Analysis', 'Disease', 'Engineering', 'Ensure', 'Florida', 'Future', 'Gender', 'Goals', 'Gold', 'Hand', 'Health', 'Housekeeping', 'Human', 'Human Resources', 'Human body', 'In Vitro', 'Individual', 'Information Sciences', 'International', 'Intuition', 'Laboratories', 'Lawyers', 'Mass Fragmentography', 'Measurement', 'Mechanics', 'Medical Device', 'Methods', 'Modeling', 'Modernization', 'Monitor', 'Nose', 'Occupations', 'Odors', 'Participant', 'Pathologic', 'Pathway interactions', 'Patients', 'Pattern', 'Pennsylvania', 'Performance', 'Phase', 'Physics', 'Production', 'RADx', 'Reagent', 'Reporting', 'Research', 'Risk', 'SARS-CoV-2 infection', 'SARS-CoV-2 negative', 'SARS-CoV-2 positive', 'Sampling', 'Skin', 'Software Engineering', 'Solid', 'Source', 'Specificity', 'Spottings', 'System', 'Systems Development', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Viral', 'Virus Diseases', 'Visual', 'Workplace', 'animal care', 'artificial neural network', 'base', 'community setting', 'coronavirus disease', 'cost', 'design', 'design and construction', 'ethnic diversity', 'experience', 'high standard', 'machine learning algorithm', 'medical schools', 'member', 'multidisciplinary', 'nano', 'nanosensors', 'next generation', 'novel virus', 'operation', 'prevent', 'programs', 'prototype', 'public health emergency', 'racial diversity', 'sample collection', 'screening', 'screening program', 'sensor', 'sex', 'software development', 'software systems', 'vapor', 'volatile organic compound']",NCATS,UNIVERSITY OF PENNSYLVANIA,U18,2021,999830
"Deep learning for population genetics Project Summary The revolution in genome sequencing technologies over the past 15 years has created an explosion of population genomic data but has left in its wake a gap in our ability to make sense of data at this scale. In particular, whereas population genetics as a field has been traditionally data-limited, the massive volume of current sequencing means that previously unanswerable questions may now be within reach. To capitalize on this flood of information we need new methods and modes of analysis.  In the past 5 years the world of machine learning has been revolutionized by the rise of deep neural networks. These so-called deep learning methods offer incredible flexibility as well as astounding improvements in performance for a wide array of machine learning tasks, including computer vision, speech recognition, and natural language processing. This proposal aims to harness the great potential of deep learning for population genetic inference.  In recent years our group has made great strides in using supervised machine learning for population genomic analysis (reviewed in Schrider and Kern 2018). However, this work has focused primarily on using more traditional machine learning methods such as random forests. As we argue in this proposal, DNA sequence data are particularly well suited for modern deep learning techniques, and we demonstrate that the application of these methods can rapidly lead to state-of-the-art performance in very difficult population genetic tasks such as estimating rates of recombination. The power of these methods for handling genetic data stems in part from their ability to automatically learn to extract as much useful information as possible from an alignment of DNA sequences in order to solve the task at hand, rather than relying on one or more predefined summary statistics which are generally problem-specific and may omit information present in the raw data.  In this proposal we lay out a systematic approach for both empowering the field with these tools and understanding their shortcomings. In particular, we propose to design deep neural networks for solving population genetic problems, and incorporate successful networks into user-friendly software tools that will be shared with the community. We will also investigate a variety of methods for estimating the uncertainty of predictions produced by deep learning methods; this area is understudied in machine learning but of great importance to biological researchers who require an accurate measure of the degree of uncertainty surrounding an estimate. Finally, we will explore the impact of training data misspecification—wherein the data used to train a machine learning method differ systematically from the data to which it will be applied in practice. We will devise techniques to mitigate the impact of such misspecification in order to ensure that our tools will be robust to the complications inherent in analyzing real genomic data sets. Together, these advances have the potential to transform the methodological landscape of population genetic inference. Project Narrative Deep learning has revolutionized such disparate fields as computer vision, natural language processing, and speech recognition. In this proposal we aim to harness the great potential of deep learning for population genetic inference. We will design, implement, and apply novel deep learning methods and provide open source software for others to both use and build upon, thereby producing valuable tools for the genetics researchers at large.",Deep learning for population genetics,10147906,R01HG010774,"['Algorithms', 'Area', 'Biological', 'Biology', 'Classification', 'Code', 'Communities', 'Computer Vision Systems', 'Computer software', 'DNA Sequence', 'Data', 'Development', 'Ensure', 'Floods', 'Genetic', 'Genetic Recombination', 'Genome', 'Genomics', 'Genotype', 'Goals', 'Image', 'Lead', 'Learning', 'Left', 'Machine Learning', 'Measures', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Natural Selections', 'Nature', 'Performance', 'Population', 'Population Explosions', 'Population Genetics', 'Process', 'Program Development', 'Publishing', 'Research Personnel', 'Sequence Alignment', 'Software Tools', 'Techniques', 'Technology', 'Training', 'Trees', 'Uncertainty', 'Ursidae Family', 'Work', 'base', 'computational chemistry', 'convolutional neural network', 'deep learning', 'deep neural network', 'design', 'empowered', 'flexibility', 'genetic information', 'genome sequencing', 'genomic data', 'infancy', 'innovation', 'learning classifier', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'network architecture', 'neural network', 'neural network architecture', 'next generation', 'novel', 'open source', 'random forest', 'recurrent neural network', 'research and development', 'speech recognition', 'statistics', 'stem', 'success', 'supervised learning', 'tool', 'tool development', 'user friendly software']",NHGRI,UNIVERSITY OF OREGON,R01,2021,417279
"Integrative Predictors of Temporomandibular Osteoarthritis ABSTRACT This application proposes the development of efficient web-based data management, mining, and analytics, to integrate and analyze clinical, biological, and high dimensional imaging data from TMJ OA patients. Based on our published results, we hypothesize that patterns of condylar bone structure, clinical symptoms, and biological mediators are unrecognized indicators of the severity of progression of TMJ OA. Efficiently capturing, curating, managing, integrating and analyzing this data in a manner that maximizes its value and accessibility is critical for the scientific advances and benefits that such comprehensive TMJ OA patient information may enable. High dimensional databases are increasingly difficult to process using on-hand database management tools or traditional processing applications, creating a continuing demand for innovative approaches. Toward this end, the DCBIA at the Univ. of Michigan has partnered with the University of North Carolina, the University of Texas MD Anderson Cancer Center and Kitware Inc. Through high-dimensional quantitative characterization of individuals with TMJ OA, at molecular, clinical and imaging levels, we will identify phenotypes at risk for more severe prognosis, as well as targets for future therapies. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA. Due to its ubiquitous design in the web, DSCI software installation will no longer be required. Our long-term goal is to create software and data repository for Osteoarthritis of the TMJ. Such repository requires maintaining the data in a distributed computational environment to allow contributions to the database from multi-clinical centers and to share trained models for TMJ classification. In years 4 and 5 of the proposed work, the dissemination and training of clinicians at the Schools of Dentistry at the University of North Carol, Univ. of Minnesota and Oregon Health Sciences will allow expansion of the proposed studies. In Aim 1, we will test state-of-the-art neural network structures to develop a combined software module that will include the most efficient and accurate neural network architecture and advanced statistics to mine imaging, clinical and biological TMJ OA markers identified at baseline. In Aim 2, we propose to develop novel data analytics tools, evaluating the performance of various machine learning and statistical predictive models, including customized- Gaussian Process Regression, extreme boosted trees, Multivariate Varying Coefficient Model, Lasso, Ridge and Elastic net, Random Forest, pdfCluster, decision tree, and support vector machine. Such automated solutions will leverage emerging computing technologies to determine risk indicators for OA progression in longitudinal cohorts of TMJ health and disease. PROJECT NARRATIVE This application proposes the development of efficient web-based data management, mining, and analytics of clinical, biological, and high dimensional imaging data from TMJ OA patients. The proposed web-based system, the Data Storage for Computation and Integration (DSCI), will remotely compute machine learning, image analysis, and advanced statistics from prospectively collected longitudinal data on patients with TMJ OA.",Integrative Predictors of Temporomandibular Osteoarthritis,10165688,R01DE024450,"['3-Dimensional', 'Age', 'Architecture', 'Arthritis', 'Benchmarking', 'Biological', 'Biological Markers', 'Blood', 'Bone remodeling', 'Bone structure', 'Cancer Center', 'Chronic', 'Classification', 'Clinical', 'Clinical Markers', 'Computer Vision Systems', 'Computer software', 'Computer-Assisted Diagnosis', 'Country', 'Custom', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Data Storage and Retrieval', 'Database Management Systems', 'Databases', 'Decision Trees', 'Degenerative polyarthritis', 'Dental', 'Development', 'Diagnosis', 'Disease', 'Early Diagnosis', 'Environment', 'Fibrocartilages', 'Future', 'Gaussian model', 'Goals', 'Hand', 'Health', 'Health Sciences', 'Image', 'Image Analysis', 'Individual', 'Inflammation Mediators', 'Inflammatory', 'Internet', 'Joints', 'Lasso', 'Longitudinal cohort', 'Machine Learning', 'Mandibular Condyle', 'Mediator of activation protein', 'Medicine', 'Methods', 'Michigan', 'Mining', 'Minnesota', 'Modeling', 'Molecular', 'Morphology', 'North Carolina', 'Online Systems', 'Oregon', 'Outcome', 'Pain', 'Paper', 'Patients', 'Pattern', 'Peer Review', 'Performance', 'Phenotype', 'Process', 'Property', 'Proteins', 'Publishing', 'Replacement Arthroplasty', 'Resolution', 'Risk', 'Saliva', 'School Dentistry', 'Scientific Advances and Accomplishments', 'Severities', 'Slice', 'Structure', 'Study models', 'Symptoms', 'System', 'Technology', 'Temporomandibular Joint', 'Temporomandibular joint osteoarthritis', 'Testing', 'Texas', 'Three-Dimensional Imaging', 'Training', 'Trees', 'Universities', 'University of Texas M D Anderson Cancer Center', 'Work', 'X-Ray Computed Tomography', 'analytical tool', 'base', 'bone', 'cadherin 5', 'cartilage degradation', 'clinical center', 'clinical diagnostics', 'cone-beam computed tomography', 'craniofacial', 'craniomaxillofacial', 'data repository', 'deep learning', 'deep neural network', 'design', 'high dimensionality', 'imaging biomarker', 'improved', 'innovation', 'joint destruction', 'machine learning algorithm', 'neural network', 'neural network architecture', 'novel', 'novel strategies', 'open source', 'outcome forecast', 'predictive modeling', 'prospective', 'quantitative imaging', 'random forest', 'repository', 'scale up', 'screening', 'serial imaging', 'software repository', 'statistical and machine learning', 'statistics', 'subchondral bone', 'support vector machine', 'tool']",NIDCR,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,503164
"OpenMM: Scalable biomolecular modeling, simulation, and machine learning PROJECT SUMMARY / ABSTRACT OpenMM [http://openmm.org] is the most widely-used open source GPU-accelerated framework for biomolecular modeling and simulation (>1300 citations, >270,000 downloads, >1M deployed instances). Its Python API makes it widely popular as both an application (for modelers) and a library (for developers), while its C/C++/Fortran bindings enable major legacy simulation packages to use OpenMM to provide high performance on modern hardware. OpenMM has been used for probing biological questions that leverage the $14B global investment in structural data from the PDB at multiple scales, from detailed studies of single disease proteins to superfamily-wide modeling studies and large-scale drug development efforts in industry and academia. Originally developed with NIH funding by the Pande lab at Stanford, we aim to fully transition toward a community governance and sustainable development model and extend its capabilities to ensure OpenMM can power the next decade of biomolecular research. To fully exploit the revolution in QM-level accuracy with machine-learning (ML) potentials, we will add plug-in support for ML models augmented by GPU-accelerated kernels, enabling transformative science with QM-level accuracy. To enable high-productivity development of new ML models with training dataset sizes approaching 100 million molecules, we will develop a Python framework to enable OpenMM to be easily used within modern ML frameworks such as TensorFlow and PyTorch. Together with continued optimizations to exploit inexpensive GPUs, these advances will power a transformation within biomolecular modeling and simulation, much as deep learning has transformed computer vision. PROJECT NARRATIVE Biomolecular modeling and simulation is a key technology for leveraging the $14B global investment in biomolec- ular structure data in the protein databank to understand the basic molecular mechanisms underlying biology and disease and the development of new therapies. In this proposal, we aim to expand the development of OpenMM, a free and open source biomolecular modeling and simulation package that can exploit a wide range of consumer-grade and high-end graphics processing units (GPUs) to enable researchers and applications built on OpenMM to achieve high performance with extreme ﬂexibility. A key aspect of this proposal is to accelerate research in the emerging ﬁeld of biomolecular machine learning by tightly integrating OpenMM with modern ma- chine learning frameworks, enabling researchers to build, use, and deploy machine learning potentials, collective variables, and integrators to advance the state of biomolecular modeling.","OpenMM: Scalable biomolecular modeling, simulation, and machine learning",10100573,R01GM140090,"['Academia', 'Architecture', 'Automobile Driving', 'Binding', 'Biological', 'Biological Process', 'Biological Response Modifier Therapy', 'Biology', 'Chemical Models', 'Chemicals', 'Chemistry', 'Code', 'Communities', 'Computer Vision Systems', 'Custom', 'Data', 'Data Set', 'Development', 'Disease', 'Ecosystem', 'Ensure', 'Event', 'Free Energy', 'Funding', 'Future', 'Goals', 'Home environment', 'Hybrids', 'Industry', 'Investigation', 'Investments', 'Laboratories', 'Learning', 'Libraries', 'Ligands', 'Machine Learning', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Conformation', 'Performance', 'Plug-in', 'Productivity', 'Proteins', 'Pythons', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Science', 'Speed', 'Standardization', 'Structure', 'Study models', 'Sustainable Development', 'System', 'Technology', 'TensorFlow', 'Training', 'United States National Institutes of Health', 'Update', 'Work', 'cluster computing', 'deep learning', 'deep neural network', 'drug development', 'enzyme mechanism', 'flexibility', 'insight', 'interoperability', 'model development', 'models and simulation', 'molecular mechanics', 'next generation', 'novel therapeutics', 'open source', 'operation', 'physical model', 'predictive modeling', 'protein data bank', 'quantum', 'repository', 'simulation', 'small molecule', 'small molecule therapeutics', 'software infrastructure', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2021,426294
"Can machines be trusted? Robustification of deep learning for medical imaging Machine learning algorithms have become increasing popular in medical imaging, where highly functional algorithms have been trained to recognize patterns or features within image data sets and perform clinically relevant tasks such as tumor segmentation and disease diagnosis. In recent years, an approach known as deep learning has revolutionized the field of machine learning, by leveraging massive datasets and immense computing power to extract features from data. Deep learning is ideally suited for problems in medical imaging, and has enjoyed success in diverse tasks such as segmenting cardiac structures, tumors, and tissues. However, research in machine learning has also shown that deep learning is fragile in the sense that carefully designed perturbations to an image can cause the algorithm to fail. These perturbations can be designed to be imperceptible by humans, so that a trained radiologist would not make the same mistakes. As deep learning approaches gain acceptance and move toward clinical implementation, it is therefore crucial to develop a better understanding of the performance of neural networks. Specifically, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms. We posit that malicious perturbations, of the type studied in theoretical machine learning, may not be representative of the sort of noise encountered in medical images. Although noise is inevitable in a physical system, the noise arising from sources such as subject motion, operator error, or instrument malfunction may have less deleterious effects on a deep learning algorithm. We propose to characterize the effect of these perturbations on the performance of deep learning algorithms. Furthermore, we will study the effect of random labeling error introduced into the data set, as might arise due to honest human error. We will also develop new methods for making deep learning algorithms more robust to the types of clinically relevant perturbations described above. In summary, although the susceptibility of neural networks to small errors in the inputs is widely recognized in the deep learning community, our work will investigate these general phenomena in the specific case of medical imaging tasks, and also conduct the first study of average-case errors that could realistically arise in clinical studies. Furthermore, we will produce novel recommendations for how to quantify and improve the resiliency of deep learning approaches in medical imaging. In recent years, an approach known as deep learning has revolutionized the field of machine learning by achieving superhuman performance on many tasks. As deep learning approaches gain acceptance and move toward clinical implementation in assisting radiologists for tasks such as segmentation of cardiac structures, tumors, and tissues, it is critical to understand the limits of deep learning when presented with noisy or imperfect data. The goal of this project is to explore these questions in the context of medical imaging—to better identify strengths, weaknesses, and failure points of deep learning algorithms.",Can machines be trusted? Robustification of deep learning for medical imaging,10208969,R01LM013151,"['Adopted', 'Algorithms', 'Attention', 'Brain', 'Cardiac', 'Classification', 'Clinical', 'Clinical Research', 'Critiques', 'Dangerous Behavior', 'Data', 'Data Set', 'Diagnostic radiologic examination', 'Disease', 'Dose', 'Effectiveness', 'Ensure', 'Exhibits', 'Exposure to', 'Failure', 'Goals', 'Human', 'Image', 'Image Analysis', 'Label', 'Machine Learning', 'Magnetic Resonance Imaging', 'Mathematics', 'Medical Imaging', 'Methods', 'Modeling', 'Morphologic artifacts', 'Motion', 'Noise', 'Output', 'Pattern', 'Performance', 'Physics', 'Positron-Emission Tomography', 'Predisposition', 'Recommendation', 'Research', 'Research Design', 'Research Personnel', 'Scheme', 'Source', 'Structure', 'System', 'Thoracic Radiography', 'Training', 'Trust', 'Tumor Tissue', 'Variant', 'Work', 'X-Ray Computed Tomography', 'base', 'classification algorithm', 'clinical implementation', 'clinically relevant', 'deep learning', 'deep learning algorithm', 'design', 'disease diagnosis', 'human error', 'imaging Segmentation', 'improved', 'instrument', 'learning community', 'loss of function', 'machine learning algorithm', 'neural network', 'novel', 'operation', 'performance tests', 'physical process', 'radiologist', 'reconstruction', 'resilience', 'statistics', 'success', 'tumor']",NLM,UNIVERSITY OF WISCONSIN-MADISON,R01,2021,318876
"Enhancing Assisted Reproductive Technologies with Deep Learning and Data Visualization PROJECT SUMMARY Assisted Reproduction Technology (ART) is a clinical treatment for infertile couples who want to achieve a pregnancy. In ART, embryologists fertilize eggs retrieved from the patient or a donor, culture the resulting embryos in vitro, and then transfer the selected embryo(s) to the mother's uterus. While ART is responsible for 1.9% of babies born in the United States as of 2018, selecting which embryo to transfer is a signiﬁcant challenge. The difﬁculty comes from the complexity of confounding factors and the lack of understanding of human pre-implantation embryo development. Because of this difﬁculty, multiple embryos are often transferred to increases the potential of success, resulting in multiple pregnancy rates of nearly 20%, which can lead to signiﬁcant morbidity and medical expenses to patients. The ideal is to transfer only a single embryo, but this necessitates the ability to select the best embryo from a cohort. Here, we propose to create a clinical decision support system to improve embryo selection in ART. To this end, we will develop novel deep learning models for robust embryo feature extraction and interactive data visualization methods for human-in-the-loop analysis. We will ﬁrst extract and analyze visual features from routinely collected images of embryos. We will then combine these visual features with patients' electronic health record (EHR) data to develop interpretable computation models that score embryos on their viability. We plan to integrate our machine learning solutions into an easily accessible cloud service platform that will be adaptable across clinics to improve ART embryo selection and clinical data analysis. Our research goals will be achieved by novel machine learning-based models for morphological feature extrac- tion and importance estimation of each confounding factor and a clinical decision support system for ART. For morphological feature extraction, we plan to conduct semi-supervised learning of convolutional neural networks to minimize manual labeling that requires extensive human effort. Our feature extraction model will be the ﬁrst comprehensive classiﬁcation and segmentation method for ART. To aid in embryo selection, we will develop novel deep learning-based models to predict probabilities of achieving pregnancy by accepting visual features and EHR data as the input. We will also develop visual analytic tools that allow analysts to better understand and steer these deep learning models. We will estimate the importance of each input interpretable factor in embryo selection to explain the prediction to embryologists. Finally, we will develop EmbryoProﬁler, a clinical decision support system for ART, that combines our machine learning-based models with a user-facing suite of visual analytic tools to support user guidance and clinical decision making. EmbryoProﬁler will help facilitate daily operation in clinics, foster human-guided decision making, enrich data-driven embryo analysis, and enhance the ability to select the developmentally most competent embryo for transfer to improve ART success rates. Our project will create state-of-the-art analysis approaches for ART clinicians. PROJECT NARRATIVE Assisted Reproductive Technology (ART) is a widespread treatment for infertility, over 300,000 treatment cycles were performed in the US in 2018, but success rates remain low. In this project, we will develop novel machine learning algorithms and a clinical decision support system to assist embryologists in embryo selection. Our tools will also enable embryologists and biologists to obtain new information on the earliest stages of human embryo development, which will advance the fundamental science of human biology and lead to further improvements in ART practice.",Enhancing Assisted Reproductive Technologies with Deep Learning and Data Visualization,10185936,R01HD104969,"['Adopted', 'Age', 'Assisted Reproductive Technology', 'Back', 'Cell Lineage', 'Classification', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Decision Support Systems', 'Clinical Treatment', 'Cloud Service', 'Communities', 'Complex', 'Computer Models', 'Computer Vision Systems', 'Computers', 'Couples', 'Data', 'Data Analyses', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Decision Making', 'Detection', 'Development', 'Discipline', 'E-learning', 'Electronic Health Record', 'Embryo', 'Embryo Transfer', 'Embryonic Development', 'Fostering', 'Goals', 'Human', 'Human Biology', 'Image', 'Image Analysis', 'In Vitro', 'Judgment', 'Knowledge', 'Label', 'Lead', 'Machine Learning', 'Manuals', 'Medical', 'Methods', 'Modeling', 'Morbidity - disease rate', 'Morphology', 'Mothers', 'Multiple Pregnancy', 'Obesity', 'Patients', 'Pattern', 'Physiological', 'Pre-implantation Embryo Development', 'Pregnancy', 'Pregnancy Rate', 'Privacy', 'Probability', 'Research', 'Science', 'Scientist', 'Secure', 'Security', 'Text', 'Time', 'Trees', 'United States', 'Ursidae Family', 'Uterus', 'Visual', 'Visualization', 'Visualization software', 'analytical tool', 'base', 'blastocyst', 'clinical decision-making', 'clinical practice', 'cloud based', 'cohort', 'convolutional neural network', 'data cleaning', 'data curation', 'data management', 'data visualization', 'deep learning', 'embryo cell', 'embryo monitoring', 'feature extraction', 'human-in-the-loop', 'implantation', 'improved', 'infertility treatment', 'insight', 'large scale data', 'machine learning algorithm', 'microscopic imaging', 'model design', 'multi-task learning', 'multimodality', 'novel', 'operation', 'predictive modeling', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'zygote']",NICHD,HARVARD UNIVERSITY,R01,2021,730410
"Integrating Ethics into Machine Learning for Precision Medicine The application of new computerized methods of data analysis to vast collections of medical, biological, and other data is emerging as a central feature of a broad vision of precision medicine (PM) in which systems based on artificial intelligence (AI) assist clinicians in treatment, diagnosis, or prognosis. The use of AI to analyze big data for clinical decision-making opens up a new domain for ELSI inquiry to address a possible future when the implications of genetics and genomics become embedded into algorithms, pervasive yet implicit and difficult to identify. Thus, an important target of inquiry is the development and developers of these algorithms. There are three distinctive features of the application of AI, and in particular machine learning (ML), to the domain of PM that create the need for ELSI inquiry. First, the process of developing ML-based systems for PM goals is technically and organizationally complex. Thus, members of development teams will likely have different expertise and assumptions about norms, responsibilities, and regulation. Second, machine learning does not solely operate through predetermined rules, and is thus difficult to hold accountable for its conclusions or reasoning. Third, designers of ML systems for PM may be subject to diverse and divergent interests and needs of multiple stakeholders, yet unaware of the associated ethical and values implications for design. These distinctive features of ML in PM could lead to difficulties in detecting misalignment of design with values, and to breakdown in responsibility for realignment. Because machine learning in the context of precision medicine is such a new phenomenon, we have very little understanding of actual practices, work processes and the specific contexts in which design decisions are made. Importantly, we have little knowledge about the influences and constraints on these decisions, and how they intersect with values and ethical principles. Although the field of machine learning for precision medicine is still in its formative stage, there is growing recognition that designers of AI systems have responsibilities to ask such questions about values and ethics. In order to ask these questions, designers must first be aware that there are values expressed by design. Yet, there are few practical options for designers to learn how to increase awareness. Our specific aims are: Aim 1 To map the current state of ML in PM by identifying and cataloging existing US-based ML in PM  projects and by exploring a range of values expressed by stakeholders about the use of ML in PM through  a combination of multi-method review, and interviews of key informants and stakeholders. Aim 2 To characterize decisions and rationales that shape ML in PM and explore whether and how  developers perceive values as part of these rationales through interviews of ML developers and site visits. Aim 3 To explore the feasibility of using design rationale as a framework for increasing awareness of the  existence of values, and multiple sources of values, in decisions about ML in PM through group-based  exercises with ML developers from academic and commercial settings. The overall goal of this project is to understand how to encourage and enable people who are developing artificial intelligence for personalized health care to be aware of values in their daily practice. We will examine actual practices and contexts in which design decisions are made for precision medicine applications, and use this information to design group-based workshop exercises to increase awareness of values.",Integrating Ethics into Machine Learning for Precision Medicine,10136061,R01HG010476,"['Address', 'Algorithms', 'Artificial Intelligence', 'Awareness', 'Big Data', 'Biological', 'Cataloging', 'Clinical', 'Collection', 'Complex', 'Computers', 'Data', 'Data Analyses', 'Development', 'Diagnosis', 'Educational workshop', 'Electronic Health Record', 'Engineering', 'Ethics', 'Evolution', 'Exercise', 'Expert Systems', 'Foundations', 'Future', 'Genetic', 'Genomics', 'Goals', 'Healthcare', 'Interview', 'Knowledge', 'Lead', 'Learning', 'Machine Learning', 'Maps', 'Medical', 'Methods', 'Outcome', 'Process', 'Regulation', 'Research', 'Resources', 'Sampling', 'Scholarship', 'Scientist', 'Shapes', 'Site Visit', 'Source', 'System', 'Time', 'Vision', 'Work', 'base', 'biobank', 'clinical decision-making', 'computerized', 'design', 'ethical legal social implication', 'genomic data', 'informant', 'innovation', 'interest', 'member', 'new technology', 'outcome forecast', 'personalized health care', 'precision medicine']",NHGRI,STANFORD UNIVERSITY,R01,2021,579506
"Center for Machine Learning in Urology PROJECT SUMMARY We propose to establish an Exploratory Center for Interdisciplinary Research in Benign Urology at the Children’s Hospital of Philadelphia (CHOP) and the University of Pennsylvania (Penn), the central mission of which is to apply machine learning to improve the understanding of the pathophysiology, diagnosis, risk stratification, and prediction of treatment responses of benign urological disease among children and adults. The proposed CHOP/Penn Center for Machine Learning in Urology (CMLU) addresses critical structural and scientific barriers that impede the development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. Structurally, urologic research occurs in silos, with little interaction among investigators that study different diseases or different populations (e.g. pediatric and adult). Scientifically, analysis of imaging and other types complex data is limited by inter-observer variability, and incomplete utilization of available information. This proposal overcomes these barriers by applying cutting-edge approaches in machine learning to analyze CT images that are routinely obtained for evaluation of individuals with kidney stone disease. Central to the CHOP/Penn CMLU is the partnership of urologists and experts in machine learning, which will bring a new approach to generating knowledge that advances research and clinical care. In addition, the CMLU will expand the urologic research community by providing a research platform and standalone machine learning executables that could be applied to other datasets. The Center’s mission will be achieved through the following Aims, with progress assessed through systematic evaluation: Aim 1. To expand the research base investigating benign urological disease. We will establish a community with the research base, particularly with the KURe, UroEpi programs, other P20 Centers, and O’Brien Centers. We will build this community by providing mini-coaching clinics to facilitate application of machine learning to individual projects, developing an educational hub for synchronous and asynchronous engagement with the research base, and making freely available all source codes and standalone executables for all machine learning tools. Aim 2. To improve prediction of ureteral stone passage using machine learning of CT images. The CMLU has developed deep learning methods that segment and automate measurement of urinary stones and adjacent renal anatomy. In the Research Project, we will compare these methods to existing segmentation methods and the current gold standard of manual measurement. We will then extract informative features from thousands of CT scans to predict the probability of spontaneous passage of ureteral stones for children and adults evaluated in the CHOP and Penn healthcare systems. Aim 3. To foster collaboration in benign urological disease research across levels of training and centers through an Educational Enrichment Program. We will amplify interactions across institutions and engage investigators locally and nationally by providing summer research internships, and interinstitutional exchange program, and an annual research symposium. PROJECT NARRATIVE The proposed CHOP/Penn O’Brien Center for Machine Learning in Urology addresses critical structural and scientific barriers that impede development of new treatments and the effective application of existing treatments for benign urologic disease across the lifespan. This application overcomes these barriers by applying cutting- edge approaches in machine learning to analyze complex imaging data for individuals with kidney stone disease.The Center’s strategic vision of using machine learning to generate knowledge that improves diagnosis, risk stratification strategies, and prediction of outcomes among children and adults will be achieved through the implementation of a Educational Enrichment Program and a Research Project.",Center for Machine Learning in Urology,10260577,P20DK127488,"['Address', 'Adult', 'Algorithms', 'Anatomy', 'Area', 'Benign', 'Characteristics', 'Child', 'Childhood', 'Clinic', 'Clinical', 'Clinical Investigator', 'Code', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Set', 'Development', 'Diagnosis', 'Disease', 'Doctor of Philosophy', 'Educational Status', 'Evaluation', 'Fostering', 'Functional disorder', 'Funding', 'Future', 'Gold', 'Healthcare Systems', 'Image', 'Individual', 'Infrastructure', 'Institution', 'Interdisciplinary Study', 'Internships', 'Interobserver Variability', 'Investigation', 'Kidney', 'Kidney Calculi', 'Knowledge', 'Lead', 'Longevity', 'Machine Learning', 'Manuals', 'Measurement', 'Methods', 'Mission', 'National Institute of Diabetes and Digestive and Kidney Diseases', 'Patient Care', 'Pattern', 'Pattern Recognition', 'Pediatric Hospitals', 'Pennsylvania', 'Philadelphia', 'Population', 'Prediction of Response to Therapy', 'Predictive Analytics', 'Probability', 'Publishing', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Site', 'Source Code', 'Structure', 'Students', 'Techniques', 'United States National Institutes of Health', 'Universities', 'Urinary Calculi', 'Urologic Diseases', 'Urologist', 'Urology', 'Vision', 'Visit', 'X-Ray Computed Tomography', 'base', 'clinical care', 'complex data', 'deep learning', 'deep neural network', 'design', 'experience', 'feature selection', 'human error', 'improved', 'interdisciplinary collaboration', 'interest', 'learning strategy', 'novel strategies', 'outcome prediction', 'peer', 'programs', 'risk stratification', 'routine imaging', 'senior faculty', 'skills', 'summer research', 'symposium', 'tool', 'urologic', 'web page']",NIDDK,CHILDREN'S HOSP OF PHILADELPHIA,P20,2021,332101
"AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition ABSTRACT Dietary intake is a complex human behavior that drives disease risk and corresponding economic and healthcare burdens worldwide. Poor diet is the leading cause of death in the US and a known driver of obesity – a global epidemic. A major contributor to poor diet is food eaten away from home, such as restaurant foods. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods. Accurate approaches and tools to evaluate food and nutrient intake are essential in monitoring the nutritional status of individuals. There is a critical need for real-time data capture that minimizes burden and reduces error. While progress has been made, there is no tool available that accurately and automatically estimates foods left unconsumed in a meal. Two major limitations of existing systems is the reliance of a fiducial marker for food detection and volume estimation, and reliance on humans – either the respondent or a trained researcher – to estimate the portion of food leftover. This application leverages novel technology to remove those limitations. The long-term research goal is to utilize digital imaging (DI), artificial intelligence (AI) and computer vision (CV) techniques to develop a novel hybrid methodology for rapid, accurate measurement of dietary intake. To attain this goal, our objective in this R21 application is to refine and test a system architecture that (a) uses digital images to record dietary intake in real-time and (b) uses AI and CV techniques to identify food/beverage items and determine amounts leftover. We plan to build on our current prototype in which digital food images are captured before and after the meal, analyzed to detect the food items, a three-dimensional (3-D) virtual model constructed, and volume remaining after the meal estimated, which will be used to calculate the amount leftover based on the initial volume. Volume consumed will be converted to weight and linked to public-use nutrition information. These calorie estimates will be compared against calories those from (a) DIs coded by trained research staff and (b) weighed plate waste methodology. Our expectation is to develop a valid system architecture for rapidly estimating dietary intake. The outcome of this proposal is expected to have a significant positive impact, enabling nutrition and health researchers to collect high-quality food consumption data in real world settings, increasing knowledge of dietary patterns and improving capacity to assess dietary interventions. This work will lead to an R01 application that will expand food types and meal settings and test the utility of our system among consumers. Project Narrative Solutions to address the global obesity epidemic are urgently needed. Research has shown that tracking one’s weight and dietary intake significantly improve success toward weight loss and maintenance goals; however, this type of tracking is burdensome, prone to error, and difficult to estimate for restaurant foods, a known driver of obesity. This study integrates nutrition science, computer science, and engineering to develop and test a new method for assessing dietary intake, and if successful would yield a rapid, reliable, accurate and cost- effective tool.",AC/DC: Artificial intelligence and Computer visioning to assess Dietary Composition,10163822,R21CA250024,"['3-Dimensional', 'Address', 'Algorithms', 'Artificial Intelligence', 'Assessment tool', 'Behavior', 'Beverages', 'Body Weight decreased', 'Calories', 'Cause of Death', 'Cellular Phone', 'Code', 'Complex', 'Computer Vision Systems', 'Consumption', 'Data', 'Databases', 'Detection', 'Development', 'Diet Records', 'Dietary Assessment', 'Dietary Intervention', 'Dietary Practices', 'Dietary intake', 'Economics', 'Engineering', 'Epidemic', 'Food', 'Goals', 'Gold', 'Health', 'Healthcare', 'Home environment', 'Human', 'Human Resources', 'Hybrids', 'Image', 'Imaging Techniques', 'Individual', 'Intake', 'Intervention', 'Knowledge', 'Left', 'Link', 'Measurement', 'Measures', 'Methodology', 'Methods', 'Monitor', 'Nutrient', 'Nutritional Science', 'Nutritional status', 'Obesity', 'Obesity Epidemic', 'Outcome', 'Output', 'Participant', 'Research', 'Research Personnel', 'Research Training', 'Respondent', 'Restaurants', 'Side', 'Speed', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Unhealthy Diet', 'Validation', 'Weight', 'Work', 'base', 'computer science', 'cost', 'cost effective', 'design', 'dietary', 'digital', 'digital imaging', 'disorder risk', 'expectation', 'food consumption', 'food quality', 'handheld mobile device', 'improved', 'knowledge base', 'new technology', 'novel', 'nutrition', 'prototype', 'success', 'system architecture', 'tool', 'virtual model', 'wasting', 'weight maintenance']",NCI,TUFTS UNIVERSITY BOSTON,R21,2021,197745
"Identifying treatment responders in medication trials for AUD using machine learning approaches ABSTRACT Alcohol use disorder (AUD), as defined in DSM-5, represents a highly prevalent, costly, and often untreated condition in the United States. Pharmacotherapy offers a promising avenue for treating AUD and for improving clinical outcomes for this debilitating disorder. While developing novel medications to treat AUD remains a high priority research area, there remain major opportunities to further elucidate clinical response in completed medication trials. To that end, a key question in randomized clinical trials (RCTs) is which patients respond to a given pharmacotherapy. Identifying treatment responders provides major opportunities to advance clinical care for AUD by personalizing medication practices on the bases of variables/predictors of good clinical response. For example, while the effect size for medications such as naltrexone is deemed small-to-moderate, a host of studies over the past decade have shown that its effect size may be considerably larger for certain subgroups of patients. Towards advancing precision medicine for AUD and leveraging data from a host of carefully conducted RCTs for AUD, this R03 application seeks to conduct secondary data analysis. Specifically, we propose to analyze data from four RCTs conducted by the NIAAA Clinical Investigations Group (NCIG). These state-of-the-art RCTs for AUD have tested the following pharmacotherapies: (a) quetiapine, (b) Levetiracetam XR (Keppra XR®), (c) Varenicline (Chantix®), and (d) HORIZANT® (Gabapentin Enacarbil) Extended-Release. In this R03 application, we propose to use a machine learning approach to identify treatment responders in the NCIG RCTs. Machine learning represents a highly promising and underutilized data analytic strategy in the field of AUD treatment response. Machine learning models prioritize the ability to predict future outcomes over creating perfectly fitting models for the data at hand. This results in models which are more generalizable to future observations, which fits well with our goal of identifying responders in RCTs. Leveraging data from these pivotal RCTs through secondary data analysis and using novel analytic methods, namely machine learning, provides a cost-effective approach to identifying AUD pharmacotherapy responders. PROJECT NARRATIVE In this R03 application, we propose to use a machine learning approach to identify treatment responders in pivotal clinical trials for AUD. We propose to analyze data from four RCTs conducted by the NIAAA Clinical Investigations Group (NCIG), testing the following pharmacotherapies: (a) quetiapine, (b) Levetiracetam XR (Keppra XR®), (c) Varenicline (Chantix®), and (d) HORIZANT® (Gabapentin Enacarbil) Extended-Release. Leveraging resources through secondary data analysis and using novel analytic methods provides a cost- effective approach to identifying AUD pharmacotherapy responders.",Identifying treatment responders in medication trials for AUD using machine learning approaches,10195465,R03AA029244,"['Age', 'Age of Onset', 'Alcohols', 'Anxiety', 'Area', 'Chantix', 'Clinical', 'Clinical Trials', 'Collaborations', 'Communities', 'Conduct Clinical Trials', 'DSM-V', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Disease', 'Ethnic Origin', 'Faculty', 'Future', 'Goals', 'Hand', 'Heavy Drinking', 'Human', 'Keppra', 'Laboratories', 'Levetiracetam', 'Machine Learning', 'Manuscripts', 'Marital Status', 'Mental Depression', 'Methods', 'Mid-Career Clinical Scientist Award (K24)', 'Modeling', 'Motivation', 'Naltrexone', 'National Institute on Alcohol Abuse and Alcoholism', 'Outcome', 'Outcome Measure', 'Patients', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Policies', 'Psychologist', 'Psychology', 'Randomized Clinical Trials', 'Recommendation', 'Research', 'Research Personnel', 'Research Priority', 'Resources', 'Scientist', 'Secondary to', 'Self Administration', 'Severities', 'Sum', 'Symptoms', 'Technical Expertise', 'Testing', 'United States', 'Withdrawal', 'Work', 'alcohol use disorder', 'analytical method', 'base', 'cigarette smoking', 'clinical care', 'clinical investigation', 'clinically relevant', 'cost', 'cost effective', 'cost effectiveness', 'craving', 'data sharing', 'drinking', 'gabapentin', 'improved', 'insight', 'machine learning method', 'material transfer agreement', 'novel', 'patient subsets', 'precision medicine', 'quetiapine', 'random forest', 'response', 'secondary analysis', 'sex', 'success', 'tenure track', 'treatment responders', 'treatment response', 'varenicline']",NIAAA,UNIVERSITY OF CALIFORNIA LOS ANGELES,R03,2021,74776
"TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS PROJECT SUMMARY Trachoma is the leading cause of infectious blindness worldwide. The WHO has set a goal of controlling trachoma to a low enough level that blindness from the disease is no longer a public health concern. Control is defined as a district-level prevalence of follicular trachomatous inflammation (TF) in the upper tarsal conjunctiva of less than 5% in children, currently determined by clinical examination. While not required for the current definition, intense trachomatous inflammation (TI) correlates better with presence of the causative agent, Chlamydia trachomatis. Grading of both TF and TI vary widely between individuals, and even in the same individual over time. As cases become rarer, training new graders becomes more difficult. As areas become controlled, trachoma budgets are being cut, and the institutional knowledge of grading lost, making detection of remaining cases and potential resurgence difficult. One of the greatest obstacles to reaching our trachoma goals is an inadequate diagnostic test. The WHO relies on field grading of TF; human inconsistency, grader bias, and training costs are becoming major obstacles, but they do not need to be. We propose to test the central hypothesis that a fully automatic, deep learning grader can perform as well as trained physicians in detecting and grading trachoma. The hypothesis will be tested in the following Specific aims: 1) Automatic identification of follicles and grading of TF and 2) Automatic tarsal blood vessels detection and grading of TI. Our approach includes the development, training and testing of novel image processing pipelines based on semantic segmentation and disease classification using deep learning neural networks and state-of-the-art object detection. All of the data to be used in this study is secondary data from NEI-funded and other trachoma clinical trials conducted by our study team. We aim to facilitate widespread adoption of these novel tools across the trachoma research and grading community, by open source availability of generated code and interoperability of generated machine learning models across programming languages through use of the open neural networks exchange format. Our proposed research addresses the problem of subjectivity, cost and reliability of human trachoma grading. Successful completion of the proposed specific aims will also be a key step forward towards future study and development of providing health organizations and research teams with a novel, efficient and extensible tool to ensure objective, automated, scalable trachoma grading in the field to enhance, or in some cases replace, traditional field grading during the critical endgame of trachoma control, as well surveillance for potential resurgence. PROJECT NARRATIVE Trachoma elimination and control are major WHO goals, but success is limited by the ability to accurately identify and grade trachoma cases in the field manually by human graders, a process expensive, subjective and slow to scale up. This project seeks to perform secondary analysis by leveraging existing trachoma photograph datasets from numerous NEI-funded and other-sponsored prior randomized controlled trachoma studies in order to further develop a novel deep learning computational tool able to automatically detect and grade the active forms of trachoma in digital photographs. By employing deep learning neural networks and advanced image analysis, we propose to create a computer program with the ability to classify and grade trachoma in a way that is automatic, objective, scalable and with subsequent potential for remote grading which is auditable by regulatory agencies.",TRACHOMA SURVEILLANCE AT SCALE: AUTOMATIC DISEASE GRADING OF EYELID PHOTOS,10196816,R21EY032567,"['Address', 'Adoption', 'Africa South of the Sahara', 'Agreement', 'Algorithms', 'Area', 'Blindness', 'Blood Vessels', 'Budgets', 'Cellular Phone', 'Child', 'Chlamydia trachomatis', 'Code', 'Communities', 'Computer Vision Systems', 'Conduct Clinical Trials', 'Consensus', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnostic tests', 'Disease', 'Ensure', 'Ethiopia', 'Eye diseases', 'Eyelid structure', 'Foundations', 'Funding', 'Future', 'Goals', 'Gold', 'Human', 'Image', 'Image Analysis', 'Individual', 'Inflammation', 'Judgment', 'Knowledge', 'Machine Learning', 'Manuals', 'Modeling', 'Photography', 'Physicians', 'Play', 'Prevalence', 'Process', 'Programming Languages', 'Property', 'Public Health', 'Randomized', 'Reproducibility', 'Research', 'Role', 'Running', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Trachoma', 'Training', 'Universities', 'aged', 'base', 'clinical examination', 'computer program', 'computerized tools', 'conjunctiva', 'cost', 'deep learning', 'deep neural network', 'density', 'digital', 'disease classification', 'disease diagnosis', 'health organization', 'image processing', 'interoperability', 'neural network', 'novel', 'open source', 'prevent', 'programs', 'scale up', 'secondary analysis', 'success', 'tool']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R21,2021,242250
"Development of a Machine Learning Model for Liver Transplantation PROJECT SUMMARY/ABSTRACT Currently, there are nearly 13,000 patients waitlisted for liver transplant, yet only two-thirds will receive a transplant, and in 2018 approximately 2,500 patients died or were removed from the waitlist due to medical deterioration. This shortage of donor livers available for transplant has led to the use of marginal livers – livers that are higher risk than typical donor livers but may be safely transplantable in carefully selected recipients. These include older donors (>70 years), steatotic livers, and livers procured through donation after cardiac death. Due to their riskiness, these marginal livers are often declined, yet as many as 84% of patients who died on the transplant waitlist declined one or more marginal livers prior to death. In light of this, certain waitlisted candidates might have derived a survival benefit from undergoing transplantation with a marginal organ rather than remaining on the waitlist (i.e. they would have survived longer after a transplant with a marginal liver than they would have survived on the waitlist). Currently, decisions about whether a particular marginal liver is suitable for a particular candidate are based on clinical gestalt or simple subgroup analysis using traditional regression models, which likely do not fully approximate the complex interactions between donor, recipient, and transplant factors. To account for this, we will utilize machine learning (which can incorporate complex, higher-order interactions) to predict whether a specific candidate would derive a survival benefit from undergoing transplantation with a specific marginal liver, and interview transplant candidates and surgeons to understand how best to translate these predictions into an immediately clinically-useful decision aid. To accomplish this, we will leverage Scientific Registry of Transplant Recipient (SRTR) national data (n=293,140) and use a machine technique (random forests) to address the following aims: (1) To predict waitlist survival for waitlisted liver transplant candidates; (2) To predict post-transplant survival for liver transplant recipients of a marginal liver; and (3) To create a decision aid that compares predicted waitlist survival and predicted post-transplant survival for a specific transplant candidates with marginal liver. These aims are highly feasible given our group’s expertise in liver transplantation, analysis of national registry data, and machine learning techniques. We hypothesize that utilizing SRTR and machine learning, we can accurately predict post-transplant survival for a particular candidate with a particular marginal liver, as well as waitlist survival for that same candidate without a liver. We also hypothesize that our decision aid could be utilized in real-time to inform clinical decision-making. If the proposed aims are achieved, our decision aid could be utilized to improve clinical practice by bringing high-quality risk prediction directly to patients and transplant professionals to directly inform the real-time clinical decision of whether a candidate should undergo transplant with a marginal liver. PROJECT NARRATIVE There are far fewer donor livers available for transplant than patients who need them, which has led to the use of marginal livers – livers that are riskier than typical donor livers but yet might still provide a benefit to carefully selected patients. However, the decision to use a particular marginal liver for a particular patient is based largely on clinical gestalt or traditional clinical studies, which likely do not account for the complex relationships between donor, recipient, and transplant characteristics. To optimally inform the decision to undergo transplantation with a marginal liver or not, we propose to utilize machine learning to generate personalized risk predictions of post-transplant survival with that specific marginal liver and waitlist survival without that liver, and then develop a decision aid to be used by patients and surgeons to compare predicted survival between both options.",Development of a Machine Learning Model for Liver Transplantation,10208791,F32DK124962,"['Accounting', 'Address', 'Cardiac Death', 'Cessation of life', 'Characteristics', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Data Analyses', 'Decision Aid', 'Decision Making', 'Deterioration', 'Development', 'Doctor of Philosophy', 'Enrollment', 'Focus Groups', 'Goals', 'Instruction', 'Interview', 'Laboratories', 'Learning', 'Light', 'Liver', 'Machine Learning', 'Medical', 'Mentors', 'Methods', 'Modeling', 'Modification', 'Observational Study', 'Operative Surgical Procedures', 'Organ', 'Organ Transplantation', 'Patient Care', 'Patients', 'Population', 'Positioning Attribute', 'Process', 'Public Health Schools', 'Qualitative Research', 'Recording of previous events', 'Registries', 'Research', 'Research Methodology', 'Research Personnel', 'Resources', 'Scientist', 'Statistical Computing', 'Subgroup', 'Surgeon', 'Survey Methodology', 'Techniques', 'Testing', 'Time', 'Training', 'Translating', 'Transplant Recipients', 'Transplant Surgeon', 'Transplantation', 'Waiting Lists', 'base', 'clinical decision-making', 'clinical investigation', 'clinical practice', 'cohort', 'data registry', 'high risk', 'improved', 'interest', 'liver transplantation', 'personalized decision', 'personalized predictions', 'personalized risk prediction', 'post-transplant', 'programs', 'public health research', 'random forest', 'recruit', 'risk prediction', 'survival prediction', 'theories', 'transplant registry', 'web site']",NIDDK,JOHNS HOPKINS UNIVERSITY,F32,2021,84562
"Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics Abstract The primary objective is to develop an artificial intelligence-centric, quantitative and noninvasive software platform that can be integrated into 3D angiographic scanners (DSA, CTA or MRA) to provide guidance regarding the diagnosis and management of intracranial aneurysms (IA). Hemorrhagic stroke secondary to ruptured IAs leads to significant morbidity and mortality and affects over 35,000 patients on a yearly basis in the United States. The diagnosis of asymptomatic IAs is on the rise with the increasing use of cerebral imaging. However, guidance regarding which aneurysms should be treated has not advanced. Leveraging recent advances in computational science and technology, particularly artificial intelligence, the proposed software platform built on two enabling technologies can (1) propel automated “patient-specific” hemodynamic evaluations into the clinical workflow and (2) conduct “data-driven” risk assessments of IA rupture on an individual basis. Specific research aims are to (1) develop a clinically-oriented CFD platform that enables automated “patient-specific” hemodynamic evaluations of IAs, (2) investigate data-driven analytics toward prediction of rupture risk for IAs and (3) evaluate the data-driven analytics in a blind study. Once validated, a follow-up R01 project is planned to examine the clinical utility of the proposed software platform in a prospective clinical study as a single gateway for computer-aided evaluation of cerebral aneurysms. Public Health Relevance/Narrative This R01 proposal is to investigate the feasibility of developing an innovative, non-invasive and artificial intelligence-centric tool that can be used as a software add-on to clinical angiographic (e.g. DSA) scanners. The software can automatically select high-risk aneurysms for immediate treatments from a pool of patients with unruptured intracranial aneurysms, impacting the clinical management of intracranial aneurysms.",Personalized Management of Intracranial Aneurysms Using Computer-aided Analytics,10121043,R01EB029570,"['3-Dimensional', 'Affect', 'Aneurysm', 'Angiography', 'Architecture', 'Artificial Intelligence', 'Benign', 'Biomedical Computing', 'Biomedical Engineering', 'Brain hemorrhage', 'Cerebral Aneurysm', 'Cerebrum', 'Clinical', 'Clinical Management', 'Clinical Research', 'Clinical Trials', 'Computational Geometry', 'Computational Science', 'Computer Assisted', 'Computer software', 'Data', 'Development', 'Diagnosis', 'Engineering', 'Ensure', 'Evaluation', 'Genetic', 'Growth', 'Human', 'Image', 'Individual', 'Intracranial Aneurysm', 'Knowledge', 'Liquid substance', 'Machine Learning', 'Medicine', 'Methods', 'Michigan', 'Morbidity - disease rate', 'Morphology', 'Natural History', 'Neural Network Simulation', 'Outcome', 'Patients', 'Physics', 'Play', 'Research', 'Research Proposals', 'Risk', 'Risk Assessment', 'Role', 'Rupture', 'Ruptured Aneurysm', 'Secondary to', 'Smoker', 'Technology', 'TensorFlow', 'Testing', 'Training', 'Translational Research', 'United States', 'Universities', 'Wisconsin', 'Work', 'analytical method', 'base', 'blind', 'computer grid', 'convolutional neural network', 'deep learning', 'flexibility', 'follow-up', 'hemodynamics', 'high risk', 'image guided', 'innovation', 'learning strategy', 'mortality', 'neurosurgery', 'open source', 'personalized management', 'prevent', 'prospective', 'prototype', 'public health relevance', 'shear stress', 'success', 'tool']",NIBIB,MICHIGAN TECHNOLOGICAL UNIVERSITY,R01,2021,346966
"A Handheld Microchip for GC analysis of breath to screen for COVID-19 Project Summary  The COVID-19 pandemic has caused unprecedented societal suffering and economic disruption. In the United States, more than six million people have contracted COVID-19 and more than one hundred ninety thousand patients have died of this disease to date. Although current COVID-19 diagnostic testing technologies are critical for slowing the spread of the virus and preventing future outbreaks, they are not practical for field use. Current diagnostic tests are cumbersome to perform because they use aqueous solutions, require multiple steps, and hours-to-days to obtain results. Since the US began to reopen the economy in May, there has been a significant increase in the number of COVID-19 cases. Therefore, there is an urgent need to develop a diagnostic approach that is non-invasive, portable, and can rapidly provide test results.  The overall goal of the project is to develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). The handheld tool will be a closed system for trapping select volatile organic compounds (VOCs) on a microfabricated chip. The captured VOCs will be eluted with ethanol and then analyzed using a commercially available, portable GC-PID instrument. Artificial intelligence (AI) and machine learning algorithms will be applied to recognize the VOC pattern that correlates with COVID-19 infection. The central innovation is the microfabricated chip that captures carbonyl compounds in exhaled breath and thus serves as a preconcentrator, which enables analysis of carbonyl VOCs by the portable GC-PID. The hypothesis is that the carbonyl metabolome in exhaled breath is directly related to the body’s reaction to the novel coronavirus infection, and changes in the carbonyl VOC composition in exhaled breath relative to healthy controls can be used to detect both symptomatic and asymptomatic COVID-19 patients.  Three specific aims are proposed to fulfill the overall goal. Aim 1 is to build a disposable handheld breath analyzer tool for concentrating carbonyl VOCs. Aim 2 is to identify VOC patterns in the breath of COVID-19 patients by machine learning algorithms. Aim 3 is to integrate portable GC technology with the breath sampling tool for COVID-19 screening guided by an AI system. The University of Louisville is uniquely suited to rapidly transition the microchip technology to field use because of the PI and Co-PI’s experience in breath analysis and translational research, and the project team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence as well as the state-of-the-art facilities that include a MicroNano Technology Center, Biosafety Level 3 Regional Biocontainment Lab, and an NIH-funded REACH program. 8. Project Narrative  This project will develop a mobile breath analysis technology for rapid screening for COVID-19 using a handheld breath collection tool and a portable GC with a photoionization detector (PID). Artificial intelligence and machine learning algorithms will be used to analyze the detected signals of volatile organic compounds (VOCs) in exhaled breath by the portable GC for detection of COVID-19 patients. UofL is uniquely suited to develop this approach because of the PI’s expertise in breath analysis for detection of Tuberculosis and lung cancer and the team’s experience in virology, infectious diseases, biostatistics, and artificial intelligence.",A Handheld Microchip for GC analysis of breath to screen for COVID-19,10266377,U18TR003787,"['2019-nCoV', 'Acute', 'Address', 'Artificial Intelligence', 'Biochemical Process', 'Biometry', 'Breath Tests', 'COVID-19', 'COVID-19 detection', 'COVID-19 diagnostic', 'COVID-19 pandemic', 'COVID-19 patient', 'COVID-19 screening', 'COVID-19 test', 'Cancer Detection', 'Clinic', 'Collaborations', 'Collection', 'Communicable Diseases', 'Contracts', 'Coronavirus Infections', 'Detection', 'Device or Instrument Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Disease Outbreaks', 'Economics', 'Epithelial Cells', 'Ethanol', 'Exhalation', 'Expert Systems', 'Foundations', 'Funding', 'Future', 'Goals', 'Hour', 'Human', 'Influenza', 'Institutes', 'Institution', 'Laboratories', 'Machine Learning', 'Malignant neoplasm of lung', 'Mass Fragmentography', 'Medical Device', 'Modeling', 'Monitor', 'Nasal Epithelium', 'Oxidative Stress', 'Patients', 'Pattern', 'Process', 'Production', 'Protocols documentation', 'Rapid screening', 'Reaction', 'Reagent', 'Research Project Grants', 'Role', 'SARS-CoV-2 infection', 'Sampling', 'Sensitivity and Specificity', 'Signal Transduction', 'Silicon', 'Sterilization', 'System', 'Technology', 'Test Result', 'Testing', 'Training', 'Translational Research', 'Tuberculosis', 'United States', 'United States National Institutes of Health', 'Universities', 'Vial device', 'Viral', 'Viral Respiratory Tract Infection', 'Virulent', 'Virus', 'Virus Diseases', 'adduct', 'aqueous', 'asymptomatic COVID-19', 'biosafety level 3 facility', 'bronchial epithelium', 'carbonyl compound', 'detection sensitivity', 'detector', 'experience', 'innovation', 'instrument', 'machine learning algorithm', 'metabolome', 'microchip', 'mobile computing', 'novel coronavirus', 'photoionization', 'point of care', 'portability', 'prevent', 'programs', 'prototype', 'reagent testing', 'tool', 'virology', 'volatile organic compound']",NCATS,UNIVERSITY OF LOUISVILLE,U18,2021,1026672
"Big Data Predictive Phylogenetics with Bayesian Learning Big Data Predictive Phylogenetics with Bayesian Learning Abstract Andrew Holbrook, Ph.D., is a Bayesian statistician with a broad background in applied, theoretical and compu- tational data science. His proposed research Big Data Predictive Phylogenetics with Bayesian Learning tackles viral outbreak forecasting by combining Bayesian phylogenetic modeling with ﬂexible, `self-exciting' stochastic process models. The development and publication of open-source, high-performance computing software for his models will facilitate fast epidemiological ﬁeld response in a big data setting. Dr. Holbrook will apply his method- ology to the reconstruction of the 2015-2016 Zika virus epidemic in the Americas, focusing on identifying key geographical routes of transmission and phylogenetic clades with enhanced infectiousness.  Candidate: Dr. Holbrook is Postdoctoral Scholar at the UCLA Department of Human Genetics. He earned his Ph.D. in Statistics from the Department of Statistics at UC Irvine, during which time he completed his dissertation Geometric Bayes, an investigation into Bayesian modeling and computing on abstract mathematical spaces, and simultaneously participated in scientiﬁc collaborations at the UC Irvine Alzheimer's Disease Research Center. The proposed career development plan will establish Dr. Holbrook as an independent leader in data intensive viral epidemiology by 1) facilitating coursework to build biological domain knowledge, 2) affording Dr. Holbrook the opportunity to lead his own project while remaining under the expert oversight of UCLA Prof. Marc Suchard, M.D., Ph.D., and 3) allowing Dr. Holbrook to continue his focus on quantitative viral epidemiology once he has moved to a faculty commitment.  Mentors: During the ﬁrst three years of the award period, Dr. Holbrook will work closely with Prof. Suchard, continuing their current schedule of weekly meetings. Prof. Suchard is a leading expert in both Bayesian phylo- genetics and high-performance statistical computing; and with his medical background, Prof. Suchard will advise Dr. Holbrook in his expansion of domain knowledge in viral epidemiology. As secondary mentor, Prof. Kristian Andersen, Ph.D., of the Scripps Institute will advise Dr. Holbrook in the impactful application of his statistical and computational methodologies to the 2015-2016 Zika virus epidemic. Dr. Holbrook and Profs. Suchard and Andersen will maintain their collaborations after the postdoctoral period.  Research: Bayesian phylogenetics successfully reconstructs evolutionary histories but fails to predict viral spread. Self-exciting point processes are devoid of biological insight and fail to account for geographic networks of diffusion. Aim 1 addresses deﬁciencies in these two complementary viral epidemiological modeling techniques by innovating a combined model where the phylogenetic and self-excitatory components support each other. Aim 2 makes widespread adoption a reality by publishing open-source, massively parallel computing software suitable for big data analysis. Aim 3 reconstructs the 2015-2016 Zika epidemic, learns key geographical routes of transmission and identiﬁes phylogenetic clades with enhanced infectiousness. Project Narrative Tracking and predicting viral outbreaks remains an open epidemiological problem with deadly consequences. Dr. Holbrook will attack the problem with his Bayesian phylogenetic Hawkes processes, a class of models tailored to simultaneously reconstruct evolutionary histories and predict viral diffusion dynamics. With the mentorship of Profs. Marc Suchard (primary) and Kristian Andersen (secondary), Dr. Holbrook will develop open-source, high-performance computing software and apply his statistical computing methodology to the analysis of the 2015-2016 Zika virus epidemic of the Americas, learning key routes of transmission and identifying phylogenetic clades with enhanced infectiousness.",Big Data Predictive Phylogenetics with Bayesian Learning,10176406,K25AI153816,"['Accounting', 'Address', 'Adoption', 'Air', 'Alzheimer&apos', 's Disease', 'Americas', 'Award', 'Bayesian Modeling', 'Bayesian learning', 'Behavior', 'Big Data', 'Biological', 'Biology', 'Collaborations', 'Complex', 'Computer Models', 'Computer software', 'Computing Methodologies', 'Dangerousness', 'Data', 'Data Analyses', 'Data Science', 'Development', 'Development Plans', 'Diffusion', 'Disease Outbreaks', 'Doctor of Medicine', 'Doctor of Philosophy', 'Earthquakes', 'Epidemic', 'Epidemiologist', 'Epidemiology', 'Evaluation', 'Event', 'Evolution', 'Faculty', 'Failure', 'Free Will', 'Generations', 'Geography', 'Goals', 'Health', 'Herd Immunity', 'High Performance Computing', 'Human Genetics', 'Individual', 'Influenza', 'Institutes', 'Investigation', 'Joints', 'Knowledge', 'Lead', 'Learning', 'Mathematics', 'Medical', 'Mentors', 'Mentorship', 'Methodology', 'Modeling', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Phylogeny', 'Process', 'Publications', 'Publishing', 'Recording of previous events', 'Research', 'Route', 'Schedule', 'Scientist', 'Ships', 'Speed', 'Statistical Computing', 'Stochastic Processes', 'Structure', 'Techniques', 'Testing', 'Time', 'Travel', 'Viral', 'Viral Epidemiology', 'Viral Physiology', 'Work', 'ZIKA', 'Zika Virus', 'blind', 'career development', 'epidemiological model', 'flexibility', 'innovation', 'insight', 'meetings', 'novel', 'open source', 'outbreak prediction', 'parallel computer', 'pathogen', 'reconstruction', 'response', 'statistics', 'transmission process']",NIAID,UNIVERSITY OF CALIFORNIA LOS ANGELES,K25,2021,106467
"Virtual Biopsy with Tissue-level Accuracy in Glioma Project Summary This is a Bioengineering Research Grant (BRG) proposal in response to PAR-19-158 to further develop and validate a non-invasive panel of the most critical glioma molecular markers (IDH, 1p/19q, MGMT) using standard clinical MRI T2-weighted images and deep learning, and extend the performance to tissue-level accuracies. Currently, the only reliable way of obtaining molecular marker status is through direct tissue sampling of the tumor, requiring either a craniotomy and stereotactic biopsy or a large open surgical resection. Noninvasive determination of molecular markers with tissue-level accuracy would be transformational in the management of gliomas, reducing or eliminating the risks and costs associated with a neurosurgical procedure, accelerating the time to definitive treatment, improving patient experience and ultimately patient outcomes and survival time. Artificial intelligence such as deep learning has emerged as a powerful method for classification of imaging data that can exceed human performance. Preliminary work using our novel voxel-wise classification-segmentation approach with the NIH/NCI TCIA glioma database has outperformed any prior noninvasive methods for determination of IDH, 1p/19q, and MGMT methylation, achieving accuracies of 97%, 93%, and 95%, respectively. The approach however, needs to be validated beyond the TCIA and accuracies need to be extended in order to achieve tissue level performance. This will be accomplished by using our top-performing voxel-wise classification framework, leveraging marker-specific targeted sample sizes, and gaining a final boost from deep-learning artifact correction networks. In Aim 1 we will curate a database of over 2000 gliomas including 500 subjects from our institution, 1200 subjects from our external collaborators, and over 300 subjects from the TCIA. We will train our voxel-wise deep learning classifiers to determine molecular status based on clinical T2-weighted MR images with target accuracies of 97%. In Aim 2 we will rigorously evaluate the motion and noise sensitivity of the networks and create an artifact correction network with the goals of 1) recovering accuracies in the setting of large amounts of motion/noise and 2) further boosting accuracy to tissue-level performance even in the absence of visible artifact. In Aim 3 we will deploy a complete end-to-end clinical workflow and evaluate real-world live performance of the AI tool on 300 prospectively acquired brain tumor cases and 300 subjects from our external collaborators. The AI tool will be made available for deployment at other medical centers. The developed framework can also be extended to additional markers in a straightforward fashion. In summary, this BRG proposal will further develop, refine and validate a non-invasive MRI-based method for determining the most critical glioma molecular markers rivaling tissue-level accuracies to significantly reduce and in many cases eliminate the need for stereotactic biopsy. Project Narrative Knowledge of molecular status for a variety of markers in gliomas has moved to the forefront in clinical decision- making. This requires direct tissue sampling either from an invasive brain biopsy or open surgical resection. In this Bioengineering Research Grant proposal in response to PAR-19-158, we will develop and validate a non- invasive method to determine a panel of the most critical molecular markers (IDH, 1p/19q and MGMT methylation) with near tissue-level accuracies using routine T2-weighted (T2w) MR images and deep learning algorithms to significantly reduce and in many cases eliminate the need for stereotactic biopsy in glioma.",Virtual Biopsy with Tissue-level Accuracy in Glioma,10226632,R01CA260705,"['19q', 'Algorithms', 'Applications Grants', 'Artificial Intelligence', 'Automation', 'Biology', 'Biomedical Engineering', 'Biopsy', 'Brain', 'Brain Neoplasms', 'Classification', 'Clinical', 'Computerized Medical Record', 'Craniotomy', 'Data', 'Data Set', 'Databases', 'Digital Imaging and Communications in Medicine', 'Excision', 'Glioma', 'Goals', 'Human', 'Hyperacusis', 'Image', 'Institution', 'Knowledge', 'MGMT gene', 'Magnetic Resonance Imaging', 'Manuals', 'Medical center', 'Methods', 'Methylation', 'Molecular', 'Molecular Analysis', 'Morphologic artifacts', 'Motion', 'Neurosurgical Procedures', 'Noise', 'Operative Surgical Procedures', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Predictive Value', 'Procedures', 'Process', 'Prospective cohort', 'Reporting', 'Research Project Grants', 'Resources', 'Risk', 'Sample Size', 'Sensitivity and Specificity', 'T2 weighted imaging', 'Testing', 'The Cancer Genome Atlas', 'The Cancer Imaging Archive', 'Time', 'Tissue Sample', 'Tissues', 'Training', 'Tumor Tissue', 'United States National Institutes of Health', 'Validation', 'Work', 'base', 'clinical decision-making', 'clinical implementation', 'clinical translation', 'contrast imaging', 'cost', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'large datasets', 'learning classifier', 'learning strategy', 'molecular marker', 'motion sensitivity', 'mutational status', 'novel', 'outcome forecast', 'prospective', 'response', 'surgical risk', 'tool', 'tumor', 'virtual biopsy']",NCI,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,655597
"Evaluation of artificial intelligence-controlled CPR to improve vital organ perfusion and survival during prolonged resuscitation Project Summary / Abstract  Almost 400,000 cases of out-of-hospital cardiac arrest (OHCA) occur each year in the United States. In patients requiring cardiopulmonary resuscitation (CPR) for prolonged periods, current CPR methods are unable to maintain adequate blood flow and oxygen delivery to the vital organs. Survival is <10% in patients with shockable rhythms and ~0% in those with non-shockable rhythms. Current American Heart Association (AHA) recommendations for CPR follow a “one-size-fits-all” paradigm. Our goal is to improve vital organ perfusion during prolonged CPR by “personalizing” compression/decompression therapy with a dynamic CPR method that changes compression characteristics over the course of CPR after taking into account the temporal changes of chest wall compliance and hemodynamics in order to increase the rate of neurologically intact survival after OHCA.  In this grant proposal, we are investigating the deployment of machine learning algorithms incorporated into a mechanical CPR device to predict and optimize hemodynamics during CPR. We will use state-of-the-art dynamical modeling in conjunction with closed-loop control algorithms to individualize CPR characteristics and optimize temporal blood flow. Our preliminary results suggest that deployment of machine learning prediction algorithms paired with control algorithms in a preclinical Ventricular Fibrillation model can adapt compression and decompression depth in real time, resulting in increased vital organ blood flow as compared to standard CPR techniques Based on these results, we hypothesize that optimization of compression depth, decompression depth, duty cycle, and compression rate of CPR will lead to better outcomes. Our proposed research will: 1) identify the most promising algorithm for the prediction of CPR hemodynamics 2) identify the best control algorithm to pair with this prediction algorithm in terms of optimizing CPR hemodynamics and return of spontaneous circulation 3) use the prediction and control pairing to improve 48h neurologically intact survival in a porcine model of ventricular fibrillation, as compared to standard CPR techniques. Throughout this process, we will identify non-invasive alternative measurements to provide to the algorithms with the ultimate goal of proceeding with device development and human trials. Project Narrative In light of a growing body of evidence which suggests that prolonged duration CPR is a dynamic process, without universally optimal “one-size-fits-all” parameters, advanced methods of CPR individualization may be applied to optimize cardiac and cerebral perfusion for these patients. We propose to study the effects of machine learning and optimal control techniques within the context of CPR, thus creating a closed-loop CPR system that has been trained by pre-clinical data to modify CPR characteristics and optimize blood flow. Our preliminary studies suggest that machine learning and control algorithms can be successfully deployed in a preclinical model to adapt compression and decompression depth, increasing vital organ blood flow as compared to standard CPR techniques. If our hypotheses are verified, a gateway for the first human trials is open.",Evaluation of artificial intelligence-controlled CPR to improve vital organ perfusion and survival during prolonged resuscitation,10186125,R01HL157625,"['Acute', 'Algorithms', 'American Heart Association', 'Animal Experiments', 'Applications Grants', 'Artificial Intelligence', 'Basic Science', 'Biofeedback', 'Blood Circulation', 'Blood flow', 'Carbon Dioxide', 'Cardiac', 'Cardiopulmonary Resuscitation', 'Cerebrum', 'Cessation of life', 'Characteristics', 'Chest wall structure', 'Choices and Control', 'Chronic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Collaborations', 'Coronary Arteriosclerosis', 'Coronary heart disease', 'Data', 'Databases', 'Device or Instrument Development', 'Devices', 'E-learning', 'Early Mobilizations', 'Evaluation', 'Family suidae', 'Feedback', 'Frequencies', 'Future', 'Gaussian model', 'Generations', 'Goals', 'Hospitals', 'Hour', 'Human', 'Knowledge', 'Learning', 'Light', 'Linear Regressions', 'Machine Learning', 'Measurement', 'Measures', 'Mechanics', 'Metabolic', 'Methods', 'Modeling', 'Near-Infrared Spectroscopy', 'Neurologic', 'Organ', 'Outcome', 'Oxygen', 'Patients', 'Performance', 'Perfusion', 'Phase I Clinical Trials', 'Pre-Clinical Model', 'Process', 'Publishing', 'Recommendation', 'Research', 'Resuscitation', 'Shock', 'Survival Rate', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Validation', 'Ventricular Fibrillation', 'Ventricular Tachycardia', 'algorithm training', 'base', 'clinically relevant', 'coronary perfusion', 'experience', 'experimental study', 'hemodynamics', 'improved', 'in vivo', 'indexing', 'innovation', 'machine learning algorithm', 'neural network', 'out-of-hospital cardiac arrest', 'pre-clinical', 'prediction algorithm', 'pressure', 'prospective', 'time interval']",NHLBI,UNIVERSITY OF MINNESOTA,R01,2021,547699
"Prevalence effects in visual research: Theoretical and practical implications Low prevalence searches form an important and problematic class of visual search tasks. These are tasks where the search target is rare. Many socially important tasks like airport security or cancer screening are low prevalence tasks. Previous work, much of it from our lab, has shown that low prevalence can have undesirable effects. Most notably, miss (false negative) errors are markedly elevated at low prevalence. This is a clear problem if the purpose of the search is to detect something rare but important like cancer or a terrorist threat. Our previous work has documented this pattern of increased miss errors in a number of expert domains including cytology (cervical cancer screening), airport baggage screening, and breast cancer screening. False alarm (false positive) error rates typically decline at low prevalence, moving in the opposite direction from miss errors. This indicates a shift in the observer’s decision criterion. At low prevalence, observers become more reluctant to call something a target. Several studies – ours and others - have shown that this “conservative” criterion shift is not adequate to explain the entire prevalence effect. Wolfe and VanWert (2010) developed a “Dual- Threshold” model that better captures the important aspects of the prevalence effect data by proposing two effects of low prevalence: (1) the conservative shift in the criterion for deciding if an attended item is a target, and (2) a lowering of the “quitting threshold.” The quitting threshold determines when observers end a search. Quitting too soon also increases the chance that the observer will miss a target. Prevalence effects have been studied in experimental isolation from other aspects of search. However, in tasks like breast cancer screening, other factors interact with prevalence. The four projects in the present proposal each investigate one of these interactions. Project 1 examines the relationship of prevalence to the “vigilance decrements” that are seen as time elapses in a task. In search, observers must maintain an internal, mental representation of the search target (or targets). Project 2 is concerned with the impact of prevalence on these “target templates”. Advances in artificial intelligence (notably deep learning) are producing tools to assist expert searchers. However, once deployed, these AI tools have been less effective than theory predicts. Project 3 tests the hypothesis that part of the problem is another side-effect of low prevalence and the project tests a potential intervention. Finally, clinicians, searching for one type of target (e.g. pneumonia) are supposed to report signs of other possible problems (e.g. lung cancer). Project 4 probes the role of prevalence in the failure to report such “incidental findings”. Again, we test several interventions. This is “use-inspired, basic research” whose results will provide guidance for experts performing socially important low prevalence tasks. Important tasks like breast cancer screening involve visual search for rare (“low prevalence”)  targets but, unfortunately, low prevalence is known to increase the percentage of targets that are  missed even by well-trained experts. In a task like breast cancer screening, prevalence interacts  with other factors like observer vigilance or the effectiveness of an artificial intelligence tool.  This proposal studies four of these interactions with the goal of counteracting the malign effects  of prevalence; thus making it possible for experts to perform their critical search tasks more  effectively.",Prevalence effects in visual research: Theoretical and practical implications,10111519,R01EY017001,"['Artificial Intelligence', 'Basic Science', 'Breast Cancer Detection', 'Cervical Cancer Screening', 'Collaborations', 'Cytology', 'Data', 'Detection', 'Effectiveness', 'Failure', 'Flecks', 'Goals', 'Human', 'Hybrids', 'Incidental Findings', 'Intervention', 'Joints', 'Low Prevalence', 'Malignant Neoplasms', 'Malignant neoplasm of lung', 'Methods', 'Modeling', 'Paper', 'Pattern', 'Performance', 'Pneumonia', 'Predictive Value', 'Prevalence', 'Prevalence Study', 'Reporting', 'Research', 'Research Personnel', 'Role', 'Screening for cancer', 'Security', 'Talents', 'Testing', 'Time', 'Training', 'Trust', 'Visual', 'Work', 'analog', 'base', 'clinically significant', 'deep learning', 'design', 'improved', 'mental representation', 'programs', 'side effect', 'social', 'theories', 'tool', 'vigilance', 'visual search']",NEI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,441020
"Deep Learning Algorithms for FreeSurfer Abstract FreeSurfer is a tool for the analysis of Magnetic Resonance Imaging (MRI) that has proven to be a flexible and powerful technology for quantifying the effects of many conditions, including numerous neurological disorders, on human brain anatomy, connectivity, vasculature, chemical composition, physiology and function. In the past 20 years, these open source tools have been developed to accurately and automatically segment an array of brain structures and have become the core analysis infrastructure for the Alzheimer’s Disease NeuroImaging Initiative (ADNI). In this project, we seek the resources to radically increase the speed, accuracy and flexibility of these tools, taking advantage of exciting new results in Deep Learning. This will enable us to more accurately quantify neuroanatomical changes that are critical to diagnosing, staging and assessing the efficacy of potential therapeutic interventions in diseases such as Alzheimer’s. This includes the generation of documentation, tutorials, unit tests, regression tests and system tests to harden the tools and make them usable by clinicians and neuroscientists, and finally the distribution and support of the data, manual labelings and tools to the more than 40,000 researchers that use FreeSurfer through our existing open source mechanism. In addition, we will analyze the entire Alzheimer’s Disease NeuroImaging Initiative dataset and return it for public release, including a set of manually labeled data that can be used to optimize Deep Learning tools for Alzheimer’s Disease over the next decade. Relevance Successful completion of the proposed project will increase the usability and accuracy of our publicly available segmentation tools, and open up new possibilities, such as integrating them into the MRI scanner and rapidly detecting Alzheimer’s-related changes. These new capabilities well enable other studies to significantly increase their ability to detect AD and other disease effects in research settings as well as phase II and phase III clinical trials due to the radical increase in speed of the new tools, enabling them to be applied to a diverse set of MRI contrasts and much larger datasets, rapidly and accurately. Further, they will allow rapid application of cutting-edge analyses to the ongoing Alzheimer’s Disease NeuroImaging Initiative dataset, improving the ability to extract early biomarkers of this devastating disease.",Deep Learning Algorithms for FreeSurfer,10143171,R01AG064027,"['Aging', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Anatomy', 'Brain', 'Chemicals', 'Code', 'Communities', 'Data', 'Data Set', 'Diagnosis', 'Disease', 'Documentation', 'Engineering', 'Ensure', 'Excision', 'Functional Magnetic Resonance Imaging', 'Future', 'Generations', 'Hour', 'Human', 'Image', 'Infrastructure', 'Label', 'Licensing', 'Magnetic Resonance Imaging', 'Manuals', 'Measures', 'Memory', 'Modeling', 'Neurobiology', 'Pattern', 'Phase II Clinical Trials', 'Phase III Clinical Trials', 'Physiology', 'Population', 'Procedures', 'Publishing', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Rest', 'Sensitivity and Specificity', 'Speed', 'Staging', 'Stream', 'Structure', 'Surface', 'System', 'Technology', 'Test Result', 'Testing', 'Therapeutic Intervention', 'Time', 'Training', 'Validation', 'Variant', 'Work', 'base', 'contrast imaging', 'convolutional neural network', 'cranium', 'deep learning', 'deep learning algorithm', 'early detection biomarkers', 'flexibility', 'high resolution imaging', 'human disease', 'improved', 'large datasets', 'morphometry', 'nervous system disorder', 'neuroimaging', 'novel', 'open source', 'prevent', 'prototype', 'skills', 'spatial relationship', 'support tools', 'tool', 'usability', 'web site', 'wiki']",NIA,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,655746
"Differential artery-vein analysis in OCT angiography for objective classification of diabetic retinopathy Abstract: This project aims to establish differential artery-vein analysis in optical coherence tomography angiography (OCTA), and to validate comprehensive OCTA features for automated classification of diabetic retinopathy (DR). Early detection, prompt intervention, and reliable assessment of treatment outcomes are essential to prevent irreversible visual loss from DR. It is known that DR can target arteries and veins differently. Therefore, differential artery-vein analysis can provide better performance of DR detection and classification. However, clinical OCTA instruments lack the capability of artery-vein differentiation. During this project, we propose to use quantitative feature analysis of OCT, which is concurrently captured with OCTA, to guide artery- vein differentiation in OCTA. The first aim is to establish automated artery-vein differentiation in OCTA. In coordination with our recently demonstrated blood vessel tracking technique, OCT intensity/geometry features will be used to guide artery-vein differentiation in OCTA automatically. Differential artery-vein analysis of blood vessel tortuosity (BVT), blood vessel caliber (BVC), blood vessel density (BVD), vessel perimeter index (VPI), vessel branching coefficient (VBC), vessel branching angle (VBA), branching width ratio (BWR), fovea avascular zone area (FAZ-A) and FAZ contour irregularity (FAZ-CI) will be implemented. Key success criterion of the aim 1 study is to demonstrate robust artery-vein differentiation in OCTA, and to establish OCTA features for objective detection and classification of DR. The second aim is to validate automated OCTA classification of DR. We propose to employ ensemble machine learning to integrate multiple classifiers to achieve robust OCTA classification of DR. Key success criterion of the aim 2 study is to identify OCTA features and optimal-feature- combination to detect early DR, and to establish the correlations between the OCTA features and clinical biomarkers. The third aim is to verify OCTA prediction and evaluation of DR treatment. Our preliminary OCTA study of diabetic macular edema (DME) with anti-vascular endothelial growth factor (anti-VEGF) treatment has shown that BVD can serve as a biomarker predictive of visual improvement. During this project, we plan to test differential artery-vein analysis for DME treatment evaluation. Key success criterion of the aim 3 study is to identify artery-vein features to provide robust prediction and evaluation of DME treatment outcomes. As an alternative approach, we propose a fully convolutional neural network (FCNN) for deep machine leaning based artery-vein and DR classification. Early layers in the FCNN will produce simple features, which will be convolved and filtered into deeper layers to produce complex features for artery-vein and DR classification. Further investigation of the relationship between the new features learned through the machine learning process and clinical biomarkers will allow us to optimize the design for better DR classification. Success of this project will pave the way towards using quantitative OCTA features for early DR detection, objective prediction and assessment of treatment outcomes. Project Narrative This project is to establish quantitative optical coherence tomography angiography (OCTA) analysis for objective classification of diabetic retinopathy (DR). By translating subjective findings into objective assessments, this study will standardize clinical OCTA for eye disease detection and treatment assessment. In addition, objective OCTA analysis based automated DR classification can foster telemedicine in rural and underserved areas where the access to experienced ophthalmologists is limited.",Differential artery-vein analysis in OCT angiography for objective classification of diabetic retinopathy,10080731,R01EY030842,"['Adult', 'Affect', 'Angiography', 'Area', 'Arteries', 'Biological Markers', 'Blindness', 'Blood Vessels', 'Blood capillaries', 'Caliber', 'Classification', 'Clinical', 'Color', 'Complex', 'Derivation procedure', 'Detection', 'Diabetes Mellitus', 'Diabetic Retinopathy', 'Disease', 'Early Diagnosis', 'Evaluation', 'Exudate', 'Eye diseases', 'Fostering', 'Fundus photography', 'Geometry', 'Health Expenditures', 'Individual', 'Intervention', 'Investigation', 'Machine Learning', 'Maps', 'Methods', 'Microaneurysm', 'Modernization', 'Ophthalmologist', 'Optical Coherence Tomography', 'Optics', 'Performance', 'Process', 'Reflex action', 'Retina', 'Retinal Edemas', 'Retinal Hemorrhage', 'Sensitivity and Specificity', 'Source', 'Staging', 'Standardization', 'Symptoms', 'Techniques', 'Telemedicine', 'Testing', 'Thinness', 'Translating', 'Treatment outcome', 'Vascular Endothelial Growth Factors', 'Veins', 'Venous', 'Visual', 'Width', 'base', 'bevacizumab', 'clinical biomarkers', 'convolutional neural network', 'deep neural network', 'density', 'design', 'diabetic', 'diabetic patient', 'experience', 'fovea centralis', 'fundus imaging', 'global health', 'image registration', 'imaging capabilities', 'improved', 'indexing', 'instrument', 'macular edema', 'predictive marker', 'prevent', 'rural area', 'success', 'support vector machine', 'underserved area', 'vascular abnormality']",NEI,UNIVERSITY OF ILLINOIS AT CHICAGO,R01,2021,351666
"Utilization of Advanced Technologies for the Understanding of Human Structural Birth Defects PROJECT SUMMARY The unifying theme of this proposal is the aim to use state-of-the-art technologies to investigate the basic biology of mammalian organ development and human structural birth defects. Our approach is wide-ranging, and aims to demonstrate how utilization of powerful technologies can inform many disorders. Importantly, this proposal marries a number of strengths of investigators at Seattle Children’s Research Institute and the University of Washington Department of Genome Sciences; specifically, expertise in the diagnosis and understanding of human congenital malformation syndromes and mammalian developmental biology, and the application of powerful new techniques for biological investigation. In Project 1, we propose to use single-cell RNA sequencing (sci-RNA-seq) technology to characterize mid- gestation embryos of mice carrying mutations relevant to human structural birth defects. Essentially, we are proposing to utilize sci-RNA-seq as a phenotype, with which one can annotate changes in expression and cell- type representation during abnormal organogenesis. Ideally, these profiles will be comparable to each other, and can potentially provide insight into fundamental biological pathways that are perturbed when developmentally important genes are lost. In Project 2, we will leverage recent advances in 3D imaging, computer vision and machine-learning to make the morphological characterization of mouse mutants more accurate, quantitative, reproducible and accessible. Progeny from the same lines studied in Project 1 will be harvested at E15.5 and imaged using microCT scanning. We will then employ several different data analysis techniques to identify differences in the tissue volume and shapes in the mutant mice compared to synthetic image constructed from a pool of ‘normative’ samples. The goal of Project 3 is to use novel technologies in prospective cohorts of children with structural birth defects to identify genetic variation not ascertained by current methods. These “hidden” variants include structural rearrangements, as well as DNA mutations that arise post-zygotically and are not present in blood-derived DNA. We will use long-read based DNA and RNA sequencing methods, or deep short-read based DNA sequencing of multiple, non-blood derived tissues, on patients with structural birth defects whose clinical workup has been non-diagnostic. PROJECT NARRATIVE The unifying theme of this proposal is the aim to use state-of-the-art technologies to investigate the basic biology of mammalian organ development and human structural birth defects. Our approach is wide-ranging, and aims to demonstrate how utilization of powerful technologies can inform many disorders. Specific methods we are proposing include: single-cell RNA sequencing and microCT imaging of mid-gestation mutant mouse embryos, and novel methods of genomic and transcriptional analysis to ascertain mutations in children with structural birth defects.",Utilization of Advanced Technologies for the Understanding of Human Structural Birth Defects,10154926,P01HD104435,"['3-Dimensional', 'Affect', 'Alprostadil', 'Biological', 'Biological Models', 'Biology', 'Blood', 'Cells', 'Child', 'Clinical', 'Computer Vision Systems', 'Congenital Abnormality', 'Copy Number Polymorphism', 'DNA', 'DNA Sequence Alteration', 'DNA sequencing', 'Data', 'Data Analyses', 'Data Set', 'Defect', 'Development', 'Developmental Biology', 'Diagnosis', 'Disease', 'Embryo', 'Embryonic Development', 'Epigenetic Process', 'Evaluation', 'Fetus', 'Frequencies', 'Genes', 'Genetic Transcription', 'Genetic Variation', 'Genomics', 'Goals', 'Harvest', 'Human', 'Human Development', 'Image', 'Investigation', 'Knowledge', 'Literature', 'Machine Learning', 'Methods', 'Modeling', 'Modification', 'Morphology', 'Mosaicism', 'Mus', 'Mutant Strains Mice', 'Mutation', 'Organogenesis', 'Orthologous Gene', 'Pathway interactions', 'Patients', 'Phenotype', 'Pregnancy', 'Prospective cohort', 'Proteins', 'Reproducibility', 'Research Institute', 'Research Personnel', 'SHH gene', 'Sampling', 'Scanning', 'Science', 'Shapes', 'Structural Congenital Anomalies', 'Structure', 'Syndrome', 'Techniques', 'Technology', 'Three-Dimensional Image', 'Three-Dimensional Imaging', 'Tissues', 'Training', 'Universities', 'Variant', 'Washington', 'base', 'cell type', 'cohort', 'computational anatomy', 'deep learning', 'exome sequencing', 'genome sciences', 'human disease', 'human population genetics', 'indexing', 'insight', 'microCT', 'morphometry', 'mouse model', 'mutant', 'new technology', 'novel', 'organ growth', 'response', 'single-cell RNA sequencing', 'smoothened signaling pathway', 'transcriptome sequencing']",NICHD,SEATTLE CHILDREN'S HOSPITAL,P01,2021,1603958
"Portable GC detector for breath-based COVID diagnostics Project Summary/Abstract: This proposal has two major goals: 1) Define signature exhaled breath volatile organic compounds (VOCs) to diagnose SARS-CoV-2 infections, and 2) Develop a portable chemical sensing device that can capture and detect exhaled VOCs and includes machine learning algorithms for automated data processing and results interpretation. This project will bring a portable sensor forward into clinical use with the aim of supplementing COVID-19 diagnostics with a reagentless alternative. Breath testing of exhaled VOC biomarkers is a relatively new concept that has the potential to transform healthcare in the US and globally. Our overarching hypothesis is that a miniature breath analysis device can measure signatures of exhaled breath VOCs in real-time and correlate their profile to viral upper respiratory infections such as SARS-CoV-2, even asymptomatically. In Aim #1, we propose a prospective, observational study to analyze breath samples from COVID-19 positive and negative subjects, solely for the purpose of analysis through gold standard GC- MS to define breath VOC biomarkers of infection. We will recruit subjects at two local sites, the UC Davis Medical Center (Sacramento, CA) and VA Northern California Health Care System (Mather, CA), where MPI Dr. Kenyon and Co-Is Drs. Harper and Schivo have joint clinical appointments. Our group has a proven track record to conduct these types of clinical breath studies. In Aim #2, we will develop a portable breath analysis device using our novel miniature differential mobility spectrometry (DMS) detector, coupled with chip-based gas chromatography. DMS is a subset of ion mobility spectrometry and detects VOCs at ambient temperatures and pressures, making it highly appropriate for portable devices. This device would include our custom chip- based preconcentrator, which is packed with a chemical sorbent for extraction of VOCs from breath, and will compare functionality of a compact commercially available GC column to a micro-GC column chip from Deviant, a subcontractor in this work. Individual components of this device have already been developed, and under direction of MPI Prof. Davis, Chair of Mechanical and Aerospace Engineering, a team of research engineers would integrate these pieces together into a single unit. Collaborator Prof. Chuah would guide development of a custom software package for the device with machine learning and artificial intelligence capabilities for automated data processing and interpretation. The device would be placed in the hands of clinicians, who would provide feedback that engineers would immediately incorporate into the device and return to the clinicians for more testing. Under Aim #3, our team would process the GC-MS and GC-DMS data generated in this work, identifying a novel VOC profile for COVID-19 diagnostics. Aim #4 would initiate towards the end of this study to develop both a regulatory pathway & contract manufacturing plan for large scale production and deployment of the device for clinical approval. These efforts are supported by collaborator Dr. Nam Tran, Director of Clinical Pathology & Clinical Chemistry at the UC Davis Medical Center. Project Narrative: In the United States and worldwide, public health experts agree that nations must increase their capacity to test for COVID-19, yet global supplies for testing materials remain scarce. This project would lead to the development of an entirely new type of COVID-19 test, one that could diagnose infections with only a breath sample. Through this proposal, our team would develop a portable device that could identify people with COVID-19 infections by analyzing volatile organic compounds (VOCs) found in exhaled breath.",Portable GC detector for breath-based COVID diagnostics,10266337,U18TR003795,"['2019-nCoV', 'Aerospace Engineering', 'Appointment', 'Artificial Intelligence', 'Automatic Data Processing', 'Benchmarking', 'Biological Markers', 'Breath Tests', 'COVID diagnostic', 'COVID-19', 'COVID-19 diagnosis', 'COVID-19 diagnostic', 'COVID-19 test', 'California', 'Catalogs', 'Chemicals', 'Clinical', 'Clinical Chemistry', 'Clinical Pathology', 'Clinical Trials', 'Communities', 'Computer software', 'Consultations', 'Contact Tracing', 'Contracts', 'Coupled', 'Custom', 'Data', 'Data Analyses', 'Detection', 'Development', 'Devices', 'Diagnosis', 'Diagnostic', 'Diagnostic tests', 'Disease', 'Engineering', 'Environment', 'Exhalation', 'Feedback', 'Fingerprint', 'Flushing', 'Funding', 'Gas Chromatography', 'Gases', 'Goals', 'Gold', 'Healthcare', 'Healthcare Systems', 'Heating', 'Human Resources', 'Individual', 'Industry', 'Infection', 'Intuition', 'Joints', 'Lead', 'Liquid substance', 'Machine Learning', 'Manufacturer Name', 'Maps', 'Mass Spectrum Analysis', 'Materials Testing', 'Mathematics', 'Measurement', 'Measures', 'Mechanics', 'Medical center', 'National Institute of Biomedical Imaging and Bioengineering', 'Observational Study', 'Output', 'Pattern', 'Polymerase Chain Reaction', 'Process', 'Production', 'Public Health', 'Publishing', 'Rapid diagnostics', 'Reagent', 'Regulatory Pathway', 'Research', 'SARS-CoV-2 infection', 'SARS-CoV-2 positive', 'Sampling', 'Sensitivity and Specificity', 'Site', 'Skin', 'Spectrometry', 'Standardization', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Training', 'Translational Research', 'United States', 'United States National Institutes of Health', 'Upper Respiratory Infections', 'Viral', 'Work', 'base', 'biomarker signature', 'clinical care', 'detector', 'deviant', 'differential expression', 'disease transmission', 'graphical user interface', 'instrument', 'intelligent algorithm', 'ion mobility', 'large scale production', 'machine learning algorithm', 'metabolomics', 'novel', 'novel diagnostics', 'pandemic disease', 'portability', 'pressure', 'programs', 'prospective', 'prototype', 'recruit', 'risk mitigation', 'scale up', 'sensor', 'standard of care', 'volatile organic compound']",NCATS,UNIVERSITY OF CALIFORNIA AT DAVIS,U18,2021,975463
"COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data Project Summary/Abstract  The brain imaging community is greatly benefiting from extensive data sharing efforts currently underway. However, there is still a major gap in that much data is still not openly shareable, which we propose to address. In addition, current approaches to data sharing often include significant logistical hurdles both for the investigator sharing the data (e.g. often times multiple data sharing agreements and approvals are required from US and international institutions) as well as for the individual requesting the data (e.g. substantial computational re- sources and time is needed to pool data from large studies with local study data). This needs to change, so that the scientific community can create a venue where data can be collected, managed, widely shared and analyzed while also opening up access to the (many) data sets which are not currently available (see overview on this from our group7). The large amount of existing data requires an approach that can analyze data in a distributed way while (if required) leaving control of the source data with the individual investigator or the data host; this motivates a dynamic, decentralized way of approaching large scale analyses. During the previous funding period, we developed a peer-to-peer system called the Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC). Our system provides an independent, open, no-strings-attached tool that performs analysis on datasets distributed across different locations. Thus, the step of actually aggregating data is avoided, while the strength of large-scale analyses can be retained. During this new phase we respond to the need for advanced algorithms such as linear mixed effects models and deep learning, by proposing to develop decentralized models for these approaches and also implement a fully scalable cloud-based framework with enhanced security features. To achieve this, in Aim 1, we will incorporate the necessary functionality to scale up analyses via the ability to work with either local or commercial private cloud environments, together with advanced visualization, quality control, and privacy and security features. This suite of new functions will open the floodgates for the use of COINSTAC by the larger neuroscience community to enable new discovery and analysis of unprecedented amounts of brain imaging data located throughout the world. We will also improve usability, training materials, engage the community in contributing to the open source code base, and ultimately facilitate the use of COINSTAC's tools for additional science and discovery in a broad range of applications. In Aim 2 we will extend the framework to handle powerful algorithms such as linear mixed effects models and deep learning, and to perform meta-learning for leveraging and updating fit models. And finally, in Aim 3, we will test this new functionality through a partnership with the worldwide ENIGMA addiction group, which is currently not able to perform advanced machine learning analyses on data that cannot be centrally located. We will evaluate the impact of 6 main classes of substances of abuse (e.g. methamphetamines, cocaine, cannabis, nicotine, opiates, alcohol and their combinations) using the new developed functionality. 3 Project Narrative  Hundreds of millions of dollars have been spent on collecting human neuroimaging data for clinical and re- search studies, many of which do not come with subject consent for sharing or contain sensitive data which are not easily shared, such as genetics. Open sharing of raw data, though desirable from the research perspective, and growing rapidly, is not a viable solution for a large number of datasets which have additional privacy risks or IRB concerns. The COINSTAC solution we propose enables us to capture this `missing data' and achieve the same performance as pooling of both open and `closed' repositories by developing privacy preserving versions of advanced and cutting edge algorithms (including linear mixed effects models and deep learning) and incorpo- rating within an easy-to-use and scalable platform which enables distributed computation. 2","COINSTAC 2.0: decentralized, scalable analysis of loosely coupled data",10269008,R01DA040487,"['Address', 'Adoption', 'Agreement', 'Alcohol or Other Drugs use', 'Alcohols', 'Algorithms', 'Atlases', 'Awareness', 'Brain', 'Brain imaging', 'Cannabis', 'Clinical Data', 'Cocaine', 'Communities', 'Consent', 'Consent Forms', 'Coupled', 'Data', 'Data Aggregation', 'Data Pooling', 'Data Set', 'Decentralization', 'Development', 'Environment', 'Family', 'Funding', 'Genetic', 'Genomics', 'Human', 'Individual', 'Informatics', 'Institution', 'Institutional Review Boards', 'International', 'Knowledge', 'Language', 'Learning', 'Legal', 'Link', 'Location', 'Logistics', 'Machine Learning', 'Measures', 'Methamphetamine', 'Modeling', 'Movement', 'Neurosciences', 'Nicotine', 'Opioid', 'Performance', 'Phase', 'Population', 'Positioning Attribute', 'Privacy', 'Privatization', 'Process', 'Public Health', 'Quality Control', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Risk', 'Running', 'Science', 'Security', 'Series', 'Site', 'Source', 'Source Code', 'Statistical Bias', 'Structure', 'Substance of Abuse', 'System', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Visualization', 'Work', 'addiction', 'base', 'cloud based', 'computational platform', 'computerized data processing', 'computerized tools', 'data harmonization', 'data repository', 'data reuse', 'data sharing', 'data visualization', 'deep learning', 'distributed data', 'improved', 'large datasets', 'learning algorithm', 'life-long learning', 'negative affect', 'neuroimaging', 'novel', 'novel strategies', 'open data', 'open source', 'peer', 'privacy preservation', 'repository', 'scale up', 'structural genomics', 'success', 'supervised learning', 'tool', 'unsupervised learning', 'usability', 'virtual']",NIDA,GEORGIA STATE UNIVERSITY,R01,2021,617911
"Adaptive evolutionary inference frameworks for understudied populations using generative neural networks PROJECT SUMMARY In the field of population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, these algorithms rely heavily on simulated datasets, which currently fail to recapitulate the features of diverse natural genomes. Deep neural networks in particular are disconnected from evolutionary modeling, and their results are difficult to interpret in a biological context. In this project, we propose to develop simulation frameworks that automatically adapt to any population or species. The resulting customized synthetic datasets will be used to train neural networks that quantify the unique evolutionary histories of understudied human groups. By including genealogical and epigenetic information as auxiliary input, we will be able to link predictions back to genomic features. Our results will enable us to estimate the interactions between local phenomena such as natural selection, mutation patterns, and recombination hotspots. Taken together, outcomes from our work will allow us to create a detailed model evolutionary of processes, both along the genome and across human populations. PROJECT NARRATIVE In population genetics, machine learning methods are emerging as promising frameworks for understanding evolution. However, it is difficult to apply these algorithms to understudied populations, as they are reliant on custom simulations, difficult to interpret, and disconnected from evolutionary modeling. The goals of this project are to develop simulation frameworks that automatically adapt to diverse datasets, allowing us to study evolutionary forces along the genome and across human populations.",Adaptive evolutionary inference frameworks for understudied populations using generative neural networks,10114449,R15HG011528,"['Admixture', 'African', 'Algorithms', 'Area', 'Back', 'Biological', 'Biological Process', 'Chromatin', 'Classification', 'Custom', 'Data', 'Data Set', 'Decision Trees', 'Epigenetic Process', 'European', 'Event', 'Evolution', 'Exposure to', 'Genealogy', 'Genes', 'Genetic Recombination', 'Genome', 'Genomic Segment', 'Genomics', 'Geography', 'Goals', 'Graph', 'Human', 'Human Genetics', 'Image', 'Individual', 'Industry', 'Internships', 'Learning', 'Link', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Mutation', 'Natural Selections', 'Outcome', 'Pattern', 'Population', 'Population Genetics', 'Population Sizes', 'Process', 'Recording of previous events', 'Research', 'Signal Transduction', 'Students', 'Training', 'Trees', 'Validation', 'Visualization', 'Work', 'automated algorithm', 'base', 'biobank', 'computer science', 'convolutional neural network', 'deep neural network', 'epigenetic marker', 'flexibility', 'health care settings', 'machine learning algorithm', 'machine learning method', 'methylation pattern', 'migration', 'neural network', 'simulation', 'single cell sequencing', 'statistics', 'theories', 'undergraduate student']",NHGRI,HAVERFORD COLLEGE,R15,2021,432494
"Optical design and the development of high accuracy automated tick classification using computer vision Abstract. The incidence of US tick-borne diseases has more than doubled in the last two decades. Due to lack of effective vaccines for tick-borne diseases, prevention of tick bites remains the primary focus of disease mitigation. Tick vector surveillance—monitoring an area to understand tick species composition, abundance, and spatial distribution—is key to providing the public with accurate and up-to-date information when they are in areas of high risk, and enabling precision vector control when necessary. Despite the importance of vector surveillance, current practices are highly resource intensive and require significant labor and time to collect and identify vector specimens. Acarologist or field taxonomist expertise is a limited resource required for tick identification, creating a significant capability barrier for national tick surveillance practice. While mobile applications to facilitate passive surveillance and reporting of human-tick encounters have grown in popularity, variable image quality, limited engagement, and scientist misidentification of rare, invasive, or morphologically similar tick species hinder the scalability of this approach. No automated solutions exist to build tick identification capacity. We seek to develop the first imaging and automated identification system capable of instantaneously and accurately identifying the top nine tick vectors in the US. This proposal will first characterize the optical requirements necessary to image diagnostic morphological features associated with adult ticks and develop a standardized imaging platform for tick identification. This will enable the development of a high-quality tick image dataset in partnership with the Walter Reed Biosystems Unit (WRBU) which will be used to train high-accuracy computer vision models for tick species and sex identification. Ultimately the approaches developed here will enable new tick identification tools for both the lab and citizen scientists; allowing vector surveillance managers to leverage image recognition in a practical system that will increase capacity and capability for biosurveillance, and equipping citizen scientists with improved tools to identify tick species during a human-tick encounter. Project Narrative. Despite the importance of tick vector surveillance for disease prevention, current practices to collect and identify specimens are resource intensive, limiting the quality and quantity of the data informing control efforts. Here we propose the determination of optical requirements for visualization of diagnostic features of the top nine US tick vectors, and the development of high-accuracy computer vision algorithms for the identification of tick species and sex for use in a standardized optical configuration. The high-accuracy tick classification system developed through this proposal promises to expand capacity and capability for tick vector surveillance.",Optical design and the development of high accuracy automated tick classification using computer vision,10325667,R43AI162425,"['Adult', 'Agreement', 'Algorithm Design', 'Algorithms', 'Anatomy', 'Area', 'Artificial Intelligence', 'Car Phone', 'Cellular Phone', 'Classification', 'Collaborations', 'Computer Vision Systems', 'Culicidae', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnostic', 'Diagnostic Imaging', 'Disease', 'Disease Surveillance', 'Disease Vectors', 'Future', 'Goals', 'Grain', 'Human', 'Image', 'Incidence', 'Insecta', 'Larva', 'Learning', 'Leg', 'Life', 'Lighting', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Nymph', 'Optics', 'Phase', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Resolution', 'Resources', 'Scientist', 'Spatial Distribution', 'Specimen', 'Standardization', 'Surveillance Methods', 'System', 'Telephone', 'Testing', 'Tick-Borne Diseases', 'Ticks', 'Time', 'Training', 'Vaccines', 'Validation', 'Visual', 'Visualization', 'Work', 'base', 'citizen science', 'convolutional neural network', 'design', 'detection method', 'disorder prevention', 'field study', 'flexibility', 'high resolution imaging', 'high risk', 'human disease', 'imaging platform', 'imaging system', 'improved', 'insight', 'intelligent algorithm', 'interest', 'mobile application', 'novel', 'sample collection', 'sex', 'tick bite', 'tool', 'validation studies', 'vector', 'vector control', 'vector tick']",NIAID,"VECTECH, LLC",R43,2021,295705
"Copper-mediated Radiofluorination: from Proof-of-Concept to Clinical Impact Abstract: Radiotracers containing [18F]-labeled electron-rich aromatic rings are among the most highly sought- after PET imaging agents but have been historically challenging to synthesize. Recent efforts have sought to improve the late-stage labeling of (hetero)arenes with [18F]fluoride. In particular, transition metal-mediated reactions using high molar activity [18F]fluoride have changed the way radiochemists form C–18F bonds, and copper-mediated radiofluorination (CMRF) has proven one of the most versatile of approaches. In the previous award, we reported 10 new CMRF reactions, validated them for Good Manufacturing Practice (GMP), and used them to synthesize FDA-approved clinical doses. However, despite many successes, several key challenges remain for the widespread clinical application of CMRF: (a) many important organic scaffolds are incompatible with existing CMRF processes, (b) yields of automated CMRF methods are typically moderate and thus unsuitable for commercial distribution, and (c) disposable cassette technologies are not available for CMRF on automated radiosynthesizers, limiting radiotracer production for routine clinical use. All of these challenges will be addressed in this renewal proposal. The overall objective is to develop robust methods for clinical production of diverse PET radiotracers. Our central hypothesis is that CMRF is uniquely positioned to enable us to achieve this goal. The proposed research will identify new reactions to radiofluorinate scaffolds that are incompatible with existing CMRF (Aim 1), use cutting edge machine learning techniques to improve automated CMRF yields (Aim 2), and develop cassette technologies for reliable GMP production of clinical radiotracers using CMRF (Aim 3). The research is significant because it entails development of methods for radiolabeling bioactive molecules containing functionality that is incompatible (or low yielding) with existing CMRF (heterocycles like pyridine and morpholine, drug molecules like GW405833), as well as optimized automated methods and cassettes for radiotracers that have been challenging to access for decades (e.g. [18F]FDOPA). The viability of the proposed efforts is supported by extensive preliminary results that provide groundwork for the exciting new research directions. Our team has been collaborating for 7 years and our expertise in transition metal catalysis (Sanford), radiochemistry (Scott), and machine learning (Doyle) uniquely positions us to accomplish the proposed research. The project goals will be accomplished through a variety of innovations including: (1) developing methods for labeling challenging electron-rich (hetero)arenes from new precursors (C–H bonds, aryl halides), (2) the first application of machine learning to radiochemistry, and (3) development of automated cassettes for conducting CMRF using the newest generation of radiosynthesizers designed for plug-and-play production. Overall, this project will deliver multiple new methods for synthesizing 18F-labeled radiotracers that are inaccessible using existing methods, and validated clinical syntheses of important radiotracers. All of these deliverables will expand the utility of PET imaging for the detection, treatment, and prevention of disease. Project Narrative: Positron emission tomography (PET) imaging is a non-invasive molecular imaging technique that allows real-time in vivo monitoring of physiological processes via administration of a radiotracer (a molecule tagged with a PET radioisotope) to a patient. Currently, PET imaging finds application in drug discovery, disease diagnosis and monitoring, and personalized medicine. Approximately 2 million PET scans are conducted annually, and there is significant room for further growth. However, the impact of PET cannot be fully realized without both new synthetic methods for the assembly of radiotracers as well as the translation of these synthesis methods to routine clinical production. The overall objective of our research is to develop new chemistry for preparing currently inaccessible PET radiotracers, use machine learning techniques to optimize production yields with these new methods, and introduce automated cassette technology that will allow easy and confident use of this new chemistry to produce PET radiotracers for clinical trials and routine standard of care.",Copper-mediated Radiofluorination: from Proof-of-Concept to Clinical Impact,10209444,R01EB021155,"['Address', 'Adoption', 'Automation', 'Award', 'Basic Science', 'Caring', 'Catalysis', 'Chemistry', 'Clinical', 'Clinical Trials', 'Copper', 'Data', 'Data Set', 'Development', 'Dose', 'Electrons', 'Emission-Computed Tomography', 'FDA approved', 'Fluorides', 'Fluorine', 'Generations', 'Goals', 'Grant', 'Growth', 'Hydrogen Bonding', 'Image Enhancement', 'Imaging Techniques', 'Label', 'Levodopa', 'Machine Learning', 'Manuals', 'Mediating', 'Mediator of activation protein', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Multi-Institutional Clinical Trial', 'Nuclear', 'Paper', 'Patients', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Pharmacy facility', 'Physiological Processes', 'Play', 'Positioning Attribute', 'Positron-Emission Tomography', 'Process', 'Production', 'Publishing', 'Radiochemistry', 'Radioisotopes', 'Radiolabeled', 'Reaction', 'Reporting', 'Reproducibility', 'Research', 'Side', 'Site', 'Techniques', 'Technology', 'Time', 'Transition Elements', 'Translating', 'Translations', 'Validation', 'aryl halide', 'base', 'clinical application', 'cost', 'design', 'disease diagnosis', 'disorder prevention', 'drug discovery', 'imaging agent', 'imaging detection', 'improved', 'in vivo monitoring', 'innovation', 'machine learning algorithm', 'method development', 'molecular imaging', 'morpholine', 'neural network', 'personalized medicine', 'preclinical imaging', 'predictive modeling', 'pyridine', 'radiotracer', 'random forest', 'scaffold', 'standard of care', 'success']",NIBIB,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,377343
"A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment  Unhealthy diet is strongly linked to risks of chronic diseases, such as cardiovascular diseases, diabetes and certain types of cancer. The Global Burden of Disease Study has found that, among the top 17 risk factors, poor diet is overwhelmingly the No. 1 risk factor for human diseases. Despite the strong connection between diet and health, unhealthy foods with large portion sizes are widely consumed. Currently, 68.5% of U.S. adults are overweight, among the highest in developed countries. The recent decline in U.S. life expectancy sent another alarming signal about the general health of the American people. Understanding how the diet-related risk factors affect people’s health and finding effective ways to empower them in improving lifestyle habits are among the most important tasks in public health. Unfortunately, dietary assessment in real-world settings has been exceedingly complex and inaccurate to implement. Technology is needed that allows researchers to assess dietary intake easily and accurately in real world settings so that effective intervention to manage obesity and related chronic diseases can be developed. We propose a biomedical engineering project to address the dietary assessment problem, taking advantage of advanced mathematical modeling, wearable electronics and artificial intelligence.  Our research team has been improving the ability to assess diet for over a decade. We have designed the eButton, a small wearable device pinned on clothes in front of the chest, capable of collecting image-based dietary data objectively and passively (i.e., without depending on subject’s self-report or volitional operation of the device). We have also developed algorithms to compute food volumes and nutrients from images. Since the eButton was developed, it has been used by many researchers in the U.S. and other countries for objective and passive diet-intake studies in both adults and children.  Despite the past successes, there have been two lingering critical problems associated with the objective and passive dietary assessment using wearable devices: 1) substantial manual efforts are required for researchers to visually examine image data to identify foods and estimate their volumes (portion sizes), and 2) there are privacy concerns about researchers’ viewing of participants’ real-life images. Although solving these problems could enable the eButton and other wearable devices for large-scale diet-intake studies, we were not able to find effective solutions until recently when Artificial intelligence (AI) emerged. Advanced AI systems, especially those based on deep learning, can be trained by large amounts of labeled data to produce results comparable or even superior to those produced by human in numerous fields of applications. AI technology is also a powerful tool for dietary assessment, potentially providing an ideal solution to the two previously mentioned problems. We thus propose to develop a human-mimetic AI system to recognize foods from images, estimate portion sizes, and find energy and nutrient values from a database in a fully automatic process. Using the AI approach, there will be no need for researchers to view participants’ real-life images, and the AI system well-respects individuals’ privacy because it is trained to recognizes human foods only, nothing else.  Currently, the performances of existing AI systems are limited by the extensive variety and high variability of human foods, insufficient training data, and difficulty in finding appropriate nutritional information from food databases. In this application, we propose a new strategy to personalize the AI system for each research participant using an advanced mathematical model of personal food choices. With this personalization step, the dimensionality of our envisioned AI system can be reduced drastically, and our goal of automatic, objective and passive dietary assessment can be reached realistically. We also propose to improve the electronic hardware and develop a biomimetic camera to enlarge the field of view for the eButton. Finally, we will conduct a thorough evaluation of the personalized AI system in real-world settings using human subjects. This research aims to apply advanced mathematical modeling, wearable electronics and artificial intelligence to evaluate individual’s energy and nutrient intake automatically and objectively.","A Human-Mimetic AI System for Automatic, Passive and Objective Dietary Assessment",10111099,R01DK127310,"['Address', 'Adopted', 'Adult', 'Affect', 'Algorithms', 'American', 'Artificial Intelligence', 'Biomedical Engineering', 'Biomimetics', 'Cardiovascular Diseases', 'Cellular Phone', 'Centers for Disease Control and Prevention (U.S.)', 'Cessation of life', 'Chest', 'Child', 'Chronic Disease', 'Complex', 'Consumption', 'Country', 'Data', 'Databases', 'Developed Countries', 'Devices', 'Diabetes Mellitus', 'Diet', 'Dietary Assessment', 'Dietary intake', 'Dietetics', 'Dimensions', 'Eating', 'Evaluation', 'Expert Systems', 'Eye', 'Feedback', 'Food', 'Food Energy', 'Future', 'Goals', 'Gold', 'Habits', 'Health', 'Health care facility', 'Healthcare', 'Heart Diseases', 'Human', 'Image', 'Individual', 'Intake', 'Label', 'Life', 'Life Expectancy', 'Life Style', 'Link', 'Malignant Neoplasms', 'Manuals', 'Modeling', 'Nutrient', 'Nutritional', 'Nutritional Science', 'Obesity', 'Output', 'Participant', 'Patient Self-Report', 'Performance', 'Persons', 'Play', 'Privacy', 'Problem Solving', 'Process', 'Public Health', 'Records', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Risk Factors', 'Role', 'Shapes', 'Signal Transduction', 'System', 'Technology', 'Training', 'Unhealthy Diet', 'Update', 'Volition', 'base', 'burden of illness', 'cancer type', 'computerized data processing', 'convolutional neural network', 'deep learning', 'design', 'dietary', 'effective intervention', 'field study', 'good diet', 'human disease', 'human subject', 'improved', 'infancy', 'intelligent algorithm', 'mathematical model', 'mimetics', 'neural network', 'obesity management', 'operation', 'overweight adults', 'robotic system', 'success', 'tool', 'validation studies', 'wearable device']",NIDDK,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,657303
"SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community Physics-based simulations provide a powerful framework for understanding biological form and function. They harmonize heterogeneous experimental data with real-world physical constraints, helping researchers understand biological systems as they engineer novel drugs, new diagnostics, medical devices, and surgical interventions. The rise in new sensors and simulation tools is generating an increasing amount of data, but this data is often inaccessible, preventing reuse and limiting scientific progress. In 2005, we launched SimTK, a website to develop and share biosimulation tools, models, and data, to address these issues. SimTK now supports 62,000+ researchers globally and 950+ projects. Members use it to meet their grants’ data sharing responsibilities; experiment with new ways of collaborating; and build communities around their datasets and tools. However, challenges remain: many researchers still do not share their digital assets due to the time needed to prepare, document, and maintain those assets, and since SimTK hosts a growing number of diverse digital assets, the site now also faces the challenge of making these assets discoverable and reusable. Thus, we propose a plan to extend SimTK and implement new solutions to promote scientific data sharing and reuse. First, we will maintain the reliable, user-friendly foundation upon which SimTK is built, continuing to provide the excellent support our members expect and supporting the site’s existing features for sharing and building communities. Second, we will implement methods to establish a culture of model and data sharing in the biomechanics community. We will encourage researchers to adopt new habits, making sharing part of their workflow, by enabling the software and systems they use to automatically upload models and data to SimTK via an application programming interface (API) and by recruiting leading researchers in the community to serve as beta testers and role models. Third, we will create tools to easily replicate and extend biomechanics simulations. Containers and cloud computing services allow researchers to capture and share a snapshot of their computing environment, enabling unprecedented fidelity in sharing. We will integrate these technologies into SimTK and provide custom, easy-to-use interfaces to replicate and extend simulation studies. Lastly, we will develop a metadata standard for models and data for the biomechanics community, increasing reusability and discoverability of the rich set of resources shared on SimTK. We will use the new standard on SimTK and fill in the metadata fields automatically using natural language processing and machine learning, minimizing the burden and inaccuracies of manual metadata entry. We will evaluate our success in achieving these aims by tracking the number of assets shared and the frequency they are used as a springboard to new research. These changes will accelerate biomechanics research and provide new tools to increase the reusability and impact of shared resources. By lowering barriers to data sharing in the biosimulation community, SimTK will continue to serve as a model for how to create national infrastructure for scientific subdisciplines. SimTK is a vibrant hub for the development and sharing of simulation software, data, and models of biological structures and processes. SimTK-based resources are being used to design medical devices and drugs, to generate new diagnostics, to create surgical interventions, and to provide insights into biology. The proposed enhancements to SimTK will accelerate progress in the field by lowering barriers to and standardizing data and model sharing, thus 1) increasing the quantity and also, importantly, the quality of resources that researchers share and 2) enabling others to reproduce and build on the wealth of past biomechanics research studies.",SimTK: An Ecosystem for Data and Model Sharing in the Biomechanics Community,10085652,R01GM124443,"['Achievement', 'Address', 'Adopted', 'Biological', 'Biological Models', 'Biology', 'Biomechanics', 'Biophysics', 'Cloud Computing', 'Code', 'Communities', 'Computer software', 'Consumption', 'Custom', 'Data', 'Data Files', 'Data Set', 'Development', 'Documentation', 'Engineering', 'Ensure', 'Environment', 'Explosion', 'Face', 'Foundations', 'Frequencies', 'Goals', 'Grant', 'Habits', 'Infrastructure', 'Letters', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical', 'Medical Device', 'Medical Device Designs', 'Metadata', 'Methods', 'Modeling', 'Natural Language Processing', 'Operative Surgical Procedures', 'Pharmaceutical Preparations', 'Physics', 'Process', 'Research', 'Research Personnel', 'Resource Sharing', 'Resources', 'Security', 'Services', 'Site', 'Structure', 'System', 'Technology', 'Time', 'Update', 'Work', 'application programming interface', 'base', 'biological systems', 'biomechanical model', 'community building', 'complex biological systems', 'data access', 'data cleaning', 'data ecosystem', 'data reuse', 'data sharing', 'data standards', 'digital', 'experience', 'experimental study', 'insight', 'member', 'metadata standards', 'new technology', 'novel diagnostics', 'novel therapeutics', 'prevent', 'recruit', 'research study', 'response', 'role model', 'sensor', 'simulation', 'simulation software', 'software systems', 'success', 'tool', 'user-friendly', 'web site']",NIGMS,STANFORD UNIVERSITY,R01,2021,489919
"Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit SUMMARY  Many of the estimated four million adults in the U.S. with severe speech and physical impairments (SSPI) resulting from neurodevelopmental or neurodegenerative diseases cannot rely on current assistive technologies (AT) for communication. During a single day, or as their disease progresses, they may transition from one access technology to another due to fatigue, medications, changing physical status, or progressive motor dysfunction. There are currently no clinical or AT solutions that adapt to the multiple, dynamic access needs of these individuals, leaving many people poorly served. This competitive renewal, called BCI-FIT (Brain Computer Interface-Functional Implementation Toolkit) adds to our innovative multidisciplinary translational research conducted over the past 11 years for the advancement of science related to non-invasive BCIs for communication for these clinical populations. BCI-FIT relies on active inference and transfer learning to customize a completely adaptive intent estimation classifier to each user's multiple modality signals in real-time. The BCI-FIT acronym has many implications: our BCI fits to each user's brain signals; to the environment, offering relevant personal language; to the user's internal states, adjusting signals based on drowsiness, medications, physical and cognitive abilities; and to users' learning patterns from BCI introduction to expert use.  Three specific aims are proposed: (1) Develop and evaluate methods for optimizing system and user performance with on-line, robust adaptation of multi-modal signal models. (2) Develop and evaluate methods for efficient user intent inference through active querying. (3) Integrate language interaction and letter/word supplementation as input modalities in real-time BCI use. Four single case experimental research designs will evaluate both user performance and technology performance for functional communication with 35 participants with SSPI in the community, and 30 healthy controls for preliminary testing. The same dependent variables will be tested in all experiments: typing accuracy (correct character selections divided by total character selections), information transfer rate (ITR), typing speed (correct characters/minute), and user experience (UX) questionnaire responses about comfort, workload, and satisfaction. Our goal is to establish individualized recommendations for each user based on a combination of clinical and machine expertise. The clinical expertise plus user feedback added to active sensor fusion and reinforcement learning for intent inference will produce optimized multi-modal BCIs for each end-user that can adjust to short- and long-term fluctuating function. Our research is conducted by four sub-teams who have collaborated successfully to implement translational science: Electrical/computer engineering; Neurophysiology and systems science; Natural language processing; and Clinical rehabilitation. The project is grounded in solid machine learning approaches with models of participatory action research and AAC participation. This project will improve technologies and BCI technical capabilities, demonstrate BCI implementation paradigms and clinical guidelines for people with severe disabilities. PROJECT NARRATIVE The populations of US citizens with severe speech and physical impairments secondary to neurodevelopmental and neurodegenerative diseases are increasing as medical technologies advance and successfully support life. These individuals with limited to no movement could potentially contribute to their medical decision making, informed consent, and daily caregiving if they had faster, more reliable means that adapt to their best access methods in communication technologies, as proposed in BCI-FIT. This project implements the translation of basic computer science and engineering into clinical care, supporting the proposed NIH Roadmap and public health initiatives.",Optimizing BCI-FIT: Brain Computer Interface - Functional Implementation Toolkit,10213005,R01DC009834,"['Adult', 'Attention', 'Behavioral', 'Brain', 'Calibration', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Clinical assessments', 'Cognition', 'Cognitive', 'Communication', 'Communities', 'Computers', 'Custom', 'Data', 'Decision Making', 'Disease', 'Drowsiness', 'Electroencephalography', 'Engineering', 'Environment', 'Eye Movements', 'Fatigue', 'Feedback', 'Goals', 'Guidelines', 'Head Movements', 'Impairment', 'Individual', 'Informed Consent', 'Knowledge', 'Language', 'Learning', 'Letters', 'Life', 'Locked-In Syndrome', 'Machine Learning', 'Measures', 'Medical', 'Medical Technology', 'Methods', 'Modality', 'Modeling', 'Motor Skills', 'Movement', 'Muscle', 'Natural Language Processing', 'Neurodegenerative Disorders', 'Participant', 'Partner Communications', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Policies', 'Population', 'Protocols documentation', 'Psychological Transfer', 'Psychological reinforcement', 'Public Health', 'Questionnaires', 'Recommendation', 'Rehabilitation therapy', 'Research', 'Research Design', 'Role', 'Science', 'Secondary to', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Solid', 'Source', 'Speech', 'Speed', 'Supplementation', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Translational Research', 'Translations', 'United States National Institutes of Health', 'Vocabulary', 'Workload', 'acronyms', 'alternative communication', 'base', 'brain computer interface', 'caregiving', 'clinical care', 'clinical implementation', 'cognitive ability', 'community based participatory research', 'computer science', 'disability', 'experience', 'experimental study', 'improved', 'innovation', 'learning strategy', 'motor disorder', 'multidisciplinary', 'multimodality', 'neurophysiology', 'phrases', 'residence', 'response', 'satisfaction', 'sensor', 'signal processing', 'simulation', 'spelling', 'theories', 'visual tracking']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,915264
"Learning to learn in structural biology with deep neural networks Project Summary/Abstract  Deep learning is gaining traction across many elds as a powerful tool. In medicine, there have been recent successes in drug design, predicting protein structure, and in functional genomics. These successes have thus far been in areas where there are hundreds of thousands of data points and deep learning in medicine is still limited by lack of large homongeous datasets.  This proposal focuses on applying a new kind of deep learning called meta-learning that mimics the human-like ability to learn from few examples. The PI will establish a sustainable research program on meta-learning by developing benchmark problems and datasets. The PI will further explore meta-learning speci cally on peptide-protein structure and NMR spectra prediction. Due to the imperative need for interpretability when using deep learning in medicine, a strong component will be connecting biophysical modeling with the deep learning models.  The outcome of this work will be a demonstrated new approach to deep learning that can work with little data. The PI will bring these research ideas together to design peptides that can bind to intrinsically disordred proteins, a challenging but important task for curing neurodegenerative diseases. This will be accomplished through meta-learning, molecular simulation, and iterative peptide design. Project Narrative  Deep learning is a technique from arti cial intelligence that has driven many high-pro le break- throughs in recognizing objects in images, translating human languages, and playing games like Chess and Go. Its use is medicine is currently limited by deep learning's need for large amounts of data and its lack of interpretability. This researh plan works towards solving these challenges and applies interpretable deep learning to designing new therapeutics.",Learning to learn in structural biology with deep neural networks,10256071,R35GM137966,"['Area', 'Benchmarking', 'Binding', 'Data', 'Data Set', 'Drug Design', 'Human', 'Image', 'Intelligence', 'Language', 'Learning', 'Medicine', 'Modeling', 'Molecular', 'Neurodegenerative Disorders', 'Outcome', 'Peptides', 'Play', 'Proteins', 'Research', 'Techniques', 'Traction', 'Translating', 'Work', 'biophysical model', 'deep learning', 'deep neural network', 'design', 'functional genomics', 'novel strategies', 'novel therapeutics', 'programs', 'protein structure', 'simulation', 'structural biology', 'success', 'tool']",NIGMS,UNIVERSITY OF ROCHESTER,R35,2021,339505
"Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues Summary Fast, accurate, and scalable testing has been recognized unanimously as crucial for mitigating the impact of COVID-19 and future pandemics. We propose a technology that allows rapid (~2 minutes) testing for SARS CoV-2. Our technology combines novel label-free imaging and dedicated deep-learning algorithms to detect and classify viral populations in exhaled air. If successful, this project will result in a device based on quantitative phase imaging and integrated AI tools, which will detect the unlabeled virus acquired by the patient’s breath condensed on a microscope slide. Toward this goal, we will advance Spatial Light Interference Microscopy (SLIM), an ultrasensitive label-free imaging technique, proven to measure structures down to the sub-nanometer scale. SLIM was developed in the PI’s Lab at UIUC, its original publication received 490 citations to date, and has been commercialized by Phi Optics (Research Park, UIUC), with sales across the world in both academia and industry. Applying the computed fluorescence maps back to the QPI data, we propose to measure nanoscale features of viral particles, with high specificity, minimal preparation time, and independent of clinical infrastructure. As a result, the new technology will eventually be ideal for point-of-care settings, surveillance screening and as a home monitoring device. We anticipate that our approach will be scalable to other viruses, with new imaging and training data. Narrative We propose a breath test using label-free imaging and AI: an individual exhales on a microscope slide, which is fed into a SLIM microscope equipped with a computer that runs deep-learning pre-trained algorithms for SARS CoV-2 identification. The result is displayed in real time, with the entire procedure requiring < 2min.",Quantitative histopathology for cancer prognosis using quantitative phase imaging on stained tissues,10249738,R01CA238191,"['2019-nCoV', 'Academia', 'Air', 'Artificial Intelligence', 'Back', 'Bedside Testings', 'Biology', 'Breath Tests', 'COVID-19', 'COVID-19 testing', 'Cancer Prognosis', 'Chemicals', 'Classification', 'Clinical', 'Clinical Microbiology', 'Computer software', 'Computers', 'Data', 'Devices', 'Exhalation', 'Fluorescence', 'Fluorescence Microscopy', 'Future', 'Glass', 'Goals', 'Histopathology', 'Home environment', 'Image', 'Imaging Device', 'Imaging Techniques', 'Individual', 'Industry', 'Influenza', 'Infrastructure', 'Interference Microscopy', 'Label', 'Light', 'Maps', 'Measures', 'Microscope', 'Modification', 'Morphologic artifacts', 'Nature', 'Optics', 'Patients', 'Performance', 'Phase', 'Photobleaching', 'Phototoxicity', 'Population', 'Preparation', 'Procedures', 'Publications', 'Research', 'Running', 'Sales', 'Slide', 'Specificity', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Tissue Stains', 'Training', 'Viral', 'Virus', 'Virus Diseases', 'algorithm training', 'base', 'clinical infrastructure', 'coronavirus disease', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'imaging system', 'instrument', 'monitoring device', 'nanoscale', 'new technology', 'novel', 'operation', 'pandemic disease', 'particle', 'point of care', 'prototype', 'screening', 'tool']",NCI,UNIVERSITY OF ILLINOIS AT URBANA-CHAMPAIGN,R01,2021,576268
"Therapeutic potential of vagal neurostimulation to reduce food intake Obesity affects almost 40% percent of US adults and is associated with high levels of comorbidities, including cancer, cardiovascular disease, and diabetes. Although effective treatments with minimal side effects are lacking, vagus nerve stimulation (VNS) can reduce body weight and suppress feeding behavior. There is little insight, however, into its mechanism and it is unclear whether VNS effects on feeding and body weight result from non-specific side effects, such as nausea. The current application directly addresses these issues by assessing gastrointestinal (GI) myoelectric changes as a potential mechanism for effects of VNS on feeding behavior, while comparing these responses to emetic activation. We plan to accomplish this by using a ferret model, which is a gold-standard for studying emesis, vagus nerve, and GI physiology. We will test the hypothesis that electrical stimulation of the vagus nerve can reduce food intake without triggering indicators of nausea, such as disrupted GI myoelectric responses, retching, and vomiting. We will complete three Aims. Aim 1: Define the individualized GI myoelectric patterns during feeding behavior using machine learning classification. Animals will be implanted with planar electrodes attached to the GI serosal surface from proximal gastric fundus to distal duodenum. We will use machine learning to classify GI myoelectric patterns of meal consumption compared to emetic-related states, including those elicited by intragastric emetine and high amplitude and frequency VNS known to trigger emesis. Aim 2: Test the efficacy of abdominal VNS on reducing meal size without triggering disruptions of GI myoelectric responses, retching, and emesis. Animals will be assessed for effects of abdominal VNS using a variety of stimulus parameters on feeding behavior and multi-site GI myoelectric recordings. Aim 3: Determine the efficacy of cervical VNS in controlling meal size without producing off-target effects (disruptions of GI myoelectric responses, retching, emesis, changes in heart rate, or blood pressure). We will test the impact of cervical VNS parameters on feeding behavior, GI myoelectric responses, retching, emesis, hear rate variability, and blood pressure. Our approach is innovative because we will use machine learning classification to detect individualized GI myoelectric response patterns in an awake free-moving animal for comparing therapeutic and off-target effects of VNS on feeding, GI activity, emesis, and cardiovascular function. This planned research is significant because VNS therapy can potentially provide a frontline treatment option for patients with high levels of obesity refractory to behavioral or pharmacological therapy, which unlike other surgical interventions for weight loss, such as gastric bypass, is potentially tunable and reversible by changing stimulation parameters, switching the device off, or complete removal. Obesity affects almost 40% percent of US adults, is associated with type 2 diabetes, cardiovascular disease, and cancer, and has a health-care cost that could total nearly one trillion US dollars by 2030. The current project is designed to test vagus nerve stimulation to reduce food intake, while limiting adverse effects, such as nausea, vomiting, and disrupted gastrointestinal function. Our proposed research is relevant to the NIH’s plan to support the design and testing of new interventions for achieving and maintaining a healthy weight (Strategic Plan for NIH Obesity Research).",Therapeutic potential of vagal neurostimulation to reduce food intake,10207620,R01DK121703,"['Abdomen', 'Address', 'Adult', 'Adverse effects', 'Affect', 'Anatomy', 'Animals', 'Behavioral', 'Blood Pressure', 'Body Weight', 'Body Weight decreased', 'Cardiovascular Diseases', 'Cardiovascular Physiology', 'Cardiovascular system', 'Cervical', 'Chemicals', 'Chronic', 'Classification', 'Consumption', 'Data', 'Devices', 'Diabetes Mellitus', 'Distal', 'Duodenum', 'Eating', 'Electric Stimulation', 'Electrodes', 'Emetics', 'Emetine', 'Event', 'Excision', 'FDA approved', 'Feeding behaviors', 'Ferrets', 'Fiber', 'Frequencies', 'Gastric Bypass', 'Gastrointestinal Motility', 'Gastrointestinal Physiology', 'Gastrointestinal tract structure', 'Goals', 'Gold', 'Health Care Costs', 'Hearing', 'Heart Rate', 'Implant', 'Individual', 'Intervention', 'Laboratory Rat', 'Laboratory mice', 'Liquid substance', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Modeling', 'Nausea', 'Nausea and Vomiting', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pharmacology', 'Phenotype', 'Physiological', 'Rattus', 'Refractory', 'Reporting', 'Research', 'Rodent Model', 'Satiation', 'Sensory', 'Signal Transduction', 'Site', 'Sleep', 'Stimulus', 'Stomach', 'Strategic Planning', 'Surface', 'Testing', 'Therapeutic', 'Training', 'United States National Institutes of Health', 'Upper digestive tract structure', 'Vagus nerve structure', 'Vomiting', 'awake', 'behavioral pharmacology', 'comorbidity', 'design', 'effective therapy', 'effectiveness evaluation', 'efficacy testing', 'experimental study', 'feeding', 'gastric fundus', 'gastrointestinal', 'gastrointestinal function', 'healthy weight', 'heart rate variability', 'indexing', 'innovation', 'insight', 'learning classifier', 'machine learning algorithm', 'obesity treatment', 'personalized medicine', 'pre-clinical', 'predicting response', 'recruit', 'reduced food intake', 'response', 'side effect', 'support vector machine', 'therapeutic target', 'vagus nerve stimulation', 'weight loss intervention']",NIDDK,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,R01,2021,482164
"A deep learning platform to evaluate the reliability of scientific claims by citation analysis. The opioid epidemic in the United States has been traced to a 1980 letter reporting in the prestigious New England Journal of Medicine that synthetic opioids are not addictive. A belated citation analysis led the journal to append this letter with a warning this letter has been “heavily and uncritically cited” as evidence that addiction is rare with opioid therapy.” This epidemic is but one example of how unreliable and uncritically cited scientific claims can affect public health, as studies from industry report that a substantial part of biomedical reports cannot be independently verified. Yet, there is no publicly available resource or indicator to determine how reliable a scientific claim is without becoming an expert on the subject or retaining one. The total citation count, the commonly used measure, is inherently a poor proxy for research quality because confirming and refuting citations are counted as equal, while the prestige of the journal is not a guarantee that a claim published there is true. The lack of indicators for the veracity of reported claims costs the public, businesses, and governments, billions of dollars per year. We have developed a prototype that automatically classifies statements citing a scientific claim into three classes: those that provide supporting or contradicting evidence, or merely mention the claim. This unique capability enables scite users to analyze the reliability of scientific claims at an unprecedented scale and speed, helping them to make better-informed decisions. The prototype has attracted potential customers among top biotechnology and pharmaceutical companies, research institutions, academia, and academic publishers. We propose to conduct research that will refine scite into an MVP by optimizing prototype efficiency and accuracy until they reach feasible milestones, and will refine the product-market fit in our beachhead market, academic publishing, whose influence on the integrity and reliability of research is difficult to overestimate. We propose to develop a platform that can be used to evaluate the reliability of scientific claims. Our deep learning model, combined with a network of experts, automatically classifies citations as supporting, contradicting, or mentioning, allowing users to easily assess the veracity of scientific articles and consequently researchers. By introducing a system that can identify how a research article has been cited, not just how many times, we can assess research better than traditional analytical approaches, thus helping to improve public health by identifying and promoting reliable research and by increasing the return on public and private investment in research.",A deep learning platform to evaluate the reliability of scientific claims by citation analysis.,10162578,R44DA050155,"['Academia', 'Address', 'Affect', 'Architecture', 'Biotechnology', 'Businesses', 'Classification', 'Data', 'Data Set', 'Epidemic', 'Government', 'Human', 'Industry', 'Institution', 'Investments', 'Journals', 'Letters', 'Link', 'Literature', 'Machine Learning', 'Marketing', 'Measures', 'Medicine', 'Modeling', 'National Institute of Drug Abuse', 'New England', 'Performance', 'Pharmacologic Substance', 'Phase', 'Privatization', 'Program Description', 'Proxy', 'Public Health', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Sales', 'Small Business Innovation Research Grant', 'Speed', 'System', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Vision', 'Visual system structure', 'addiction', 'commercialization', 'cost', 'dashboard', 'deep learning', 'design', 'improved', 'insight', 'interest', 'learning classifier', 'literature citation', 'opioid epidemic', 'opioid therapy', 'product development', 'programs', 'prototype', 'synthetic opioid', 'tool', 'user-friendly']",NIDA,"SCITE, INC.",R44,2021,753275
"Super Greedy Trees Project Summary/Abstract We identify critical weaknesses with Classiﬁcation and Regression Trees (CART), a widely used base learner for machine learning of big omic-data analysis, and propose to replace these with a fundamentally different type of base learner we call super greedy trees (SGT's). SGT's cut the space in a fundamentally different manner, resulting in a richer partition structure with provable consistency and superior empirical performance. The project will develop a uniﬁed SGT framework for big data analysis using machine learning including the treatment of time varying covariate survival analysis, unsupervised learning, highly imbalanced data and multivariate regression. The SGT framework will be deployed within scalable and extensible open source software that will allow NIGMS researchers to deploy them to deal with their challenging big data problems. Project Narrative We develop a comprehensive framework and scalable open source software for machine learning of big omic-data using super greedy tree base learners.",Super Greedy Trees,10086529,R35GM139659,"['Big Data', 'Computer software', 'Data', 'Data Analyses', 'Machine Learning', 'National Institute of General Medical Sciences', 'Performance', 'Research Personnel', 'Structure', 'Survival Analysis', 'Time', 'Trees', 'base', 'classification trees', 'open source', 'regression trees', 'unsupervised learning']",NIGMS,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R35,2021,415245
"Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1 PROJECT SUMMARY Previous studies showed discrepancies of health and behavior prevalence between American Indians (AI) population and other racial or ethnic groups. Most health surveys have certain limitations when studying AI population due to the small sample sizes for AI population. Data collected by AI Tribal Epidemiology Centers (TECs) provides an excellent opportunity to conduct research for AI population due to sufficient sample size and extensive information. However, most surveys conducted by TECs used non-probability sampling design (e.g. convenient sample) due to its lower cost and increased time efficiency. Non-probability sample may suffer from sampling, coverage and nonresponse errors without further proper adjustments. Such difficulties greatly hampers the analysis of AI population in health and behavior research. Our general hypothesis is that data integration by combining information from non-probability and probability samples can reduce sampling, coverage and nonresponse errors in original non-probability sample. The Goal of this project is to develop an accurate and robust data integration methodology for AI population analysis specifically tailored to health and behavior research. During the past years, we have 1) studied data integration using calibration and parametric modeling approaches; 2) investigated machine learning and propensity score modeling methods in survey sampling and other fields; and 3) assembled an experienced team of multi-disciplinary team of experts. In this project, we propose to capitalize on our expertise and fulfill the following Specific Aims: Aim 1. Develop a data integration approach using machine learning and propensity score modeling We will develop machine learning and propensity score based data integration approaches to combine information from non-probability and probability samples. Compared to existing methods (i.e., Calibration, Parametric approach), our proposed approaches are more robust against the failure of underlying model assumptions. The inference is more general and multi-purpose (e.g. one can estimate most parameters such as means, totals and percentiles). Simulation studies will be performed to compare our proposed methods with other existing methods. A computing package will be built to implement the method in other settings. Aim 2. Evaluate the accuracy and robustness of the proposed method in AI health and behavior research We will use real data to validate the proposed methods in terms of accuracy and robustness to the various data types. The performance will also be assessed by comparing with results from existing data integration methods such as calibration and parametric modeling approaches. The planned study takes advantage of a unique data source and expands the impact of the Indian Health Service (IHS)-funded research. We expect this novel integration method will vertically advance the field by facilitating the analysis based on non-probability sample, which can provide in-depth understanding regarding the AI population health and behavior studies. Project Narrative The overall goal of this R21 project is to develop an accurate, robust and multi-purpose data integration methodology for AI population (non-probability sample) analysis specifically tailored to health and behavior research such as diabetes and smoking. The code implementing the proposed method will be released and is general enough to be applied to AI population studies of other fileds. The success of this study will vertically advance the field by facilitating the AI population analysis, which can provide a better guidance and new insights on the future precision personalized prevention and treatment of certain diseases.",Improving the representativeness of American Indian Tribal Behavioral Risk Factor Surveillance System (TBRFSS) by machine learning and propensity score based data integration approach A1,10271402,R21MD014658,"['Adult', 'Age', 'American', 'American Indians', 'Behavioral', 'Behavioral Risk Factor Surveillance System', 'Calibration', 'Censuses', 'Code', 'Communities', 'Community Surveys', 'Cross-Sectional Studies', 'Custom', 'Data', 'Data Sources', 'Diabetes Mellitus', 'Disease', 'Epidemiology', 'Ethnic group', 'Event', 'Failure', 'Funding', 'Future', 'General Population', 'Geographic state', 'Goals', 'Health', 'Health Fairs', 'Health Surveys', 'Health behavior', 'High Prevalence', 'Kansas', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Not Hispanic or Latino', 'Oklahoma', 'Performance', 'Population', 'Population Analysis', 'Population Study', 'Prevalence', 'Probability', 'Probability Samples', 'Publishing', 'Race', 'Research', 'Research Personnel', 'Respondent', 'Risk Factors', 'Sample Size', 'Sampling', 'Smoking', 'Surveys', 'Target Populations', 'Testing', 'Texas', 'Time', 'Tobacco', 'Training', 'United States Indian Health Service', 'Weight', 'Work', 'Youth', 'base', 'behavioral study', 'cigarette smoking', 'cluster computing', 'cost', 'data integration', 'data quality', 'design', 'experience', 'improved', 'individualized prevention', 'innovation', 'insight', 'multidisciplinary', 'novel', 'personalized medicine', 'population health', 'simulation', 'smoking prevalence', 'success', 'therapy development', 'tribal health']",NIMHD,UNIVERSITY OF OKLAHOMA HLTH SCIENCES CTR,R21,2021,109613
"Lagrangian computational modeling for biomedical data science The goal of the project is to develop a new mathematical and computational modeling framework for from biomedical data extracted from biomedical experiments such as voltages, spectra (e.g. mass, magnetic resonance, impedance, optical absorption, …), microscopy or radiology images, gene expression, and many others. Scientists who are looking to understand relationships between different molecular and cellular measurements are often faced with questions involving deciphering differences between different cell or organ measurements. Current approaches (e.g. feature engineering and classification, end-to-end neural networks) are often viewed as “black boxes,” given their lack of connection to any biological mechanistic effects. The approach we propose builds from the “ground up” an entirely new modeling framework build based on recently developed invertible transformation. As such, it allows for any machine learning model to be represented in original data space, allowing for not only increased accuracy in prediction, but also direct visualization and interpretation. Preliminary data including drug screening, modeling morphological changes in cancer, cardiac image reconstruction, modeling subcellular organization, and others are discussed. Mathematical data analysis algorithms have enabled great advances in technology for building predictive models from biological data which have been useful for learning about cells and organs, as well as for stratifying patient subgroups in different diseases, and other applications. Given their lack to fundamental biophysics properties, the modeling approaches in current existence (e.g. numerical feature engineering, artificial neural networks) have significant short-comings when applied to biological data analysis problems. The project describes a new mathematical data analysis approach, rooted on transport and related phenomena, which is aimed at greatly enhance our ability to extract meaning from diverse biomedical datasets, while augmenting the accuracy of predictions.",Lagrangian computational modeling for biomedical data science,10063532,R01GM130825,"['3-Dimensional', 'Accountability', 'Address', 'Algorithmic Analysis', 'Area', 'Biological', 'Biological Models', 'Biology', 'Biophysics', 'Brain', 'Cancer Detection', 'Cartilage', 'Cell model', 'Cells', 'Classification', 'Collaborations', 'Communication', 'Communities', 'Computer Models', 'Computer software', 'Data', 'Data Analyses', 'Data Reporting', 'Data Science', 'Data Scientist', 'Data Set', 'Development', 'Disease', 'Drug Screening', 'Engineering', 'Flow Cytometry', 'Fluorescence', 'Gene Expression', 'Generations', 'Goals', 'Heart', 'Image', 'Knee', 'Laboratories', 'Learning', 'Letters', 'Libraries', 'Link', 'Machine Learning', 'Magnetic Resonance', 'Magnetic Resonance Imaging', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Mathematics', 'Measurement', 'Medical Imaging', 'Methodology', 'Modeling', 'Molecular', 'Morphology', 'Optics', 'Organ', 'Performance', 'Plant Roots', 'Population', 'Pythons', 'Research', 'Scientist', 'Signal Transduction', 'System', 'Techniques', 'Technology', 'Training', 'Universities', 'Virginia', 'Visualization', 'absorption', 'algorithm development', 'artificial neural network', 'base', 'biomedical data science', 'biophysical properties', 'brain morphology', 'cellular imaging', 'clinical application', 'clinical practice', 'convolutional neural network', 'cost', 'data space', 'deep learning', 'deep neural network', 'effectiveness testing', 'electric impedance', 'experimental study', 'graphical user interface', 'gray matter', 'heart imaging', 'image reconstruction', 'learning strategy', 'mathematical algorithm', 'mathematical model', 'mathematical theory', 'microscopic imaging', 'models and simulation', 'neural network', 'patient stratification', 'patient subsets', 'predictive modeling', 'radiological imaging', 'technology research and development', 'tool', 'voltage']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,360227
"Climate Penalty: Climate-driven Increases in Ozone and PM2.5 Levels and Mortality Project Summary Climate change is the greatest public health challenge of the 21st century. While numerous pathways of the health impact of climate change have been proposed, the “climate penalty” effect, i.e., a warming temperature worsens ambient air quality and consequently influences human health, remains poorly understood, resulting in an underestimated public health burden associated with global warming. Our previous epidemiological studies have reported that higher summer mean temperatures and higher PM2.5 concentrations are each associated with increased all-cause mortality in the Medicare population (aged ≥65) in the Southeastern US (SEUS)1, 2. Satellite and ground-based observations suggest a strong dependence of air pollution on interannual variabilities of summer mean temperature in SEUS3. These findings suggest that the indirect health effect of temperature via the climate penalty on air quality can be potentially important in the SEUS region, in addition to the direct adverse effects that we observed. However, clear epidemiological evidence of the air pollution serving as a mediator for the health effects of temperature, and accurate estimate of this effect is still missing in current literature. Herein, drawing on our preliminary results, we hypothesize that rising temperature can indirectly affect all-cause mortality via worsening both PM2.5 and ozone levels in the SEUS. We propose a study that will leverage the Medicare cohort from 2000-2016 (124 million person-years), the largest longitudinal cohort available for the SEUS and the high-resolution temperature, PM2.5, and O3 data, to investigate all-cause mortality in response to the “climate penalty” effect using a mediation statistical analysis. Specifically, in this project we will (1) update the present- day temperature and ozone predictions at 1-km2 grids across the SEUS through 2016 by incorporating ensemble averaging of machine learning models; (2) quantify the health effect of “climate penalty” on all-cause mortality using a mediation analysis, and explore whether mitigating anthropogenic air pollution emissions might serve as a pathway of climate change adaptation; (3) perform a risk assessment on the excess deaths related to the climate penalty on air pollution for the mid- (2050) and late-21st century (2100), using climate model output, chemical transport modeling, along with the top-down estimate of “climate penalty” from Aim 2. The proposed research will improve understanding of the interplays between climate, air pollution, and human health based on real-world big data, and provide epidemiological evidence of an important pathway that climate change adversely affects human health, with immediate relevance to climate and environmental policymaking. Project Narrative This project aims to estimate the health effect of “climate penalty”, i.e., the rising temperature indirectly affects human health via worsening ambient air quality (primarily PM2.5 and ozone levels) using a mediation analysis based on satellite-retrieved exposures and Medicare all-cause mortality. We will test the hypotheses that 1) the indirect health effect of a warming climate by worsening air quality can be a major public health burden of future climate change, and 2) improving air quality by reducing anthropogenic emission can mitigate the health effect of climate penalty. We will also forecast the excess deaths in 2050 and 2100 related to the climate penalty on air pollution using climate model ensembles simulated for different emission scenarios.",Climate Penalty: Climate-driven Increases in Ozone and PM2.5 Levels and Mortality,10218738,R21ES032606,"['Address', 'Adverse effects', 'Affect', 'Air', 'Air Pollution', 'American', 'Big Data', 'Cessation of life', 'Chemicals', 'Chronic', 'Climate', 'Coupled', 'Data', 'Data Set', 'Databases', 'Dependence', 'Environmental Policy', 'Epidemiology', 'Frequencies', 'Future', 'Global Warming', 'Goals', 'Health', 'Health Insurance', 'Hospitalization', 'Human', 'Individual', 'Knowledge', 'Lead', 'Link', 'Literature', 'Longitudinal cohort', 'Machine Learning', 'Measures', 'Mediation', 'Mediator of activation protein', 'Medicare', 'Modeling', 'Outcome', 'Output', 'Ozone', 'Pathway interactions', 'Personal Satisfaction', 'Persons', 'Planet Earth', 'Policies', 'Policy Making', 'Pollution', 'Population', 'Population Study', 'Positioning Attribute', 'Public Health', 'Quality Control', 'Reaction', 'Reporting', 'Research', 'Resolution', 'Risk Assessment', 'Statistical Data Interpretation', 'Statistical Methods', 'Suggestion', 'Surface', 'Temperature', 'Testing', 'Update', 'Weather', 'air pollution control', 'anthropogenesis', 'atmospheric chemistry', 'base', 'climate change', 'climate impact', 'cohort', 'epidemiology study', 'experience', 'fine particles', 'human old age (65+)', 'improved', 'mortality', 'neural network', 'oxidation', 'pollutant', 'prevent', 'prospective', 'random forest', 'resilience', 'response', 'tropospheric ozone', 'ventilation', 'volatile organic compound', 'warm temperature']",NIEHS,EMORY UNIVERSITY,R21,2021,260895
"2021 Annual Meeting of the American Society for Investigative Pathology The purpose of this proposal is to seek support for the 2021 Annual Meeting of the American Society for Investigative Pathology (ASIP), which will be held in conjunction with the Experimental Biology 2021 conference from May 1-4 using a virtual meeting platform. ASIP’s Annual Meeting provides a unique forum for presentation and sharing of cutting-edge research in experimental pathology. The target audience and subject matter for the meeting are diverse but united by a common focus on mechanisms of disease. The theme of the ASIP 2021 Annual Meeting is ‘From microbiota to artificial intelligence: emerging technologies and approaches for discovering mechanisms of pathobiology.’ Reflecting the interests of the ASIP membership, the 2021 Annual Meeting contains strong components in neoplasia and precision medicine. Major sessions will focus on the tumor microenvironment in breast cancer; hepatic tumorigenesis; epigenetic regulation in cancer; single-cell transcriptome and epigenome analysis; precision oncology; new technologies in precision medicine; and progress in the use of big data and artificial intelligence to understand mechanisms of disease. Application of insights gained from basic research to therapy and prevention will be a particular focus throughout the meeting. The four-day program comprises symposia, workshops, and lectures by award recipients, as well as abstract-driven minisymposia and poster sessions. The program further provides a number of educational initiatives, both targeted and of interest to the biomedical research community as a whole. These include sessions on diverse career paths in the biomedical sciences; preparation for the first faculty position; and creation of individual development plans. The ASIP regards promotion of the career development of trainee and young investigators as an extremely important aspect of the Annual Meeting. Accordingly, the meeting provides not only special events designed for their needs but also sessions that showcase their work. Similarly, the Program Committee works hard to ensure diversity among the participants with respect to gender, ethnic/racial group, and stage of career. The sole specific aim of this application is to promote the participation of trainees in the 2021 Annual Meeting through provision of a trainee scholar award program targeted to graduate students, postdoctoral fellows, and clinical residents and fellows in pathology. The Annual Meeting of the American Society for Investigative Pathology offers a unique forum for the sharing of original research results related to a wide spectrum of human diseases and disorders, with particular emphasis on the development, treatment, and prevention of cancer. Such sharing fosters more rapid advances in the understanding of human diseases such as cancer and accelerates the rate at which this knowledge can be applied to the development of diagnostic and prognostic tests, as well as targeted therapies. A major goal of the meeting is to provide educational and career support to young investigators who are interested in cancer biology and experimental pathobiology.",2021 Annual Meeting of the American Society for Investigative Pathology,10231963,R13CA260876,"['American', 'Area', 'Artificial Intelligence', 'Award', 'Basic Science', 'Big Data', 'Biochemistry', 'Biology', 'Biomedical Research', 'Cancer Biology', 'Career Choice', 'Cells', 'Clinical', 'Communities', 'Development', 'Development Plans', 'Diagnostic tests', 'Disease', 'Disease model', 'Educational workshop', 'Emerging Technologies', 'Ensure', 'Exhibits', 'Experimental Pathology', 'Faculty', 'Feedback', 'Fostering', 'Gender', 'Genomics', 'Goals', 'Hepatic', 'Individual', 'Investigational Therapies', 'Knowledge', 'Malignant Neoplasms', 'Mentors', 'Molecular', 'Molecular Biology', 'Neoplasms', 'Organoids', 'Participant', 'Pathology', 'Pharmaceutical Societies', 'Physiological', 'Positioning Attribute', 'Postdoctoral Fellow', 'Preparation', 'Prevention', 'Program Development', 'Race', 'Research', 'Research Personnel', 'Resources', 'Role', 'Science', 'Scientist', 'Seasons', 'Societies', 'Special Event', 'Structure', 'Suggestion', 'Translating', 'Translational Research', 'Work', 'breast cancer progression', 'cancer prevention', 'cancer therapy', 'career', 'career development', 'clinical application', 'design', 'epigenetic regulation', 'epigenome', 'experience', 'graduate student', 'human disease', 'induced pluripotent stem cell', 'insight', 'interest', 'lectures', 'malignant breast neoplasm', 'meetings', 'member', 'microbiota', 'new technology', 'posters', 'precision medicine', 'precision oncology', 'prognostic assays', 'programs', 'racial and ethnic', 'social', 'symposium', 'targeted treatment', 'transcriptome', 'tumor microenvironment', 'tumorigenesis', 'virtual']",NCI,AMERICAN SOCIETY/INVESTIGATIVE PATHOLOGY,R13,2021,12500
"VR-Based Evaluation and Training System for Emergency Responders and Managers Virtual and Augmented Reality (VR/AR) systems are increasingly being utilized as training platforms for complex, extremely demanding or rarely executed tasks. Often, VR systems focus primarily on delivering increasingly realistic scenarios for training purposes without any capability to assess or refine trainee performance in situ. Our novel VR training platform to deliver HAZMAT training not only delivers realistic scenarios, but also measures and evaluates performance using scientifically validated measures of variables associated with both individual and team performance. The advantage of our approach is to immerse first responders in HAZMAT emergency scenarios that are realistic and also designed to focus on measurement and refinement of specific areas of performance. Key contributors to performance among emergency responders and managers were identified by an extensive review of the literature and subsequent tested for association by psychometric assessment of over three hundred emergency responders. A subset of 18 highly associated contributors were then identified through statistical analysis of survey results. These contributors can be measurably represented in VR Training scenario elements. Performance related to each can then be measured and assessed for individual or team trainees. These refined key contributors can then be validated on larger, more diverse samples of emergency responders using the beta version of our proposed VR-based system. Our VR system is also a configurable platform that enables the evaluation and training of a wide range of skills needed by distinct roles (police, firefighters, EMTs, etc.) in diverse scenarios such as biosafety spills, HAZMAT disasters and bioterrorism threats. Also, HAZMAT disasters that are rare or very difficult/costly to create real world training events can be more easily and cost effectively mastered. Scenarios also can be dynamically modulated by trainer input in real-time, or by computerized Artificial Intelligence analysis of performance and trainee real-time physiological measures to rapidly optimize specific key contributor performance of individuals and teams. Rapid, efficient and effective training of emergency responders serves the ultimate goal of minimizing potential catastrophic consequences of these events. Our novel VR training platform to deliver HAZMAT training not only delivers realistic scenarios, but also measures and evaluates performance using scientifically validated measures of variables associated with both individual and team performance",VR-Based Evaluation and Training System for Emergency Responders and Managers,10164783,R44ES029348,"['Area', 'Artificial Intelligence', 'Bioterrorism', 'Competence', 'Complex', 'Elements', 'Evaluation', 'Event', 'Goals', 'Gold', 'Hazardous Substances', 'In Situ', 'Individual', 'Measurable', 'Measurement', 'Measures', 'Performance', 'Phase', 'Physiological', 'Police', 'Psychometrics', 'Resources', 'Review Literature', 'Role', 'Sampling', 'Statistical Data Interpretation', 'Surveys', 'System', 'Testing', 'Time', 'Training', 'Virtual and Augmented reality', 'base', 'computerized', 'cost', 'design', 'effectiveness measure', 'emergency service responder', 'first responder', 'hazardous materials disaster', 'improved', 'novel', 'skills']",NIEHS,"TIETRONIX SOFTWARE, INC.",R44,2021,199154
"Automated data curation to ensure model credibility in the Vascular Model Repository Three-dimensional anatomic modeling and simulation (3D M&S) in cardiovascular (CV) disease have become a crucial component of treatment planning, medical device design, diagnosis, and FDA approval. Comprehensive, curated 3-D M&S databases are critical to enable grand challenges, and to advance model reduction, shape analysis, and deep learning for clinical application. However, large-scale open data curation involving 3-D M&S present unique challenges; simulations are data intensive, physics-based models are increasingly complex and highly resolved, heterogeneous solvers and data formats are employed by the community, and simulations require significant high-performance computing resources. Manually curating a large open-data repository, while ensuring the contents are verified and credible, is therefore intractable. We aim to overcome these challenges by developing broadly applicable automated curation data science to ensure model credibility and accuracy in 3-D M&S, leveraging our team’s expertise in CV simulation, uncertainty quantification, imaging science, and our existing open data and open source projects. Our team has extensive experience developing and curating open data and software resources. In 2013, we launched the Vascular Model Repository (VMR), providing 120 publicly-available datasets, including medical image data, anatomic vascular models, and blood flow simulation results, spanning numerous vascular anatomies and diseases. The VMR is compatible with SimVascular, the only fully open source platform providing state-of-the-art image-based blood flow modeling and analysis capability to the CV simulation community. We propose that novel curation science will enable the VMR to rapidly intake new data while automatically assessing model credibility, creating a unique resource to foster rigor and reproducibility in the CV disease community with broad application in 3D M&S. To accomplish these goals, we propose three specific aims: 1) Develop and validate automated curation methods to assess credibility of anatomic patient-specific models built from medical image data, 2) Develop and validate automated curation methods to assess credibility of 3D blood flow simulation results, 3) Disseminate the data curation suite and expanded VMR. The proposed research is significant and innovative because it will 1) enable rapid expansion of the repository by limiting curator intervention during data intake, leveraging compatibility with SimVascular, 2) increase model credibility in the CV simulation community, 3) apply novel supervised and unsupervised approaches to evaluate anatomic model fidelity, 4) leverage reduced order models for rapid assessment of complex 3D data. This project assembles a unique team of experts in cardiovascular simulation, the developers of SimVascular and creator of the VMR, a professional software engineer, and radiology technologists. We will build upon our successful track record of launching and supporting open source and open data resources to ensure success. Data curation science for 3D M&S will have direct and broad impacts in other physiologic systems and to ultimately impact clinical care in cardiovascular disease. Cardiovascular anatomic models and blood flow simulations are increasingly used for personalized surgical planning, medical device design, and the FDA approval process. We propose to develop automated data curation science to rapidly assess credibility of anatomic models and 3D simulation data, which present unique challenges for large-scale data curation. Leveraging our open source SimVascular project, the proposed project will enable rapid expansion of the existing Vascular Model Repository while ensuring model credibility and reproducibility to foster innovation in clinical and basic science cardiovascular research.",Automated data curation to ensure model credibility in the Vascular Model Repository,10175029,R01LM013120,"['3-Dimensional', 'Adoption', 'Anatomic Models', 'Anatomy', 'Basic Science', 'Blood Vessels', 'Blood flow', 'Cardiac', 'Cardiovascular Diseases', 'Cardiovascular Models', 'Cardiovascular system', 'Clinical', 'Clinical Data', 'Clinical Sciences', 'Collaborations', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Databases', 'Diagnosis', 'Disease', 'Electrophysiology (science)', 'Ensure', 'Feedback', 'Fostering', 'Funding', 'Goals', 'High Performance Computing', 'Image', 'Image Analysis', 'Incentives', 'Intake', 'Intervention', 'Joints', 'Laws', 'Machine Learning', 'Manuals', 'Maps', 'Mechanics', 'Medical Device Designs', 'Medical Imaging', 'Methods', 'Modeling', 'Musculoskeletal', 'Operative Surgical Procedures', 'Patient risk', 'Patients', 'Physics', 'Physiological', 'Process', 'Publications', 'Radiology Specialty', 'Recording of previous events', 'Reproducibility', 'Research', 'Resolution', 'Resources', 'Risk Assessment', 'Running', 'Science', 'Software Engineering', 'Source Code', 'Supervision', 'System', 'Techniques', 'Time', 'Triage', 'Uncertainty', 'United States National Institutes of Health', 'automated analysis', 'base', 'clinical application', 'clinical care', 'computing resources', 'data curation', 'data format', 'data repository', 'data resource', 'deep learning', 'experience', 'gigabyte', 'imaging Segmentation', 'innovation', 'large scale data', 'models and simulation', 'novel', 'online repository', 'open data', 'open source', 'repository', 'respiratory', 'shape analysis', 'simulation', 'software development', 'stem', 'success', 'supercomputer', 'supervised learning', 'three-dimensional modeling', 'treatment planning', 'trustworthiness', 'unsupervised learning', 'web portal']",NLM,STANFORD UNIVERSITY,R01,2021,330299
"Modeling the influence of translation-elongation kinetics on protein structure and function Project Summary mRNA degradation is an essential process in post-translational gene regulation, and influences protein expression levels in cells. In S. cerevisea the lifetime of mRNA ranges from 43 sec to 39 min, with a median half-life of 3.6 min. The molecular factors governing these differential degradation rates has long been an area of active research. Recently though, clear evidence has emerged that the codon optimality correlates with half- lives. At a mechanistic level, the emerging perspective is that some transcripts are translated quickly, and some slowly, and that transcripts in which ribosomes end up forming queues, much like a traffic jam of cars on a highway, are recognized by ubiquitin ligases such as Hel2 that trigger the RQC pathway to promote mRNA degradation. There are two major gaps in this field. The first is the capability to predict mRNA half-lives accurately from mRNA sequence features. The second is understanding at the molecular level how the distribution of codon translation speeds along a transcript’s coding sequence promote ribosome queues and hence degradation. In this proposal, a graduate student will combine the PI’s labs expertise in modeling the kinetics of translation and ribosome traffic with interpretable machine learning techniques to address these two gaps. In achieving this, the field will be advanced by having both predictive and explanatory models for how translation speed and codon usage differentially impacts the degradation rates of different mRNAs. Specifically, our first aim is to build an interpretable machine learning model to identify robust and predictive features governing mRNA degradation. Our second aim is to explain at the molecular level why these features influence degradation rates. We will do this in two ways. First, we will use the essential and predictive features resulting from the interpretable machine learning model to identify potential underlying mechanisms contributing to degradation. Second, we will simulate the movement of ribosomes on each transcript based on reported initiation and elongation rates to detect ribosome queues and provide an explanation for differential degradation rates. Finally, our third aim is to test the predictions coming from the models. For example, do the models from Aim 1 accurately predict mRNA half-lives when synonymous mutations are introduced? There is sufficient published data on transcriptome-wide mRNA half-lives on S. cerevisiae to train and test the machine learning models in Aim 1. Further, we have arranged for a machine learning expert to co-advise the graduate student on the second aim. This co-advisor is already a collaborator of the PI on other machine learning projects. Finally, a collaborator who has measured mRNA half-lives will further advise the student on the third aim. In summary, this training supplement will address cutting edge questions in the molecular biology and biophysics of mRNA lifetimes and provide the student the opportunity to get advanced training and expertise in machine learning, molecular modeling, and experimental techniques. Project Narrative Messenger RNA (mRNA) half-lives are influenced by the rate of protein synthesis and the ribosome traffic jams that can form on transcripts when slow-translating codons are encountered by ribosomes. The complex distribution of codon usage across transcripts, and the interplay of initiation and elongation rates that can create ribosome queues make it difficult to predict an mRNA's half-life based on its sequence. Here, we will apply machine learning to accurately predict mRNA half-lives from sequence, and combine it with biophysical modeling to understand the molecular events regulating mRNA degradation.",Modeling the influence of translation-elongation kinetics on protein structure and function,10307359,R35GM124818,"['Address', 'Area', 'Biophysics', 'Cells', 'Code', 'Codon Nucleotides', 'Complex', 'Coupling', 'Data', 'Event', 'Gene Expression Regulation', 'Half-Life', 'Kinetics', 'Lead', 'Machine Learning', 'Measures', 'Messenger RNA', 'Modeling', 'Molecular', 'Molecular Biology', 'Movement', 'Mutation', 'Pathway interactions', 'Process', 'Property', 'Protein Biosynthesis', 'Proteins', 'Publishing', 'Reporter', 'Reporting', 'Research', 'Ribosomes', 'Saccharomyces cerevisiae', 'Speed', 'Students', 'Techniques', 'Testing', 'Training', 'Transcript', 'Translating', 'Translations', 'base', 'biophysical model', 'graduate student', 'insight', 'kinetic model', 'mRNA Transcript Degradation', 'models and simulation', 'molecular modeling', 'protein expression', 'protein structure function', 'ribosome profiling', 'simulation', 'transcriptome', 'ubiquitin ligase']",NIGMS,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R35,2021,31246
"Phenotype screens of Chlamydia Inclusions Abstract Chlamydia trachomatis is a major health concern with over 200 million people with active urogenital or ocular infection each year worldwide. Chlamydia are obligate intracellular bacteria with a unique biphasic developmental cycle. A better understanding of that biphasic cycle can lead to inhibitors that are specific for chlamydial infection in order to avoid overuse of antibiotics. Individual Chlamydia are too small and tightly packed to be spatially separated with conventional light microscopes, and 3D SEM is too labor-intensive for inhibitor studies. We will use a new sample preparation method that physically expands the sample with polymers termed ""Expansion Microscopy"" or ExM. Expanded samples can then be imaged with a traditional confocal microscope, and high-content analysis performed automatically using machine learning methods such as pixel classification and novelty detection. Prepared samples can be imaged and analyzed in under an hour instead of the multiple days required for 3D SEM. This R03 grant will develop an innovative high-content screening platform, called Expansion Microscopy Aided Phenotyping (ExMAP), for the quantification of changes in Chlamydia development after treatment. ExMAP can be paired with Chlamydia transformed with promoters for EUO and IhtA (RB cell types) and the promoters for HctB and Tarp (EB cell types). The combination of expansion microscopy, machine learning, and chlamydial transformation will make ExMAP a powerful tool for research on both the developmental cycle and new therapy development. Project Narrative This project will develop a new high-content platform, termed ExMAP, that will physically expand the sample of interest and then utilize machine learning for image analysis. At the completion of the project, we expect to have developed a new method for the study of the Chlamydia developmental cycle and inhibitors that disrupt that cycle.",Phenotype screens of Chlamydia Inclusions,10128374,R03AI146437,"['3-Dimensional', 'Acrylates', 'Aftercare', 'Agonist', 'Antibiotics', 'Applications Grants', 'Bacteria', 'Cells', 'Chlamydia', 'Chlamydia Infections', 'Chlamydia genome', 'Chlamydia trachomatis', 'Chloramphenicol', 'Classification', 'Clinical', 'Computer software', 'Confocal Microscopy', 'Consumption', 'Data', 'Detection', 'Development', 'Developmental Gene', 'Drug Costs', 'Drug Screening', 'Electron Microscopy', 'Eye Infections', 'Gel', 'Genitourinary System Infection', 'Grant', 'Growth', 'Health', 'Hour', 'Human', 'Image', 'Image Analysis', 'Individual', 'Iron Chelating Agents', 'Lead', 'Light Microscope', 'Machine Learning', 'Malaria', 'Measurement', 'Methods', 'Microbiology', 'Microscope', 'Microscopy', 'Morbidity - disease rate', 'PF4 Gene', 'Penicillins', 'Pharmaceutical Preparations', 'Pharmacotherapy', 'Phenotype', 'Polymers', 'Preparation', 'Research', 'Resolution', 'SIRT1 gene', 'Sampling', 'Sodium', 'Techniques', 'Time', 'Work', 'cell type', 'chlamydia vaccine', 'human pathogen', 'inhibitor/antagonist', 'innovation', 'interest', 'machine learning method', 'novel', 'novel therapeutics', 'pathogen', 'promoter', 'screening', 'small molecule', 'small molecule inhibitor', 'therapy development', 'tool']",NIAID,WAKE FOREST UNIVERSITY,R03,2021,77243
"Nathan Shock Center of Excellence in Basic Biology of Aging OVERALL PROJECT SUMMARY This application is for renewal of the Nathan Shock Center of Excellence in the Basic Biology of Aging at the University of Washington and affiliated institutions. This Center has over the past 25 years provided key resources in support of investigators who study the biology of aging. This application continues a theme that emphasizes outreach and service to the broadest community of investigators in the gerosciences. Of proximal relevance is the characterization of aging-related phenotypes of longevity and healthspan. As our Center services must be easily accessible to outside users, our Longevity and Healthspan Core (Core E) focuses on invertebrate assays, many of them novel. Two other Resources Cores focus on the high dimensional assessments that are closely related to aging phenotypes: Protein Phenotypes of Aging (Core C) and Metabolite Phenotypes of Aging (Core D). Sophisticated computational and bioinformatic tools for data analysis and optimal insight are provided by the Artificial Intelligence and Bioinformatics Core F. Each of these four Resource Cores is led by highly respected experts in that field, including Michael MacCoss and Judit Villen (Core C), Daniel Promislow (Core D), Matt Kaeberlein and Maitreya Dunham (Core E) and Su-In Lee (Core F). Each will push the envelope of appropriate technologies, developing new state-of-the art approaches for assessments that are the most applicable to gerontology and making them accessible to the national aging community. The Research Development Core (Core B) will continue to support pilot and junior faculty studies, with a firm focus on outreach of service to the national geroscience constituency. The Administrative and Program Enrichment Core (Core A) supports administrative management, an external advisory panel, courses, and data sharing and dissemination. Core A’s program of seminars and symposia will continue a focus on sponsorship and organization of national courses, meetings and pre-meetings, as well as workshops in the fields allied to our Resource Core Services. In coordination with other Nathan Shock Centers, we will support a new Geropathology Research initiative. UW NATHAN SHOCK CENTER OVERALL - PROJECT NARRATIVE We apply for renewal of the Nathan Shock Center of Excellence in the Basic Biology of Aging at the University of Washington, which has for 25 years provided key resources supporting investigators who study the biology of aging. The overarching goal of this Center is to have a positive impact on the field by accelerating research discovery and providing research support for investigators nationally and internationally, particularly junior investigators in the process of building their own research programs. We will accomplish this goal through six cores that function synergistically together: four Resource Cores with particular expertise in protein (Core C) and metabolite (Core D) phenotypes of aging, invertebrate longevity and healthspan phenotypes (Core E) and artificial intelligence and bioinformatics (Core F), along with a Research Development Core (Core B) that supports external pilot projects and junior faculty studies, and an Administrative and Program Enrichment Core (Core A) that supports administrative management, an external advisory panel, sponsorship and organization of national meetings and pre-meetings, courses, workshops and seminars, and, in coordination with other Nathan Shock Centers, a Geropathology Research initiative.",Nathan Shock Center of Excellence in Basic Biology of Aging,10260476,P30AG013280,"['Aging', 'Artificial Intelligence', 'Bioinformatics', 'Biological Assay', 'Biology of Aging', 'Collaborations', 'Communication', 'Communities', 'Consult', 'Data', 'Data Analyses', 'Development', 'Educational workshop', 'Environment', 'Experimental Designs', 'Faculty', 'Genes', 'Genetic study', 'Gerontology', 'Geroscience', 'Goals', 'Growth', 'Informatics', 'Institution', 'International', 'Invertebrates', 'Leadership', 'Longevity', 'Methodology', 'Methods', 'Microfluidics', 'Molecular Genetics', 'Office of Administrative Management', 'Pathway interactions', 'Phenotype', 'Philosophy', 'Pilot Projects', 'Post-Translational Protein Processing', 'Process', 'Proteins', 'Proteomics', 'Research', 'Research Activity', 'Research Personnel', 'Research Support', 'Resources', 'Robotics', 'Services', 'Shock', 'Statistical Data Interpretation', 'Technology', 'Transcript', 'Universities', 'Variant', 'Washington', 'bioinformatics tool', 'career development', 'cell age', 'computerized tools', 'data dissemination', 'data sharing', 'healthspan', 'high dimensionality', 'insight', 'meetings', 'metabolomics', 'multiple omics', 'novel', 'outreach', 'outreach services', 'programs', 'protein metabolite', 'research and development', 'symposium', 'tool', 'trait']",NIA,UNIVERSITY OF WASHINGTON,P30,2021,962037
"Research Symposium in Communication Sciences and Disorders The Research Symposium in Communication Sciences and Disorders supports a full day of presentations by leading scientists in areas that are having transformational effects in the communication sciences and disorders (CSD) discipline. The Research Symposium is held at the annual Convention of the American Speech-Language-Hearing Association (ASHA) and is open to all of the approximately 15,000 Convention attendees, which includes students, practitioners, and researchers. Following Convention, the Symposium content is widely disseminated through audio recordings of the presentations, which are synced with the slides and transcribed, and by making them freely accessible on the ASHA website. Additionally, each presenter submits an article based on their presentation to the Journal of Speech, Language, and Hearing Research to be published in the annual Research Symposium Forum. An innovation that will be implemented in this current funding cycle is that ASHA will make these articles freely accessible upon publication on the ASHA Journals website and will deposit them in PubMed Central without embargo. The first aim of the Research Symposium grant is to advance scientific discourse and dissemination of scientific discovery and innovation on five topics that are having transformational effects across several subareas in CSD. This will be accomplished, in part, by making the Research Symposium Forum open access and by widely promoting both the recorded and the written content across ASHA’s many communication channels. Over the next 5-year funding cycle, the Symposium will address five topics that cut across the areas of hearing, speech, language, and other aspects of cognition, including (1) Health and Healthcare Equity of People With Communication Disabilities, (2) Bilingualism, (3) Artificial Intelligence in CSD, (4) Genetics in CSD, and (5) Intervention and Implementation Clinical Trials in CSD. The second aim of the Research Symposium grant is to advance the research career development of early- career scientists focused on research in CSD. Between 2021 and 2025, the Research Mentoring- Pair Travel Award and ASHA’s in-kind contribution will provide funding to attend the Symposium and mentoring support to 130 early-career scientists in CSD. The Travel Award recipients will attend the Symposium along with a mentor and engage in mentored research activities before, during, and after each Symposium. These activities are designed to help integrate the protégés into their scientific community and encourage them to pursue a research career and become productive scholars. The scientific base of the CSD discipline will be strengthened by these scientific dissemination, research education, and mentoring activities. The Research Symposium in Communication Sciences and Disorders aims to strengthen the scientific base and increase the research capacity of the discipline, which will lead to improvements in the communication health of millions people with communication or related disorders. The Symposium presentations will advance the scientific dialogue and be broadly disseminated through freely available peer-reviewed publications and transcribed recordings. The associated Travel Award will provide funds to support 130 promising early-career scientists in attending the Research Symposium and engaging in mentored research activities before, during, after the Symposium to increase their recruitment and retention in a research career.",Research Symposium in Communication Sciences and Disorders,10070224,R13DC003383,"['Address', 'American Speech-Language-Hearing Association', 'Area', 'Artificial Intelligence', 'Award', 'Awareness', 'Clinical', 'Clinical Trials', 'Cognition', 'Communication', 'Communication Disability', 'Communities', 'Data', 'Degree program', 'Deposition', 'Dimensions', 'Discipline', 'Disease', 'Doctor&apos', 's Degree', 'Enrollment', 'Ensure', 'Event', 'Funding', 'Generations', 'Genetic', 'Grant', 'Health', 'Health Communication', 'Healthcare', 'Hearing', 'Hour', 'Intervention', 'Journals', 'Knowledge', 'Language', 'Manuscripts', 'Mentors', 'Methodology', 'Monitor', 'Outcome Measure', 'Peer Review', 'Postdoctoral Fellow', 'Preparation', 'PubMed', 'Publications', 'Publishing', 'Readiness', 'Reporting', 'Research', 'Research Activity', 'Research Personnel', 'Resources', 'Science', 'Scientific Advances and Accomplishments', 'Scientist', 'Seminal', 'Slide', 'Speech', 'Students', 'Surveys', 'Time', 'Travel', 'Work', 'base', 'bilingualism', 'career', 'career development', 'clinical trial implementation', 'design', 'dissemination research', 'doctoral student', 'education research', 'experience', 'innovation', 'knowledge base', 'meetings', 'next generation', 'online community', 'recruit', 'social media', 'stem', 'symposium', 'web site']",NIDCD,AMERICAN SPEECH-LANGUAGE-HEARING ASSN,R13,2021,39900
"Portable Hearing Laboratory  - CRP In the parent Phase II project (R44DC016247; PI: C. Pavlovic) we successfully developed a portable platform for developing and testing new hearing aid technology. This Portable Hearing Laboratory, or PHL, has now been acquired and is being used by a number of leading university laboratories and other research centers and their feedback has been extremely positive. The device features a central unit (BatAndCat Box) which provides an appropriate and complete hearing aid ambient for developing new algorithms. A number of realistic interfaces has also been provided. This includes an extremely high quality BTE system we designed; an ITE system adapted by us, as well as an appropriate interface circuitry for typical wearables (e.g; headsets via the line input). Finally, a smart phone app features interfaces both for the researcher and the subject. The system runs the Master Hearing aid sweet developed concurrently in R01DC015429 (PIs Hohmann and Pavlovic). In this CRP renewal we will achieve the following goals: 1. Implement various Design for Excellence Measures (DFX) and super modern manufacturing  technology to obtain the highest product quality at the lowest product cost. This would make  the product affordable for large clinical studies and, potentially, for some consumer sales. 2. In response to the recent availability of, and the recent research demand for, a far greater  processing power to enable the development of algorithms which rely on machine learning,  we plan to increase the processing power of the device by at least 10 times, and likely 20  times, by changing the processor core to a multicore system. 3. Introduce modern low-latency BLE technology to enable efﬁcient noise reduction by utilizing  remote microphones and machine learning. 4. The other complementary requirement to extract speech from noise is being able to inform  the system whom the listener is actually listening to. This will be achieved by providing on  the PHL the interface means for external multi-sensor arrays such as EEG, OEG, etc. 5. Execute electrical and mechanical design changes dramatically reducing the size and  weight of the device. This would not only be a much more acceptable device for long clinical  trials, but would also open up a direct-to-consumer, secondary market for the device. 6. It is our strong determination to provide continuous support to the Beta sites for extensive  further testing of the device in a variety of settings. We consider this the best means to  reach the perfection. Portable Hearing Laboratory (PHL), developed in R44DC016247 has been deployed successfully at various research centers and it features a central unit connected to a number of realistic interfaces such as BTEs, ITEs, or typical wearables. In this CRP renewal we upgrade the technology to support demanding machine learning algorithms interfaced almost inconspicuously to a number of EEG and EOG electrodes to extract perfectly speech from noise. Simultaneously, we apply modern manufacturing technology to produce small, powerful and low cost devices.",Portable Hearing Laboratory  - CRP,10138807,R44DC016247,"['Acoustics', 'Algorithms', 'Cessation of life', 'Clinical', 'Clinical Research', 'Clinical Trials', 'Code', 'Communities', 'Data', 'Device or Instrument Development', 'Devices', 'Ear', 'Electrodes', 'Electroencephalography', 'Environment', 'Esthetics', 'Evaluation', 'Feedback', 'Funding', 'Goals', 'Hearing', 'Hearing Aids', 'Institution', 'Laboratories', 'Libraries', 'Life', 'Linux', 'Machine Learning', 'Measures', 'Mechanics', 'Modernization', 'National Institute on Deafness and Other Communication Disorders', 'Noise', 'Parents', 'Phase', 'Process', 'Reporting', 'Request for Applications', 'Research', 'Research Personnel', 'Running', 'Sales', 'Signal Transduction', 'Site', 'Small Business Innovation Research Grant', 'Software Tools', 'Source Code', 'Speech', 'System', 'Technology', 'Testing', 'Time', 'Transducers', 'Universities', 'Validation', 'Weight', 'Wireless Technology', 'Work', 'algorithm development', 'base', 'cost', 'design', 'improved', 'machine learning algorithm', 'man', 'manufacturing process', 'meter', 'microphone', 'new technology', 'open source', 'parent project', 'portability', 'response', 'sensor', 'signal processing', 'simulation', 'smartphone Application', 'sound', 'speech in noise', 'tool', 'virtual']",NIDCD,"BATANDCAT, INC.",R44,2021,837653
"An Autonomous, Non-invasive, and Bioanalytics-enabled Wearable Platform for Precision Nutrition and Personalized Medicine Project Summary  This proposal aims to enable precision nutrition by creating a wearable technology that can be scaled across the general population to non-invasively track the diurnal profiles of a panel of putative circulating nutrients and biomarkers. Accordingly, we will address fundamental and intermeshed engineering bottlenecks and scientific questions at sensor, device, and data analytics levels to realize a sweat-based wearable bioanalytical technology, equipped with autonomous sweat secretion modulation, biofluid management, and analysis capabilities. To illustrate our technology’s transformative potential, we will particularly position it to monitor a panel of nutrients and indicators of the metabolic and disease state that are relevant in cystic fibrosis (CF, the most common inherited multisystemic disorder), in order to enable individualized nutritional support, which is central to the CF treatment.  Accordingly, in the first phase (R21), we will develop microsensor arrays targeting glucose, triglyceride, and β- hydroxybutyrate. We will incorporate our readily developed auxiliary sensing modalities (sweat sodium, chloride, pH, and sweat secretion rate sensing interfaces) to enable the in-situ characterization of the secretion profile (which is useful for the normalization of sweat readings and tracking of the CF progression). In parallel to these engineering efforts, we will conduct sweat characterization experiments to study the effect of the secretion rate on analyte partitioning from blood into sweat. These datasets will be augmented with state-of-art machine learning algorithms to formulate a dedicated analytical framework that accounts for sweat secretion variabilities and determines optimal sweat secretion condition(s) to provide undistorted and physiologically meaningful sweat readings.  In the second phase (R33), we will establish the clinical utility of our technology by demonstrating the ability to non-invasively track the target nutrients’ temporal profiles in relation to their circulating levels in blood (in both healthy subjects and CF patients and through simple/mixed meal-modulated studies). Accordingly, we will first measure the sweat and blood analytes’ excursion profiles after controlled single/binary combinations of nutrients intake and develop a machine-learning based algorithm to correlate the sweat analyte readouts to their circulating concentrations. Then we will assess and characterize the predictive utility of our solution in the context of complex nutritional supplement studies. Upon its validation, we will recruit a cohort of CF patients and perform a longitudinal randomized nutritional support study to demonstrate the enabling remote patient monitoring capabilities rendered by our solution.  The success of this work will represent a groundbreaking contribution towards the development of strategies to enable precision nutrition and personalized medicine. Project Narrative This proposal aims to enable precision nutrition by creating a wearable sweat bioanalytical technology— equipped with autonomous sweat secretion modulation, biofluid management, and analysis capabilities—that can be scaled across the general population to non-invasively track the diurnal profiles of a panel of putative circulating nutrients and biomarkers. By deploying this technology in clinical studies (with a particular focus on cystic fibrosis, the most common inherited multisystemic disorder), we will study and establish the correlation of the sweat readings to the circulating analytes and in response to nutritional interventions. This technology will provide a comprehensive and physiologically rich view of the individuals’ well-being/disease and nutritional status, rendering a personalized solution for effective treatment and nutritional support.","An Autonomous, Non-invasive, and Bioanalytics-enabled Wearable Platform for Precision Nutrition and Personalized Medicine",10198604,R21DK128711,"['Accounting', 'Address', 'Algorithms', 'Biological Markers', 'Blood', 'Clinical', 'Clinical Engineering', 'Clinical Research', 'Complex', 'Cystic Fibrosis', 'Data Analytics', 'Data Set', 'Development', 'Devices', 'Dietary Intervention', 'Disease', 'Disease Management', 'Engineering', 'General Population', 'Glucose', 'Health', 'Hour', 'In Situ', 'Individual', 'Influentials', 'Inherited', 'Intake', 'Iontophoresis', 'Machine Learning', 'Measures', 'Metabolic Diseases', 'Methodology', 'Microfluidics', 'Mission', 'Modality', 'Modeling', 'Monitor', 'Nutrient', 'Nutritional Support', 'Nutritional status', 'Periodicity', 'Personal Satisfaction', 'Phase', 'Physiological', 'Physiology', 'Positioning Attribute', 'Randomized', 'Reading', 'Sampling', 'Sodium Chloride', 'Study Subject', 'Sweat Glands', 'Sweat test', 'System', 'Technology', 'Triglycerides', 'Validation', 'Work', 'base', 'beta-Hydroxybutyrate', 'cofactor', 'cohort', 'cystic fibrosis patients', 'dietary supplements', 'effective therapy', 'experimental study', 'human subject', 'machine learning algorithm', 'microsensor', 'multidisciplinary', 'operation', 'personalized medicine', 'precision nutrition', 'predictive modeling', 'recruit', 'remote patient monitoring', 'response', 'sensor', 'success', 'targeted biomarker', 'wearable device']",NIDDK,UNIVERSITY OF CALIFORNIA LOS ANGELES,R21,2021,210796
"Selection of Flow Modulation Protocols for Patients on Continuous Flow Ventricular Assist Devices (CF-VADs) PROJECT SUMMARY A major concern with continuous flow ventricular assist devices (CF-VADs) is the resulting non-physiological flow with diminished pulsatility which has been shown to be a major risk factor for development of arteriovenous malformations (AVMs) and gastrointestinal (GI) bleeding. To address this issue, flow modulation via rapid changes in pump impeller speed has been proposed as a technique to introduce ‘artificial pulsatility’. However, given the inadequacy of large animal models with recreating CF-VAD associated non-surgical bleeding events, it is still unclear if artificial pulsatility can prevent these adverse events or what level of artificial pulsatility is even necessary. To evaluate the effects of pulsatility and identify promising flow modulation approaches we developed a vascular pulse perfusion model (VPPM) to culture Human Aortic Endothelial Cells (HAECs) under conditions of normal pulsatile flow or flow with diminished pulsatility (CF-VAD support). Our rationale for modeling arterial vessels is because pulsatility primarily affects the arterial side of the circulatory system and its effects are transduced by endothelial cells that line the large arterial vessels. The VPPM was validated as relevant model via direct comparison with aortic samples of patients with and without CF-VADs. Our published data also shows that loss of pulsatility is associated with an increase in production of pro-angiogenic/inflammatory cytokines. The relevance of these results is further strengthened by supporting data from patients that experience AVMs and GI bleeding events (both CF-VAD related and due to other conditions) showing similar elevated levels of pro- angiogenic/inflammatory cytokines. The VPPM therefore provides a powerful model to evaluate artificial pulsatility in the context of CF-VAD flow modulation and determine if restoring pulse pressure and/or pulse frequency can mitigate non-surgical bleeding events. Based on recent studies that suggest that pulse pressure < 35 mmHg is a major risk factor for development of GI bleeds, we hypothesize that “Diminished pulsatility associated with ‘CF-VAD support’ results in endothelial dysfunction and pro-inflammatory/pro-angiogenic soluble factor production. These changes can be mitigated via introduction of artificial pulsatility using flow modulation strategies where pulse pressure is preserved at > 35 mmHg”. Aim1 will evaluate response of patient derived endothelial cells within the VPPM to CF-VAD flow and quantify angiogenic/inflammatory soluble factor production, Aim2 will follow patients for up to 36 months to evaluate serum levels of pro-angiogenic/pro- inflammatory cytokines and non-surgical bleeding events which will then be compared to results from in-vitro studies within the VPPM and Aim3 will evaluate different flow modulation strategies using patient-derived endothelial cells to determine most promising patient-specific approaches via comparison of hemodynamic profiles and cytokine biomarkers using deep learning approaches. Successful completion of this project will enable identification of device-based strategies to prevent non-surgical bleeding in patients on CF-VAD support. PROJECT NARRATIVE This project seeks to determine the effects of diminished pulsatility during continuous flow ventricular assist device (CF-VAD) support on human aortic endothelial cells (HAECs). Changes in production of pro- angiogenic/pro-inflammatory cytokines will be used as biomarkers to evaluate the effects of loss of pulsatility and help validate new approaches to introduce artificial pulsatility in CF-VADs.",Selection of Flow Modulation Protocols for Patients on Continuous Flow Ventricular Assist Devices (CF-VADs),10116660,R01HL151663,"['Activities of Daily Living', 'Address', 'Adverse event', 'Affect', 'Age-Years', 'Aging', 'Animal Model', 'Animals', 'Antioxidants', 'Arteriovenous malformation', 'Biological Markers', 'Blood Vessels', 'Blood specimen', 'Brain hemorrhage', 'Cardiovascular system', 'Cell Line', 'Cells', 'Data', 'Development', 'Devices', 'Endothelial Cells', 'Endothelin-1', 'Endothelium', 'Event', 'Frequencies', 'Functional disorder', 'Gastrointestinal Hemorrhage', 'Heart failure', 'Hemorrhage', 'Human', 'In Vitro', 'Individual', 'Inflammatory', 'Machine Learning', 'Mediating', 'Medical', 'Modeling', 'Monitor', 'Operative Surgical Procedures', 'Organ', 'Patients', 'Perfusion', 'Physiologic pulse', 'Physiological', 'Production', 'Protocols documentation', 'Publishing', 'Pulsatile Flow', 'Pulse Pressure', 'Pump', 'Quality of life', 'Quantitative Evaluations', 'Refractory', 'Regulation', 'Risk Factors', 'Sampling', 'Serum', 'Sheep', 'Side', 'Signal Transduction', 'Speed', 'Techniques', 'Testing', 'Time', 'Tissue Sample', 'Transducers', 'Translating', 'VWF gene', 'Validation', 'Work', 'base', 'cytokine', 'deep learning', 'endothelial dysfunction', 'experience', 'gastrointestinal', 'hemodynamics', 'improved', 'novel strategies', 'operation', 'patient response', 'preservation', 'pressure', 'prevent', 'response', 'safety testing', 'ventricular assist device']",NHLBI,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2021,535547
"Accounting for Hidden Bias in Vaccine Studies: A Negative Control Framework Project Summary / Abstract The proposed research aims to develop novel causal inference methods to resolve unmeasured confounding bias known to plague vaccine effectiveness and safety studies by leveraging so-called negative control variables widely available in vaccine studies. A negative control outcome is a variable known not to be causally affected by the treatment of interest, while a negative control exposure is a variable known not to causally affect the outcome of interest. Both share a common confounding mechanism as the exposure-outcome pair of primary interest. Examples of negative controls abound in vaccine studies. Such known-null effects form the basis of falsiﬁca- tion strategy to detect unmeasured confounding, however little is known about when and how negative controls can be used to resolve unmeasured confounding bias. We plan to develop principled negative control methods for identiﬁcation and semiparametric estimation of causal effects in the presence of unmeasured confounding, incorporating modern highly adaptive machine learning methods. We also plan to develop negative control meth- ods to detect and quantify causal effects in complex longitudinal and survival settings critical to vaccine studies using routinely collected healthcare data. Finally we plan to apply the proposed methods to evaluate vaccine effectiveness using data collected from a pioneering test-negative design platform and to monitor vaccine safety using electronic health record data. Successful completion of the proposed research will equip investigators with paradigm-shifting methods to unlock the full potential of contemporary healthcare data, encourage investigators to routinely check for evidence of confounding bias, and ultimately improve the validity of scientiﬁc research. Project Narrative The proposed research will develop statistical methods to detect and resolve unmeasured confounding bias by leveraging prior knowledge about known-null effects widely available but often underappreciated in healthcare data — thereby facilitating valid and reproducible research in vaccine effectiveness and safety studies.",Accounting for Hidden Bias in Vaccine Studies: A Negative Control Framework,10093358,R01GM139926,"['Accounting', 'Affect', 'Area', 'Benefits and Risks', 'Complex', 'Data', 'Data Set', 'Dimensions', 'Electronic Health Record', 'Ensure', 'Evaluation', 'Event', 'Failure', 'Gene Expression Profiling', 'Health Policy', 'Healthcare', 'Knowledge', 'Machine Learning', 'Methods', 'Modernization', 'Monitor', 'Nature', 'Observational Study', 'Outcome', 'Plague', 'Plague Vaccine', 'Property', 'Public Health', 'Recording of previous events', 'Reproducibility', 'Research', 'Research Design', 'Research Personnel', 'Residual state', 'Risk', 'Statistical Methods', 'Techniques', 'Testing', 'Time', 'Tissue-Specific Gene Expression', 'Use Effectiveness', 'Vaccination', 'Vaccines', 'adverse event risk', 'design', 'effectiveness evaluation', 'effectiveness study', 'flexibility', 'high dimensionality', 'improved', 'innovation', 'interest', 'machine learning method', 'novel', 'pathogen', 'public health priorities', 'safety study', 'semiparametric', 'theories', 'tool', 'user friendly software', 'vaccine effectiveness', 'vaccine evaluation', 'vaccine safety', 'vaccine trial']",NIGMS,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,401613
"Development of A High Throughput Image-Guided IMRT System for Preclinical Research Project Summary/Abstract Preclinical radiobiology experiments on small animals are crucial to test the safety and efficacy before human clinical trials. However, limited by currently available technologies, preclinical animal studies substantially differ from state-of-the-art human treatments in dose conformity. Consequently, the animal studies poorly mimic the radiobiological, radioimmunological, and toxicity environment of human therapies. The disparity adversely affects our ability to meaningfully test hypotheses that are intended for human translation. With decades of advancement, human radiotherapy has achieved high targeting accuracy and dose conformality based on technological breakthroughs, including intensity-modulated radiotherapy (IMRT), which is unavailable for mouse experiments. A practical device and algorithm to modulate the x-ray intensity for the scale of small animals is the first step to bridge the gap. With the support of an NIH R21 grant, we engineered a novel small animal IMRT dose modulator termed sparse orthogonal collimator (SOC). Equally important as the hardware, we created the enabling mathematical tools to deliver SOC IMRT plans with higher achievable resolution than a theoretically miniaturized MLC-based IMRT. We commissioned and tested prototypical SOCs to deliver highly modulated doses in silico and on phantoms. Nonetheless, there are still large gaps between an intensity modulation device and a small animal IMRT system suitable for broad adoption and impact. The required time, resources, and training to create sophisticated SOC-IMRT plans are incompatible with preclinical settings. Furthermore, without automation, the existing image-guided small animal IMRT treatment is prohibitively slow for treating live animals under anesthesia. Lastly, the current manual method to switch between imaging and therapy modes results in intractable uncertainties in dose delivery. We propose to fill these gaps using automation, robotics, and system optimization. We propose the following specific aims. Specific Aim 1 (SA1). Automated organ segmentation for mice using deep learning neural networks. Specific Aim 2 (SA2). Development of a fully functional, automated, and efficient IMRT system. Specific Aim 3 (SA3). Development and validation of a robotic Multi Mouse Automated Treatment Environment (Multi-MATE) for automated imaging and treatment. Besides dosimetry, we will quantify the time performance, which is critical to small animal IMRT system. As a result, in addition to improving the hardware accuracy and reliability, the proposed project will provide a fully automated planning and delivery system, thus removing the last barriers towards the broad adoption of small animal IMRT. The success of the proposed project will help existing research to achieve the full potential for human translation and enable future hypotheses testing where accurate complex dose distribution is critical. Project Narrative A major impediment in translating animal radiation studies to human patients is the disparity in radiation techniques. Existing methods cannot create human like conformal radiation dose on mice with necessary accuracy and efficiency. To better mimic human treatment without prohibitively complicated and slow procedures, we propose to develop a high throughput image guided small animal conformal irradiation platform.",Development of A High Throughput Image-Guided IMRT System for Preclinical Research,10317441,R01CA259008,"['Address', 'Adoption', 'Affect', 'Algorithms', 'Anesthesia procedures', 'Animals', 'Automation', 'Calibration', 'Characteristics', 'Clinical', 'Clinical Trials', 'Collimator', 'Complex', 'Computer software', 'Conformal Radiotherapy', 'Development', 'Devices', 'Dose', 'Engineering', 'Environment', 'Future', 'Grant', 'Human', 'Image', 'Individual', 'Intensity-Modulated Radiotherapy', 'Intervention', 'Knowledge', 'Manuals', 'Mathematics', 'Methods', 'Mus', 'Organ', 'Patients', 'Performance', 'Procedures', 'Radiation', 'Radiation Dose Unit', 'Radiation therapy', 'Radiobiology', 'Research', 'Resolution', 'Resources', 'Risk', 'Robotics', 'Roentgen Rays', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'TimeLine', 'Toxic effect', 'Training', 'Translating', 'Translations', 'Uncertainty', 'United States National Institutes of Health', 'Validation', 'automated segmentation', 'base', 'biological research', 'deep learning', 'deep neural network', 'design', 'dosimetry', 'experimental study', 'image guided', 'improved', 'in silico', 'innovation', 'irradiation', 'miniaturize', 'novel', 'pre-clinical', 'pre-clinical research', 'process optimization', 'robotic system', 'safety testing', 'success', 'tool', 'treatment planning', 'trend', 'tumor', 'user-friendly']",NCI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,441662
"CSHL Network Biology Conference PROJECT SUMMARY This proposal seeks support for the conference on Network Biology, to take place March/April 2021 to 2025, at the Cold Spring Harbor Laboratory (CSHL). This meeting, held in biannual rotation on the CSHL campus in New York, brings together senior and junior scientists from both experimental and computational laboratories with common interests in network biology. The meeting will emphasize new discoveries and provide an open forum for the presentation of the latest research and results on molecular networks and their relevance to normal and abnormal cellular physiology. It will be essential for advancing knowledge in all aspects of the network modeling process, from data generation in experimental cell biology to data analysis and computer simulation and from the development and validation of network models describing these data to biological inferences made from the models. The conference will include platform sessions on interaction networks, signaling and network dynamics, regulatory networks, computational tools, artificial intelligence and big data, multi-scale networks, networks and disease, networks in differentiation, microbiome networks, network evolution, synthetic networks, network engineering and networks beyond biology though the exact program for the meeting will be assembled after the abstract submission deadline in February 2021 and adapted to ongoing developments in the field in subsequent years. This conference will include significant components designed to facilitate the active participation of younger scientists such as selection of platform speakers on the basis of the scientific merit of their submitted abstracts as well as poster presentations, round tables, lightning talks and poster prizes. Distinguished speakers will also be invited to give platform talks and interact with more junior scientists. The intimate environment at CSHL fosters social interactions and active participation by all. The majority of participants to the previous CSHL Network Biology meeting expressed that they were “very satisfied”. Speakers' panels have consisted of at least 50% women; the gender balance will be maintained in future meetings. In the 2019 iteration of the meeting, a panel discussion was established to address the challenges of Women in Network Science. We will continue to address big community challenges though panel discussions in this meeting. In 2021, we will discuss Applicability and Translatability of Network Biology with panelists including network biologists whose work is deeply influential throughout the ongoing covid-19 pandemic. PROJECT NARRATIVE Biological systems are functionally and structurally formed by complex networks of interacting molecular components, many of which are encoded in the genome. Elucidating the structure and function of these networks and understanding how their dysregulation causes disease are critical steps toward improving human health. This application seeks support for the conference on Network Biology to be held every two years in March/April 2021-25 at the Cold Spring Harbor Laboratory, to bring together experimental and computational biologists and discuss emerging trends and latest results in the field.",CSHL Network Biology Conference,10137390,R13HG011550,"['Address', 'Animals', 'Artificial Intelligence', 'Attention', 'Awareness', 'Big Data', 'Biochemistry', 'Biological', 'Biological Process', 'Biology', 'COVID-19 pandemic', 'Cell physiology', 'Cellular biology', 'Chalk', 'Collaborations', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Analyses', 'Development', 'Discipline', 'Disease', 'Engineering', 'Ensure', 'Environment', 'Equilibrium', 'Event', 'Evolution', 'Faculty', 'Fostering', 'Future', 'Gender', 'Gene Proteins', 'Generations', 'Genetic', 'Genome', 'Geography', 'Health', 'Human', 'Industrialization', 'Influentials', 'International', 'Intervention', 'Knowledge', 'Laboratories', 'Length of Stay', 'Lightning', 'Methodology', 'Microbe', 'Modeling', 'Molecular', 'Nationalities', 'New York', 'Normal Cell', 'Organism', 'Participant', 'Plants', 'Postdoctoral Fellow', 'Prize', 'Process', 'Property', 'Published Comment', 'RNA', 'Reagent', 'Reproducibility', 'Research', 'Research Institute', 'Research Personnel', 'Rotation', 'Schedule', 'Science', 'Scientist', 'Signal Transduction', 'Social Interaction', 'Structure', 'Technology', 'Validation', 'Woman', 'Work', 'base', 'biological systems', 'career', 'computer science', 'computerized tools', 'data exchange', 'data reuse', 'design', 'graduate student', 'host-microbe interactions', 'improved', 'innovation', 'interdisciplinary collaboration', 'interest', 'meetings', 'microbiome', 'multidisciplinary', 'network models', 'posters', 'precision medicine', 'programs', 'senior faculty', 'social', 'symposium', 'trend', 'unpublished works']",NHGRI,COLD SPRING HARBOR LABORATORY,R13,2021,3000
"Fast and flexible Bayesian phylogenetics via modern machine learning Project Abstract/Summary The SARS-CoV-2 pandemic underlines both our susceptibility to and the toll of a global pathogen outbreak. Phylogenetic analysis of viral genomes provides key insight into disease pathophysiology, spread and po- tential control. However, if these methods are to be used in a viral control strategy they must reliably account for uncertainty and be able to perform inference on 1,000s of genomes in actionable time. Scaling Bayesian phylogenet- ics to meet this need is a grand challenge that is unlikely to be met by optimizing existing algorithms.  We will meet this challenge with a radically new approach: Bayesian variational inference for phylogenet- ics (VIP) using ﬂexible distributions on phylogenetic trees that are ﬁt using gradient-based methods analogous to how one efﬁciently trains massive neural networks. By taking a variational approach we will also be able to integrate phylogenetic analysis into very powerful open-source modeling frameworks such as TensorFlow and PyTorch. This will open up new classes of models, such as neural network models, to integrate data such as sampling location and migration patterns with phylogenetic inference. These ﬂexible models will inform strategies for viral control.  In Aim 1 we will develop the theory necessary for scalable and reliable VIP, including subtree marginal- ization, local gradient updates needed for online algorithms, convergence diagnostics, and parameter support estimates. We will implement these algorithms in our C++ foundation library for VIP. In Aim 2 we will develop a ﬂexible TensorFlow-based modeling platform for phylogenetics, enabling a whole new realm of phylogenetic models based on neural networks to learn phylodynamic heterogeneity with minimal program- ming effort. We will provide efﬁcient gradients to this implementation via our C++ library. In Aim 3 we will use the fact that VIP posteriors are durable and extensible descriptions of the full data posterior to enable dynamic online computation of variational posteriors, including divide-and-conquer Bayesian phylogenetics. This work will enable a cloud-based viral phylogenetics solution to rapidly update our current estimate of the posterior distribution when new data arrive or the model is modiﬁed. 1 Project Narrative We have seen in the current SARS-CoV-2 pandemic, as for all major pathogen outbreaks in the last decade, how phylogenetic (i.e. evolutionary tree) methods are required to use viral genomic information to under- stand large-scale transmission patterns. However, current phylogenetic methods have two major limitations as a tool for viral control: ﬁrst, rigorous Bayesian probabilistic methods cannot scale to 1,000s of genomes, and second, models incorporating phylogenetic trees must be expressed in specialized phylogenetics pack- ages, making modern machine-learning approaches impossible. In this proposal, we develop variational ap- proaches to phylogenetics, which will allow fast inference and procedures to rapidly update inferences when new data arrives, as well as making phylogenetic trees a ﬁrst-class inferential object in major machine-learning packages. 1",Fast and flexible Bayesian phylogenetics via modern machine learning,10266670,R01AI162611,"['Age', 'Algorithms', 'Back', 'Bayesian Method', 'COVID-19 pandemic', 'Code', 'Collection', 'Complex', 'Computational Biology', 'Custom', 'Data', 'Data Set', 'Diagnostic', 'Discipline', 'Disease', 'Disease Outbreaks', 'Epidemic', 'Foundations', 'Functional disorder', 'Genome', 'Graph', 'Heterogeneity', 'Learning', 'Libraries', 'Location', 'Machine Learning', 'Markov chain Monte Carlo methodology', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Nature', 'Neural Network Simulation', 'Pattern', 'Phylogenetic Analysis', 'Predisposition', 'Procedures', 'Public Health', 'Research Personnel', 'Sampling', 'Statistical Models', 'Structural Models', 'Structure', 'Technology', 'TensorFlow', 'Time', 'Training', 'Trees', 'Uncertainty', 'Update', 'Variant', 'Viral', 'Viral Genome', 'Work', 'base', 'cloud based', 'data modeling', 'epidemiologic data', 'flexibility', 'genomic data', 'high dimensionality', 'insight', 'knowledge base', 'mathematical algorithm', 'mathematical methods', 'migration', 'neural network', 'novel strategies', 'open source', 'pathogen', 'prevent', 'scale up', 'social exclusion', 'theories', 'tool', 'transmission process', 'user-friendly', 'viral genomics', 'viral transmission']",NIAID,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2021,797370
"Integrating Biology into In Silico Methodologies: Modern approaches for incorporating biological reasoning and understanding into computational methods. 1 This proposal is for PA-18-648, NIH Support for Conferences and Scientific Meetings –  2 funding intended to help finance a two-day standalone “SOT CCT” workshop titled Integrating  3 Biology into In Silico Methodologies: Modern Approaches for incorporating biological  4 reasoning and understanding into computational methods. As a “Contemporary Concepts  5 in Toxicology” meeting, this workshop has the full backing, including being financially  6 underwritten, by the Society of Toxicology.  7 Computational modeling is an important tool for assessing the safety and use of  8 chemicals across many industries, including chemical, pharmaceutical, and consumer products.  9 Moreover, in silico methodologies offer academia and regulatory a fast and cheap method of 10 prioritizing its efforts to maintain compliance and safety in the market and environment. 11 This conference is designed to promote the development of actionable insights and 12 methodologies for increasing the biological relevance of in silico solutions. Specifically, this 13 conference will focus on solving the “black box effect”. There are many ways to validate a 14 model’s accuracy and domain – however if the model cannot explain what is happening 15 biologically, its use is severely diminished. This workshop will bring together regulatory, 16 academia, industry, and service providers to discuss current solutions and efforts, as well as 17 ongoing and future research. One goal of this conference will be to develop a roadmap for the 18 incorporation of AOPs (and similar biological reasonings) for computational tools. 19 This workshop has great appeal for multiple stakeholders within toxicology, namely 20 industry, academia, regulators, as well as service providers. The use of machine-learning to 21 replace laboratory toxicological tests is paramount to the future of the industry (3Rs). The use 22 of in silico models are explicitly referenced by NICEATM’s U.S. Strategic Roadmap, as well as 23 TSCA. Moreover, many industries and regulatory entities are taking significant steps away from 24 animal testing. Most recently, the US EPA stated that it will eliminate animal testing by 2035. 25 This workshop will bring together different stakeholders to discuss the current state of 26 AOPs and in silico methodologies, and to work towards a unified approach for their 27 incorporation. The final outcome of the workshop will be a white-paper that not only reviews the 28 current landscape but discusses concretes steps, as outlined in the breakout session, needed 29 for the regulatory acceptance of machine learning technologies – specifically a roadmap for the 30 inclusion of AOPs into computational tools and explanations. This proposal is for PA-18-648, NIH Support for Conferences and Scientific Meetings – funding intended to help finance a two-day standalone “SOT CCT” workshop titled Integrating Biology into In Silico Methodologies: Modern Approaches for incorporating biological reasoning and understanding into computational methods. This workshop will bring together different stakeholders to discuss the current state of AOPs and in silico methodologies, and to work towards a unified approach for their incorporation. The final outcome of the workshop will be a white- paper that not only reviews the current landscape but discusses concretes steps, as outlined in the breakout session, needed for the regulatory acceptance of machine learning technologies – specifically a roadmap for the inclusion of AOPs into computational tools and explanations.",Integrating Biology into In Silico Methodologies: Modern approaches for incorporating biological reasoning and understanding into computational methods.,10144727,R13ES032662,"['Academia', 'Address', 'Adoption', 'Animal Testing', 'Animals', 'Back', 'Biological', 'Biology', 'Budgets', 'Chemicals', 'Chemistry', 'Communities', 'Computer Models', 'Computing Methodologies', 'Decision Making', 'Development', 'Educational workshop', 'Environment', 'Event', 'Funding', 'Future', 'Goals', 'In Vitro', 'Individual', 'Industry', 'Laboratories', 'Laws', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'National Institute of Environmental Health Sciences', 'Nonprofit Organizations', 'Outcome', 'Paper', 'Pathway interactions', 'Pharmacologic Substance', 'Policies', 'Process', 'Publishing', 'Safety', 'Societies', 'System', 'Technology', 'Testing', 'Toxicology', 'United States National Institutes of Health', 'Work', 'adverse outcome', 'cheminformatics', 'computer framework', 'computerized tools', 'consumer product', 'cost', 'design', 'improved', 'in silico', 'in vivo', 'insight', 'meetings', 'predictive modeling', 'research and development', 'service providers', 'symposium', 'tool', 'web site']",NIEHS,"TOXTRACK, LLC",R13,2021,4000
"Human-like automated radiotherapy treatment planning via imitation learning PROJECT SUMMARY Radiation therapy is one of the major approaches for cancer treatment. Treatment planning, the process of designing the optimal treatment plan for each patient, is one of the most critical steps. If a treatment is poorly designed, a satisfactory outcome cannot be achieved, regardless of the quality of other treatment steps. Treatment planning in modern radiotherapy is formulated as a mathematical optimization problem defined by a set of hyperparameters. While there exists several quantifiable metrics to quantify plan quality and guide the planning process, these are simplified representations that cannot fully describe the physician’s intent. In addition, these metrics only measure plan quality from a population-based perspective, and cannot guide treatment planning to achieve the patient-specific best treatment plans. Hence, the best physician-preferred solution often sits in a gray area, only achievable by an extensive trial-and-error hyperparameter tuning process and interactions between the planner and physician. Consequently, planning time can take up to a week for complex cases and plan quality may be poor, if the planner is inexperienced and/or under heavy time constraints. These consequences substantially deteriorate treatment outcomes, as having been clearly demonstrated in clinical studies. Recently, the advancement in artificial intelligence (AI), particularly in imitation learning allows human- like decision making by observing a human expert’s actions and internally building its own decision-making system. In response to PAR-18-530, the goal of this project is to develop and translate an AI planner that mimics human experts’ behavior to generate a high quality plan. The AI planner will not replace human planners. Instead, the AI plan will be used as a starting point in the current planning process to improve plan quality and planning efficiency. The human planner’s actions on further plan improvement can feed back to the AI planner through continuous learning for its continuous evolution. We will pursue this goal using prostate cancer as the test bed through an academic-industrial partnership, jointing strong research and clinical expertise at UT Southwestern Medical Center with extensive commercial product development experience at Varian Medical Systems Inc. The following specific aims are defined. Aim 1: Model and algorithm development. We will collect experts’ behavior data in routine treatment planning and train the AI planner. Aim 2: System validation and translation. We will integrate the AI planner into Varian Eclipse treatment planning system and validate the system in a clinically realistic setting. The innovations include the use of a state-of-the-art AI imitation learning algorithm to solve a clinically important problem, the novel technological capabilities enabled by the developed system, as well as coherent translation activities to deliver new capabilities to end users. Deliverability is ensured by extensive preliminary studies and the partnership integrating complementary expertise and resources. Clinical translation of the AI planner will bring substantial impacts to radiotherapy by providing high-quality and efficient treatment planning to benefit patients, especially those in resource-limited regions. NARRATIVE Treatment planning for radiation therapy, where an optimal treatment strategy is designed for each individual patient and executed for the whole treatment course, plays a central role for the success of radiation therapy treatment. The current treatment planning workflow is inefficient and produces plans with sub-optimal quality, substantially deteriorating treatment outcomes. Jointing strong research and clinical expertise at UT Southwestern Medical Center with extensive commercial product development experience at Varian Medical Systems Inc, this project will develop and translate an artificial intelligence planner that is capable of efficiently generating high quality treatment plans.",Human-like automated radiotherapy treatment planning via imitation learning,10143143,R01CA254377,"['Anatomy', 'Area', 'Artificial Intelligence', 'Attention', 'Back', 'Beds', 'Behavior', 'Cancer Patient', 'Caring', 'Clinical', 'Clinical Research', 'Communities', 'Complex', 'Complication', 'Data', 'Decision Making', 'Development', 'Dose', 'Due Process', 'Ensure', 'Environment', 'Evaluation', 'Evolution', 'Feedback', 'Goals', 'Growth', 'Head and Neck Cancer', 'Human', 'Intention', 'Joints', 'Learning', 'Malignant neoplasm of prostate', 'Manuals', 'Mathematics', 'Measures', 'Medical', 'Medical center', 'Mind', 'Modality', 'Modeling', 'Modernization', 'Normal tissue morphology', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Play', 'Probability', 'Process', 'Radiation therapy', 'Research', 'Resources', 'Role', 'Scheme', 'Site', 'Structure', 'System', 'Testing', 'Time', 'Training', 'Translating', 'Translations', 'Treatment Step', 'Treatment outcome', 'Validation', 'algorithm development', 'base', 'cancer therapy', 'chemotherapy', 'clinical translation', 'design', 'experience', 'head and neck cancer patient', 'improved', 'individual patient', 'industry partner', 'innovation', 'learning algorithm', 'learning progression', 'model development', 'negative affect', 'novel', 'optimal treatments', 'population based', 'product development', 'prototype', 'response', 'routine practice', 'success', 'treatment planning', 'treatment strategy', 'tumor', 'validation studies']",NCI,UT SOUTHWESTERN MEDICAL CENTER,R01,2021,626797
"Manifold representations and active learning for 21 st century biology Project Summary With the rise of high-throughput sequencing and multiplexed biotechnologies enabling single-cell multi-omics and massively parallel CRISPR experiments, the biomedical community is generating a monumental amount of data. These data promise to reveal new biology and drive personal and precision medicine. However, the sheer volume of genomic data is overwhelming current computational resources, requiring prohibitively high compute time, memory usage, and storage. My lab has been at the forefront of solving big data challenges in genomics, designing novel algorithms that enable efficient and secure analyses that were previously computationally infeasible, and that reveal novel structural, cellular, and systems biology. Drawing upon our expertise in developing scalable and insightful algorithms for analyzing genomic, transcriptomic, and proteomic data, we aim to tackle two key data-driven challenges facing the biological community: 1) efficient, accurate, and robust characterization of tissues at the single-cell level, and 2) translating high-throughput datasets into biological discoveries via machine learning-based prediction. To solve the first challenge, we will leverage our discovery that seemingly high-dimensional sequencing data often lies on low-dimensional manifolds that capture the underlying biological state of interest. We will design algorithms that generate these compact, meaningful manifold representations of single-cell omics datasets. This will enable a number of key applications including characterizing co-expression and gene-modules that define healthy and pathologic cell states; integrating multi-modal single-cell omics datasets to more richly characterize cellular diversity; and investigating the mechanisms underlying transcriptomic diversity across tissues and developmental states. To solve the second challenge, we will take a two-pronged approach. First, we will design novel machine learning frameworks that provide a measure of confidence when predicting in unfamiliar biological states, enabling prediction that is robust to “out-of-distribution” (unobserved) examples. We will then work with our experimental collaborators and CROs to rapidly perform experimental validation of model-based predictions. Finally, we will return the experimental results to the model to further improve performance. This will enable an “active learning” feedback loop to efficiently explore a complex biological space for outcomes of interest. We will use this uncertainty-powered active learning approach to explore several pressing biological concerns such as the identification of small molecule compounds with enzymatic or whole-cell growth inhibitory properties, efficient design of spatial- transcriptomic experiments, computationally guided CRISPR perturbation experiments, and identification of functional non-coding mutations. This project will result in 1) numerous software tools with wide utility that efficiently analyze massive biological datasets and guide complex experimentation, and 2) reveal biological insights, especially into biomolecular interactions and cellular heterogeneity. Project Narrative The rise of high-throughput genomic profiling of individual cells and efficient, targeted manipulation of cellular phenotypes (including CRISPR-based genetic perturbations) promise to revolutionize our understanding of cellular biology and disease. However, realizing this revolution will require new computing paradigms that can integrate and analyze these massive datasets and suggest new biological hypotheses and experimental designs. Here we develop novel computational algorithms and software for tackling these challenges to characterize cellular diversity and improve our ability to manipulate cells to understand and treat disease.",Manifold representations and active learning for 21 st century biology,10207091,R35GM141861,"['Active Learning', 'Algorithm Design', 'Algorithmic Analysis', 'Algorithmic Software', 'Algorithms', 'Big Data', 'Biological', 'Biology', 'Biotechnology', 'Cells', 'Cellular biology', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Communities', 'Complex', 'Computational algorithm', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Experimental Designs', 'Feedback', 'Genes', 'Genetic', 'Genomics', 'Heterogeneity', 'High-Throughput Nucleotide Sequencing', 'Individual', 'Machine Learning', 'Measures', 'Memory', 'Modeling', 'Mutation', 'Outcome', 'Pathologic', 'Performance', 'Phenotype', 'Property', 'Proteomics', 'Secure', 'Software Tools', 'Spatial Design', 'State Interests', 'Systems Biology', 'Time', 'Tissues', 'Translating', 'Uncertainty', 'Untranslated RNA', 'Validation', 'Work', 'base', 'cell growth', 'computing resources', 'design', 'experimental study', 'genomic data', 'high dimensionality', 'improved', 'insight', 'interest', 'multimodality', 'multiple omics', 'novel', 'precision medicine', 'small molecule', 'structural biology', 'transcriptomics']",NIGMS,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,R35,2021,478341
"An Agent-Based Modeling Platform for Environmental Biotechnology Hazardous pollutants in the environment continue to threaten public health and environmental  safety. Human exposure to major contaminant classes, such as polyfluorinated compounds  (PFCs), hazardous organic compounds (HOCs), and heavy metals, has been linked to a variety of  diseases and is subject to stringent State and Federal environmental regulations.  Bioremediation is a low-cost and environmentally friendly approach with many successful  use-cases; however, conventional bioremediation technologies can suffer from unreliability, low  degradation rates, and incomplete degradation. As stakeholders to Superfund sites and other sites  with water or soil pollution urgently demand more efficient, less costly and more reliable  remediation technologies, it is critical to look to advancements in computational  modeling to develop next-generation, precision-engineered bioremediation technologies. The proposed project builds on successful outcomes from Phase I in which a new computational  platform was designed and validated to accurately predict the bioremediation kinetics of  a multi-organism microcosm degrading a combination of HOCs in groundwater. The basis of  this platform is an approach called agent-based modeling (ABM), where the functions of  individual components (e.g. microorganisms) within complex ecosystems are used to predict and  optimize system-level properties (e.g. bioremediation kinetics). In this Phase II project, the novel computational platform developed in Phase I is  further improved with a machine learning component that leverages bioinformatics  databases to develop rationally tailored microbiomes for degrading complex pollutant  mixtures. Iterative experimental validation of model outputs is conducted using an innovative  materials science platform that maintains the relative concentration of different species in the  microbiome constant within the multi-zone treatment barrier (in-situ) or multi-zone bioreactor  (ex-situ). The project includes focused development of a prototype for one bioremediation use-case,  which is directly compared to a conventional (non-precision) bioremediation system treating   actual contaminated groundwater. This will be performed in order to assess and quantify  the expected technical and economic benefits of harnessing the project's novel computational  platform in biotechnology development. The broad, long-term impact of the proposed project will be to transform the development and  implementation of bioremediation by integrating advancements in computational modeling, machine  learning, bioinformatics, and materials science. By leveraging novel tools across disciplines, the  project will accelerate the development of more precise, reliable and inexpensive technologies for  environmental remediation. The successful outcome of the proposed project will also provide new  collaborative opportunities for industry and academia to more rapidly address the remediation of  high-priority pollutants in the environment, and ultimately help mitigate the effects of hazardous  pollutants on communities impacted by the presence of environmental contamination. PROJECT NARRATIVE Contaminated soils and waters continue to threaten public health and safety. This project builds on the development of a novel computational platform for predicting the complex, dynamic interactions between microbial ecosystems and hazardous contaminants-of-concern in the environment, and to utilize this information to develop improved engineered remediation biotechnologies.",An Agent-Based Modeling Platform for Environmental Biotechnology,10158243,R44ES026541,"['Academia', 'Address', 'Biodegradation', 'Bioinformatics', 'Bioreactors', 'Bioremediations', 'Biotechnology', 'Chemicals', 'Classification', 'Colorado', 'Communities', 'Complex', 'Computer Models', 'Data', 'Databases', 'Development', 'Discipline', 'Disease', 'Economics', 'Ecosystem', 'Engineering', 'Environment', 'Environmental Monitoring', 'Environmental Pollution', 'Enzymes', 'Exposure to', 'Ginkgo biloba', 'Goals', 'Growth', 'Heavy Metals', 'In Situ', 'Indiana', 'Individual', 'Industry', 'Kinetics', 'Laboratories', 'Learning Module', 'Letters', 'Life', 'Link', 'Machine Learning', 'Modeling', 'Molecular', 'Municipalities', 'Organism', 'Outcome', 'Output', 'Phase', 'Polymers', 'Process', 'Property', 'Public Health', 'Regulation', 'Research', 'Safety', 'Side', 'Site', 'Soil', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Training', 'Universities', 'Validation', 'Water', 'Water Pollution', 'base', 'computational platform', 'cost', 'design', 'economic evaluation', 'enzyme pathway', 'exposed human population', 'ground water', 'improved', 'innovation', 'laboratory experiment', 'materials science', 'microbial', 'microbiome', 'microorganism', 'next generation', 'novel', 'pollutant', 'prototype', 'remediation', 'research and development', 'soil pollution', 'success', 'superfund site', 'tool']",NIEHS,"MICROVI BIOTECH, INC.",R44,2021,630992
"Accelerating Community-Driven Medical Innovation with VTK Abstract Thousands of medical researchers around the world use VTK —the Visualization Toolkit— an open-source, freely available software development toolkit providing advanced 3D interactive visualization, image processing and data analysis algorithms. They either use VTK directly in their in-house research applications or indirectly via one of the multitude of medical image analysis and bioinformatics applications that is built using VTK: Osirix, 3D Slicer, BioImageXD, MedINRIA, SCIRun, ParaView, and others. Furthermore, VTK also provides 3D visualizations for clinical applications such as BrainLAB’s VectorVision surgical guidance system and Zimmer’s prosthesis design and evaluation platform. VTK has been downloaded many hundreds of thousands of times since its initial release in 1993. Considering its broad distribution and prevalent use, it can be argued that VTK has had a greater impact on medical research, and patient care, than any other open-source visualization package.  This proposal is in response to the multitude of requests we have been receiving from the VTK medical community. The aims are as follows:  1. Aim 1: Adaptive visualization framework: Produce an integrated framework that supports  visualization applications that balance server-side and client-side processing depending on data size,  analysis requirements, and the user platform (e.g., phone, tablet, or GPU-enabled desktop).  2. Aim 2: Integrated, interactive applications: Extend VTK to support a diversity of programming  paradigms ranging from C++ to JavaScript to Python and associated tools such as Jupyter Notebooks,  integrating with emerging technologies such as deep learning technologies.  3. Aim 3: Advanced rendering, including AR/VR: Target shader-based rendering systems and AR/VR  libraries that achieve high frame rates with minimal latency for ubiquitous applications that combine  low-cost, portable devices such as phones, ultrasound transducers, and other biometric sensors for  visually monitoring, guiding, and delivering advanced healthcare.  4. Aim 4: Infrastructure, Outreach, and Validation: Engage the VTK community and the proposed  External Advisory Board during the creation and assessment of the proposed work and corresponding  modern, digital documentation in the form of videos and interactive web-based content. Project Narrative The Visualization Toolkit (VTK) is an open source, freely available software library for the interactive display and processing of medical images. It is being used in most major medical imaging research applications, e.g., 3D Slicer and Osirix, and in several commercial medical applications, e.g., BrainLAB’s VectorVision surgical guidance system. VTK development began in 1993 and since then an extensive community of users and developers has grown around it. However, the rapid advancement of cloud computing, GPU hardware, deep learning algorithms, and VR/AR systems require corresponding advances in VTK so that the research and products that depend on VTK continue to deliver leading edge healthcare technologies. With the proposed updates, not only will existing applications continue to provide advanced healthcare, but new, innovative medical applications will also be inspired.",Accelerating Community-Driven Medical Innovation with VTK,10091434,R01EB014955,"['3-Dimensional', 'Adopted', 'Algorithmic Analysis', 'Algorithms', 'Bioinformatics', 'Biomechanics', 'Biomedical Technology', 'Biometry', 'Client', 'Cloud Computing', 'Cloud Service', 'Code', 'Communities', 'Computational Geometry', 'Computer software', 'Data', 'Data Analyses', 'Development', 'Devices', 'Documentation', 'Emerging Technologies', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Explosion', 'Foundations', 'Funding', 'Grant', 'Health Technology', 'Healthcare', 'Hybrids', 'Image Analysis', 'Industry', 'Infrastructure', 'Internet', 'Language', 'Letters', 'Libraries', 'Licensing', 'Medical', 'Medical Imaging', 'Medical Research', 'Methods', 'Modernization', 'Monitor', 'Online Systems', 'Operative Surgical Procedures', 'Patient Care', 'Prevalence', 'Process', 'Prosthesis Design', 'Publications', 'Pythons', 'Research', 'Research Personnel', 'Resources', 'Side', 'Surveys', 'System', 'Tablets', 'Techniques', 'Technology', 'Telephone', 'TensorFlow', 'Testing', 'Time', 'Training', 'Ultrasonic Transducer', 'Update', 'Validation', 'Virtual and Augmented reality', 'Visual', 'Visualization', 'Work', 'base', 'clinical application', 'cloud based', 'computerized data processing', 'cost', 'deep learning', 'deep learning algorithm', 'design', 'digital', 'health care delivery', 'image processing', 'innovation', 'interest', 'learning strategy', 'meetings', 'new technology', 'open source', 'outreach', 'point of care', 'portability', 'processing speed', 'real world application', 'response', 'sensor', 'software development', 'statistics', 'success', 'supercomputer', 'synergism', 'three-dimensional visualization', 'tool', 'trend', 'web services']",NIBIB,"KITWARE, INC.",R01,2021,498914
"Maternal Antecedents and Electronic Fetal Monitoring in Term Asphyxia (MAESTRA) Neonatal hypoxic-ischemic encephalopathy (HIE) is a neurologic syndrome that results from reduced flow of oxygenated blood to the fetal or newborn brain. HIE occurs in 1-3 per 1,000 term births and may cause death or neurologic disabilities such as cerebral palsy. Electronic fetal monitoring (EFM) was developed in the 1970's to assess the adequacy of fetal oxygenation as a strategy to prevent HIE, and is now standard of care. Yet clinical trials report that EFM usage has not reduced the rate of CP, perinatal death or HIE, but is associated with a dramatic increase in cesarean deliveries. The currently used 3 Category fetal heart rate (FHR) classification system, based on simple rules designed to be easy to apply at the bedside, has some utility in predicting HIE. However, Category II FHR patterns that make up the vast majority of tracings are poorly predictive of HIE and confer “indeterminate” risk. Category III patterns are also of limited use in predicting HIE due to low sensitivity. There is an urgent need to develop better objective methods to assess EFM that would identify more fetuses at risk of HIE in time for corrective actions. Uterine tachysystole, or excessive frequency of uterine contractions, has been implicated as a preventable cause of HIE; yet studies report conflicting results. EFM research has been limited by an inability to access and manually analyze the large datasets needed to study HIE. We now have the ability to analyze digital EFM signals using automated methods to measure standard FHR patterns as well as to discover novel aspects of the tracing that may not be readily detectable by a clinician at the bedside. We hypothesize that modern signal processing and machine learning techniques can create highly predictive models of HIE by analyzing established and novel features of EFM tracings, in combination with demographic and pertinent clinical information from the mother and fetus. We propose a population-based retrospective cohort study of 350,000 infants born at ≥ 36 weeks gestation at Kaiser Permanente Northern California in 2010-19. Our specific aims are: 1) To create the MAESTRA Cohort dataset that links EFM recordings to HIE and neonatal acidosis among 350,000 infants born at ≥ 36 weeks gestation in 2010-19 at Kaiser Permanente Northern CA; 2) Using modern signal processing and machine learning techniques, to extract established and novel FHR and uterine contractility features from the EFM recordings, and to determine which of these features are most predictive of HIE and acidosis when combined with maternal and fetal clinical data; and 3) To perform external validation by applying the final predictive models to a historical dataset. We anticipate that machine learning techniques incorporating novel FHR and uterine contractility patterns over time, as well as pre- and perinatal clinical characteristics, will improve the predictive value of the EFM data that are already being collected as part of routine care. Our results will inform future clinical trials. Such an unprecedented large-scale multidisciplinary study will lead to improvements in our ability to use EFM data to prevent neonatal brain injury while minimizing unnecessary cesarean sections. MAESTRA Project Narrative Hypoxic-ischemic encephalopathy (HIE) occurs when a baby gets reduced oxygen and blood flow to the brain, and can lead to death or long-term disabilities such as cerebral palsy. During labor and delivery, doctors are able to continuously record the heart rate of the fetus. This study will determine how best to use the heart rate information so that we can reduce the number of infants who develop this severe brain condition.",Maternal Antecedents and Electronic Fetal Monitoring in Term Asphyxia (MAESTRA),10145055,R01HD099216,"['Acidosis', 'Address', 'Apgar Score', 'Asphyxia', 'Blood', 'Blood flow', 'Brain', 'California', 'Categories', 'Cause of Death', 'Cerebral Palsy', 'Cesarean section', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Cohort Studies', 'Computerized Medical Record', 'Conflict (Psychology)', 'Data', 'Data Set', 'Discipline of obstetrics', 'Educational workshop', 'Fetal Heart Rate', 'Fetal Monitoring', 'Fetus', 'Frequencies', 'Future', 'Heart Rate', 'Infant', 'Lead', 'Link', 'Machine Learning', 'Manuals', 'Metabolic Brain Diseases', 'Metabolic acidosis', 'Methods', 'Modeling', 'Modernization', 'Mothers', 'National Institute of Child Health and Human Development', 'Neonatal', 'Neonatal Brain Injury', 'Neurologic', 'Newborn Infant', 'Observational Study', 'Outcome', 'Oxygen', 'Pattern', 'Perinatal', 'Perinatal anoxic ischemic brain injury', 'Perinatal mortality demographics', 'Population', 'Positioning Attribute', 'Predictive Value', 'Pregnancy', 'Preventive Intervention', 'Records', 'Reporting', 'Research', 'Retrospective cohort study', 'Risk', 'Seizures', 'Sensitivity and Specificity', 'Signal Transduction', 'Syndrome', 'System', 'Techniques', 'Term Birth', 'Testing', 'Time', 'Uterine Contraction', 'Uterus', 'Validation', 'base', 'cohort', 'computerized', 'design', 'digital', 'disability', 'effectiveness evaluation', 'falls', 'fetal', 'fetus at risk', 'high risk', 'improved', 'large datasets', 'multidisciplinary', 'neonatal hypoxic-ischemic brain injury', 'novel', 'population based', 'predictive modeling', 'prevent', 'routine care', 'signal processing', 'standard measure', 'standard of care', 'uterine contractility']",NICHD,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2021,566881
"Developing novel technologies that ensure privacy and security in biomedical data science research Data science holds the promise of enabling new pathways to discovery and can improve the understanding, prevention and treatment of complex disorders such as cancer, diabetes, substance abuse, etc., which are significantly on the rise. The promise of data science can be fully realized only when collected data can be collaboratively shared and analyzed. However, the widespread increases in healthcare data breaches due to inappropriate access as well as the increasing number of novel privacy attacks restrict institutions from sharing data. Indeed, in some cases, the results of the analysis can themselves lead to significant privacy harm. The success of the data commons depends on ensuring the maximal access to data, subject to all of the patient privacy requirements including those mandated by legislation, and all of the constraints of the organization collecting the data itself. While there are existing solutions that can solve parts of the problem, there are significant challenges in truly incorporating these into comprehensive working solutions that are usable by the biomedical research community, and new challenges brought on by modern techniques such as deep learning. The long-term goal of this research is to develop technologies that can holistically enable data sharing while respecting privacy and security considerations and to ensure that they are implemented in existing platforms that have widespread acceptance in the research community. Towards this, the objective of this project is to develop complementary solutions for risk inference, distributed learning, and access control that can enable different modalities of data sharing. The problems studied are general in nature and will evolve depending on research successes and new impediments that arise. The proposed program of research is significant since lack of access to biomedical data can lead to fragmentation of care, resulting in higher economic and social costs, and is a significant impediment to biomedical research. The project will result in open-source, freely available software tools that will be integrated into widely used data collection, cohort identification, and distributed analytics platforms. There are several ongoing collaborations that will serve as initial pilot customers to provide use cases, identify the requirements, evaluate results, and in general validate the developed solutions. Project Narrative Statement of Relevance to Public Health Being able to ensure privacy and security while enabling data sharing and analysis is critical to pave the way forward for public health research and improve our understanding of diseases. The proposed work will address the challenges that impede the use of data across all of the different modalities of data sharing. The integration into existing platforms will ensure that the developed models, tools, and solutions directly impact the research community and improve public health interventions.",Developing novel technologies that ensure privacy and security in biomedical data science research,10077318,R35GM134927,"['Address', 'Biomedical Research', 'Collaborations', 'Communities', 'Complex', 'Data', 'Data Analyses', 'Data Collection', 'Data Commons', 'Data Science', 'Diabetes Mellitus', 'Disease', 'Economics', 'Ensure', 'Goals', 'Healthcare', 'Institution', 'Lead', 'Learning', 'Malignant Neoplasms', 'Modality', 'Modeling', 'Modernization', 'Nature', 'Pathway interactions', 'Prevention', 'Privacy', 'Public Health', 'Research', 'Risk', 'Security', 'Software Tools', 'Statutes and Laws', 'Substance abuse problem', 'Techniques', 'Technology', 'Work', 'biomedical data science', 'care fragmentation', 'cohort', 'cost', 'data sharing', 'deep learning', 'improved', 'new technology', 'novel', 'open source', 'patient privacy', 'programs', 'public health intervention', 'public health research', 'social', 'success', 'tool']",NIGMS,RUTGERS THE STATE UNIV OF NJ NEWARK,R35,2021,383279
"A Geometric and Morphoelastic Study of Aortic Dissection Evolution Project Summary/Abstract: The natural evolution of aortic dissection is notoriously unpredictable under current methods of evaluation and management. There is an urgent need to more completely elucidate the biomechanical stability of type B aortic dissections and identify signatures in the imaging data allowing for optimal patient classification based on aortic fragility. The long-term goal is the development and validation of image-based analysis algorithms to classify aortic stability and allow a personalized risk stratification for a given patient’s aortic geometry providing the basis for optimizing clinical management. The overall objective of this proposal is to utilize modern approaches in differential geometry, continuum mechanics, and computer vision to discover and characterize high-risk geometric structures hidden within computed tomography angiography (CTA) data of fragile aortas. The central hypothesis of this application is the existence of a fundamental link between aortic shape and aortic stability as it relates to the risk of aortic dissection and fragility. The rationale for this work is development of an easily translatable geometry and mechanics-based algorithm to predict dissection stability and intervention timing by discovering a richer and more nuanced mapping of aortic shapes hidden in existing patient imaging data. The central hypothesis will be tested by pursuing three specific aims: 1) develop a modern geometric classification for aortic shapes, 2) develop a computational model that provides the mechanism underpinning the shape evolution of aortic dissections, and 3) develop a modern successor to the traditional ‘maximum diameter’ measure of aortic dissections that integrates geometric, finite element, and physiologic factors. Utilizing a large pre-identified CTA data set of normal and dissected aortas at various stages of disease and intervention, aim 1 will use tools from computer vision to reduce aortic shape to distributions of shape index and curvedness. Aim 2 will utilize advanced morphoelastic finite element growth models to discover the biomechanical mechanism underpinning aortic shape changes in aortic dissections and validate these models on patient specific geometries over clinically relevant time periods. These novel shape and mechanical stability classifiers will be used in both linear and non-linear dimensionality reduction methods to define aortic shape sub-spaces for different clinical scenarios in aim 3. This proposal is innovative as it challenges the status quo of evaluation and treatment by deploying novel measures and techniques that analyze clinically relevant aortic geometry and the evolution of aortic shape. Every patient is taken to the operating room under the full intent of having a positive clinical outcome. The research outlined is significant because it is expected to provide surgeons and patients a more discriminative framework with which to make better informed management decisions concerning type B aortic dissections and ultimately optimize outcomes. Project Narrative: The proposed research is relevant to public health because it seeks to inform upon the potential benefits of surgical versus medical intervention for type B aortic dissection through the development of modern geometric and mechanistically based selection criteria. Upon completion there will be a richer and more nuanced understanding of aortic stability as defined from computed tomography angiography imaging, which will allow for more optimal patient selection. Thus, the proposed research is relevant to the part of the NIH’s mission to enhance cardiovascular health and improve mortality.",A Geometric and Morphoelastic Study of Aortic Dissection Evolution,10280305,R01HL159205,"['Algorithmic Analysis', 'Algorithms', 'Angiography', 'Aorta', 'Behavior', 'Biomechanics', 'Caliber', 'Cessation of life', 'Characteristics', 'Classification', 'Clinical', 'Clinical Management', 'Clinical Pathways', 'Computer Models', 'Computer Vision Systems', 'Data', 'Data Set', 'Development', 'Dimensions', 'Disease', 'Dissection', 'Elasticity', 'Elements', 'Equilibrium', 'Evaluation', 'Evolution', 'Failure', 'Foundations', 'Geometry', 'Goals', 'Growth', 'Image', 'Injury', 'Intervention', 'Link', 'Maps', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Mission', 'Modeling', 'Modernization', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Pathway interactions', 'Patient Selection', 'Patient imaging', 'Patients', 'Pattern', 'Physiological', 'Principal Component Analysis', 'Probability', 'Process', 'Public Health', 'Research', 'Risk', 'Role', 'Scanning', 'Selection Criteria', 'Shapes', 'Stress', 'Surgeon', 'System', 'Techniques', 'Testing', 'Time', 'United States National Institutes of Health', 'Validation', 'Walking', 'Work', 'X-Ray Computed Tomography', 'base', 'biomechanical model', 'blood pressure variability', 'cardiovascular health', 'clinically relevant', 'density', 'differential geometry', 'geometric structure', 'high risk', 'improved', 'indexing', 'individual patient', 'innovation', 'mortality', 'novel', 'patient population', 'preservation', 'risk stratification', 'simulation', 'surgical risk', 'tool']",NHLBI,UNIVERSITY OF CHICAGO,R01,2021,459189
"Biomechanical Analysis in Strabismus Surgery We propose 3 interrelated aims to define the biomechanics of the eye rotating (extraocular) muscles (EOMs) & optic nerve (ON) in health & visual disease, understand novel EOM actions, & characterize mechanical effects that may contribute to severe myopia. We aim to improve treatment of strabismus, misalignment of visual directions of the eyes; glaucoma & non-arteritic anterior ischemic optic neuropathy (NA-AION), both common blinding ON diseases; & high axial myopia, an ocular elongation & distortion that has become a worldwide epidemic & major cause of blindness. We propose a novel & critical nexus linking the EOMs, ON, & structure of the eye's scleral wall that we will explore using modern imaging & artificial intelligence techniques. Aim I will clarify the kinematic (motion) properties of the human eye, testing by multipositional magnetic resonance imaging (MRI) of the eyeball & EOMs the hypothesis that translational (linear) movement contributes importantly to ocular alignment. MRI will be performed during horizontal convergence & vertical eye rotation in normal people, & in patients who have common forms of strabismus including convergence insufficiency, eye crossing (esotropia), & outward ocular deviation (exotropia), both before & after corrective EOM surgery. Clarification of ocular translation is necessary to understand normal ocular motility and treat its disorders. Aim II will characterize the mechanical loading on the ON caused by eye movements. We will characterize the mechanical effects of ON tractional loading on the eyeball during horizontal & vertical eye rotations at 2 scales in living people, to test the hypothesis that such ON loading deforms it & adjacent retina & blood vessels as loading translates the eye. We propose that the resulting deformation during eye movements may create repetitive strain injury contributing to glaucoma, NA-AION, & axial myopia. In groups of subjects with the foregoing diseases, & in an equal group of matched healthy subjects, we will study mechanical effects of eye movement within the living eye by imaging its internal micro structure & blood vessels with optical coherence tomography, & outside the eyeball in the eye socket using MRI. Effects of tethering during eye movement will be studied ex vivo by precision 3D optical imaging of fresh human eye bank specimens subjected to mechanical tension on the ON that mimic effects of the eye movements imaged in the living subjects. Aim III will model the biomechanics of ocular kinematics. The constitutive mechanical properties of the non-muscular ocular & eye socket tissues will be described by finite element models (FEMs) using modern engineering methods for computational simulation to predict ocular kinematics, as well as local mechanical strains in the ON & sclera that may cause glaucoma, NA-AION, & the ocular deformities underlying extreme nearsightedness. We will determine if FEMs employing normal tissue properties can simulate normal ocular translation during horizontal & vertical rotations & convergence. By FEM simulation, we will also test the hypothesis that ocular loading by eye movement might contribute to: normal vergence, strabismus, & the effects of strabismus surgery. Relevance. Strabismus is a common clinical disorder that can cause double vision in adults and vision loss in children. Strabismus is often treated by surgical manipulation of the eye muscles, although current knowledge of their structure and function is incomplete. Proposed functional imaging and biomechanical studies of the properties of the eye muscles, eyeball, and optic nerve will improve understanding of the causes and treatment of strabismus, optic nerve diseases, and nearsightedness.",Biomechanical Analysis in Strabismus Surgery,10134346,R01EY008313,"['3-Dimensional', 'Accounting', 'Adult', 'Agreement', 'Algorithms', 'Anatomy', 'Anterior Ischemic Optic Neuropathy', 'Artificial Intelligence', 'Behavior', 'Biological Specimen Banks', 'Biomechanics', 'Blindness', 'Blood Vessels', 'Child', 'Choroid', 'Clinical', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Connective Tissue', 'Convergence Insufficiency', 'Cumulative Trauma Disorders', 'Deformity', 'Degenerative Myopia', 'Diplopia', 'Disease', 'Duct (organ) structure', 'Elements', 'Engineering', 'Epidemic', 'Equilibrium', 'Esotropia', 'Etiology', 'Exotropia', 'Eye', 'Eye Banks', 'Eye Movements', 'Failure', 'Functional Imaging', 'Gap Junctions', 'Glaucoma', 'Health', 'Human', 'Image', 'Individual', 'Knowledge', 'Lasers', 'Link', 'Magnetic Resonance Imaging', 'Matched Group', 'Measurement', 'Measures', 'Mechanics', 'Modeling', 'Modernization', 'Motion', 'Movement', 'Muscle', 'Muscle Contraction', 'Myopia', 'Normal tissue morphology', 'Ocular orbit', 'Operative Surgical Procedures', 'Ophthalmoscopy', 'Optic Disk', 'Optic Nerve', 'Optical Coherence Tomography', 'Optics', 'Patients', 'Physiologic Intraocular Pressure', 'Play', 'Primary Open Angle Glaucoma', 'Property', 'Retina', 'Role', 'Rotation', 'Scanning', 'Sclera', 'Strabismus', 'Stress', 'Structure', 'Techniques', 'Testing', 'Therapeutic', 'Tissues', 'Traction', 'Translating', 'Translations', 'Validation', 'Variant', 'Visual', 'anatomic imaging', 'biomechanical model', 'cell motility', 'crosslink', 'digital imaging', 'ex vivo imaging', 'human tissue', 'improved', 'in vivo imaging', 'in vivo optical imaging', 'kinematics', 'mechanical load', 'mechanical properties', 'model development', 'models and simulation', 'monocular', 'neglect', 'novel', 'ocular imaging', 'optic nerve disorder', 'optical imaging', 'orbit muscle', 'predictive modeling', 'quantitative imaging', 'retina blood vessel structure', 'simulation']",NEI,UNIVERSITY OF CALIFORNIA LOS ANGELES,R01,2021,584907
"Large-scale data integration and harmonization to accurately predict sites facing future health-based drinking water crises Project summary: Up to 45 million people per year in the U.S. are directly impacted by health-based drinking water problems. This leads to at least 16 million cases of acute gastroenteritis directly linked to pollution at community water systems, with tens of millions more directly impacted by chemical and organic pollutants. Impacts are further exacerbated in locations dealing with water scarcity, in under-served populations, and within other vulnerable populations already suffering from health disparities. Many of these water problems are the direct result of managerial negligence, inconsistent monitoring, and a lack of the ability to anticipate where problems may arise next. While the reasons for drinking water problems are complex, if we could anticipate where health-based drinking water problems were to occur in the future, it could have an immediate and positive impact on tens of millions of Americans annually. Interestingly, extensive data about water quality and the performance of municipal water systems already exists in large, disparate databases. These databases are largely ignored and, when used, are typically used only anecdotally and retroactively. Preliminary evidence suggests that these existing databases, which contain histories of administrative violations and sub-threshold water-quality results, can be mined to accurately predict future drinking water crises. The Superior Statistical Research R&D team is an internationally recognized group of water experts with cross-cutting expertise in statistics/data analysis/modelling/computing, water-quality monitoring of biological and chemical contaminants, and the ability to clearly and compellingly translate water-quality and health information to actionable steps for individuals, organizations and communities. In this Phase I project, we will show that it is possible to predict water-related, health-based problem areas utilizing already collected, historical data on water quality and municipal water system performance. We will begin by harmonizing the disparate water quality and municipal water system performance in two different states (Michigan and Iowa). We will then utilize machine-learning techniques to predict health-based violation histories and will evaluate our methods by comparing predicted violations to actual health-based violations in the previous 5 years. Finally, we will identify at least 10 municipalities determined by our algorithm to be at the highest risk for future health- based water problems and will do systematic sampling to confirm our model-based predictions. We will then demonstrate how making these predictions can be leveraged to profitability by exploring how our model-based predictions can be presented to customers in an economical, usable form. Proof of our concept and profitability models in two states (Phase I) will set us up for widespread (multi-state) database harmonization and improvement of the proposed machine-learning/modelling effort in Phase II. With multi-state harmonized datasets, identification of key data gaps in particular states/areas, and proven financial models, our technology will ultimately lead to dramatic reductions in the number of health-based drinking water problems annually. Project Narrative Up to 45 million people per year in the U.S. are directly impacted by health-based drinking water problems, but predicting where and when these health-based drinking water problems will occur remains a large and complex obstacle. Current approaches focus on a reactive approach to health-based water-quality violations in community water systems, rather than a proactive one that seeks to anticipate where problems will occur in the future. The overall goal of this project is to leverage large and disparate historical datasets of water quality to accurately predict locations of future health-based water-quality violations, validate the predictions, and commercialize our proprietary predictions as a practical and cost-saving approach to anticipating and heading off future health-based water problems.",Large-scale data integration and harmonization to accurately predict sites facing future health-based drinking water crises,10253600,R43ES033134,"['Acute', 'Address', 'Algorithms', 'American', 'Area', 'Biological Monitoring', 'Chemicals', 'Cities', 'Coal', 'Communities', 'Community Surveys', 'Complex', 'Cost Savings', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Ensure', 'Exposure to', 'Filtration', 'Focus Groups', 'Future', 'Gastroenteritis', 'Goals', 'Government', 'Health', 'Human', 'Individual', 'International', 'Iowa', 'Lead', 'Lead levels', 'Link', 'Location', 'Machine Learning', 'Methods', 'Michigan', 'Modeling', 'Monitor', 'Municipalities', 'Negligence', 'Pathway interactions', 'Performance', 'Persons', 'Phase', 'Pollution', 'Price', 'Provider', 'Public Health', 'ROC Curve', 'Recording of previous events', 'Records', 'Research', 'Safety', 'Sampling', 'Serinus', 'Site', 'Surveys', 'System', 'Techniques', 'Technology', 'Testing', 'Translating', 'Trust', 'Underserved Population', 'Vulnerable Populations', 'Water', 'advocacy organizations', 'base', 'commercialization', 'data harmonization', 'data integration', 'drinking water', 'economic impact', 'health disparity', 'high risk', 'improved', 'inner city', 'innovation', 'large scale data', 'member', 'pollutant', 'predictive modeling', 'research and development', 'rural area', 'statistics', 'water quality', 'water sampling', 'water testing', 'willingness to pay']",NIEHS,"SUPERIOR STATISTICAL RESEARCH, LLC",R43,2021,256579
"Methods for Evolutionary Genomics Analysis Summary/Abstract Continuing advances in nucleotide sequencing have resulted in the assembly of datasets containing large numbers of species, genes, and genomic segments. Phylogenomic analyses of these data are essential to progress in understanding evolutionary patterns across the tree of life, and are finding increasing numbers of applications in practical analyses that require understanding of how patterns change over time. The sheer size of phylogenomic datasets limits the practical utility of available methods due to excessive time and memory requirements. We have developed many high impact methods and tools for comparative analysis of molecular sequences, a tradition we propose to continue through this MIRA project by developing innovative methods that address new challenges in phylogenomics. We will focus on pattern-based approaches of machine learning with sparsity constraint (SL) applied to phylogenomics, as a complement to traditional model-based methods in molecular evolution and phylogenetics. In the proposed SL in Phylogenomics (SLiP) framework, we will build models that best explain the biological trait or evolutionary hypothesis of interest, with genomic loci, such as genes, proteins, and genomic segments, serving as model parameters. Preliminary results from two example applications establish the premise and promise of a general SLiP framework. In one, SLiP successfully detected loci whose inclusion in a phylogenomic dataset overtakes a consistent and contrasting signal from hundreds of other loci when inferring phylogenetic relationships. In the other example, SLiP revealed loci and biological functional categories that harbor convergent sequence evolutionary patterns associated with the emergence of the same trait in distinct evolutionary lineages. In all of these analyses, SLiP required only a small fraction of the computational time and memory demanded by traditional methods, and it enabled better evolutionary contrasts with fewer assumptions. Consequently, the successful development of SLiP will improve the feasibility, rigor, and reproducibility of large-scale data analysis. It will also democratize big data analytics via shortened analysis time and a relatively small memory footprint, and encourage the development of a new class of methods for phylogenomic analysis. This framework will be accessed from a free library of SLiP functions, which will be directly useable via command line and available in a graphical interface through integration with the MEGA software. Narrative The long-term goal of my research program is to develop methods and tools for comparative analysis of molecular sequences. In this project, we will develop a new class of phylogenomic methods based on sparse machine learning and benchmark their absolute and relative performance. New techniques and their software implementation will greatly facilitate data analyses that are vital for evolutionary and functional genomics.",Methods for Evolutionary Genomics Analysis,10086181,R35GM139540,"['Address', 'Benchmarking', 'Big Data Methods', 'Biological', 'Categories', 'Complement', 'Computer software', 'Data Analyses', 'Data Set', 'Development', 'Gene Proteins', 'Genes', 'Genomic Segment', 'Genomics', 'Goals', 'Libraries', 'Life', 'Machine Learning', 'Memory', 'Methods', 'Modeling', 'Molecular Analysis', 'Molecular Evolution', 'Nucleotides', 'Pattern', 'Performance', 'Phylogenetic Analysis', 'Reproducibility', 'Research', 'Signal Transduction', 'Techniques', 'Time', 'Trees', 'base', 'comparative', 'functional genomics', 'genomic locus', 'graphical user interface', 'improved', 'innovation', 'interest', 'large scale data', 'programs', 'tool', 'trait']",NIGMS,TEMPLE UNIV OF THE COMMONWEALTH,R35,2021,396250
"Detection and characterization of critical under-immunized hotspots - Summer Undergraduate Support Detection and characterization of critical under-immunized hotspots  Emergence of undervaccinated geographical clusters for diseases like measles has become a national concern. A number of measles outbreaks have occurred in recent months, despite high MMR coverage in the United States ( 95%). Such undervaccinated clusters can act as reservoirs of infection that can transmit the disease to a wider population, magnifying their importance far beyond what their absolute numbers might indicate. The existence and growth of such undervaccinated clusters is often known to public health agencies and health provider networks, but they typically do not have enough resources to target people in each such cluster, to attempt to improve the vaccination rate. Preliminary results show that not all undervaccinated clusters are “equal” in terms of their potential for causing a big outbreak (referred to as its “criticality”), and the rate of undervaccination in a cluster does not necessarily correlate with its criticality.  However, there are no existing methods to estimate the potential risk of such clusters, and to identify the most “critical” ones. Some of the key reasons are: (i) purely data-driven spatial statistics methods rely only on immunization coverage, which does not give any indication of the risk of an outbreak; and (ii) current causal epidemic models need to be combined with detailed incidence data, which has not been easily available.  This proposal brings together a systems science approach, combining agent-based stochastic epidemic models, and techniques from machine learning, high performance computing, data mining, and spatial statistics, along with novel public and private datasets on immunization and incidence, to develop a novel methodology for identifying critical clusters, through the following tasks: (i) Identify spatial clusters with signiﬁcantly low immunization rates, or strong anti-vaccine sentiment; (ii) Develop an agent based model for the spread of measles that incorporates detailed immunization data, and is calibrated using a novel source of incidence data; (iii) Develop methods to ﬁnd and characterize critical spatial clusters, with respect to different metrics, which capture both epidemic and economic burden, and order underimmunized clusters based on their criticality; and (iv) Use the methodology to evaluate interventions in terms of their effect on criticality. A highly interdisciplinary team involving two universities, a health care delivery organization and a state department of Health, will work together to develop this methodology. Characterization of such clusters will enable public health departments and policy makers in targeted surveillance of their regions and a more efﬁcient allocation of resources. Project Narrative  This project will develop a new methodology to quantify the potential risks of under-vaccinated spatial clusters for highly infectious diseases. It will rank the clusters based on their economic and epidemic burden which will enable public health ofﬁcials in targeted surveillance and interventions, to mitigate their risk.",Detection and characterization of critical under-immunized hotspots - Summer Undergraduate Support,10393815,R01GM109718,"['Communicable Diseases', 'Data', 'Data Set', 'Detection', 'Disease', 'Disease Clusterings', 'Disease Outbreaks', 'Economic Burden', 'Economics', 'Epidemic', 'Geography', 'Growth', 'Health', 'Health Personnel', 'High Performance Computing', 'Immunization', 'Immunize', 'Incidence', 'Infection', 'Intervention', 'Machine Learning', 'Measles', 'Methodology', 'Methods', 'Modeling', 'Policy Maker', 'Population', 'Privatization', 'Public Health', 'Resource Allocation', 'Resources', 'Risk', 'Science', 'Source', 'System', 'Techniques', 'United States', 'Universities', 'Vaccinated', 'Vaccination', 'Vaccines', 'Work', 'base', 'data mining', 'health care delivery', 'improved', 'novel', 'provider networks', 'statistics', 'undergraduate student']",NIGMS,UNIVERSITY OF VIRGINIA,R01,2021,11253
