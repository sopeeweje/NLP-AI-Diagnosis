text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Efficient Statistical Learning Methods for Personalized Medicine Using Large Scale Biomedical Data Project Summary/Abstract  Current medical treatment guidelines largely rely on data from randomized controlled trials that study  average effects, which may be inadequate for making individualized decisions for real-world patients. Large-scale electronic health records (EHRs) data provide unprecedented opportunities to optimize personalized treatment strategies and generate evidence relevant to real-world patients. However, there are inherent challenges in the use of EHRs, including non-experimental nature of data collection processes, heterogeneous data types with complex dependencies, irregular measurement patterns, multiple dynamic treatment sequences, and the need to balance risk and benefit of treatments. Using two high-quality EHR databases, Columbia University Medical Center's clinical data warehouse and the Indiana Network for Patient Care database, and focusing on type 2 diabetes (T2D), this proposal will develop novel and scalable statistical learning approaches that overcome these challenges to discover optimal personalized treatment strategies for T2D from real-world patients. Specifically, under Aim 1, we will develop a unified framework to learn latent temporal processes for feature extraction and dynamic patient records representation. Our approach will accommodate large-scale variables of mixed types (continuous, binary, counts) measured at irregular intervals. They extract lower-dimensional components to reflect patients' dynamic health status, account for informative healthcare documentation processes, and characterize similarities between patients. Under Aim 2, we will develop fast and efficient multi-category machine learning methods, in order to evaluate treatment propensities and adaptively learn optimal dynamic treatment regimens (DTRs) among the extensive number of treatment options observed in the EHRs. The methods will provide  sequential decisions that determine the best treatment sequence for a T2D patient given his/her EHRs. Under Aim 3, we will develop statistical learning methods to assist multi-faceted treatment decision-making, which balances risks versus benefits when evaluating a DTR. Our approach will ensure maximizing benefit to the greatest extent while controlling all risk outcomes under the safety margins. For all aims, we will develop efficient stochastic resampling algorithms to scale up the optimization for massive data sizes. We will identify optimal DTRs for T2D using the extracted information from patients' comorbidity conditions, medications, and laboratory tests, as well as records-collection processes. Our methodologies will be applied and cross-validated between the two EHR databases. The treatment strategies learned from the representative EHR databases with a diverse patient  population will be beneficial for individual patient care, assisting clinicians to adaptively choose the optimal treatment for a patient. Finally, we will disseminate our methods and results through freely available software and outreach to the informatics and clinical experts at our Centers for Translational Science and elsewhere. Project Narrative  This proposal aims to develop novel and scalable statistical learning methods to analyze electronic health records (EHRs) and use two real-world, high-quality EHR databases for personalized medicine research. The methods will handle the non-experimental nature of data collection processes, along with heterogeneous data types, dynamic treatment sequences, and the trade-off between benefit and risk outcomes. The results will complement the current knowledge base for individual patient care using evidence generated from patients in real-world clinical practices.",Efficient Statistical Learning Methods for Personalized Medicine Using Large Scale Biomedical Data,10129392,R01GM124104,"['Academic Medical Centers', 'Address', 'Adverse event', 'Algorithms', 'Benefits and Risks', 'Categories', 'Center for Translational Science Activities', 'Classification', 'Clinical', 'Collaborations', 'Collection', 'Complement', 'Complex', 'Computer software', 'Data', 'Data Collection', 'Databases', 'Decision Making', 'Dependence', 'Dimensions', 'Documentation', 'Electronic Health Record', 'Ensure', 'Equilibrium', 'Exclusion Criteria', 'Formulation', 'Gaussian model', 'Goals', 'Health', 'Health Status', 'Healthcare', 'Healthcare Systems', 'Heterogeneity', 'Indiana', 'Informatics', 'International', 'Knowledge', 'Laboratories', 'Learning', 'Length', 'Measurement', 'Measures', 'Medical', 'Methodology', 'Methods', 'Modeling', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Outcome', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Pharmaceutical Preparations', 'Process', 'Quality Control', 'Randomized Controlled Trials', 'Records', 'Research', 'Risk', 'Safety', 'Sampling', 'Structure', 'Testing', 'Time', 'Treatment Protocols', 'adaptive learning', 'adverse event risk', 'algorithmic methodologies', 'analytical tool', 'base', 'big biomedical data', 'clinical data warehouse', 'clinical decision-making', 'clinical encounter', 'clinical practice', 'comorbidity', 'complex data', 'data modeling', 'data space', 'design', 'evidence base', 'feature extraction', 'heterogenous data', 'individual patient', 'individualized medicine', 'knowledge base', 'learning strategy', 'machine learning method', 'novel', 'optimal treatments', 'outreach', 'patient population', 'personalized decision', 'personalized medicine', 'population based', 'scale up', 'statistical learning', 'temporal measurement', 'theories', 'treatment effect', 'treatment guidelines', 'treatment response', 'treatment strategy']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2021,328697
"Real-world outcomes of proliferative diabetic retinopathy PROJECT SUMMARY: Real-world outcomes of proliferative diabetic retinopathy Vision loss from diabetic retinopathy remains the leading cause of preventable blindness in working-aged adults in the United States (US). Advanced diabetic retinopathy is referred to as proliferative diabetic retinopathy (PDR). In many patients, blindness associated with PDR can be prevented with appropriate and timely diagnosis and treatment. Unfortunately, some patients at high risk for PDR are not receiving adequate eye care. More knowledge is needed about PDR outcomes in a real-world setting, and the differences between published study outcomes and real-world effectiveness. Electronic health records (EHRs) are used in nearly 90% of outpatient physician offices and can be a powerful tool for studying PDR in a real-world setting. The goal of this proposal is to develop and validate EHR-based methods to improve outcomes in PDR. The study aims are: (1) to classify patients with PDR in the EHR system using an automated method that incorporates structured (e.g., diagnosis code, medications, labs) and unstructured data (e.g., clinical notes), (2) to predict the progression of non-proliferative diabetic retinopathy to PDR using a forecasting model with time-varying covariates, and (3) to determine the real-world effectiveness of treatments for PDR in a large nationwide eye dataset. The study will utilize data from the University of California San Francisco’s (UCSF) De-Identified Clinical Data Warehouse, a de-identified EHR with over 1 million patients that has available eye exam information, and the Intelligent Research in Sight (IRIS) registry, a nationwide comprehensive eye database that includes data from over 15,000 eye providers in the US with over 1 million patients with PDR. The innovative methods and tools from this study can be applied to other eye conditions to facilitate future EHR- based clinical studies in ophthalmology. The candidate, Dr. Catherine Sun is an ophthalmologist whose long- term goal is to study real-world clinical outcomes in ophthalmology by conducting EHR-based pragmatic clinical trials and using large-scale EHR data. While she possesses the foundational skills, additional mentored training and coursework in data analytics, biomedical informatics, biostatistics, and advanced clinical trial design and implementation will help her reach her goals. Her outstanding mentorship team of primary mentor Dr. Nisha Acharya and co-mentors Dr. Travis Porco and Dr. Joshua Stein, and the exceptional environment of the Department of Ophthalmology and the F.I. Proctor Foundation at UCSF will support Dr. Sun’s development into an R01-funded independent investigator. PROJECT NARRATIVE Proliferative diabetic retinopathy (PDR) represents advanced diabetic eye disease and can result in permanent vision loss. The electronic health record (EHR) can be a powerful tool for studying real-world outcomes of conditions like PDR to help prevent disease occurrence and improve outcomes. We will develop and validate EHR-based methods and tools to improve outcomes in PDR, which can also be applied to other eye conditions to facilitate future EHR-based clinical studies in ophthalmology.",Real-world outcomes of proliferative diabetic retinopathy,10191673,K23EY032637,"['Adult', 'Algorithms', 'Anatomy', 'Background Diabetic Retinopathy', 'Biometry', 'Blindness', 'California', 'Caring', 'Classification', 'Clinical', 'Clinical Research', 'Clinical Trials Design', 'Clinical effectiveness', 'Code', 'Data', 'Data Analytics', 'Data Set', 'Databases', 'Development', 'Diabetic Retinopathy', 'Diagnosis', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Environment', 'Ethnic Origin', 'Eye', 'Eye diseases', 'Foundational Skills', 'Foundations', 'Funding', 'Future', 'General Hospitals', 'Goals', 'Health Insurance', 'Healthcare', 'Hospitals', 'ICD-9', 'Image', 'Infrastructure', 'Injections', 'Intelligence', 'Intervention', 'Knowledge', 'Light Coagulation', 'Manuals', 'Measures', 'Mentors', 'Mentorship', 'Methods', 'Modeling', 'Natural Language Processing', 'Observational Study', 'Ophthalmic examination and evaluation', 'Ophthalmologist', 'Ophthalmology', 'Outcome', 'Outcome Study', 'Outpatients', 'Participant', 'Patient Recruitments', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Physicians&apos', ' Offices', 'Pragmatic clinical trial', 'Prospective Studies', 'Provider', 'Publishing', 'Race', 'Randomized Controlled Trials', 'Registries', 'Reporting', 'Research', 'Research Personnel', 'Retrospective Studies', 'Risk Factors', 'San Francisco', 'Structure', 'System', 'Techniques', 'Testing', 'Text', 'The Sun', 'Time', 'Training', 'Treatment Effectiveness', 'United States', 'Universities', 'Vascular Endothelial Growth Factors', 'Vision', 'Visual', 'aged', 'base', 'biomedical informatics', 'clinical data warehouse', 'comparison intervention', 'cost effectiveness', 'design', 'diabetic', 'follow-up', 'health disparity', 'high risk', 'improved', 'improved outcome', 'innovation', 'low socioeconomic status', 'medication compliance', 'novel', 'predictive modeling', 'prevent', 'primary outcome', 'proliferative diabetic retinopathy', 'risk stratification', 'routine care', 'structured data', 'tool', 'treatment as usual', 'unstructured data']",NEI,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",K23,2021,252236
"COVID-19 disease course analysis using multi-site large-scale EHR data Project Summary/Abstract  Since its ﬁrst case reported in December 2019, the coronavirus disease-2019 (COVID-19) has caused a pan- demic in 188 countries/regions, and has precipitated an unprecedented health, economic and social crisis. In order to cope with the volatile dynamic and severity of the pandemic, it is imperative that we characterize the various clinical courses of COVID-19 infection, and determine whether and how demographic, clinical and other variables inﬂuence them. Knowledge of the disease's transmission, symptomatology, clinical course, treatment and outcomes is rapidly evolving based on many sources. An important source for advancing this knowledge is data from electronic health records (EHR) and health information exchanges (HIE) because they can pro- vide a real-time, unvarnished view of the disease. Using large-scale, well-integrated and rich EHR data enables comprehensive proﬁling and quantiﬁcation of the COVID-19 disease course that can directly inform clinical prac- tice. The long-term goal of our research is to develop Artiﬁcial Intelligence (AI) tools to facilitate access to and analysis of clinical data. The goal of this application is to develop effective algorithms and tools to mine clinical data to categorize disease courses of COVID-19, and determine the effect of clinical and other variables asso- ciated with them. We will develop our algorithms using data from a large and comprehensive health information exchange, the Indiana Network for Patient Care (INPC), which has about 40,000 COVID-19 patients and fairly complete EHR data about them. We will evaluate the algorithms against other data sets, including EHR data from the OSU Wexner Medical Center and the National COVID Cohort Collaborative (N3C). The speciﬁc aims of this project are to (1) develop COVID-19 disease course groupings, (2) relate comorbidities and other clinical variables to the COVID-19 disease course, and (3) validate the developed algorithms on N3C data. This pro- posal is signiﬁcant because the methods developed in this project have the potential to signiﬁcantly increase our capability for computational analysis of large and rich patient data during the pandemic and beyond; the knowl- edge derived from our comprehensive proﬁling of COVID-19 courses over large, inclusive patient populations supported by rich EHR data can positively impact clinical practice; and the tools developed in this project will be released to the public as a free COVID-19 research re- source. It is innovative because our methods integrate novel methods such as patient clustering using clinical variables and disease progression trajectories, and pa- tient trajectory comparison, with established univariate and predictive analysis; our primary approach will lever- age the oldest and one of the country's largest HIEs to derive detailed and comprehensive knowledge about a large patient population; and the strong preliminary data generated by this project can help improve COVID-19 patient phenotyping, disease characterization and diagnosis. Project Narrative  The coronavirus disease-2019 (COVID-19) has caused a pandemic in 188 countries/regions, and has pre- cipitated an unprecedented health, economic and social crisis. It is imperative that we characterize the various clinical courses of COVID-19 infection, and determine whether and how demographic, clinical and other vari- ables inﬂuence them. This project will use large-scale, comprehensive EHR data from the Indiana Network for Patient Care (INPC), the Ohio State University Wexner Medical Center (OSUWMC) and National COVID Cohort Collaborative (N3C) to develop effective algorithms and tools to accomplish this goal.",COVID-19 disease course analysis using multi-site large-scale EHR data,10196001,R21LM013678,"['Address', 'Age', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'COVID-19', 'COVID-19 pandemic', 'COVID-19 patient', 'Cardiovascular Diseases', 'Caring', 'Case Study', 'Centers for Disease Control and Prevention (U.S.)', 'Chills', 'Clinical', 'Clinical Course of Disease', 'Clinical Data', 'Cluster Analysis', 'Communicable Diseases', 'Computer Analysis', 'Coronavirus', 'Coughing', 'Country', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Diabetes Mellitus', 'Diagnosis', 'Disadvantaged', 'Disease', 'Disease Management', 'Disease Progression', 'Dyspnea', 'Electronic Health Record', 'Fever', 'Functional disorder', 'Geographic Locations', 'Goals', 'Grouping', 'Guidelines', 'Headache', 'Health', 'Hypoxia', 'Image', 'Indiana', 'Interdisciplinary Study', 'Kidney Diseases', 'Knowledge', 'Lung', 'Medical center', 'Methods', 'Modeling', 'Myalgia', 'Ohio', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Physicians', 'Play', 'Pneumonia', 'Postdoctoral Fellow', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Respiratory Failure', 'Role', 'SARS-CoV-2 infection', 'Salvelinus', 'Severities', 'Severity of illness', 'Shock', 'Shortness of Breath', 'Signs and Symptoms', 'Site', 'Smell Perception', 'Source', 'Symptoms', 'System', 'Taste Perception', 'Time', 'Treatment outcome', 'Universities', 'Work', 'base', 'clinical effect', 'clinical practice', 'cohort', 'comorbidity', 'coronavirus disease', 'disease transmission', 'electronic data', 'health economics', 'improved', 'innovation', 'novel', 'pandemic disease', 'patient population', 'respiratory', 'response', 'social', 'symptomatology', 'tool']",NLM,OHIO STATE UNIVERSITY,R21,2021,229308
"Improving Quality of Electronic Health Record Ophthalmic Data for Big Data Analytics PROJECT SUMMARY The widespread adoption of EHRs has enabled the collection of massive amounts of digital ophthalmic data which have great potential for secondary use in research, quality improvement, and clinical decision support. While the amount of digital ophthalmic data recorded in the EHR is substantial and could be analyzed using the latest techniques for big data, questions about the quality of the data are a barrier to its reuse. Now that the American Academy of Ophthalmology has aggregated digital ophthalmic data from the EHR into the IRIS Registry, data quality is even more imperative for reaching the potential of the registry. To date, there has not be a comprehensive evaluation of the data quality of digital ophthalmic data, nor have there been any solutions for improving its quality. These are important gaps that will limit the utility of EHR data as a tool for knowledge discovery in ophthalmology. The goal of this grant is to assess the quality of digital ophthalmic exam data in order to improve its ability to be reused for research. Our hypothesis is that studying the variability of data quality in large datasets will provide insights into improving its quality. The first aim employs an established framework for data quality analysis to assess the intrinsic quality of a single institution’s EHR data as well as its fitness for use--the ability to be applied to a particular research scenario. In this proposal, we are evaluating the data’s ability to identify patient cohorts for clinical trials and to accurately calculate outcome based clinical quality measures. The variability in data’s quality and fitness among providers, subspecialties, diagnoses, and visit types will be analyzed. The second aim validates the analysis of the first aim by repeating it for all of the ophthalmic data in the IRIS Registry. For this analysis, the differences in quality and fitness between institutions and EHR vendors will also be assessed, along with the barriers to data quality and reuse. For both aims, ophthalmology experts will review the results to make recommendations for improving data quality and utility for digital ophthalmic data. In the future, these recommendations will provide a direction for correcting these quality issues and for ultimately advancing knowledge discovery in ophthalmic care. PROJECT NARRATIVE Electronic health records (EHRs) have not yet reached their potential for transforming healthcare, particularly for reusing clinical data for research. The American Academy of Ophthalmology has aggregated ophthalmic data from the EHR into the IRIS Registry, and data quality is even more imperative to achieve to reach the potential of this registry. Using methodological data quality analysis, we will analyze the quality of a single institution’s ophthalmic data and again for multiple institutions’ ophthalmic data in the IRIS Registry, documenting barriers for data quality and reuse that will lead to improving knowledge discovery from this data.",Improving Quality of Electronic Health Record Ophthalmic Data for Big Data Analytics,10149327,R21LM013937,"['Academy', 'Adoption', 'Age related macular degeneration', 'American', 'Big Data', 'Big Data Methods', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Collection', 'Complex', 'Data', 'Data Discovery', 'Data Store', 'Diabetic Retinopathy', 'Diagnosis', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Exfoliation Syndrome', 'Eye', 'Future', 'Glaucoma', 'Goals', 'Grant', 'Hand', 'Health Sciences', 'Healthcare', 'Human', 'Image', 'Individual', 'Informatics', 'Institutes', 'Institution', 'Intelligence', 'Iris', 'Knowledge Discovery', 'Manuals', 'Measurement', 'Measures', 'Medical Informatics', 'Medicine', 'Methodology', 'Methods', 'Ophthalmology', 'Oregon', 'Outcome', 'Patients', 'Process', 'Provider', 'Recommendation', 'Registries', 'Research', 'Research Personnel', 'Retinopathy of Prematurity', 'Secondary to', 'Source', 'Structure', 'System', 'Techniques', 'Terminology', 'Treatment outcome', 'Universities', 'Vendor', 'Vision', 'Visit', 'base', 'clinical decision support', 'clinical encounter', 'cohort', 'data framework', 'data harmonization', 'data quality', 'data registry', 'data reuse', 'data submission', 'deep learning', 'digital', 'electronic data', 'experience', 'fitness', 'improved', 'insight', 'large datasets', 'large scale data', 'research study', 'tool', 'treatment comparison']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2021,186725
"PheMAP: Measured, Automated Profile to Facilitate High Throughput Phenotyping Electronic health records (EHRs) are a powerful and efficient tool for biological discovery globally. However, a vital step for EHR-based research is valid, accurate, and reliable phenotyping (i.e., correctly identifying individuals with a particular trait of interest). Conventional approaches to phenotyping are ad hoc, domain expert dependent, rule-based, and usually specific to EHR environments. However, each requires an extensive investment of time and resources to develop due to the heterogeneity, complexity, inaccuracy, and frequent fragmentation of EHRs. The lack of general, automatic, and portable approaches to enable accurate high- throughput phenotyping is a critical barrier that hampers our ability to leverage valuable clinical data in EHRs for better healthcare. We propose a new generalizable high-throughput approach: Phenotyping by Measured, Automated Profile (PheMAP) that we have developed from public resources and will further refine and implement across various EHRs. We recognize that mass information about phenotypes is often described in significant detail and continuedly accumulated within publicly available resources (e.g., MedlinePlus and Wikipedia). We hypothesize this information can be retrieved, filtered, organized, measured, and formalized into standard EHR phenotype profiles. Indeed, we have used such an ensemble approach to integrate four generalizable online medication resources (e.g., SIDER and RxNorm) to create MEDI--a resource linking 2,136 medications and 13,304 indications. In preliminary studies, we extended this strategy to phenotyping and created a prototype PheMAP. For each phenotype, we identified relevant clinical concepts and weighted each based on its importance to the phenotype. We then mapped all associated concepts to commonly-used clinical terminologies. Our preliminary studies showed an average consistency of 98.6%±0.8% between our early-stage PheMAP and three validated eMERGE algorithms (Type 2 Diabetes, dementia, and hypothyroidism). We seek support to refine and optimize PheMAP and develop tools to allow researchers to implement PheMAP efficiently in different EHRs. This will allow researchers to rapidly and accurately determine the status of thousands of phenotypes for millions of individuals with minimal human intervention. Since PheMAP is created using independent resources that are more generalizable than a local clinical dataset, the implementation will generate more consistent outcomes in different EHRs for large-scale analyses.The work we propose is a necessary step toward being able to conduct high-throughput genome-wide and phenome-wide association analyses (GWASs and PheWASs). We will use data from multiple biobanks to accomplish these tasks. Specifically, we will achieve the following goals in this grant: 1.refine PheMAP and conduct large-scale validation, 2. implement PheMAP and perform representative GWASs and PheWASs, 3. Use PheMAP to conduct GWASs for unstudied or understudied diseases and phenotypes, and 4. Share PheMAP to facilitate research using EHRs. Electronic health records (EHRs) are a powerful and efficient tool for biological discovery globally while a vital step for EHR-based research is valid, accurate, and reliable phenotyping. Conventional approaches to phenotyping are ad hoc, domain expert dependent, rule-based, and usually specific to EHR environments. We propose to refine, validate, and share a new generalizable high-throughput approach: Phenotyping by Measured, Automated Profile (PheMAP) that allows researchers to rapidly and accurately determine the status of thousands of phenotypes for millions of individuals with minimal human intervention.","PheMAP: Measured, Automated Profile to Facilitate High Throughput Phenotyping",10095131,R01GM139891,"['Algorithms', 'Benchmarking', 'Biological', 'Catalogs', 'Clinical', 'Clinical Data', 'Data', 'Data Set', 'Dementia', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Environment', 'Evaluation', 'Genes', 'Genotype', 'Goals', 'Grant', 'Healthcare', 'Heritability', 'Heterogeneity', 'Human', 'Hypothyroidism', 'Individual', 'Institution', 'Intervention', 'Investments', 'Knowledge', 'Left', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Medical center', 'MedlinePlus', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Physicians', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Sensorineural Hearing Loss', 'Signal Transduction', 'Site', 'Statistical Models', 'Terminology', 'Time', 'Validation', 'Work', 'base', 'biobank', 'biomedical ontology', 'clinically relevant', 'cost', 'data modeling', 'disease phenotype', 'experience', 'genome wide association study', 'genome-wide', 'implementation tool', 'interest', 'novel', 'off-label drug', 'off-label use', 'phenome', 'phenotyping algorithm', 'portability', 'prototype', 'tool', 'trait']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,432500
"Quantifying Microbial Keratitis to Predict Outcomes: An Imaging and Epidemiologic Approach PROJECT SUMMARY/ABSTRACT For epidemiological studies, future clinical trials, and personalized patient care, there is a critical need to create a risk-stratification system for microbial keratitis. Microbial keratitis (MK), a debilitating, infectious corneal disease, is estimated to be the fourth-leading cause of blindness worldwide. MK severity depends on a complex interaction of patient, organism, and environment, resulting in a spectrum of clinical presentations and responses to treatment. Clinical presentations manifest with unique morphology features and clinical symptoms. Morphology features are visible in the cornea, and symptoms are measurable. But most patients are treated with non-specific broad-spectrum antimicrobials, an approach that increases antimicrobial resistance. This non-specific treatment approach lacks congruence with the unique MK presentations. There is a critical need for a new strategy to personalize treatments for MK and measure treatment efficacy. With quantified MK morphologic and clinical features, clinicians will have the tools to risk-stratify patients. The long-term goal is to develop rapid, objective, personalized treatment plans for patients with MK. This proposal’s objective is to quantify dynamic morphologic and clinical MK features using image and electronic health record (EHR) analyses and then build a risk-stratification scoring system associated with MK outcomes. The proposed research will test the hypothesis that morphologic and clinical features accurately risk- stratify patients for corneal and vision outcomes. Our premise is supported by preliminary data demonstrating that: (1) different organisms generate distinct morphologic and clinical features; (2) clinicians quantify morphology less precisely than image-analysis methods, (3) an expert is able to use MK features to tailor treatments; (4) the use of quantified features has improved outcomes in other diseases, such as diabetic retinopathy, by helping providers to tailor treatments; (5) EHR data can be used to quantify and classify clinical disease features accurately; and (6) EHR data can be used effectively to risk-stratify patients. Aim 1 will develop objective image analysis tools to measure features of MK with existing clinical equipment. Aim 2 will evaluate MK treatment efficacy using morphologic image analysis and clinical features from prospective surveys. Aim 3 will risk-stratify patients with MK by combining image analysis and EHR extracted data. The expected outcomes are: (1) characterized databases of MK images and linked clinical data, (2) quantified MK features across a spectrum of clinical presentations, (3) performance-tested, open-source imaging algorithms and surveys to measure MK markers dynamically, and (4) a novel risk stratification model and scoring system. The resultant work will have significant value to clinicians. Clinicians can use practical, low-cost technologies and readily-available EHR data to quantify MK features and risk-stratify patients in order to tailor treatments. NARRATIVE The clinical management of microbial keratitis is imprecise and dependent on the expertise of the treating physician. Our innovative strategies will quantify corneal features using image analysis and available clinical data from the electronic health record. Quantified image features will be linked to health outcomes to give physicians new tools to risk-stratify patients and to tailor their management to optimize outcomes.",Quantifying Microbial Keratitis to Predict Outcomes: An Imaging and Epidemiologic Approach,10113626,R01EY031033,"['Algorithms', 'Antimicrobial Resistance', 'Blindness', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Management', 'Clinical Trials', 'Complex', 'Control Groups', 'Cornea', 'Corneal Diseases', 'Data', 'Data Collection', 'Databases', 'Diabetic Retinopathy', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Enrollment', 'Environment', 'Epidemiology', 'Equipment', 'Evaluation', 'Eye', 'Future', 'Goals', 'Health', 'Image', 'Image Analysis', 'Inflammatory', 'Keratitis', 'Link', 'Measurable', 'Measurement', 'Measures', 'Methods', 'Michigan', 'Modeling', 'Morphology', 'National Eye Institute', 'Organism', 'Outcome', 'Participant', 'Patient Outcomes Assessments', 'Patients', 'Pharmaceutical Preparations', 'Physicians', 'Provider', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Self-Examination', 'Severities', 'Standardization', 'Strategic Planning', 'Surveys', 'Symptoms', 'System', 'Technology', 'Testing', 'Treatment Efficacy', 'Universities', 'Virulence', 'Vision', 'Visual Acuity', 'Work', 'antimicrobial', 'automated algorithm', 'base', 'care systems', 'case control', 'clinical risk', 'cost', 'deep learning', 'epidemiology study', 'healing', 'improved outcome', 'individualized medicine', 'innovation', 'microbial', 'novel', 'open source', 'outcome prediction', 'patient stratification', 'performance tests', 'personalized care', 'personalized medicine', 'primary outcome', 'prospective', 'risk stratification', 'slit lamp imaging', 'tool', 'treatment planning', 'treatment response']",NEI,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,397484
"ICLIC-MS for Enhancing Outcomes Research and Clinical Care in Multiple Sclerosis PROJECT SUMMARY Cognitive impairment, physical disability and progressive disease are common but understudied clinical outcomes that substantially impact employment and overall quality of life for individuals with multiple sclerosis (MS). We have recently developed and validated an assisted, web-based tool (ICLIC-MS) for systematic and longitudinal clinical outcomes data collection of MS-validated cognitive function measures, physical disability and progressive disease measures that are not reliably captured in the electronic health record (EHR). In response to FOA# PA-17-010, Use of Technology to Enhance Patient Outcomes and Prevent Illness, our team proposes the study of MS outcomes in a large, multi-ethnic population representative sample of more than 3,000 female and male MS cases from the Kaiser Permanente Northern California Health Plan Membership. We will integrate other EHR data such as important comorbid conditions, use of disease modifying therapy, MRI reports, as well as quality of life measures and employment histories. Our goals include: 1) comprehensively characterizing clinical outcomes in a large MS patient cohort; 2) developing and utilizing an integrated MS health report to enhance patient care; and 3) establishing a resource for clinical outcomes research in MS that also includes whole genomic and environmental exposure data. Findings from our proposed study represent an extraordinary opportunity to facilitate effective long-term management of MS, accelerate progress in the understanding of disease pathogenesis, predict patient trajectories and inform prevention strategies. We have assembled a team with strong expertise in clinical neurology/MS neurology, advanced epidemiologic methods, EHR structure and clinical care within a health maintenance organization, human genomics, biostatistics, and big data approaches. PROJECT NARRATIVE Our team has developed and validated an assisted web-based interface for longitudinal clinical data collection of cognitive function measures, physical disability and depression measures that are not reliably captured in the electronic health record (EHR) of multiple sclerosis (MS) patients. We will integrate several sources of patient data including genomic, clinical and EHR for 3,000 individuals to facilitate research and improve clinical care.",ICLIC-MS for Enhancing Outcomes Research and Clinical Care in Multiple Sclerosis,10160965,R01NR017431,"['Address', 'Area', 'Big Data', 'Biological', 'Biology', 'Biometry', 'California', 'Clinic', 'Clinic Visits', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Clinical assessments', 'Cognition', 'Cognitive', 'Collection', 'Consumption', 'Data', 'Data Collection', 'Development', 'Disease', 'Disease Progression', 'Electronic Health Record', 'Employment', 'Employment Status', 'Environmental Exposure', 'Epidemiologic Methods', 'Ethnic Origin', 'Ethnic group', 'Family', 'Female', 'Funding Opportunities', 'Genetic', 'Genomics', 'Goals', 'Health', 'Health Maintenance Organizations', 'Impaired cognition', 'Individual', 'Internet', 'Intervention', 'Lead', 'Light', 'Machine Learning', 'Magnetic Resonance Imaging', 'Measures', 'Mental Depression', 'Methods', 'Multiple Sclerosis', 'Neurologist', 'Neurology', 'Outcome', 'Outcome Measure', 'Outcome Study', 'Outcomes Research', 'Pathogenesis', 'Patient Care', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Pilot Projects', 'Population', 'Predictive Factor', 'Preparation', 'Prevention strategy', 'Primary Health Care', 'Progressive Disease', 'Quality of life', 'Race', 'Recording of previous events', 'Reporting', 'Research', 'Resources', 'Risk Factors', 'Sampling', 'Source', 'Structure', 'Technology', 'Testing', 'Time', 'Unemployment', 'Validity and Reliability', 'Visit', 'Work', 'base', 'clinical care', 'clinical outcome measures', 'cognitive function', 'cohort', 'comorbidity', 'disability', 'electronic data', 'health plan', 'human genomics', 'improved', 'male', 'member', 'multidisciplinary', 'multiple sclerosis patient', 'new technology', 'physically handicapped', 'prevent', 'programs', 'response', 'sex', 'web based interface', 'web-based tool']",NINR,UNIVERSITY OF CALIFORNIA BERKELEY,R01,2021,587963
"Identification of biologically relevant subtypes of hidradenitis suppurativa Project Summary Hidradenitis suppurativa (HS) is a neglected, prevalent, chronic, stigmatizing, and debilitating disease that has recently been prioritized for study by NIAMS. Evidence suggests that some HS patients choose to self-manage symptoms remaining unconnected to healthcare, and some seek medical care for repeated outbreaks of boils but never receive a diagnosis. Such ‘hidden populations’ create challenges for designing research studies that are generalizable. Precision medicine initiatives and resources offer opportunities to rapidly increase our knowledge about biological causes of HS and to improve the care that HS patients receive. For example, the NIH has made considerable investments in the development of data repositories that link genetic data to EHR for hundreds of thousands of patients, including the NHGRI-funded eMERGE Network and the NIH-funded All of Us Research Program. Columbia University investigators are integral members of these nationwide programs, both as a recruitment site, as well as a data and research center (5U01HG008680, 1OT2OD026556). Engaging research participants who are willing to contribute longitudinal data is a major obstacle to precision medicine initiatives. The public’s use of the Internet and social media to obtain and exchange health-related information has created opportunities to rapidly and efficiently assemble large longitudinal cohorts, yet there are important differences from traditional research methods and best practice guidelines have yet to be developed. Columbia University is at the forefront of the development and application of these methods. A major challenge to implementing precision medicine arises from patients who share a diagnosis but have different biological causes of disease. HS patients have a high burden of comorbidities and we hypothesize that sets of comorbidities that tend to present together in individual patients can be used to identify biologically relevant disease subtypes. Here we will use three approaches to identify patterns of comorbidities within patients, to characterize the generalizability of the results from studies conducted in EHR, and to use genetic data to biologically validate comorbidities and resolve causality underlying disease associations. Training in biomedical informatics and Internet-based survey research will allow the applicant to use EHR data and Internet resources for assembling cohorts to conduct these studies, and complement her previous training in epidemiology, biostatistics, molecular biology and human genetics, providing fluency across several domains that are crucial for advancing precision medicine initiatives. Completion of this proposal will achieve the applicant’s long-term goal of obtaining advanced training aimed at implementing precision medicine in the treatment of skin disease. Project Narrative This project addresses the imperative needs of hidradenitis suppurativa (HS) patients who suffer from pain, stigma, diminished quality of life, decreased work productivity, and increased healthcare costs that arise from managing a difficult-to-treat, debilitating disease with a high burden of comorbidities. We will conduct studies of HS comorbidities to identify biologically distinct subclasses of HS in large samples of patients using data in electronic health records and data collected from Internet surveys. This work will improve the precision of HS diagnoses and set up the infrastructure for future large-scale studies of HS.",Identification of biologically relevant subtypes of hidradenitis suppurativa,10160823,K01AR075111,"['Abscess', 'Address', 'Advertising', 'Affect', 'All of Us Research Program', 'Anogenital region', 'Attenuated', 'Automobile Driving', 'Axilla', 'Biological', 'Biology', 'Biometry', 'Caring', 'Chronic', 'Cicatrix', 'Clinical', 'Code', 'Communities', 'Complement', 'Consent', 'Data', 'Data Reporting', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Disease Outbreaks', 'Economic Burden', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Enrollment', 'Epidemiology', 'Etiology', 'Funding', 'Furuncles', 'Future', 'Genetic', 'Genetic Risk', 'Genome', 'Goals', 'Health', 'Health Care Costs', 'Healthcare', 'Heterogeneity', 'Hidradenitis Suppurativa', 'Human Genetics', 'Individual', 'Infrastructure', 'Inguinal region', 'International Classification of Disease Codes', 'Internet', 'Investments', 'Knowledge', 'Lead', 'Leg', 'Lesion', 'Link', 'Liquid substance', 'Literature', 'Longitudinal cohort', 'Maps', 'Medical', 'Medical Research', 'Mendelian randomization', 'Methods', 'Molecular Biology', 'Molecular Diagnosis', 'Mutation', 'National Human Genome Research Institute', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Pain', 'Participant', 'Pathogenesis', 'Patient Care', 'Patients', 'Pattern', 'Phenotype', 'Physiological', 'Plant Roots', 'Population', 'Practice Guidelines', 'Precision Medicine Initiative', 'Prevalence', 'Productivity', 'Publishing', 'Quality of life', 'Recording of previous events', 'Records', 'Recurrence', 'Research', 'Research Design', 'Research Methodology', 'Research Personnel', 'Research Training', 'Resources', 'Sampling', 'Site', 'Stigmatization', 'Subgroup', 'Surveys', 'Symptoms', 'Syndrome', 'Testing', 'Time', 'Training', 'Translational Research', 'Treatment outcome', 'United States National Institutes of Health', 'Universities', 'Validation', 'Work', 'arm', 'base', 'biomedical informatics', 'clinical Diagnosis', 'cohort', 'comorbidity', 'data repository', 'data resource', 'data sharing', 'design', 'disorder subtype', 'effective therapy', 'genome wide association study', 'health care service utilization', 'health data', 'improved', 'individual patient', 'instrument', 'large datasets', 'learning strategy', 'medically underserved', 'member', 'multidimensional data', 'neglect', 'online resource', 'patient engagement', 'patient stratification', 'patient subsets', 'precision medicine', 'prevent', 'programs', 'psychosocial', 'recruit', 'research study', 'skin disorder', 'social media', 'social stigma', 'symptom self management', 'tool', 'unsupervised learning', 'validation studies']",NIAMS,COLUMBIA UNIVERSITY HEALTH SCIENCES,K01,2021,121288
"Leveraging Electronic Health Records and Genomic Biobanks for Kidney Stone Disease PROJECT SUMMARY Kidney stones are highly prevalent and recurrent. Our current understanding of kidney stone disease risk factors and disease associations has relied primarily on data from chart review, nonspecific administrative datasets, and secondary analyses of observation studies. Current study designs suffer from small sample sizes, heterogenous patient groups, and lack of standardized accuracy data and outcome definitions. The widespread adoption of electronic health records (EHRs) provides novel research opportunities for kidney stone disease. EHRs contain a robust clinical repository of data collected over time from clinical care. However, there are currently limited tools to identify and characterize kidney stone patients in the EHR. The objective of this study is to establish feasibility of utilizing EHR data to investigate kidney stone disease. To structure EHR data in an efficient and cost-effective manner, natural language processing and deep learning methods can be designed for identifying and phenotyping kidney stone patients and clinical outcomes. Our de-identified EHR is linked to a DNA biobank that can enable investigation of genetic associations with disease. This project has two specific aims. In Aim 1, we will perform genetic association studies in our EHR and linked DNA biobank. We will replicate previously described associations with genetic variants and kidney stone disease. We will then perform a genome-wide association study to discover novel associations. In Aim 2, our goal is to develop and validate a computable framework to extract clinical outcomes of kidney stone disease from the EHR. Clinically meaningful outcomes include symptomatic stone passage and radiographic stone characterization. We will develop and test natural language processing and deep learning algorithms to extract keywords and context-based information in clinical notes and reports. We will train and test these algorithms using manual annotation as the gold standard. This aim will enable rigorous phenotyping of each kidney stone patient using structured and unstructured EHR data. Successful completion of this project will lay the groundwork towards advancing genomic medicine and precision health to support clinical decision-making in kidney stone patients. PROJECT NARRATIVE Our overall goal is to establish the feasibility of kidney stone research using electronic health record data. Genetic association studies will be performed to replicate known and discover new variants with kidney stone disease. A computerized framework will be developed and validated to extract kidney stone patient outcomes.",Leveraging Electronic Health Records and Genomic Biobanks for Kidney Stone Disease,10103906,R21DK127075,"['Address', 'Adoption', 'Algorithms', 'Area', 'Bioinformatics', 'Clinical', 'Clinical Data', 'Collaborations', 'Coronary heart disease', 'DNA', 'Data', 'Data Set', 'Diabetes Mellitus', 'Diagnostic radiologic examination', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Emergency department visit', 'Event', 'Future', 'Genetic Variation', 'Genetic study', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Hypertension', 'Investigation', 'Kidney Calculi', 'Link', 'Manuals', 'Methods', 'Mind', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phenotype', 'Precision Health', 'Radiology Specialty', 'Recurrence', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Risk Factors', 'Sample Size', 'Sampling', 'Scanning', 'Standardization', 'Structure', 'Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Variant', 'Vision', 'Work', 'artificial neural network', 'base', 'biobank', 'case control', 'clinical care', 'clinical data repository', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinically relevant', 'computerized', 'cost effective', 'deep learning', 'deep learning algorithm', 'design', 'disorder risk', 'electronic structure', 'genetic association', 'genetic variant', 'genome wide association study', 'genomic tools', 'knowledge base', 'learning strategy', 'machine learning algorithm', 'novel', 'phenotypic data', 'secondary analysis', 'support tools', 'text searching', 'tool', 'treatment response', 'unstructured data', 'web site']",NIDDK,VANDERBILT UNIVERSITY MEDICAL CENTER,R21,2021,259500
"Using Large Electronic Health Records and Advanced Analytics to Develop Predictive Frailty Trajectories in Patients with Heart Failure Candidate objective: My objective for this award is to become an independent quantitative scientist in analytical clinical research through structured training and mentored research experience. My goal is to become an academic leader and developer of advanced predictive models of health trajectories using electronic health records (EHR). Training objectives: I seek to sharpen my skill set as a clinical quantitative scientist using clinical informatics, EHR data warehouses, and advanced computational models. I will use the protected time provided by this award to gain proficiency in patient-clinician interactions, clinical informatics, natural language processing, and advanced survival analysis to accomplish my research aims. Background: Frailty is a complex clinical syndrome associated with aging and chronic illness. It decreases physiological reserves and increases vulnerability to stressors. The prevalence of frailty in patients with heart failure is 74%. The interplay of frailty and heart failure increases the risk for death, prolonged hospital stays, and functional dependence. One conceptual framework to operationalize frailty is accumulation of deficits: the frailty index (FI). The FI provides a risk score based on the assumption that the more ailments a patient has, the higher the risk of adverse outcomes, including mortality. Prior FI models have not been used in routine clinical practice due to the following limitations: insufficient number and range of clinical variables, lack of personalized deficit detection, use of data not commonly found in EHRs, insufficient use of longitudinal analytical models including survival analysis techniques, and the reduction of FI to a cross-sectional health status rather than a health trajectory. Research Aim: The overarching goal of this application is to develop a frailty trajectory (FT) for heart failure patients that provides information integrating prior functional impairment, current functional status, and future risk of mortality. In Aim 1, we will develop a novel cross-sectional FI that uses the full breadth of outpatient EHR data and innovative machine learning data science methods to predict mortality. In Aim 2, we will use serial cross-sectional FIs to build FTs and identify clusters of individuals following a similar progression of frailty over time. In Aim 3, we will compare the prognostic value of cross-sectional FI versus FT. The VA national EHR offers the ideal context for this study, as it provides longitudinal data since 1999 and can link to administrative data from non- VA sources, including linked Medicare databases. Mentoring & environment: A multidisciplinary mentoring team will supervise my training and will oversee my mentored research projects, formal coursework, directed reading, and career development. The proposed activities will provide a foundation for transitioning to an independent quantitative data scientist developing clinical decision aids to guide patient care. Baylor College of Medicine and the Center for Innovations in Quality, Effectiveness, and Safety have a national reputation of mentoring and supporting junior faculty members from diverse academic backgrounds to independent careers as clinical-investigators. Physical frailty is common in adults with heart failure and increases the risk for poor health outcomes. Clinicians need tools to identify adults with physical frailty as part of routine care to support early intervention to treat frailty and reduce this risk. This application seeks to develop a novel measure of physical frailty using data collected as part of routine clinical care and recorded in the electronic health record.",Using Large Electronic Health Records and Advanced Analytics to Develop Predictive Frailty Trajectories in Patients with Heart Failure,10199037,K25HL152006,"['Accident and Emergency department', 'Activities of Daily Living', 'Admission activity', 'Adult', 'Affect', 'Aging', 'American', 'Award', 'Big Data', 'Biological Models', 'Cessation of life', 'Chronic Disease', 'Clinical', 'Clinical Data', 'Clinical Informatics', 'Clinical Investigator', 'Clinical Research', 'Code', 'Complex', 'Computer Models', 'Congestive Heart Failure', 'Consensus', 'Data', 'Data Collection', 'Data Science', 'Data Scientist', 'Data Set', 'Databases', 'Decision Aid', 'Decision Making', 'Dependence', 'Detection', 'Diagnosis', 'Disease', 'Early Intervention', 'Effectiveness', 'Elderly', 'Electronic Health Record', 'Environment', 'Faculty', 'Foundations', 'Frail Elderly', 'Future', 'Goals', 'Guidelines', 'Health', 'Health Care Costs', 'Health Status', 'Heart failure', 'Hospitalization', 'Individual', 'International', 'Intervention', 'Laboratories', 'Length of Stay', 'Link', 'Machine Learning', 'Measures', 'Medicare', 'Medicare claim', 'Medicine', 'Mentors', 'Methods', 'Modeling', 'Natural Language Processing', 'Older Population', 'Outcome', 'Outpatients', 'Patient Care', 'Patients', 'Pattern', 'Physiological', 'Population', 'Predictive Value', 'Prevalence', 'Procedures', 'Quality of Care', 'Reading', 'Records', 'Research', 'Research Project Grants', 'Risk', 'Safety', 'Scientist', 'Series', 'Source', 'Structure', 'Supervision', 'Survival Analysis', 'Symptoms', 'Syndrome', 'Techniques', 'Testing', 'Text', 'Time', 'Training', 'advanced analytics', 'adverse outcome', 'analytical method', 'base', 'career', 'career development', 'clinical care', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'college', 'data warehouse', 'deep neural network', 'experience', 'frailty', 'functional disability', 'functional status', 'high risk', 'hospital readmission', 'indexing', 'individual variation', 'innovation', 'member', 'mortality', 'mortality risk', 'multidisciplinary', 'novel', 'point of care', 'predictive modeling', 'prognostic value', 'random forest', 'routine care', 'screening', 'signal processing', 'skills', 'stressor', 'support tools', 'tool']",NHLBI,BAYLOR COLLEGE OF MEDICINE,K25,2021,143762
"Deep clinical trajectory modeling to optimize accrual to cancer clinical trials PROJECT SUMMARY/ABSTRACT Electronic health records (EHRs) are now ubiquitous in routine cancer care delivery. The large volumes of data that EHRs contain could constitute an important resource for research and quality improvement, but to date, EHRs have not fully realized this potential. Important clinical endpoints, such as disease histology, stage, response, progression, and burden, are often recorded in the EHR only in unstructured free-text form. Even when structured data are available, they may be recorded only at one point in time, such as diagnosis, and may not be as relevant later in a patient's dynamic disease trajectory. These barriers prevent scalable analysis of EHR data for even relatively straightforward research tasks, such as identification of a cohort of patients potentially eligible for clinical trials. Identifying patients for trials is an important challenge in cancer research, since under 5% of adults with cancer have historically enrolled in therapeutic trials. Tools are in development to better match patients to trials, but no such tools are both publicly available and capable of incorporating time- specific patient phenotypes generated using unstructured EHR data. Recent rapid innovation in deep learning techniques could provide novel solutions to these challenges. In ongoing work, I have found that natural language processing based on a neural network architecture can reliably extract clinically relevant oncologic endpoints from free-text radiology reports. My goal is to develop an independent research program focused on leveraging such methods to put the EHR to use at scale for discovery and improving cancer care delivery. My specific aims are (1) to develop and validate a clinically relevant, dynamic, pre-trained cancer trajectory model by applying deep learning to integrated structured and unstructured EHR data; (2) to apply transfer learning to a pre-trained cancer trajectory model to match patients to clinical trials using EHR data and clinical trial protocols; and (3) to pilot the incorporation of cancer trajectory modeling into an institutional clinical trial matching tool. In the near term, this work will facilitate accrual to clinical trials at our institution. During the independent research portion of the proposal, it will constitute the basis for a general framework for conducting scalable cancer research using EHR data. PROJECT NARRATIVE Electronic health records (EHRs) are now ubiquitous in routine cancer care delivery, but their utility for research and quality improvement has been limited by a dearth of methods for integrating the unstructured data in which most key cancer outcomes are encoded within EHRs. I propose to apply recent innovations in deep learning to integrate structured and unstructured data to create a dynamic pre-trained model of cancer patients' treatment trajectories, and to apply this model to identify patients who are appropriate candidates for clinical trials at times when they are eligible. I will then evaluate the effect of trajectory modeling on clinical trial accrual as I prepare for an independent research career focused on clinical cancer data science.",Deep clinical trajectory modeling to optimize accrual to cancer clinical trials,10090579,K99CA245899,"['Academia', 'Adult', 'Cancer Model', 'Cancer Patient', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Medicine', 'Clinical Trials', 'Clinical trial protocol document', 'Complex', 'Computers', 'Dana-Farber Cancer Institute', 'Data', 'Data Science', 'Data Scientist', 'Development', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Eligibility Determination', 'Enrollment', 'Goals', 'Government', 'Health Services Research', 'Health system', 'Healthcare Systems', 'Histology', 'Institution', 'Intervention', 'Label', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Medical Records', 'Methods', 'Modeling', 'Natural Language Processing', 'Oncologist', 'Oncology', 'Outcome', 'Pathology Report', 'Patients', 'Phenotype', 'Primary Neoplasm', 'Psychological Transfer', 'Radiology Specialty', 'Randomized', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Services', 'Site', 'Source', 'Structure', 'Systemic Therapy', 'Techniques', 'Technology', 'Text', 'Therapeutic Trials', 'Time', 'Training', 'Work', 'anticancer research', 'base', 'burden of illness', 'cancer care', 'cancer clinical trial', 'care delivery', 'career', 'clinical candidate', 'clinical practice', 'clinical trial enrollment', 'clinically relevant', 'cohort', 'data registry', 'deep learning', 'design', 'electronic data', 'genomic data', 'improved', 'innovation', 'learning strategy', 'multiple data types', 'neoplasm registry', 'neural network architecture', 'novel', 'palliative', 'patient population', 'precision medicine clinical trials', 'prevent', 'programs', 'response', 'skills', 'structural genomics', 'structured data', 'survival prediction', 'tool', 'tumor progression', 'unstructured data']",NCI,DANA-FARBER CANCER INST,K99,2021,170176
"Development of End-To-End Clinical Decision Support Tools To Prevent Cardiotoxic Drug Response SUMMARY Drug-induced cardiac toxicity, in the form of QT prolongation and torsade de pointes, is an uncommon but devastating side effect of over one hundred currently marketed drugs. The ubiquity of drug-induced QT prolongation (diLQTS) across medical specialties and conditions creates a challenge for providers seeking to prescribe known QT-prolonging medications, particularly for non-cardiac conditions. Work by our group to develop automated clinical decision support (CDS) tools that alert providers of patient risk has shown promise towards reducing the number of prescriptions to at-risk individuals. However, these tools rely on a history of an electrocardiogram (ECG) with QT prolongation to identify at-risk patients, and thus exclude a large number of potentially at-risk individuals who have not had an ECG within our system. Through a unique institutional partnership with Google, in which a copy of our entire electronic health record (EHR) is stored on the Google Cloud Platform (GCP), we have developed preliminary deep-learning models to predict risk of diLQTS. We have also validated the genetic association with the QT interval and diLQTS across several real-world populations using an aggregate polygenic risk score. Through creation of an institutional biobank with certification for clinical application of results, as well as cloud-based integration of EHR data with genetic data, we have the capability to leverage our existing infrastructure to study the role of deep learning and genetics to reduce the risk of diLQTS. This investigation will combine our unique research and clinical infrastructure on the University of Colorado Anschutz Medical Campus with our investigative team composed of experts in the study of pharmacogenomics and medical informatics to develop and study an end-to-end CDS tool incorporating genetics and deep learning to predict risk of diLQTS. The specific aims of this application include the following: (1) develop and test a cloud-based, deep-learning model using EHR data on in- and outpatients to predict risk of diLQTS; (2) validate genetic predictors of diLQTS using institutional biobank samples, and a multi-ethnic external population; and (3) develop and test CDS tools using these advanced methods to reduce the risk of diLQTS. We will use a common data model (Observational Medical Outcomes Partnership) mapped from EHR data, as well as a custom DNA array (Multi-Ethnic Genotyping Array) designed for imputation across a variety of non-European ancestries, to ensure that the our prediction model and findings from this study can be replicated in other institutions and populations in the future. In such a way, this investigation will not only provide insight into the use of machine learning and genetics for risk prediction of diLQTS, but it will also create a blueprint for future advanced CDS development for other conditions. PROJECT NARRATIVE The goal of this project is the development of a clinical decision support tool that can be used to predict the risk of drug-induced QT prolongation based on deep learning and genetics. This tool could be used to prevent potentially fatal side effects of medications when alternatives are available, or increase vigilance when safer alternatives are not available. This study is specifically designed so that the models created can be directly applied across other institutional medical record systems beyond the study population.",Development of End-To-End Clinical Decision Support Tools To Prevent Cardiotoxic Drug Response,10088467,R01HL146824,"['Adherence', 'Adverse drug effect', 'Arrhythmia', 'Artificial Intelligence', 'Automated Clinical Decision Support', 'Benefits and Risks', 'Biometry', 'Cardiotoxicity', 'Certification', 'Clinical', 'Cluster randomized trial', 'Colorado', 'Custom', 'DNA', 'Data', 'Data Science', 'Decision Analysis', 'Development', 'Electrocardiogram', 'Electronic Health Record', 'Ensure', 'Excision', 'Future', 'Genetic', 'Genetic Risk', 'Genotype', 'Goals', 'Health Technology', 'Health system', 'Heritability', 'Hospitals', 'Individual', 'Information Technology', 'Infrastructure', 'Inpatients', 'Institution', 'Investigation', 'Long QT Syndrome', 'Machine Learning', 'Maps', 'Medical', 'Medical Informatics', 'Medical Records', 'Methods', 'Modeling', 'Outcome', 'Outpatients', 'Participant', 'Patient risk', 'Patient-Focused Outcomes', 'Patients', 'Persons', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Physicians', 'Population', 'Protocols documentation', 'Provider', 'Recording of previous events', 'Relative Risks', 'Research', 'Research Infrastructure', 'Research Personnel', 'Rest', 'Risk', 'Role', 'Sample Size', 'Sampling', 'Science', 'System', 'Technology', 'Testing', 'Time', 'Torsades de Pointes', 'Toxic effect', 'Universities', 'Validation', 'Variant', 'Work', 'analytical tool', 'base', 'biobank', 'classification algorithm', 'clinical application', 'clinical decision support', 'clinical implementation', 'clinical infrastructure', 'cloud based', 'cloud platform', 'cloud storage', 'data modeling', 'data warehouse', 'deep learning', 'design', 'disorder risk', 'drug market', 'electronic data', 'experience', 'genetic association', 'genetic epidemiology', 'genetic information', 'genetic predictors', 'genetic variant', 'genome wide association study', 'health data', 'improved', 'innovation', 'insight', 'machine learning method', 'medical schools', 'medical specialties', 'patient safety', 'personalized medicine', 'polygenic risk score', 'practical application', 'predictive modeling', 'prevent', 'primary outcome', 'response', 'risk prediction', 'risk stratification', 'secondary outcome', 'side effect', 'study population', 'support tools', 'tool', 'trend', 'vigilance']",NHLBI,UNIVERSITY OF COLORADO DENVER,R01,2021,777314
"Sarcopenia: computable phenotypes and clinical outcomes. PROJECT SUMMARY  Sarcopenia is a generalized muscle condition that develops with aging and complicates many common chronic diseases, resulting in low muscle mass, weakness, and impaired physical function. Sarcopenia contributes to disability, increased hospitalizations, healthcare costs, and risk of death. Despite being under- recognized clinically, sarcopenia is a major public health concern, with the worldwide prevalence projected to increase by up to 72% in the next 30 years. However, limited knowledge of sarcopenia among clinicians, combined with time pressures in clinical encounters delay its detection, and limit opportunity for intervention or recruitment into clinical trials. To overcome this barrier to detecting sarcopenia, we propose to use advanced big data and machine learning methods to identify additional component variables predicting sarcopenia among the rich electronic health record (EHR) data and develop a validated and portable sarcopenia computable phenotype (which uses a computer algorithm to detect patient characteristics or outcomes from the EHR). This innovative proposal takes advantage of key resources at Indiana University and its affiliation with the Regenstrief Institute and the Indiana Network for Patient Care (INPC), a statewide multi-health system clinical data warehouse including >100 healthcare entities and >18 million unique patients with both coded and text-based data, combined with the ability to perform comprehensive musculoskeletal measurements in the Musculoskeletal Function Imaging and Tissue (MSK-FIT) Core funded through a NIAMS Core Center for Clinical Research grant (P30AR072581). Our long-term goal is to accurately identify patients with, or at risk for, sarcopenia and its consequences in order to provide targeted interventions. We hypothesize that by using medical informatics and machine learning innovations, computable phenotypes can identify patients with sarcopenia from the EHR, predict deficits in measured muscle strength and physical function, and prospectively predict risk of hospitalization and death. In Aim 1, we will categorize >2000 adult participants in the MSK-FIT Core with accessible EHR data, as either sarcopenic or nonsarcopenic according to measurements of muscle strength, muscle mass and physical performance. We will then use 75% of the MSK- FIT Core cohort to train machine deep learning algorithms to detect combinations of variables from these subjects’ EHR predicting whether the patient is sarcopenic or not sarcopenic. The performance of the resulting computable phenotype will then be tested in the remaining 25% of the MSK-FIT Core participants. In Aim 2, we will test the performance of the sarcopenia computable phenotype to detect a clinically meaningful phenotype in the entire INPC adult population (>18 million), by evaluating the ability to predict the rate of hospitalizations and death among patients rated as sarcopenic versus matched controls. Such a computable phenotype will then enable large scale targeted recruitment, pragmatic clinical trials, clinical evaluation and intervention. PROJECT NARRATIVE Sarcopenia is a generalized muscle condition that develops with aging and complicates many common chronic diseases, resulting in low muscle mass, weakness, and impaired physical function, and contributing to disability, increased hospitalizations and risk of death. Despite being underrecognized clinically, sarcopenia is a major public health concern, with projected large increases in its prevalence worldwide. The overall goal of this grant is to use advanced, state-of-the art biomedical informatics and big data methods to generate a tool using electronic health record data to detect patients with sarcopenia early and facilitate patient recruitment, engagement and clinical interventions to treat sarcopenia.",Sarcopenia: computable phenotypes and clinical outcomes.,10147651,R01AR077273,"['Adult', 'Aging', 'Algorithms', 'Automated Clinical Decision Support', 'Awareness', 'Big Data', 'Big Data Methods', 'Birth', 'Cessation of life', 'Characteristics', 'Chronic', 'Chronic Disease', 'Chronic Kidney Failure', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Code', 'Computational algorithm', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Detection', 'Diagnosis', 'Disease', 'Electronic Health Record', 'Exercise', 'Funding', 'Goals', 'Grant', 'Hand Strength', 'Health Care Costs', 'Health system', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Image', 'Impairment', 'Indiana', 'Individual', 'Institutes', 'Intervention', 'Knowledge', 'Machine Learning', 'Measurement', 'Measures', 'Medical Informatics', 'Methods', 'Muscle', 'Musculoskeletal', 'National Institute of Arthritis and Musculoskeletal and Skin Diseases', 'Natural Language Processing', 'Outcome', 'Participant', 'Patient Care', 'Patient Recruitments', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Pharmacology', 'Phenotype', 'Physical Function', 'Physical Performance', 'Physicians', 'Population', 'Pragmatic clinical trial', 'Prevalence', 'Process', 'Provider', 'Public Health', 'Public Health Informatics', 'Publishing', 'Race', 'Reporting', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Supervision', 'Testing', 'Text', 'Time', 'Tissues', 'Training', 'Universities', 'age group', 'base', 'biomedical informatics', 'clinical center', 'clinical data warehouse', 'clinical encounter', 'cohort', 'comorbidity', 'computable phenotypes', 'deep learning algorithm', 'detection limit', 'dietary', 'disability', 'electronic data', 'experience', 'hospitalization rates', 'improved', 'improved outcome', 'innovation', 'machine learning method', 'mortality risk', 'muscle form', 'muscle strength', 'performance tests', 'physical conditioning', 'population health', 'portability', 'pressure', 'prevent', 'prospective', 'ranpirnase', 'recruit', 'reduced muscle mass', 'research clinical testing', 'sarcopenia', 'sex', 'text searching', 'tool']",NIAMS,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2021,173901
"Automating Delirium Identification and Risk Prediction in Electronic Health Records Abstract. Delirium, or acute confusional state, affects 30-40% of hospitalized older adults, with the added cost of care estimated to be up to $7 billion. Although originally conceptualized as a transient disorder, delirium is now recognized to have significant consequences, including increased risk of death, functional decline, and long-term cognitive impairment. As up to 75% cases are not recognized by providers, there is an urgent need for additional methods to identify delirium for clinical and research purposes, and to stratify patients based on delirium risk. In this proposal, we present a novel approach to the identification of delirium based on large-scale data mining (i.e., pattern recognition) algorithms using machine learning and natural language processing applied to electronic health record (EHR) data, which will automate chart-based determination of delirium status and risk prediction. We will combine these algorithms with data collected through our recently implemented Virtual Acute Care for Elders (ACE) quality improvement project, which institutes delirium screening once per shift by nursing staff for all individuals over age 65 admitted to the University of Alabama at Birmingham (UAB) Hospital. This unprece- dented volume of data will allow us to achieve the necessary sample sizes for effective training and validation of our data mining algorithms. Data mining algorithms that discover patterns of associations in data, rather than testing predetermined hypotheses, are well suited to application in large-scale algorithms for identification of delirium. Using our Virtual ACE and hospital EHR data, we will be able to evaluate more than 10,000 individual features (e.g., text words and phrases, laboratory and other diagnostic tests, concurrent medical conditions) as- sociated with delirium, which will be classified as risk factors for delirium, as signs, symptoms, and descriptors of delirium itself, and as complications and consequences of delirium, based on expert consensus. We will then use these features to develop rules for identification of delirium in the EHR, as well as risk prediction models that can be integrated into the EHR to provide individualized assessments of delirium risk. This study will lay the foundation for methods of automated delirium identification and risk prediction in healthcare settings that are unable to implement the screening by providers done in our Virtual ACE, as well as for large-scale epidemiological investigations of delirium using EHR data, expanding the current armamentarium for studying this common and debilitating disorder. Project Narrative. Delirium, or acute confusional state, affects up to 7 million hospitalized older adults annu- ally and is associated with long-term declines in cognition and function, but is not recognized by providers in up to 75% of cases. The growth of electronic health records offers a unique opportunity to improve recognition of delir- ium, as methods for identifying delirium based on chart review by clinicians have been developed but are time- and resource-intensive. In this secondary data analysis, we will examine methods for automating delirium recog- nition and risk prediction in electronic health records using machine learning and natural language processing computer algorithms, which in turn will lead to improved care for this serious but often overlooked disorder.",Automating Delirium Identification and Risk Prediction in Electronic Health Records,10091381,R01AG060993,"['Acute', 'Address', 'Adult', 'Affect', 'Agreement', 'Alabama', 'Algorithms', 'Ally', 'Assessment tool', 'Automation', 'Caring', 'Characteristics', 'Clinical Research', 'Cognition', 'Cognitive', 'Computational algorithm', 'Confusion', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Delirium', 'Descriptor', 'Detection', 'Development', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Elderly', 'Electronic Health Record', 'Epidemiology', 'Foundations', 'Growth', 'Health system', 'Hospitals', 'Impaired cognition', 'Individual', 'Inpatients', 'Institutes', 'Institutionalization', 'Laboratories', 'Link', 'Logistics', 'Long-Term Care for Elderly', 'Machine Learning', 'Measurable', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Nursing Staff', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pattern Recognition', 'Persons', 'Prevention', 'Property', 'Provider', 'ROC Curve', 'Reference Standards', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Signs and Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'acute care', 'adverse outcome', 'base', 'care costs', 'confusion assessment method', 'data mining', 'epidemiology study', 'functional decline', 'functional disability', 'health care settings', 'high dimensionality', 'human old age (65+)', 'improved', 'instrument', 'interest', 'large scale data', 'model development', 'mortality risk', 'novel', 'novel strategies', 'patient stratification', 'phrases', 'prediction algorithm', 'programs', 'risk prediction', 'risk prediction model', 'screening', 'validation studies', 'virtual', 'ward']",NIA,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2021,376860
"Developing scalable algorithms to incorporate unstructured electronic health records for causal inference based on real-world data Project Summary/Abstract The routine operation of the US Healthcare system produces an abundance of electronically-stored data that captures the care of patients as it is provided in settings outside of controlled research environments. The potential for utilizing these data to inform future treatment choices and improve patient care and outcomes of all patients in the very system that generates the data is widely acknowledged. Given these key properties of the routine-care data and the abundance of electronic healthcare databases covering millions of patients, it is critical to strengthen the rigor of analyses of such data. Our group has previously developed an analytic approach to reduce bias when analyzing routine-care databases, which has proven effective in more than 50 empirical research studies across a range of topics and data sources. However, this approach currently cannot incorporate free-text information that is recorded in electronic health records, such as clinical notes and reports. This limitation has left a large amount of rich patient information underutilized for clinical research. We thus aim to adapt and refine a set of established computerized natural language processing algorithms that can identify and extract useful information from the clinical notes and reports in electronic health records and incorporate them into our validated analytical approach for balancing background risks of different comparison groups, a key step to ensure fair evaluation when comparing different therapeutic options. To test this newly integrated and augmented approach, we will implement and adapt it in simulation studies where we can evaluate and improve the performance of these new analytic methods in a controlled but realistic fashion. In addition, we will assess the performance of our new approach in 8 practical studies comparing medical or surgical treatments that are highly relevant to patients. To ensure highest level of data completeness and quality, we have linked multiple healthcare utilization (claims) databases, spanning from 2007 to 2016, with 3 electronic health records systems, including one each in Massachusetts, North Carolina, and Texas. This data will allow testing of our newly integrated approach in a variety of care delivery systems and data environments, which will be very informative for the application of our products in the real-world settings. Narrative The project will yield a highly flexible and effective analytical method for reducing confounding bias in studies that utilize routine-care data to compare effects of medical or surgical treatments. This method will enable researchers to leverage a large amount of patient information recorded in the clinical notes and reports that are contained within electronic health records to adjust for differences in background risks of different comparison groups. Our proposal can improve the quality of evidence based on electronic healthcare data generated in the routine-care settings to better inform patient care and optimal prescribing.",Developing scalable algorithms to incorporate unstructured electronic health records for causal inference based on real-world data,10168610,R01LM013204,"['Address', 'Algorithms', 'Clinical', 'Clinical Research', 'Code', 'Cohort Studies', 'Comparative Effectiveness Research', 'Complex', 'Confounding Factors (Epidemiology)', 'Consumption', 'Data', 'Data Set', 'Data Sources', 'Data Store', 'Databases', 'Disease', 'Electronic Health Record', 'Elements', 'Empirical Research', 'Ensure', 'Environment', 'Equilibrium', 'Evaluation', 'Future', 'Gold', 'Healthcare', 'Healthcare Systems', 'Influentials', 'Knowledge', 'Knowledge acquisition', 'Left', 'Link', 'Machine Learning', 'Manuals', 'Massachusetts', 'Medical', 'Medicare/Medicaid', 'Methods', 'Modeling', 'Names', 'Natural Language Processing', 'North Carolina', 'Operative Surgical Procedures', 'Patient Care', 'Patients', 'Pattern', 'Performance', 'Physicians', 'Probability', 'Property', 'Proxy', 'Randomized Controlled Trials', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Risk', 'Risk Factors', 'Semantics', 'Severities', 'Specific qualifier value', 'Stratification', 'Structure', 'Symptoms', 'System', 'Techniques', 'Testing', 'Texas', 'Text', 'Therapeutic', 'Time', 'Training', 'Treatment outcome', 'Validation', 'Weight', 'Work', 'analytical method', 'base', 'care delivery', 'care outcomes', 'comparative effectiveness study', 'comparison group', 'computerized', 'cost', 'disorder risk', 'evidence base', 'flexibility', 'health care service utilization', 'high dimensionality', 'improved', 'innovation', 'machine learning method', 'novel strategies', 'operation', 'outcome forecast', 'preservation', 'randomized trial', 'research study', 'routine care', 'safety study', 'simulation', 'sound', 'tool', 'treatment choice', 'unstructured data']",NLM,BRIGHAM AND WOMEN'S HOSPITAL,R01,2021,469927
"Discovering and Applying Knowledge in Clinical Databases PROJECT SUMMARY / ABSTRACT The long-term goal of our ongoing project, “Discovering and applying knowledge in clinical databases,” is to learn from data in the electronic health record (EHR) and to apply that knowledge to understand and improve health. The EHR, because of its broad capture of human health, greatly amplifies our ability to carry out observational research, opening the possibility of covering emerging problems, diverse populations, rare diseases, and chronic diseases in long-term longitudinal studies. Unfortunately, the strength of EHR data—its breadth and flexible nature—imposes additional challenges. We have found that the biggest challenge comes from the inaccuracy, incompleteness, complexity, and resulting bias inherent in the recording of the health care process. We previously showed that health care process bias exists to the extent, for example, that simple use of the data can create signals implying the opposite of what we know to be true. One of the most important factors is sparse, irregular sampling; we found that sampling bias can be reduced by reparameterizing time and that prediction techniques that can accommodate EHR-specific data and resist their biases like data assimilation can be used on EHR data to produce good estimates of glucose and HA1c. The previous cycle of this project produced 75 publications. We propose to develop methods to accommodate health care process bias, using both knowledge engineering and experience with health care process bias as well as advanced statistical techniques that employ dynamical models and latent variables. We hypothesize that heuristics and models combined with knowledge can improve our ability to generate inferences and learn phenotypes despite health care process bias. Our aims are as follows: (1) Taking a knowledge engineering approach, study the effect of preprocessing and analytic choices on reducing health care process bias, and using machine learning techniques, learn more about health care process bias. (2) Taking a more empirical approach, use dynamic latent factor modeling and variation inference to accommodate health care process bias, learning how a patient's health state and health processes affect censoring, exploiting information from many variables at once. (3) Use data assimilation and mechanistic models to learn otherwise unmeasurable physiologic phenotypes despite irregular, sparse sampling typical of electronic health records. (4) Use the developed models and generated phenotypes to answer clinical questions, and disseminate the results. PROJECT NARRATIVE This project studies the biases that health care processes bring to electronic health record data, and it develops methods to overcome those biases to improve reuse of the data for purposes such as clinical research and quality improvement.",Discovering and Applying Knowledge in Clinical Databases,10321056,R01LM006910,"['Active Learning', 'Adopted', 'Affect', 'Algorithms', 'Area', 'Assimilations', 'Award', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Data Reporting', 'Drug Side Effects', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'Generations', 'Glucose', 'Goals', 'Health', 'Healthcare', 'Human', 'Insulin', 'Knowledge', 'Learning', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Metabolism', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nonlinear Dynamics', 'Observational Study', 'Patients', 'Performance', 'Phenotype', 'Physiological', 'Physiology', 'Population Heterogeneity', 'Process', 'Publications', 'Rare Diseases', 'Research', 'Sampling', 'Sampling Biases', 'Signal Transduction', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Work', 'abstracting', 'clinical database', 'data reuse', 'deep learning', 'experience', 'flexibility', 'heuristics', 'improved', 'novel', 'precision medicine', 'predictive modeling']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,37243
"Discovering and Applying Knowledge in Clinical Databases PROJECT SUMMARY / ABSTRACT The long-term goal of our ongoing project, “Discovering and applying knowledge in clinical databases,” is to learn from data in the electronic health record (EHR) and to apply that knowledge to understand and improve health. The EHR, because of its broad capture of human health, greatly amplifies our ability to carry out observational research, opening the possibility of covering emerging problems, diverse populations, rare diseases, and chronic diseases in long-term longitudinal studies. Unfortunately, the strength of EHR data—its breadth and flexible nature—imposes additional challenges. We have found that the biggest challenge comes from the inaccuracy, incompleteness, complexity, and resulting bias inherent in the recording of the health care process. We previously showed that health care process bias exists to the extent, for example, that simple use of the data can create signals implying the opposite of what we know to be true. One of the most important factors is sparse, irregular sampling; we found that sampling bias can be reduced by reparameterizing time and that prediction techniques that can accommodate EHR-specific data and resist their biases like data assimilation can be used on EHR data to produce good estimates of glucose and HA1c. The previous cycle of this project produced 75 publications. We propose to develop methods to accommodate health care process bias, using both knowledge engineering and experience with health care process bias as well as advanced statistical techniques that employ dynamical models and latent variables. We hypothesize that heuristics and models combined with knowledge can improve our ability to generate inferences and learn phenotypes despite health care process bias. Our aims are as follows: (1) Taking a knowledge engineering approach, study the effect of preprocessing and analytic choices on reducing health care process bias, and using machine learning techniques, learn more about health care process bias. (2) Taking a more empirical approach, use dynamic latent factor modeling and variation inference to accommodate health care process bias, learning how a patient's health state and health processes affect censoring, exploiting information from many variables at once. (3) Use data assimilation and mechanistic models to learn otherwise unmeasurable physiologic phenotypes despite irregular, sparse sampling typical of electronic health records. (4) Use the developed models and generated phenotypes to answer clinical questions, and disseminate the results. PROJECT NARRATIVE This project studies the biases that health care processes bring to electronic health record data, and it develops methods to overcome those biases to improve reuse of the data for purposes such as clinical research and quality improvement.",Discovering and Applying Knowledge in Clinical Databases,10116464,R01LM006910,"['Active Learning', 'Adopted', 'Affect', 'Algorithms', 'Area', 'Assimilations', 'Award', 'Chronic Disease', 'Clinical', 'Clinical Research', 'Complex', 'Data', 'Data Reporting', 'Drug Side Effects', 'Electronic Health Record', 'Engineering', 'Functional disorder', 'Generations', 'Glucose', 'Goals', 'Health', 'Healthcare', 'Human', 'Insulin', 'Knowledge', 'Learning', 'Longitudinal Studies', 'Machine Learning', 'Measurement', 'Metabolism', 'Methods', 'Modeling', 'Monitor', 'Nature', 'Non-Insulin-Dependent Diabetes Mellitus', 'Nonlinear Dynamics', 'Observational Study', 'Patients', 'Performance', 'Phenotype', 'Physiological', 'Physiology', 'Population Heterogeneity', 'Process', 'Publications', 'Rare Diseases', 'Research', 'Sampling', 'Sampling Biases', 'Signal Transduction', 'Structure', 'Techniques', 'Testing', 'Time', 'Training', 'Variant', 'Work', 'abstracting', 'clinical database', 'data reuse', 'deep learning', 'experience', 'flexibility', 'heuristics', 'improved', 'novel', 'precision medicine', 'predictive modeling']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,568584
"Deep phenotyping in Electronic Health Records for Genomic Medicine PROJECT SUMMARY The overarching goal of the project is to establish a genomic medicine learning system to accelerate genomic knowledge discovery and application in electronic health records (EHRs). We will integrate deep characteristic phenotypes extracted from EHRs and evolving knowledge of genotype-phenotype associations to optimize the accuracy of variant interpretation and the cost-effectiveness of clinical genome/exome sequencing, and to accelerate the discovery of causal genes by constructing a dynamic genotype-phenotype knowledge network. Prior knowledge on phenotype-gene relationships and phenotypic information about patients can facilitate the identification of disease-causing mutations from thousands of genetic variants in the context of clinical genomic sequencing; however, how best to abstract phenotype information from notes in the EHRs of patients who are diagnosed with or evaluated for monogenetic disorders, standardize the computable representation of phenotypes, and utilize it in genomic interpretation remains unclear. Additionally, how to systematically compare phenotypes across diseases to discover new knowledge in human genetics remains a largely untapped area with great promise. To address these challenges, we will develop and validate scalable and portable open-source natural language processing (NLP) methods for automated and accurate abstraction of characteristic phenotype concepts (e.g., “j-shaped sella turcica” and “short stature”) from EHR narratives. We will then develop a phenotype-driven scoring system called EHR-Phenolyzer to predict the likely candidate genetic variants associated with the phenotypes for patients with genomic sequencing and a high probability of a monogenic condition. On this basis, we will develop a probabilistic disease diagnosis and knowledge discovery system using rich and deep EHR phenotypes, and evaluate these methods for genomic diagnosis and discovery using large- scale clinical exome sequencing data. Ultimately, these methods will support efficient, effective, and scalable genomic diagnostics, and facilitate the implementation of genome-guided precision medicine in clinical practice. NARRATIVE We will develop novel informatics methods to abstract characteristic phenotypes from electronic health records (EHRs) for patients diagnosed with or evaluated for monogenetic disorders, enable the interoperability of computable characteristic phenotypes with existing phenotype-genotype association knowledge such as OMIM and ClinVar, and improve the efficiency and effectiveness of genomic diagnostics.",Deep phenotyping in Electronic Health Records for Genomic Medicine,10164857,R01LM012895,"['Address', 'Adopted', 'Age', 'Area', 'Benchmarking', 'Candidate Disease Gene', 'Characteristics', 'ClinVar', 'Clinical', 'Clinical Research', 'Clinical effectiveness', 'Computer software', 'Data', 'Data Science', 'Data Set', 'Data Sources', 'Diagnosis', 'Diagnostic', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Event', 'Genes', 'Genetic Diseases', 'Genome', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Human', 'Human Genetics', 'Informatics', 'Knowledge', 'Knowledge Discovery', 'Learning', 'Link', 'Literature', 'Measures', 'Methods', 'Natural Language Processing', 'Online Mendelian Inheritance In Man', 'Ontology', 'Patients', 'Phenotype', 'Probability', 'Research', 'Resources', 'Software Tools', 'Standardization', 'Statistical Models', 'System', 'Terminology', 'Testing', 'Text', 'Translating', 'Universities', 'Variant', 'abstracting', 'base', 'causal variant', 'clinical decision support', 'clinical diagnostics', 'clinical practice', 'clinical sequencing', 'cost effectiveness', 'data modeling', 'data standards', 'data warehouse', 'design', 'disease diagnosis', 'disease phenotype', 'disease-causing mutation', 'disorder prevention', 'ethnic diversity', 'exome', 'exome sequencing', 'experience', 'genetic disorder diagnosis', 'genetic variant', 'health record', 'human disease', 'improved', 'information organization', 'innovation', 'interoperability', 'next generation', 'novel', 'open source', 'patient health information', 'phenotypic data', 'pituitary fossa', 'portability', 'precision medicine', 'success']",NLM,COLUMBIA UNIVERSITY HEALTH SCIENCES,R01,2021,399965
"Health Information Technology for Surveillance of Health Care-Associated Infections PROJECT SUMMARY/ABSTRACT Health care-associated infections (HAIs) affect one in every 20 hospitalized patients and account for $10 billion dollars in potentially preventable health care expenditures annually. Current efforts at detection of HAIs are limited to manual chart review which hinders the generalizability and scalability of HAI detection. My goal in seeking a Mentored Clinical Scientist Career Development Award is to acquire the necessary training, practical experience, and knowledge to develop a health services research career as a principal investigator focusing on leveraging novel health information technology (HIT) tools to improve the measurement of surgical health care quality, safety, and effectiveness. To continue my progress towards this goal, the objective of this project is to address the challenges of HAI detection by developing a robust and portable automated HAI surveillance toolkit. This toolkit will combine structured electronic health record (EHR) data with rich information locked in clinical notes using machine learning and natural language processing (NLP) to identify HAIs after surgical procedures. Our overall hypothesis is that combining structured variables from the EHR supplemented with NLP will improve our ability to identify HAIs after surgical procedures. To test the central hypothesis and accomplish the objectives for this application, I will pursue the following three specific aims: 1) Determine the EHR data elements indicative of postoperative HAIs and evaluate the performance of a novel HAI surveillance algorithm; 2) Identify the presence of postoperative SSIs from clinical notes using an automated portable NLP-based algorithm; 3) Apply user-centered design to create a high fidelity prototype of a surgical quality dashboard incorporating our HAI case detection methodology. This contribution is a significant first step in a continuum of research that utilizes the large amounts of data in the EHR combined with novel HIT methods to improve the measurement of surgical health-care quality, safety, and effectiveness. This approach is significant because the tools developed in this proposal have potential to serve as a prototype for identification and monitoring hospitals adverse events and could be replicated on a national scale. The proposed research is innovative in its approach using a combination of structured and unstructured data in the EHR along with novel machine learning and NLP tools to create a generalizable surveillance toolkit for the detection of HAIs. This proposal is responsive to the AHRQ Special Emphasis Notice (NOT-HS-13-011) specifically addressing the use of HIT to improve quality measurement. I have assembled a mentoring team who all internationally recognized experts with long and successful track records of funding and trainee mentorship. This project will provide the means to place me on a trajectory towards a health services research career focused on improving the measurement of surgical health-care quality, safety, and effectiveness using novel HIT tools. In summary, my previous training and experience, innovative research plan, high-quality training plan, first-rate mentorship team, and supportive research environment give me the highest likelihood of success to research independence with the proposed K08 award. PROJECT NARRATIVE/RELEVANCE TO PUBLIC HEALTH The proposed research and career development plan are relevant to public health because health care- associated infections (HAIs) affect about one in every 20 hospitalized patients and account for $30 billion dollars in potentially preventable health care expenditures annually. The objective of this project is to develop robust and portable automated surveillance toolkit that combines structured EHR data with rich information locked in clinical notes using natural language processing to identify HAIs after surgical procedures. The proposed research has the potential to serve as a prototype for identification and monitoring of numerous hospitals adverse events and could be replicated on a national scale.",Health Information Technology for Surveillance of Health Care-Associated Infections,10186798,K08HS025776,[' '],AHRQ,UNIVERSITY OF UTAH,K08,2021,160142
"Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics ABSTRACT Total joint arthroplasty (TJA) is the most common and fastest growing surgical procedure in the nation. Despite the high procedure volume, the evidence base for TJA procedures and associated interventions are limited. This is mainly due to lack of high quality data sources and the logistical difficulties associated with manually extracting TJA information from the unstructured text of the Electronic Health Records (EHR). Meanwhile, the rapid adoption of EHR and the advances in health information technology offer the potential to transform unstructured EHR notes into structured, codified format that can then be analyzed and shared with local and national arthroplasty registries and other agencies. We therefore propose to leverage unique data resources and natural language processing (NLP) technologies to build an informatics infrastructure for automated EHR data extraction and analysis. We will (1) develop a high performance, externally validated and user centric NLP- enabled algorithm for extraction of complex TJA-specific data elements from the structured and unstructured text of the EHR, (2) validate the algorithm externally in multiple EHR platforms and hospital settings, and (3) conduct a demonstration project focused on prediction of prosthetic joint infections using data elements collected by the NLP-enabled algorithm. Our overarching goal is to develop valid, open source and portable NLP-enabled data collection and risk prediction tools and disseminate them widely to hospitals participating in regional and national TJA registries. This research is significant as it leverages strong data resources and expertise to tackle the pressing need for high quality data and accurate prediction models in TJA. Automated data collection and processing capabilities will lead to an upsurge in secondary use of EHR to advance scientific knowledge on TJA risk factors, healthcare quality and patient outcomes. Accurate prediction of high risk patients for prosthetic joint infections will guide prevention and treatment decisions resulting in significant health benefits to TJA patients. The research is innovative because TJA-specific bioinformatics technology will shift TJA research from current under-powered, single-center studies to large, multi-center registry-based observational studies and clinical trials. Our deliverables have the potential to exert a sustained downstream effect on future TJA research, practice and policy. PUBLIC HEALTH RELEVANCE Lack of high quality data is a critical barrier to progress in total joint arthroplasty (TJA) research. We will utilize health information technology to automate extraction of rich TJA information from the electronic health records, and develop a robust risk prediction score for prosthetic joint infections, a devastating and yet preventable complication of TJA. Widespread adoption of these tools will enhance data collection capabilities and enable affordable large scale studies for practice improvements through secondary use of real-world data. Accurate prediction of post- operative infection risk among TJA candidates will guide individualized preventive strategies for modifiable risk factors, thereby reducing the burden of prosthetic joint infections in TJA patients.",Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics,10103780,R01AR073147,"['Adoption', 'Algorithms', 'American', 'Bioinformatics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Complication', 'Data', 'Data Collection', 'Data Element', 'Data Set', 'Data Sources', 'Decision Making', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Epidemic', 'Evidence based practice', 'Future', 'Goals', 'Gold', 'Guide prevention', 'Health Benefit', 'Hospitals', 'Individual', 'Informatics', 'Institution', 'Intervention', 'Joint Prosthesis', 'Knowledge', 'Logistics', 'Manuals', 'Marketing', 'Medicare', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Policies', 'Postoperative Period', 'Prevention', 'Prevention strategy', 'Procedures', 'Provider', 'Publishing', 'Registries', 'Replacement Arthroplasty', 'Research', 'Risk', 'Risk Factors', 'Safety', 'Scientific Advances and Accomplishments', 'Source', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'age group', 'base', 'computerized data processing', 'cost', 'data access', 'data resource', 'electronic data', 'electronic structure', 'epidemiology study', 'evidence base', 'health care quality', 'health information technology', 'high risk', 'improved', 'individual patient', 'infection risk', 'informatics infrastructure', 'informatics tool', 'innovation', 'joint infection', 'modifiable risk', 'novel', 'open source', 'outcome prediction', 'patient population', 'portability', 'pragmatic trial', 'predictive modeling', 'prototype', 'public health relevance', 'risk prediction', 'risk prediction model', 'structured data', 'surgery outcome', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,R01,2021,574852
"Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing The adoption of Electronic Health Record (EHR) systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format with tremendous potential but an equally large concern for patient confidentiality breaches. Secondary use of clinical data is essential to fulfill the potential for high quality healthcare, improved healthcare management, and effective clinical research. NIH expects that larger research projects share their research data in a way that protects the confidentiality of research subjects. De-identification of patient data has been proposed as a solution to both facilitate secondary use of clinical data and protect patient data confidentiality. The majority of clinical data found in the EHR is represented as narrative text clinical notes, and de-identification of clinical text is a tedious and costly manual endeavor. Automated approaches based on Natural Language Processing have been implemented and evaluated, allowing for higher accuracy and much faster de- identification than manual approaches. Clinacuity, Inc. proposes to advance a text de-identification system from a prototype to an accurate, adaptable, and robust system, integrated into the research infrastructure at our implementation and testing site (Medical University of South Carolina, Charleston, SC), and ready for commercialization efforts. To accomplish this undertaking, we will focus on the following specific aims and related objectives, while continuing to prepare the commercialization of the integrated system, with detailed market analysis, commercial roadmap development, and modern media communication: 1) Enhance the text de-identification system performance, scalability, and quality to produce an enterprise-grade solution ready for deployment; 2) Enable use of structured data for enhanced text de-identification (when structured PII is available) and for complete patient records de-identification (i.e., records combining structured and unstructured data). This aim also includes implementing “one-way” pseudo-identifier cryptographic hashing to enable securely linking already de-identified patient records; 3) Integrate the text de-identification system with a research data capture and management system. This includes implementation of the de-identification system as a secure web service, with standards-based access and integration. This de-identification system has potential commercial applications in clinical research and in healthcare settings. It will improve access to richer, more detailed, and more accurate clinical data (in clinical text) for clinical researchers. It will ease research data sharing (as expected for larger NIH-funded research projects) and help healthcare organizations protect patient data confidentiality. Significant time-savings will also be offered, with a process at least 200-1000 times faster than manual de-identification. The adoption of Electronic Health Record systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format, with tremendous potential, but also equally growing concern for patient confidentiality breaches. De-identification of patient data has been proposed as a solution to both facilitate secondary uses of clinical data and protect patient data confidentiality. This project will advance a text de-identification system from a prototype to an accurate, adaptable and robust system allowing for complete patient records de-identification, integrated in the research infrastructure at our implementation and testing site and ready for commercialization efforts. It will improve access to richer, more detailed, and more accurate clinical data for clinical researchers, ease research data sharing and help healthcare organizations protect patient data confidentiality. !",Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing,10098325,R42GM116479,"['Adoption', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Communications Media', 'Confidentiality of Patient Information', 'Data', 'Deimplementation', 'Development', 'Electronic Health Record', 'Environment', 'Fast Healthcare Interoperability Resources', 'Funding', 'Growth', 'Health Insurance Portability and Accountability Act', 'Improve Access', 'Link', 'Manuals', 'Medical', 'Modernization', 'National Institute of General Medical Sciences', 'Natural Language Processing', 'Patient Care', 'Patient Data Privacy', 'Patients', 'Performance', 'Personally Identifiable Information', 'Phase', 'Privacy', 'Process', 'Records', 'Reference Standards', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Risk', 'Savings', 'Secure', 'Site', 'South Carolina', 'Speed', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trust', 'United States National Institutes of Health', 'Universities', 'Visualization', 'base', 'commercial application', 'commercialization', 'cost', 'cryptography', 'data reuse', 'data sharing', 'health care quality', 'health care service organization', 'health care settings', 'health management', 'improved', 'large scale data', 'participant enrollment', 'prototype', 'software development', 'standard measure', 'structured data', 'systems research', 'unstructured data', 'web services']",NIGMS,"CLINACUITY,INC.",R42,2021,725232
"Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project PROJECT SUMMARY The National Institutes on Aging (NIA) has recommended strengthening research infrastructures to address future aging research questions (2016 Data Infrastructure Review Committee Report and PAR-16-367). In particular, they recommend: 1) integrating biological data into larger population-based studies; 2) increasing use of electronic health record (EHR) data and linking to medical care claims data; and 3) developing new approaches to collecting data to answer important scientific questions about mechanisms of aging. The Rochester Epidemiology Project (REP; NIA R01 AG034676) is a unique infrastructure for studies of aging, because the REP collects longitudinal EHR data on all health conditions that come to medical attention for a large, Midwestern population. Therefore, the REP allows investigators to study all age-related diseases and outcomes. However, the REP has three significant gaps. First, the REP does not include biospecimens. Second, the REP is missing health care delivered outside of the health care institutions that partner with the REP, and it does not include information on filled prescriptions. Third, a significant proportion of EHR data is difficult to access due to two factors: 1) the full text of the EHRs includes extensive clinical notes about aging outcomes and geriatric syndromes, but these notes are not routinely coded for billing, and can only be accessed through laborious manual review; and 2) the REP health care partners use three different EHR systems, making it difficult to apply electronic data extraction tools across all partners. To address these three gaps, we will develop an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to create a new, comprehensive research infrastructure (“Bio-REP”) to support aging research. In the R21 phase, we will develop a comprehensive research infrastructure that combines the REP data with Mayo Clinic Biobank biospecimens, medical claims data from the Centers for Medicare and Medicaid Services (CMS; Aim 1), and geriatric syndrome data that are included in the unstructured EHR clinical notes using Natural Language Processing techniques (NLP; Aim 2). In the R33 phase, we will deploy NLP algorithms developed in Aim 2 in the clinical notes from two additional EHR systems (Aim 3), and we will conduct two demonstration projects. First, we will measure associations between novel aging-related biomarkers and aging-related outcomes (Aim 4). Second, we will determine whether two common medications that are hypothesized to impact aging (metformin and angiotensin receptor blockers) modify associations between aging biomarkers and aging outcomes (Aim 5). The new, robust Bio-REP infrastructure will support a wide range of efficient, cost-effective observational studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population. PROJECT NARRATIVE We will establish an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to develop and test a new, comprehensive research infrastructure (“Bio- REP”) to support aging research. The Bio-REP will support efficient, cost-effective studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population.",Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project,10224079,R33AG058738,"['Address', 'Age-Years', 'Aging', 'Agreement', 'Algorithms', 'Angiotensin Receptor', 'Area', 'Benchmarking', 'Biological', 'Biological Markers', 'Caring', 'Ceramides', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Data', 'Delirium', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Disease Outcome', 'Drug Utilization', 'Elderly', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'Future', 'Grant', 'Health', 'Healthcare', 'Infrastructure', 'Institution', 'Link', 'Manuals', 'Measures', 'Medical', 'Medical Informatics', 'Medical Records', 'Metformin', 'National Institute on Aging', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Polypharmacy', 'Population', 'Population Study', 'Proteins', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Review Committee', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'United States Centers for Medicare and Medicaid Services', 'age related', 'aging population', 'biobank', 'cost effective', 'data infrastructure', 'design', 'electronic data', 'falls', 'healthspan', 'improved', 'interdisciplinary collaboration', 'medical attention', 'novel', 'novel marker', 'novel strategies', 'senescence', 'tool']",NIA,MAYO CLINIC ROCHESTER,R33,2021,792718
"Data-driven subtyping in major depressive disorder Abstract  Major depressive disorder contributes substantially to morbidity, mortality, and health care cost. Standard treatments are ineffective for up to a third of patients, so new treatment options are needed along with strategies to make more effective use of existing treatments. However, progress in expanding therapeutic options has been hindered by heterogeneity in clinical presentation and course of depression.  In other disorders such as inflammatory bowel disease, cancer, and dementia, identifying disease subtypes has led to therapeutic discoveries. In major depressive disorder, efforts to identify subtypes based on clinical observation have yielded limited success, primarily because of the lack of availability of adequate cohorts for replication, and because those features most apparent to clinicians may not be the most relevant for differentiating subgroups. Efforts to leverage large electronic health record data sets for subtyping address some of these challenges, but standard approaches may not yield human-interpretable features nor those with value in prediction.  The investigators have developed methods for engineering features that balance utility in prediction with interpretability. Preliminary work by the investigators during a year of R56 support yielding 4 publications demonstrates that this approach indeed yields coherent topics without sacrificing predictive validity; electronic health records contain meaningful data that facilitates identification of interpretable patient subgroups. The present study draws on very large cohorts of individuals with major depression, defined by a validated algorithm, in electronic health records from two health systems. It will first apply methods developed by the investigators to identify MDD subtypes. These subtypes will then be examined in terms of predictive validity as well as interpretability by clinicians.  The study builds on a productive collaboration between a team experienced in mood disorder phenotyping and clinical investigation, analysis of large-scale longitudinal electronic health records, and development and application of innovative methods in machine learning that yield interpretable models rather than black boxes. Data-driven disease subtyping will facilitate clinically useful risk stratification as well as biological study of mood disorders. Narrative  The wide variation in symptoms of major depressive disorder complicates efforts to develop new treatments and make effective use of existing treatments. Applying machine learning methods to electronic health records will enable the identification of interpretable disease subgroups, enabling development of more targeted treatment strategies.",Data-driven subtyping in major depressive disorder,10211310,R01MH123804,"['Address', 'Algorithms', 'Area', 'Biological', 'Biology', 'Cessation of life', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Data', 'Data Set', 'Dementia', 'Development', 'Diagnostic', 'Dimensions', 'Disease', 'Disease remission', 'Electronic Health Record', 'Endocrine System Diseases', 'Engineering', 'Equilibrium', 'Evidence based treatment', 'Functional disorder', 'Health Care Costs', 'Health system', 'Heart Diseases', 'Heterogeneity', 'Hospitals', 'Human', 'Individual', 'Inflammatory Bowel Diseases', 'Machine Learning', 'Major Depressive Disorder', 'Malignant Neoplasms', 'Manuals', 'Measures', 'Medical', 'Medicine', 'Mental Depression', 'Methods', 'Modeling', 'Mood Disorders', 'Morbidity - disease rate', 'National Institute of Mental Health', 'Outcome', 'Patients', 'Performance', 'Phenotype', 'Prevalence', 'Public Health', 'Publications', 'Quality of life', 'Research Personnel', 'Selection for Treatments', 'Series', 'Subgroup', 'Suicide', 'Supervision', 'Symptoms', 'System', 'Therapeutic', 'Variant', 'Work', 'base', 'biomarker identification', 'clinical investigation', 'clinical subtypes', 'cohort', 'depressive symptoms', 'disorder subtype', 'experience', 'ineffective therapies', 'innovation', 'machine learning method', 'mortality', 'mortality risk', 'novel therapeutics', 'patient subsets', 'phenomenological models', 'precision medicine', 'risk stratification', 'standard care', 'success', 'targeted treatment', 'therapy resistant', 'treatment response', 'treatment strategy']",NIMH,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,832192
