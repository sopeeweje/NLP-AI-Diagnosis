text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms Project Summary The nematode worm Caenorhabditis elegans has proven valuable as a model for many high-impact medical conditions. The strength of C. elegans derives from the extensive homologies between human and nematode genes (60-80%) and the many powerful tools available to manipulate genes in C. elegans, including expressing human genes. Researchers utilizing medical models based on C. elegans have converged on two main quantifiable measures of health and disease: locomotion and feeding; the latter is the focus of this proposal. C. elegans feeds on bacteria ingested through the pharynx, a rhythmic muscular pump in the worm’s throat. Alterations in pharyngeal activity are a sensitive indicator of dysfunction in muscles and neurons, as well as the animal’s overall health and metabolic state. C. elegans neurobiologists have long recognized the utility of the elec- tropharyngeogram (EPG), a non-invasive, whole-body electrical recording analogous to an electrocardiogram (ECG), which provides a quantitative readout of feeding. However, technical barriers associated with whole- animal electrophysiology have limited its adoption to fewer than fifteen laboratories world-wide. NemaMetrix Inc. surmounted these barriers by developing a turn-key, microfluidic system for EPG acquisition and analysis called the the ScreenChip platform. The proposed research and commercialization activities significantly expand the capabilities of the ScreenChip platform in two key respects. First, they enlarge the phenotyping capabilities of the platform by incorporating high-speed video of whole animal and pharyngeal movements. Second they develop a cloud database compatible with Gene Ontology, Open Biomedical Ontologies and Worm Ontology standards, allowing data-mining of combined electrophysiological, imaging and other data modalities. The machine-readable database will be compatible with artificial intelligence and machine learning algorithms. It will be accessible to all researchers to enable discovery of relationships between genotypes, phenotypes and treatments using large-scale analysis of multidimensional phenotypic profiles. The research and commercialization efforts culminate in an unprecedented integration of genetic, cellular, and organismal levels of analysis, with minimal training and effort required by users. Going forward, we envision the PheNom platform as a gold standard for medical research using C. elegans. n/a",Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms,9671422,R44GM119906,"['Adopted', 'Adoption', 'Aging', 'Amplifiers', 'Animal Model', 'Animals', 'Artificial Intelligence', 'Bacteria', 'Biomedical Research', 'Caenorhabditis elegans', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Disease', 'Electrocardiogram', 'Electrodes', 'Electrophysiology (science)', 'Equipment', 'Face', 'Familiarity', 'Feeds', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Models', 'Genotype', 'Gold', 'Health', 'Health Status', 'Human', 'Image', 'Ingestion', 'Kinetics', 'Laboratories', 'Locomotion', 'Market Research', 'Measures', 'Medical', 'Medical Research', 'Metabolic', 'Metabolic dysfunction', 'Metadata', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscope', 'Microscopy', 'Modality', 'Modeling', 'Molecular', 'Movement', 'Muscle', 'Nematoda', 'Neurodegenerative Disorders', 'Neuromuscular Diseases', 'Neurons', 'Ontology', 'Optics', 'Periodicity', 'Pharyngeal structure', 'Phase', 'Phenotype', 'Physiological', 'Pre-Clinical Model', 'Pump', 'Readability', 'Recommendation', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Speed', 'Statistical Data Interpretation', 'Stream', 'Structure', 'Surveys', 'System', 'Training', 'United States National Institutes of Health', 'Video Microscopy', 'addiction', 'automated image analysis', 'base', 'biomedical ontology', 'commercialization', 'data mining', 'design', 'feeding', 'human disease', 'human model', 'machine learning algorithm', 'member', 'phenotypic data', 'prevent', 'software development', 'success', 'tool', 'trait', 'web app']",NIGMS,"NEMAMETRIX, INC.",R44,2019,475637,0.08491612494366588
"Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols Project Summary Biological assays are the foundation for developing chemical probes and drugs, but new Big Data approaches – which have revolutionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that scientists specify their assays through text descriptions written in scientific English, which need to be translated into standardized annotations readable by computers. This lack of standardized and machine-readable assay descriptions is a major impediment to manage, find, aggregate, compare, re-use, and learn from the ever-growing corpus of assays (e.g., >1.2 million in PubChem). Thus, there is a critical need for better annotation and curation tools for drug discovery assays. However, the process to go from a simple text protocol to highly detailed machine-readable semantic annotations is not trivial. Multiple tools and technologies are required: ontologies or the structured controlled vocabularies; templates that map specific vocabularies to properties that are to be captured; and software tools to actually apply these ontologies to a given text. Currently, each of these exists in isolation; yet, a bottleneck in any one tool or technology, or a gap between the different pieces, disrupts the overall process, resulting in poor or no annotation of the datasets. Here we propose a project to combine and integrate these three technologies (which are also the core competencies of the three groups collaborating on this proposal). We will deliver a novel, comprehensive, user-friendly data annotation and curation system that is highly interconnected, encompassing the full cycle, and real-world practice, of required tasks and decisions, by all parties within the `bioassay annotation ecosystem' (researchers performing curation, dedicated curators, IT specialists, ontology owners, and librarians/repositories). The alliance between academic and commercial collaborators, who already work together, will greatly benefit the project and minimize execution risk. Our specific aims are to: (1) Develop a bioassay-specific template editor and templates by adopting the Stanford (Center for Expanded Data Annotation and Retrieval, CEDAR) data model to the machine learning-based curation tool BioAssay Express, to exploit the broad functionality of its data structures, tools and interfaces; (2) Define and create an ontology update process and tool (`OntoloBridge') to support rapid feedback between curators/users and ontology experts and enable semi-automated incorporation of suggestions for updates to existing published ontologies; (3) Develop new tools to export annotated data into public repositories such as PubChem; and (4) Evaluate our solution across diverse audiences (pharma, academia, repositories). The system will improve bioassay curation efficiency, quality, and effectiveness, enabling scientists to generate standardized annotations for their experiments to make these data FAIR (Findable, Accessible, Interoperable, Reusable). We envision this suite of tools will encourage annotation earlier in the data lifecycle while still supporting annotation at later stages (e.g., submission to repositories or to journals). Project Narrative Biological assays are the foundation for developing drugs, but new Big Data approaches – which have revolu- tionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that assays are written in scientific English, which need to be translated into standardized descriptions readable by computers. This lack of machine-readable annotations is a major impediment to manage, find, compare, re-use, and learn from the millions of assays. This project will develop a formal process and integrated tools to support the complete cycle of tasks and decisions required for bioassay annotation, enabling expedited (and more cost-effective) drug discovery.","Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols",9747967,U01LM012630,"['Academia', 'Address', 'Adopted', 'Adoption', 'Area', 'Big Data', 'Big Data Methods', 'Biological Assay', 'Biomedical Research', 'Chemicals', 'Communication', 'Communities', 'Competence', 'Complex', 'Computer software', 'Computers', 'Controlled Vocabulary', 'Custom', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Ecosystem', 'Effectiveness', 'Elements', 'Ensure', 'Exercise', 'FAIR principles', 'Feedback', 'Foundations', 'Hour', 'Journals', 'Learning', 'Librarians', 'Machine Learning', 'Manuals', 'Maps', 'Metadata', 'Ontology', 'Output', 'Participant', 'Pharmaceutical Preparations', 'Polishes', 'Problem Solving', 'Process', 'Property', 'Protocols documentation', 'PubChem', 'Publishing', 'Readability', 'Research', 'Research Personnel', 'Retrieval', 'Risk', 'Science', 'Scientist', 'Semantics', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Standardization', 'Structure', 'Suggestion', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Tweens', 'Update', 'Vocabulary', 'Work', 'base', 'cost effective', 'data modeling', 'design', 'drug discovery', 'drug mechanism', 'experience', 'experimental study', 'improved', 'improved functioning', 'in vivo', 'informatics training', 'novel', 'ontology development', 'open source', 'practical application', 'predictive modeling', 'repository', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,U01,2019,514129,0.1645377237314936
"Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences Project Abstract The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage burgeoning numbers of data. The need to annotate, retrieve, and integrate high- throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous international community of scientists—supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 300,000 users as of this writing. The widespread use of ontologies in biomedicine and the availability of tools, such as Protégé, have taken the biomedical field forward to a new set of challenges that current technology has not been designed to address: Biomedical ontologies have grown in size and scope, and their creation, maintenance and quality assurance have become particularly effort-intensive and error-prone. In this proposal, we will develop new methods and tools that will significantly aid biomedical researchers in easily creating and testing biomedical ontologies throughout their lifecycle. Our plan entails four specific aims. First, we will develop methods and tools to allow biomedical scientist to easily create ontologies directly from their source documents, such as spreadsheets, tab indented hierarchies, and document outlines. Second, we will provide the methods and tools to allow biomedical scientist to identify potential “hot spots” in their ontologies that might affect their quality. Third, we will implement a comprehensive, automated testing framework for ontologies that will assist biomedical researchers in performing ontology and data quality assurance throughout the development cycle. Fourth, we will continue to expand and support the thriving Protégé user community, as it grows to include new clinicians and biomedical scientists as they build the ontologies needed to support clinical care, data-driven research, and the elucidation of new discoveries. Project Narrative Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care. Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences,9607599,R01GM121724,"['Address', 'Adopted', 'Advanced Development', 'Affect', 'Applications Grants', 'Area', 'Biomedical Research', 'Clinical', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Data', 'Data Quality', 'Data Set', 'Data Sources', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Engineering', 'Ensure', 'Environment', 'Foundations', 'Goals', 'Head', 'Hot Spot', 'Human', 'Informatics', 'Information Retrieval', 'Information Systems', 'Infrastructure', 'International', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Letters', 'Maintenance', 'Manuals', 'Methods', 'Modernization', 'Natural Language Processing', 'Ontology', 'Patient Care', 'Process', 'Publications', 'Research', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Source', 'System', 'Technology', 'Terminology', 'Testing', 'Time', 'Update', 'Work', 'Writing', 'biomedical ontology', 'biomedical scientist', 'clinical care', 'data integration', 'data sharing', 'design', 'document outlines', 'improved', 'innovation', 'interoperability', 'knowledge base', 'natural language', 'next generation', 'ontology development', 'open source', 'quality assurance', 'software systems', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2019,559237,0.3038083073865155
"Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms Project Summary The nematode worm Caenorhabditis elegans has proven valuable as a model for many high-impact medical conditions. The strength of C. elegans derives from the extensive homologies between human and nematode genes (60-80%) and the many powerful tools available to manipulate genes in C. elegans, including expressing human genes. Researchers utilizing medical models based on C. elegans have converged on two main quantifiable measures of health and disease: locomotion and feeding; the latter is the focus of this proposal. C. elegans feeds on bacteria ingested through the pharynx, a rhythmic muscular pump in the worm’s throat. Alterations in pharyngeal activity are a sensitive indicator of dysfunction in muscles and neurons, as well as the animal’s overall health and metabolic state. C. elegans neurobiologists have long recognized the utility of the elec- tropharyngeogram (EPG), a non-invasive, whole-body electrical recording analogous to an electrocardiogram (ECG), which provides a quantitative readout of feeding. However, technical barriers associated with whole- animal electrophysiology have limited its adoption to fewer than fifteen laboratories world-wide. NemaMetrix Inc. surmounted these barriers by developing a turn-key, microfluidic system for EPG acquisition and analysis called the the ScreenChip platform. The proposed research and commercialization activities significantly expand the capabilities of the ScreenChip platform in two key respects. First, they enlarge the phenotyping capabilities of the platform by incorporating high-speed video of whole animal and pharyngeal movements. Second they develop a cloud database compatible with Gene Ontology, Open Biomedical Ontologies and Worm Ontology standards, allowing data-mining of combined electrophysiological, imaging and other data modalities. The machine-readable database will be compatible with artificial intelligence and machine learning algorithms. It will be accessible to all researchers to enable discovery of relationships between genotypes, phenotypes and treatments using large-scale analysis of multidimensional phenotypic profiles. The research and commercialization efforts culminate in an unprecedented integration of genetic, cellular, and organismal levels of analysis, with minimal training and effort required by users. Going forward, we envision the PheNom platform as a gold standard for medical research using C. elegans. n/a",Advancing Human Health by Lowering Barriers to Electrophysiology in Genetic Model Organisms,9467327,R44GM119906,"['Adopted', 'Adoption', 'Aging', 'Algorithms', 'Amplifiers', 'Animal Model', 'Animals', 'Artificial Intelligence', 'Bacteria', 'Biomedical Research', 'Caenorhabditis elegans', 'Communities', 'Computer software', 'Data', 'Data Analyses', 'Databases', 'Disease', 'Electrocardiogram', 'Electrodes', 'Electrophysiology (science)', 'Equipment', 'Face', 'Familiarity', 'Feeds', 'Functional disorder', 'Genes', 'Genetic', 'Genetic Models', 'Genotype', 'Gold', 'Health', 'Health Status', 'Human', 'Image', 'Image Analysis', 'Kinetics', 'Laboratories', 'Locomotion', 'Machine Learning', 'Market Research', 'Measures', 'Medical', 'Medical Research', 'Metabolic', 'Metabolic dysfunction', 'Metadata', 'Methods', 'Microfluidic Microchips', 'Microfluidics', 'Microscope', 'Microscopy', 'Modality', 'Modeling', 'Molecular', 'Movement', 'Muscle', 'Nematoda', 'Neurodegenerative Disorders', 'Neuromuscular Diseases', 'Neurons', 'Ontology', 'Optics', 'Periodicity', 'Pharyngeal structure', 'Phase', 'Phenotype', 'Physiological', 'Pre-Clinical Model', 'Pump', 'Readability', 'Recommendation', 'Research', 'Research Personnel', 'Resources', 'Signal Transduction', 'Speed', 'Statistical Data Interpretation', 'Stream', 'Structure', 'Surveys', 'System', 'Training', 'United States National Institutes of Health', 'Video Microscopy', 'addiction', 'base', 'biomedical ontology', 'commercialization', 'data mining', 'design', 'feeding', 'human disease', 'human model', 'member', 'phenotypic data', 'prevent', 'software development', 'success', 'tool', 'trait', 'web app']",NIGMS,"NEMAMETRIX, INC.",R44,2018,510448,0.08491612494366588
"Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols Project Summary Biological assays are the foundation for developing chemical probes and drugs, but new Big Data approaches – which have revolutionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that scientists specify their assays through text descriptions written in scientific English, which need to be translated into standardized annotations readable by computers. This lack of standardized and machine-readable assay descriptions is a major impediment to manage, find, aggregate, compare, re-use, and learn from the ever-growing corpus of assays (e.g., >1.2 million in PubChem). Thus, there is a critical need for better annotation and curation tools for drug discovery assays. However, the process to go from a simple text protocol to highly detailed machine-readable semantic annotations is not trivial. Multiple tools and technologies are required: ontologies or the structured controlled vocabularies; templates that map specific vocabularies to properties that are to be captured; and software tools to actually apply these ontologies to a given text. Currently, each of these exists in isolation; yet, a bottleneck in any one tool or technology, or a gap between the different pieces, disrupts the overall process, resulting in poor or no annotation of the datasets. Here we propose a project to combine and integrate these three technologies (which are also the core competencies of the three groups collaborating on this proposal). We will deliver a novel, comprehensive, user-friendly data annotation and curation system that is highly interconnected, encompassing the full cycle, and real-world practice, of required tasks and decisions, by all parties within the `bioassay annotation ecosystem' (researchers performing curation, dedicated curators, IT specialists, ontology owners, and librarians/repositories). The alliance between academic and commercial collaborators, who already work together, will greatly benefit the project and minimize execution risk. Our specific aims are to: (1) Develop a bioassay-specific template editor and templates by adopting the Stanford (Center for Expanded Data Annotation and Retrieval, CEDAR) data model to the machine learning-based curation tool BioAssay Express, to exploit the broad functionality of its data structures, tools and interfaces; (2) Define and create an ontology update process and tool (`OntoloBridge') to support rapid feedback between curators/users and ontology experts and enable semi-automated incorporation of suggestions for updates to existing published ontologies; (3) Develop new tools to export annotated data into public repositories such as PubChem; and (4) Evaluate our solution across diverse audiences (pharma, academia, repositories). The system will improve bioassay curation efficiency, quality, and effectiveness, enabling scientists to generate standardized annotations for their experiments to make these data FAIR (Findable, Accessible, Interoperable, Reusable). We envision this suite of tools will encourage annotation earlier in the data lifecycle while still supporting annotation at later stages (e.g., submission to repositories or to journals). Project Narrative Biological assays are the foundation for developing drugs, but new Big Data approaches – which have revolu- tionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that assays are written in scientific English, which need to be translated into standardized descriptions readable by computers. This lack of machine-readable annotations is a major impediment to manage, find, compare, re-use, and learn from the millions of assays. This project will develop a formal process and integrated tools to support the complete cycle of tasks and decisions required for bioassay annotation, enabling expedited (and more cost-effective) drug discovery.","Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols",9527186,U01LM012630,"['Academia', 'Address', 'Adopted', 'Adoption', 'Area', 'Big Data', 'Biological Assay', 'Biomedical Research', 'Chemicals', 'Communication', 'Communities', 'Competence', 'Complex', 'Computer software', 'Computers', 'Controlled Vocabulary', 'Custom', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Ecosystem', 'Effectiveness', 'Elements', 'Ensure', 'Exercise', 'FAIR principles', 'Feedback', 'Foundations', 'Hour', 'Journals', 'Learning', 'Librarians', 'Machine Learning', 'Manuals', 'Maps', 'Metadata', 'Methods', 'Ontology', 'Output', 'Participant', 'Pharmaceutical Preparations', 'Polishes', 'Problem Solving', 'Process', 'Property', 'Protocols documentation', 'PubChem', 'Publishing', 'Readability', 'Research', 'Research Personnel', 'Retrieval', 'Risk', 'Science', 'Scientist', 'Semantics', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Standardization', 'Structure', 'Suggestion', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Tweens', 'Update', 'Vocabulary', 'Work', 'base', 'cost effective', 'data modeling', 'design', 'drug discovery', 'drug mechanism', 'experience', 'experimental study', 'improved', 'improved functioning', 'in vivo', 'informatics training', 'novel', 'ontology development', 'open source', 'practical application', 'predictive modeling', 'repository', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,U01,2018,516810,0.1645377237314936
"Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences Project Abstract The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage burgeoning numbers of data. The need to annotate, retrieve, and integrate high- throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous international community of scientists—supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 300,000 users as of this writing. The widespread use of ontologies in biomedicine and the availability of tools, such as Protégé, have taken the biomedical field forward to a new set of challenges that current technology has not been designed to address: Biomedical ontologies have grown in size and scope, and their creation, maintenance and quality assurance have become particularly effort-intensive and error-prone. In this proposal, we will develop new methods and tools that will significantly aid biomedical researchers in easily creating and testing biomedical ontologies throughout their lifecycle. Our plan entails four specific aims. First, we will develop methods and tools to allow biomedical scientist to easily create ontologies directly from their source documents, such as spreadsheets, tab indented hierarchies, and document outlines. Second, we will provide the methods and tools to allow biomedical scientist to identify potential “hot spots” in their ontologies that might affect their quality. Third, we will implement a comprehensive, automated testing framework for ontologies that will assist biomedical researchers in performing ontology and data quality assurance throughout the development cycle. Fourth, we will continue to expand and support the thriving Protégé user community, as it grows to include new clinicians and biomedical scientists as they build the ontologies needed to support clinical care, data-driven research, and the elucidation of new discoveries. Project Narrative Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care. Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences,9404042,R01GM121724,"['Address', 'Adopted', 'Advanced Development', 'Affect', 'Applications Grants', 'Area', 'Biomedical Research', 'Clinical', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Data', 'Data Quality', 'Data Set', 'Data Sources', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Engineering', 'Ensure', 'Environment', 'Foundations', 'Goals', 'Head', 'Hot Spot', 'Human', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Letters', 'Maintenance', 'Manuals', 'Methods', 'Modernization', 'Natural Language Processing', 'Ontology', 'Patient Care', 'Process', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Source', 'System', 'Technology', 'Terminology', 'Testing', 'Time', 'Update', 'Work', 'Writing', 'biomedical ontology', 'biomedical scientist', 'clinical care', 'data integration', 'data sharing', 'design', 'document outlines', 'improved', 'innovation', 'interoperability', 'knowledge base', 'natural language', 'next generation', 'ontology development', 'open source', 'quality assurance', 'software systems', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2018,564487,0.3038083073865155
"PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge ﻿    DESCRIPTION (provided by applicant): PROJECT SUMMARY Biomedical ontologies are critical to the accurate representation and integration of genome-scale data in biomedical and clinical research. The Protein Ontology (PRO)-the reference ontology for protein entities in the OBO (Open Biological and Biomedical Ontologies) Foundry-represents protein families, multiple protein forms (proteoforms) arising from single genes, and protein complexes. This competitive renewal grant application will further establish PRO as a scalable, flexible, collaborative research infrastructure for protein-centric semantic integration of biomedical data of increasing volume and complexity. Specific aims are to: (i) enable scalable and dynamic representation of protein types; (ii) provide comprehensive coverage of human proteoforms in their biological context; (iii) develop collaborative use cases and support an expanding community of users to advance protein-disease understanding; and (iv) broaden dissemination to support semantic computing, dynamic term mapping, and interoperability and reusability. We will increase PRO coverage by semi-automated import of proteoforms and complexes from curated databases and via established text mining approaches. Expert curation will focus on human variant forms, post-translational modification (PTM) forms and complexes critical to disease processes, along with homologous mouse forms. We will develop a new PRO sub-ontology of protein sites-amino acid positions of significance-to enable automatic and dynamic definition of combinatoric proteoforms. We will establish PRO OWL and RDF versions and provide a SPARQL query endpoint to support semantic computing. We will organize annual workshops and annotation jamborees to develop use cases and promote PRO co-development with community collaborators to address specific disciplinary needs. PRO has several unique features. For knowledge representation, PRO defines precise protein entities to support accurate annotation at the appropriate level of granularity and provides the ontological framework to connect PTM and variant proteoforms and complexes necessary to model human health and disease. For semantic data integration, PRO provides the ontological structure to connect-via specified relations-the vast amounts of proteomics data and biomedical knowledge to support hypothesis generation and testing. PRO therefore addresses the gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully complementing existing knowledge sources. The proposed research will allow the PRO Consortium to deepen and broaden PRO for scalable semantic integration of biomedical data, facilitating protein-disease knowledge discovery and clinical applications by an expanding community of biomedical, clinical and computational users. PUBLIC HEALTH RELEVANCE: PROJECT NARRATIVE The Protein Ontology (PRO) will allow researchers to capture and accurately represent scientific knowledge of proteins thus providing a research infrastructure for modeling biological systems and for protein-centric integration of existing and emerging experimental and clinical data. As a component of the global informatics resource network, the PRO resource will be instrumental in computational analysis and knowledge discovery of genome-scale data and will aid in improving our understanding of human disease, and in the identification of potential diagnostic and therapeutic targets.",PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge,9546737,R01GM080646,"['Address', 'Adopted', 'Amino Acid Sequence', 'Amino Acids', 'Applications Grants', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biological Models', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Research', 'Combinatorics', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Educational workshop', 'FAIR principles', 'Fostering', 'Gene Proteins', 'Generations', 'Genetic Polymorphism', 'Health', 'Histones', 'Human', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Literature', 'Mus', 'Natural Language Processing', 'Ontology', 'Organism', 'Phenotype', 'Phosphotransferases', 'Play', 'Positioning Attribute', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Informatics', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Services', 'Signal Transduction', 'Site', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Testing', 'Training', 'Variant', 'base', 'biological systems', 'biomedical ontology', 'clinical application', 'computational reasoning', 'data integration', 'disease classification', 'flexibility', 'genome-wide', 'human disease', 'human model', 'improved', 'information organization', 'interoperability', 'knowledge base', 'protein complex', 'public health relevance', 'symposium', 'text searching', 'therapeutic target', 'usability', 'web portal', 'web services']",NIGMS,UNIVERSITY OF DELAWARE,R01,2018,688354,0.11876966996859015
"Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols Project Summary Biological assays are the foundation for developing chemical probes and drugs, but new Big Data approaches – which have revolutionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that scientists specify their assays through text descriptions written in scientific English, which need to be translated into standardized annotations readable by computers. This lack of standardized and machine-readable assay descriptions is a major impediment to manage, find, aggregate, compare, re-use, and learn from the ever-growing corpus of assays (e.g., >1.2 million in PubChem). Thus, there is a critical need for better annotation and curation tools for drug discovery assays. However, the process to go from a simple text protocol to highly detailed machine-readable semantic annotations is not trivial. Multiple tools and technologies are required: ontologies or the structured controlled vocabularies; templates that map specific vocabularies to properties that are to be captured; and software tools to actually apply these ontologies to a given text. Currently, each of these exists in isolation; yet, a bottleneck in any one tool or technology, or a gap between the different pieces, disrupts the overall process, resulting in poor or no annotation of the datasets. Here we propose a project to combine and integrate these three technologies (which are also the core competencies of the three groups collaborating on this proposal). We will deliver a novel, comprehensive, user-friendly data annotation and curation system that is highly interconnected, encompassing the full cycle, and real-world practice, of required tasks and decisions, by all parties within the `bioassay annotation ecosystem' (researchers performing curation, dedicated curators, IT specialists, ontology owners, and librarians/repositories). The alliance between academic and commercial collaborators, who already work together, will greatly benefit the project and minimize execution risk. Our specific aims are to: (1) Develop a bioassay-specific template editor and templates by adopting the Stanford (Center for Expanded Data Annotation and Retrieval, CEDAR) data model to the machine learning-based curation tool BioAssay Express, to exploit the broad functionality of its data structures, tools and interfaces; (2) Define and create an ontology update process and tool (`OntoloBridge') to support rapid feedback between curators/users and ontology experts and enable semi-automated incorporation of suggestions for updates to existing published ontologies; (3) Develop new tools to export annotated data into public repositories such as PubChem; and (4) Evaluate our solution across diverse audiences (pharma, academia, repositories). The system will improve bioassay curation efficiency, quality, and effectiveness, enabling scientists to generate standardized annotations for their experiments to make these data FAIR (Findable, Accessible, Interoperable, Reusable). We envision this suite of tools will encourage annotation earlier in the data lifecycle while still supporting annotation at later stages (e.g., submission to repositories or to journals). Project Narrative Biological assays are the foundation for developing drugs, but new Big Data approaches – which have revolu- tionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that assays are written in scientific English, which need to be translated into standardized descriptions readable by computers. This lack of machine-readable annotations is a major impediment to manage, find, compare, re-use, and learn from the millions of assays. This project will develop a formal process and integrated tools to support the complete cycle of tasks and decisions required for bioassay annotation, enabling expedited (and more cost-effective) drug discovery.","Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols",9398728,U01LM012630,"['Academia', 'Address', 'Adopted', 'Adoption', 'Area', 'Big Data', 'Biological Assay', 'Biomedical Research', 'Chemicals', 'Communication', 'Communities', 'Competence', 'Complex', 'Computer software', 'Computers', 'Controlled Vocabulary', 'Custom', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Development', 'Ecosystem', 'Effectiveness', 'Elements', 'Ensure', 'Exercise', 'FAIR principles', 'Feedback', 'Foundations', 'Hour', 'Journals', 'Learning', 'Librarians', 'Machine Learning', 'Manuals', 'Maps', 'Metadata', 'Methods', 'Ontology', 'Output', 'Participant', 'Pharmaceutical Preparations', 'Polishes', 'Problem Solving', 'Process', 'Property', 'Protocols documentation', 'PubChem', 'Publishing', 'Readability', 'Research', 'Research Personnel', 'Retrieval', 'Risk', 'Science', 'Scientist', 'Semantics', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Standardization', 'Structure', 'Suggestion', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Tweens', 'Update', 'Vocabulary', 'Work', 'base', 'cost effective', 'data modeling', 'design', 'drug discovery', 'drug mechanism', 'experience', 'experimental study', 'improved', 'improved functioning', 'in vivo', 'informatics training', 'novel', 'open source', 'practical application', 'predictive modeling', 'repository', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,U01,2017,546372,0.1645377237314936
"Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences Project Abstract The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage burgeoning numbers of data. The need to annotate, retrieve, and integrate high- throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous international community of scientists—supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 300,000 users as of this writing. The widespread use of ontologies in biomedicine and the availability of tools, such as Protégé, have taken the biomedical field forward to a new set of challenges that current technology has not been designed to address: Biomedical ontologies have grown in size and scope, and their creation, maintenance and quality assurance have become particularly effort-intensive and error-prone. In this proposal, we will develop new methods and tools that will significantly aid biomedical researchers in easily creating and testing biomedical ontologies throughout their lifecycle. Our plan entails four specific aims. First, we will develop methods and tools to allow biomedical scientist to easily create ontologies directly from their source documents, such as spreadsheets, tab indented hierarchies, and document outlines. Second, we will provide the methods and tools to allow biomedical scientist to identify potential “hot spots” in their ontologies that might affect their quality. Third, we will implement a comprehensive, automated testing framework for ontologies that will assist biomedical researchers in performing ontology and data quality assurance throughout the development cycle. Fourth, we will continue to expand and support the thriving Protégé user community, as it grows to include new clinicians and biomedical scientists as they build the ontologies needed to support clinical care, data-driven research, and the elucidation of new discoveries. Project Narrative Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care. Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences,9217457,R01GM121724,"['Address', 'Adopted', 'Advanced Development', 'Affect', 'Applications Grants', 'Area', 'Biomedical Research', 'Clinical', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Data', 'Data Quality', 'Data Set', 'Data Sources', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Engineering', 'Ensure', 'Environment', 'Foundations', 'Goals', 'Head', 'Hot Spot', 'Human', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Letters', 'Maintenance', 'Manuals', 'Methods', 'Modernization', 'Natural Language Processing', 'Ontology', 'Patient Care', 'Process', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Source', 'System', 'Technology', 'Terminology', 'Testing', 'Time', 'Update', 'Work', 'Writing', 'biomedical ontology', 'biomedical scientist', 'clinical care', 'clinical development', 'data integration', 'data sharing', 'design', 'document outlines', 'improved', 'innovation', 'interoperability', 'knowledge base', 'natural language', 'next generation', 'open source', 'quality assurance', 'software systems', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2017,578512,0.3038083073865155
"PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge ﻿    DESCRIPTION (provided by applicant): PROJECT SUMMARY Biomedical ontologies are critical to the accurate representation and integration of genome-scale data in biomedical and clinical research. The Protein Ontology (PRO)-the reference ontology for protein entities in the OBO (Open Biological and Biomedical Ontologies) Foundry-represents protein families, multiple protein forms (proteoforms) arising from single genes, and protein complexes. This competitive renewal grant application will further establish PRO as a scalable, flexible, collaborative research infrastructure for protein-centric semantic integration of biomedical data of increasing volume and complexity. Specific aims are to: (i) enable scalable and dynamic representation of protein types; (ii) provide comprehensive coverage of human proteoforms in their biological context; (iii) develop collaborative use cases and support an expanding community of users to advance protein-disease understanding; and (iv) broaden dissemination to support semantic computing, dynamic term mapping, and interoperability and reusability. We will increase PRO coverage by semi-automated import of proteoforms and complexes from curated databases and via established text mining approaches. Expert curation will focus on human variant forms, post-translational modification (PTM) forms and complexes critical to disease processes, along with homologous mouse forms. We will develop a new PRO sub-ontology of protein sites-amino acid positions of significance-to enable automatic and dynamic definition of combinatoric proteoforms. We will establish PRO OWL and RDF versions and provide a SPARQL query endpoint to support semantic computing. We will organize annual workshops and annotation jamborees to develop use cases and promote PRO co-development with community collaborators to address specific disciplinary needs. PRO has several unique features. For knowledge representation, PRO defines precise protein entities to support accurate annotation at the appropriate level of granularity and provides the ontological framework to connect PTM and variant proteoforms and complexes necessary to model human health and disease. For semantic data integration, PRO provides the ontological structure to connect-via specified relations-the vast amounts of proteomics data and biomedical knowledge to support hypothesis generation and testing. PRO therefore addresses the gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully complementing existing knowledge sources. The proposed research will allow the PRO Consortium to deepen and broaden PRO for scalable semantic integration of biomedical data, facilitating protein-disease knowledge discovery and clinical applications by an expanding community of biomedical, clinical and computational users. PUBLIC HEALTH RELEVANCE: PROJECT NARRATIVE The Protein Ontology (PRO) will allow researchers to capture and accurately represent scientific knowledge of proteins thus providing a research infrastructure for modeling biological systems and for protein-centric integration of existing and emerging experimental and clinical data. As a component of the global informatics resource network, the PRO resource will be instrumental in computational analysis and knowledge discovery of genome-scale data and will aid in improving our understanding of human disease, and in the identification of potential diagnostic and therapeutic targets.",PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge,9331689,R01GM080646,"['Address', 'Adopted', 'Amino Acid Sequence', 'Amino Acids', 'Applications Grants', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biological Models', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Research', 'Combinatorics', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Educational workshop', 'FAIR principles', 'Fostering', 'Gene Proteins', 'Generations', 'Genetic Polymorphism', 'Health', 'Histones', 'Human', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Literature', 'Modeling', 'Mus', 'Natural Language Processing', 'Ontology', 'Organism', 'Phenotype', 'Phosphotransferases', 'Play', 'Positioning Attribute', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Informatics', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Services', 'Signal Transduction', 'Site', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Testing', 'Training', 'Variant', 'base', 'biological systems', 'biomedical ontology', 'clinical application', 'computational reasoning', 'data integration', 'disease classification', 'flexibility', 'genome-wide', 'human disease', 'improved', 'information organization', 'interoperability', 'knowledge base', 'protein complex', 'public health relevance', 'symposium', 'text searching', 'therapeutic target', 'usability', 'web portal', 'web services']",NIGMS,UNIVERSITY OF DELAWARE,R01,2017,708354,0.11876966996859015
"Turning Data into Whole Cell Ontology Models for Functional Analysis     DESCRIPTION (provided by applicant): A holy grail of bioinformatics is the creation of whole-cell models with the ability to enhance human understanding and facilitate discovery. To this end, a successful and widely-used effort is the Gene Ontology (GO), a massive project to manually annotate genes into terms describing molecular functions, biological processes and cellular components and provide relationships between terms, e.g. capturing that ""small ribosomal subunit"" and ""large ribosomal subunit"" come together to make ""ribosome"". GO is widely used to understand the function of a gene or group of genes. Unfortunately, GO is limited by the effort required to create and update it by hand. It exists only for well-studied organisms and even then in only one, generic form per organism with limited overall genome coverage and a bias towards well-studied genes and functions. It is not possible to learn about an uncharacterized gene or discover a new function using GO, and one cannot quickly assemble an ontology model for a new organism, let alone a specific cell-type or disease-state.  This proposed research will change this state of affairs. Already, work has shown that large networks of gene and protein interactions in Saccharomyces cerevisiae can be used to computationally infer an ontology whose coverage and power are equivalent to those of the manually-curated GO Cellular Component ontology. Still, this first attempt was limited in the types of experimental data used and its ability to infer the more generally useful Biological Process ontology. Here machine learning approaches will be applied to integrate many types of experimental data into ontology model construction and analyze the type of biological information provided by each experiment, revealing those experiments most informative for capturing Biological Process information. Furthermore, the high-throughput experimental data to ontology paradigm explored here will be used to develop a computational tool to highlight novel types of hypotheses that are inaccessible by current high-throughput experimental data analysis methods.  Preliminary work has shown GO to be useful for prediction of synthetic lethal pairs of genes, i.e. genes that are individually non-essential but when knocked out together cause cell death. Given the high mutation rate in cancer, these pairs provide potential cancer drug targets, as a drug may target a gene product which is now essential in the mutated cancer cells but not other cells, thereby killing only cancer cells. Because data-driven ontologies are not as hindered by issues with bias and coverage and are specifically designed to capture only functional relationships, this proposal will explore the idea that data-driven ontologies will be better suited to help predict synthetic lethal pairs than GO. To this end, algorithms will be developed to construct a data-driven ontology of yeast DNA repair and use this ontology to predict synthetic lethal pairs of genes.  Overall, this proposal will develop the computational and experimental roadmap to construct a whole-cell model of gene function - an ontology - and use the model to discover useful biology - synthetic lethal pairs.         PUBLIC HEALTH RELEVANCE: In this proposal, a new framework for using the results of commonly performed, genome-wide experiments has the potential to create whole-cell models of gene function, similar to the widely-used Gene Ontology, directly from data without manual intervention. This will allow creation of useful models of cells from different organisms, tissues and diseases which researchers can use to discover the function of unstudied genes and to uncover new functions performed by the cell. Furthermore, this proposal will use these models for the discovery of new cancer drug targets called synthetic lethal pairs of genes.            ",Turning Data into Whole Cell Ontology Models for Functional Analysis,9145523,F30HG007618,"['Algorithms', 'Antineoplastic Agents', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cell Death', 'Cell model', 'Cell physiology', 'Cells', 'Cluster Analysis', 'Code', 'Collection', 'Coupled', 'DNA Repair', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Disease', 'Drug Targeting', 'Future', 'Gene Cluster', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Goals', 'Hand', 'Human', 'Individual', 'Intervention', 'Knock-out', 'Learning', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Ontology', 'Organism', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Processed Genes', 'Proteins', 'Research', 'Research Personnel', 'Ribosomes', 'Saccharomyces cerevisiae', 'Subgroup', 'System', 'Tissues', 'Update', 'Work', 'Yeasts', 'base', 'biological information processing', 'cancer cell', 'cell type', 'computerized tools', 'design', 'experimental analysis', 'functional group', 'gene function', 'gene product', 'genome-wide', 'improved', 'killings', 'novel', 'novel anticancer drug', 'prediction algorithm', 'public health relevance', 'research study', 'synthetic biology', 'tool']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",F30,2016,48576,0.1738039488987169
"Collaborative Development of Biomedical Ontologies and Terminologies DESCRIPTION (provided by applicant): The construction of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process  natural language, and to build systems for decision support has set many communities  of biomedical investigators to work building large ontologies.  We developed and evaluated the Collaborative Prot¿g¿ system in the first phase of our research project. This software system has become an indispensable open-source resource for an international community of scientists who develop ontologies in a cooperative, distributed manner. In this competing renewal proposal, we describe novel data-driven methods and tools that promise to make collaborative ontology design both more streamlined and more principled. Our goal is to create a more empirical basis for ontology engineering, and to develop methods whereby the ontology-engineering enterprise both can profit from data regarding the underlying processes and those processes in turn can generate increasing amounts of data to inform future ontology-engineering activities.  Our research plan entails three specific aims. First, we will enable ontology developers to apply ontology-design patterns (ODPs) to their ontologies, and we will measure the way in which these patterns alter the ontology-engineering process. Second, we will analyze the vast amounts of log data that we collect from users of Collaborative Prot¿g¿ to understand the patterns of ontology development. We will use these patterns to recommend to developers areas of ontologies that may need their attention, facilitating the process of reaching consensus and making collaborative ontology engineering more efficient. Finally, we will use the extensive data collected by our group and others to understand how scientists reuse terms from various ontologies and we will use these emerging patterns to facilitate term reuse. Each of these analyses not only will increase our understanding of collaboration in scientific modeling, but also will lead to new technology within our Collaborative Prot¿g¿ suite that will improve the ontology-development process and make collaboration among biomedical scientists more efficient. PUBLIC HEALTH RELEVANCE: Collaborative Prot�g� is a software system that helps a burgeoning user community to cooperate in developing ontologies that enhance biomedical research and improve patient care. Collaborative Prot�g� supports scientists, clinician researchers, and workers in informatics to build ontologies to solve problems in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision support. The proposed research will develop data-driven methods to identify patterns in design, development, and use of ontologies, and will apply these methods to help us to build new technology that both facilitates the ontology-development process and makes ontology design more principled.",Collaborative Development of Biomedical Ontologies and Terminologies,8997510,R01GM086587,"['Address', 'Applications Grants', 'Area', 'Attention', 'Biomedical Research', 'Classification', 'Collaborations', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Consensus', 'Craniofacial Abnormalities', 'Data', 'Data Analyses', 'Data Set', 'Decision Support Systems', 'Development', 'Engineering', 'FaceBase', 'Future', 'Generations', 'Genes', 'Goals', 'Health', 'Human', 'Informatics', 'Information Retrieval', 'International', 'International Classification of Diseases', 'Knowledge', 'Lead', 'Learning', 'Maintenance', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'NCI Thesaurus', 'National Cancer Institute', 'Natural Language Processing', 'Ontology', 'Parasites', 'Patient Care', 'Pattern', 'Phase', 'Problem Solving', 'Process', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Scientist', 'Software Design', 'Software Engineering', 'Specialist', 'System', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Traditional Medicine', 'Work', 'base', 'biomedical ontology', 'biomedical resource', 'biomedical scientist', 'craniofacial development', 'data integration', 'design', 'experience', 'improved', 'interoperability', 'new technology', 'novel', 'open source', 'repository', 'software systems', 'tool', 'tool development']",NIGMS,STANFORD UNIVERSITY,R01,2016,510376,0.31020829168729047
"Protege: An Ontology-Development Platform for Biomedical Scientists DESCRIPTION (provided by applicant): The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in  biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous internationa community of scientists-supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 195,000 users as of this writing. To date, however, the use of ontologies in biomedicine has been limited by the complexity of the ontology-development tools, which often make ontologies inaccessible to many biomedical scientists.  In this proposal, we will develop new methods and tools that will significantly lower the barrier of entry for ontology development, expanding Protégé to provide intuitive and user-friendly ontology-acquisition methods throughout the ontology lifecycle.  Our plan entails five specific aims.  First, we will develop methods that enable initial specification of ontology terms in an informal manner, using lists and diagrams.  Scientists will be able to start modeling their domain without having to think in terms of formal ontological distinctions. Second, we will provide intuitive, easy-to-use tools for ontology specification that will aid developers as they start to formalize their models.  Third, we will track the requirements that an ontology must address and develop novel  methods  for  evaluating  ontology  coverage  based  on  these  requirements.  Fourth, for ontologies that inherently have complex internal structure that cannot be represented fully using only simple ontology constructs, we will develop methods that will create templates covering regular structures in the ontology. Scientists will then be able to fill out forms based o these templates, with Protégé generating the corresponding logical structure in the background.  Fifth, we will continue to expand and support the thriving Protégé user community, as it expands to include the biomedical scientists who will now be able to build the ontologies to support their data-driven research and discoveries. PUBLIC HEALTH RELEVANCE: Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care.  Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic- technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: An Ontology-Development Platform for Biomedical Scientists,8987580,R01GM103316,"['Address', 'Adoption', 'Applications Grants', 'Area', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computerized Patient Records', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Electronics', 'Engineering', 'Evolution', 'Feedback', 'Foundations', 'Funding', 'Grant', 'Hand', 'Health', 'Home environment', 'Human', 'Indium', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Letters', 'Libraries', 'Maintenance', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patient Care', 'Pattern', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'Source', 'Structure', 'System', 'Technology', 'Terminology', 'Thinking', 'To specify', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Update', 'Work', 'Writing', 'base', 'biomedical ontology', 'biomedical scientist', 'data integration', 'design', 'improved', 'innovation', 'knowledge base', 'light weight', 'next generation', 'novel', 'online community', 'open source', 'research and development', 'software development', 'software systems', 'success', 'tool', 'tool development', 'user-friendly']",NIGMS,STANFORD UNIVERSITY,R01,2016,526540,0.3279778415089173
"PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge ﻿    DESCRIPTION (provided by applicant): PROJECT SUMMARY Biomedical ontologies are critical to the accurate representation and integration of genome-scale data in biomedical and clinical research. The Protein Ontology (PRO)-the reference ontology for protein entities in the OBO (Open Biological and Biomedical Ontologies) Foundry-represents protein families, multiple protein forms (proteoforms) arising from single genes, and protein complexes. This competitive renewal grant application will further establish PRO as a scalable, flexible, collaborative research infrastructure for protein-centric semantic integration of biomedical data of increasing volume and complexity. Specific aims are to: (i) enable scalable and dynamic representation of protein types; (ii) provide comprehensive coverage of human proteoforms in their biological context; (iii) develop collaborative use cases and support an expanding community of users to advance protein-disease understanding; and (iv) broaden dissemination to support semantic computing, dynamic term mapping, and interoperability and reusability. We will increase PRO coverage by semi-automated import of proteoforms and complexes from curated databases and via established text mining approaches. Expert curation will focus on human variant forms, post-translational modification (PTM) forms and complexes critical to disease processes, along with homologous mouse forms. We will develop a new PRO sub-ontology of protein sites-amino acid positions of significance-to enable automatic and dynamic definition of combinatoric proteoforms. We will establish PRO OWL and RDF versions and provide a SPARQL query endpoint to support semantic computing. We will organize annual workshops and annotation jamborees to develop use cases and promote PRO co-development with community collaborators to address specific disciplinary needs. PRO has several unique features. For knowledge representation, PRO defines precise protein entities to support accurate annotation at the appropriate level of granularity and provides the ontological framework to connect PTM and variant proteoforms and complexes necessary to model human health and disease. For semantic data integration, PRO provides the ontological structure to connect-via specified relations-the vast amounts of proteomics data and biomedical knowledge to support hypothesis generation and testing. PRO therefore addresses the gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully complementing existing knowledge sources. The proposed research will allow the PRO Consortium to deepen and broaden PRO for scalable semantic integration of biomedical data, facilitating protein-disease knowledge discovery and clinical applications by an expanding community of biomedical, clinical and computational users. PUBLIC HEALTH RELEVANCE: PROJECT NARRATIVE The Protein Ontology (PRO) will allow researchers to capture and accurately represent scientific knowledge of proteins thus providing a research infrastructure for modeling biological systems and for protein-centric integration of existing and emerging experimental and clinical data. As a component of the global informatics resource network, the PRO resource will be instrumental in computational analysis and knowledge discovery of genome-scale data and will aid in improving our understanding of human disease, and in the identification of potential diagnostic and therapeutic targets.",PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge,9303592,R01GM080646,"['Address', 'Adopted', 'Amino Acid Sequence', 'Amino Acids', 'Applications Grants', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Research', 'Combinatorics', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Educational workshop', 'Fostering', 'Gene Proteins', 'Generations', 'Genetic Polymorphism', 'Health', 'Histones', 'Human', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Literature', 'Maps', 'Modeling', 'Mus', 'Natural Language Processing', 'Ontology', 'Organism', 'Peptide Sequence Determination', 'Phosphotransferases', 'Play', 'Positioning Attribute', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Informatics', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Services', 'Signal Transduction', 'Site', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Taxon', 'Testing', 'Training', 'Variant', 'base', 'biological systems', 'biomedical ontology', 'clinical application', 'computational reasoning', 'data integration', 'disease classification', 'disease phenotype', 'flexibility', 'genome-wide', 'human disease', 'improved', 'information organization', 'interoperability', 'knowledge base', 'protein complex', 'public health relevance', 'symposium', 'text searching', 'therapeutic target', 'usability', 'web portal', 'web services']",NIGMS,UNIVERSITY OF DELAWARE,R01,2016,20000,0.11876966996859015
"PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge ﻿    DESCRIPTION (provided by applicant): PROJECT SUMMARY Biomedical ontologies are critical to the accurate representation and integration of genome-scale data in biomedical and clinical research. The Protein Ontology (PRO)-the reference ontology for protein entities in the OBO (Open Biological and Biomedical Ontologies) Foundry-represents protein families, multiple protein forms (proteoforms) arising from single genes, and protein complexes. This competitive renewal grant application will further establish PRO as a scalable, flexible, collaborative research infrastructure for protein-centric semantic integration of biomedical data of increasing volume and complexity. Specific aims are to: (i) enable scalable and dynamic representation of protein types; (ii) provide comprehensive coverage of human proteoforms in their biological context; (iii) develop collaborative use cases and support an expanding community of users to advance protein-disease understanding; and (iv) broaden dissemination to support semantic computing, dynamic term mapping, and interoperability and reusability. We will increase PRO coverage by semi-automated import of proteoforms and complexes from curated databases and via established text mining approaches. Expert curation will focus on human variant forms, post-translational modification (PTM) forms and complexes critical to disease processes, along with homologous mouse forms. We will develop a new PRO sub-ontology of protein sites-amino acid positions of significance-to enable automatic and dynamic definition of combinatoric proteoforms. We will establish PRO OWL and RDF versions and provide a SPARQL query endpoint to support semantic computing. We will organize annual workshops and annotation jamborees to develop use cases and promote PRO co-development with community collaborators to address specific disciplinary needs. PRO has several unique features. For knowledge representation, PRO defines precise protein entities to support accurate annotation at the appropriate level of granularity and provides the ontological framework to connect PTM and variant proteoforms and complexes necessary to model human health and disease. For semantic data integration, PRO provides the ontological structure to connect-via specified relations-the vast amounts of proteomics data and biomedical knowledge to support hypothesis generation and testing. PRO therefore addresses the gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully complementing existing knowledge sources. The proposed research will allow the PRO Consortium to deepen and broaden PRO for scalable semantic integration of biomedical data, facilitating protein-disease knowledge discovery and clinical applications by an expanding community of biomedical, clinical and computational users. PUBLIC HEALTH RELEVANCE: PROJECT NARRATIVE The Protein Ontology (PRO) will allow researchers to capture and accurately represent scientific knowledge of proteins thus providing a research infrastructure for modeling biological systems and for protein-centric integration of existing and emerging experimental and clinical data. As a component of the global informatics resource network, the PRO resource will be instrumental in computational analysis and knowledge discovery of genome-scale data and will aid in improving our understanding of human disease, and in the identification of potential diagnostic and therapeutic targets.",PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge,9120920,R01GM080646,"['Address', 'Adopted', 'Amino Acid Sequence', 'Amino Acids', 'Applications Grants', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Research', 'Combinatorics', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Educational workshop', 'Fostering', 'Gene Proteins', 'Generations', 'Genetic Polymorphism', 'Health', 'Histones', 'Human', 'Imagery', 'Knowledge', 'Knowledge Discovery', 'Literature', 'Maps', 'Modeling', 'Mus', 'Natural Language Processing', 'Ontology', 'Organism', 'Peptide Sequence Determination', 'Phosphotransferases', 'Play', 'Positioning Attribute', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Informatics', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Services', 'Signal Transduction', 'Site', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Taxon', 'Testing', 'Training', 'Variant', 'base', 'biological systems', 'biomedical ontology', 'clinical application', 'computational reasoning', 'data integration', 'disease classification', 'disease phenotype', 'flexibility', 'genome-wide', 'human disease', 'improved', 'information organization', 'interoperability', 'knowledge base', 'protein complex', 'public health relevance', 'symposium', 'text searching', 'therapeutic target', 'usability', 'web portal', 'web services']",NIGMS,UNIVERSITY OF DELAWARE,R01,2016,688354,0.11876966996859015
"Turning Data into Whole Cell Ontology Models for Functional Analysis     DESCRIPTION (provided by applicant): A holy grail of bioinformatics is the creation of whole-cell models with the ability to enhance human understanding and facilitate discovery. To this end, a successful and widely-used effort is the Gene Ontology (GO), a massive project to manually annotate genes into terms describing molecular functions, biological processes and cellular components and provide relationships between terms, e.g. capturing that ""small ribosomal subunit"" and ""large ribosomal subunit"" come together to make ""ribosome"". GO is widely used to understand the function of a gene or group of genes. Unfortunately, GO is limited by the effort required to create and update it by hand. It exists only for well-studied organisms and even then in only one, generic form per organism with limited overall genome coverage and a bias towards well-studied genes and functions. It is not possible to learn about an uncharacterized gene or discover a new function using GO, and one cannot quickly assemble an ontology model for a new organism, let alone a specific cell-type or disease-state.  This proposed research will change this state of affairs. Already, work has shown that large networks of gene and protein interactions in Saccharomyces cerevisiae can be used to computationally infer an ontology whose coverage and power are equivalent to those of the manually-curated GO Cellular Component ontology. Still, this first attempt was limited in the types of experimental data used and its ability to infer the more generally useful Biological Process ontology. Here machine learning approaches will be applied to integrate many types of experimental data into ontology model construction and analyze the type of biological information provided by each experiment, revealing those experiments most informative for capturing Biological Process information. Furthermore, the high-throughput experimental data to ontology paradigm explored here will be used to develop a computational tool to highlight novel types of hypotheses that are inaccessible by current high-throughput experimental data analysis methods.  Preliminary work has shown GO to be useful for prediction of synthetic lethal pairs of genes, i.e. genes that are individually non-essential but when knocked out together cause cell death. Given the high mutation rate in cancer, these pairs provide potential cancer drug targets, as a drug may target a gene product which is now essential in the mutated cancer cells but not other cells, thereby killing only cancer cells. Because data-driven ontologies are not as hindered by issues with bias and coverage and are specifically designed to capture only functional relationships, this proposal will explore the idea that data-driven ontologies will be better suited to help predict synthetic lethal pairs than GO. To this end, algorithms will be developed to construct a data-driven ontology of yeast DNA repair and use this ontology to predict synthetic lethal pairs of genes.  Overall, this proposal will develop the computational and experimental roadmap to construct a whole-cell model of gene function - an ontology - and use the model to discover useful biology - synthetic lethal pairs.         PUBLIC HEALTH RELEVANCE: In this proposal, a new framework for using the results of commonly performed, genome-wide experiments has the potential to create whole-cell models of gene function, similar to the widely-used Gene Ontology, directly from data without manual intervention. This will allow creation of useful models of cells from different organisms, tissues and diseases which researchers can use to discover the function of unstudied genes and to uncover new functions performed by the cell. Furthermore, this proposal will use these models for the discovery of new cancer drug targets called synthetic lethal pairs of genes.            ",Turning Data into Whole Cell Ontology Models for Functional Analysis,8951600,F30HG007618,"['Algorithms', 'Antineoplastic Agents', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cell Death', 'Cell model', 'Cell physiology', 'Cells', 'Cluster Analysis', 'Code', 'Collection', 'Coupled', 'DNA Repair', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Disease', 'Drug Targeting', 'Future', 'Gene Cluster', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Goals', 'Hand', 'Human', 'Individual', 'Intervention', 'Knock-out', 'Learning', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Ontology', 'Organism', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Processed Genes', 'Proteins', 'Research', 'Research Personnel', 'Ribosomes', 'Saccharomyces cerevisiae', 'Subgroup', 'System', 'Tissues', 'Update', 'Work', 'Yeasts', 'base', 'biological information processing', 'cancer cell', 'cell type', 'computerized tools', 'design', 'experimental analysis', 'functional group', 'gene function', 'genome-wide', 'improved', 'killings', 'novel', 'public health relevance', 'research study', 'synthetic biology', 'tool']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",F30,2015,39304,0.1738039488987169
"Collaborative Development of Biomedical Ontologies and Terminologies DESCRIPTION (provided by applicant): The construction of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process  natural language, and to build systems for decision support has set many communities  of biomedical investigators to work building large ontologies.  We developed and evaluated the Collaborative Prot¿g¿ system in the first phase of our research project. This software system has become an indispensable open-source resource for an international community of scientists who develop ontologies in a cooperative, distributed manner. In this competing renewal proposal, we describe novel data-driven methods and tools that promise to make collaborative ontology design both more streamlined and more principled. Our goal is to create a more empirical basis for ontology engineering, and to develop methods whereby the ontology-engineering enterprise both can profit from data regarding the underlying processes and those processes in turn can generate increasing amounts of data to inform future ontology-engineering activities.  Our research plan entails three specific aims. First, we will enable ontology developers to apply ontology-design patterns (ODPs) to their ontologies, and we will measure the way in which these patterns alter the ontology-engineering process. Second, we will analyze the vast amounts of log data that we collect from users of Collaborative Prot¿g¿ to understand the patterns of ontology development. We will use these patterns to recommend to developers areas of ontologies that may need their attention, facilitating the process of reaching consensus and making collaborative ontology engineering more efficient. Finally, we will use the extensive data collected by our group and others to understand how scientists reuse terms from various ontologies and we will use these emerging patterns to facilitate term reuse. Each of these analyses not only will increase our understanding of collaboration in scientific modeling, but also will lead to new technology within our Collaborative Prot¿g¿ suite that will improve the ontology-development process and make collaboration among biomedical scientists more efficient. PUBLIC HEALTH RELEVANCE: Collaborative Prot�g� is a software system that helps a burgeoning user community to cooperate in developing ontologies that enhance biomedical research and improve patient care. Collaborative Prot�g� supports scientists, clinician researchers, and workers in informatics to build ontologies to solve problems in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision support. The proposed research will develop data-driven methods to identify patterns in design, development, and use of ontologies, and will apply these methods to help us to build new technology that both facilitates the ontology-development process and makes ontology design more principled.",Collaborative Development of Biomedical Ontologies and Terminologies,8803385,R01GM086587,"['Address', 'Applications Grants', 'Area', 'Attention', 'Biomedical Research', 'Classification', 'Collaborations', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Consensus', 'Craniofacial Abnormalities', 'Data', 'Data Analyses', 'Data Set', 'Decision Support Systems', 'Development', 'Engineering', 'FaceBase', 'Future', 'Generations', 'Genes', 'Goals', 'Health', 'Human', 'Informatics', 'Information Retrieval', 'International', 'International Classification of Diseases', 'Knowledge', 'Lead', 'Learning', 'Maintenance', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'NCI Thesaurus', 'National Cancer Institute', 'Natural Language Processing', 'Ontology', 'Parasites', 'Patient Care', 'Pattern', 'Phase', 'Problem Solving', 'Process', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Scientist', 'Software Design', 'Software Engineering', 'Specialist', 'System', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Traditional Medicine', 'Work', 'base', 'biomedical ontology', 'biomedical resource', 'biomedical scientist', 'craniofacial development', 'data integration', 'design', 'experience', 'improved', 'interoperability', 'new technology', 'novel', 'open source', 'repository', 'software systems', 'tool', 'tool development']",NIGMS,STANFORD UNIVERSITY,R01,2015,523965,0.31020829168729047
"Protege: An Ontology-Development Platform for Biomedical Scientists DESCRIPTION (provided by applicant): The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in  biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous internationa community of scientists-supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 195,000 users as of this writing. To date, however, the use of ontologies in biomedicine has been limited by the complexity of the ontology-development tools, which often make ontologies inaccessible to many biomedical scientists.  In this proposal, we will develop new methods and tools that will significantly lower the barrier of entry for ontology development, expanding Protégé to provide intuitive and user-friendly ontology-acquisition methods throughout the ontology lifecycle.  Our plan entails five specific aims.  First, we will develop methods that enable initial specification of ontology terms in an informal manner, using lists and diagrams.  Scientists will be able to start modeling their domain without having to think in terms of formal ontological distinctions. Second, we will provide intuitive, easy-to-use tools for ontology specification that will aid developers as they start to formalize their models.  Third, we will track the requirements that an ontology must address and develop novel  methods  for  evaluating  ontology  coverage  based  on  these  requirements.  Fourth, for ontologies that inherently have complex internal structure that cannot be represented fully using only simple ontology constructs, we will develop methods that will create templates covering regular structures in the ontology. Scientists will then be able to fill out forms based o these templates, with Protégé generating the corresponding logical structure in the background.  Fifth, we will continue to expand and support the thriving Protégé user community, as it expands to include the biomedical scientists who will now be able to build the ontologies to support their data-driven research and discoveries. PUBLIC HEALTH RELEVANCE: Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care.  Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic- technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: An Ontology-Development Platform for Biomedical Scientists,8788417,R01GM103316,"['Address', 'Adoption', 'Applications Grants', 'Area', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computerized Patient Records', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Electronics', 'Engineering', 'Evolution', 'Feedback', 'Foundations', 'Funding', 'Grant', 'Hand', 'Health', 'Home environment', 'Human', 'Indium', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Letters', 'Libraries', 'Maintenance', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patient Care', 'Pattern', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'Source', 'Structure', 'System', 'Technology', 'Terminology', 'To specify', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Update', 'Work', 'Writing', 'base', 'biomedical ontology', 'biomedical scientist', 'data integration', 'design', 'improved', 'innovation', 'knowledge base', 'next generation', 'novel', 'open source', 'research and development', 'software development', 'software systems', 'success', 'tool', 'tool development', 'user-friendly']",NIGMS,STANFORD UNIVERSITY,R01,2015,526540,0.3279778415089173
"PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge ﻿    DESCRIPTION (provided by applicant): PROJECT SUMMARY Biomedical ontologies are critical to the accurate representation and integration of genome-scale data in biomedical and clinical research. The Protein Ontology (PRO)-the reference ontology for protein entities in the OBO (Open Biological and Biomedical Ontologies) Foundry-represents protein families, multiple protein forms (proteoforms) arising from single genes, and protein complexes. This competitive renewal grant application will further establish PRO as a scalable, flexible, collaborative research infrastructure for protein-centric semantic integration of biomedical data of increasing volume and complexity. Specific aims are to: (i) enable scalable and dynamic representation of protein types; (ii) provide comprehensive coverage of human proteoforms in their biological context; (iii) develop collaborative use cases and support an expanding community of users to advance protein-disease understanding; and (iv) broaden dissemination to support semantic computing, dynamic term mapping, and interoperability and reusability. We will increase PRO coverage by semi-automated import of proteoforms and complexes from curated databases and via established text mining approaches. Expert curation will focus on human variant forms, post-translational modification (PTM) forms and complexes critical to disease processes, along with homologous mouse forms. We will develop a new PRO sub-ontology of protein sites-amino acid positions of significance-to enable automatic and dynamic definition of combinatoric proteoforms. We will establish PRO OWL and RDF versions and provide a SPARQL query endpoint to support semantic computing. We will organize annual workshops and annotation jamborees to develop use cases and promote PRO co-development with community collaborators to address specific disciplinary needs. PRO has several unique features. For knowledge representation, PRO defines precise protein entities to support accurate annotation at the appropriate level of granularity and provides the ontological framework to connect PTM and variant proteoforms and complexes necessary to model human health and disease. For semantic data integration, PRO provides the ontological structure to connect-via specified relations-the vast amounts of proteomics data and biomedical knowledge to support hypothesis generation and testing. PRO therefore addresses the gaps in the bioinformatics infrastructure for protein representations in a way that makes knowledge about proteins more accessible to computational reasoning, fully complementing existing knowledge sources. The proposed research will allow the PRO Consortium to deepen and broaden PRO for scalable semantic integration of biomedical data, facilitating protein-disease knowledge discovery and clinical applications by an expanding community of biomedical, clinical and computational users.         PUBLIC HEALTH RELEVANCE: PROJECT NARRATIVE The Protein Ontology (PRO) will allow researchers to capture and accurately represent scientific knowledge of proteins thus providing a research infrastructure for modeling biological systems and for protein-centric integration of existing and emerging experimental and clinical data. As a component of the global informatics resource network, the PRO resource will be instrumental in computational analysis and knowledge discovery of genome-scale data and will aid in improving our understanding of human disease, and in the identification of potential diagnostic and therapeutic targets.            ",PRO: A Protein Ontology in OBO Foundry for Scalable Integration of Biomedical Knowledge,8964875,R01GM080646,"['Address', 'Adopted', 'Amino Acid Sequence', 'Amino Acids', 'Applications Grants', 'Automobile Driving', 'Bioinformatics', 'Biological', 'Biomedical Research', 'Clinical', 'Clinical Data', 'Clinical Research', 'Combinatorics', 'Communities', 'Complement', 'Complex', 'Computer Analysis', 'Data', 'Databases', 'Development', 'Diagnostic', 'Disease', 'Educational workshop', 'Fostering', 'Gene Proteins', 'Generations', 'Genetic Polymorphism', 'Health', 'Histones', 'Human', 'Imagery', 'Internet', 'Knowledge', 'Knowledge Discovery', 'Literature', 'Maps', 'Modeling', 'Mus', 'Natural Language Processing', 'Ontology', 'Organism', 'Peptide Sequence Determination', 'Phosphotransferases', 'Play', 'Positioning Attribute', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Process', 'Protein Family', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resource Informatics', 'Resources', 'Role', 'Semantics', 'Sequence Alignment', 'Services', 'Signal Transduction', 'Site', 'Source', 'Specific qualifier value', 'Structure', 'System', 'Taxon', 'Testing', 'Training', 'Variant', 'base', 'biological systems', 'biomedical ontology', 'clinical application', 'data integration', 'disease classification', 'disease phenotype', 'flexibility', 'genome-wide', 'human disease', 'improved', 'information organization', 'interoperability', 'knowledge base', 'protein complex', 'public health relevance', 'symposium', 'text searching', 'therapeutic target', 'usability', 'web services']",NIGMS,UNIVERSITY OF DELAWARE,R01,2015,745136,0.11876966996859015
"Turning Data into Whole Cell Ontology Models for Functional Analysis     DESCRIPTION (provided by applicant): A holy grail of bioinformatics is the creation of whole-cell models with the ability to enhance human understanding and facilitate discovery. To this end, a successful and widely-used effort is the Gene Ontology (GO), a massive project to manually annotate genes into terms describing molecular functions, biological processes and cellular components and provide relationships between terms, e.g. capturing that ""small ribosomal subunit"" and ""large ribosomal subunit"" come together to make ""ribosome"". GO is widely used to understand the function of a gene or group of genes. Unfortunately, GO is limited by the effort required to create and update it by hand. It exists only for well-studied organisms and even then in only one, generic form per organism with limited overall genome coverage and a bias towards well-studied genes and functions. It is not possible to learn about an uncharacterized gene or discover a new function using GO, and one cannot quickly assemble an ontology model for a new organism, let alone a specific cell-type or disease-state.  This proposed research will change this state of affairs. Already, work has shown that large networks of gene and protein interactions in Saccharomyces cerevisiae can be used to computationally infer an ontology whose coverage and power are equivalent to those of the manually-curated GO Cellular Component ontology. Still, this first attempt was limited in the types of experimental data used and its ability to infer the more generally useful Biological Process ontology. Here machine learning approaches will be applied to integrate many types of experimental data into ontology model construction and analyze the type of biological information provided by each experiment, revealing those experiments most informative for capturing Biological Process information. Furthermore, the high-throughput experimental data to ontology paradigm explored here will be used to develop a computational tool to highlight novel types of hypotheses that are inaccessible by current high-throughput experimental data analysis methods.  Preliminary work has shown GO to be useful for prediction of synthetic lethal pairs of genes, i.e. genes that are individually non-essential but when knocked out together cause cell death. Given the high mutation rate in cancer, these pairs provide potential cancer drug targets, as a drug may target a gene product which is now essential in the mutated cancer cells but not other cells, thereby killing only cancer cells. Because data-driven ontologies are not as hindered by issues with bias and coverage and are specifically designed to capture only functional relationships, this proposal will explore the idea that data-driven ontologies will be better suited to help predict synthetic lethal pairs than GO. To this end, algorithms will be developed to construct a data-driven ontology of yeast DNA repair and use this ontology to predict synthetic lethal pairs of genes.  Overall, this proposal will develop the computational and experimental roadmap to construct a whole-cell model of gene function - an ontology - and use the model to discover useful biology - synthetic lethal pairs.         PUBLIC HEALTH RELEVANCE: In this proposal, a new framework for using the results of commonly performed, genome-wide experiments has the potential to create whole-cell models of gene function, similar to the widely-used Gene Ontology, directly from data without manual intervention. This will allow creation of useful models of cells from different organisms, tissues and diseases which researchers can use to discover the function of unstudied genes and to uncover new functions performed by the cell. Furthermore, this proposal will use these models for the discovery of new cancer drug targets called synthetic lethal pairs of genes.            ",Turning Data into Whole Cell Ontology Models for Functional Analysis,8644512,F30HG007618,"['Algorithms', 'Antineoplastic Agents', 'Bioinformatics', 'Biological', 'Biological Process', 'Biology', 'Cell Death', 'Cell model', 'Cell physiology', 'Cells', 'Cluster Analysis', 'Code', 'Collection', 'Coupled', 'DNA Repair', 'Data', 'Data Analyses', 'Data Quality', 'Data Set', 'Disease', 'Drug Targeting', 'Future', 'Gene Cluster', 'Gene Proteins', 'Generic Drugs', 'Genes', 'Genome', 'Goals', 'Hand', 'Human', 'Individual', 'Intervention', 'Knock-out', 'Learning', 'Lighting', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Methods', 'Modeling', 'Molecular', 'Mutate', 'Mutation', 'Ontology', 'Organism', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Processed Genes', 'Proteins', 'Research', 'Research Personnel', 'Ribosomes', 'Saccharomyces cerevisiae', 'Subgroup', 'System', 'Tissues', 'Update', 'Work', 'Yeasts', 'base', 'biological information processing', 'cancer cell', 'cell type', 'computerized tools', 'design', 'experimental analysis', 'functional group', 'gene function', 'genome-wide', 'improved', 'killings', 'novel', 'public health relevance', 'research study', 'synthetic biology', 'tool']",NHGRI,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",F30,2014,35110,0.1738039488987169
"Collaborative Development of Biomedical Ontologies and Terminologies     DESCRIPTION (provided by applicant): The construction of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process  natural language, and to build systems for decision support has set many communities  of biomedical investigators to work building large ontologies.  We developed and evaluated the Collaborative Prot¿g¿ system in the first phase of our research project. This software system has become an indispensable open-source resource for an international community of scientists who develop ontologies in a cooperative, distributed manner. In this competing renewal proposal, we describe novel data-driven methods and tools that promise to make collaborative ontology design both more streamlined and more principled. Our goal is to create a more empirical basis for ontology engineering, and to develop methods whereby the ontology-engineering enterprise both can profit from data regarding the underlying processes and those processes in turn can generate increasing amounts of data to inform future ontology-engineering activities.  Our research plan entails three specific aims. First, we will enable ontology developers to apply ontology-design patterns (ODPs) to their ontologies, and we will measure the way in which these patterns alter the ontology-engineering process. Second, we will analyze the vast amounts of log data that we collect from users of Collaborative Prot¿g¿ to understand the patterns of ontology development. We will use these patterns to recommend to developers areas of ontologies that may need their attention, facilitating the process of reaching consensus and making collaborative ontology engineering more efficient. Finally, we will use the extensive data collected by our group and others to understand how scientists reuse terms from various ontologies and we will use these emerging patterns to facilitate term reuse. Each of these analyses not only will increase our understanding of collaboration in scientific modeling, but also will lead to new technology within our Collaborative Prot¿g¿ suite that will improve the ontology-development process and make collaboration among biomedical scientists more efficient.         PUBLIC HEALTH RELEVANCE: Collaborative Prot�g� is a software system that helps a burgeoning user community to cooperate in developing ontologies that enhance biomedical research and improve patient care. Collaborative Prot�g� supports scientists, clinician researchers, and workers in informatics to build ontologies to solve problems in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision support. The proposed research will develop data-driven methods to identify patterns in design, development, and use of ontologies, and will apply these methods to help us to build new technology that both facilitates the ontology-development process and makes ontology design more principled.            ",Collaborative Development of Biomedical Ontologies and Terminologies,8628132,R01GM086587,"['Address', 'Applications Grants', 'Area', 'Attention', 'Biomedical Research', 'Classification', 'Collaborations', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Decision Support Systems', 'Development', 'Engineering', 'FaceBase', 'Future', 'Generations', 'Genes', 'Goals', 'Human', 'Informatics', 'Information Retrieval', 'International', 'International Classification of Diseases', 'Knowledge', 'Lead', 'Learning', 'Maintenance', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'NCI Thesaurus', 'National Cancer Institute', 'Natural Language Processing', 'Ontology', 'Parasites', 'Patient Care', 'Pattern', 'Phase', 'Problem Solving', 'Process', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Scientist', 'Software Design', 'Software Engineering', 'Specialist', 'System', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Traditional Medicine', 'Work', 'base', 'biomedical ontology', 'biomedical resource', 'biomedical scientist', 'craniofacial', 'data integration', 'design', 'experience', 'improved', 'interoperability', 'malformation', 'new technology', 'novel', 'open source', 'public health relevance', 'repository', 'software systems', 'tool', 'tool development']",NIGMS,STANFORD UNIVERSITY,R01,2014,525880,0.31020829168729047
"Protege: An Ontology-Development Platform for Biomedical Scientists     DESCRIPTION (provided by applicant): The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in  biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Prot¿g¿ system has become an indispensable open-source resource for an enormous internationa community of scientists-supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Prot¿g¿ users has grown from 3,500 in 2002 to more than 195,000 users as of this writing. To date, however, the use of ontologies in biomedicine has been limited by the complexity of the ontology-development tools, which often make ontologies inaccessible to many biomedical scientists.  In this proposal, we will develop new methods and tools that will significantly lower the barrier of entry for ontology development, expanding Prot¿g¿ to provide intuitive and user-friendly ontology-acquisition methods throughout the ontology lifecycle.  Our plan entails five specific aims.  First, we will develop methods that enable initial specification of ontology terms in an informal manner, using lists and diagrams.  Scientists will be able to start modeling their domain without having to think in terms of formal ontological distinctions. Second, we will provide intuitive, easy-to-use tools for ontology specification that will aid developers as they start to formalize their models.  Third, we will track the requirements that an ontology must address and develop novel  methods  for  evaluating  ontology  coverage  based  on  these  requirements.  Fourth, for ontologies that inherently have complex internal structure that cannot be represented fully using only simple ontology constructs, we will develop methods that will create templates covering regular structures in the ontology. Scientists will then be able to fill out forms based o these templates, with Prot¿g¿ generating the corresponding logical structure in the background.  Fifth, we will continue to expand and support the thriving Prot¿g¿ user community, as it expands to include the biomedical scientists who will now be able to build the ontologies to support their data-driven research and discoveries.          PUBLIC HEALTH RELEVANCE: Prot�g� is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care.  Prot�g� supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Prot�g� resource provides critical semantic- technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.            ",Protege: An Ontology-Development Platform for Biomedical Scientists,8597446,R01GM103316,"['Address', 'Adoption', 'Applications Grants', 'Area', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computerized Patient Records', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Electronics', 'Engineering', 'Evolution', 'Feedback', 'Foundations', 'Funding', 'Grant', 'Hand', 'Home environment', 'Human', 'Indium', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Letters', 'Libraries', 'Mails', 'Maintenance', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patient Care', 'Pattern', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'Source', 'Structure', 'Support System', 'System', 'Technology', 'Terminology', 'To specify', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Update', 'Work', 'Writing', 'base', 'biomedical ontology', 'biomedical scientist', 'data integration', 'design', 'improved', 'innovation', 'knowledge base', 'next generation', 'novel', 'open source', 'public health relevance', 'research and development', 'software development', 'software systems', 'success', 'tool', 'tool development', 'user-friendly']",NIGMS,STANFORD UNIVERSITY,R01,2014,533554,0.3279778415089173
"National Center for Biomedical Ontology    DESCRIPTION (PROVIDED BY APPLICANT): We propose to continue the National Center for Biomedical Ontology (NCBO), which develops tools and methods for assimilating, archiving, accessing, and applying machine-processable representations of biomedical domain objects, processes, and relations to assist in the management, integration, visualization, analysis, and interpretation of the huge, distributed data sets that are now the hallmark of biomedical research and clinical care. Our center is truly national in scope, with participation of leading scientific groups at Stanford, Mayo Clinic, University at Buffalo, and the University of Victoria. Our objectives are defined by the following six Cores: (1) the development of enhanced computational methods for management of ontologies and controlled terminologies using current Web standards; integration of ontology authoring, publishing, and peer review; creation of a comprehensive ontology-based index of publicly available data resources; development of new analytic methods to summarize and profile biomedical data; (2) the promotion of Driving Biological Projects that can stimulate our research by suggesting new requirements and offering new test beds for deployment-initially involving the Cardiovascular Research Grid, the Rat Genome Database, the caNanoLab nanoparticle database, and the i2b2 National Center for Biomedical Computing, and later engaging the WHO's development of lCD-11, studies performed by ArrayExpress, and projects that will be selected via open requests for applications; (3) the maintenance of a computational infrastructure to support our research, development, and dissemination activities; provision of user support to the growing number of researchers and clinicians who use our   technologies; (4) the training of the next generation of scientists in biomedical ontology; (5) a comprehensive set of dissemination activities, that include workshops, tutorials. Web-based seminars, and a major international conference; and (6) outstanding project administration conducted by a dedicated and talented management team. The NCBO will accelerate the transition of biomedicine into the world of e-science, facilitate the creation of a National Health Information Infrastructure, and extend a network of collaboration through its interactions with other NCBCs, with other research consortia, and with the biomedical community at large.    RELEVANCE (See instructions):  The NCBO supports a burgeoning user community that is using ontologies to enhance biomedical research and to improve patient care. It supports bench scientists, clinician researchers, and workers in informatics in data annnotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. It is a primary source of semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information svstems.",National Center for Biomedical Ontology,8737919,U54HG004028,"['Adoption', 'Archives', 'Automobile Driving', 'Beds', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Buffaloes', 'Cardiovascular system', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Computerized Patient Records', 'Computers', 'Computing Methodologies', 'DNA Microarray Chip', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Discipline', 'Educational workshop', 'Electronics', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Feedback', 'Generations', 'Genes', 'Goals', 'Government', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Imagery', 'Informatics', 'Information Retrieval', 'Information Technology', 'Instruction', 'Interest Group', 'International', 'International Classification of Diseases', 'Internet', 'Knowledge', 'Language', 'Life', 'Link', 'Maintenance', 'Medicine', 'Methods', 'NIH Program Announcements', 'National Cancer Institute', 'Natural Language Processing', 'Neurosciences', 'North America', 'Online Systems', 'Ontology', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Process', 'Property', 'Publishing', 'Publishing Peer Reviews', 'Recommendation', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Services', 'Shapes', 'Societies', 'Solutions', 'Source', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Vocabulary', 'Work', 'base', 'biomedical ontology', 'clinical care', 'comparative effectiveness', 'computer based Semantic Analysis', 'computer infrastructure', 'data integration', 'design', 'distributed data', 'e-science', 'genome database', 'health information technology', 'improved', 'indexing', 'interest', 'interoperability', 'knowledge base', 'nanoparticle', 'new technology', 'next generation', 'novel', 'novel strategies', 'open source', 'rat genome', 'research and development', 'research study', 'response', 'symposium', 'text searching', 'tool']",NHGRI,STANFORD UNIVERSITY,U54,2014,2941548,0.19048071237689607
"Collaborative Development of Biomedical Ontologies and Terminologies     DESCRIPTION (provided by applicant): The construction of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process  natural language, and to build systems for decision support has set many communities  of biomedical investigators to work building large ontologies.  We developed and evaluated the Collaborative Prot¿g¿ system in the first phase of our research project. This software system has become an indispensable open-source resource for an international community of scientists who develop ontologies in a cooperative, distributed manner. In this competing renewal proposal, we describe novel data-driven methods and tools that promise to make collaborative ontology design both more streamlined and more principled. Our goal is to create a more empirical basis for ontology engineering, and to develop methods whereby the ontology-engineering enterprise both can profit from data regarding the underlying processes and those processes in turn can generate increasing amounts of data to inform future ontology-engineering activities.  Our research plan entails three specific aims. First, we will enable ontology developers to apply ontology-design patterns (ODPs) to their ontologies, and we will measure the way in which these patterns alter the ontology-engineering process. Second, we will analyze the vast amounts of log data that we collect from users of Collaborative Prot¿g¿ to understand the patterns of ontology development. We will use these patterns to recommend to developers areas of ontologies that may need their attention, facilitating the process of reaching consensus and making collaborative ontology engineering more efficient. Finally, we will use the extensive data collected by our group and others to understand how scientists reuse terms from various ontologies and we will use these emerging patterns to facilitate term reuse. Each of these analyses not only will increase our understanding of collaboration in scientific modeling, but also will lead to new technology within our Collaborative Prot¿g¿ suite that will improve the ontology-development process and make collaboration among biomedical scientists more efficient.         PUBLIC HEALTH RELEVANCE: Collaborative Prot�g� is a software system that helps a burgeoning user community to cooperate in developing ontologies that enhance biomedical research and improve patient care. Collaborative Prot�g� supports scientists, clinician researchers, and workers in informatics to build ontologies to solve problems in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision support. The proposed research will develop data-driven methods to identify patterns in design, development, and use of ontologies, and will apply these methods to help us to build new technology that both facilitates the ontology-development process and makes ontology design more principled.            ",Collaborative Development of Biomedical Ontologies and Terminologies,8504843,R01GM086587,"['Address', 'Applications Grants', 'Area', 'Attention', 'Biomedical Research', 'Classification', 'Collaborations', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Decision Support Systems', 'Development', 'Engineering', 'Future', 'Generations', 'Genes', 'Goals', 'Human', 'Informatics', 'Information Retrieval', 'International', 'International Classification of Diseases', 'Knowledge', 'Lead', 'Learning', 'Maintenance', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morphologic artifacts', 'NCI Thesaurus', 'National Cancer Institute', 'Natural Language Processing', 'Ontology', 'Parasites', 'Patient Care', 'Pattern', 'Phase', 'Problem Solving', 'Process', 'Recording of previous events', 'Research', 'Research Personnel', 'Research Project Grants', 'Resources', 'Scientist', 'Software Design', 'Software Engineering', 'Specialist', 'System', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Traditional Medicine', 'Work', 'base', 'biomedical ontology', 'biomedical resource', 'biomedical scientist', 'craniofacial', 'data integration', 'design', 'experience', 'improved', 'interoperability', 'malformation', 'new technology', 'novel', 'open source', 'public health relevance', 'repository', 'software systems', 'tool', 'tool development']",NIGMS,STANFORD UNIVERSITY,R01,2013,527736,0.31020829168729047
"Protege: An Ontology-Development Platform for Biomedical Scientists     DESCRIPTION (provided by applicant): The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in  biomedicine.  Ontologies help both humans and computers to manage burgeoning numbers of data.  The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Prot¿g¿ system has become an indispensable open-source resource for an enormous internationa community of scientists-supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Prot¿g¿ users has grown from 3,500 in 2002 to more than 195,000 users as of this writing. To date, however, the use of ontologies in biomedicine has been limited by the complexity of the ontology-development tools, which often make ontologies inaccessible to many biomedical scientists.  In this proposal, we will develop new methods and tools that will significantly lower the barrier of entry for ontology development, expanding Prot¿g¿ to provide intuitive and user-friendly ontology-acquisition methods throughout the ontology lifecycle.  Our plan entails five specific aims.  First, we will develop methods that enable initial specification of ontology terms in an informal manner, using lists and diagrams.  Scientists will be able to start modeling their domain without having to think in terms of formal ontological distinctions. Second, we will provide intuitive, easy-to-use tools for ontology specification that will aid developers as they start to formalize their models.  Third, we will track the requirements that an ontology must address and develop novel  methods  for  evaluating  ontology  coverage  based  on  these  requirements.  Fourth, for ontologies that inherently have complex internal structure that cannot be represented fully using only simple ontology constructs, we will develop methods that will create templates covering regular structures in the ontology. Scientists will then be able to fill out forms based o these templates, with Prot¿g¿ generating the corresponding logical structure in the background.  Fifth, we will continue to expand and support the thriving Prot¿g¿ user community, as it expands to include the biomedical scientists who will now be able to build the ontologies to support their data-driven research and discoveries.          PUBLIC HEALTH RELEVANCE: Prot�g� is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care.  Prot�g� supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Prot�g� resource provides critical semantic- technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.            ",Protege: An Ontology-Development Platform for Biomedical Scientists,8438361,R01GM103316,"['Address', 'Adoption', 'Applications Grants', 'Area', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Clinical', 'Communities', 'Complex', 'Computer software', 'Computerized Patient Records', 'Computers', 'Custom', 'Data', 'Data Set', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Electronics', 'Engineering', 'Evolution', 'Feedback', 'Foundations', 'Funding', 'Grant', 'Hand', 'Home environment', 'Human', 'Indium', 'Informatics', 'Information Retrieval', 'Information Systems', 'International', 'Knowledge', 'Knowledge Discovery', 'Laboratories', 'Letters', 'Libraries', 'Mails', 'Maintenance', 'Medicine', 'Methods', 'Modeling', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Patient Care', 'Pattern', 'Publications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Scientist', 'Semantics', 'Source', 'Structure', 'Support System', 'System', 'Technology', 'Terminology', 'To specify', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Update', 'Work', 'Writing', 'base', 'biomedical ontology', 'biomedical scientist', 'data integration', 'design', 'improved', 'innovation', 'knowledge base', 'next generation', 'novel', 'open source', 'public health relevance', 'research and development', 'software development', 'software systems', 'success', 'tool', 'tool development', 'user-friendly']",NIGMS,STANFORD UNIVERSITY,R01,2013,533554,0.3279778415089173
"National Center for Biomedical Ontology    DESCRIPTION (PROVIDED BY APPLICANT): We propose to continue the National Center for Biomedical Ontology (NCBO), which develops tools and methods for assimilating, archiving, accessing, and applying machine-processable representations of biomedical domain objects, processes, and relations to assist in the management, integration, visualization, analysis, and interpretation of the huge, distributed data sets that are now the hallmark of biomedical research and clinical care. Our center is truly national in scope, with participation of leading scientific groups at Stanford, Mayo Clinic, University at Buffalo, and the University of Victoria. Our objectives are defined by the following six Cores: (1) the development of enhanced computational methods for management of ontologies and controlled terminologies using current Web standards; integration of ontology authoring, publishing, and peer review; creation of a comprehensive ontology-based index of publicly available data resources; development of new analytic methods to summarize and profile biomedical data; (2) the promotion of Driving Biological Projects that can stimulate our research by suggesting new requirements and offering new test beds for deployment-initially involving the Cardiovascular Research Grid, the Rat Genome Database, the caNanoLab nanoparticle database, and the i2b2 National Center for Biomedical Computing, and later engaging the WHO's development of lCD-11, studies performed by ArrayExpress, and projects that will be selected via open requests for applications; (3) the maintenance of a computational infrastructure to support our research, development, and dissemination activities; provision of user support to the growing number of researchers and clinicians who use our   technologies; (4) the training of the next generation of scientists in biomedical ontology; (5) a comprehensive set of dissemination activities, that include workshops, tutorials. Web-based seminars, and a major international conference; and (6) outstanding project administration conducted by a dedicated and talented management team. The NCBO will accelerate the transition of biomedicine into the world of e-science, facilitate the creation of a National Health Information Infrastructure, and extend a network of collaboration through its interactions with other NCBCs, with other research consortia, and with the biomedical community at large.    RELEVANCE (See instructions):  The NCBO supports a burgeoning user community that is using ontologies to enhance biomedical research and to improve patient care. It supports bench scientists, clinician researchers, and workers in informatics in data annnotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. It is a primary source of semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information svstems.",National Center for Biomedical Ontology,8541872,U54HG004028,"['Adoption', 'Archives', 'Automobile Driving', 'Beds', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Buffaloes', 'Cardiovascular system', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Computerized Patient Records', 'Computers', 'Computing Methodologies', 'DNA Microarray Chip', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Discipline', 'Educational workshop', 'Electronics', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Feedback', 'Generations', 'Genes', 'Goals', 'Government', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Imagery', 'Informatics', 'Information Retrieval', 'Information Technology', 'Instruction', 'Interest Group', 'International', 'International Classification of Diseases', 'Internet', 'Knowledge', 'Language', 'Life', 'Link', 'Maintenance', 'Medicine', 'Methods', 'NIH Program Announcements', 'National Cancer Institute', 'Natural Language Processing', 'Neurosciences', 'North America', 'Online Systems', 'Ontology', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Process', 'Property', 'Publishing', 'Publishing Peer Reviews', 'Recommendation', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Services', 'Shapes', 'Societies', 'Solutions', 'Source', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Vocabulary', 'Work', 'base', 'biomedical ontology', 'clinical care', 'comparative effectiveness', 'computer based Semantic Analysis', 'computer infrastructure', 'data integration', 'design', 'distributed data', 'e-science', 'genome database', 'health information technology', 'improved', 'indexing', 'interest', 'interoperability', 'knowledge base', 'nanoparticle', 'new technology', 'next generation', 'novel', 'novel strategies', 'open source', 'rat genome', 'research and development', 'research study', 'response', 'symposium', 'text searching', 'tool']",NHGRI,STANFORD UNIVERSITY,U54,2013,872488,0.19048071237689607
"Ontology-based Information Network to Support Vaccine Research  Project Summary (Abstract):  Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.  Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,8311060,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Semantics', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'abstracting', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2012,264994,0.10241996655652154
"Collaborative Development of Biomedical Ontologies and Terminologies    DESCRIPTION (provided by applicant): The development of ontologies that define entities and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage the burgeoning data that are pervasive in biology and medicine. The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. To date, these groups of ontology developers have been limited by the lack of methods and tools that facilitate distributed, collaborative engineering of large-scale ontologies and vocabularies. In this proposal, we outline three specific aims. First, we will explore basic computational methods that are essential for collaborative ontology engineering. We will investigate methods for representing diverse collaborative workflows, information about changes and concept history, trust, and provenance, and for recording decision making and design rationale. Empirical analysis of existing ontology-development projects will inform our construction of models for collaborative development workflows that will guide the processes of authoring, reviewing, and curating biomedical ontologies. Second, we will use the results from our first specific aim to build cProtigi, a set of robust, customizable, interactive tools to support distributed users in their collaborative work to build and edit terminologies and ontologies. Third, we will evaluate our work in the context of real-world, large-scale ontology-engineering projects, including the autism ontology of the National Database for Autism Research; the 11th revision of the WHO's International Classification of Diseases; the Ontology for Biomedical Investigations, under development by a wide range of NIH-supported researchers; and BiomedGT, under development by NCI. It is no longer feasible to imagine that investigators can create biomedical ontologies working independently. The collaborative methods that we will study and the tools that we will build will lead to expanded opportunities to support the diverse data- and knowledge-intensive activities that pervade BISTI, the CTSAs, the NCBCs, and myriad biomedical initiatives that require robust, scaleable ontologies. PUBLIC HEALTH RELEVANCE: The knowledge-based nature of modern medicine requires the use of ontologies and terminologies to process and integrate data. Ontology development itself becomes a collaborative process, with members of the larger research community contributing to and commenting on emerging ontologies. We plan to extend the Protigi ontology editor-the most widely used ontology editor today, with almost 100,000 registered users-to support collaborative development of ontologies and to evaluate the new tools by deploying them at the World Health Organization for the development of ICD-11 and in other settings.             n/a",Collaborative Development of Biomedical Ontologies and Terminologies,8242742,R01GM086587,"['Adopted', 'Autistic Disorder', 'Beds', 'Bioinformatics', 'Biology', 'Collaborations', 'Communities', 'Computers', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Engineering', 'Evaluation', 'Generic Drugs', 'Goals', 'Health', 'Human', 'Industry', 'Institutes', 'International Classification of Diseases', 'Internet', 'Investigation', 'Knowledge', 'Lead', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Modern Medicine', 'NCI Thesaurus', 'NIH Program Announcements', 'Natural Language Processing', 'Nature', 'Online Systems', 'Ontology', 'Process', 'Program Development', 'Published Comment', 'Recording of previous events', 'Research', 'Research Personnel', 'Scientist', 'Source', 'Staging', 'Systems Development', 'Terminology', 'Testing', 'Trust', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'World Health Organization', 'biomedical ontology', 'biomedical scientist', 'cancer Biomedical Informatics Grid', 'conflict resolution', 'design', 'experience', 'flexibility', 'forging', 'knowledge base', 'member', 'open source', 'programs', 'research study', 'response', 'tool', 'usability']",NIGMS,STANFORD UNIVERSITY,R01,2012,392767,0.3107895866742969
"National Center for Biomedical Ontology    DESCRIPTION (PROVIDED BY APPLICANT): We propose to continue the National Center for Biomedical Ontology (NCBO), which develops tools and methods for assimilating, archiving, accessing, and applying machine-processable representations of biomedical domain objects, processes, and relations to assist in the management, integration, visualization, analysis, and interpretation of the huge, distributed data sets that are now the hallmark of biomedical research and clinical care. Our center is truly national in scope, with participation of leading scientific groups at Stanford, Mayo Clinic, University at Buffalo, and the University of Victoria. Our objectives are defined by the following six Cores: (1) the development of enhanced computational methods for management of ontologies and controlled terminologies using current Web standards; integration of ontology authoring, publishing, and peer review; creation of a comprehensive ontology-based index of publicly available data resources; development of new analytic methods to summarize and profile biomedical data; (2) the promotion of Driving Biological Projects that can stimulate our research by suggesting new requirements and offering new test beds for deployment-initially involving the Cardiovascular Research Grid, the Rat Genome Database, the caNanoLab nanoparticle database, and the i2b2 National Center for Biomedical Computing, and later engaging the WHO's development of lCD-11, studies performed by ArrayExpress, and projects that will be selected via open requests for applications; (3) the maintenance of a computational infrastructure to support our research, development, and dissemination activities; provision of user support to the growing number of researchers and clinicians who use our   technologies; (4) the training of the next generation of scientists in biomedical ontology; (5) a comprehensive set of dissemination activities, that include workshops, tutorials. Web-based seminars, and a major international conference; and (6) outstanding project administration conducted by a dedicated and talented management team. The NCBO will accelerate the transition of biomedicine into the world of e-science, facilitate the creation of a National Health Information Infrastructure, and extend a network of collaboration through its interactions with other NCBCs, with other research consortia, and with the biomedical community at large.    RELEVANCE (See instructions):  The NCBO supports a burgeoning user community that is using ontologies to enhance biomedical research and to improve patient care. It supports bench scientists, clinician researchers, and workers in informatics in data annnotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. It is a primary source of semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information svstems.",National Center for Biomedical Ontology,8330927,U54HG004028,"['Adoption', 'Archives', 'Automobile Driving', 'Beds', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Buffaloes', 'Cardiovascular system', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Computerized Patient Records', 'Computers', 'Computing Methodologies', 'DNA Microarray Chip', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Discipline', 'Educational workshop', 'Electronics', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Feedback', 'Generations', 'Genes', 'Goals', 'Government', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Imagery', 'Informatics', 'Information Retrieval', 'Information Technology', 'Instruction', 'Interest Group', 'International', 'International Classification of Diseases', 'Internet', 'Knowledge', 'Language', 'Life', 'Link', 'Maintenance', 'Medicine', 'Methods', 'NIH Program Announcements', 'National Cancer Institute', 'Natural Language Processing', 'Neurosciences', 'North America', 'Online Systems', 'Ontology', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Process', 'Property', 'Publishing', 'Publishing Peer Reviews', 'Recommendation', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Services', 'Shapes', 'Societies', 'Solutions', 'Source', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Vocabulary', 'Work', 'base', 'biomedical ontology', 'clinical care', 'comparative effectiveness', 'computer based Semantic Analysis', 'computer infrastructure', 'data integration', 'design', 'distributed data', 'e-science', 'genome database', 'health information technology', 'improved', 'indexing', 'interest', 'interoperability', 'knowledge base', 'nanoparticle', 'new technology', 'next generation', 'novel', 'novel strategies', 'open source', 'rat genome', 'research and development', 'research study', 'response', 'symposium', 'text searching', 'tool']",NHGRI,STANFORD UNIVERSITY,U54,2012,1821611,0.19048071237689607
"National Center for Biomedical Ontology    DESCRIPTION (PROVIDED BY APPLICANT): We propose to continue the National Center for Biomedical Ontology (NCBO), which develops tools and methods for assimilating, archiving, accessing, and applying machine-processable representations of biomedical domain objects, processes, and relations to assist in the management, integration, visualization, analysis, and interpretation of the huge, distributed data sets that are now the hallmark of biomedical research and clinical care. Our center is truly national in scope, with participation of leading scientific groups at Stanford, Mayo Clinic, University at Buffalo, and the University of Victoria. Our objectives are defined by the following six Cores: (1) the development of enhanced computational methods for management of ontologies and controlled terminologies using current Web standards; integration of ontology authoring, publishing, and peer review; creation of a comprehensive ontology-based index of publicly available data resources; development of new analytic methods to summarize and profile biomedical data; (2) the promotion of Driving Biological Projects that can stimulate our research by suggesting new requirements and offering new test beds for deployment-initially involving the Cardiovascular Research Grid, the Rat Genome Database, the caNanoLab nanoparticle database, and the i2b2 National Center for Biomedical Computing, and later engaging the WHO's development of lCD-11, studies performed by ArrayExpress, and projects that will be selected via open requests for applications; (3) the maintenance of a computational infrastructure to support our research, development, and dissemination activities; provision of user support to the growing number of researchers and clinicians who use our   technologies; (4) the training of the next generation of scientists in biomedical ontology; (5) a comprehensive set of dissemination activities, that include workshops, tutorials. Web-based seminars, and a major international conference; and (6) outstanding project administration conducted by a dedicated and talented management team. The NCBO will accelerate the transition of biomedicine into the world of e-science, facilitate the creation of a National Health Information Infrastructure, and extend a network of collaboration through its interactions with other NCBCs, with other research consortia, and with the biomedical community at large.    RELEVANCE (See instructions):  The NCBO supports a burgeoning user community that is using ontologies to enhance biomedical research and to improve patient care. It supports bench scientists, clinician researchers, and workers in informatics in data annnotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. It is a primary source of semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information svstems.",National Center for Biomedical Ontology,8541935,U54HG004028,"['Adoption', 'Archives', 'Automobile Driving', 'Beds', 'Biological', 'Biological Sciences', 'Biology', 'Biomedical Computing', 'Biomedical Research', 'Buffaloes', 'Cardiovascular system', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Computerized Patient Records', 'Computers', 'Computing Methodologies', 'DNA Microarray Chip', 'DNA Sequence', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Discipline', 'Educational workshop', 'Electronics', 'Evaluation', 'Event', 'Evidence Based Medicine', 'Evolution', 'Feedback', 'Generations', 'Genes', 'Goals', 'Government', 'Growth', 'Health', 'Healthcare', 'Home environment', 'Imagery', 'Informatics', 'Information Retrieval', 'Information Technology', 'Instruction', 'Interest Group', 'International', 'International Classification of Diseases', 'Internet', 'Knowledge', 'Language', 'Life', 'Link', 'Maintenance', 'Medicine', 'Methods', 'NIH Program Announcements', 'National Cancer Institute', 'Natural Language Processing', 'Neurosciences', 'North America', 'Online Systems', 'Ontology', 'Participant', 'Patient Care', 'Patients', 'Peer Review', 'Process', 'Property', 'Publishing', 'Publishing Peer Reviews', 'Recommendation', 'Request for Applications', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Services', 'Shapes', 'Societies', 'Solutions', 'Source', 'System', 'Systematized Nomenclature of Medicine', 'Technology', 'Terminology', 'Testing', 'Thesauri', 'Time', 'Training', 'United States National Institutes of Health', 'Universities', 'Vendor', 'Vocabulary', 'Work', 'base', 'biomedical ontology', 'clinical care', 'comparative effectiveness', 'computer based Semantic Analysis', 'computer infrastructure', 'data integration', 'design', 'distributed data', 'e-science', 'genome database', 'health information technology', 'improved', 'indexing', 'interest', 'interoperability', 'knowledge base', 'nanoparticle', 'new technology', 'next generation', 'novel', 'novel strategies', 'open source', 'rat genome', 'research and development', 'research study', 'response', 'symposium', 'text searching', 'tool']",NHGRI,STANFORD UNIVERSITY,U54,2012,100000,0.19048071237689607
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,8120230,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Semantics', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2011,264994,0.1038975997559228
"Integrating Microarray and Proteomic Data by Ontology-based Annotation    DESCRIPTION (provided by applicant):       With the completion of the Human Genome Project, there is a need to translate genome-era discoveries into clinical utility. One difficulty in making bench-to-bedside translations with gene-expression and proteomic data is our current inability to relate these findings with each other and with clinical measurements. A translational researcher studying a particular biological process using microarrays or proteomics will want to gather as many relevant publicly-available data sets as possible, to compare findings. Translational investigators wanting to relate clinical or chemical data with multiple genomic or proteomic measurements will want to find and join related data sets. Unfortunately, finding and joining relevant data sets is particularly challenging today, as the useful annotations of this data are still represented only by unstructured free-text, limiting its secondary use. A question we have sought to answer is whether prior investments in biomedical ontologies can provide leverage in determining the context of genomic data in an automated manner, thereby enabling integration of gene expression and proteomic data and the secondary use of genomic data in multiple fields of research beyond those for which the data sets were originally targeted. The three specific aims to address this question are to (1) develop tools that comprehensively map contextual annotations to the largest biomedical ontology, the Unified Medical Language System (UMLS), built and supported by the National Library of Medicine, validate, and disseminate the mappings, (2) execute a four-pronged strategy to evaluate experiment-concept mappings, and (3) apply experiment-context mappings to find and integrate data within and across microarray and proteomics repositories. To keep these tools relevant to biomedical investigators, we have included three Driving Biological Projects (DBPs), in the domains of breast cancer, organ transplantation, and T-cell biology. To accomplish these DBPs, our tools and mappings will be used to find and join experimental data within and across microarray and proteomic repositories. Having DBPs to address will focus our development on a set of scalable tools that can access and analyze experimental data covering a large variety of diseases. Through our advisory committee of world-renowned NIH-funded investigators, we will ensure that our findings will have broad applicability and are useful to a wide variety of biomedical researchers.          n/a",Integrating Microarray and Proteomic Data by Ontology-based Annotation,8138486,R01LM009719,"['Address', 'Advisory Committees', 'Automobile Driving', 'Biological', 'Biological Process', 'Cells', 'Cellular biology', 'Chemicals', 'Clinical', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Ensure', 'Funding', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Head', 'Human Genome Project', 'Improve Access', 'International', 'Investments', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Molecular Biology', 'Nature', 'Online Systems', 'Ontology', 'Organ Transplantation', 'Phenotype', 'Play', 'Process', 'Proteomics', 'Publications', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Specificity', 'System', 'T-Lymphocyte', 'Text', 'Time', 'Translating', 'Translations', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Writing', 'base', 'bench to bedside', 'biomedical informatics', 'biomedical ontology', 'genome-wide', 'improved', 'malignant breast neoplasm', 'repository', 'research study', 'text searching', 'tool', 'translational medicine']",NLM,STANFORD UNIVERSITY,R01,2011,266112,0.11264903115995172
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,8061704,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'information model', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2011,2923298,0.16049849628765347
"Collaborative Development of Biomedical Ontologies and Terminologies    DESCRIPTION (provided by applicant): The development of ontologies that define entities and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage the burgeoning data that are pervasive in biology and medicine. The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. To date, these groups of ontology developers have been limited by the lack of methods and tools that facilitate distributed, collaborative engineering of large-scale ontologies and vocabularies. In this proposal, we outline three specific aims. First, we will explore basic computational methods that are essential for collaborative ontology engineering. We will investigate methods for representing diverse collaborative workflows, information about changes and concept history, trust, and provenance, and for recording decision making and design rationale. Empirical analysis of existing ontology-development projects will inform our construction of models for collaborative development workflows that will guide the processes of authoring, reviewing, and curating biomedical ontologies. Second, we will use the results from our first specific aim to build cProtigi, a set of robust, customizable, interactive tools to support distributed users in their collaborative work to build and edit terminologies and ontologies. Third, we will evaluate our work in the context of real-world, large-scale ontology-engineering projects, including the autism ontology of the National Database for Autism Research; the 11th revision of the WHO's International Classification of Diseases; the Ontology for Biomedical Investigations, under development by a wide range of NIH-supported researchers; and BiomedGT, under development by NCI. It is no longer feasible to imagine that investigators can create biomedical ontologies working independently. The collaborative methods that we will study and the tools that we will build will lead to expanded opportunities to support the diverse data- and knowledge-intensive activities that pervade BISTI, the CTSAs, the NCBCs, and myriad biomedical initiatives that require robust, scaleable ontologies. PUBLIC HEALTH RELEVANCE: The knowledge-based nature of modern medicine requires the use of ontologies and terminologies to process and integrate data. Ontology development itself becomes a collaborative process, with members of the larger research community contributing to and commenting on emerging ontologies. We plan to extend the Protigi ontology editor-the most widely used ontology editor today, with almost 100,000 registered users-to support collaborative development of ontologies and to evaluate the new tools by deploying them at the World Health Organization for the development of ICD-11 and in other settings.             n/a",Collaborative Development of Biomedical Ontologies and Terminologies,8039246,R01GM086587,"['Adopted', 'Autistic Disorder', 'Beds', 'Bioinformatics', 'Biology', 'Collaborations', 'Communities', 'Computers', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Engineering', 'Evaluation', 'Generic Drugs', 'Goals', 'Health', 'Human', 'Industry', 'Institutes', 'International Classification of Diseases', 'Internet', 'Investigation', 'Knowledge', 'Lead', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Modern Medicine', 'NCI Thesaurus', 'NIH Program Announcements', 'Natural Language Processing', 'Nature', 'Online Systems', 'Ontology', 'Process', 'Program Development', 'Published Comment', 'Recording of previous events', 'Research', 'Research Personnel', 'Scientist', 'Source', 'Staging', 'Systems Development', 'Terminology', 'Testing', 'Trust', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'World Health Organization', 'biomedical ontology', 'biomedical scientist', 'cancer Biomedical Informatics Grid', 'conflict resolution', 'design', 'experience', 'flexibility', 'forging', 'knowledge base', 'member', 'open source', 'programs', 'research study', 'response', 'tool', 'usability']",NIGMS,STANFORD UNIVERSITY,R01,2011,526649,0.3107895866742969
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,7935464,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'knowledge base', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2010,267671,0.1038975997559228
"Integrating Microarray and Proteomic Data by Ontology-based Annotation    DESCRIPTION (provided by applicant):       With the completion of the Human Genome Project, there is a need to translate genome-era discoveries into clinical utility. One difficulty in making bench-to-bedside translations with gene-expression and proteomic data is our current inability to relate these findings with each other and with clinical measurements. A translational researcher studying a particular biological process using microarrays or proteomics will want to gather as many relevant publicly-available data sets as possible, to compare findings. Translational investigators wanting to relate clinical or chemical data with multiple genomic or proteomic measurements will want to find and join related data sets. Unfortunately, finding and joining relevant data sets is particularly challenging today, as the useful annotations of this data are still represented only by unstructured free-text, limiting its secondary use. A question we have sought to answer is whether prior investments in biomedical ontologies can provide leverage in determining the context of genomic data in an automated manner, thereby enabling integration of gene expression and proteomic data and the secondary use of genomic data in multiple fields of research beyond those for which the data sets were originally targeted. The three specific aims to address this question are to (1) develop tools that comprehensively map contextual annotations to the largest biomedical ontology, the Unified Medical Language System (UMLS), built and supported by the National Library of Medicine, validate, and disseminate the mappings, (2) execute a four-pronged strategy to evaluate experiment-concept mappings, and (3) apply experiment-context mappings to find and integrate data within and across microarray and proteomics repositories. To keep these tools relevant to biomedical investigators, we have included three Driving Biological Projects (DBPs), in the domains of breast cancer, organ transplantation, and T-cell biology. To accomplish these DBPs, our tools and mappings will be used to find and join experimental data within and across microarray and proteomic repositories. Having DBPs to address will focus our development on a set of scalable tools that can access and analyze experimental data covering a large variety of diseases. Through our advisory committee of world-renowned NIH-funded investigators, we will ensure that our findings will have broad applicability and are useful to a wide variety of biomedical researchers.          n/a",Integrating Microarray and Proteomic Data by Ontology-based Annotation,7929664,R01LM009719,"['Address', 'Advisory Committees', 'Automobile Driving', 'Biological', 'Biological Process', 'Cells', 'Cellular biology', 'Chemicals', 'Clinical', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Ensure', 'Funding', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Head', 'Human Genome Project', 'Improve Access', 'International', 'Investments', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Molecular Biology', 'Nature', 'Online Systems', 'Ontology', 'Organ Transplantation', 'Phenotype', 'Play', 'Process', 'Proteomics', 'Publications', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Specificity', 'System', 'T-Lymphocyte', 'Text', 'Time', 'Translating', 'Translations', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Writing', 'base', 'bench to bedside', 'biomedical informatics', 'biomedical ontology', 'genome-wide', 'improved', 'malignant breast neoplasm', 'repository', 'research study', 'text searching', 'tool', 'translational medicine']",NLM,STANFORD UNIVERSITY,R01,2010,277200,0.11264903115995172
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7780085,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2010,3513343,0.16049849628765347
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,8138946,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2010,745063,0.16049849628765347
"A Resource for Biomedical Ontologies and Knowledge Bases    DESCRIPTION (provided by applicant):       For more than two decades, our laboratory has been studying technology to develop, manage, and use formal descriptions of biomedical concepts. The result of this work is Protege, a workbench that allows users to edit and apply controlled terminologies, ontologies, and knowledge bases to a wide range of information-management problems. To date, more than 50,000 people have registered as users of the system. Many diverse projects in biomedicine-supported by nearly every institute and center at NIH-have become critically dependent on this software and the knowledge-engineering principles that it supports. This P41 competing renewal application seeks to continue support for Protege, as a biomedical informatics resource that will benefit the system's entire user community.      We propose technology research and development to expand the capabilities of the Protege system to meet the current and anticipated needs of the user community. We will re-engineer Protege with a service-oriented architecture that can adapt to the requirements of new ontology languages, large ontology repositories, and cutting-edge ontology-management-services, such as reasoning, alignment, and evolution. We will create support for collaborative ontology development, in the context of both large, centralized projects and open, decentralized efforts. We also will develop advanced support for using ontologies in application software development and as integral parts of software systems.      As a biomedical informatics resource, we will expand our collaborative research projects with other Prot¿g¿ users. We will provide service to the Protege user community through enhanced technical support, user documentation, tutorials, and workshops. These activities will serve to disseminate information about the resource and will aid research and development in many aspects of biomedical informatics both in the United States and internationally.          n/a",A Resource for Biomedical Ontologies and Knowledge Bases,8076789,P41LM007885,"['Address', 'Adopted', 'Anatomy', 'Applications Grants', 'Architecture', 'Area', 'Biomedical Computing', 'Biomedical Technology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data Set', 'Development', 'Documentation', 'Educational workshop', 'Electronics', 'Engineering', 'Ensure', 'Environment', 'Evolution', 'Foundations', 'Funding', 'Generic Drugs', 'Genes', 'Goals', 'Grant', 'Guidelines', 'Information Management', 'Institutes', 'International', 'Knowledge', 'Laboratories', 'Language', 'Mails', 'Maintenance', 'Modeling', 'Natural Language Processing', 'Ontology', 'Participant', 'Process', 'Published Comment', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Resources', 'Semantics', 'Services', 'Software Engineering', 'Strigiformes', 'System', 'Technology', 'Terminology', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'biomedical informatics', 'biomedical ontology', 'biomedical scientist', 'design', 'information organization', 'innovation', 'knowledge base', 'meetings', 'member', 'next generation', 'open source', 'repository', 'research and development', 'software development', 'software systems', 'symposium', 'tool']",NLM,STANFORD UNIVERSITY,P41,2010,956625,0.21807289708921987
"Collaborative Development of Biomedical Ontologies and Terminologies    DESCRIPTION (provided by applicant): The development of ontologies that define entities and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage the burgeoning data that are pervasive in biology and medicine. The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. To date, these groups of ontology developers have been limited by the lack of methods and tools that facilitate distributed, collaborative engineering of large-scale ontologies and vocabularies. In this proposal, we outline three specific aims. First, we will explore basic computational methods that are essential for collaborative ontology engineering. We will investigate methods for representing diverse collaborative workflows, information about changes and concept history, trust, and provenance, and for recording decision making and design rationale. Empirical analysis of existing ontology-development projects will inform our construction of models for collaborative development workflows that will guide the processes of authoring, reviewing, and curating biomedical ontologies. Second, we will use the results from our first specific aim to build cProtigi, a set of robust, customizable, interactive tools to support distributed users in their collaborative work to build and edit terminologies and ontologies. Third, we will evaluate our work in the context of real-world, large-scale ontology-engineering projects, including the autism ontology of the National Database for Autism Research; the 11th revision of the WHO's International Classification of Diseases; the Ontology for Biomedical Investigations, under development by a wide range of NIH-supported researchers; and BiomedGT, under development by NCI. It is no longer feasible to imagine that investigators can create biomedical ontologies working independently. The collaborative methods that we will study and the tools that we will build will lead to expanded opportunities to support the diverse data- and knowledge-intensive activities that pervade BISTI, the CTSAs, the NCBCs, and myriad biomedical initiatives that require robust, scaleable ontologies. PUBLIC HEALTH RELEVANCE: The knowledge-based nature of modern medicine requires the use of ontologies and terminologies to process and integrate data. Ontology development itself becomes a collaborative process, with members of the larger research community contributing to and commenting on emerging ontologies. We plan to extend the Protigi ontology editor-the most widely used ontology editor today, with almost 100,000 registered users-to support collaborative development of ontologies and to evaluate the new tools by deploying them at the World Health Organization for the development of ICD-11 and in other settings.             n/a",Collaborative Development of Biomedical Ontologies and Terminologies,7774343,R01GM086587,"['Adopted', 'Autistic Disorder', 'Beds', 'Bioinformatics', 'Biology', 'Collaborations', 'Communities', 'Computer Systems Development', 'Computers', 'Computing Methodologies', 'Consensus', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Engineering', 'Evaluation', 'Generic Drugs', 'Goals', 'Human', 'Industry', 'Institutes', 'International Classification of Diseases', 'Internet', 'Investigation', 'Knowledge', 'Lead', 'Life', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Modern Medicine', 'NCI Thesaurus', 'NIH Program Announcements', 'Natural Language Processing', 'Nature', 'Online Systems', 'Ontology', 'Outsourcing', 'Process', 'Program Development', 'Published Comment', 'Recording of previous events', 'Research', 'Research Personnel', 'Scientist', 'Source', 'Staging', 'Terminology', 'Testing', 'Trust', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'World Health Organization', 'biomedical ontology', 'biomedical scientist', 'cancer Biomedical Informatics Grid', 'conflict resolution', 'design', 'experience', 'flexibility', 'forging', 'knowledge base', 'member', 'open source', 'programs', 'public health relevance', 'research study', 'response', 'tool', 'usability']",NIGMS,STANFORD UNIVERSITY,R01,2010,525262,0.3107895866742969
"Automated Integration of Biomedical Knowledge Today, ontologies are critical instruments for biomedical investigators, especially in those areas, such as cancer research, that require the command of a vast amount of information and a systemic approach to the design and interpretation of experiments. In fact, ontologies are proliferating in all areas of biomedical research, offering both challenges and opportunities. One of the principal challenges of this field stems from the fact that ontologies are developed in isolation, rendering it impossible to move, for instance, from genes to organisms, to diseases, to drugs. The National Center for Biomedical Ontology (NCBO) represents a fundamental endeavor in the collection, coordination and distribution of biomedical ontologies and offers an unparalleled opportunity to combine these biomedical ontologies into a single search space where genetic, anatomic, molecular and pharmacological information can be seamlessly explored and exploited as a holistic representation of biomedical knowledge. Unfortunately, ontology integration using standard means of manual curation is a labor intensive task, unable to scale up and keep up with the current growth rate of biomedical ontologies. We have developed a systematic framework for automated ontology engineering based on information theory, and we have successfully applied it to the analysis and engineering of Gene Ontology (GO), the development gene and protein databases, and the identification of peripheral biomarkers of disease progression and drug response. This project brings together a unique group of competences, ranging from ontology engineering, statistical signal processing, bioinformatics, cancer research, and clinical pharmacogenomics, to develop a principled method, grounded on the mathematics of information theory, to automatically combine and integrate biomedical ontologies and implement it as part of the NCBO architecture Ontologies are critical instruments for biomedical investigators especially in those areas, such as cancer research, that require a vast amount of information and a systemic approach to the design and interpretation of their experiments. In collaboration with the National Center for Biomedical Ontology (NCBO), this project will develop a principled method, grounded on the mathematics of information theory, to automatically combine biomedical ontologies. As a result, this project will integrate biomedical knowledge along dimensions that are today isolated and, in so doing, it will empower investigators with a new holistic understanding of disease, it will fast track the clinical  translation of biological discoveries, and it will change the approach to discovery, especially for those diseases that, like cancer, require a systemic view of their biological mechanisms.",Automated Integration of Biomedical Knowledge,7945368,R01HG004836,"['Anatomy', 'Area', 'Artificial Intelligence', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Research', 'Clinical', 'Collaborations', 'Collection', 'Colorectal Cancer', 'Communities', 'Competence', 'Complex', 'Computer software', 'Consultations', 'Controlled Vocabulary', 'Dana-Farber Cancer Institute', 'Data', 'Databases', 'Development', 'Dimensions', 'Disease', 'Disease Progression', 'Engineered Gene', 'Engineering', 'Fostering', 'Future', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Growth', 'Human', 'In Vitro', 'Information Theory', 'Internet', 'Java', 'Knowledge', 'Link', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Mathematics', 'Methodology', 'Methods', 'Molecular', 'National Cancer Institute', 'Nature', 'Ontology', 'Organism', 'Peripheral', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Proliferating', 'Protein Databases', 'Research Infrastructure', 'Research Personnel', 'Services', 'Structure', 'Testing', 'Text', 'Tissues', 'Translations', 'Validation', 'anticancer research', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'design', 'empowered', 'gene function', 'graphical user interface', 'information organization', 'instrument', 'interoperability', 'novel', 'open source', 'repository', 'research study', 'response', 'scale up', 'sound', 'statistics', 'stem']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2010,428079,0.2477869760341465
"Ontologies and Biomedical Language Processing    DESCRIPTION (provided by applicant): We hypothesize that there are significant synergies between the applications of biomedical ontologies and of biomedical language processing (BLP) which can be used to improve the quality and scope of both activities. A growing body of work suggests such synergies might exist, but there has yet to be a systematic exploration of their potential. We propose to carry out a focused effort to explore both the potential for, and obstacles to, the mutual application of biomedical ontologies and biomedical language processing. To provide immediate biological relevance to our work, we propose to focus on the topics of autoimmune and pulmonary disease. We group our proposed explorations into three specific aims: (1) Create novel tools and approaches for the application and maintenance of biomedical ontologies, based on an assessment of the processes and tools used for the ontological annotation of textual corpora in the biomedical language processing community. Particularly, we will focus on the creation of new methods for effective search through large ontologies, compositional approaches to annotation, effective capture of the evidence underlying annotations, and the use of automated suggestions for manual confirmation. (2) Evaluate the utility of BLP tools and techniques when applied to terms and definitions of biomedical ontologies, both to enrich and interconnect orthogonal ontologies, and to provide quality assurance and quality control mechanisms. Particularly, we propose to develop and evaluate methods for connecting terms within and across ontologies, for assessing completeness of an ontology against the literature, and for implementing automatically executable measures of ontology quality. (3) Compare the differences between annotations produced by manual procedures and those produced by automated BLP methods for completeness and correctness. Based on the resulting data, produce guidelines for the optimal interplay between manual and automatic procedures for producing broad, accurate and useful knowledge-bases. Because ontologies are the central organizing tool of the model organism databases, improvements in their quality and in the ease and efficiency of their use will have a major effect on the model organism databases, speed the translational process generally, and create a potentially large public health impact.          n/a",Ontologies and Biomedical Language Processing,7928868,R01GM083649,"['Address', 'Area', 'Autoimmune Diseases', 'Autoimmune Process', 'Autoimmunity', 'Automated Annotation', 'Biological', 'Biomedical Computing', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Elements', 'Ensure', 'Environment', 'Genes', 'Guidelines', 'Human', 'Immunology', 'Insulin-Dependent Diabetes Mellitus', 'Language', 'Linguistics', 'Literature', 'Lung diseases', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Medicine', 'Metaphor', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Motivation', 'Natural Language Processing', 'Ontology', 'Peer Review', 'Procedures', 'Process', 'Process Assessment', 'Production', 'Psyche structure', 'Public Health', 'Publications', 'Pulmonary Hypertension', 'Quality Control', 'Recording of previous events', 'Research', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Semantics', 'Speed', 'Suggestion', 'Techniques', 'Technology', 'Text', 'Ursidae Family', 'Validation', 'Work', 'base', 'biomedical ontology', 'computer science', 'computerized tools', 'cost', 'design', 'experience', 'gene function', 'improved', 'information organization', 'innovation', 'knowledge base', 'language processing', 'model organisms databases', 'natural language', 'novel', 'quality assurance', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R01,2010,605009,0.25582971935576837
"DEVELOPMENT OF DATA ONTOLOGIES FOR INTEGRATING MULTI-CENTER CARDIOVASCULAR STUDIE Cardiovascular disease (CVD) and its associated risk factors such as hypertension and dyslipidemia constitute a major public-health burden due to increased mortality and morbidity and rising health care costs. Massive epidemiological data are needed to detect the small effects of many individual genes and the environment on these traits. However, sample sizes needed to make powerful inferences may only be reached by integrating multiple epidemiological studies. Meaningful integration of information from multiple studies requires the development of data ontologies which make it possible to integrate information across studies in an optimum manner so as to maximize the information content and hence the statistical power for detecting small effect sizes. A second compounding problem of data integration is that software applications that manage such study data are typically non-interoperable, i.e. “silos” of data, and are incapable of being shared in a syntactically and semantically meaningful manner. Consequently, an infrastructure that integrates across studies in an interoperable manner is needed to ensure that epidemiological cardiovascular research remains a viable and major player in the biomedical informatics revolution which is currently underway. The cancer Biomedical Informatics Grid (caBIGTM) is addressing these problems in the cancer domain by developing software systems that are able to exchange information or that are syntactically interoperable by accessing metadata that is semantically annotated using controlled vocabularies. Our overarching goal is to develop ontologies for integrating cardiovascular epidemiological data from multiple studies. Specifically, we propose three Aims: First, develop cardiovascular data ontologies and vocabularies for each of three disparate multi-center epidemiological studies that facilitate data integration across the studies and data mining for various phenotypes. Second, adopt a technology infrastructure that leverages the cardiovascular data ontologies and vocabularies using Model Driven Architecture (MDA) and caBIGTM tools to facilitate the integration and widespread sharing of cardiovascular data sets. Third, facilitate seamless data sharing and promote widespread data dissemination among research communities cutting across clinical, translational and epidemiological domains, primarily through collaboration with the established CardioVascular Research Grid (CVRG). Cardiovascular disease (CVD) is a leading cause of mortality and morbidity which contributes substantially to rising health care costs and consequently constitutes a major public health burden. Therefore, understanding the genetic and environmental effects on these CVD traits is important. Massive epidemiological study data are needed to detect the small individual effects of genes and their interactions, and integration of multiple epidemiological studies are necessary for generating large sample sizes. Unfortunately, integrating information from multiple studies in a meaningful manner requires the development of data ontologies (language and grammar). Our proposal addresses this need, and does this in a way that is informative and user-friendly from the End User’s point of view.",DEVELOPMENT OF DATA ONTOLOGIES FOR INTEGRATING MULTI-CENTER CARDIOVASCULAR STUDIE,7851333,R01HL094286,"['Address', 'Adopted', 'Architecture', 'Belief', 'Bioinformatics', 'Biological Assay', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Collaborations', 'Common Data Element', 'Communities', 'Complex', 'Computer software', 'Computerized Medical Record', 'Controlled Vocabulary', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Dyslipidemias', 'Elements', 'Ensure', 'Environment', 'Epidemiologic Studies', 'Epidemiology', 'Equipment', 'Failure', 'Family Study', 'Ferrets', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Health Care Costs', 'Human', 'Hypertension', 'Individual', 'Language', 'Literature', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morbidity - disease rate', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Ontology', 'Phenotype', 'Physiological', 'Protocols documentation', 'Public Health', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Factors', 'Sample Size', 'Scientist', 'Solutions', 'Strategic Planning', 'Structure', 'System', 'Technology', 'Time', 'Time Study', 'Vocabulary', 'Work', 'anticancer research', 'biomedical informatics', 'cancer Biomedical Informatics Grid', 'cardiovascular disorder risk', 'data integration', 'data mining', 'data sharing', 'design', 'experience', 'mortality', 'software development', 'software systems', 'tool', 'trait', 'user-friendly']",NHLBI,WASHINGTON UNIVERSITY,R01,2010,474912,0.11964034907954996
"Ontology-based Information Network to Support Vaccine Research    DESCRIPTION (provided by applicant): Since the introduction of Edward Jenner's smallpox vaccine in 1796, vaccines have proven invaluable for their ability to stimulate the immune system and to confer protection against pathogenic organisms. Progress in modern vaccine research has been accompanied by a dramatic increase in the number of vaccine-related papers in the published literature. It has become increasingly challenging to identify and annotate vaccine data from this large and diverse literature which no one scientist or team can fully master. Although vaccine databases exist that emphasize commercialized vaccines, no public central repository is available to store research data concerning commercial vaccines, vaccines in clinical trials, or vaccine candidates in early stages of development, in a fashion that render such data available for advanced analyses. To fill this need, we have developed VIOLIN (http://www.violinet.org), a web-based database system for annotation, storage, and analysis of published vaccine data. An ontology represents consensus-based controlled vocabularies of terms and relations, with associated definitions which are logically formulated in such a way as to promote automated reasoning. A bottleneck of vaccine research and further VIOLIN development is the lack of a vaccine ontology, which in turn makes a significant obstacle for vaccine data standardization, retrieval, integration, and advanced analysis and prediction. Our goal is to develop the community-based Vaccine Ontology (VO) and apply it to efficient vaccine literature mining and analysis of protective immune mechanisms. We will focus on two model pathogens: Escherichia coli and Brucella species. This project contains three specific aims: (1) develop a community-based Vaccine Ontology (VO), and apply it to establish a vaccine knowledgebase and to promote vaccine data integration and query through Semantic Web. The VO development will be achieved through collaboration with vaccine researchers, the Infectious Disease Ontology (IDO) Initiative, and the National Center for Biomedical Ontology (NCBO); (2) develop a VO-based natural language processing (NLP) system and apply it for more efficient retrieval of Brucella and E. coli vaccine information, automated annotation of journal articles with VO terms, and VO improvement. This task will be achieved by collaboration with the National Center for Integrative Biomedical Informatics (NCIBI). (3) analyze and predict vaccine targets and protective immune networks attributable to the interactions between host and vaccine. This will be achieved mainly by VO-based literature mining and a novel genome- and literature-based statistical methodology. This project will be implemented by a strong collaborative team and supported from a large user community. The Vaccine Ontology and its applications to literature mining and for studying protective immunity against Brucella spp. and E. coli will lay a strong foundation for further advanced informatics research on vaccines against infectious diseases in the post-genomics and information era.            Narrative: Vaccines stimulate the immune system and confer protection against pathogenic microorganisms. A bottleneck of vaccine research is the lack of an ontology (consensus- based controlled vocabularies of terms and relations) to ensure consistency of literature curation and support automated reasoning. The goal of this project is to develop a community-based Vaccine Ontology and apply it to vaccine literature mining and analysis of vaccine-induced immune mechanisms.",Ontology-based Information Network to Support Vaccine Research,7735790,R01AI081062,"['Algorithms', 'Attenuated Live Virus Vaccine', 'Automated Annotation', 'Bacterial Genes', 'Brucella', 'Brucella Vaccine', 'Clinical Trials', 'Collaborations', 'Communicable Diseases', 'Communities', 'Consensus', 'Controlled Vocabulary', 'Data', 'Databases', 'Development', 'Dictionary', 'Ensure', 'Escherichia coli', 'Escherichia coli Vaccines', 'Foundations', 'Genome', 'Genomics', 'Goals', 'Immune', 'Immune response', 'Immune system', 'Immunity', 'Informatics', 'Information Networks', 'Information Retrieval', 'Journals', 'Laboratories', 'Literature', 'MeSH Thesaurus', 'Methodology', 'Methods', 'Modeling', 'National Center for Integrative Biomedical Informatics', 'Natural Language Processing', 'Online Systems', 'Ontology', 'Organism', 'Paper', 'Preparation', 'Process', 'Proteins', 'Publications', 'Publishing', 'Research', 'Research Personnel', 'Retrieval', 'Scientist', 'Smallpox Vaccine', 'Staging', 'Standardization', 'Structure', 'Subunit Vaccines', 'System', 'Testing', 'Training', 'Vaccine Research', 'Vaccines', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'data integration', 'editorial', 'gene function', 'genome-wide', 'interest', 'journal article', 'microorganism', 'novel', 'novel vaccines', 'pathogen', 'programs', 'repository', 'research study', 'statistics', 'text searching', 'user-friendly', 'vaccine candidate', 'vaccine development', 'vaccine evaluation', 'web interface']",NIAID,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2009,270375,0.1038975997559228
"Integrating Microarray and Proteomic Data by Ontology-based Annotation    DESCRIPTION (provided by applicant):       With the completion of the Human Genome Project, there is a need to translate genome-era discoveries into clinical utility. One difficulty in making bench-to-bedside translations with gene-expression and proteomic data is our current inability to relate these findings with each other and with clinical measurements. A translational researcher studying a particular biological process using microarrays or proteomics will want to gather as many relevant publicly-available data sets as possible, to compare findings. Translational investigators wanting to relate clinical or chemical data with multiple genomic or proteomic measurements will want to find and join related data sets. Unfortunately, finding and joining relevant data sets is particularly challenging today, as the useful annotations of this data are still represented only by unstructured free-text, limiting its secondary use. A question we have sought to answer is whether prior investments in biomedical ontologies can provide leverage in determining the context of genomic data in an automated manner, thereby enabling integration of gene expression and proteomic data and the secondary use of genomic data in multiple fields of research beyond those for which the data sets were originally targeted. The three specific aims to address this question are to (1) develop tools that comprehensively map contextual annotations to the largest biomedical ontology, the Unified Medical Language System (UMLS), built and supported by the National Library of Medicine, validate, and disseminate the mappings, (2) execute a four-pronged strategy to evaluate experiment-concept mappings, and (3) apply experiment-context mappings to find and integrate data within and across microarray and proteomics repositories. To keep these tools relevant to biomedical investigators, we have included three Driving Biological Projects (DBPs), in the domains of breast cancer, organ transplantation, and T-cell biology. To accomplish these DBPs, our tools and mappings will be used to find and join experimental data within and across microarray and proteomic repositories. Having DBPs to address will focus our development on a set of scalable tools that can access and analyze experimental data covering a large variety of diseases. Through our advisory committee of world-renowned NIH-funded investigators, we will ensure that our findings will have broad applicability and are useful to a wide variety of biomedical researchers.          n/a",Integrating Microarray and Proteomic Data by Ontology-based Annotation,7693803,R01LM009719,"['Address', 'Advisory Committees', 'Automobile Driving', 'Biological', 'Biological Process', 'Cells', 'Cellular biology', 'Chemicals', 'Classification', 'Clinical', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Ensure', 'Funding', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Head', 'Human Genome Project', 'Improve Access', 'International', 'Investments', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Molecular Biology', 'Nature', 'Online Systems', 'Ontology', 'Organ Transplantation', 'Phenotype', 'Play', 'Process', 'Proteomics', 'Publications', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Specificity', 'System', 'T-Lymphocyte', 'Text', 'Time', 'Translating', 'Translations', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Writing', 'base', 'bench to bedside', 'biomedical informatics', 'biomedical ontology', 'genome-wide', 'improved', 'malignant breast neoplasm', 'repository', 'research study', 'text searching', 'tool', 'translational medicine']",NLM,STANFORD UNIVERSITY,R01,2009,280000,0.11264903115995172
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7941562,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2009,1038804,0.16049849628765347
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7581087,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Data', 'Databases', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'data format', 'empowered', 'functional genomics', 'genetic element', 'human disease', 'interest', 'model organisms databases', 'repository', 'tool']",NHGRI,JACKSON LABORATORY,P41,2009,3437506,0.16049849628765347
"A Resource for Biomedical Ontologies and Knowledge Bases    DESCRIPTION (provided by applicant):       For more than two decades, our laboratory has been studying technology to develop, manage, and use formal descriptions of biomedical concepts. The result of this work is Protege, a workbench that allows users to edit and apply controlled terminologies, ontologies, and knowledge bases to a wide range of information-management problems. To date, more than 50,000 people have registered as users of the system. Many diverse projects in biomedicine-supported by nearly every institute and center at NIH-have become critically dependent on this software and the knowledge-engineering principles that it supports. This P41 competing renewal application seeks to continue support for Protege, as a biomedical informatics resource that will benefit the system's entire user community.      We propose technology research and development to expand the capabilities of the Protege system to meet the current and anticipated needs of the user community. We will re-engineer Protege with a service-oriented architecture that can adapt to the requirements of new ontology languages, large ontology repositories, and cutting-edge ontology-management-services, such as reasoning, alignment, and evolution. We will create support for collaborative ontology development, in the context of both large, centralized projects and open, decentralized efforts. We also will develop advanced support for using ontologies in application software development and as integral parts of software systems.      As a biomedical informatics resource, we will expand our collaborative research projects with other Prot¿g¿ users. We will provide service to the Protege user community through enhanced technical support, user documentation, tutorials, and workshops. These activities will serve to disseminate information about the resource and will aid research and development in many aspects of biomedical informatics both in the United States and internationally.          n/a",A Resource for Biomedical Ontologies and Knowledge Bases,7660538,P41LM007885,"['Address', 'Adopted', 'Anatomy', 'Applications Grants', 'Architecture', 'Area', 'Biomedical Computing', 'Biomedical Technology', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data Set', 'Development', 'Documentation', 'Educational workshop', 'Electronics', 'Engineering', 'Ensure', 'Environment', 'Evolution', 'Foundations', 'Funding', 'Generic Drugs', 'Genes', 'Goals', 'Grant', 'Guidelines', 'Information Management', 'Institutes', 'International', 'Knowledge', 'Laboratories', 'Language', 'Mails', 'Maintenance', 'Modeling', 'Natural Language Processing', 'Ontology', 'Participant', 'Process', 'Published Comment', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Resources', 'Semantics', 'Services', 'Software Engineering', 'Strigiformes', 'System', 'Technology', 'Terminology', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'biomedical informatics', 'biomedical ontology', 'biomedical scientist', 'design', 'information organization', 'innovation', 'knowledge base', 'meetings', 'member', 'next generation', 'open source', 'repository', 'research and development', 'software development', 'software systems', 'symposium', 'tool']",NLM,STANFORD UNIVERSITY,P41,2009,688362,0.21807289708921987
"Automated Integration of Biomedical Knowledge Today, ontologies are critical instruments for biomedical investigators, especially in those areas, such as cancer research, that require the command of a vast amount of information and a systemic approach to the design and interpretation of experiments. In fact, ontologies are proliferating in all areas of biomedical research, offering both challenges and opportunities. One of the principal challenges of this field stems from the fact that ontologies are developed in isolation, rendering it impossible to move, for instance, from genes to organisms, to diseases, to drugs. The National Center for Biomedical Ontology (NCBO) represents a fundamental endeavor in the collection, coordination and distribution of biomedical ontologies and offers an unparalleled opportunity to combine these biomedical ontologies into a single search space where genetic, anatomic, molecular and pharmacological information can be seamlessly explored and exploited as a holistic representation of biomedical knowledge. Unfortunately, ontology integration using standard means of manual curation is a labor intensive task, unable to scale up and keep up with the current growth rate of biomedical ontologies. We have developed a systematic framework for automated ontology engineering based on information theory, and we have successfully applied it to the analysis and engineering of Gene Ontology (GO), the development gene and protein databases, and the identification of peripheral biomarkers of disease progression and drug response. This project brings together a unique group of competences, ranging from ontology engineering, statistical signal processing, bioinformatics, cancer research, and clinical pharmacogenomics, to develop a principled method, grounded on the mathematics of information theory, to automatically combine and integrate biomedical ontologies and implement it as part of the NCBO architecture Ontologies are critical instruments for biomedical investigators especially in those areas, such as cancer research, that require a vast amount of information and a systemic approach to the design and interpretation of their experiments. In collaboration with the National Center for Biomedical Ontology (NCBO), this project will develop a principled method, grounded on the mathematics of information theory, to automatically combine biomedical ontologies. As a result, this project will integrate biomedical knowledge along dimensions that are today isolated and, in so doing, it will empower investigators with a new holistic understanding of disease, it will fast track the clinical  translation of biological discoveries, and it will change the approach to discovery, especially for those diseases that, like cancer, require a systemic view of their biological mechanisms.",Automated Integration of Biomedical Knowledge,7558468,R01HG004836,"['Anatomy', 'Architecture', 'Area', 'Artificial Intelligence', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Research', 'Classification', 'Clinical', 'Collaborations', 'Collection', 'Colorectal Cancer', 'Competence', 'Complex', 'Development', 'Dimensions', 'Disease', 'Disease Progression', 'Engineered Gene', 'Engineering', 'Gene Proteins', 'Genes', 'Genetic', 'Goals', 'Growth', 'Human', 'Information Theory', 'Internet', 'Java', 'Knowledge', 'Link', 'Literature', 'Malignant Neoplasms', 'Manuals', 'Maps', 'Mathematics', 'Methods', 'Molecular', 'Ontology', 'Organism', 'Peripheral', 'Pharmaceutical Preparations', 'Pharmacogenomics', 'Proliferating', 'Protein Databases', 'Research Infrastructure', 'Research Personnel', 'Services', 'Side', 'Structure', 'Testing', 'Text', 'Tissues', 'Translations', 'anticancer research', 'base', 'biomedical ontology', 'computer based Semantic Analysis', 'computerized data processing', 'design', 'empowered', 'graphical user interface', 'insight', 'instrument', 'open source', 'programs', 'repository', 'research study', 'response', 'scale up', 'statistics', 'stem']",NHGRI,BRIGHAM AND WOMEN'S HOSPITAL,R01,2009,428078,0.2477869760341465
"Collaborative Development of Biomedical Ontologies and Terminologies    DESCRIPTION (provided by applicant): The development of ontologies that define entities and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage the burgeoning data that are pervasive in biology and medicine. The need to annotate, retrieve, and integrate high-throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. To date, these groups of ontology developers have been limited by the lack of methods and tools that facilitate distributed, collaborative engineering of large-scale ontologies and vocabularies. In this proposal, we outline three specific aims. First, we will explore basic computational methods that are essential for collaborative ontology engineering. We will investigate methods for representing diverse collaborative workflows, information about changes and concept history, trust, and provenance, and for recording decision making and design rationale. Empirical analysis of existing ontology-development projects will inform our construction of models for collaborative development workflows that will guide the processes of authoring, reviewing, and curating biomedical ontologies. Second, we will use the results from our first specific aim to build cProtigi, a set of robust, customizable, interactive tools to support distributed users in their collaborative work to build and edit terminologies and ontologies. Third, we will evaluate our work in the context of real-world, large-scale ontology-engineering projects, including the autism ontology of the National Database for Autism Research; the 11th revision of the WHO's International Classification of Diseases; the Ontology for Biomedical Investigations, under development by a wide range of NIH-supported researchers; and BiomedGT, under development by NCI. It is no longer feasible to imagine that investigators can create biomedical ontologies working independently. The collaborative methods that we will study and the tools that we will build will lead to expanded opportunities to support the diverse data- and knowledge-intensive activities that pervade BISTI, the CTSAs, the NCBCs, and myriad biomedical initiatives that require robust, scaleable ontologies. PUBLIC HEALTH RELEVANCE: The knowledge-based nature of modern medicine requires the use of ontologies and terminologies to process and integrate data. Ontology development itself becomes a collaborative process, with members of the larger research community contributing to and commenting on emerging ontologies. We plan to extend the Protigi ontology editor-the most widely used ontology editor today, with almost 100,000 registered users-to support collaborative development of ontologies and to evaluate the new tools by deploying them at the World Health Organization for the development of ICD-11 and in other settings.             n/a",Collaborative Development of Biomedical Ontologies and Terminologies,7565504,R01GM086587,"['Adopted', 'Autistic Disorder', 'Beds', 'Bioinformatics', 'Biology', 'Collaborations', 'Communities', 'Computer Systems Development', 'Computers', 'Computing Methodologies', 'Conflict (Psychology)', 'Consensus', 'Data', 'Data Set', 'Databases', 'Decision Making', 'Decision Support Systems', 'Development', 'Engineering', 'Evaluation', 'Generic Drugs', 'Goals', 'Human', 'Industry', 'Institutes', 'International Classification of Diseases', 'Internet', 'Investigation', 'Knowledge', 'Lead', 'Life', 'Mainstreaming', 'Maintenance', 'Medicine', 'Metadata', 'Methods', 'Modeling', 'Modern Medicine', 'NCI Thesaurus', 'NIH Program Announcements', 'Natural Language Processing', 'Nature', 'Online Systems', 'Ontology', 'Outsourcing', 'Process', 'Program Development', 'Published Comment', 'Recording of previous events', 'Research', 'Research Personnel', 'Resolution', 'Scientist', 'Source', 'Staging', 'Terminology', 'Testing', 'Trust', 'United States National Institutes of Health', 'Vocabulary', 'Work', 'World Health Organization', 'biomedical ontology', 'biomedical scientist', 'cancer Biomedical Informatics Grid', 'design', 'experience', 'flexibility', 'forging', 'knowledge base', 'member', 'open source', 'programs', 'public health relevance', 'research study', 'response', 'tool', 'usability']",NIGMS,STANFORD UNIVERSITY,R01,2009,529858,0.3107895866742969
"Ontologies and Biomedical Language Processing    DESCRIPTION (provided by applicant): We hypothesize that there are significant synergies between the applications of biomedical ontologies and of biomedical language processing (BLP) which can be used to improve the quality and scope of both activities. A growing body of work suggests such synergies might exist, but there has yet to be a systematic exploration of their potential. We propose to carry out a focused effort to explore both the potential for, and obstacles to, the mutual application of biomedical ontologies and biomedical language processing. To provide immediate biological relevance to our work, we propose to focus on the topics of autoimmune and pulmonary disease. We group our proposed explorations into three specific aims: (1) Create novel tools and approaches for the application and maintenance of biomedical ontologies, based on an assessment of the processes and tools used for the ontological annotation of textual corpora in the biomedical language processing community. Particularly, we will focus on the creation of new methods for effective search through large ontologies, compositional approaches to annotation, effective capture of the evidence underlying annotations, and the use of automated suggestions for manual confirmation. (2) Evaluate the utility of BLP tools and techniques when applied to terms and definitions of biomedical ontologies, both to enrich and interconnect orthogonal ontologies, and to provide quality assurance and quality control mechanisms. Particularly, we propose to develop and evaluate methods for connecting terms within and across ontologies, for assessing completeness of an ontology against the literature, and for implementing automatically executable measures of ontology quality. (3) Compare the differences between annotations produced by manual procedures and those produced by automated BLP methods for completeness and correctness. Based on the resulting data, produce guidelines for the optimal interplay between manual and automatic procedures for producing broad, accurate and useful knowledge-bases. Because ontologies are the central organizing tool of the model organism databases, improvements in their quality and in the ease and efficiency of their use will have a major effect on the model organism databases, speed the translational process generally, and create a potentially large public health impact.          n/a",Ontologies and Biomedical Language Processing,7684604,R01GM083649,"['Address', 'Area', 'Autoimmune Diseases', 'Autoimmune Process', 'Autoimmunity', 'Automated Annotation', 'Biological', 'Biomedical Computing', 'Body of uterus', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Elements', 'Ensure', 'Environment', 'Genes', 'Guidelines', 'Human', 'Immunology', 'Insulin-Dependent Diabetes Mellitus', 'Language', 'Linguistics', 'Literature', 'Lung diseases', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Medicine', 'Metaphor', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Motivation', 'Natural Language Processing', 'Ontology', 'Peer Review', 'Procedures', 'Process', 'Process Assessment', 'Production', 'Psyche structure', 'Public Health', 'Publications', 'Pulmonary Hypertension', 'Quality Control', 'Recording of previous events', 'Research', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Semantics', 'Speed', 'Suggestion', 'Techniques', 'Technology', 'Text', 'Ursidae Family', 'Validation', 'Work', 'base', 'biomedical ontology', 'computer science', 'computerized tools', 'cost', 'design', 'experience', 'gene function', 'improved', 'information organization', 'innovation', 'knowledge base', 'language processing', 'model organisms databases', 'natural language', 'novel', 'quality assurance', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R01,2009,639134,0.25582971935576837
"DEVELOPMENT OF DATA ONTOLOGIES FOR INTEGRATING MULTI-CENTER CARDIOVASCULAR STUDIE Cardiovascular disease (CVD) and its associated risk factors such as hypertension and dyslipidemia constitute a major public-health burden due to increased mortality and morbidity and rising health care costs. Massive epidemiological data are needed to detect the small effects of many individual genes and the environment on these traits. However, sample sizes needed to make powerful inferences may only be reached by integrating multiple epidemiological studies. Meaningful integration of information from multiple studies requires the development of data ontologies which make it possible to integrate information across studies in an optimum manner so as to maximize the information content and hence the statistical power for detecting small effect sizes. A second compounding problem of data integration is that software applications that manage such study data are typically non-interoperable, i.e. “silos” of data, and are incapable of being shared in a syntactically and semantically meaningful manner. Consequently, an infrastructure that integrates across studies in an interoperable manner is needed to ensure that epidemiological cardiovascular research remains a viable and major player in the biomedical informatics revolution which is currently underway. The cancer Biomedical Informatics Grid (caBIGTM) is addressing these problems in the cancer domain by developing software systems that are able to exchange information or that are syntactically interoperable by accessing metadata that is semantically annotated using controlled vocabularies. Our overarching goal is to develop ontologies for integrating cardiovascular epidemiological data from multiple studies. Specifically, we propose three Aims: First, develop cardiovascular data ontologies and vocabularies for each of three disparate multi-center epidemiological studies that facilitate data integration across the studies and data mining for various phenotypes. Second, adopt a technology infrastructure that leverages the cardiovascular data ontologies and vocabularies using Model Driven Architecture (MDA) and caBIGTM tools to facilitate the integration and widespread sharing of cardiovascular data sets. Third, facilitate seamless data sharing and promote widespread data dissemination among research communities cutting across clinical, translational and epidemiological domains, primarily through collaboration with the established CardioVascular Research Grid (CVRG). Cardiovascular disease (CVD) is a leading cause of mortality and morbidity which contributes substantially to rising health care costs and consequently constitutes a major public health burden. Therefore, understanding the genetic and environmental effects on these CVD traits is important. Massive epidemiological study data are needed to detect the small individual effects of genes and their interactions, and integration of multiple epidemiological studies are necessary for generating large sample sizes. Unfortunately, integrating information from multiple studies in a meaningful manner requires the development of data ontologies (language and grammar). Our proposal addresses this need, and does this in a way that is informative and user-friendly from the End User’s point of view.",DEVELOPMENT OF DATA ONTOLOGIES FOR INTEGRATING MULTI-CENTER CARDIOVASCULAR STUDIE,7558424,R01HL094286,"['Address', 'Adopted', 'Architecture', 'Area', 'Belief', 'Bioinformatics', 'Biological Assay', 'Budgets', 'Cardiovascular Diseases', 'Cardiovascular system', 'Clinical', 'Clinical Research', 'Collaborations', 'Common Data Element', 'Communities', 'Complex', 'Computer software', 'Computerized Medical Record', 'Controlled Vocabulary', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Dimensions', 'Disease', 'Dyslipidemias', 'Electrocardiogram', 'Elements', 'Ensure', 'Environment', 'Epidemiologic Studies', 'Epidemiology', 'Equipment', 'Failure', 'Family Study', 'Ferrets', 'Genes', 'Genetic', 'Genotype', 'Goals', 'Grant', 'Health Care Costs', 'Human', 'Hypertension', 'Individual', 'Language', 'Length', 'Literature', 'Malignant Neoplasms', 'Measurement', 'Measures', 'Metadata', 'Methods', 'Modeling', 'Morbidity - disease rate', 'National Cancer Institute', 'Natural Language Processing', 'Nature', 'Ontology', 'Peer Review', 'Phenotype', 'Physiological', 'Preparation', 'Protocols documentation', 'Public Health', 'Published Comment', 'Publishing', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Risk Factors', 'Sample Size', 'Scientist', 'Solutions', 'Strategic Planning', 'Structure', 'System', 'Technology', 'Time', 'Time Study', 'Vocabulary', 'Work', 'anticancer research', 'base', 'bench to bedside', 'biomedical informatics', 'cancer Biomedical Informatics Grid', 'cardiovascular disorder risk', 'data integration', 'data mining', 'data sharing', 'design', 'experience', 'graphical user interface', 'interest', 'meetings', 'mortality', 'software development', 'software systems', 'tool', 'trait', 'user-friendly', 'working group']",NHLBI,WASHINGTON UNIVERSITY,R01,2009,488000,0.11964034907954996
"Integrating Microarray and Proteomic Data by Ontology-based Annotation    DESCRIPTION (provided by applicant):       With the completion of the Human Genome Project, there is a need to translate genome-era discoveries into clinical utility. One difficulty in making bench-to-bedside translations with gene-expression and proteomic data is our current inability to relate these findings with each other and with clinical measurements. A translational researcher studying a particular biological process using microarrays or proteomics will want to gather as many relevant publicly-available data sets as possible, to compare findings. Translational investigators wanting to relate clinical or chemical data with multiple genomic or proteomic measurements will want to find and join related data sets. Unfortunately, finding and joining relevant data sets is particularly challenging today, as the useful annotations of this data are still represented only by unstructured free-text, limiting its secondary use. A question we have sought to answer is whether prior investments in biomedical ontologies can provide leverage in determining the context of genomic data in an automated manner, thereby enabling integration of gene expression and proteomic data and the secondary use of genomic data in multiple fields of research beyond those for which the data sets were originally targeted. The three specific aims to address this question are to (1) develop tools that comprehensively map contextual annotations to the largest biomedical ontology, the Unified Medical Language System (UMLS), built and supported by the National Library of Medicine, validate, and disseminate the mappings, (2) execute a four-pronged strategy to evaluate experiment-concept mappings, and (3) apply experiment-context mappings to find and integrate data within and across microarray and proteomics repositories. To keep these tools relevant to biomedical investigators, we have included three Driving Biological Projects (DBPs), in the domains of breast cancer, organ transplantation, and T-cell biology. To accomplish these DBPs, our tools and mappings will be used to find and join experimental data within and across microarray and proteomic repositories. Having DBPs to address will focus our development on a set of scalable tools that can access and analyze experimental data covering a large variety of diseases. Through our advisory committee of world-renowned NIH-funded investigators, we will ensure that our findings will have broad applicability and are useful to a wide variety of biomedical researchers.          n/a",Integrating Microarray and Proteomic Data by Ontology-based Annotation,7467204,R01LM009719,"['Address', 'Advisory Committees', 'Automobile Driving', 'Biological', 'Biological Process', 'Cells', 'Cellular biology', 'Chemicals', 'Classification', 'Clinical', 'Computer software', 'Data', 'Data Set', 'Databases', 'Detection', 'Development', 'Disease', 'Ensure', 'Funding', 'Gene Expression', 'Genetic Transcription', 'Genome', 'Genomics', 'Growth', 'Head', 'Human Genome Project', 'Improve Access', 'International', 'Investments', 'Machine Learning', 'Manuals', 'Maps', 'Measurement', 'Methods', 'Molecular Biology', 'Nature', 'Online Systems', 'Ontology', 'Organ Transplantation', 'Personal Satisfaction', 'Phenotype', 'Play', 'Process', 'Proteomics', 'Publications', 'Research', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Specificity', 'System', 'T-Lymphocyte', 'Text', 'Time', 'Today', 'Translating', 'Translations', 'Transplantation', 'Unified Medical Language System', 'United States National Institutes of Health', 'United States National Library of Medicine', 'Writing', 'base', 'bench to bedside', 'biomedical informatics', 'concept', 'improved', 'malignant breast neoplasm', 'repository', 'research study', 'text searching', 'tool', 'translational medicine']",NLM,STANFORD UNIVERSITY,R01,2008,280000,0.11264903115995172
"Ontologies and Biomedical Language Processing    DESCRIPTION (provided by applicant): We hypothesize that there are significant synergies between the applications of biomedical ontologies and of biomedical language processing (BLP) which can be used to improve the quality and scope of both activities. A growing body of work suggests such synergies might exist, but there has yet to be a systematic exploration of their potential. We propose to carry out a focused effort to explore both the potential for, and obstacles to, the mutual application of biomedical ontologies and biomedical language processing. To provide immediate biological relevance to our work, we propose to focus on the topics of autoimmune and pulmonary disease. We group our proposed explorations into three specific aims: (1) Create novel tools and approaches for the application and maintenance of biomedical ontologies, based on an assessment of the processes and tools used for the ontological annotation of textual corpora in the biomedical language processing community. Particularly, we will focus on the creation of new methods for effective search through large ontologies, compositional approaches to annotation, effective capture of the evidence underlying annotations, and the use of automated suggestions for manual confirmation. (2) Evaluate the utility of BLP tools and techniques when applied to terms and definitions of biomedical ontologies, both to enrich and interconnect orthogonal ontologies, and to provide quality assurance and quality control mechanisms. Particularly, we propose to develop and evaluate methods for connecting terms within and across ontologies, for assessing completeness of an ontology against the literature, and for implementing automatically executable measures of ontology quality. (3) Compare the differences between annotations produced by manual procedures and those produced by automated BLP methods for completeness and correctness. Based on the resulting data, produce guidelines for the optimal interplay between manual and automatic procedures for producing broad, accurate and useful knowledge-bases. Because ontologies are the central organizing tool of the model organism databases, improvements in their quality and in the ease and efficiency of their use will have a major effect on the model organism databases, speed the translational process generally, and create a potentially large public health impact.          n/a",Ontologies and Biomedical Language Processing,7502636,R01GM083649,"['Address', 'Area', 'Autoimmune Diseases', 'Autoimmune Process', 'Autoimmunity', 'Automated Annotation', 'Biological', 'Biomedical Computing', 'Body of uterus', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Elements', 'Ensure', 'Environment', 'Genes', 'Guidelines', 'Human', 'Immunology', 'Insulin-Dependent Diabetes Mellitus', 'Language', 'Linguistics', 'Literature', 'Lung diseases', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Medicine', 'Metaphor', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Motivation', 'Natural Language Processing', 'Numbers', 'Ontology', 'Peer Review', 'Procedures', 'Process', 'Process Assessment', 'Production', 'Psyche structure', 'Public Health', 'Publications', 'Pulmonary Hypertension', 'Quality Control', 'Recording of previous events', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Semantics', 'Speed', 'Suggestion', 'Techniques', 'Technology', 'Text', 'Ursidae Family', 'Validation', 'Work', 'base', 'computer science', 'computerized tools', 'concept', 'cost', 'design', 'experience', 'gene function', 'improved', 'information organization', 'innovation', 'knowledge base', 'language processing', 'model organisms databases', 'novel', 'quality assurance', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R01,2008,640921,0.25582971935576837
"Gene Ontology Consortium    DESCRIPTION (provided by applicant): Our objective is to provide the scientific community with a consistent, robust information environment for describing, sharing, integrating and comparing the functional roles of genes, proteins and functional RNAs within and across all organisms. The Gene Ontology (GO) Consortium is an international collaboration of model organism database and genome annotation groups who have joined together to establish standards for describing genomes and gene products and to provide tools and support for the consistent application of these standards for functional annotations that facilitate and enable biological research. The GO provides specific classifications including well-defined, biologically descriptive terms that are organized into specialization and part-of hierarchies for the domains of genome feature, molecular function, biological process and cellular component. The GO classifications are independent of any particular technology, an uncoupling of terminology from technology that encourages application of these semantic standards by organism annotation groups that utilize a wide range of technical environments. The GO has been widely adopted and used for representation of complex biological information for model organism genomes, and is increasingly used for the functional annotation of emerging genomes. With the increased use of the GO, the Consortium must actively work to ensure both the accuracy of the ontologies as well as consistency and quality of annotations so that these resources may be reliably used to draw inferences and make biological predictions. We will do so by focusing on four key aims: 1) We will maintain logically rigorous and biologically precise ontologies; 2) We will ensure comprehensive annotation of reference genomes, including human, using the GO; 3) We will support GO annotation efforts for emerging genomes and for those specialized sets of genes and proteins of particular community interest; and 4) We will provide annotations and tools to the research community thus supporting experimental biologists, genome informaticists, and computational biologists who are using GO annotations in their research particularly in the areas of functional genomics and comparative biology. The relevance of this work for public health is that comprehensive integration and standardization of biomedical and genomics information is an essential component of advancing the understanding of the molecular systems underlying human health and disease outcomes.             n/a",Gene Ontology Consortium,7185305,P41HG002273,"['Adopted', 'Adoption', 'Animal Model', 'Area', 'Biological', 'Biological Process', 'Biology, Other', 'Classification', 'Collaborations', 'Collection', 'Communities', 'Comparative Biology', 'Complex', 'Computer information processing', 'Data', 'Databases', 'Depth', 'Disease', 'Disease Outcome', 'EST Library', 'Ensure', 'Environment', 'Experimental Models', 'Functional RNA', 'Gene Proteins', 'Genes', 'Genome', 'Genomics', 'Goals', 'Health', 'Human', 'Information Retrieval', 'International', 'Knowledge', 'Literature', 'Methodology', 'Methods', 'Molecular', 'Natural Language Processing', 'Ontology', 'Organism', 'Proteins', 'Proteomics', 'Public Health', 'Purpose', 'Range', 'Relative (related person)', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Role', 'Semantics', 'Standardization', 'Standards of Weights and Measures', 'Structure', 'System', 'Technology', 'Terminology', 'Translating', 'Work', 'base', 'biological research', 'comparative', 'functional genomics', 'genetic element', 'genome database', 'human disease', 'interest', 'model organisms databases', 'repository', 'size', 'tool']",NHGRI,JACKSON LABORATORY,P41,2007,3146180,0.16049849628765347
"A Resource for Biomedical Ontologies and Knowledge Bases    DESCRIPTION (provided by applicant):       For more than two decades, our laboratory has been studying technology to develop, manage, and use formal descriptions of biomedical concepts. The result of this work is Protege, a workbench that allows users to edit and apply controlled terminologies, ontologies, and knowledge bases to a wide range of information-management problems. To date, more than 50,000 people have registered as users of the system. Many diverse projects in biomedicine-supported by nearly every institute and center at NIH-have become critically dependent on this software and the knowledge-engineering principles that it supports. This P41 competing renewal application seeks to continue support for Protege, as a biomedical informatics resource that will benefit the system's entire user community.      We propose technology research and development to expand the capabilities of the Protege system to meet the current and anticipated needs of the user community. We will re-engineer Protege with a service-oriented architecture that can adapt to the requirements of new ontology languages, large ontology repositories, and cutting-edge ontology-management-services, such as reasoning, alignment, and evolution. We will create support for collaborative ontology development, in the context of both large, centralized projects and open, decentralized efforts. We also will develop advanced support for using ontologies in application software development and as integral parts of software systems.      As a biomedical informatics resource, we will expand our collaborative research projects with other Prot¿g¿ users. We will provide service to the Protege user community through enhanced technical support, user documentation, tutorials, and workshops. These activities will serve to disseminate information about the resource and will aid research and development in many aspects of biomedical informatics both in the United States and internationally.          n/a",A Resource for Biomedical Ontologies and Knowledge Bases,7475421,P41LM007885,"['Address', 'Adopted', 'Anatomy', 'Applications Grants', 'Architecture', 'Area', 'Biomedical Computing', 'Biomedical Technology', 'Class', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data Set', 'Development', 'Documentation', 'Educational workshop', 'Electronics', 'Engineering', 'Ensure', 'Environment', 'Evolution', 'Facility Construction Funding Category', 'Foundations', 'Funding', 'Generic Drugs', 'Genes', 'Goals', 'Grant', 'Guidelines', 'Information Management', 'Institutes', 'International', 'Knowledge', 'Laboratories', 'Language', 'Mails', 'Maintenance', 'Modeling', 'Natural Language Processing', 'Numbers', 'Ontology', 'Participant', 'Process', 'Published Comment', 'Range', 'Representations, Knowledge (Computer)', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Resources', 'Semantics', 'Services', 'Software Engineering', 'Strigiformes', 'System', 'Technology', 'Terminology', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'biomedical informatics', 'biomedical resource', 'concept', 'design', 'information organization', 'innovation', 'knowledge base', 'member', 'next generation', 'open source', 'repository', 'research and development', 'size', 'software development', 'software systems', 'symposium', 'tool']",NLM,STANFORD UNIVERSITY,P41,2007,160000,0.21807289708921987
"A Resource for Biomedical Ontologies and Knowledge Bases    DESCRIPTION (provided by applicant):       For more than two decades, our laboratory has been studying technology to develop, manage, and use formal descriptions of biomedical concepts. The result of this work is Protege, a workbench that allows users to edit and apply controlled terminologies, ontologies, and knowledge bases to a wide range of information-management problems. To date, more than 50,000 people have registered as users of the system. Many diverse projects in biomedicine-supported by nearly every institute and center at NIH-have become critically dependent on this software and the knowledge-engineering principles that it supports. This P41 competing renewal application seeks to continue support for Protege, as a biomedical informatics resource that will benefit the system's entire user community.      We propose technology research and development to expand the capabilities of the Protege system to meet the current and anticipated needs of the user community. We will re-engineer Protege with a service-oriented architecture that can adapt to the requirements of new ontology languages, large ontology repositories, and cutting-edge ontology-management-services, such as reasoning, alignment, and evolution. We will create support for collaborative ontology development, in the context of both large, centralized projects and open, decentralized efforts. We also will develop advanced support for using ontologies in application software development and as integral parts of software systems.      As a biomedical informatics resource, we will expand our collaborative research projects with other Prot¿g¿ users. We will provide service to the Protege user community through enhanced technical support, user documentation, tutorials, and workshops. These activities will serve to disseminate information about the resource and will aid research and development in many aspects of biomedical informatics both in the United States and internationally.          n/a",A Resource for Biomedical Ontologies and Knowledge Bases,7248464,P41LM007885,"['Address', 'Adopted', 'Anatomy', 'Applications Grants', 'Architecture', 'Area', 'Biomedical Computing', 'Biomedical Technology', 'Class', 'Clinical', 'Code', 'Communities', 'Complex', 'Computer software', 'Data Set', 'Development', 'Documentation', 'Educational workshop', 'Electronics', 'Engineering', 'Ensure', 'Environment', 'Evolution', 'Facility Construction Funding Category', 'Foundations', 'Funding', 'Generic Drugs', 'Genes', 'Goals', 'Grant', 'Guidelines', 'Information Management', 'Institutes', 'International', 'Knowledge', 'Laboratories', 'Language', 'Mails', 'Maintenance', 'Modeling', 'Natural Language Processing', 'Numbers', 'Ontology', 'Participant', 'Process', 'Published Comment', 'Range', 'Representations, Knowledge (Computer)', 'Research', 'Research Infrastructure', 'Research Project Grants', 'Resources', 'Semantics', 'Services', 'Software Engineering', 'Strigiformes', 'System', 'Technology', 'Terminology', 'Time', 'Training', 'United States', 'United States National Institutes of Health', 'Work', 'Writing', 'base', 'biomedical informatics', 'biomedical resource', 'concept', 'design', 'information organization', 'innovation', 'knowledge base', 'member', 'next generation', 'open source', 'repository', 'research and development', 'size', 'software development', 'software systems', 'symposium', 'tool']",NLM,STANFORD UNIVERSITY,P41,2007,693808,0.21807289708921987
"Ontologies and Biomedical Language Processing    DESCRIPTION (provided by applicant): We hypothesize that there are significant synergies between the applications of biomedical ontologies and of biomedical language processing (BLP) which can be used to improve the quality and scope of both activities. A growing body of work suggests such synergies might exist, but there has yet to be a systematic exploration of their potential. We propose to carry out a focused effort to explore both the potential for, and obstacles to, the mutual application of biomedical ontologies and biomedical language processing. To provide immediate biological relevance to our work, we propose to focus on the topics of autoimmune and pulmonary disease. We group our proposed explorations into three specific aims: (1) Create novel tools and approaches for the application and maintenance of biomedical ontologies, based on an assessment of the processes and tools used for the ontological annotation of textual corpora in the biomedical language processing community. Particularly, we will focus on the creation of new methods for effective search through large ontologies, compositional approaches to annotation, effective capture of the evidence underlying annotations, and the use of automated suggestions for manual confirmation. (2) Evaluate the utility of BLP tools and techniques when applied to terms and definitions of biomedical ontologies, both to enrich and interconnect orthogonal ontologies, and to provide quality assurance and quality control mechanisms. Particularly, we propose to develop and evaluate methods for connecting terms within and across ontologies, for assessing completeness of an ontology against the literature, and for implementing automatically executable measures of ontology quality. (3) Compare the differences between annotations produced by manual procedures and those produced by automated BLP methods for completeness and correctness. Based on the resulting data, produce guidelines for the optimal interplay between manual and automatic procedures for producing broad, accurate and useful knowledge-bases. Because ontologies are the central organizing tool of the model organism databases, improvements in their quality and in the ease and efficiency of their use will have a major effect on the model organism databases, speed the translational process generally, and create a potentially large public health impact.          n/a",Ontologies and Biomedical Language Processing,7364235,R01GM083649,"['Address', 'Area', 'Autoimmune Diseases', 'Autoimmune Process', 'Autoimmunity', 'Automated Annotation', 'Biological', 'Biomedical Computing', 'Body of uterus', 'Classification', 'Collaborations', 'Communities', 'Complex', 'Data', 'Development', 'Elements', 'Ensure', 'Environment', 'Genes', 'Guidelines', 'Human', 'Immunology', 'Insulin-Dependent Diabetes Mellitus', 'Language', 'Linguistics', 'Literature', 'Lung diseases', 'Maintenance', 'Manuals', 'Maps', 'Measures', 'Medicine', 'Metaphor', 'Methods', 'Mission', 'Modeling', 'Molecular', 'Motivation', 'Natural Language Processing', 'Numbers', 'Ontology', 'Peer Review', 'Procedures', 'Process', 'Process Assessment', 'Production', 'Psyche structure', 'Public Health', 'Publications', 'Pulmonary Hypertension', 'Quality Control', 'Recording of previous events', 'Representations, Knowledge (Computer)', 'Research', 'Research Personnel', 'Rheumatoid Arthritis', 'Role', 'Semantics', 'Speed', 'Suggestion', 'Techniques', 'Technology', 'Text', 'Ursidae Family', 'Validation', 'Work', 'base', 'computer science', 'computerized tools', 'concept', 'cost', 'design', 'experience', 'gene function', 'improved', 'information organization', 'innovation', 'knowledge base', 'language processing', 'model organisms databases', 'novel', 'quality assurance', 'tool']",NIGMS,UNIVERSITY OF COLORADO DENVER,R01,2007,631600,0.25582971935576837
"Biomedical Ontology and Tools for Database Curation DESCRIPTION (provided by applicant): This proposal describes a new tool for text data mining-a biomedical language ontology and integrated natural-language-processing methods. Our long-term goal is to provide resources for biomedical knowledge discovery from text. Our immediate goal is to provide a knowledge discovery tool for the curation of organism databases such as the Genome Database (SGD). The proposed research not only serves the research needs of the SGD community, it also helps the broader biomedical community exploit the strengths of the comparative approach to biological research. The hypothesis of this proposal is that knowledge discovery from biomedical text requires a knowledge base that integrates both genomic and linguistic information. This hypothesis is based on two observations: (a) the language of biomedicine, like all natural language, is complex in structure and morphology (the basic units of meaning) and poses problems of synonymy (several terms having the same meaning), polysemy (a term having more than one meaning), hypernymy (one term being more general than another), hyponymy (one term being more specific than another), denotation (what a term refers to in contrast to what it means), and denotation and description (different ways of referring to the same thing); and (b) important biomedical knowledge sources, such as the Gene Ontology (GO), are expressed in natural language. The specific aims of the proposed project are to: 1. Extend an existing biomedical language ontology to include genomic and linguistic data from SGD; 2. Use this ontology to discover, in full-text articles made available by SGD, information about the molecular function of yeast gene products that can be inferred from direct experimental assays; 3. Evaluate the effectiveness of the new tool and methods by comparing its results to those of the SGD curators for gene products that have GO functional annotations with evidence code IDA (Inferred from Direct Assay). n/a",Biomedical Ontology and Tools for Database Curation,6885487,R43HG003600,"['computer program /software', 'computer system design /evaluation', 'fungal genetics', 'information retrieval', 'information system analysis', 'molecular biology information system', 'yeasts']",NHGRI,"CONVERSPEECH, LLC",R43,2005,99250,0.11655132007787765
"Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols Project Summary Biological assays are the foundation for developing chemical probes and drugs, but new Big Data approaches – which have revolutionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that scientists specify their assays through text descriptions written in scientific English, which need to be translated into standardized annotations readable by computers. This lack of standardized and machine-readable assay descriptions is a major impediment to manage, find, aggregate, compare, re-use, and learn from the ever-growing corpus of assays (e.g., >1.2 million in PubChem). Thus, there is a critical need for better annotation and curation tools for drug discovery assays. However, the process to go from a simple text protocol to highly detailed machine-readable semantic annotations is not trivial. Multiple tools and technologies are required: ontologies or the structured controlled vocabularies; templates that map specific vocabularies to properties that are to be captured; and software tools to actually apply these ontologies to a given text. Currently, each of these exists in isolation; yet, a bottleneck in any one tool or technology, or a gap between the different pieces, disrupts the overall process, resulting in poor or no annotation of the datasets. Here we propose a project to combine and integrate these three technologies (which are also the core competencies of the three groups collaborating on this proposal). We will deliver a novel, comprehensive, user-friendly data annotation and curation system that is highly interconnected, encompassing the full cycle, and real-world practice, of required tasks and decisions, by all parties within the `bioassay annotation ecosystem' (researchers performing curation, dedicated curators, IT specialists, ontology owners, and librarians/repositories). The alliance between academic and commercial collaborators, who already work together, will greatly benefit the project and minimize execution risk. Our specific aims are to: (1) Develop a bioassay-specific template editor and templates by adopting the Stanford (Center for Expanded Data Annotation and Retrieval, CEDAR) data model to the machine learning-based curation tool BioAssay Express, to exploit the broad functionality of its data structures, tools and interfaces; (2) Define and create an ontology update process and tool (`OntoloBridge') to support rapid feedback between curators/users and ontology experts and enable semi-automated incorporation of suggestions for updates to existing published ontologies; (3) Develop new tools to export annotated data into public repositories such as PubChem; and (4) Evaluate our solution across diverse audiences (pharma, academia, repositories). The system will improve bioassay curation efficiency, quality, and effectiveness, enabling scientists to generate standardized annotations for their experiments to make these data FAIR (Findable, Accessible, Interoperable, Reusable). We envision this suite of tools will encourage annotation earlier in the data lifecycle while still supporting annotation at later stages (e.g., submission to repositories or to journals). Project Narrative Biological assays are the foundation for developing drugs, but new Big Data approaches – which have revolu- tionized other areas of biomedical science – have not yet advanced this early step of biomedical research: analysis of assay data. The obstacle is that assays are written in scientific English, which need to be translated into standardized descriptions readable by computers. This lack of machine-readable annotations is a major impediment to manage, find, compare, re-use, and learn from the millions of assays. This project will develop a formal process and integrated tools to support the complete cycle of tasks and decisions required for bioassay annotation, enabling expedited (and more cost-effective) drug discovery.","Unifying Templates, Ontologies and Tools to Achieve Effective Annotation of Bioassay Protocols",9979969,U01LM012630,"['Academia', 'Address', 'Adopted', 'Adoption', 'Area', 'Big Data', 'Big Data Methods', 'Biological Assay', 'Biomedical Research', 'Chemicals', 'Communication', 'Communities', 'Competence', 'Complex', 'Computer software', 'Computers', 'Controlled Vocabulary', 'Custom', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Ecosystem', 'Effectiveness', 'Elements', 'Ensure', 'Estrogen receptor positive', 'Exercise', 'FAIR principles', 'Feedback', 'Foundations', 'Hour', 'Journals', 'Learning', 'Librarians', 'Machine Learning', 'Manuals', 'Maps', 'Metadata', 'Ontology', 'Output', 'Participant', 'Pharmaceutical Preparations', 'Polishes', 'Problem Solving', 'Process', 'Property', 'Protocols documentation', 'PubChem', 'Publishing', 'Readability', 'Research', 'Research Personnel', 'Retrieval', 'Risk', 'Science', 'Scientist', 'Semantics', 'Site', 'Software Engineering', 'Software Tools', 'Specialist', 'Specific qualifier value', 'Standardization', 'Structure', 'Suggestion', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Translating', 'Tweens', 'Update', 'Vocabulary', 'Work', 'base', 'cost effective', 'data modeling', 'data standards', 'design', 'drug discovery', 'drug mechanism', 'experience', 'experimental study', 'improved', 'improved functioning', 'in vivo', 'informatics training', 'novel', 'ontology development', 'open source', 'practical application', 'predictive modeling', 'public repository', 'repository', 'structured data', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,U01,2020,511367,0.1645377237314936
"Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences Project Abstract The engineering of ontologies that define the entities in an application area and the relationships among them has become essential for modern work in biomedicine. Ontologies help both humans and computers to manage burgeoning numbers of data. The need to annotate, retrieve, and integrate high- throughput data sets, to process natural language, and to build systems for decision support has set many communities of investigators to work building large ontologies. The Protégé system has become an indispensable open-source resource for an enormous international community of scientists—supporting the development, maintenance, and use of ontologies and electronic knowledge bases by biomedical investigators everywhere. The number of registered Protégé users has grown from 3,500 in 2002 to more than 300,000 users as of this writing. The widespread use of ontologies in biomedicine and the availability of tools, such as Protégé, have taken the biomedical field forward to a new set of challenges that current technology has not been designed to address: Biomedical ontologies have grown in size and scope, and their creation, maintenance and quality assurance have become particularly effort-intensive and error-prone. In this proposal, we will develop new methods and tools that will significantly aid biomedical researchers in easily creating and testing biomedical ontologies throughout their lifecycle. Our plan entails four specific aims. First, we will develop methods and tools to allow biomedical scientist to easily create ontologies directly from their source documents, such as spreadsheets, tab indented hierarchies, and document outlines. Second, we will provide the methods and tools to allow biomedical scientist to identify potential “hot spots” in their ontologies that might affect their quality. Third, we will implement a comprehensive, automated testing framework for ontologies that will assist biomedical researchers in performing ontology and data quality assurance throughout the development cycle. Fourth, we will continue to expand and support the thriving Protégé user community, as it grows to include new clinicians and biomedical scientists as they build the ontologies needed to support clinical care, data-driven research, and the elucidation of new discoveries. Project Narrative Protégé is a software system that helps a burgeoning user community to develop ontologies that enhance biomedical research and improve patient care. Protégé supports scientists, clinician researchers, and workers in informatics in data annotation, data integration, information retrieval, natural-language processing, electronic patient record systems, and decision-support systems. The Protégé resource provides critical semantic-technology infrastructure and expertise for biomedical research and the development of advanced clinical information systems.",Protege: A Knowledge-Engineering Environment for Advancing Biomedical Sciences,9848600,R01GM121724,"['Address', 'Adopted', 'Advanced Development', 'Affect', 'Applications Grants', 'Area', 'Biomedical Research', 'Clinical', 'Communities', 'Computer software', 'Computerized Patient Records', 'Computers', 'Data', 'Data Set', 'Data Sources', 'Decision Support Systems', 'Development', 'Education and Outreach', 'Engineering', 'Ensure', 'Environment', 'Foundations', 'Goals', 'Head', 'Hot Spot', 'Human', 'Informatics', 'Information Retrieval', 'Information Systems', 'Infrastructure', 'International', 'Investigation', 'Knowledge', 'Knowledge Discovery', 'Letters', 'Maintenance', 'Manuals', 'Methods', 'Modernization', 'Natural Language Processing', 'Ontology', 'Patient Care', 'Process', 'Publications', 'Research', 'Research Personnel', 'Resources', 'Science', 'Scientist', 'Semantics', 'Source', 'System', 'Technology', 'Terminology', 'Testing', 'Time', 'Update', 'Work', 'Writing', 'biomedical ontology', 'biomedical scientist', 'clinical care', 'data integration', 'data quality', 'data sharing', 'design', 'document outlines', 'improved', 'innovation', 'interoperability', 'knowledge base', 'large datasets', 'natural language', 'next generation', 'ontology development', 'open source', 'quality assurance', 'software systems', 'tool']",NIGMS,STANFORD UNIVERSITY,R01,2020,559088,0.3038083073865155
