text,title,id,project_number,terms,administration,organization,mechanism,year,funding,score
"Optimization and joint modeling for peptide detection by tandem mass spectrometry Project Summary/Abstract Proteins are the primary functional molecules in living cells, and tandem mass spectrometry provides the most efﬁcient means of studying proteins in a high-throughput fashion. The proposal aims to use state-of-the-art methods from the ﬁelds of machine learning, statistics, and natural language processing to improve our ability to make sense of large tandem mass spectrometry data sets. Our project will focus on three key problems in the analysis of such data: 1. facilitating the use of previously annotated spectra to improve our ability to annotate new spectra by creating  a hybrid search scheme that compares an observed spectrum to a database comprised of theoretical spectra  and previously annotated spectra, 2. enabling the efﬁcient and accurate detection of peptides containing post-translational modiﬁcations and  sequence variants, and 3. detecting sets of peptide species that are co-fragmented in the mass spectrometer and hence give rise to  complex, mixture spectra. Each of these aims will improve the ability of mass spectrometrists to efﬁciently and accurately identify and quantify proteins in complex mixtures. To increase the impact of our work, we will continue to make all of our tools available as free software. Project narrative The applications of mass spectrometry, and its promises for improvements of human health, are numerous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and speciﬁc diagnostic and prognostic screens. However, making optimal use of mass spectrometry data requires sophisticated computational methods. This project will develop and apply novel statistical and machine learning methods for interpreting mass spectra.",Optimization and joint modeling for peptide detection by tandem mass spectrometry,9627997,R01GM121818,"['Algorithms', 'Amino Acid Sequence', 'Automobile Driving', 'Bayesian Network', 'Biological', 'Cells', 'Collection', 'Column Chromatography', 'Communities', 'Complex', 'Complex Mixtures', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Discipline', 'Economics', 'Fertilization', 'Game Theory', 'Health', 'Human', 'Hybrids', 'Joints', 'Libraries', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Natural Language Processing', 'Operations Research', 'Peptides', 'Population', 'Post-Translational Protein Processing', 'Proteins', 'Proteomics', 'Protocols documentation', 'Sampling', 'Scheme', 'Shotguns', 'Speed', 'Statistical Models', 'Time', 'Variant', 'Work', 'computerized tools', 'cost', 'disease phenotype', 'experimental study', 'improved', 'innovation', 'learning strategy', 'mass spectrometer', 'mathematical theory', 'novel', 'prognostic', 'protein aminoacid sequence', 'speech recognition', 'statistics', 'tandem mass spectrometry', 'theories', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2019,315830,0.08260694832740166
"Binding-Site Modeling with Multiple-Instance Machine-Learning Project Summary / Abstract This proposal is entitled “Binding-Site Modeling with Multiple-Instance Machine-Learning.” A number of in- terrelated computational methods for making predictions about the biological behavior of small molecules have been the subject of development within the Jain Laboratory for over twenty years. These share a common strat- egy that considers molecular interactions at their surface interface, where proteins and ligands actually interact. These methods yield measurements of similarity between small molecules or between protein binding pockets. They also yield measurements of the complementarity of a small molecule to a protein binding site (the molecular docking problem). A generalization of these concepts makes possible the construction of a virtual binding site for quantitative activity prediction purely from data about the biological activities of a set of small molecules.  The goals of the proposed work include further improving the accuracy and breadth of applicability of the binding site modeling approach. The primary application of the approach is to guide optimization of leads within medicinal chemistry projects, and to quantify potential off-target effects during pre-clinical drug discovery.  A critical focus of the work will be in data and software dissemination, in order to accelerate the efficient development of targeted therapies. In addition to methods development, the proposed work will involve broad application of these state-of-the-art predictive modeling methods. The proposed work will proceed with the col- laborative input of our pharmaceutical industry colleagues, who have specialized knowledge and data sets that are vital for cutting-edge work in computer-aided drug design.  The expected results include more efficient lead optimization (fewer compounds to reach desired biological pa- rameters), truly effective scaffold replacement (to move away from a molecular series with biological limitations), and improved computational predictions of off-target effects during pre-clinical drug design. Project Narrative This project seeks to refine an integrated platform for physically realistic prediction of ligand binding affinities using multiple methods that span small molecule molecular similarity, molecular docking, and protein binding site similarity. These tools will provide predictive modeling unrestrained by scaffold congruence between what is known and what is to be predicted. Prediction of bioactive molecular poses and activities to guide lead optimiza- tion and to quantify off-target liability effects are applications of the effort, and data and software will be made widely available to academic and industrial research groups.",Binding-Site Modeling with Multiple-Instance Machine-Learning,9670817,R01GM101689,"['3-Dimensional', 'Address', 'Affinity', 'Behavior', 'Binding', 'Binding Proteins', 'Binding Sites', 'Biological', 'Biological Assay', 'Characteristics', 'Charge', 'Chemicals', 'Computer Assisted', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Development', 'Docking', 'Drug Design', 'Drug Industry', 'Electrostatics', 'Formulation', 'Future', 'Goals', 'Hydrogen Bonding', 'Industrialization', 'Industry Collaboration', 'Knowledge', 'Laboratories', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Probes', 'Performance', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Physics', 'Positioning Attribute', 'Procedures', 'Protein Conformation', 'Proteins', 'Research', 'Series', 'Structural Models', 'Structural Protein', 'Surface', 'Testing', 'Variant', 'Work', 'base', 'blind', 'combinatorial', 'design', 'drug discovery', 'improved', 'interest', 'lead optimization', 'learning strategy', 'method development', 'novel', 'novel strategies', 'physical model', 'pre-clinical', 'predictive modeling', 'protein structure', 'scaffold', 'segregation', 'small molecule', 'targeted treatment', 'tool', 'treatment fees', 'virtual']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2019,310202,-0.019086843016794093
"Computational Techniques for Advancing Untargeted Metabolomics Analysis PROJECT SUMMARY/ABSTRACT Detecting and quantifying products of cellular metabolism using mass spectrometry (MS) has already shown great promise in biomarker discovery, nutritional analysis and other biomedical research fields. Despite recent advances in analysis techniques, our ability to interpret MS measurements remains limited. The biggest challenge in metabolomics is annotation, where measured compounds are assigned chemical identities. The annotation rates of current computational tools are low. For several surveyed metabolomics studies, less than 20% of all compounds are annotated. Another contributing factor to low annotation rates is the lack of systematic ways of designing a candidate set, a listing of putative chemical identities that can be used during annotation. Relying on exiting databases is problematic as considering the large combinatorial space of molecular arrangements, there are many biologically relevant compounds not catalogued in databases or documented in the literature. A secondary yet important challenge is interpreting the measurements to understand the metabolic activity of the sample under study. Current techniques are limited in utilizing complex information about the sample to elucidate metabolic activity. The goal of this project is to develop computational techniques to advance the interpretation of large-scale metabolomics measurements. To address current challenges, we propose to pursue three Aims: (1) Engineering candidate sets that enhance biological discovery. (2) Developing new techniques for annotation including using deep learning and incremental build out methods to recommend novel chemical structures that best explain the measurements. (3) Constructing probabilistic models to analyze metabolic activity. Each technique will be rigorously validated computationally and experimentally using chemical standards. Two detailed case studies on the intestinal microbiota will allow us to further validate our tools. Microbiota-derived metabolites have been detected in circulation and shown to engage host cellular pathways in organs and tissues beyond the digestive system. Identifying these metabolites is thus critical for understanding the metabolic function of the microbiota and elucidating their mechanisms. The complex test cases will challenge our techniques, provide feedback during development, and allow us to further disseminate our techniques. We will work closely with early adopters of our tools, as proposed in supporting letters, to further validate our tools and encourage wide adoption. All proposed tools will be open source and made accessible through the web. Our tools promise to change current practices in interpreting metabolomics data beyond what is currently possible with databases, current annotation tools, statistical and overrepresentation analysis, or combinations thereof. The use of machine learning and large data sets as proposed herein defines the most promising research direction in metabolomics analysis. PROJECT NARRATIVE  Untargeted Metabolomics is a recently developed technique that allows the measurement of thousands of molecules in a biological sample. This work proposes several novel computational techniques that address limitations of current metabolomics analysis tools. We anticipate that this work will advance discoveries in biomedical research and have direct benefits to human health.",Computational Techniques for Advancing Untargeted Metabolomics Analysis,9886611,R01GM132391,"['Address', 'Adoption', 'Biological', 'Biomedical Research', 'Blood Circulation', 'Case Study', 'Chemical Structure', 'Chemicals', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Engineering', 'Ensure', 'Feedback', 'Goals', 'Health', 'Human', 'Internet', 'Intestines', 'Label', 'Letters', 'Literature', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Medical', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Nutritional', 'Organ', 'Pathway interactions', 'Performance', 'Play', 'Probability', 'Property', 'PubChem', 'PubMed', 'Public Domains', 'Research', 'Research Personnel', 'Role', 'Running', 'Sampling', 'Statistical Models', 'Structure', 'Subject Headings', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Uncertainty', 'Validation', 'Work', 'annotation  system', 'base', 'biomarker discovery', 'chemical standard', 'combinatorial', 'computerized tools', 'cost', 'dark matter', 'deep learning', 'design', 'drug development', 'drug discovery', 'experimental study', 'gastrointestinal system', 'gut microbiota', 'interest', 'metabolome', 'metabolomics', 'microbiota', 'microbiota metabolites', 'neural network', 'novel', 'nutrition', 'open source', 'physical property', 'small molecule', 'tool']",NIGMS,TUFTS UNIVERSITY MEDFORD,R01,2019,379614,0.040990191105938524
"Feature Learning For Improved Multiplex Disease Diagnosis Abstract This proposal is for CATTS, a feature learning technique optimized for use in multiplex mass spectrometry (MS) fingerprinting assays. MS fingerprints consist of a large number of chemical species, leading to very high dimensional feature spaces, and subsequent high false-discovery rates. CATTS aims to reduce the size of this space, by using knowledge of the underlying biochemistry, as well as general-purpose clustering algorithms. Our preliminary results demonstrate that, when used as a feature-learning technique for a variety of classification methods, CATTS significantly improves assay sensitivity. This proposal takes our existing implementation of CATTS and extends it to support additional feature learning algorithms and classification methods. Additionally, its performance as a multiplex assay strategy will be tested on both protein and lipid MS fingerprint libraries, with an eye towards commercialization.. Relevance to public health: The detection of pathogens via mass spectroscopy fingerprinting is rapidly becoming a standard technique for clinical microbiology. However, high false detection rates and conflicting multiple identifications limit applicability, and make interpretation of results difficult. Our work on CATTS aims to improve the statistical performance of these assays. Preliminary results from studies on one dataset we intend to apply CATTS to suggest that UTIs and, in some cases antimicrobial resistance, can be detected, directly from patient samples. However, the statistical methods currently employed aren't reliable enough - the further development of CATTS will accelerate the development of this, and other mass-spectroscopy-based assays..",Feature Learning For Improved Multiplex Disease Diagnosis,9813280,R43GM128538,"['Algorithms', 'Antimicrobial Resistance', 'Biochemistry', 'Biodiversity', 'Biological Assay', 'Chemicals', 'Classification', 'Clinical Microbiology', 'Conflict (Psychology)', 'Data Set', 'Decision Trees', 'Detection', 'Development', 'Dimensions', 'Eye', 'Fingerprint', 'Immune', 'Knowledge', 'Learning', 'Libraries', 'Lipids', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Modeling', 'Noise', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Process', 'Protein Fingerprints', 'Proteins', 'Public Health', 'Reporting', 'Research', 'Sampling', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Testing', 'Work', 'base', 'commercialization', 'disease diagnosis', 'feeding', 'high dimensionality', 'improved', 'learning algorithm', 'learning strategy', 'neural network', 'novel', 'random forest', 'vector']",NIGMS,"DEURION, LLC",R43,2019,14770,0.027801138347844256
"Feature Learning For Improved Multiplex Disease Diagnosis Abstract This proposal is for CATTS, a feature learning technique optimized for use in multiplex mass spectrometry (MS) fingerprinting assays. MS fingerprints consist of a large number of chemical species, leading to very high dimensional feature spaces, and subsequent high false-discovery rates. CATTS aims to reduce the size of this space, by using knowledge of the underlying biochemistry, as well as general-purpose clustering algorithms. Our preliminary results demonstrate that, when used as a feature-learning technique for a variety of classification methods, CATTS significantly improves assay sensitivity. This proposal takes our existing implementation of CATTS and extends it to support additional feature learning algorithms and classification methods. Additionally, its performance as a multiplex assay strategy will be tested on both protein and lipid MS fingerprint libraries, with an eye towards commercialization.. Relevance to public health: The detection of pathogens via mass spectroscopy fingerprinting is rapidly becoming a standard technique for clinical microbiology. However, high false detection rates and conflicting multiple identifications limit applicability, and make interpretation of results difficult. Our work on CATTS aims to improve the statistical performance of these assays. Preliminary results from studies on one dataset we intend to apply CATTS to suggest that UTIs and, in some cases antimicrobial resistance, can be detected, directly from patient samples. However, the statistical methods currently employed aren't reliable enough - the further development of CATTS will accelerate the development of this, and other mass-spectroscopy-based assays..",Feature Learning For Improved Multiplex Disease Diagnosis,9813275,R43GM128538,"['Algorithms', 'Antimicrobial Resistance', 'Biochemistry', 'Biodiversity', 'Biological Assay', 'Chemicals', 'Classification', 'Clinical Microbiology', 'Conflict (Psychology)', 'Data Set', 'Decision Trees', 'Detection', 'Development', 'Dimensions', 'Eye', 'Fingerprint', 'Immune', 'Knowledge', 'Learning', 'Libraries', 'Lipids', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Modeling', 'Noise', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Process', 'Protein Fingerprints', 'Proteins', 'Public Health', 'Reporting', 'Research', 'Sampling', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Testing', 'Work', 'base', 'commercialization', 'disease diagnosis', 'feeding', 'high dimensionality', 'improved', 'learning algorithm', 'learning strategy', 'neural network', 'novel', 'random forest', 'vector']",NIGMS,"DEURION, LLC",R43,2019,25298,0.027801138347844256
"Computational Explorations of Unconventional Approaches to Control Noncovalent Interactions PROJECT SUMMARY The research interests of my group are rooted in explorations of new and useful conceptual models to improve the control and prediction of noncovalent interactions. Our research involves the use of a variety of computational quantum chemical tools, applications of density functional theory (DFT), cheminformatics, and machine-learning methods. A premise of our research is that aromaticity may be used to modulate many types of noncovalent interactions (such as hydrogen bonding, π-stacking, anion-π interactions). The reciprocal relationship we find, between “aromaticity” in molecules and the strengths of “noncovalent interactions,” is surprising especially since they are typically considered as largely separate ideas in chemistry. The innovation of this research is that it will enable use of intuitive “back-of-the-envelope” electron-counting rules (such as the 4n+2πe Hückel rule for aromaticity) to make predictions of experimental outcomes regarding the impact of noncovalent interactions. A five-year goal is to realize the use of our conceptual models in real synthetic examples prepared by our experimental collaborators. My research vision is to bridge discoveries of innovative concepts to their practical impacts for biomedical and biomolecular research. PROJECT NARRATIVE This research proposal includes four projects that are jointly motivated by the challenge to control and predict noncovalent interactions in organic and biomolecular systems. The proposed work involves applications of a variety of computational quantum chemical tools and synergistic investigations with experimental collaborators. We seek to identify new and useful concepts to guide experimental designs of novel “non-natural” molecular systems (e.g., receptors, biosensors, and hydrogels) that have potential biomedical applications.",Computational Explorations of Unconventional Approaches to Control Noncovalent Interactions,9798401,R35GM133548,"['Anions', 'Back', 'Biosensor', 'Chemicals', 'Chemistry', 'Electrons', 'Experimental Designs', 'Goals', 'Hydrogels', 'Hydrogen Bonding', 'Intuition', 'Investigation', 'Machine Learning', 'Modeling', 'Molecular', 'Outcome', 'Plant Roots', 'Research', 'Research Project Summaries', 'Research Proposals', 'System', 'Vision', 'Work', 'cheminformatics', 'density', 'improved', 'innovation', 'interest', 'learning strategy', 'novel', 'quantum computing', 'receptor', 'theories', 'tool']",NIGMS,UNIVERSITY OF HOUSTON,R35,2019,377200,0.010046824572802579
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9806367,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2019,184118,0.0069600633639773975
"Machine Learning Tools for Discovery and Analysis of Active Metabolic Pathways ﻿    DESCRIPTION (provided by applicant): This project aims to develop new statistical machine learning methods for metabolomics data from diverse platforms, including targeted and unbiased/global mass spectrometry (MS), labeled MS experiments for measuring metabolic ﬂux and Nuclear Magnetic Resonance (NMR) platforms. Unbiased MS and NMR proﬁling studies result in identifying a large number of unnamed spectra, which cannot be directly matched to known metabolites and are hence often discarded in downstream analyses. The ﬁrst aim develops a novel kernel penalized regression method for analysis of data from unbiased proﬁling studies. It provides a systematic framework for extracting the relevant information from unnamed spectra through a kernel that highlights the similarities and differences between samples, and in turn boosts the signal from named metabolites. This results in improved power in identiﬁcation of named metabolites associated with the phenotype of interest, as well as improved prediction accuracy. An extension of this kernel-based framework is also proposed to allow for systematic integration of metabolomics data from diverse proﬁling studies, e.g. targeted and unbiased MS proﬁling technologies. The second aim pro- vides a formal inference framework for kernel penalized regression and thus complements the discovery phase of the ﬁrst aim. The third aim focuses on metabolic pathway enrichment analysis that tests both orchestrated changes in activities of steady state metabolites in a given pathway, as well as aberrations in the mechanisms of metabolic reactions. The fourth aim of the project provides a uniﬁed framework for network-based integrative analysis of static (based on mass spectrometry) and dynamic (based on metabolic ﬂux) metabolomics measurements, thus providing an integrated view of the metabolome and the ﬂuxome. Finally, the last aim implements the pro- posed methods in easy-to-use open-source software leveraging the R language, the capabilities of the Cytoscape platform and the Galaxy workﬂow system, thus providing an expandable platform for further developments in the area of metabolomics. The proposed software tool will also provide a plug-in to the Data Repository and Coordination Center (DRCC) data sets, where all regional metabolomics centers supported by the NIH Common Funds Metabolomics Program deposit curated data. PUBLIC HEALTH RELEVANCE: Metabolomics, i.e. the study of small molecules involved in metabolism, provides a dynamic view into processes that reﬂect the actual physiology of the cell, and hence offers vast potential for detection of novel biomarkers and targeted therapies for complex diseases. However, despite this potential, the development of computational methods for analysis of metabolomics data lags the rapid growth of metabolomics proﬁling technologies. The current application addresses this need by developing novel statistical machine learning methods for integrative analysis of static and dynamic metabolomics measurements, as well as easy-to-use open-source software to facilitate the application of these methods.",Machine Learning Tools for Discovery and Analysis of Active Metabolic Pathways,9667435,R01GM114029,"['Address', 'Adoption', 'Anabolism', 'Area', 'Biochemical Pathway', 'Biochemical Reaction', 'Biological', 'Biological Assay', 'Cardiovascular Diseases', 'Cell physiology', 'Cells', 'Characteristics', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diabetes Mellitus', 'Disease', 'Environment', 'Environmental Risk Factor', 'Equilibrium', 'Funding', 'Galaxy', 'Homeostasis', 'Imagery', 'Knowledge', 'Label', 'Language', 'Letters', 'Linear Models', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methodology', 'Methods', 'Names', 'Network-based', 'Nuclear Magnetic Resonance', 'Pathway interactions', 'Phase', 'Phenotype', 'Plug-in', 'Procedures', 'Process', 'Prognostic Marker', 'Proteomics', 'Reaction', 'Sampling', 'Signal Transduction', 'Software Tools', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Work', 'base', 'biological systems', 'biomarker discovery', 'data warehouse', 'diagnostic biomarker', 'experimental study', 'flexibility', 'high dimensionality', 'improved', 'insight', 'interest', 'learning strategy', 'metabolome', 'metabolomics', 'new technology', 'novel', 'novel diagnostics', 'novel marker', 'open source', 'programs', 'public health relevance', 'rapid growth', 'response', 'small molecule', 'targeted treatment', 'tool', 'transcriptomics']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2019,337658,0.070671492253398
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9705993,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Data Analyses', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'SLEB2 gene', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'analysis pipeline', 'aptamer', 'base', 'clinical diagnostics', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2019,314000,0.023952968166928268
"Multiplexed high-content assay for toxicity profiling using live iPSC-derived cardiomyocyte lines with lineage-specific barcoding Project Summary/Abstract Human induced pluripotent stem cells (hiPSCs) are poised to transform toxicological evaluation, however new approaches to enable their functional and structural profiling are needed to improve the utility of hiPSC -based models for predictive and mechanistic toxicology screening. This need is addressed by our project’s Specific Aims that encompass (1) development of a novel platform for generation of hiPSC-derived reporter cells; (2) generation of a panel of multicolor hiPSC-derived cardiomyocytes (hiPSC-CMs) with stable lineage specific fluorescent reporters; and (3) implementation and validation of a pilot machine learning-enabled predictive cardiotoxicity screen using these tools. The proposed tools are configured to be extensible to other toxicology- relevant pathways and phenotypes making it uniquely positioned to capitalize on the growing commercial need for high-throughput predictive toxicology assays. The project deliverables benefit public health by improving the ability to rapidly identify liabilities in specific cardiomyocyte lineage types, thus reducing the time and cost to pinpoint cardiotoxicity of pharmaceutical and environmental chemicals. Project Narrative The assay and reagents established in the course of this project directly address the goals of significant initiatives to improve the effectiveness of cardiotoxicity testing, such as the FDA’s CiPA initiative and the work of the Cardiac Safety Research Consortium. The resulting improvements in the pace and precision of drug testing will result in public health benefit through the development of more cost-effective and safer medicines. Beyond toxicological evaluation of therapeutic compounds, our innovative technology will deliver additional benefit to public health by virtue of its utility in investigating the toxicities of environmental chemicals, in line with the focus of government agencies and initiatives such as the EPA and Tox21 in the US and EU-ToxRisk in Europe.",Multiplexed high-content assay for toxicity profiling using live iPSC-derived cardiomyocyte lines with lineage-specific barcoding,9761607,R44TR002572,"['Address', 'Biological Assay', 'CRISPR/Cas technology', 'Cardiac', 'Cardiac Myocytes', 'Cardiotoxicity', 'Cell Line', 'Cell Lineage', 'Cells', 'Cellular Assay', 'Cellular Structures', 'Chemicals', 'Classification', 'Contracts', 'Data', 'Development', 'Drug Modelings', 'Drug toxicity', 'Effectiveness', 'Europe', 'Evaluation', 'Foundations', 'Generations', 'Goals', 'Government Agencies', 'Health Benefit', 'Heart Atrium', 'Human', 'In Vitro', 'Industry Standard', 'Machine Learning', 'Medicine', 'Methods', 'Microscopy', 'Mitochondria', 'Nodal', 'Nuclear', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Physiological', 'Population Heterogeneity', 'Positioning Attribute', 'Public Health', 'Reagent', 'Reporter', 'Reporting', 'Research', 'Safety', 'Sarcomeres', 'Site', 'Small Business Innovation Research Grant', 'Specificity', 'Speed', 'Structure', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Training', 'Treatment-Related Cancer', 'Validation', 'Ventricular', 'Withdrawal', 'Work', 'base', 'cell immortalization', 'clinical candidate', 'clinical predictors', 'cost', 'cost effective', 'drug discovery', 'drug testing', 'environmental chemical', 'expression vector', 'genome editing', 'high throughput screening', 'immortalized cell', 'improved', 'induced pluripotent stem cell', 'innovation', 'innovative technologies', 'machine learning algorithm', 'model development', 'new technology', 'novel', 'novel strategies', 'phase I trial', 'pre-clinical', 'predictive modeling', 'predictive test', 'predictive tools', 'programs', 'response', 'safety assessment', 'screening', 'site-specific integration', 'success', 'therapeutic development', 'therapeutic evaluation', 'tool']",NCATS,"CAIRN BIOSCIENCES, INC.",R44,2019,821559,0.005985071481508057
"Next-generation integrated quantum force fields for biomedical applications Next-generation integrated quantum force ﬁelds for biomedical applications PI: Darrin M. York, Rutgers University, Piscataway, NJ 08854-8087 USA.  We have recently developed novel framework for next-generation quantum mechanical force ﬁelds (QMFFs) designed to meet the challenges of biomolecular simulations and drug discovery applications. QMFFs have tremendous computational advantages relative to their fully QM counterparts, being inherently parallelizable and linearly scaling, offering tremendous computational speedup, and promising quantitative accuracy potentially superior to full QM methods. QMFFs accurately model multipolar electrostatics, charge penetration effects, and non-linear polarization response. QMFFs thus offer a transformative technology for drug discovery applications, in particular, for advancing the predictive capability of free energy simulations in lead reﬁnement. These are critically important for the diverse chemical space of drug molecules, including halogen bonding, cation-  and metal-ligand interactions. Further, QMFFs offer a mechanism for modeling covalent inhibitors. Speciﬁcally, we propose to: I. Develop new QMFFs for drug discovery. QMFFs will be developed based on both semiempirical and ab initio density-functional methods in the following stages: 1) determination of multipolar mapping parameters enhancing the DFTB electrostatic potential to reach greater accuracy, 2) augmentation of electronic response terms using chemical potential equalization (CPE) corrections using an orthogonal perturbation-response approach to solve the under-polarization problem of DFTB methods, 3) parameterization of non-electrostatic non-bonded interac- tion parameters using realistic potentials that capture many-body exchange and dispersion interactions, and 4) exploration of statistical potentials, using machine learning approaches applied to quantum data sets, to correct internal conformational energies and short-range interactions. II. Develop new free energy methods to enable protein-ligand binding predictions using QMFFs. We will develop a novel integrated free energy pipeline to pre- dict alchemical binding free energies for ligands and inhibitors. This will include new GPU-accelerated methods for  -space self-adaptive mixture sampling ( -SAMS) and 2D-vFEP analysis, coupled with conformational space enhanced sampling methods for alchemical steps of the thermodynamic cycle, and advancements in free en- ergy “book-ending” methods (BBQm) to efﬁciently connect molecular mechanical force ﬁeld and QMFF model representations. III. Test and validate QMFFs and free energy methods, and apply to MIF inhibitor binding. The methods will be broadly tested against established data sets for solvation free energies, and a drug discovery data set. More in-depth validation studies will be conducted by examining the relative binding free energies of inhibitors of the macrophage inhibitory factor (MIF). Finally, exploratory applications will examine mechanisms, characterize transition states and predict rates for covalent inhibition for a series of MIF inhibitors. Next-generation integrated quantum force ﬁelds for biomedical applications PI: Darrin M. York, Laboratory for Biomolecular Simulation Research, Rutgers University, Piscat- away, NJ 08854-8087 USA.  We propose a novel strategy to develop a class of integrated quantum mechanical force ﬁelds (QMFFs) that create highly accurate physical models for complex biomolecular simulations. Com- bined with recently developed high-precision free energy simulation and analysis tools, the pro- posed QMFFs will overcome current critical barriers to progress for drug discovery and deliver accurate and precise predictions for drug binding afﬁnity to enhance lead optimization. The pro- posed work will be applied to understand ligand-protein binding in the macrophage inhibitory factor (MIF), and provide insight that may guide the design of new non-covalent and targeted covalent inhibitors to MIF and other systems.",Next-generation integrated quantum force fields for biomedical applications,9817829,R01GM107485,"['Affinity', 'Attention', 'Binding', 'Binding Proteins', 'Books', 'Cations', 'Charge', 'Chemicals', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Drug Targeting', 'Electrostatics', 'Free Energy', 'Halogens', 'Inflammatory', 'Laboratories', 'Lead', 'Libraries', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Penetration', 'Periodicity', 'Pharmaceutical Preparations', 'Phase', 'Problem Solving', 'Proteins', 'Research', 'Sampling', 'Series', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Thermodynamics', 'Universities', 'Variant', 'Work', 'base', 'density', 'design', 'drug discovery', 'flexibility', 'inhibitor/antagonist', 'innovation', 'insight', 'lead optimization', 'macrophage', 'mechanical force', 'nervous system disorder', 'next generation', 'novel', 'novel strategies', 'physical model', 'programs', 'quantum', 'response', 'simulation', 'tool', 'validation studies']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",R01,2019,326559,-0.010670578666584097
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9608754,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2019,356625,0.08323257777792344
"Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets PROJECT SUMMARY/ABSTRACT Recent advances in high-resolution mass spectrometry (HRMS) instrumentation have not been fully leveraged to upgrade the information content of metabolomics datasets obtained from stable isotope labeling studies. This is primarily due to lack of validated software tools for extracting and interpreting isotope enrichments from HRMS datasets. The overall objective of the current application is to develop tools that enable the metabolomics community to fully leverage stable isotopes to profile metabolic network dynamics. Two new tools will be implemented within the open-source OpenMS software library, which provides an infrastructure for rapid development and dissemination of mass spectrometry software. The first tool will automate tasks required for extracting isotope enrichment information from HRMS datasets, and the second tool will use this information to group ion peaks into interaction networks based on similar patterns of isotope labeling. The tools will be validated using in-house datasets derived from metabolic flux studies of animal and plant systems, as well as through feedback from the metabolomics community. The rationale for the research is that the software tools will enable metabolomics investigators to address important questions about pathway dynamics and regulation that cannot be answered without the use of stable isotopes. The first aim is to develop a software tool to automate data extraction and quantification of isotopologue distributions from HRMS datasets. The software will provide several key features not included in currently available metabolomics software: i) a graphical, interactive user interface that is appropriate for non-expert users, ii) support for native instrument file formats, iii) support for samples that are labeled with multiple stable isotopes, iv) support for tandem mass spectra, and v) support for multi-group or time-series comparisons. The second aim is to develop a companion software that applies machine learning and correlation-based algorithms to group unknown metabolites into modules and pathways based on similarities in isotope labeling. The third aim is to validate the tools through comparative analysis of stable isotope labeling in test standards and samples from animal and plant tissues, including time-series and dual-tracer experiments. A variety of collaborators and professional working groups will be engaged to test and validate the software, and the tools will be refined based on their feedback. The proposed research is exceptionally innovative because it will provide the advanced software capabilities required for both targeted and untargeted analysis of isotopically labeled metabolites, but in a flexible and user-friendly environment. The research is significant because it will contribute software tools that automate and standardize the data processing steps required to extract and utilize isotope enrichment information from large-scale metabolomics datasets. This work will have an important positive impact on the ability of metabolomics investigators to leverage information from stable isotopes to identify unknown metabolic interactions and quantify flux within metabolic networks. In addition, it will enable entirely new approaches to study metabolic dynamics within biological systems. PROJECT NARRATIVE The proposed research is relevant to public health because it will develop novel software tools to quantify and interpret data from stable isotope labeling experiments, which can be used to uncover relationships between metabolites and biochemical pathways. These tools have potential to accelerate progress toward identifying the causes and cures of many important diseases that impact metabolism.",Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets,9786702,U01CA235508,"['Address', 'Algorithms', 'Animals', 'Biochemical Pathway', 'Biological', 'Communities', 'Companions', 'Complement', 'Computer software', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Environment', 'Feedback', 'Infrastructure', 'Ions', 'Isotope Labeling', 'Isotopes', 'Knowledge', 'Label', 'Letters', 'Libraries', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Network-based', 'Outcome', 'Pathway interactions', 'Pattern', 'Plants', 'Process', 'Public Health', 'Publishing', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Series', 'Software Tools', 'Stable Isotope Labeling', 'Standardization', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'Validation', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'experience', 'experimental study', 'file format', 'flexibility', 'improved', 'innovation', 'instrument', 'instrumentation', 'metabolic abnormality assessment', 'metabolic phenotype', 'metabolic profile', 'metabolomics', 'novel', 'novel strategies', 'open source', 'operation', 'stable isotope', 'tandem mass spectrometry', 'tool', 'user-friendly', 'working group']",NCI,VANDERBILT UNIVERSITY,U01,2019,431816,0.05225838875779643
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,9782980,UG3HL145593,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'automated analysis', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'preservation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NHLBI,PURDUE UNIVERSITY,UG3,2019,375000,0.04978721529258343
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,10012251,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computer Simulation', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Diet', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computerized tools', 'dark matter', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2019,141763,0.0696303955939617
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,9769745,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computer Simulation', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Diet', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computerized tools', 'dark matter', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2019,998631,0.0696303955939617
"Next Generation Testing Strategies for Assessment of Genotoxicity Project Summary  It is well recognized that current batteries of genetic toxicology assays exhibit two critical deficiencies. First, the throughput capacity of in vitro mammalian cell genotoxicity tests is low, and does not meet current needs. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no consideration for potency, and virtually no information is provided about molecular targets and mechanisms. These deficiencies in hazard characterization prevent genotoxicity data from optimally contributing to modern risk assessments, where this information is essential. We will address these major problems with current in vitro mammalian cell genetic toxicity assays by developing methods and associated commercial assay kits that dramatically enhance throughput capacity, and delineate genotoxicants' primary molecular targets, while simultaneously providing information about potency. Once biomarkers and a family of multiplexed assays have been developed for these purposes, an interlaboratory trial will be performed with prototype assay kits to assess the transferability of the methods. Project Narrative  DNA damage that cannot be faithfully repaired results in gene mutation and/or chromosomal aberrations, and these effects are known to contribute to cancer and other severe diseases. Thus, there is an important need for sensitive assays to evaluate chemicals for genotoxic and other deleterious effects. The work proposed herein will address issues that have plagued genotoxicity assessments for the last several decades: low throughput, lack of potency metrics, and little to no information about molecular targets. We will address these major problems with current genetic toxicity assays by developing new methods and associated commercial assay kits.",Next Generation Testing Strategies for Assessment of Genotoxicity,9807074,R44ES029014,"['Address', 'Affect', 'Aneugens', 'Antioxidants', 'Appearance', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Biological Response Modifiers', 'Bleomycin', 'Caspase', 'Cell Cycle', 'Cell Nucleus', 'Cells', 'Chemicals', 'Chromosome abnormality', 'Chromosomes', 'Classification', 'Cleaved cell', 'Colcemid', 'Companions', 'Complex', 'Computer Simulation', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'DNA-PKcs', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Dose', 'Epitopes', 'Etoposide', 'Exhibits', 'Family', 'GADD45A gene', 'Gamma-H2AX', 'Gene Mutation', 'Genetic', 'Goals', 'Harvest', 'Histone H3', 'Human', 'In Vitro', 'Intercalating Agents', 'Investigation', 'Kinetics', 'Label', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Modification', 'Molecular Target', 'Mutagenicity Tests', 'NF-kappa B', 'Nuclear', 'Pathway interactions', 'Phase', 'Physiologic pulse', 'Procedures', 'Protocols documentation', 'Reagent', 'Reference Values', 'Risk Assessment', 'Schedule', 'Scheme', 'Series', 'Stains', 'TP53 gene', 'Testing', 'Time', 'Toxic effect', 'Toxicogenetics', 'Training', 'Validation', 'Work', 'aurora kinase', 'base', 'clastogen', 'computerized tools', 'design', 'experimental study', 'genotoxicity', 'hazard', 'inhibitor/antagonist', 'next generation', 'prediction algorithm', 'prevent', 'prototype', 'random forest', 'repaired', 'response', 'targeted agent', 'tool', 'treatment optimization', 'virtual']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2019,482291,0.012552430589009381
"Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria PROJECT SUMMARY Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacterial infections are increasing in incidence and novel antibiotics are urgently needed to combat this growing threat to public health. A major roadblock to the development of novel antibiotics is our poor understanding of the structural features of small molecules that correlate with bacterial penetration and efflux. As a result, while potent biochemical inhibitors can often be identified for new targets, developing them into compounds with whole-cell antibacterial activity has proven challenging. To address this critical problem, we propose herein a comprehensive, multidisciplinary approach to develop quantitative models to predict small-molecule penetration and efflux in Gram-negative bacteria. We have pioneered a general platform for systematic, quantitative evaluation of small-molecule accumulation in bacteria, using label-free LC-MS/MS detection and multivariate cheminformatic analysis. We have also developed unique isogenic strain sets of wild-type, hyperporinated, efflux-knockout, and doubly-compromised E. coli, P. aeruginosa, and A. baumannii that allow us to dissect the individual contributions of outer/inner membrane penetration and active efflux to net accumulation, using a kinetic model that accurately recapitulates available experimental data. Moreover, we have developed machine learning and neural network approaches to QSAR (quantitative structure–activity relationship) modeling of pharmacological properties that will now be used to develop predictive cheminformatic models for Gram-negative accumulation, penetration, and efflux. This project will be carried out by a multidisciplinary SPEAR-GN Project Team (Small-molecule Penetration & Efflux in Antibiotic-Resistant Gram-Negatives, “speargun”) involving the labs of Derek Tan (MSK, PI), Helen Zgurskaya (OU, PI), Bradley Sherborne (Merck, Lead Collaborator), Valentin Rybenkov (OU, Co-I), Adam Duerfeldt (OU, Co-I), Carl Balibar (Merck, Collaborator), and David McLaren (Merck, Collaborator), comprising extensive combined expertise in organic and diversity-oriented synthesis, biochemistry, microbiology, high- throughput screening, mass spectrometry, biophysical modeling, cheminformatics, and medicinal chemistry. Herein, we will design and synthesize chemical libraries with diverse structural and physicochemical properties; analyze their accumulation in the isogenic strain sets in both high-throughput and high-density assay formats; extract kinetic parameters for penetration and efflux from the resulting experimental datasets; develop and validate robust QSAR models for accumulation, penetration, and efflux; and demonstrate the utility of these models in medicinal chemistry campaigns to develop novel Gram-negative antibiotics against three targets. This project will provide a major advance in the field of antibacterial drug discovery, providing powerful enabling tools to the scientific community to address this major threat to public health. PUBLIC HEALTH RELEVANCE Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacteria pose a growing threat to public health in the U.S. and globally. A major obstacle to the development of new antibiotics to combat such infections is our poor understanding of the chemical requirements for small molecules to enter Gram-negative cells and to avoid ejection by efflux pumps. The proposed comprehensive, multidisciplinary research program aims to develop predictive computational tools to identify such molecules by carrying out large-scale, quantitative analyses of the accumulation of diverse small molecules in Gram-negative bacteria. These tools will then enable medicinal chemistry campaigns to develop novel antibiotics.",Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria,9761970,R01AI136795,"['Acinetobacter baumannii', 'Address', 'Algorithmic Software', 'Anti-Bacterial Agents', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Bacteria', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biological Availability', 'Cells', 'Chemicals', 'Communities', 'Data', 'Data Set', 'Detection', 'Development', 'Effectiveness', 'Escherichia coli', 'Gram-Negative Bacteria', 'Gram-Negative Bacterial Infections', 'Human', 'Incidence', 'Individual', 'Infection', 'Interdisciplinary Study', 'Kinetics', 'Knock-out', 'Lead', 'Libraries', 'Machine Learning', 'Mammalian Cell', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Membrane', 'Microbiology', 'Modeling', 'Oral', 'Partner in relationship', 'Penetration', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacology', 'Property', 'Pseudomonas aeruginosa', 'Public Health', 'Quantitative Evaluations', 'Quantitative Structure-Activity Relationship', 'Role', 'Structure', 'Testing', 'Variant', 'analog', 'base', 'biophysical model', 'cell envelope', 'cheminformatics', 'combat', 'computerized tools', 'density', 'design', 'drug discovery', 'efflux pump', 'high throughput screening', 'improved', 'inhibitor/antagonist', 'interdisciplinary approach', 'lead optimization', 'learning network', 'multidisciplinary', 'neural network', 'novel', 'off-label use', 'predictive modeling', 'programs', 'prospective', 'public health relevance', 'screening', 'small molecule', 'small molecule libraries', 'success', 'tool']",NIAID,SLOAN-KETTERING INST CAN RESEARCH,R01,2019,1212566,0.009840935820182086
"Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC PROJECT SUMMARY The Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC (CMP-GA) is a cross-cutting team with advanced high-throughput chemical analytics and big data capabilities to develop a comprehensive map of molecular transducers of physical activity. The investigative team excels in ultrasensitive, precise and spatially resolved analyses of small molecules, lipids, and proteins. The team members have strong academic records as innovative, independent scientists, core laboratory directors and effective collaborators in complex research initiatives. Instrumentation includes state-of-the-art ultra-high resolution accurate mass high-field Orbitrap tandem mass spectrometry (MS) and ultraperformance liquid chromatography (UPLC); three- dimensional (3-D) molecular imaging via high throughput multi-modal MS at 5 m resolution; unique ion mobility-mass spectrometry machine-learning approaches for chemical identifications; and other such as GC- Orbitrap, 1D and 2D high field (800 MHz) NMR spectroscopy, ICP-MS, immunoassays, chemical and enzymatic assays, etc. The analytical laboratories are integrated through the NIH-supported Atlanta Clinical and Translational Sciences Institute, and operate within the outstanding research environment of Emory University and the Georgia Institute of Technology (GA Tech). CMP-GA has six elements organized to provide 1) leadership in the design and implementation of MoTrPAC goals; 2) bioinformatics, computational support and data delivery to the MoTrPAC Data Coordinating Center; 3) global, targeted and spatially resolved metabolomics; 4) metabolite forensics for unequivocal chemical identification of novel molecular transducers; 5) innovative proteomic and chemoproteomic technologies to define transducers within the redox proteome, ubiquitinome, acetylome, kinome and nuclear proteome; and 6) identification and quantification of lipid transducers. Through the successful completion of these aims and collaboration with the MoTrPAC consortium, investigators of CMP-GA will deliver a publically-available data resource and molecular transducer map that will enhance and accelerate mechanistic research on diseases and conditions affected by physical activity. PROJECT NARRATIVE This is a comprehensive metabolomics and proteomics chemical analysis site to support the Molecular Transducers of Physical Activity Consortium (MoTrPAC). Advanced analytical methods, including mass spectrometry, bioinformatics and chemical forensics are used to provide targeted and global analysis of small molecules, lipids, proteins to develop a molecular transducer map for physical activity.",Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC,9648148,U24DK112341,"['3-Dimensional', 'Adipocytes', 'Affect', 'Aging', 'Animal Experimentation', 'Animals', 'Automobile Driving', 'Big Data', 'Bioinformatics', 'Biological Assay', 'Chemicals', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Communication', 'Complement', 'Complex', 'Custom', 'Data', 'Data Coordinating Center', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Elements', 'Environment', 'Exercise', 'Forensic Medicine', 'Goals', 'Health', 'Health Benefit', 'Immunoassay', 'Institutes', 'Isotopes', 'Label', 'Laboratories', 'Leadership', 'Link', 'Lipids', 'Liquid Chromatography', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Monitor', 'Muscle', 'NMR Spectroscopy', 'Neurodegenerative Disorders', 'Nuclear', 'Oral', 'Oxidation-Reduction', 'Oxidative Stress', 'Particle Size', 'Peptide Mapping', 'Phosphotransferases', 'Physical activity', 'Plasma', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Protocols documentation', 'Publications', 'Reaction', 'Records', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Signal Transduction', 'Site', 'System', 'Systems Biology', 'Technology', 'Time', 'Training', 'Transducers', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'advanced system', 'analytical method', 'chemoproteomics', 'cytokine', 'data resource', 'design', 'differential expression', 'innovation', 'instrumentation', 'ion mobility', 'lectures', 'member', 'metabolomics', 'molecular imaging', 'multimodality', 'novel', 'oxidized lipid', 'phenotypic biomarker', 'response', 'small molecule', 'tandem mass spectrometry', 'tool', 'ultra high resolution']",NIDDK,EMORY UNIVERSITY,U24,2019,1419260,0.029869634989698374
"Illuminating Function of the Understudied Druggable Kinome Project Summary/Abstract Kinases are among the most important drug targets and clinically significant kinase inhibitors have been developed for multiple diseases. A subset of kinases, the understudied dark kinases (DKs), have received little or no attention because foundational data on their biochemical and biological functions is not available. This proposal will collect such data by perturbing DKs genetically and with small molecules and then measuring the cellular consequences using multiplex proteomic, gene expression, metabolomic and imaging assays. A subset of DKs with potential links to human disease will be intensively studied as a means to qualify new therapeutic drug targets. Data collected in this project will be aggregated with existing information from previous NIH-funded large-scale structural and genomic projects to create a Dark Kinase Knowledgebase (DKK) that provides gene-by-gene and network-level information on the dark kinome and its interaction with other signal transduction and regulatory networks. Close coordination with the NIH LINCS project will ensure data interoperability and make efficient use of informatics tools. The DKK will be developed in collaboration with the IDG Knowledge Management Center (KMC), adhere to standards for Findable, Accessible, Interoperable and Reusable (FAIR) data, and be accessible to human users and machines (via an API). Commercially available DK reagents be validated and extended with new genetic and chemical tools provided to the Resource Dissemination Center (RDOC). The overall approach will be iterative, with simpler methods applied first (e.g. simple gene knockout) and more sophisticated methods subsequently (e.g. stable CRIPSRa/i) pursued by an interdisciplinary team of chemists, computational biologists, mass spectroscopists and pharmacologists working on five linked aims. Aim 1 will develop a computational algorithm for prioritizing DKs, develop and maintain the DKK, and perform network-level analysis on the kinome using supervised and unsupervised machine learning. Aim 2 will measure kinase abundance in normal and perturbed cells using parallel reaction monitoring with stable isotope dilution (PRM-SID) and RNASeq and data analyzed using network inference tools to provide insight into dark and light kinome in diverse cell types. Aim 3 will perturb DKs with genetic tools such as CRIPSR/Cas9-mediated gene knockout, CRIPSRa/i to induce more subtle-up and down regulation and inducible gene inaction. The impact on cell fate, morphology and signal transduction will then be determined using PRM-SID, phosphoproteomics, RNASeq, gene reporter assays, metabolomics profiling and highly multiplex single-cell imaging. Aim 4 will extend DK analysis to small molecule inhibitors by carefully profiling existing drugs against DKs and by designing and synthesizing new chemical ligands. Aim 5 will involve collaboration with other investigators to assay the expression and function of DKs in primary human cells and tissues relevant to the NIH Precision Medicine Initiative. All aims will be pursued in parallel for a progressively expanding resource of data and tools for continued study of DKs. Project Narrative/Health Relevance Advancing understanding of understudied kinases, a highly druggable class of proteins, will increase knowledge about signal transduction and control over cellular physiology and is likely to reveal a subset of proteins that should be advanced as targets for new therapeutic drugs.",Illuminating Function of the Understudied Druggable Kinome,9762097,U24DK116204,"['Algorithms', 'Anabolism', 'Arthritis', 'Attention', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Process', 'Cell Line', 'Cell physiology', 'Cells', 'Chemicals', 'Chronic Obstructive Airway Disease', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Collection', 'Complement', 'Computational algorithm', 'Cystic Fibrosis', 'Data', 'Data Analyses', 'Development', 'Diabetes Mellitus', 'Disease', 'Down-Regulation', 'Drug Targeting', 'Engineering', 'Ensure', 'FAIR principles', 'Foundations', 'Funding', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Goals', 'Health', 'Homeostasis', 'Human', 'Image', 'Individual', 'Information Resources Management', 'Knowledge', 'Libraries', 'Ligands', 'Light', 'Link', 'Logic', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mediating', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Mutate', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Play', 'Precision Medicine Initiative', 'Production', 'Proteins', 'Proteomics', 'Reaction', 'Reagent', 'Reporter', 'Reporter Genes', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Signal Transduction', 'Signal Transduction Pathway', 'Site', 'Supervision', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Tumor Tissue', 'United States National Institutes of Health', 'Up-Regulation', 'Validation', 'base', 'cell type', 'cellular imaging', 'clinically significant', 'computerized tools', 'data resource', 'design', 'human disease', 'human model', 'informatics\xa0tool', 'innovation', 'insight', 'interoperability', 'kinase inhibitor', 'knockout gene', 'knowledge base', 'metabolic profile', 'metabolomics', 'new therapeutic target', 'novel', 'novel therapeutics', 'phosphoproteomics', 'programs', 'protein protein interaction', 'screening', 'small molecule', 'small molecule inhibitor', 'stable isotope', 'structural genomics', 'therapeutic development', 'therapeutic target', 'tool', 'transcription factor', 'transcriptome sequencing', 'unsupervised learning']",NIDDK,UNIV OF NORTH CAROLINA CHAPEL HILL,U24,2019,2265987,-0.001296085531721469
"High-Throughput De Novo Glycan Sequencing Glycosylation fulfills important physiological functions, including protein folding, embryogenesis, cell adhesion, pathogen recognition, and immune response. The multifaceted roles glycosylation plays derive from the presence of a range of glycan epitopes, where a small structural variation can have a profound impact on functions. Further, a glycome consists of many closely related structures, with their relative amounts determined by metabolic conditions in a cell- and growth-specific manner. Altered glycosylation is linked to many diseases, including cardiovascular, pulmonary, neurological and autoimmune disorders, and cancer. Thus, there is a clear need for analytical methods that can rapidly identify and quantify the many glycoforms in a glycome from different health and disease states. Finally, no genome-predicted glycan database exists due to the unscripted nature of glycan biosynthesis, and discovery of new glycan structures must be achieved by de novo methods. Although tandem mass spectrometry-based biopolymer sequencing has been the major catalyst to the recent rapid advance of 'omics, the prevailing collisionally activated dissociation method often fails to provide sufficient glycan structural detail at the MS2 level, whereas the MSn approach lacks the speed, sensitivity, and quantitative potential for high-throughput glycome analysis. We have recently developed an electronic excitation dissociation (EED) method that can yield rich structural information in a single stage of MS/MS analysis. However, the impact of EED on glycomics research is currently limited by its poor accessibility, insufficient coupling to on-line glycan separation methods, and difficulty in interpretation of complex glycan EED tandem mass spectra. Here, we propose to develop an integrated approach that combines EED with on-line liquid chromatography (LC) separation and a novel bioinformatics tool to achieve high-throughput, de novo, and comprehensive glycome characterization. We will explore the potential of EED for analysis of glycans in various derivatized forms, study their fragmentation behaviors, and establish fragmentation rules for the development of bioinformatics software. We will optimize conditions for efficient coupling of EED to reversed-phase, and porous graphitic carbon LC, and develop an LC-EED-MS/MS approach for simultaneous characterization and quantitation of glycan mixtures. We will implement EED on a Q-TOF instrument to improve its access to the glycoscience community. Finally, we will develop and rigorously test the performance of a novel bioinformatics software that can rapidly and accurately determine each glycan's structure from its tandem MS spectra. The proposed algorithm is fundamentally different from most existing software, in that it no longer relies solely on glycosidic and cross-ring fragments for topology and linkage analysis, but rather adopts a machine learning approach that considers the contexts of various types of fragment peaks, and the spectral features associated with different linkage configurations and structural motifs. The availability of such a high-throughput, de novo glycan sequencing tool will have an immense impact on many biomedical research fields, as glycosylation plays critical roles in almost all biological pathways. High-Throughput De Novo Glycan Sequencing Project narrative Characterization of glycans from biological sources requires sensitive and high-throughput analytical methods that can separate and identify each glycoform in a complex mixture. We propose to develop an HPLC-EED- MS/MS method for comprehensive glycome characterization. We will also develop a novel bioinformatics program that can accurately determine the glycan structure from its EED tandem mass spectrum de novo.",High-Throughput De Novo Glycan Sequencing,9713593,R01GM132675,"['Address', 'Adopted', 'Algorithm Design', 'Algorithms', 'Anabolism', 'Autoimmune Diseases', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Research', 'Biopolymers', 'Carbon', 'Cardiovascular Diseases', 'Cell Adhesion', 'Communities', 'Complex', 'Complex Mixtures', 'Computer software', 'Coupling', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Dissociation', 'Effectiveness', 'Electron Transport', 'Embryonic Development', 'Epitopes', 'Fourier transform ion cyclotron resonance', 'Genome', 'Glycoconjugates', 'Glycosides', 'Health', 'High Pressure Liquid Chromatography', 'Immune response', 'Impairment', 'Individual', 'Isomerism', 'Link', 'Liquid Chromatography', 'Liquid substance', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Metabolic', 'Methods', 'Natural graphite', 'Nature', 'Pathologic Processes', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Physiological Processes', 'Physiology', 'Play', 'Polysaccharides', 'Research', 'Research Project Grants', 'Role', 'Sampling', 'Scheme', 'Source', 'Specificity', 'Speed', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Vacuum', 'Variant', 'analytical method', 'base', 'bioinformatics tool', 'catalyst', 'cell growth', 'design', 'genetic linkage analysis', 'glycosylation', 'improved', 'instrument', 'mass spectrometer', 'nervous system disorder', 'novel', 'pathogen', 'performance tests', 'programs', 'protein folding', 'reconstruction', 'tandem mass spectrometry', 'therapeutic target', 'tool', 'ultraviolet']",NIGMS,BOSTON UNIVERSITY MEDICAL CAMPUS,R01,2019,462286,0.012839898274211997
"Digital representation of chemical mixtures to aid drug discovery and formulation PROJECT SUMMARY Collaborative Drug Discovery, Inc. (CDD) proposes to develop a suite of software modules to enable scientists to unambiguously represent chemical mixtures in standard machine-readable formats, filling an urgent and widely-recognized need. Chemicals are typically formulated as mixtures. Recording and communicating information about chemical mixtures is essential for scientists and support staff in the pharmaceutical industry, in academia, in non-profit research organizations, in government, at specialty chemical vendors, and at commercial manufacturers to: • discover, develop, formulate, manufacture and regulate drugs; • manage reagent inventories; comply with laboratory safety requirements; inform first responders; • describe and reproduce biomedical experiments; and • assess and disseminate information about toxicity risks of chemical reagents and consumer products.  A working committee of the International Union of Pure and Applied Chemistry (IUPAC) is close to formalizing “Mixtures InChI” (or MInChI), which will extend the International Chemical Identifier (InChI) to become the first standard to encompass mixtures. MInChI will effectively index mixtures in the same way that InChI indexes individual compounds.  CDD will first develop the data structures and software necessary to enable adoption and utilization of MInChI and create the first general-purpose system for recording information about chemical mixtures that is computable and interoperable. The most innovative part of the project and the bulk of the effort will be to develop a sophisticated automated translation tool that will accurately convert legacy catalogs of chemical mixtures from plaintext descriptions or ad hoc formats so that they are properly represented in a machine readable format that can in turn be easily rendered into MInChI identifiers. The broad vision is to help industry to overcome the barriers to adoption so that MInChI can quickly deliver benefits for drug discovery, chemical safety, and toxicology. PROJECT NARRATIVE The proposed project will create novel computational tools that will help researchers to efficiently and accurately document the composition of chemical mixtures in a format that computers can easily interpret, process, and exchange. This innovative capability will help to accelerate the discovery and development of novel and improved drugs against a wide range of diseases. It will also help to advance our understanding of the toxicology of mixtures (which often differs from the toxicology of individual components) and improve laboratory safety both in industry and in educational settings. !",Digital representation of chemical mixtures to aid drug discovery and formulation,9826639,R43TR002528,"['Academia', 'Address', 'Adoption', 'Catalogs', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Code', 'Collaborations', 'Computer software', 'Computers', 'Data', 'Databases', 'Development', 'Disease', 'Drug Formulations', 'Drug Industry', 'Elements', 'English Language', 'Equipment and supply inventories', 'Government', 'Human', 'Individual', 'Industry', 'Infrastructure', 'Intelligence', 'International', 'Laboratories', 'Letters', 'Machine Learning', 'Manufacturer Name', 'Methods', 'Modeling', 'Names', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Process', 'Readability', 'Reagent', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Scientist', 'Services', 'Shorthand', 'Solvents', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Text', 'Toxic effect', 'Toxicology', 'Traction', 'Training', 'Translations', 'Vendor', 'Vision', 'Visual', 'cofactor', 'computerized tools', 'consumer product', 'data structure', 'digital', 'drug discovery', 'experimental study', 'first responder', 'improved', 'indexing', 'innovation', 'interoperability', 'medical specialties', 'member', 'natural language', 'novel', 'open source', 'text searching', 'tool']",NCATS,"COLLABORATIVE DRUG DISCOVERY, INC.",R43,2019,54833,0.016145801936251866
"Integrating cheminformatics and molecular simulations for virtual drug screening ﻿    DESCRIPTION (provided by applicant): The development of highly efficient and accurate approaches to structure-based virtual screening (VS) continues to represent a formidable challenge in the field of computational drug discovery. Outstanding and widely recognized research problems in the field include the relative computational inefficiency of most approaches, which limits the size of molecular libraries used for virtual screening; the low hit rate; and the inaccurate prediction of ligand binding affinity and pose. The proposed studies address these challenges by using innovative and computationally efficient approaches to VS that fully integrate concepts from the complementary fields of cheminformatics and molecular simulation to devise an integrated two-step VS methodology. Building upon our experience in cheminformatics and QSAR modeling, we aim to develop novel, computationally efficient cheminformatics approaches to pre-process very large (on the order of 107 compounds) chemical libraries available for biological screening, and eliminate up to 99% of improbable ligands. Only the remaining 1% of probable ligands will be evaluated by slower but accurate ensemble flexible docking approaches relying on molecular simulation techniques. The cheminformatics step will also produce important information on privileged protein-ligand interactions that will be used in a live-processing step to guide the structure-based virtual screening and avoid oversampling of ligand poses. Moreover, post- processing cheminformatics methods will be implemented to filter out decoy poses from docking calculations. The ultimate goal of our hybrid methodology is to arrive at a small set of high-affinity computational hits in receptor-bound conformations that can be validated experimentally. We will pursue this goal following three specific aims: 1) Develop novel cheminformatics-based virtual screening approaches to eliminate both improbable ligands and improbable poses, as well as generate information on preferred protein-ligand interactions; 2) Develop new, efficient flexible ensemble docking methods guided by the preferred protein- ligand interactions to select the most probable ligands and predict their binding poses; 3) Apply the developed hierarchical virtual screening workflow to several therapeutic targets and test high-confidence computational hits in experimental assays. All computational tools resulting from this project will be made publicly available. This proposal is innovative because the proposed VS platform will result from a unique marriage of disparate approaches for VS, combining their corresponding strengths. This proposal is significant because the implementation of this project will enable substantial improvement in the efficiency, accuracy, and experimentally-confirmed impact of structure-based drug discovery tools. PUBLIC HEALTH RELEVANCE: Advances in drug discovery rely on the development of novel effective computational methodologies. This proposal advances an efficient and robust computational workflow for structure-based virtual screening of very large chemical libraries. The ultimate goal of this project is to arrive at a small number of candidate molecules with high predicted binding affinity to their biological targets, which will be tested in confirmatory experiments.",Integrating cheminformatics and molecular simulations for virtual drug screening,9694695,R01GM114015,"['Active Sites', 'Address', 'Affect', 'Affinity', 'Benchmarking', 'Binding', 'Binding Sites', 'Biological', 'Biological Assay', 'Biological Availability', 'Chemicals', 'Computational Geometry', 'Computer Simulation', 'Computing Methodologies', 'Data Set', 'Descriptor', 'Development', 'Docking', 'Drug Screening', 'Enzymes', 'G-Protein-Coupled Receptors', 'Goals', 'Hybrids', 'Libraries', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Conformation', 'Orphan', 'Performance', 'Pharmaceutical Preparations', 'Pharmacology', 'Phosphotransferases', 'Process', 'Proteins', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Research', 'Series', 'Side', 'Structure', 'Techniques', 'Testing', 'Validation', 'Vertebral column', 'base', 'cheminformatics', 'computerized tools', 'drug discovery', 'experience', 'experimental study', 'flexibility', 'improved', 'improved outcome', 'innovation', 'molecular size', 'novel', 'novel strategies', 'programs', 'public health relevance', 'receptor binding', 'screening', 'simulation', 'small molecule', 'small molecule libraries', 'sperm cell', 'therapeutic evaluation', 'therapeutic target', 'three dimensional structure', 'tool', 'user friendly software', 'virtual', 'virtual technology']",NIGMS,PENNSYLVANIA STATE UNIV HERSHEY MED CTR,R01,2019,235391,-0.009793417913331213
"UVPD-MS Characterization of Lipopolysaccharides Abstract. Gram-negative bacteria have caused many of the most persistent infections as well as some of the deadliest pandemics in the world. Some strains have developed resistant to all available drugs, thus leading to increasing mortality from previously treatable bacterial infections. The National Strategy for Combating Antibiotic-Resistant Bacteria released by the White House in September 2014 focused on the need for (i) advancing the development of methods for identification and characterization of bacteria, (ii) accelerating basic research for new antibiotics, and (iii) improving capabilities for surveillance of antibiotic-resistant bacteria. This proposal focuses on the development of innovative tandem mass spectrometry approaches for characterization of lipopolysaccharides (LPS), the primary constituent of the outer membrane of Gram-negative bacteria that protects the membrane from chemical attack and is recognized by the immune system during pathogenic invasion. Structural characterization of LPS is critical to understanding how the structure of LPS influences immune stimulation as well as facilitating development of new antimicrobials and vaccines. This is a significant analytical challenge due to the branched structures and amphipathic properties of LPS. The escalating concerns about antibiotic resistance bacteria and the need for better avenues of defense against infectious diseases have motivated the proposed work. The objectives of this proposal are: Aim 1: Development of ultraviolet photodissociation (UVPD) mass spectrometry via hierarchical, decision-tree workflows for top-down characterization of LPS to facilitate high throughput analysis; Aim 2: Development of MS/MS approaches for serotyping of Gram-negative bacteria based on LPS; Aim 3: Examination of peptide/LPS interactions via native-spray mass spectrometry to provide both mechanistic information and screening capabilities for new antimicrobials, and Aim 4: Applications to a variety of structural problems related to the biosynthesis of LPS in Gram- negative bacteria and characterization of hybrid O-antigen/lipid A molecules in vesicle-based vaccines.  We have established a new collaboration with Dr. Bryan Davies' group to develop mass spectrometry methods to characterize peptide/lipid A interactions in support of the hunt for better antimicrobials. The continued collaboration with Dr. Stephen Trent's group emphasizes: (i) approaches for deciphering the biosynthetic pathways of bacterial LPS that endow them with the remarkable ability to re-design their outer membranes and develop antibiotic resistance, and (ii) innovative vaccine design based on antigenic LPS in vesicles.    Narrative: Gram-negative bacteria are responsible for some of the deadliest and more widespread pandemics in the world. The proposed work focuses on the development of advanced mass spectrometry approaches for characterization of complex lipopolysaccharides, including the endotoxic lipid A domains, that comprise the outer membrane of Gram-negative bacteria. The proposed work will be applied to evaluate new antimicrobials and support development of hybrid vaccines.",UVPD-MS Characterization of Lipopolysaccharides,9774073,R01GM103655,"['Acylation', 'Address', 'Advanced Development', 'Affinity', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Architecture', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Bacterial Vaccines', 'Basic Science', 'Binding', 'Catalogs', 'Cells', 'Chemical Warfare', 'Code', 'Collaborations', 'Combating Antibiotic Resistant Bacteria', 'Communicable Diseases', 'Complex', 'Complex Mixtures', 'Custom', 'Databases', 'Decision Trees', 'Development', 'Distal', 'Exhibits', 'Focus Groups', 'Glycolipids', 'Gram-Negative Bacteria', 'Hybrids', 'Hydrophobicity', 'Immune system', 'Immunization', 'Infection', 'Ions', 'Lipid A', 'Lipopolysaccharide Biosynthesis Pathway', 'Lipopolysaccharides', 'Mass Spectrum Analysis', 'Membrane', 'Methodology', 'Methods', 'Modification', 'Molecular', 'O Antigens', 'Oligosaccharides', 'Pathogenicity', 'Pathway interactions', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphorylation', 'Polysaccharides', 'Process', 'Production', 'Property', 'Publishing', 'Resistance', 'Serotyping', 'Structure', 'System', 'Tail', 'Vaccine Design', 'Vaccines', 'Variant', 'Vesicle', 'Virulence', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'cell envelope', 'chronic infection', 'design', 'high throughput analysis', 'hydrophilicity', 'improved', 'innovation', 'innovative technologies', 'inorganic phosphate', 'instrument', 'method development', 'mortality', 'novel', 'novel therapeutics', 'pandemic disease', 'response', 'screening', 'sugar', 'tandem mass spectrometry', 'ultraviolet']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2019,297043,0.039671448529459384
"Physical detection of HLA-C binding peptides to identify and predict immunogenic personal neoepitopes for improving cancer vaccines Peptides bound to class I HLA molecules (HLA-A, -B and –C) arise from endogenous or foreign proteins that are cleaved by the proteasome and peptidases of the endoplasmic reticulum prior to loading and display by surface HLA class I proteins. Each HLA allele is estimated to bind and present ~1,000-10,000 unique peptides to T cells. Given such diversity in HLA binding, an important question is whether we can predict whether a particular peptide is likely to bind to a specific HLA allele. Indeed, peptide-binding rules have been long-studied extensively for a subset of HLA alleles and encoded in advanced neural network-based algorithms that predict binding. Historically, little attention has been paid to HLA-C because of its perceived lower surface expression and hence predictive algorithms of HLA-C are very much lacking, as only a few thousand peptides epitopes have been reported in databases. New studies, however, suggests that important epitopes can arise from HLA-C, and have been detected for HIV, EBV, CMV and influenza. Our hypothesis is that large-scale datasets of endogenous HLA bound peptides can improve prediction of binding, and that through applying such an approach to HLA-C, a substantial increase in numbers of actionable immunogenic targets on tumor cells can be gained. Recently, I spearheaded a successful effort to integrate my expertise in experimental workflows for the isolation of HLA-bound peptides with newly available innovations in analysis and instrumentation for mass spectrometry (MS) to create a high throughput MS-based approach for the physical detection of peptides directly displayed by HLA molecules. This workflow and analytic framework now provides an exciting opportunity to generate high-quality data to directly address these challenges. In Aim 1, to systematically identify HLA-C binding peptides, we will use MS to provide experimentally-derived datasets of peptides from 21 HLA-C alleles to provide 99.9% global population coverage. In Aim 2, to define the rules of processing and presentation across HLA-C de novo, we will discover the binding motifs of the HLA-C peptides and use this information to develop predictive algorithms, which we will validate using independent datasets. In Aim 3, we seek to determine if predicted tumor neoepitopes are physically detected on patient tumor cells. We will perform experimental validation of HLA-C prediction algorithms directly on tumor samples available from study subjects enrolled on high-priority clinical trials of personalized neoantigen-targeting cancer vaccines at DFCI using a new nano-scale MS-based analysis. We will confirm the immunogenicity of the detected HLA-C epitopes through in vitro T cell assays using banked peripheral blood mononuclear cell samples collected from study subjects. We anticipate the proposed studies to enable fuller understanding HLA-C epitope presentation, more robust prediction of HLA-C peptide epitopes, and expansion of the spectrum of actionable immune targets. Immune recognition of short peptides representative of proteins within a cell in conjunction with a group of surface molecules called HLA is essential for the process of immune reactivity but characterization of the properties of how these peptides bind to HLA molecules has been constrained by the limited available information about these peptides. We have developed a new high-throughput approach to rapidly isolate thousands of HLA-bound peptides directly from informative cell lines and tumor samples (from patients with melanoma, glioblastoma and renal cell cancer) and to use this information to develop novel algorithms to predict binding of peptides to HLA. We anticipate the proposed studies t o enable fuller understanding of how a subset of understudied HLA molecules (i.e. HLA-C) interact with their binding peptides, to improve prediction of HLA-C bound peptides, and to expand the spectrum of actionable immune targets.",Physical detection of HLA-C binding peptides to identify and predict immunogenic personal neoepitopes for improving cancer vaccines,9625817,R21CA216772,"['Acids', 'Address', 'Algorithms', 'Alleles', 'Antigen Presentation', 'Attention', 'Binding', 'C-Peptide', 'Cancer Vaccines', 'Cell Line', 'Cells', 'Cellular Assay', 'Cleaved cell', 'Clinical', 'Clinical Trials', 'Cytomegalovirus', 'Cytotoxic T-Lymphocytes', 'DNA sequencing', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Endoplasmic Reticulum', 'Enrollment', 'Epitopes', 'Frequencies', 'Funding', 'Gene Expression', 'Glioblastoma', 'HIV', 'HLA-A gene', 'HLA-C Antigens', 'Human', 'Human Herpesvirus 4', 'Immune', 'Immune Targeting', 'Immune response', 'Immunity', 'Immunoprecipitation', 'In Vitro', 'Influenza', 'Letters', 'Ligands', 'Lymphocyte', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Methods', 'Network-based', 'Operative Surgical Procedures', 'Patients', 'Peptide Hydrolases', 'Peptide Sequence Determination', 'Peptides', 'Peripheral Blood Mononuclear Cell', 'Phase', 'Population', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Renal Cell Carcinoma', 'Renal carcinoma', 'Reporting', 'Research', 'Resected', 'Role', 'Sampling', 'Somatic Mutation', 'Specimen', 'Study Subject', 'Surface', 'T cell response', 'T memory cell', 'T-Lymphocyte', 'Testing', 'Training', 'Tumor Antigens', 'Tumor Cell Line', 'Vaccine Design', 'Validation', 'Viral', 'base', 'experience', 'high risk', 'immunogenic', 'immunogenicity', 'improved', 'innovation', 'instrument', 'instrumentation', 'machine learning algorithm', 'melanoma', 'multicatalytic endopeptidase complex', 'nanoscale', 'neoantigen vaccine', 'neoantigens', 'neoplastic cell', 'neural network', 'next generation', 'novel', 'polypeptide C', 'prediction algorithm', 'programs', 'tool', 'tumor', 'vaccine trial']",NCI,DANA-FARBER CANCER INST,R21,2019,187702,0.02043803958830075
"Optimization and joint modeling for peptide detection by tandem mass spectrometry Project Summary/Abstract Proteins are the primary functional molecules in living cells, and tandem mass spectrometry provides the most efﬁcient means of studying proteins in a high-throughput fashion. The proposal aims to use state-of-the-art methods from the ﬁelds of machine learning, statistics, and natural language processing to improve our ability to make sense of large tandem mass spectrometry data sets. Our project will focus on three key problems in the analysis of such data: 1. facilitating the use of previously annotated spectra to improve our ability to annotate new spectra by creating  a hybrid search scheme that compares an observed spectrum to a database comprised of theoretical spectra  and previously annotated spectra, 2. enabling the efﬁcient and accurate detection of peptides containing post-translational modiﬁcations and  sequence variants, and 3. detecting sets of peptide species that are co-fragmented in the mass spectrometer and hence give rise to  complex, mixture spectra. Each of these aims will improve the ability of mass spectrometrists to efﬁciently and accurately identify and quantify proteins in complex mixtures. To increase the impact of our work, we will continue to make all of our tools available as free software. Project narrative The applications of mass spectrometry, and its promises for improvements of human health, are numerous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and speciﬁc diagnostic and prognostic screens. However, making optimal use of mass spectrometry data requires sophisticated computational methods. This project will develop and apply novel statistical and machine learning methods for interpreting mass spectra.",Optimization and joint modeling for peptide detection by tandem mass spectrometry,9419312,R01GM121818,"['Algorithms', 'Amino Acid Sequence', 'Automobile Driving', 'Biological', 'Cells', 'Collection', 'Column Chromatography', 'Communities', 'Complex', 'Complex Mixtures', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Discipline', 'Economics', 'Fertilization', 'Game Theory', 'Health', 'Human', 'Hybrids', 'Joints', 'Libraries', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Natural Language Processing', 'Operations Research', 'Peptides', 'Population', 'Post-Translational Protein Processing', 'Proteins', 'Proteomics', 'Protocols documentation', 'Sampling', 'Scheme', 'Shotguns', 'Speed', 'Statistical Models', 'Time', 'Variant', 'Work', 'computer based statistical methods', 'computerized tools', 'cost', 'disease phenotype', 'experimental study', 'improved', 'innovation', 'learning strategy', 'mass spectrometer', 'mathematical theory', 'novel', 'prognostic', 'protein aminoacid sequence', 'speech recognition', 'statistics', 'tandem mass spectrometry', 'theories', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2018,315421,0.08260694832740166
"Binding-Site Modeling with Multiple-Instance Machine-Learning Project Summary / Abstract This proposal is entitled “Binding-Site Modeling with Multiple-Instance Machine-Learning.” A number of in- terrelated computational methods for making predictions about the biological behavior of small molecules have been the subject of development within the Jain Laboratory for over twenty years. These share a common strat- egy that considers molecular interactions at their surface interface, where proteins and ligands actually interact. These methods yield measurements of similarity between small molecules or between protein binding pockets. They also yield measurements of the complementarity of a small molecule to a protein binding site (the molecular docking problem). A generalization of these concepts makes possible the construction of a virtual binding site for quantitative activity prediction purely from data about the biological activities of a set of small molecules.  The goals of the proposed work include further improving the accuracy and breadth of applicability of the binding site modeling approach. The primary application of the approach is to guide optimization of leads within medicinal chemistry projects, and to quantify potential off-target effects during pre-clinical drug discovery.  A critical focus of the work will be in data and software dissemination, in order to accelerate the efficient development of targeted therapies. In addition to methods development, the proposed work will involve broad application of these state-of-the-art predictive modeling methods. The proposed work will proceed with the col- laborative input of our pharmaceutical industry colleagues, who have specialized knowledge and data sets that are vital for cutting-edge work in computer-aided drug design.  The expected results include more efficient lead optimization (fewer compounds to reach desired biological pa- rameters), truly effective scaffold replacement (to move away from a molecular series with biological limitations), and improved computational predictions of off-target effects during pre-clinical drug design. Project Narrative This project seeks to refine an integrated platform for physically realistic prediction of ligand binding affinities using multiple methods that span small molecule molecular similarity, molecular docking, and protein binding site similarity. These tools will provide predictive modeling unrestrained by scaffold congruence between what is known and what is to be predicted. Prediction of bioactive molecular poses and activities to guide lead optimiza- tion and to quantify off-target liability effects are applications of the effort, and data and software will be made widely available to academic and industrial research groups.",Binding-Site Modeling with Multiple-Instance Machine-Learning,9454479,R01GM101689,"['Address', 'Affinity', 'Behavior', 'Binding', 'Binding Proteins', 'Binding Sites', 'Biological', 'Biological Assay', 'Characteristics', 'Charge', 'Chemicals', 'Computer Assisted', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Development', 'Docking', 'Drug Design', 'Drug Industry', 'Electrostatics', 'Formulation', 'Future', 'Goals', 'Hydrogen Bonding', 'Industrialization', 'Industry Collaboration', 'Knowledge', 'Laboratories', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Probes', 'Performance', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Physics', 'Positioning Attribute', 'Procedures', 'Protein Conformation', 'Proteins', 'Research', 'Series', 'Structural Models', 'Structural Protein', 'Surface', 'Testing', 'Variant', 'Work', 'base', 'blind', 'combinatorial', 'design', 'drug discovery', 'improved', 'interest', 'lead optimization', 'learning strategy', 'method development', 'novel', 'novel strategies', 'physical model', 'pre-clinical', 'predictive modeling', 'scaffold', 'segregation', 'small molecule', 'targeted treatment', 'tool', 'treatment fees', 'virtual']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2018,310202,-0.019086843016794093
"Machine Learning Tools for Discovery and Analysis of Active Metabolic Pathways ﻿    DESCRIPTION (provided by applicant): This project aims to develop new statistical machine learning methods for metabolomics data from diverse platforms, including targeted and unbiased/global mass spectrometry (MS), labeled MS experiments for measuring metabolic ﬂux and Nuclear Magnetic Resonance (NMR) platforms. Unbiased MS and NMR proﬁling studies result in identifying a large number of unnamed spectra, which cannot be directly matched to known metabolites and are hence often discarded in downstream analyses. The ﬁrst aim develops a novel kernel penalized regression method for analysis of data from unbiased proﬁling studies. It provides a systematic framework for extracting the relevant information from unnamed spectra through a kernel that highlights the similarities and differences between samples, and in turn boosts the signal from named metabolites. This results in improved power in identiﬁcation of named metabolites associated with the phenotype of interest, as well as improved prediction accuracy. An extension of this kernel-based framework is also proposed to allow for systematic integration of metabolomics data from diverse proﬁling studies, e.g. targeted and unbiased MS proﬁling technologies. The second aim pro- vides a formal inference framework for kernel penalized regression and thus complements the discovery phase of the ﬁrst aim. The third aim focuses on metabolic pathway enrichment analysis that tests both orchestrated changes in activities of steady state metabolites in a given pathway, as well as aberrations in the mechanisms of metabolic reactions. The fourth aim of the project provides a uniﬁed framework for network-based integrative analysis of static (based on mass spectrometry) and dynamic (based on metabolic ﬂux) metabolomics measurements, thus providing an integrated view of the metabolome and the ﬂuxome. Finally, the last aim implements the pro- posed methods in easy-to-use open-source software leveraging the R language, the capabilities of the Cytoscape platform and the Galaxy workﬂow system, thus providing an expandable platform for further developments in the area of metabolomics. The proposed software tool will also provide a plug-in to the Data Repository and Coordination Center (DRCC) data sets, where all regional metabolomics centers supported by the NIH Common Funds Metabolomics Program deposit curated data. PUBLIC HEALTH RELEVANCE: Metabolomics, i.e. the study of small molecules involved in metabolism, provides a dynamic view into processes that reﬂect the actual physiology of the cell, and hence offers vast potential for detection of novel biomarkers and targeted therapies for complex diseases. However, despite this potential, the development of computational methods for analysis of metabolomics data lags the rapid growth of metabolomics proﬁling technologies. The current application addresses this need by developing novel statistical machine learning methods for integrative analysis of static and dynamic metabolomics measurements, as well as easy-to-use open-source software to facilitate the application of these methods.",Machine Learning Tools for Discovery and Analysis of Active Metabolic Pathways,9462161,R01GM114029,"['Address', 'Adoption', 'Anabolism', 'Area', 'Biochemical Pathway', 'Biochemical Reaction', 'Biological', 'Biological Assay', 'Cardiovascular Diseases', 'Cell physiology', 'Cells', 'Characteristics', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diabetes Mellitus', 'Disease', 'Environment', 'Environmental Risk Factor', 'Equilibrium', 'Funding', 'Galaxy', 'Homeostasis', 'Imagery', 'Knowledge', 'Label', 'Language', 'Letters', 'Linear Models', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methodology', 'Methods', 'Names', 'Network-based', 'Nuclear Magnetic Resonance', 'Pathway interactions', 'Phase', 'Phenotype', 'Plug-in', 'Procedures', 'Process', 'Prognostic Marker', 'Proteomics', 'Reaction', 'Sampling', 'Signal Transduction', 'Software Tools', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Work', 'base', 'biological systems', 'biomarker discovery', 'data warehouse', 'diagnostic biomarker', 'experimental study', 'flexibility', 'high dimensionality', 'improved', 'insight', 'interest', 'learning strategy', 'metabolome', 'metabolomics', 'new technology', 'novel', 'novel diagnostics', 'novel marker', 'open source', 'programs', 'public health relevance', 'rapid growth', 'response', 'small molecule', 'targeted treatment', 'tool', 'transcriptomics']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2018,338393,0.070671492253398
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9579149,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Data Analyses', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'SLEB2 gene', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'functional group', 'improved', 'innovation', 'instrument', 'novel', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2018,314000,0.023952968166928268
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9406318,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cancer Etiology', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2018,356625,0.08323257777792344
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,9659552,UG3HL145593,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NHLBI,PURDUE UNIVERSITY,UG3,2018,375000,0.04978721529258343
"Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets PROJECT SUMMARY/ABSTRACT Recent advances in high-resolution mass spectrometry (HRMS) instrumentation have not been fully leveraged to upgrade the information content of metabolomics datasets obtained from stable isotope labeling studies. This is primarily due to lack of validated software tools for extracting and interpreting isotope enrichments from HRMS datasets. The overall objective of the current application is to develop tools that enable the metabolomics community to fully leverage stable isotopes to profile metabolic network dynamics. Two new tools will be implemented within the open-source OpenMS software library, which provides an infrastructure for rapid development and dissemination of mass spectrometry software. The first tool will automate tasks required for extracting isotope enrichment information from HRMS datasets, and the second tool will use this information to group ion peaks into interaction networks based on similar patterns of isotope labeling. The tools will be validated using in-house datasets derived from metabolic flux studies of animal and plant systems, as well as through feedback from the metabolomics community. The rationale for the research is that the software tools will enable metabolomics investigators to address important questions about pathway dynamics and regulation that cannot be answered without the use of stable isotopes. The first aim is to develop a software tool to automate data extraction and quantification of isotopologue distributions from HRMS datasets. The software will provide several key features not included in currently available metabolomics software: i) a graphical, interactive user interface that is appropriate for non-expert users, ii) support for native instrument file formats, iii) support for samples that are labeled with multiple stable isotopes, iv) support for tandem mass spectra, and v) support for multi-group or time-series comparisons. The second aim is to develop a companion software that applies machine learning and correlation-based algorithms to group unknown metabolites into modules and pathways based on similarities in isotope labeling. The third aim is to validate the tools through comparative analysis of stable isotope labeling in test standards and samples from animal and plant tissues, including time-series and dual-tracer experiments. A variety of collaborators and professional working groups will be engaged to test and validate the software, and the tools will be refined based on their feedback. The proposed research is exceptionally innovative because it will provide the advanced software capabilities required for both targeted and untargeted analysis of isotopically labeled metabolites, but in a flexible and user-friendly environment. The research is significant because it will contribute software tools that automate and standardize the data processing steps required to extract and utilize isotope enrichment information from large-scale metabolomics datasets. This work will have an important positive impact on the ability of metabolomics investigators to leverage information from stable isotopes to identify unknown metabolic interactions and quantify flux within metabolic networks. In addition, it will enable entirely new approaches to study metabolic dynamics within biological systems. PROJECT NARRATIVE The proposed research is relevant to public health because it will develop novel software tools to quantify and interpret data from stable isotope labeling experiments, which can be used to uncover relationships between metabolites and biochemical pathways. These tools have potential to accelerate progress toward identifying the causes and cures of many important diseases that impact metabolism.",Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets,9589711,U01CA235508,"['Address', 'Algorithms', 'Animals', 'Biochemical Pathway', 'Biological', 'Communities', 'Companions', 'Complement', 'Computer software', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Environment', 'Feedback', 'Ions', 'Isotope Labeling', 'Isotopes', 'Knowledge', 'Label', 'Letters', 'Libraries', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Network-based', 'Outcome', 'Pathway interactions', 'Pattern', 'Plants', 'Process', 'Public Health', 'Publishing', 'Regulation', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resolution', 'Sampling', 'Series', 'Software Tools', 'Stable Isotope Labeling', 'Standardization', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'Validation', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'experience', 'experimental study', 'file format', 'flexibility', 'improved', 'innovation', 'instrument', 'instrumentation', 'metabolic abnormality assessment', 'metabolic phenotype', 'metabolic profile', 'metabolomics', 'novel', 'novel strategies', 'open source', 'operation', 'stable isotope', 'tandem mass spectrometry', 'tool', 'user-friendly', 'working group']",NCI,VANDERBILT UNIVERSITY,U01,2018,439996,0.05225838875779643
"Assay Classifier Engine (ACE) for enhancing splice sensor assay performance SUMMARY:  The goal of this proposal is to improve the sensitivity and specificity of the Spinach-based splice sensor platform by developing a novel multiprobe (MP) assay design and a companion machine learning-based classification algorithm called assay classifier engine (ACE). Improvement in sensitivity and specificity of the splice sensor platform enables its application to detect endogenous RNA isoforms with low copy number and distinguish alternative RNA isoforms that share high degree of sequence similarities.  The aim of any assay development effort is to achieve excellent assay specificity and sensitivity. However, this is often a futile endeavor since specificity and sensitivity are two inversely correlated factors. The underlying reason for poor sensitivity or specificity is due to the off-target signals generated by competing molecules present in the sample. In the field of diagnostics, one of the ways these issues are addressed is to perform multiple single probe testing instead of one single probe testing. While individual singe probe assays might have poor specificity and sensitivity, when combined, these assays synergistically improve the sensitivity and specificity of the ultimate diagnostic determination. In the field of research and drug discovery, researchers have employed a multitude of strategies (e.g. signal amplification, reaction cascades, or sample enrichment) to improve sensitivity and MP design or strand displacement strategies to improve specificity. Some of the PCR- based methods have combined both enzyme-based signal amplification and MP strategies to improve assay determination. However, when it comes to detecting targets that are highly similar to their competitors, such as detecting single nucleotide polymorphism, DNA methylation, RNA modification and alternative splicing, there is still an unmet need for more sensitive and specific analytical methods.  In the past few years, Lucerna has developed Spinach-based sensors to detect intractable metabolites and biomolecules. One such sensor is the splice sensor, which is a Spinach-based sensor that can generate fluorescence signal based on the alternative RNA isoform of interest. One of the challenges encountered during splice sensor assay development is the lack of sensitivity toward low copy number RNA isoforms and low specificity when distinguishing two splice isoforms that share a high sequence similarity. To overcome this challenge in this proposal, we will develop a MP assay panel comprised of splice sensor variants that recognize the target RNA and the competitor with varying binding affinities and differing signal responses. We will use data sets generated from the MP assay to train a ML-based ACE algorithm to make target determination in test samples. Further, we will develop a quantitative MP data set and re-train the ACE algorithm to classify the assay signals into various categories based on target concentrations in the test sample. This new ACE algorithm will then be tested against conventional single probe assays to determine specificity and sensitivity improvement of the MP assay platform. PROJECT NARRATIVE: Improved specificity and sensitivity are highly sought-after features in assays where there are high similarity between the target and its competitors or when the target exists naturally in very low abundance. To address this unmet need, we will develop a fluorescence sensor-based multiprobe assay approach and a companion machine learning-based assay classifier engine (ACE). The ACE algorithm will integrate the multiprobe assay data and classify them based on trained machine learning models to make sample determination with enhanced specificity, sensitivity, and dynamic range than possible with conventional single probe assays.",Assay Classifier Engine (ACE) for enhancing splice sensor assay performance,9622514,R43GM130258,"['Address', 'Adopted', 'Affinity', 'Algorithms', 'Alternative Splicing', 'Area Under Curve', 'Binding', 'Binding Sites', 'Biochemical', 'Biological Assay', 'Categories', 'Cells', 'Characteristics', 'Classification', 'Companions', 'Custom', 'DNA Methylation', 'Data', 'Data Set', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Disease', 'Enzyme-Linked Immunosorbent Assay', 'Enzymes', 'Evaluation', 'Exhibits', 'Fluorescence', 'Goals', 'Individual', 'Learning', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Methods', 'Modeling', 'Modification', 'Molecular', 'Nerve Degeneration', 'Nucleotides', 'Output', 'Pattern', 'Performance', 'Process', 'Protein Isoforms', 'RNA', 'RNA Splicing', 'Reaction', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Sampling', 'Scientist', 'Sensitivity and Specificity', 'Series', 'Side', 'Signal Transduction', 'Single Nucleotide Polymorphism', 'Specificity', 'Spinach - dietary', 'Technology', 'Testing', 'Time', 'Titrations', 'Training', 'Variant', 'analytical method', 'aptamer', 'assay development', 'base', 'cost', 'design', 'drug discovery', 'experience', 'improved', 'interest', 'novel', 'outcome forecast', 'predictive modeling', 'response', 'sensor', 'targeted biomarker']",NIGMS,"LUCERNA, INC.",R43,2018,224925,-0.007822138200732959
"Multiplexed high-content assay for toxicity profiling using live iPSC-derived cardiomyocyte lines with lineage-specific barcoding Project Summary/Abstract Human induced pluripotent stem cells (hiPSCs) are poised to transform toxicological evaluation, however new approaches to enable their functional and structural profiling are needed to improve the utility of hiPSC -based models for predictive and mechanistic toxicology screening. This need is addressed by our project’s Specific Aims that encompass (1) development of a novel platform for generation of hiPSC-derived reporter cells; (2) generation of a panel of multicolor hiPSC-derived cardiomyocytes (hiPSC-CMs) with stable lineage specific fluorescent reporters; and (3) implementation and validation of a pilot machine learning-enabled predictive cardiotoxicity screen using these tools. The proposed tools are configured to be extensible to other toxicology- relevant pathways and phenotypes making it uniquely positioned to capitalize on the growing commercial need for high-throughput predictive toxicology assays. The project deliverables benefit public health by improving the ability to rapidly identify liabilities in specific cardiomyocyte lineage types, thus reducing the time and cost to pinpoint cardiotoxicity of pharmaceutical and environmental chemicals. Project Narrative The assay and reagents established in the course of this project directly address the goals of significant initiatives to improve the effectiveness of cardiotoxicity testing, such as the FDA’s CiPA initiative and the work of the Cardiac Safety Research Consortium. The resulting improvements in the pace and precision of drug testing will result in public health benefit through the development of more cost-effective and safer medicines. Beyond toxicological evaluation of therapeutic compounds, our innovative technology will deliver additional benefit to public health by virtue of its utility in investigating the toxicities of environmental chemicals, in line with the focus of government agencies and initiatives such as the EPA and Tox21 in the US and EU-ToxRisk in Europe.",Multiplexed high-content assay for toxicity profiling using live iPSC-derived cardiomyocyte lines with lineage-specific barcoding,9623156,R44TR002572,"['Address', 'Algorithms', 'Biological Assay', 'CRISPR/Cas technology', 'Cardiac', 'Cardiac Myocytes', 'Cardiotoxicity', 'Cell Line', 'Cell Lineage', 'Cells', 'Cellular Assay', 'Cellular Structures', 'Chemicals', 'Classification', 'Contracts', 'Data', 'Development', 'Drug Modelings', 'Drug toxicity', 'Effectiveness', 'Europe', 'Evaluation', 'Foundations', 'Generations', 'Goals', 'Government Agencies', 'Health Benefit', 'Heart Atrium', 'Human', 'In Vitro', 'Industry Standard', 'Machine Learning', 'Medicine', 'Methods', 'Microscopy', 'Mitochondria', 'Nodal', 'Nuclear', 'Pathway interactions', 'Patients', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Phenotype', 'Physiological', 'Population Heterogeneity', 'Positioning Attribute', 'Public Health', 'Reagent', 'Reporter', 'Reporting', 'Research', 'Safety', 'Sarcomeres', 'Site', 'Small Business Innovation Research Grant', 'Specificity', 'Speed', 'Structure', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Training', 'Treatment-Related Cancer', 'Validation', 'Ventricular', 'Withdrawal', 'Work', 'base', 'cell immortalization', 'clinical candidate', 'clinical predictors', 'cost', 'cost effective', 'drug discovery', 'drug testing', 'environmental chemical', 'expression vector', 'genome editing', 'high throughput screening', 'immortalized cell', 'improved', 'induced pluripotent stem cell', 'innovation', 'innovative technologies', 'model development', 'new technology', 'novel', 'novel strategies', 'phase I trial', 'pre-clinical', 'predictive modeling', 'predictive test', 'predictive tools', 'programs', 'response', 'screening', 'site-specific integration', 'success', 'therapeutic development', 'therapeutic evaluation', 'tool']",NCATS,"CAIRN BIOSCIENCES, INC.",R44,2018,1178386,0.005985071481508057
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,9589783,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computer Simulation', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Diet', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computerized tools', 'dark matter', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2018,1076717,0.0696303955939617
"Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria PROJECT SUMMARY Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacterial infections are increasing in incidence and novel antibiotics are urgently needed to combat this growing threat to public health. A major roadblock to the development of novel antibiotics is our poor understanding of the structural features of small molecules that correlate with bacterial penetration and efflux. As a result, while potent biochemical inhibitors can often be identified for new targets, developing them into compounds with whole-cell antibacterial activity has proven challenging. To address this critical problem, we propose herein a comprehensive, multidisciplinary approach to develop quantitative models to predict small-molecule penetration and efflux in Gram-negative bacteria. We have pioneered a general platform for systematic, quantitative evaluation of small-molecule accumulation in bacteria, using label-free LC-MS/MS detection and multivariate cheminformatic analysis. We have also developed unique isogenic strain sets of wild-type, hyperporinated, efflux-knockout, and doubly-compromised E. coli, P. aeruginosa, and A. baumannii that allow us to dissect the individual contributions of outer/inner membrane penetration and active efflux to net accumulation, using a kinetic model that accurately recapitulates available experimental data. Moreover, we have developed machine learning and neural network approaches to QSAR (quantitative structure–activity relationship) modeling of pharmacological properties that will now be used to develop predictive cheminformatic models for Gram-negative accumulation, penetration, and efflux. This project will be carried out by a multidisciplinary SPEAR-GN Project Team (Small-molecule Penetration & Efflux in Antibiotic-Resistant Gram-Negatives, “speargun”) involving the labs of Derek Tan (MSK, PI), Helen Zgurskaya (OU, PI), Bradley Sherborne (Merck, Lead Collaborator), Valentin Rybenkov (OU, Co-I), Adam Duerfeldt (OU, Co-I), Carl Balibar (Merck, Collaborator), and David McLaren (Merck, Collaborator), comprising extensive combined expertise in organic and diversity-oriented synthesis, biochemistry, microbiology, high- throughput screening, mass spectrometry, biophysical modeling, cheminformatics, and medicinal chemistry. Herein, we will design and synthesize chemical libraries with diverse structural and physicochemical properties; analyze their accumulation in the isogenic strain sets in both high-throughput and high-density assay formats; extract kinetic parameters for penetration and efflux from the resulting experimental datasets; develop and validate robust QSAR models for accumulation, penetration, and efflux; and demonstrate the utility of these models in medicinal chemistry campaigns to develop novel Gram-negative antibiotics against three targets. This project will provide a major advance in the field of antibacterial drug discovery, providing powerful enabling tools to the scientific community to address this major threat to public health. PUBLIC HEALTH RELEVANCE Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacteria pose a growing threat to public health in the U.S. and globally. A major obstacle to the development of new antibiotics to combat such infections is our poor understanding of the chemical requirements for small molecules to enter Gram-negative cells and to avoid ejection by efflux pumps. The proposed comprehensive, multidisciplinary research program aims to develop predictive computational tools to identify such molecules by carrying out large-scale, quantitative analyses of the accumulation of diverse small molecules in Gram-negative bacteria. These tools will then enable medicinal chemistry campaigns to develop novel antibiotics.",Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria,9486312,R01AI136795,"['Acinetobacter baumannii', 'Address', 'Algorithmic Software', 'Anti-Bacterial Agents', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Bacteria', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biological Availability', 'Biological Neural Networks', 'Cells', 'Chemicals', 'Communities', 'Data', 'Data Set', 'Detection', 'Development', 'Effectiveness', 'Escherichia coli', 'Gram-Negative Bacteria', 'Gram-Negative Bacterial Infections', 'Human', 'Incidence', 'Individual', 'Infection', 'Interdisciplinary Study', 'Kinetics', 'Knock-out', 'Label', 'Lead', 'Libraries', 'Machine Learning', 'Mammalian Cell', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Membrane', 'Microbiology', 'Modeling', 'Oral', 'Partner in relationship', 'Penetration', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacology', 'Property', 'Pseudomonas aeruginosa', 'Public Health', 'Quantitative Evaluations', 'Quantitative Structure-Activity Relationship', 'Role', 'Structure', 'Testing', 'Variant', 'analog', 'base', 'biophysical model', 'cell envelope', 'cheminformatics', 'combat', 'computerized tools', 'density', 'design', 'drug discovery', 'efflux pump', 'high throughput screening', 'improved', 'inhibitor/antagonist', 'interdisciplinary approach', 'lead optimization', 'learning network', 'multidisciplinary', 'novel', 'predictive modeling', 'programs', 'prospective', 'public health relevance', 'screening', 'small molecule', 'small molecule libraries', 'success', 'tool']",NIAID,SLOAN-KETTERING INST CAN RESEARCH,R01,2018,1527746,0.009840935820182086
"Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC PROJECT SUMMARY The Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC (CMP-GA) is a cross-cutting team with advanced high-throughput chemical analytics and big data capabilities to develop a comprehensive map of molecular transducers of physical activity. The investigative team excels in ultrasensitive, precise and spatially resolved analyses of small molecules, lipids, and proteins. The team members have strong academic records as innovative, independent scientists, core laboratory directors and effective collaborators in complex research initiatives. Instrumentation includes state-of-the-art ultra-high resolution accurate mass high-field Orbitrap tandem mass spectrometry (MS) and ultraperformance liquid chromatography (UPLC); three- dimensional (3-D) molecular imaging via high throughput multi-modal MS at 5 m resolution; unique ion mobility-mass spectrometry machine-learning approaches for chemical identifications; and other such as GC- Orbitrap, 1D and 2D high field (800 MHz) NMR spectroscopy, ICP-MS, immunoassays, chemical and enzymatic assays, etc. The analytical laboratories are integrated through the NIH-supported Atlanta Clinical and Translational Sciences Institute, and operate within the outstanding research environment of Emory University and the Georgia Institute of Technology (GA Tech). CMP-GA has six elements organized to provide 1) leadership in the design and implementation of MoTrPAC goals; 2) bioinformatics, computational support and data delivery to the MoTrPAC Data Coordinating Center; 3) global, targeted and spatially resolved metabolomics; 4) metabolite forensics for unequivocal chemical identification of novel molecular transducers; 5) innovative proteomic and chemoproteomic technologies to define transducers within the redox proteome, ubiquitinome, acetylome, kinome and nuclear proteome; and 6) identification and quantification of lipid transducers. Through the successful completion of these aims and collaboration with the MoTrPAC consortium, investigators of CMP-GA will deliver a publically-available data resource and molecular transducer map that will enhance and accelerate mechanistic research on diseases and conditions affected by physical activity. PROJECT NARRATIVE This is a comprehensive metabolomics and proteomics chemical analysis site to support the Molecular Transducers of Physical Activity Consortium (MoTrPAC). Advanced analytical methods, including mass spectrometry, bioinformatics and chemical forensics are used to provide targeted and global analysis of small molecules, lipids, proteins to develop a molecular transducer map for physical activity.",Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC,9394009,U24DK112341,"['3-Dimensional', 'Adipocytes', 'Affect', 'Aging', 'Animal Experimentation', 'Animals', 'Automobile Driving', 'Big Data', 'Bioinformatics', 'Biological Assay', 'Chemicals', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Communication', 'Complement', 'Complex', 'Custom', 'Data', 'Data Coordinating Center', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Elements', 'Environment', 'Exercise', 'Forensic Medicine', 'Goals', 'Health', 'Health Benefit', 'Immunoassay', 'Institutes', 'Isotopes', 'Label', 'Laboratories', 'Leadership', 'Link', 'Lipids', 'Liquid Chromatography', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Modality', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Monitor', 'Muscle', 'NMR Spectroscopy', 'Neurodegenerative Disorders', 'Nuclear', 'Oral', 'Oxidation-Reduction', 'Oxidative Stress', 'Particle Size', 'Peptide Mapping', 'Phosphotransferases', 'Physical activity', 'Plasma', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Protocols documentation', 'Publications', 'Reaction', 'Records', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Signal Transduction', 'Site', 'System', 'Systems Biology', 'Technology', 'Time', 'Training', 'Transducers', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'advanced system', 'analytical method', 'chemoproteomics', 'cytokine', 'data resource', 'design', 'differential expression', 'innovation', 'instrumentation', 'ion mobility', 'lectures', 'member', 'metabolomics', 'molecular imaging', 'novel', 'oxidized lipid', 'phenotypic biomarker', 'response', 'small molecule', 'tandem mass spectrometry', 'tool', 'ultra high resolution']",NIDDK,EMORY UNIVERSITY,U24,2018,1612261,0.029869634989698374
"Illuminating Function of the Understudied Druggable Kinome Project Summary/Abstract Kinases are among the most important drug targets and clinically significant kinase inhibitors have been developed for multiple diseases. A subset of kinases, the understudied dark kinases (DKs), have received little or no attention because foundational data on their biochemical and biological functions is not available. This proposal will collect such data by perturbing DKs genetically and with small molecules and then measuring the cellular consequences using multiplex proteomic, gene expression, metabolomic and imaging assays. A subset of DKs with potential links to human disease will be intensively studied as a means to qualify new therapeutic drug targets. Data collected in this project will be aggregated with existing information from previous NIH-funded large-scale structural and genomic projects to create a Dark Kinase Knowledgebase (DKK) that provides gene-by-gene and network-level information on the dark kinome and its interaction with other signal transduction and regulatory networks. Close coordination with the NIH LINCS project will ensure data interoperability and make efficient use of informatics tools. The DKK will be developed in collaboration with the IDG Knowledge Management Center (KMC), adhere to standards for Findable, Accessible, Interoperable and Reusable (FAIR) data, and be accessible to human users and machines (via an API). Commercially available DK reagents be validated and extended with new genetic and chemical tools provided to the Resource Dissemination Center (RDOC). The overall approach will be iterative, with simpler methods applied first (e.g. simple gene knockout) and more sophisticated methods subsequently (e.g. stable CRIPSRa/i) pursued by an interdisciplinary team of chemists, computational biologists, mass spectroscopists and pharmacologists working on five linked aims. Aim 1 will develop a computational algorithm for prioritizing DKs, develop and maintain the DKK, and perform network-level analysis on the kinome using supervised and unsupervised machine learning. Aim 2 will measure kinase abundance in normal and perturbed cells using parallel reaction monitoring with stable isotope dilution (PRM-SID) and RNASeq and data analyzed using network inference tools to provide insight into dark and light kinome in diverse cell types. Aim 3 will perturb DKs with genetic tools such as CRIPSR/Cas9-mediated gene knockout, CRIPSRa/i to induce more subtle-up and down regulation and inducible gene inaction. The impact on cell fate, morphology and signal transduction will then be determined using PRM-SID, phosphoproteomics, RNASeq, gene reporter assays, metabolomics profiling and highly multiplex single-cell imaging. Aim 4 will extend DK analysis to small molecule inhibitors by carefully profiling existing drugs against DKs and by designing and synthesizing new chemical ligands. Aim 5 will involve collaboration with other investigators to assay the expression and function of DKs in primary human cells and tissues relevant to the NIH Precision Medicine Initiative. All aims will be pursued in parallel for a progressively expanding resource of data and tools for continued study of DKs. Project Narrative/Health Relevance Advancing understanding of understudied kinases, a highly druggable class of proteins, will increase knowledge about signal transduction and control over cellular physiology and is likely to reveal a subset of proteins that should be advanced as targets for new therapeutic drugs.",Illuminating Function of the Understudied Druggable Kinome,9564894,U24DK116204,"['Algorithms', 'Anabolism', 'Arthritis', 'Attention', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Process', 'Cell Line', 'Cell physiology', 'Cells', 'Chemicals', 'Chronic Obstructive Airway Disease', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Collection', 'Complement', 'Computational algorithm', 'Cystic Fibrosis', 'Data', 'Data Analyses', 'Development', 'Diabetes Mellitus', 'Disease', 'Down-Regulation', 'Drug Targeting', 'Engineering', 'Ensure', 'FAIR principles', 'Foundations', 'Funding', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Goals', 'Health', 'Homeostasis', 'Human', 'Image', 'Individual', 'Informatics', 'Information Resources Management', 'Knowledge', 'Libraries', 'Ligands', 'Light', 'Link', 'Logic', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mediating', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Mutate', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Play', 'Precision Medicine Initiative', 'Production', 'Proteins', 'Proteomics', 'Reaction', 'Reagent', 'Reporter', 'Reporter Genes', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Signal Transduction', 'Signal Transduction Pathway', 'Site', 'Supervision', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Tumor Tissue', 'United States National Institutes of Health', 'Up-Regulation', 'Validation', 'base', 'cell type', 'cellular imaging', 'clinically significant', 'computerized tools', 'data resource', 'design', 'human disease', 'human model', 'innovation', 'insight', 'interoperability', 'kinase inhibitor', 'knockout gene', 'knowledge base', 'metabolic profile', 'metabolomics', 'new therapeutic target', 'novel', 'novel therapeutics', 'phosphoproteomics', 'programs', 'protein protein interaction', 'screening', 'small molecule', 'small molecule inhibitor', 'stable isotope', 'structural genomics', 'therapeutic development', 'therapeutic target', 'tool', 'transcription factor', 'transcriptome sequencing', 'unsupervised learning']",NIDDK,UNIV OF NORTH CAROLINA CHAPEL HILL,U24,2018,2270717,-0.001296085531721469
"Feature Learning For Improved Multiplex Disease Diagnosis Abstract This proposal is for CATTS, a feature learning technique optimized for use in multiplex mass spectrometry (MS) fingerprinting assays. MS fingerprints consist of a large number of chemical species, leading to very high dimensional feature spaces, and subsequent high false-discovery rates. CATTS aims to reduce the size of this space, by using knowledge of the underlying biochemistry, as well as general-purpose clustering algorithms. Our preliminary results demonstrate that, when used as a feature-learning technique for a variety of classification methods, CATTS significantly improves assay sensitivity. This proposal takes our existing implementation of CATTS and extends it to support additional feature learning algorithms and classification methods. Additionally, its performance as a multiplex assay strategy will be tested on both protein and lipid MS fingerprint libraries, with an eye towards commercialization.. Relevance to public health: The detection of pathogens via mass spectroscopy fingerprinting is rapidly becoming a standard technique for clinical microbiology. However, high false detection rates and conflicting multiple identifications limit applicability, and make interpretation of results difficult. Our work on CATTS aims to improve the statistical performance of these assays. Preliminary results from studies on one dataset we intend to apply CATTS to suggest that UTIs and, in some cases antimicrobial resistance, can be detected, directly from patient samples. However, the statistical methods currently employed aren't reliable enough - the further development of CATTS will accelerate the development of this, and other mass-spectroscopy-based assays..",Feature Learning For Improved Multiplex Disease Diagnosis,9559527,R43GM128538,"['Algorithms', 'Antimicrobial Resistance', 'Biochemistry', 'Biodiversity', 'Biological Assay', 'Biological Neural Networks', 'Chemicals', 'Classification', 'Clinical Microbiology', 'Conflict (Psychology)', 'Data Set', 'Decision Trees', 'Detection', 'Development', 'Dimensions', 'Eye', 'Fingerprint', 'Immune', 'Knowledge', 'Learning', 'Libraries', 'Lipids', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Modeling', 'Noise', 'Organism', 'Pathogen detection', 'Patients', 'Performance', 'Process', 'Protein Fingerprints', 'Proteins', 'Public Health', 'Reporting', 'Research', 'Sampling', 'Statistical Methods', 'System', 'Techniques', 'Testing', 'Work', 'base', 'commercialization', 'disease diagnosis', 'feeding', 'forest', 'high dimensionality', 'improved', 'learning strategy', 'novel', 'vector']",NIGMS,"DEURION, LLC",R43,2018,189594,0.027801138347844256
"Digital representation of chemical mixtures to aid drug discovery and formulation PROJECT SUMMARY Collaborative Drug Discovery, Inc. (CDD) proposes to develop a suite of software modules to enable scientists to unambiguously represent chemical mixtures in standard machine-readable formats, filling an urgent and widely-recognized need. Chemicals are typically formulated as mixtures. Recording and communicating information about chemical mixtures is essential for scientists and support staff in the pharmaceutical industry, in academia, in non-profit research organizations, in government, at specialty chemical vendors, and at commercial manufacturers to: • discover, develop, formulate, manufacture and regulate drugs; • manage reagent inventories; comply with laboratory safety requirements; inform first responders; • describe and reproduce biomedical experiments; and • assess and disseminate information about toxicity risks of chemical reagents and consumer products.  A working committee of the International Union of Pure and Applied Chemistry (IUPAC) is close to formalizing “Mixtures InChI” (or MInChI), which will extend the International Chemical Identifier (InChI) to become the first standard to encompass mixtures. MInChI will effectively index mixtures in the same way that InChI indexes individual compounds.  CDD will first develop the data structures and software necessary to enable adoption and utilization of MInChI and create the first general-purpose system for recording information about chemical mixtures that is computable and interoperable. The most innovative part of the project and the bulk of the effort will be to develop a sophisticated automated translation tool that will accurately convert legacy catalogs of chemical mixtures from plaintext descriptions or ad hoc formats so that they are properly represented in a machine readable format that can in turn be easily rendered into MInChI identifiers. The broad vision is to help industry to overcome the barriers to adoption so that MInChI can quickly deliver benefits for drug discovery, chemical safety, and toxicology. PROJECT NARRATIVE The proposed project will create novel computational tools that will help researchers to efficiently and accurately document the composition of chemical mixtures in a format that computers can easily interpret, process, and exchange. This innovative capability will help to accelerate the discovery and development of novel and improved drugs against a wide range of diseases. It will also help to advance our understanding of the toxicology of mixtures (which often differs from the toxicology of individual components) and improve laboratory safety both in industry and in educational settings. !",Digital representation of chemical mixtures to aid drug discovery and formulation,9611819,R43TR002528,"['Academia', 'Address', 'Adoption', 'Anti-HIV Agents', 'Catalogs', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Code', 'Collaborations', 'Computer software', 'Computers', 'Data', 'Databases', 'Development', 'Disease', 'Drug Formulations', 'Drug Industry', 'Elements', 'English Language', 'Equipment and supply inventories', 'Government', 'Human', 'Individual', 'Industry', 'International', 'Laboratories', 'Letters', 'Machine Learning', 'Manufacturer Name', 'Methods', 'Modeling', 'Names', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Process', 'Readability', 'Reagent', 'Research', 'Research Infrastructure', 'Research Personnel', 'Risk', 'Safety', 'Scientist', 'Services', 'Shorthand', 'Solvents', 'Specific qualifier value', 'Structure', 'System', 'Technology', 'Text', 'Toxic effect', 'Toxicology', 'Traction', 'Training', 'Translations', 'Vendor', 'Vision', 'Visual', 'cofactor', 'computerized tools', 'consumer product', 'data structure', 'digital', 'drug discovery', 'emergency service responder', 'experimental study', 'improved', 'indexing', 'innovation', 'interoperability', 'medical specialties', 'member', 'natural language', 'novel', 'open source', 'text searching', 'tool']",NCATS,"COLLABORATIVE DRUG DISCOVERY, INC.",R43,2018,149471,0.016145801936251866
"Next Generation Testing Strategies for Assessment of Genotoxicity Project Summary  It is well recognized that current batteries of genetic toxicology assays exhibit two critical deficiencies. First, the throughput capacity of in vitro mammalian cell genotoxicity tests is low, and does not meet current needs. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no consideration for potency, and virtually no information is provided about molecular targets and mechanisms. These deficiencies in hazard characterization prevent genotoxicity data from optimally contributing to modern risk assessments, where this information is essential. We will address these major problems with current in vitro mammalian cell genetic toxicity assays by developing methods and associated commercial assay kits that dramatically enhance throughput capacity, and delineate genotoxicants' primary molecular targets, while simultaneously providing information about potency. Once biomarkers and a family of multiplexed assays have been developed for these purposes, an interlaboratory trial will be performed with prototype assay kits to assess the transferability of the methods. Project Narrative  DNA damage that cannot be faithfully repaired results in gene mutation and/or chromosomal aberrations, and these effects are known to contribute to cancer and other severe diseases. Thus, there is an important need for sensitive assays to evaluate chemicals for genotoxic and other deleterious effects. The work proposed herein will address issues that have plagued genotoxicity assessments for the last several decades: low throughput, lack of potency metrics, and little to no information about molecular targets. We will address these major problems with current genetic toxicity assays by developing new methods and associated commercial assay kits.",Next Generation Testing Strategies for Assessment of Genotoxicity,9465735,R44ES029014,"['Address', 'Affect', 'Aneugens', 'Antioxidants', 'Appearance', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Biological Response Modifiers', 'Bleomycin', 'Caspase', 'Cell Cycle', 'Cell Nucleus', 'Cells', 'Chemicals', 'Chromosome abnormality', 'Chromosomes', 'Classification', 'Cleaved cell', 'Colcemid', 'Companions', 'Complex', 'Computer Simulation', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'DNA-PKcs', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Dose', 'Epitopes', 'Etoposide', 'Exhibits', 'Family', 'GADD45A gene', 'Gamma-H2AX', 'Gene Mutation', 'Genetic', 'Goals', 'Harvest', 'Histone H3', 'Human', 'In Vitro', 'Intercalating Agents', 'Investigation', 'Kinetics', 'Label', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Modification', 'Molecular Target', 'Mutagenicity Tests', 'NF-kappa B', 'Nuclear', 'Pathway interactions', 'Phase', 'Physiologic pulse', 'Procedures', 'Protocols documentation', 'Reagent', 'Reference Values', 'Risk Assessment', 'Schedule', 'Scheme', 'Series', 'Stains', 'TP53 gene', 'Testing', 'Time', 'Toxic effect', 'Toxicogenetics', 'Training', 'Validation', 'Work', 'aurora kinase', 'base', 'clastogen', 'computerized tools', 'design', 'experimental study', 'forest', 'genotoxicity', 'hazard', 'inhibitor/antagonist', 'next generation', 'prediction algorithm', 'prevent', 'prototype', 'repaired', 'response', 'targeted agent', 'tool', 'treatment optimization', 'virtual']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2018,178854,0.012552430589009381
"Physical detection of HLA-C binding peptides to identify and predict immunogenic personal neoepitopes for improving cancer vaccines Peptides bound to class I HLA molecules (HLA-A, -B and –C) arise from endogenous or foreign proteins that are cleaved by the proteasome and peptidases of the endoplasmic reticulum prior to loading and display by surface HLA class I proteins. Each HLA allele is estimated to bind and present ~1,000-10,000 unique peptides to T cells. Given such diversity in HLA binding, an important question is whether we can predict whether a particular peptide is likely to bind to a specific HLA allele. Indeed, peptide-binding rules have been long-studied extensively for a subset of HLA alleles and encoded in advanced neural network-based algorithms that predict binding. Historically, little attention has been paid to HLA-C because of its perceived lower surface expression and hence predictive algorithms of HLA-C are very much lacking, as only a few thousand peptides epitopes have been reported in databases. New studies, however, suggests that important epitopes can arise from HLA-C, and have been detected for HIV, EBV, CMV and influenza. Our hypothesis is that large-scale datasets of endogenous HLA bound peptides can improve prediction of binding, and that through applying such an approach to HLA-C, a substantial increase in numbers of actionable immunogenic targets on tumor cells can be gained. Recently, I spearheaded a successful effort to integrate my expertise in experimental workflows for the isolation of HLA-bound peptides with newly available innovations in analysis and instrumentation for mass spectrometry (MS) to create a high throughput MS-based approach for the physical detection of peptides directly displayed by HLA molecules. This workflow and analytic framework now provides an exciting opportunity to generate high-quality data to directly address these challenges. In Aim 1, to systematically identify HLA-C binding peptides, we will use MS to provide experimentally-derived datasets of peptides from 21 HLA-C alleles to provide 99.9% global population coverage. In Aim 2, to define the rules of processing and presentation across HLA-C de novo, we will discover the binding motifs of the HLA-C peptides and use this information to develop predictive algorithms, which we will validate using independent datasets. In Aim 3, we seek to determine if predicted tumor neoepitopes are physically detected on patient tumor cells. We will perform experimental validation of HLA-C prediction algorithms directly on tumor samples available from study subjects enrolled on high-priority clinical trials of personalized neoantigen-targeting cancer vaccines at DFCI using a new nano-scale MS-based analysis. We will confirm the immunogenicity of the detected HLA-C epitopes through in vitro T cell assays using banked peripheral blood mononuclear cell samples collected from study subjects. We anticipate the proposed studies to enable fuller understanding HLA-C epitope presentation, more robust prediction of HLA-C peptide epitopes, and expansion of the spectrum of actionable immune targets. Immune recognition of short peptides representative of proteins within a cell in conjunction with a group of surface molecules called HLA is essential for the process of immune reactivity but characterization of the properties of how these peptides bind to HLA molecules has been constrained by the limited available information about these peptides. We have developed a new high-throughput approach to rapidly isolate thousands of HLA-bound peptides directly from informative cell lines and tumor samples (from patients with melanoma, glioblastoma and renal cell cancer) and to use this information to develop novel algorithms to predict binding of peptides to HLA. We anticipate the proposed studies t o enable fuller understanding of how a subset of understudied HLA molecules (i.e. HLA-C) interact with their binding peptides, to improve prediction of HLA-C bound peptides, and to expand the spectrum of actionable immune targets.",Physical detection of HLA-C binding peptides to identify and predict immunogenic personal neoepitopes for improving cancer vaccines,9456316,R21CA216772,"['Acids', 'Address', 'Algorithms', 'Alleles', 'Antigen Presentation', 'Attention', 'Binding', 'Biological Neural Networks', 'C-Peptide', 'Cancer Vaccines', 'Cell Line', 'Cells', 'Cellular Assay', 'Cleaved cell', 'Clinical', 'Clinical Trials', 'Cytomegalovirus', 'Cytotoxic T-Lymphocytes', 'DNA sequencing', 'Data', 'Data Quality', 'Data Set', 'Databases', 'Detection', 'Endoplasmic Reticulum', 'Enrollment', 'Epitopes', 'Frequencies', 'Funding', 'Gene Expression', 'Glioblastoma', 'HIV', 'HLA-A gene', 'HLA-C Antigens', 'Human', 'Human Herpesvirus 4', 'Immune', 'Immune Targeting', 'Immune response', 'Immunity', 'Immunoprecipitation', 'In Vitro', 'Influenza', 'Letters', 'Ligands', 'Lymphocyte', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Methods', 'Network-based', 'Operative Surgical Procedures', 'Patients', 'Peptide Hydrolases', 'Peptide Sequence Determination', 'Peptides', 'Peripheral Blood Mononuclear Cell', 'Phase', 'Population', 'Process', 'Property', 'Proteins', 'Proteomics', 'Protocols documentation', 'Renal Cell Carcinoma', 'Renal carcinoma', 'Reporting', 'Research', 'Resected', 'Role', 'Sampling', 'Somatic Mutation', 'Specimen', 'Study Subject', 'Surface', 'T cell response', 'T memory cell', 'T-Lymphocyte', 'Testing', 'Training', 'Tumor Antigens', 'Tumor Cell Line', 'Vaccine Design', 'Validation', 'Viral', 'base', 'experience', 'high risk', 'immunogenic', 'immunogenicity', 'improved', 'innovation', 'instrument', 'instrumentation', 'melanoma', 'multicatalytic endopeptidase complex', 'nanoscale', 'neoantigens', 'neoplastic cell', 'next generation', 'novel', 'polypeptide C', 'prediction algorithm', 'programs', 'tool', 'tumor', 'vaccine trial']",NCI,DANA-FARBER CANCER INST,R21,2018,232224,0.02043803958830075
"UVPD-MS Characterization of Lipopolysaccharides Abstract. Gram-negative bacteria have caused many of the most persistent infections as well as some of the deadliest pandemics in the world. Some strains have developed resistant to all available drugs, thus leading to increasing mortality from previously treatable bacterial infections. The National Strategy for Combating Antibiotic-Resistant Bacteria released by the White House in September 2014 focused on the need for (i) advancing the development of methods for identification and characterization of bacteria, (ii) accelerating basic research for new antibiotics, and (iii) improving capabilities for surveillance of antibiotic-resistant bacteria. This proposal focuses on the development of innovative tandem mass spectrometry approaches for characterization of lipopolysaccharides (LPS), the primary constituent of the outer membrane of Gram-negative bacteria that protects the membrane from chemical attack and is recognized by the immune system during pathogenic invasion. Structural characterization of LPS is critical to understanding how the structure of LPS influences immune stimulation as well as facilitating development of new antimicrobials and vaccines. This is a significant analytical challenge due to the branched structures and amphipathic properties of LPS. The escalating concerns about antibiotic resistance bacteria and the need for better avenues of defense against infectious diseases have motivated the proposed work. The objectives of this proposal are: Aim 1: Development of ultraviolet photodissociation (UVPD) mass spectrometry via hierarchical, decision-tree workflows for top-down characterization of LPS to facilitate high throughput analysis; Aim 2: Development of MS/MS approaches for serotyping of Gram-negative bacteria based on LPS; Aim 3: Examination of peptide/LPS interactions via native-spray mass spectrometry to provide both mechanistic information and screening capabilities for new antimicrobials, and Aim 4: Applications to a variety of structural problems related to the biosynthesis of LPS in Gram- negative bacteria and characterization of hybrid O-antigen/lipid A molecules in vesicle-based vaccines.  We have established a new collaboration with Dr. Bryan Davies' group to develop mass spectrometry methods to characterize peptide/lipid A interactions in support of the hunt for better antimicrobials. The continued collaboration with Dr. Stephen Trent's group emphasizes: (i) approaches for deciphering the biosynthetic pathways of bacterial LPS that endow them with the remarkable ability to re-design their outer membranes and develop antibiotic resistance, and (ii) innovative vaccine design based on antigenic LPS in vesicles.    Narrative: Gram-negative bacteria are responsible for some of the deadliest and more widespread pandemics in the world. The proposed work focuses on the development of advanced mass spectrometry approaches for characterization of complex lipopolysaccharides, including the endotoxic lipid A domains, that comprise the outer membrane of Gram-negative bacteria. The proposed work will be applied to evaluate new antimicrobials and support development of hybrid vaccines.",UVPD-MS Characterization of Lipopolysaccharides,9552867,R01GM103655,"['Acylation', 'Address', 'Advanced Development', 'Affinity', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Architecture', 'Bacteria', 'Bacterial Antibiotic Resistance', 'Bacterial Infections', 'Bacterial Vaccines', 'Basic Science', 'Binding', 'Catalogs', 'Cells', 'Chemical Warfare', 'Code', 'Collaborations', 'Combating Antibiotic Resistant Bacteria', 'Communicable Diseases', 'Complex', 'Complex Mixtures', 'Custom', 'Databases', 'Decision Trees', 'Development', 'Distal', 'Exhibits', 'Focus Groups', 'Glycolipids', 'Gram-Negative Bacteria', 'Hybrids', 'Hydrophobicity', 'Immune system', 'Immunization', 'Infection', 'Ions', 'Lipid A', 'Lipopolysaccharide Biosynthesis Pathway', 'Lipopolysaccharides', 'Mass Spectrum Analysis', 'Membrane', 'Methodology', 'Methods', 'Modification', 'Molecular', 'O Antigens', 'Oligosaccharides', 'Pathogenicity', 'Pathway interactions', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphorylation', 'Polysaccharides', 'Process', 'Production', 'Property', 'Publishing', 'Resistance', 'Serotyping', 'Structure', 'System', 'Tail', 'Vaccine Design', 'Vaccines', 'Variant', 'Vesicle', 'Virulence', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'cell envelope', 'chronic infection', 'design', 'high throughput analysis', 'hydrophilicity', 'improved', 'innovation', 'innovative technologies', 'inorganic phosphate', 'instrument', 'method development', 'mortality', 'novel', 'novel therapeutics', 'pandemic disease', 'response', 'screening', 'sugar', 'tandem mass spectrometry', 'ultraviolet']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2018,297043,0.039671448529459384
"Quantifying the role of adaptation in olfactory coding through the logic of navigation No abstract available Project Narrative This project will contribute to our understanding of how the olfactory sensory periphery and neural circuitry have evolved to effectively encode our vast and varied chemical environment. The project will help reveal how odor discrimination capability is maintained in natural odor landscapes, leading to practical interventional strategies for the control of disease vectors such as tsetse flies and mosquitos, who rely critically on their sense of smell to navigate. Chemical sensing is the only shared sensation among organisms as simple as bacteria and as complex as humans, and this project will enhance our fundamental knowledge of this universal sensory modality.",Quantifying the role of adaptation in olfactory coding through the logic of navigation,9667825,F32MH118700,"['Affect', 'Algorithms', 'Animals', 'Bacteria', 'Behavior', 'Behavioral', 'Behavioral Assay', 'Binding', 'Biological Assay', 'Characteristics', 'Chemicals', 'Code', 'Complex', 'Conflict (Psychology)', 'Cues', 'Culicidae', 'Data Analyses', 'Data Analytics', 'Dictionary', 'Discrimination', 'Disease Vectors', 'Drosophila genus', 'Drosophila melanogaster', 'Electrophysiology (science)', 'Environment', 'Esthesia', 'Exhibits', 'Feedback', 'Frequencies', 'Future', 'Genetic', 'Goals', 'Human', 'Image', 'Impairment', 'Insecta', 'Intervention', 'Knowledge', 'Laws', 'Left', 'Logic', 'Lymph', 'Machine Learning', 'Measures', 'Mediating', 'Memory', 'Modality', 'Motion', 'Odors', 'Olfactory Pathways', 'Olfactory Receptor Neurons', 'Organism', 'Output', 'Pheromone', 'Photosensitivity', 'Play', 'Proteins', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Smell Perception', 'Stimulus', 'System', 'Testing', 'Theoretical model', 'Time', 'Tsetse Flies', 'Walking', 'analytical method', 'disorder control', 'environmental change', 'experience', 'experimental study', 'fly', 'light intensity', 'mutant', 'neural circuit', 'neurobiological mechanism', 'neurosensory', 'novel', 'odorant-binding protein', 'optogenetics', 'relating to nervous system', 'sensory input', 'statistics', 'tool']",NIMH,YALE UNIVERSITY,F32,2018,63654,0.0012367615903933662
"Optimization and joint modeling for peptide detection by tandem mass spectrometry Project Summary/Abstract Proteins are the primary functional molecules in living cells, and tandem mass spectrometry provides the most efﬁcient means of studying proteins in a high-throughput fashion. The proposal aims to use state-of-the-art methods from the ﬁelds of machine learning, statistics, and natural language processing to improve our ability to make sense of large tandem mass spectrometry data sets. Our project will focus on three key problems in the analysis of such data: 1. facilitating the use of previously annotated spectra to improve our ability to annotate new spectra by creating  a hybrid search scheme that compares an observed spectrum to a database comprised of theoretical spectra  and previously annotated spectra, 2. enabling the efﬁcient and accurate detection of peptides containing post-translational modiﬁcations and  sequence variants, and 3. detecting sets of peptide species that are co-fragmented in the mass spectrometer and hence give rise to  complex, mixture spectra. Each of these aims will improve the ability of mass spectrometrists to efﬁciently and accurately identify and quantify proteins in complex mixtures. To increase the impact of our work, we will continue to make all of our tools available as free software. Project narrative The applications of mass spectrometry, and its promises for improvements of human health, are numerous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and speciﬁc diagnostic and prognostic screens. However, making optimal use of mass spectrometry data requires sophisticated computational methods. This project will develop and apply novel statistical and machine learning methods for interpreting mass spectra.",Optimization and joint modeling for peptide detection by tandem mass spectrometry,9214942,R01GM121818,"['Algorithms', 'Amino Acid Sequence', 'Automobile Driving', 'Biological', 'Cells', 'Collection', 'Column Chromatography', 'Communities', 'Complex', 'Complex Mixtures', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Discipline', 'Economics', 'Fertilization', 'Game Theory', 'Health', 'Human', 'Hybrids', 'Joints', 'Libraries', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Natural Language Processing', 'Operations Research', 'Peptides', 'Population', 'Post-Translational Protein Processing', 'Proteins', 'Proteomics', 'Protocols documentation', 'Sampling', 'Scheme', 'Shotguns', 'Speed', 'Statistical Models', 'Time', 'Variant', 'Work', 'computer based statistical methods', 'computerized tools', 'cost', 'disease phenotype', 'experimental study', 'improved', 'innovation', 'learning strategy', 'liquid chromatography mass spectrometry', 'mass spectrometer', 'mathematical theory', 'novel', 'prognostic', 'protein aminoacid sequence', 'speech recognition', 'statistics', 'tandem mass spectrometry', 'theories', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2017,332329,0.08260694832740166
"Binding-Site Modeling with Multiple-Instance Machine-Learning Project Summary / Abstract This proposal is entitled “Binding-Site Modeling with Multiple-Instance Machine-Learning.” A number of in- terrelated computational methods for making predictions about the biological behavior of small molecules have been the subject of development within the Jain Laboratory for over twenty years. These share a common strat- egy that considers molecular interactions at their surface interface, where proteins and ligands actually interact. These methods yield measurements of similarity between small molecules or between protein binding pockets. They also yield measurements of the complementarity of a small molecule to a protein binding site (the molecular docking problem). A generalization of these concepts makes possible the construction of a virtual binding site for quantitative activity prediction purely from data about the biological activities of a set of small molecules.  The goals of the proposed work include further improving the accuracy and breadth of applicability of the binding site modeling approach. The primary application of the approach is to guide optimization of leads within medicinal chemistry projects, and to quantify potential off-target effects during pre-clinical drug discovery.  A critical focus of the work will be in data and software dissemination, in order to accelerate the efficient development of targeted therapies. In addition to methods development, the proposed work will involve broad application of these state-of-the-art predictive modeling methods. The proposed work will proceed with the col- laborative input of our pharmaceutical industry colleagues, who have specialized knowledge and data sets that are vital for cutting-edge work in computer-aided drug design.  The expected results include more efficient lead optimization (fewer compounds to reach desired biological pa- rameters), truly effective scaffold replacement (to move away from a molecular series with biological limitations), and improved computational predictions of off-target effects during pre-clinical drug design. Project Narrative This project seeks to refine an integrated platform for physically realistic prediction of ligand binding affinities using multiple methods that span small molecule molecular similarity, molecular docking, and protein binding site similarity. These tools will provide predictive modeling unrestrained by scaffold congruence between what is known and what is to be predicted. Prediction of bioactive molecular poses and activities to guide lead optimiza- tion and to quantify off-target liability effects are applications of the effort, and data and software will be made widely available to academic and industrial research groups.",Binding-Site Modeling with Multiple-Instance Machine-Learning,9309936,R01GM101689,"['Address', 'Affinity', 'Behavior', 'Binding', 'Binding Proteins', 'Binding Sites', 'Biological', 'Biological Assay', 'Characteristics', 'Charge', 'Chemicals', 'Computer Assisted', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Development', 'Docking', 'Drug Design', 'Drug Industry', 'Electrostatics', 'Formulation', 'Future', 'Goals', 'Hydrogen Bonding', 'Industrialization', 'Industry Collaboration', 'Knowledge', 'Laboratories', 'Lead', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Probes', 'Performance', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Physics', 'Positioning Attribute', 'Procedures', 'Protein Conformation', 'Proteins', 'Research', 'Series', 'Structural Models', 'Structural Protein', 'Surface', 'Testing', 'Variant', 'Work', 'base', 'blind', 'combinatorial', 'design', 'drug discovery', 'improved', 'interest', 'learning strategy', 'method development', 'novel', 'novel strategies', 'physical model', 'pre-clinical', 'predictive modeling', 'scaffold', 'segregation', 'small molecule', 'targeted treatment', 'tool', 'treatment fees', 'virtual']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2017,310202,-0.019086843016794093
"Machine Learning Tools for Discovery and Analysis of Active Metabolic Pathways ﻿    DESCRIPTION (provided by applicant): This project aims to develop new statistical machine learning methods for metabolomics data from diverse platforms, including targeted and unbiased/global mass spectrometry (MS), labeled MS experiments for measuring metabolic ﬂux and Nuclear Magnetic Resonance (NMR) platforms. Unbiased MS and NMR proﬁling studies result in identifying a large number of unnamed spectra, which cannot be directly matched to known metabolites and are hence often discarded in downstream analyses. The ﬁrst aim develops a novel kernel penalized regression method for analysis of data from unbiased proﬁling studies. It provides a systematic framework for extracting the relevant information from unnamed spectra through a kernel that highlights the similarities and differences between samples, and in turn boosts the signal from named metabolites. This results in improved power in identiﬁcation of named metabolites associated with the phenotype of interest, as well as improved prediction accuracy. An extension of this kernel-based framework is also proposed to allow for systematic integration of metabolomics data from diverse proﬁling studies, e.g. targeted and unbiased MS proﬁling technologies. The second aim pro- vides a formal inference framework for kernel penalized regression and thus complements the discovery phase of the ﬁrst aim. The third aim focuses on metabolic pathway enrichment analysis that tests both orchestrated changes in activities of steady state metabolites in a given pathway, as well as aberrations in the mechanisms of metabolic reactions. The fourth aim of the project provides a uniﬁed framework for network-based integrative analysis of static (based on mass spectrometry) and dynamic (based on metabolic ﬂux) metabolomics measurements, thus providing an integrated view of the metabolome and the ﬂuxome. Finally, the last aim implements the pro- posed methods in easy-to-use open-source software leveraging the R language, the capabilities of the Cytoscape platform and the Galaxy workﬂow system, thus providing an expandable platform for further developments in the area of metabolomics. The proposed software tool will also provide a plug-in to the Data Repository and Coordination Center (DRCC) data sets, where all regional metabolomics centers supported by the NIH Common Funds Metabolomics Program deposit curated data. PUBLIC HEALTH RELEVANCE: Metabolomics, i.e. the study of small molecules involved in metabolism, provides a dynamic view into processes that reﬂect the actual physiology of the cell, and hence offers vast potential for detection of novel biomarkers and targeted therapies for complex diseases. However, despite this potential, the development of computational methods for analysis of metabolomics data lags the rapid growth of metabolomics proﬁling technologies. The current application addresses this need by developing novel statistical machine learning methods for integrative analysis of static and dynamic metabolomics measurements, as well as easy-to-use open-source software to facilitate the application of these methods.",Machine Learning Tools for Discovery and Analysis of Active Metabolic Pathways,9250169,R01GM114029,"['Address', 'Adoption', 'Anabolism', 'Area', 'Biochemical Pathway', 'Biochemical Reaction', 'Biological', 'Biological Assay', 'Cardiovascular Diseases', 'Cell physiology', 'Cells', 'Characteristics', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Diabetes Mellitus', 'Disease', 'Environment', 'Environmental Risk Factor', 'Equilibrium', 'Funding', 'Galaxy', 'Homeostasis', 'Imagery', 'Knowledge', 'Label', 'Language', 'Letters', 'Linear Models', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methodology', 'Methods', 'Names', 'Network-based', 'Nuclear Magnetic Resonance', 'Pathway interactions', 'Phase', 'Phenotype', 'Plug-in', 'Procedures', 'Process', 'Prognostic Marker', 'Proteomics', 'Reaction', 'Sampling', 'Signal Transduction', 'Software Tools', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Work', 'base', 'biological systems', 'biomarker discovery', 'diagnostic biomarker', 'experimental study', 'flexibility', 'high dimensionality', 'improved', 'insight', 'interest', 'learning strategy', 'metabolome', 'metabolomics', 'new technology', 'novel', 'novel diagnostics', 'novel marker', 'open source', 'programs', 'public health relevance', 'rapid growth', 'response', 'small molecule', 'targeted treatment', 'tool', 'transcriptomics']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2017,339051,0.070671492253398
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9260548,R01GM120033,"['Address', 'Algorithms', 'Alpha Cell', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cancer Etiology', 'Cardiovascular system', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical practice', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'metabolome', 'metabolomics', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2017,356625,0.08323257777792344
"Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC PROJECT SUMMARY The Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC (CMP-GA) is a cross-cutting team with advanced high-throughput chemical analytics and big data capabilities to develop a comprehensive map of molecular transducers of physical activity. The investigative team excels in ultrasensitive, precise and spatially resolved analyses of small molecules, lipids, and proteins. The team members have strong academic records as innovative, independent scientists, core laboratory directors and effective collaborators in complex research initiatives. Instrumentation includes state-of-the-art ultra-high resolution accurate mass high-field Orbitrap tandem mass spectrometry (MS) and ultraperformance liquid chromatography (UPLC); three- dimensional (3-D) molecular imaging via high throughput multi-modal MS at 5 m resolution; unique ion mobility-mass spectrometry machine-learning approaches for chemical identifications; and other such as GC- Orbitrap, 1D and 2D high field (800 MHz) NMR spectroscopy, ICP-MS, immunoassays, chemical and enzymatic assays, etc. The analytical laboratories are integrated through the NIH-supported Atlanta Clinical and Translational Sciences Institute, and operate within the outstanding research environment of Emory University and the Georgia Institute of Technology (GA Tech). CMP-GA has six elements organized to provide 1) leadership in the design and implementation of MoTrPAC goals; 2) bioinformatics, computational support and data delivery to the MoTrPAC Data Coordinating Center; 3) global, targeted and spatially resolved metabolomics; 4) metabolite forensics for unequivocal chemical identification of novel molecular transducers; 5) innovative proteomic and chemoproteomic technologies to define transducers within the redox proteome, ubiquitinome, acetylome, kinome and nuclear proteome; and 6) identification and quantification of lipid transducers. Through the successful completion of these aims and collaboration with the MoTrPAC consortium, investigators of CMP-GA will deliver a publically-available data resource and molecular transducer map that will enhance and accelerate mechanistic research on diseases and conditions affected by physical activity. PROJECT NARRATIVE This is a comprehensive metabolomics and proteomics chemical analysis site to support the Molecular Transducers of Physical Activity Consortium (MoTrPAC). Advanced analytical methods, including mass spectrometry, bioinformatics and chemical forensics are used to provide targeted and global analysis of small molecules, lipids, proteins to develop a molecular transducer map for physical activity.",Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC,9246760,U24DK112341,"['3-Dimensional', 'Adipocytes', 'Affect', 'Aging', 'Animal Experimentation', 'Animals', 'Automobile Driving', 'Big Data', 'Bioinformatics', 'Biological Assay', 'Chemicals', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Communication', 'Complement', 'Complex', 'Custom', 'Data', 'Data Coordinating Center', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Elements', 'Environment', 'Exercise', 'Forensic Medicine', 'Goals', 'Health', 'Health Benefit', 'Immunoassay', 'Institutes', 'Isotopes', 'Label', 'Laboratories', 'Leadership', 'Link', 'Lipids', 'Liquid Chromatography', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Modality', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Monitor', 'Muscle', 'NMR Spectroscopy', 'Neurodegenerative Disorders', 'Nuclear', 'Oral', 'Oxidation-Reduction', 'Oxidative Stress', 'Particle Size', 'Peptide Mapping', 'Phosphotransferases', 'Physical activity', 'Plasma', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Protocols documentation', 'Publications', 'Reaction', 'Records', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Signal Transduction', 'Site', 'System', 'Systems Biology', 'Technology', 'Time', 'Training', 'Transducers', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'advanced system', 'analytical method', 'chemoproteomics', 'cytokine', 'data resource', 'design', 'differential expression', 'innovation', 'instrumentation', 'ion mobility', 'lectures', 'member', 'metabolomics', 'molecular imaging', 'novel', 'oxidized lipid', 'phenotypic biomarker', 'response', 'small molecule', 'tandem mass spectrometry', 'tool', 'ultra high resolution']",NIDDK,EMORY UNIVERSITY,U24,2017,84511,0.029869634989698374
"Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC PROJECT SUMMARY The Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC (CMP-GA) is a cross-cutting team with advanced high-throughput chemical analytics and big data capabilities to develop a comprehensive map of molecular transducers of physical activity. The investigative team excels in ultrasensitive, precise and spatially resolved analyses of small molecules, lipids, and proteins. The team members have strong academic records as innovative, independent scientists, core laboratory directors and effective collaborators in complex research initiatives. Instrumentation includes state-of-the-art ultra-high resolution accurate mass high-field Orbitrap tandem mass spectrometry (MS) and ultraperformance liquid chromatography (UPLC); three- dimensional (3-D) molecular imaging via high throughput multi-modal MS at 5 m resolution; unique ion mobility-mass spectrometry machine-learning approaches for chemical identifications; and other such as GC- Orbitrap, 1D and 2D high field (800 MHz) NMR spectroscopy, ICP-MS, immunoassays, chemical and enzymatic assays, etc. The analytical laboratories are integrated through the NIH-supported Atlanta Clinical and Translational Sciences Institute, and operate within the outstanding research environment of Emory University and the Georgia Institute of Technology (GA Tech). CMP-GA has six elements organized to provide 1) leadership in the design and implementation of MoTrPAC goals; 2) bioinformatics, computational support and data delivery to the MoTrPAC Data Coordinating Center; 3) global, targeted and spatially resolved metabolomics; 4) metabolite forensics for unequivocal chemical identification of novel molecular transducers; 5) innovative proteomic and chemoproteomic technologies to define transducers within the redox proteome, ubiquitinome, acetylome, kinome and nuclear proteome; and 6) identification and quantification of lipid transducers. Through the successful completion of these aims and collaboration with the MoTrPAC consortium, investigators of CMP-GA will deliver a publically-available data resource and molecular transducer map that will enhance and accelerate mechanistic research on diseases and conditions affected by physical activity. PROJECT NARRATIVE This is a comprehensive metabolomics and proteomics chemical analysis site to support the Molecular Transducers of Physical Activity Consortium (MoTrPAC). Advanced analytical methods, including mass spectrometry, bioinformatics and chemical forensics are used to provide targeted and global analysis of small molecules, lipids, proteins to develop a molecular transducer map for physical activity.",Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC,9516960,U24DK112341,"['3-Dimensional', 'Adipocytes', 'Affect', 'Aging', 'Animal Experimentation', 'Animals', 'Automobile Driving', 'Big Data', 'Bioinformatics', 'Biological Assay', 'Chemicals', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Communication', 'Complement', 'Complex', 'Custom', 'Data', 'Data Coordinating Center', 'Development', 'Dimensions', 'Disease', 'Educational workshop', 'Elements', 'Environment', 'Exercise', 'Forensic Medicine', 'Goals', 'Health', 'Health Benefit', 'Immunoassay', 'Institutes', 'Isotopes', 'Label', 'Laboratories', 'Leadership', 'Link', 'Lipids', 'Liquid Chromatography', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Modality', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Monitor', 'Muscle', 'NMR Spectroscopy', 'Neurodegenerative Disorders', 'Nuclear', 'Oral', 'Oxidation-Reduction', 'Oxidative Stress', 'Particle Size', 'Peptide Mapping', 'Phosphotransferases', 'Physical activity', 'Plasma', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Protocols documentation', 'Publications', 'Reaction', 'Records', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Signal Transduction', 'Site', 'System', 'Systems Biology', 'Technology', 'Time', 'Training', 'Transducers', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'advanced system', 'analytical method', 'chemoproteomics', 'cytokine', 'data resource', 'design', 'differential expression', 'innovation', 'instrumentation', 'ion mobility', 'lectures', 'member', 'metabolomics', 'molecular imaging', 'novel', 'oxidized lipid', 'phenotypic biomarker', 'response', 'small molecule', 'tandem mass spectrometry', 'tool', 'ultra high resolution']",NIDDK,EMORY UNIVERSITY,U24,2017,149094,0.029869634989698374
"Illuminating Function of the Understudied Druggable Kinome Project Summary/Abstract Kinases are among the most important drug targets and clinically significant kinase inhibitors have been developed for multiple diseases. A subset of kinases, the understudied dark kinases (DKs), have received little or no attention because foundational data on their biochemical and biological functions is not available. This proposal will collect such data by perturbing DKs genetically and with small molecules and then measuring the cellular consequences using multiplex proteomic, gene expression, metabolomic and imaging assays. A subset of DKs with potential links to human disease will be intensively studied as a means to qualify new therapeutic drug targets. Data collected in this project will be aggregated with existing information from previous NIH-funded large-scale structural and genomic projects to create a Dark Kinase Knowledgebase (DKK) that provides gene-by-gene and network-level information on the dark kinome and its interaction with other signal transduction and regulatory networks. Close coordination with the NIH LINCS project will ensure data interoperability and make efficient use of informatics tools. The DKK will be developed in collaboration with the IDG Knowledge Management Center (KMC), adhere to standards for Findable, Accessible, Interoperable and Reusable (FAIR) data, and be accessible to human users and machines (via an API). Commercially available DK reagents be validated and extended with new genetic and chemical tools provided to the Resource Dissemination Center (RDOC). The overall approach will be iterative, with simpler methods applied first (e.g. simple gene knockout) and more sophisticated methods subsequently (e.g. stable CRIPSRa/i) pursued by an interdisciplinary team of chemists, computational biologists, mass spectroscopists and pharmacologists working on five linked aims. Aim 1 will develop a computational algorithm for prioritizing DKs, develop and maintain the DKK, and perform network-level analysis on the kinome using supervised and unsupervised machine learning. Aim 2 will measure kinase abundance in normal and perturbed cells using parallel reaction monitoring with stable isotope dilution (PRM-SID) and RNASeq and data analyzed using network inference tools to provide insight into dark and light kinome in diverse cell types. Aim 3 will perturb DKs with genetic tools such as CRIPSR/Cas9-mediated gene knockout, CRIPSRa/i to induce more subtle-up and down regulation and inducible gene inaction. The impact on cell fate, morphology and signal transduction will then be determined using PRM-SID, phosphoproteomics, RNASeq, gene reporter assays, metabolomics profiling and highly multiplex single-cell imaging. Aim 4 will extend DK analysis to small molecule inhibitors by carefully profiling existing drugs against DKs and by designing and synthesizing new chemical ligands. Aim 5 will involve collaboration with other investigators to assay the expression and function of DKs in primary human cells and tissues relevant to the NIH Precision Medicine Initiative. All aims will be pursued in parallel for a progressively expanding resource of data and tools for continued study of DKs. Project Narrative/Health Relevance Advancing understanding of understudied kinases, a highly druggable class of proteins, will increase knowledge about signal transduction and control over cellular physiology and is likely to reveal a subset of proteins that should be advanced as targets for new therapeutic drugs.",Illuminating Function of the Understudied Druggable Kinome,9453342,U24DK116204,"['Algorithms', 'Anabolism', 'Arthritis', 'Attention', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Process', 'Cell Line', 'Cell physiology', 'Cells', 'Chemicals', 'Chronic Obstructive Airway Disease', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Collection', 'Complement', 'Computational algorithm', 'Cystic Fibrosis', 'Darkness', 'Data', 'Data Analyses', 'Development', 'Diabetes Mellitus', 'Disease', 'Down-Regulation', 'Drug Targeting', 'Engineering', 'Ensure', 'FAIR principles', 'Foundations', 'Funding', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Goals', 'Health', 'Homeostasis', 'Human', 'Image', 'Individual', 'Informatics', 'Information Resources Management', 'Knowledge', 'Libraries', 'Ligands', 'Light', 'Link', 'Logic', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mediating', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Mutate', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Play', 'Precision Medicine Initiative', 'Production', 'Proteins', 'Proteomics', 'Reaction', 'Reagent', 'Reporter', 'Reporter Genes', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Signal Transduction', 'Signal Transduction Pathway', 'Site', 'Supervision', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Tumor Tissue', 'United States National Institutes of Health', 'Up-Regulation', 'Validation', 'base', 'cell type', 'cellular imaging', 'clinically significant', 'computerized tools', 'data resource', 'design', 'drug development', 'human disease', 'innovation', 'insight', 'interoperability', 'kinase inhibitor', 'knockout gene', 'knowledge base', 'metabolic profile', 'metabolomics', 'new therapeutic target', 'novel', 'novel therapeutics', 'phosphoproteomics', 'programs', 'protein protein interaction', 'screening', 'small molecule', 'small molecule inhibitor', 'stable isotope', 'structural genomics', 'therapeutic development', 'therapeutic target', 'tool', 'transcription factor', 'transcriptome sequencing']",NIDDK,UNIV OF NORTH CAROLINA CHAPEL HILL,U24,2017,2308193,-0.001296085531721469
"Ion mobility based informatics and visualization strategies in support of metabolomics Project Summary  Metabolites are building blocks of cellular function, thus understanding the mechanisms that underlie various physiological conditions and processes will provide insight into disease or aberrant states. Innovative developments in high-throughput analytical technologies and data analysis have allowed for systems-level metabolomics analyses to be performed, many of these technologies have centered around mass spectrometry. The diverse chemical structures in the human metabolome exhibit a wide range of concentration, solubility, polarity and volatility with highly diverse structural forms and physiochemical properties as well as a high number of isomers, therefore the need for as many orthogonal separations as possible is necessary for metabolomics experiments (i.e., multidimensional data sets). Mass spectrometry approaches incorporating liquid chromatography ion mobility mass spectrometry (LC-IM-MS/MS) analyses have shown utility for global untargeted metabolic profiling experiments. Since ion mobility coupled to mass spectrometry (IM-MS) is a relatively new commercially available technology, the incorporation of the ion mobility measurement (via collision cross section, CCS) into current metabolomics data analysis identification strategies is minimal. The typical analytical use of ion mobility is as a quick chemical separation (which allows for noise reduction, increase in peak capacity, etc.), however IM can also be used to increase the confidence in identification and characterization because CCS provides structure specific information about individual metabolites. The long term objectives of this proposal are all centered around incorporating IM measurements into metabolomics based chemoinformatic and bioinformatics pipelines. These include: (1) determining the extent at which the ion mobility dimension can address molecular specificity of isomeric metabolites, (2) developing an IM-based library using CCS values as a descriptor to screen and assign identities to unknown metabolites and lastly, (3) incorporating visualization tools for navigating multidimensional datasets which will allow scientists to better uncover relationships between metabolites and human health. Molecular specificity of the IM dimension will be addressed by analyzing previously generated IM-MS data from a commercially available metabolite library (>600 primary metabolites, of which >20% are isomeric). Individual metabolites in the metabolite library will also be interrogated for curation of the CCS library and these values will be used in the molecular identification pipeline for global untargeted metabolite studies generated previously. Lastly, multidimensional self-organizing maps will be utilized to visualize and navigate various dimensions of data (LC, CCS, m/z, etc.) and ultimately allow the user to prioritize and identify with high confidence metabolites indicative of disease state. Accomplishing the aims outlined in this proposal will be seen as overcoming several critical barriers which have so far hindered the routine and widespread use of ion mobility in MS-based metabolomics workflows. Project Narrative  The innovative developments described in the proposal incorporate high-throughput metabolomics technologies, big data informatics, and multidimensional visualization strategies which will allow scientists to uncover relationships between metabolites and human health using systems-level metabolomics analyses. Specifically, we believe these goals can be accomplished by overcoming several critical barriers to adopting new technologies based on multidimensional mass spectrometry which hold promise for furthering our knowledge about the nature and behavior of living systems. Strategies outlined in this proposal include, providing a highly annotated library incorporating empirical ion mobility based collision cross section values (inclusive also of exact mass, fragment ion data, and retention time) and developing novel big data and visualization strategies to improve throughput and confidence in metabolite annotations.",Ion mobility based informatics and visualization strategies in support of metabolomics,9433378,R03CA222452,"['Address', 'Adopted', 'Adoption', 'Algorithms', 'Behavior', 'Big Data', 'Bioinformatics', 'Biological', 'Cell physiology', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Communities', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Defect', 'Descriptor', 'Development', 'Dimensions', 'Disease', 'Electronic Mail', 'Exhibits', 'Funding Opportunities', 'Goals', 'Health', 'Human', 'Imagery', 'Individual', 'Informatics', 'Ions', 'Isomerism', 'Knowledge', 'Laboratories', 'Libraries', 'Link', 'Lipids', 'Liquid Chromatography', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Metabolic', 'Molecular', 'Nature', 'Noise', 'Organism', 'Pathway interactions', 'Phonation', 'Physiological', 'Play', 'Process', 'Property', 'Reporting', 'Reproducibility', 'Research', 'Research Infrastructure', 'Research Personnel', 'Role', 'Scientist', 'Solubility', 'Specificity', 'Structure', 'System', 'Techniques', 'Technology', 'Telephone', 'Time', 'Universities', 'Visualization software', 'Work', 'base', 'cheminformatics', 'data visualization', 'experimental study', 'improved', 'innovation', 'innovative technologies', 'insight', 'instrument', 'interest', 'ion mobility', 'metabolic profile', 'metabolome', 'metabolomics', 'new technology', 'novel', 'novel strategies', 'professor', 'tandem mass spectrometry', 'tool']",NCI,VANDERBILT UNIVERSITY,R03,2017,151533,0.06946923411356314
"Integrating cheminformatics and molecular simulations for virtual drug screening ﻿    DESCRIPTION (provided by applicant): The development of highly efficient and accurate approaches to structure-based virtual screening (VS) continues to represent a formidable challenge in the field of computational drug discovery. Outstanding and widely recognized research problems in the field include the relative computational inefficiency of most approaches, which limits the size of molecular libraries used for virtual screening; the low hit rate; and the inaccurate prediction of ligand binding affinity and pose. The proposed studies address these challenges by using innovative and computationally efficient approaches to VS that fully integrate concepts from the complementary fields of cheminformatics and molecular simulation to devise an integrated two-step VS methodology. Building upon our experience in cheminformatics and QSAR modeling, we aim to develop novel, computationally efficient cheminformatics approaches to pre-process very large (on the order of 107 compounds) chemical libraries available for biological screening, and eliminate up to 99% of improbable ligands. Only the remaining 1% of probable ligands will be evaluated by slower but accurate ensemble flexible docking approaches relying on molecular simulation techniques. The cheminformatics step will also produce important information on privileged protein-ligand interactions that will be used in a live-processing step to guide the structure-based virtual screening and avoid oversampling of ligand poses. Moreover, post- processing cheminformatics methods will be implemented to filter out decoy poses from docking calculations. The ultimate goal of our hybrid methodology is to arrive at a small set of high-affinity computational hits in receptor-bound conformations that can be validated experimentally. We will pursue this goal following three specific aims: 1) Develop novel cheminformatics-based virtual screening approaches to eliminate both improbable ligands and improbable poses, as well as generate information on preferred protein-ligand interactions; 2) Develop new, efficient flexible ensemble docking methods guided by the preferred protein- ligand interactions to select the most probable ligands and predict their binding poses; 3) Apply the developed hierarchical virtual screening workflow to several therapeutic targets and test high-confidence computational hits in experimental assays. All computational tools resulting from this project will be made publicly available. This proposal is innovative because the proposed VS platform will result from a unique marriage of disparate approaches for VS, combining their corresponding strengths. This proposal is significant because the implementation of this project will enable substantial improvement in the efficiency, accuracy, and experimentally-confirmed impact of structure-based drug discovery tools. PUBLIC HEALTH RELEVANCE: Advances in drug discovery rely on the development of novel effective computational methodologies. This proposal advances an efficient and robust computational workflow for structure-based virtual screening of very large chemical libraries. The ultimate goal of this project is to arrive at a small number of candidate molecules with high predicted binding affinity to their biological targets, which will be tested in confirmatory experiments.",Integrating cheminformatics and molecular simulations for virtual drug screening,9325031,R01GM114015,"['Active Sites', 'Address', 'Affect', 'Affinity', 'Benchmarking', 'Binding', 'Binding Sites', 'Biological', 'Biological Assay', 'Biological Availability', 'Chemicals', 'Computational Geometry', 'Computer Simulation', 'Computing Methodologies', 'Data Set', 'Descriptor', 'Development', 'Docking', 'Enzymes', 'G-Protein-Coupled Receptors', 'Goals', 'Hybrids', 'Libraries', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Conformation', 'Orphan', 'Performance', 'Pharmaceutical Preparations', 'Pharmacology', 'Phosphotransferases', 'Preclinical Drug Evaluation', 'Process', 'Proteins', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Research', 'Series', 'Side', 'Structure', 'Techniques', 'Technology', 'Testing', 'Validation', 'Vertebral column', 'base', 'cheminformatics', 'computerized tools', 'drug discovery', 'experience', 'experimental study', 'flexibility', 'improved', 'improved outcome', 'innovation', 'molecular size', 'novel', 'novel strategies', 'programs', 'public health relevance', 'receptor binding', 'screening', 'simulation', 'small molecule', 'small molecule libraries', 'sperm cell', 'therapeutic evaluation', 'therapeutic target', 'three dimensional structure', 'tool', 'user friendly software', 'virtual']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2017,293344,-0.009793417913331213
"Development of integrative models for early liver toxicity assessment ﻿    DESCRIPTION (provided by applicant): Computational toxicology has become a critical area of research due to the burgeoning need to evaluate thousands of pharmaceutical and environmental chemicals with unknown toxicity profiles, the high demand in time and resources by current experimental toxicity testing, and the growing ethical concerns over animal use in toxicity studies. Despite tremendous efforts, little success has been attained thus far in the development of predictive computational models for toxicity, primarily due to the complexity of toxicity mechanisms as well as the lack of high-quality experimental data for model development.  A critical challenge in toxicity testing of chemicals is that toxicity effects are doe-dependent: the true toxic hits may show no toxicity at all at low dose level. Therefore, traditiona high-throughput screening (HTS) that test chemicals only at a single concentration is not suitable for toxicity screening. On the contrary, the recently developed quantitative high-throughput screening (qHTS) platforms can evaluate each chemical across a broad range of concentrations, and is gaining ever-increasing popularity as a tool for in vitro toxicity profiling The concentration-response information generated by qHTS are expected to provide more accurate and comprehensive information of the toxicity effects of chemicals, offering promising data that can be mined to estimate in vivo toxicities of chemicals. However, our previous studies showed that if processed inappropriately, such concentration-response information contribute little to improve the toxicity prediction. This is especially true when multiple types of qHTS data are used together. Therefore, in this study, we will extend our previous approaches to develop novel statistical and computational tools that can curate, preprocess, and normalize the concentration-response information from multiple different qHTS databases.  Traditionally, toxicity models are based on either the chemical data (such as the quantitative structure- activity relationship analysis), or the in vitro toxicity profiling data (such as the in vitro-in vivo extrapolations). Our previous experiences suggested that integrating biological descriptors such as the in vitro cytotoxicity profiles or the short-term toxigenomic data, with chemical structural features is able to predict rodent acute liver toxicity with reasonable accuracy. Therefore, the second part of this proposal will be devoted to develop novel computational models for hepatotoxicity prediction by integrating qHTS toxicity profiles and chemical structural information In Aim 1, we will curate, preprocess, and normalize collected public liver toxicity datasets. In ths study, we will model toxicity effects using multiple large public datasets such as HTS and qHTS bioassay data (Tox21[1] and ToxCast[2]), hepatotoxicity side effect reports on marketed failed drugs[3], the Liver Toxicity Knowledge Base Benchmark Dataset (LTKB-BD[4]), etc. Statistical methods for cross-study validation and quality control will be applied to the collected datasets to ensure computational compatibility and to select the appropriate datasets for analysis. In Aim 2, we will develop predictive models for chemicals' liver toxicity based on an integrative modeling workflow that will make use of both structural and in vitro toxicity profiles of a chemical. Our previous studies [5] showed that models using both in vitro toxicity profiles and chemical structural data have better accuracy for rodent acute liver toxicity than models using either data type alone. Here, we will develop a novel modeling workflow that start with defining the functional clusters of chemicals via curated qHTS toxicity profiles, and is followed by developing computational models to correlate chemical and biological data with overall toxicity risks in humans. The predictive models will be validated using independent datasets with over 800 compounds. In Aim 3, we propose to prioritize the qHTS profiling assays used in the model for future toxicity testing. We will evaluate all the in vitro assays as biological descriptors from thee perspectives, including descriptor importance in the integrative toxicity model, correlation with i vivo DILI outcomes, and level of information content estimated by a novel approach based on network analysis. PUBLIC HEALTH RELEVANCE: In this study we aim to develop computational models that can identify potential liver toxicants. Liver toxicity is a significant contributor to the high attition rate in drug development. Moreover, toxic chemicals in food, water, and consumer products all pose serious risks for liver toxicity. As a result, there is great interest in developing high-throughput, high-content experimental and computational tools to evaluate the liver toxicity of thousands of pharmaceutical and environmental chemicals. This study focuses on developing novel informatics tools that enable the extraction and integration of chemical concentration-response information from multiple quantitative high-throughput screening databases for model development, and developing statistical models that are able to integrate this concentration-response information with chemical structural features to predict their risk of liver toxicity.  ",Development of integrative models for early liver toxicity assessment,9333370,R03ES026397,"['Acute', 'Address', 'Adverse effects', 'Algorithms', 'Animals', 'Area', 'Benchmarking', 'Biological', 'Biological Assay', 'Chemical Models', 'Chemicals', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Dose', 'Dreams', 'Ensure', 'Ethics', 'Food', 'Future', 'Gene Expression', 'Genomics', 'Goals', 'Gold', 'Hepatotoxicity', 'Human', 'In Vitro', 'Informatics', 'International', 'Liver', 'Machine Learning', 'Marketing', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Environmental Health Sciences', 'Nature', 'Network-based', 'North Carolina', 'Outcome', 'Pathway Analysis', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Poison', 'Process', 'Productivity', 'Quality Control', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Resources', 'Risk', 'Rodent', 'Scientist', 'Shapes', 'Statistical Methods', 'Statistical Models', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicogenetics', 'Toxicology', 'Translational Research', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'Universities', 'Variant', 'Water', 'base', 'computational toxicology', 'computerized tools', 'consumer product', 'cost', 'cost effective', 'cytotoxicity', 'data modeling', 'drug development', 'drug market', 'drug withdrawal', 'environmental chemical', 'experience', 'high throughput screening', 'improved', 'in vitro Assay', 'in vivo', 'interest', 'knowledge base', 'liver injury', 'model development', 'novel', 'novel strategies', 'preclinical study', 'predictive modeling', 'programs', 'public health relevance', 'response', 'screening', 'success', 'tool', 'toxicant', 'validation studies']",NIEHS,UT SOUTHWESTERN MEDICAL CENTER,R03,2017,81000,0.021854686053667773
"UVPD-MS Characterization of Lipopolysaccharides Abstract. Gram-negative bacteria have caused many of the most persistent infections as well as some of the deadliest pandemics in the world. Some strains have developed resistant to all available drugs, thus leading to increasing mortality from previously treatable bacterial infections. The National Strategy for Combating Antibiotic-Resistant Bacteria released by the White House in September 2014 focused on the need for (i) advancing the development of methods for identification and characterization of bacteria, (ii) accelerating basic research for new antibiotics, and (iii) improving capabilities for surveillance of antibiotic-resistant bacteria. This proposal focuses on the development of innovative tandem mass spectrometry approaches for characterization of lipopolysaccharides (LPS), the primary constituent of the outer membrane of Gram-negative bacteria that protects the membrane from chemical attack and is recognized by the immune system during pathogenic invasion. Structural characterization of LPS is critical to understanding how the structure of LPS influences immune stimulation as well as facilitating development of new antimicrobials and vaccines. This is a significant analytical challenge due to the branched structures and amphipathic properties of LPS. The escalating concerns about antibiotic resistance bacteria and the need for better avenues of defense against infectious diseases have motivated the proposed work. The objectives of this proposal are: Aim 1: Development of ultraviolet photodissociation (UVPD) mass spectrometry via hierarchical, decision-tree workflows for top-down characterization of LPS to facilitate high throughput analysis; Aim 2: Development of MS/MS approaches for serotyping of Gram-negative bacteria based on LPS; Aim 3: Examination of peptide/LPS interactions via native-spray mass spectrometry to provide both mechanistic information and screening capabilities for new antimicrobials, and Aim 4: Applications to a variety of structural problems related to the biosynthesis of LPS in Gram- negative bacteria and characterization of hybrid O-antigen/lipid A molecules in vesicle-based vaccines.  We have established a new collaboration with Dr. Bryan Davies' group to develop mass spectrometry methods to characterize peptide/lipid A interactions in support of the hunt for better antimicrobials. The continued collaboration with Dr. Stephen Trent's group emphasizes: (i) approaches for deciphering the biosynthetic pathways of bacterial LPS that endow them with the remarkable ability to re-design their outer membranes and develop antibiotic resistance, and (ii) innovative vaccine design based on antigenic LPS in vesicles.    Narrative: Gram-negative bacteria are responsible for some of the deadliest and more widespread pandemics in the world. The proposed work focuses on the development of advanced mass spectrometry approaches for characterization of complex lipopolysaccharides, including the endotoxic lipid A domains, that comprise the outer membrane of Gram-negative bacteria. The proposed work will be applied to evaluate new antimicrobials and support development of hybrid vaccines.",UVPD-MS Characterization of Lipopolysaccharides,9320998,R01GM103655,"['Acylation', 'Address', 'Advanced Development', 'Affinity', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Architecture', 'Bacteria', 'Bacterial Infections', 'Bacterial Vaccines', 'Basic Science', 'Binding', 'Catalogs', 'Cells', 'Chemical Warfare', 'Code', 'Collaborations', 'Combating Antibiotic Resistant Bacteria', 'Communicable Diseases', 'Complex', 'Complex Mixtures', 'Custom', 'Databases', 'Decision Trees', 'Development', 'Distal', 'Exhibits', 'Focus Groups', 'Glycolipids', 'Gram-Negative Bacteria', 'Hybrids', 'Hydrophobicity', 'Immune system', 'Immunization', 'Infection', 'Ions', 'Lipid A', 'Lipopolysaccharide Biosynthesis Pathway', 'Lipopolysaccharides', 'Mass Spectrum Analysis', 'Membrane', 'Methodology', 'Methods', 'Modification', 'Molecular', 'O Antigens', 'Oligosaccharides', 'Pathogenicity', 'Pathway interactions', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphorylation', 'Polysaccharides', 'Process', 'Production', 'Property', 'Publishing', 'Resistance', 'Serotyping', 'Structure', 'System', 'Tail', 'Vaccine Design', 'Vaccines', 'Variant', 'Vesicle', 'Virulence', 'Work', 'antimicrobial', 'bacterial resistance', 'base', 'cell envelope', 'design', 'high throughput analysis', 'hydrophilicity', 'improved', 'innovation', 'innovative technologies', 'inorganic phosphate', 'instrument', 'method development', 'mortality', 'novel', 'novel therapeutics', 'pandemic disease', 'response', 'screening', 'sugar', 'tandem mass spectrometry', 'ultraviolet']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2017,297043,0.039671448529459384
"Binding-Site Modeling with Multiple-Instance Machine-Learning DESCRIPTION (provided by applicant): This proposal is entitled ""Binding-Site Modeling with Multiple-Instance Machine-Learning."" One of the most challenging and longest studied problems in computer-aided drug design has been affinity prediction of small molecule ligands for their cognate protein targets. Despite decades of work, quantitative structure-activity re- lationship prediction (QSAR) approaches still suffer from poor accuracy, especially when predicting outside of closely related series of molecules. Even with high-quality structures of target proteins, approaches grounded in physics are also far from robust and accurate enough for reliable use in drug lead optimization. This proposal will build upon a foundation in multiple-instance machine learning applied to computer-aided drug design problems and develop a robust, accurate, and practically applicable affinity prediction methodology. The methodology requires only ligand structures and associated activity data for training, and it induces a virtual protein binding site composed of molecular fragments. The virtual binding pocket (or ""pocketmol"") is used in conjunction with a scoring function developed originally for molecular docking. The pocketmol configuration is chosen such that the optimal conformation and alignment of a ligand (based on the docking scoring function), yields scores for training ligands that are close to the known experimental values. Feasibility has been demon- strated in papers involving both membrane-bound receptors and enzymes.  However, multiple challenges remain and are the subject of the proposed research. There are three key issues. First, there exist many pocketmols that satisfy the requirements of fitting the training data, so general solutions must be developed to address the inductive bias of the learning procedure as well as model selection after the procedure. Second, since any particular model is the product of a learning process, it will have some domain of applicability, with some new molecules likely to be predicted well and others poorly. Further, the model will be better informed by learning with certain new molecules but not others. We must develop solutions for estimating confidence of predictions for new molecules as well as for identifying particular molecules that will be highly informative. Third, the operational application of these methods involves model building, guided chemical synthesis, and iterative refinement of models. Convincing validation will require application on temporal series of molecules synthesized for multiple targets of pharmaceutical interest. The proposed work will develop novel methods to address these challenges and will establish extensive validation on multiple pharmaceutically relevant temporal series of small molecules that were the subject of real-world lead-optimization exercises. PUBLIC HEALTH RELEVANCE: The dominant mode of therapeutic discovery involves the design ""me-too"" drugs that are very similar in structure and effect to existing drugs. In order to address the unmet medical needs of an aging population, novel therapeutics must be developed, and this will require much more creativity in the design process. The proposed research will develop a predictive computational framework to aid in active design of structurally novel drug molecules during the drug discovery lead optimization process.",Binding-Site Modeling with Multiple-Instance Machine-Learning,8987578,R01GM101689,"['Address', 'Affinity', 'Binding', 'Binding Proteins', 'Binding Sites', 'Biological Assay', 'Chemicals', 'Collaborations', 'Computer Assisted', 'Creativeness', 'Data', 'Data Set', 'Docking', 'Drug Design', 'Enzymes', 'Exercise', 'Foundations', 'Health', 'Knowledge', 'Lead', 'Learning', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Measures', 'Medical', 'Membrane', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Paper', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Physics', 'Population', 'Procedures', 'Process', 'Proteins', 'Publishing', 'Quantitative Structure-Activity Relationship', 'Research', 'Series', 'Site', 'Structure', 'System', 'Testing', 'Therapeutic', 'Training', 'Validation', 'Work', 'aging population', 'base', 'blind', 'chemical synthesis', 'computer framework', 'design', 'design and construction', 'drug discovery', 'falls', 'interest', 'model building', 'novel', 'novel therapeutics', 'predictive modeling', 'process optimization', 'prospective', 'receptor binding', 'small molecule', 'virtual']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2016,301150,-0.005442746851805772
"Machine Learning Tools for Discovery and Analysis of Active Metabolic Pathways ﻿    DESCRIPTION (provided by applicant): This project aims to develop new statistical machine learning methods for metabolomics data from diverse platforms, including targeted and unbiased/global mass spectrometry (MS), labeled MS experiments for measuring metabolic ﬂux and Nuclear Magnetic Resonance (NMR) platforms. Unbiased MS and NMR proﬁling studies result in identifying a large number of unnamed spectra, which cannot be directly matched to known metabolites and are hence often discarded in downstream analyses. The ﬁrst aim develops a novel kernel penalized regression method for analysis of data from unbiased proﬁling studies. It provides a systematic framework for extracting the relevant information from unnamed spectra through a kernel that highlights the similarities and differences between samples, and in turn boosts the signal from named metabolites. This results in improved power in identiﬁcation of named metabolites associated with the phenotype of interest, as well as improved prediction accuracy. An extension of this kernel-based framework is also proposed to allow for systematic integration of metabolomics data from diverse proﬁling studies, e.g. targeted and unbiased MS proﬁling technologies. The second aim pro- vides a formal inference framework for kernel penalized regression and thus complements the discovery phase of the ﬁrst aim. The third aim focuses on metabolic pathway enrichment analysis that tests both orchestrated changes in activities of steady state metabolites in a given pathway, as well as aberrations in the mechanisms of metabolic reactions. The fourth aim of the project provides a uniﬁed framework for network-based integrative analysis of static (based on mass spectrometry) and dynamic (based on metabolic ﬂux) metabolomics measurements, thus providing an integrated view of the metabolome and the ﬂuxome. Finally, the last aim implements the pro- posed methods in easy-to-use open-source software leveraging the R language, the capabilities of the Cytoscape platform and the Galaxy workﬂow system, thus providing an expandable platform for further developments in the area of metabolomics. The proposed software tool will also provide a plug-in to the Data Repository and Coordination Center (DRCC) data sets, where all regional metabolomics centers supported by the NIH Common Funds Metabolomics Program deposit curated data.         PUBLIC HEALTH RELEVANCE: Metabolomics, i.e. the study of small molecules involved in metabolism, provides a dynamic view into processes that reﬂect the actual physiology of the cell, and hence offers vast potential for detection of novel biomarkers and targeted therapies for complex diseases. However, despite this potential, the development of computational methods for analysis of metabolomics data lags the rapid growth of metabolomics proﬁling technologies. The current application addresses this need by developing novel statistical machine learning methods for integrative analysis of static and dynamic metabolomics measurements, as well as easy-to-use open-source software to facilitate the application of these methods.            ",Machine Learning Tools for Discovery and Analysis of Active Metabolic Pathways,9104589,R01GM114029,"['Accounting', 'Address', 'Adoption', 'Anabolism', 'Area', 'Biochemical Pathway', 'Biochemical Reaction', 'Biological', 'Biological Assay', 'Cardiovascular system', 'Cell physiology', 'Cells', 'Characteristics', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Deposition', 'Detection', 'Development', 'Diabetes Mellitus', 'Dimensions', 'Disease', 'Environment', 'Environmental Risk Factor', 'Equilibrium', 'Funding', 'Galaxy', 'Homeostasis', 'Imagery', 'Knowledge', 'Label', 'Language', 'Letters', 'Linear Models', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methodology', 'Methods', 'Names', 'Network-based', 'Nuclear Magnetic Resonance', 'Pathway interactions', 'Phase', 'Phenotype', 'Plug-in', 'Procedures', 'Process', 'Prognostic Marker', 'Proteomics', 'Reaction', 'Sampling', 'Signal Transduction', 'Software Tools', 'Staging', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Work', 'base', 'biological systems', 'biomarker discovery', 'design', 'diagnostic biomarker', 'improved', 'insight', 'interest', 'learning strategy', 'metabolome', 'metabolomics', 'new technology', 'novel', 'novel diagnostics', 'novel marker', 'open source', 'programs', 'public health relevance', 'rapid growth', 'research study', 'response', 'small molecule', 'targeted treatment', 'tool', 'transcriptomics']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2016,359776,0.070671492253398
"A Machine-Learning Based Software Widget for Resolving Metabolite Identities Owing to recent technological advances in measurement platforms, it is now possible to simultaneously detect and characterize a very large number of metabolites covering a substantial fraction of the small molecules present in a biological sample. This presents an exciting opportunity to develop potentially transformative approaches to study cells and organisms. One major challenge in realizing this potential lies in processing and analyzing the data. A typical dataset from an untargeted experiment contains many of thousands of “features,” each of which could correspond to a unique metabolite. Analyzing such datasets to obtain meaningful biological information depends on reliably and efficiently resolving the chemical identities of the detected features. Currently, in silico fragmentation methods predict candidate metabolites that are scored and ranked based on how well the fragmentation explains the observed MS/MS spectrum, and on other factors influencing fragmentation such as bond dissociation energies and ionization conditions. Deciding which candidate metabolites is the best match for a particular feature in the context of the biological sample, however, is a daunting task. Extensive testing of candidate metabolites against chemical standards library may be prohibitive in terms of cost and efforts. We seek to develop software-enabled workflows centered on resolving metabolite identities. Our approach is to exploit knowledge of the biological context of a sample to identify the metabolites. Recognizing that the metabolites present in a sample result from enzyme-catalyzed biochemical reactions active in the corresponding biological system, we employ topological analysis and inference to best map the metabolites implied by the detected features to metabolic pathways that are feasible based on the genome(s) of cells in the biological system. Aim 1 develops a computational method based on Bayesian-inference to enhance candidate metabolite rankings that are obtained via in silico fragmentation analysis. Our method utilizes all available information (database lookups, in silico fragmentation analysis, and network/pathway context) to maximally inform and adjust the rankings. Aim 2 will build software widgets to implement the metabolite identification workflow within a data-analytics framework. As the analytics framework, we will use Orange, which allows the user to create interactive data analysis pipelines through a plug-and-play graphical user interface (GUI). Aim 3 will validate the computational method and software widget implementation. Experimental validation will utilize high-purity standards to confirm (or reject) the computationally assigned metabolite identities. Widget implementation will be evaluated through a focus group discussion with the widget users in the labs directed by the PIs. As project outcomes, we anticipate both a methodological advance in analyzing mass signature data as well as a suite of easily accessible software in the form of widgets. Metabolomics is concerned with the comprehensive characterization of the small molecule metabolites in biological systems. Owing to recent technological advances in measurement platforms, it is now possible to simultaneously detect and characterize a very large number of metabolites. Prospectively, advanced computational tools and software for metabolomics data analysis can aid discovery efforts aimed at identifying novel bioactive metabolites that could be developed into diagnostic indicators or therapeutic agents. ",A Machine-Learning Based Software Widget for Resolving Metabolite Identities,9223450,R03CA211839,"['Address', 'Algorithms', 'Attention', 'Automatic Data Processing', 'Bayesian Analysis', 'Biochemical Pathway', 'Biochemical Reaction', 'Biological', 'Cells', 'Chemicals', 'Classification', 'Complex', 'Computer Simulation', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Analytics', 'Data Set', 'Databases', 'Diagnostic', 'Dissociation', 'Environment', 'Enzymes', 'Feedback', 'Focus Groups', 'Genes', 'Genome', 'Goals', 'Human', 'Knowledge', 'Libraries', 'Literature', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Metabolic Pathway', 'Metabolism', 'Methodology', 'Methods', 'Nuclear Magnetic Resonance', 'Oranges', 'Organism', 'Outcome', 'Pathway Analysis', 'Pathway interactions', 'Pattern', 'Play', 'Process', 'Reproducibility', 'Research', 'Resolution', 'Sampling', 'Signal Transduction', 'Statistical Data Interpretation', 'Statistical Models', 'Surveys', 'Testing', 'Therapeutic Agents', 'Time', 'Uncertainty', 'Validation', 'Visual', 'base', 'biological systems', 'chemical standard', 'computerized tools', 'cost', 'database query', 'flexibility', 'functional outcomes', 'graphical user interface', 'heuristics', 'inhibitor/antagonist', 'instrument', 'ionization', 'mass spectrometer', 'member', 'metabolomics', 'novel', 'programs', 'protein expression', 'research study', 'small molecule', 'software development']",NCI,TUFTS UNIVERSITY MEDFORD,R03,2016,147569,0.042597824857785904
"Self Correcting Nanoflow LC-MS for Clinical Proteomics DESCRIPTION (provided by applicant): The overall goal of this proposal is to improve the quality, reliability, and interlaboratory comparability of peptide mass spectrometry data. Mass spectrometry (MS) has become a fundamental technology for the identification and quantitative analysis of proteins, protein interactions, and protein post-translational modifications. These analyses are an important part of solving biological problems that involve changes in protein abundance in response to disease, drug treatment, and genetic or environmental perturbations. Unfortunately, the application of protein mass spectrometry measurements in the clinical laboratory has been limited. Unlike most clinical assays by mass spectrometry, which use microflow liquid chromatography, peptide measurements are commonly performed using a nanoflow liquid chromatograph interface to the mass spectrometer (nanoflow LC-MS). Despite their analytical power, these nanoflow LC-MS methods have been difficult to apply robustly in quantitative assays involving large numbers of samples from a challenging sample matrix. The successful completion of our project will result in a peptide analysis platform that can automatically assess problems with the nanoflow LC-MS system and correct the problem during an analytical run and will significantly improve the robustness and reproducibility of peptide mass spectrometry measurements. PUBLIC HEALTH RELEVANCE: Mass spectrometry has been a fundamental technology for the analysis of proteins in health and disease. However, despite the analytical power of conventional mass spectrometry methods, they have not been well-suited for the comparative analysis of very large numbers of samples acquired under a large number of conditions. Thus, the continued development of novel mass spectrometry technology is essential to understanding complex biological systems so that can be characterized that have a change in abundance in response to disease, drug treatment, and genetic or environmental perturbation.",Self Correcting Nanoflow LC-MS for Clinical Proteomics,9060365,R01GM107142,"['Biological', 'Biological Assay', 'Clinical', 'Communities', 'Computer software', 'Couples', 'Data', 'Data Collection', 'Data Quality', 'Development', 'Disease', 'Environment', 'Event', 'Failure', 'Genetic', 'Goals', 'Health', 'Information Systems', 'Laboratories', 'Liquid Chromatography', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Medicine', 'Methods', 'Outcome', 'Peptides', 'Performance', 'Pharmacotherapy', 'Post-Translational Protein Processing', 'Process', 'Protein Analysis', 'Proteins', 'Proteomics', 'Protocols documentation', 'Quality Control', 'Reproducibility', 'Robotics', 'Running', 'Sampling', 'Source', 'System', 'Technology', 'Time', 'Training', 'Universities', 'Washington', 'base', 'comparative', 'complex biological systems', 'experience', 'improved', 'instrument', 'liquid chromatography mass spectrometry', 'mass spectrometer', 'novel', 'open source', 'operation', 'protein protein interaction', 'response', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2016,359848,0.06843062092225913
"Integrating cheminformatics and molecular simulations for virtual drug screening ﻿    DESCRIPTION (provided by applicant): The development of highly efficient and accurate approaches to structure-based virtual screening (VS) continues to represent a formidable challenge in the field of computational drug discovery. Outstanding and widely recognized research problems in the field include the relative computational inefficiency of most approaches, which limits the size of molecular libraries used for virtual screening; the low hit rate; and the inaccurate prediction of ligand binding affinity and pose. The proposed studies address these challenges by using innovative and computationally efficient approaches to VS that fully integrate concepts from the complementary fields of cheminformatics and molecular simulation to devise an integrated two-step VS methodology. Building upon our experience in cheminformatics and QSAR modeling, we aim to develop novel, computationally efficient cheminformatics approaches to pre-process very large (on the order of 107 compounds) chemical libraries available for biological screening, and eliminate up to 99% of improbable ligands. Only the remaining 1% of probable ligands will be evaluated by slower but accurate ensemble flexible docking approaches relying on molecular simulation techniques. The cheminformatics step will also produce important information on privileged protein-ligand interactions that will be used in a live-processing step to guide the structure-based virtual screening and avoid oversampling of ligand poses. Moreover, post- processing cheminformatics methods will be implemented to filter out decoy poses from docking calculations. The ultimate goal of our hybrid methodology is to arrive at a small set of high-affinity computational hits in receptor-bound conformations that can be validated experimentally. We will pursue this goal following three specific aims: 1) Develop novel cheminformatics-based virtual screening approaches to eliminate both improbable ligands and improbable poses, as well as generate information on preferred protein-ligand interactions; 2) Develop new, efficient flexible ensemble docking methods guided by the preferred protein- ligand interactions to select the most probable ligands and predict their binding poses; 3) Apply the developed hierarchical virtual screening workflow to several therapeutic targets and test high-confidence computational hits in experimental assays. All computational tools resulting from this project will be made publicly available. This proposal is innovative because the proposed VS platform will result from a unique marriage of disparate approaches for VS, combining their corresponding strengths. This proposal is significant because the implementation of this project will enable substantial improvement in the efficiency, accuracy, and experimentally-confirmed impact of structure-based drug discovery tools.         PUBLIC HEALTH RELEVANCE: Advances in drug discovery rely on the development of novel effective computational methodologies. This proposal advances an efficient and robust computational workflow for structure-based virtual screening of very large chemical libraries. The ultimate goal of this project is to arrive at a small number of candidate molecules with high predicted binding affinity to their biological targets, which will be tested in confirmatory experiments.        ",Integrating cheminformatics and molecular simulations for virtual drug screening,8858750,R01GM114015,"['Active Sites', 'Address', 'Affect', 'Affinity', 'Benchmarking', 'Binding', 'Binding Sites', 'Biological', 'Biological Assay', 'Chemicals', 'Computational Geometry', 'Computer Simulation', 'Computing Methodologies', 'Data Set', 'Descriptor', 'Development', 'Docking', 'Enzymes', 'G-Protein-Coupled Receptors', 'Goals', 'Hybrids', 'Lead', 'Libraries', 'Life', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Malignant Neoplasms', 'Marriage', 'Methodology', 'Methods', 'Mining', 'Modeling', 'Molecular', 'Molecular Bank', 'Molecular Conformation', 'Orphan', 'Performance', 'Pharmaceutical Preparations', 'Phosphotransferases', 'Planning Techniques', 'Preclinical Drug Evaluation', 'Process', 'Proteins', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Research', 'Series', 'Side', 'Staging', 'Structure', 'Techniques', 'Technology', 'Testing', 'Validation', 'Vertebral column', 'base', 'cheminformatics', 'computerized tools', 'drug discovery', 'experience', 'flexibility', 'improved', 'improved outcome', 'innovation', 'novel', 'novel strategies', 'programs', 'public health relevance', 'receptor binding', 'research study', 'screening', 'simulation', 'small molecule', 'small molecule libraries', 'sperm cell', 'therapeutic target', 'three dimensional structure', 'tool', 'user friendly software', 'virtual']",NIGMS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2016,293344,-0.009793417913331213
"Development of integrative models for early liver toxicity assessment ﻿    DESCRIPTION (provided by applicant): Computational toxicology has become a critical area of research due to the burgeoning need to evaluate thousands of pharmaceutical and environmental chemicals with unknown toxicity profiles, the high demand in time and resources by current experimental toxicity testing, and the growing ethical concerns over animal use in toxicity studies. Despite tremendous efforts, little success has been attained thus far in the development of predictive computational models for toxicity, primarily due to the complexity of toxicity mechanisms as well as the lack of high-quality experimental data for model development.  A critical challenge in toxicity testing of chemicals is that toxicity effects are doe-dependent: the true toxic hits may show no toxicity at all at low dose level. Therefore, traditiona high-throughput screening (HTS) that test chemicals only at a single concentration is not suitable for toxicity screening. On the contrary, the recently developed quantitative high-throughput screening (qHTS) platforms can evaluate each chemical across a broad range of concentrations, and is gaining ever-increasing popularity as a tool for in vitro toxicity profiling The concentration-response information generated by qHTS are expected to provide more accurate and comprehensive information of the toxicity effects of chemicals, offering promising data that can be mined to estimate in vivo toxicities of chemicals. However, our previous studies showed that if processed inappropriately, such concentration-response information contribute little to improve the toxicity prediction. This is especially true when multiple types of qHTS data are used together. Therefore, in this study, we will extend our previous approaches to develop novel statistical and computational tools that can curate, preprocess, and normalize the concentration-response information from multiple different qHTS databases.  Traditionally, toxicity models are based on either the chemical data (such as the quantitative structure- activity relationship analysis), or the in vitro toxicity profiling data (such as the in vitro-in vivo extrapolations). Our previous experiences suggested that integrating biological descriptors such as the in vitro cytotoxicity profiles or the short-term toxigenomic data, with chemical structural features is able to predict rodent acute liver toxicity with reasonable accuracy. Therefore, the second part of this proposal will be devoted to develop novel computational models for hepatotoxicity prediction by integrating qHTS toxicity profiles and chemical structural information In Aim 1, we will curate, preprocess, and normalize collected public liver toxicity datasets. In ths study, we will model toxicity effects using multiple large public datasets such as HTS and qHTS bioassay data (Tox21[1] and ToxCast[2]), hepatotoxicity side effect reports on marketed failed drugs[3], the Liver Toxicity Knowledge Base Benchmark Dataset (LTKB-BD[4]), etc. Statistical methods for cross-study validation and quality control will be applied to the collected datasets to ensure computational compatibility and to select the appropriate datasets for analysis. In Aim 2, we will develop predictive models for chemicals' liver toxicity based on an integrative modeling workflow that will make use of both structural and in vitro toxicity profiles of a chemical. Our previous studies [5] showed that models using both in vitro toxicity profiles and chemical structural data have better accuracy for rodent acute liver toxicity than models using either data type alone. Here, we will develop a novel modeling workflow that start with defining the functional clusters of chemicals via curated qHTS toxicity profiles, and is followed by developing computational models to correlate chemical and biological data with overall toxicity risks in humans. The predictive models will be validated using independent datasets with over 800 compounds. In Aim 3, we propose to prioritize the qHTS profiling assays used in the model for future toxicity testing. We will evaluate all the in vitro assays as biological descriptors from thee perspectives, including descriptor importance in the integrative toxicity model, correlation with i vivo DILI outcomes, and level of information content estimated by a novel approach based on network analysis.    PUBLIC HEALTH RELEVANCE: In this study we aim to develop computational models that can identify potential liver toxicants. Liver toxicity is a significant contributor to the high attition rate in drug development. Moreover, toxic chemicals in food, water, and consumer products all pose serious risks for liver toxicity. As a result, there is great interest in developing high-throughput, high-content experimental and computational tools to evaluate the liver toxicity of thousands of pharmaceutical and environmental chemicals. This study focuses on developing novel informatics tools that enable the extraction and integration of chemical concentration-response information from multiple quantitative high-throughput screening databases for model development, and developing statistical models that are able to integrate this concentration-response information with chemical structural features to predict their risk of liver toxicity.  ",Development of integrative models for early liver toxicity assessment,9017336,R03ES026397,"['Acute', 'Address', 'Adverse effects', 'Algorithms', 'Animals', 'Area', 'Benchmarking', 'Biological', 'Biological Assay', 'Chemicals', 'Communities', 'Complex', 'Computer Simulation', 'Data', 'Data Set', 'Databases', 'Descriptor', 'Development', 'Dose', 'Dreams', 'Ensure', 'Ethics', 'Food', 'Future', 'Gene Expression', 'Genomics', 'Goals', 'Gold', 'Health', 'Hepatotoxicity', 'Human', 'In Vitro', 'Informatics', 'International', 'Liver', 'Machine Learning', 'Marketing', 'Mining', 'Modeling', 'National Human Genome Research Institute', 'National Institute of Environmental Health Sciences', 'Nature', 'North Carolina', 'Outcome', 'Pathway Analysis', 'Performance', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Poison', 'Process', 'Productivity', 'Quality Control', 'Quantitative Structure-Activity Relationship', 'Reporting', 'Research', 'Resources', 'Risk', 'Rodent', 'Scientist', 'Shapes', 'Statistical Methods', 'Statistical Models', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicogenetics', 'Toxicology', 'Translational Research', 'United States Environmental Protection Agency', 'United States Food and Drug Administration', 'Universities', 'Variant', 'Water', 'base', 'computerized tools', 'consumer product', 'cost', 'cost effective', 'cytotoxicity', 'data modeling', 'drug development', 'drug market', 'drug withdrawal', 'environmental chemical', 'experience', 'high throughput screening', 'improved', 'in vitro Assay', 'in vivo', 'interest', 'knowledge base', 'liver injury', 'model building', 'model development', 'novel', 'novel strategies', 'post-market', 'preclinical study', 'predictive modeling', 'programs', 'response', 'screening', 'success', 'tool', 'toxicant', 'validation studies']",NIEHS,UT SOUTHWESTERN MEDICAL CENTER,R03,2016,81000,0.021854686053667773
"UVPD-MS Characterization of Lipopolysaccharides Abstract. Gram-negative bacteria have caused many of the most persistent infections as well as some of the deadliest pandemics in the world. Some strains have developed resistant to all available drugs, thus leading to increasing mortality from previously treatable bacterial infections. The National Strategy for Combating Antibiotic-Resistant Bacteria released by the White House in September 2014 focused on the need for (i) advancing the development of methods for identification and characterization of bacteria, (ii) accelerating basic research for new antibiotics, and (iii) improving capabilities for surveillance of antibiotic-resistant bacteria. This proposal focuses on the development of innovative tandem mass spectrometry approaches for characterization of lipopolysaccharides (LPS), the primary constituent of the outer membrane of Gram-negative bacteria that protects the membrane from chemical attack and is recognized by the immune system during pathogenic invasion. Structural characterization of LPS is critical to understanding how the structure of LPS influences immune stimulation as well as facilitating development of new antimicrobials and vaccines. This is a significant analytical challenge due to the branched structures and amphipathic properties of LPS. The escalating concerns about antibiotic resistance bacteria and the need for better avenues of defense against infectious diseases have motivated the proposed work. The objectives of this proposal are: Aim 1: Development of ultraviolet photodissociation (UVPD) mass spectrometry via hierarchical, decision-tree workflows for top-down characterization of LPS to facilitate high throughput analysis; Aim 2: Development of MS/MS approaches for serotyping of Gram-negative bacteria based on LPS; Aim 3: Examination of peptide/LPS interactions via native-spray mass spectrometry to provide both mechanistic information and screening capabilities for new antimicrobials, and Aim 4: Applications to a variety of structural problems related to the biosynthesis of LPS in Gram- negative bacteria and characterization of hybrid O-antigen/lipid A molecules in vesicle-based vaccines.  We have established a new collaboration with Dr. Bryan Davies' group to develop mass spectrometry methods to characterize peptide/lipid A interactions in support of the hunt for better antimicrobials. The continued collaboration with Dr. Stephen Trent's group emphasizes: (i) approaches for deciphering the biosynthetic pathways of bacterial LPS that endow them with the remarkable ability to re-design their outer membranes and develop antibiotic resistance, and (ii) innovative vaccine design based on antigenic LPS in vesicles.    Narrative: Gram-negative bacteria are responsible for some of the deadliest and more widespread pandemics in the world. The proposed work focuses on the development of advanced mass spectrometry approaches for characterization of complex lipopolysaccharides, including the endotoxic lipid A domains, that comprise the outer membrane of Gram-negative bacteria. The proposed work will be applied to evaluate new antimicrobials and support development of hybrid vaccines.",UVPD-MS Characterization of Lipopolysaccharides,9174984,R01GM103655,"['Acylation', 'Address', 'Advanced Development', 'Affinity', 'Antibiotic Resistance', 'Antibiotics', 'Antimicrobial Resistance', 'Architecture', 'Bacteria', 'Bacterial Infections', 'Bacterial Vaccines', 'Basic Science', 'Binding', 'Cataloging', 'Catalogs', 'Cells', 'Chemical Warfare', 'Code', 'Collaborations', 'Communicable Diseases', 'Complex', 'Complex Mixtures', 'Custom', 'Databases', 'Decision Trees', 'Development', 'Distal', 'Exhibits', 'Focus Groups', 'Glycolipids', 'Gram-Negative Bacteria', 'Housing', 'Hybrids', 'Immune', 'Immune system', 'Infection', 'Ions', 'Lipid A', 'Lipopolysaccharide Biosynthesis Pathway', 'Lipopolysaccharides', 'Mass Spectrum Analysis', 'Membrane', 'Methodology', 'Methods', 'Modification', 'Molecular', 'O Antigens', 'Oligosaccharides', 'Pathway interactions', 'Pattern', 'Peptides', 'Pharmaceutical Preparations', 'Phosphorylation', 'Polysaccharides', 'Process', 'Production', 'Property', 'Publishing', 'Resistance', 'Serotyping', 'Structure', 'System', 'Tail', 'Vaccine Design', 'Vaccines', 'Variant', 'Vesicle', 'Virulence', 'Work', 'abstracting', 'acyl group', 'antimicrobial', 'base', 'cell envelope', 'combat', 'design', 'high throughput analysis', 'improved', 'innovation', 'innovative technologies', 'inorganic phosphate', 'instrument', 'mortality', 'novel', 'novel therapeutics', 'pandemic disease', 'response', 'screening', 'sugar', 'tandem mass spectrometry', 'ultraviolet']",NIGMS,"UNIVERSITY OF TEXAS, AUSTIN",R01,2016,322883,0.039671448529459384
"Forecasting pulmonary inflammation from in vitro assay results for nanoparticles ﻿    DESCRIPTION (provided by applicant):  The rapidly developing field of nanotechnology shows promise by allowing designers to specifically select unique combinations of material properties as needed increasing the effectiveness of applications in medicine, coatings, lubrication, semiconductors, composites, and many others. These materials with their unique combinations of properties on exposure to humans may result in unanticipated hazards, however, putting workers in nanotechnology-related industries at risk. Traditional animal testing is expensive and too slow to evaluate potential risks for the current pace of new nanomaterial development. Both technology developers and regulators need more rapid methods to evaluate new nanomaterial configurations for their risk potential. Much hope is placed in high-throughput in vitro screening assays, but the relevance of these results to the potential for human disease or even the observed toxic effects in animal exposures is unclear. Some research has proposed Quantitative Structure Activity Relationships (QSARs) to predict in vitro nanomaterial toxicity in a few specific assays, but the applicability of these models to a wider group of materials, alternative in vitro assays, or in vivo toxicity has not been explored. If the primary exposure pathway for workers in the near term is inhalation, which in vitro assays will provide the most reliable risk information for that scenario? Two recently available data sources will permit this study to investigate this question: the Environmental Protection Agency's (EPA) ToxCast data for nanomaterials and the Nanomaterial Pulmonary Toxicity Database (NTDB), a collection of published peer reviewed studies observing pulmonary inflammation in rodents upon exposures to nanomaterials. This study will pursue the following specific aims: (1.) identify combinations of in vitro assay results that can reliably forecast the results of pulmonary inflammation results in rodents; (2.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to a wider array of in vitro toxicity assays; and (3.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to in vivo pulmonary inflammation results. This study will employ machine learning methods to cluster similar nanomaterials between the various in vitro and in vivo results, and to identify combinations of in vitro assays that rank order the toxicity of nanomaterials most similarly to pulmonary inflammation results in rodents considering also how changes in specific chemical and physical particle properties exacerbate or mitigate observed toxicity. This study addresses documented research needs in the National Occupational Research Agenda (NORA) cross- sector Nanotechnology program including specific goals in the Human Health and Informatics categories. Implementation complies with the Research to Practice (r2p) Initiative in its formulation, design, and implementation plan including industry an public outreach. The insight generated by this study will improve nanomaterial risk screening capabilities and focus attention and effort on those measurements and techniques proven to be most effective and reliable enabling better management and control of the risks faced by workers. PUBLIC HEALTH RELEVANCE:  Although toxicity risk information for nanoparticles is accumulating rapidly, the development of new nanomaterial configurations is proceeding too fast for our best risk assessment tools (i.e. animal testing) to keep up. The new availability of two large databases of in vitro assay results and pulmonary inflammation results in rodents will permit this study to investigate which in vitro assays provide the most predictive information about the results from in vivo exposures, and thus speed up the risk screening process for nanomaterials. The results of this study will have important implications for more quickly identifying new nanomaterial-related risks to workers.",Forecasting pulmonary inflammation from in vitro assay results for nanoparticles,9144793,R03OH010956,[' '],NIOSH,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R03,2016,66564,0.004834351304609276
"Binding-Site Modeling with Multiple-Instance Machine-Learning DESCRIPTION (provided by applicant): This proposal is entitled ""Binding-Site Modeling with Multiple-Instance Machine-Learning."" One of the most challenging and longest studied problems in computer-aided drug design has been affinity prediction of small molecule ligands for their cognate protein targets. Despite decades of work, quantitative structure-activity re- lationship prediction (QSAR) approaches still suffer from poor accuracy, especially when predicting outside of closely related series of molecules. Even with high-quality structures of target proteins, approaches grounded in physics are also far from robust and accurate enough for reliable use in drug lead optimization. This proposal will build upon a foundation in multiple-instance machine learning applied to computer-aided drug design problems and develop a robust, accurate, and practically applicable affinity prediction methodology. The methodology requires only ligand structures and associated activity data for training, and it induces a virtual protein binding site composed of molecular fragments. The virtual binding pocket (or ""pocketmol"") is used in conjunction with a scoring function developed originally for molecular docking. The pocketmol configuration is chosen such that the optimal conformation and alignment of a ligand (based on the docking scoring function), yields scores for training ligands that are close to the known experimental values. Feasibility has been demon- strated in papers involving both membrane-bound receptors and enzymes.  However, multiple challenges remain and are the subject of the proposed research. There are three key issues. First, there exist many pocketmols that satisfy the requirements of fitting the training data, so general solutions must be developed to address the inductive bias of the learning procedure as well as model selection after the procedure. Second, since any particular model is the product of a learning process, it will have some domain of applicability, with some new molecules likely to be predicted well and others poorly. Further, the model will be better informed by learning with certain new molecules but not others. We must develop solutions for estimating confidence of predictions for new molecules as well as for identifying particular molecules that will be highly informative. Third, the operational application of these methods involves model building, guided chemical synthesis, and iterative refinement of models. Convincing validation will require application on temporal series of molecules synthesized for multiple targets of pharmaceutical interest. The proposed work will develop novel methods to address these challenges and will establish extensive validation on multiple pharmaceutically relevant temporal series of small molecules that were the subject of real-world lead-optimization exercises. PUBLIC HEALTH RELEVANCE: The dominant mode of therapeutic discovery involves the design ""me-too"" drugs that are very similar in structure and effect to existing drugs. In order to address the unmet medical needs of an aging population, novel therapeutics must be developed, and this will require much more creativity in the design process. The proposed research will develop a predictive computational framework to aid in active design of structurally novel drug molecules during the drug discovery lead optimization process.",Binding-Site Modeling with Multiple-Instance Machine-Learning,8786087,R01GM101689,"['Address', 'Affinity', 'Binding', 'Binding Sites', 'Biological Assay', 'Chemicals', 'Collaborations', 'Computer Assisted', 'Creativeness', 'Data', 'Data Set', 'Docking', 'Drug Design', 'Enzymes', 'Exercise', 'Foundations', 'Health', 'Knowledge', 'Lead', 'Learning', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Measures', 'Medical', 'Membrane', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Paper', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Physics', 'Population', 'Procedures', 'Process', 'Protein Binding', 'Proteins', 'Publishing', 'Quantitative Structure-Activity Relationship', 'Research', 'Series', 'Site', 'Solutions', 'Structure', 'System', 'Testing', 'Therapeutic', 'Training', 'Validation', 'Work', 'aging population', 'base', 'blind', 'chemical synthesis', 'computer framework', 'design', 'design and construction', 'drug discovery', 'falls', 'interest', 'model building', 'novel', 'novel therapeutics', 'predictive modeling', 'process optimization', 'prospective', 'receptor binding', 'small molecule', 'virtual']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2015,300675,-0.005442746851805772
"Computational approaches to protein identification and quantification using MS/MS (Not modified) Liquid chromatography (LC) coupled with tandem mass spectrometry (MS/MS) is a widely used platform for high-throughput identification and quantification of proteins in biological samples. In addition to experimental steps in the pipeline, computational and statistical procedures play important roles in determining the content of the mixture. However, even with the best analytical platforms and modern software, only a small fraction of spectra are typically identified, thus directly impacting the quality of the biological sample analysis. If high- throughput proteomics techniques are to become routinely used in biomedical applications on the population scale, it is critical to address analytical and computational factors that contribute to the inadequate identification coverage and sensitivity. Over the past several years, we and others have spent a significant amount of research activity to understand and model analytical platforms and subsequently improve computational methods for the analyses of complex biological mixtures. While our original grant application has resulted in methods and programs already accepted by the community, there is a need and significant room for further key contributions. We see many of these contributions being related to the analyses of dynamic changes in cells and tissues, and involving changes in protein quantities, protein post-translational modifications (PTMs) and transient protein-protein interactions. Mass spectrometry-based proteomics provides an excellent platform to address each of these challenges. Thus, we plan to continue to develop novel methods for label-free quantification and remain close to our core strengths, but also strongly focus on PTMs and protein-protein interactions as new directions of this renewal application. This application includes a considerably closer collaboration between computational (Dr. Radivojac, Dr. Tang) and experimental (Dr. Arnold, Dr. Clemmer, Dr. Reilly) scientists than did our original application. The investigators bring complementary expertise and experience in a range of disciplines involving protein bioinformatics, algorithms, machine learning, as well as analytical chemistry and instrumentation. Overall, we believe that this proposal will result in significant advances for mass spectrometry-based proteomics. (Not modified) We propose to develop novel and theoretically sound methodology for several important yet challenging problems in mass spectrometry-based proteomics, including the identification of peptides containing post- translational modifications and cross-linked peptides, and the absolute quantification of proteins in complex samples.",Computational approaches to protein identification and quantification using MS/MS,8902210,R01GM103725,"['Address', 'Algorithmic Software', 'Algorithms', 'Analytical Chemistry', 'Applications Grants', 'Area', 'Bioinformatics', 'Biological', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Coupled', 'Custom', 'Data', 'Data Set', 'Development', 'Discipline', 'Funding', 'Gases', 'Goals', 'Indiana', 'Ions', 'Label', 'Learning', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Occupations', 'Peptide Library', 'Peptides', 'Phase', 'Play', 'Population', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Relative (related person)', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Site', 'Spectrometry', 'Staging', 'Synthesis Chemistry', 'Synthetic Peptide Libraries', 'Techniques', 'Tissues', 'Training', 'Universities', 'Work', 'base', 'crosslink', 'experience', 'improved', 'instrument', 'instrumentation', 'ion mobility', 'model development', 'novel', 'programs', 'protein protein interaction', 'research study', 'response', 'sound', 'tandem mass spectrometry']",NIGMS,INDIANA UNIVERSITY BLOOMINGTON,R01,2015,411329,0.01281984885258114
"Self Correcting Nanoflow LC-MS for Clinical Proteomics DESCRIPTION (provided by applicant): The overall goal of this proposal is to improve the quality, reliability, and interlaboratory comparability of peptide mass spectrometry data. Mass spectrometry (MS) has become a fundamental technology for the identification and quantitative analysis of proteins, protein interactions, and protein post-translational modifications. These analyses are an important part of solving biological problems that involve changes in protein abundance in response to disease, drug treatment, and genetic or environmental perturbations. Unfortunately, the application of protein mass spectrometry measurements in the clinical laboratory has been limited. Unlike most clinical assays by mass spectrometry, which use microflow liquid chromatography, peptide measurements are commonly performed using a nanoflow liquid chromatograph interface to the mass spectrometer (nanoflow LC-MS). Despite their analytical power, these nanoflow LC-MS methods have been difficult to apply robustly in quantitative assays involving large numbers of samples from a challenging sample matrix. The successful completion of our project will result in a peptide analysis platform that can automatically assess problems with the nanoflow LC-MS system and correct the problem during an analytical run and will significantly improve the robustness and reproducibility of peptide mass spectrometry measurements. PUBLIC HEALTH RELEVANCE: Mass spectrometry has been a fundamental technology for the analysis of proteins in health and disease. However, despite the analytical power of conventional mass spectrometry methods, they have not been well-suited for the comparative analysis of very large numbers of samples acquired under a large number of conditions. Thus, the continued development of novel mass spectrometry technology is essential to understanding complex biological systems so that can be characterized that have a change in abundance in response to disease, drug treatment, and genetic or environmental perturbation.",Self Correcting Nanoflow LC-MS for Clinical Proteomics,8840976,R01GM107142,"['Biological', 'Biological Assay', 'Clinical', 'Communities', 'Computer software', 'Couples', 'Data', 'Data Collection', 'Data Quality', 'Development', 'Disease', 'Environment', 'Event', 'Failure', 'Genetic', 'Goals', 'Health', 'Information Systems', 'Laboratories', 'Liquid Chromatography', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Medicine', 'Methods', 'Outcome', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Post-Translational Protein Processing', 'Process', 'Protein Analysis', 'Proteins', 'Proteomics', 'Protocols documentation', 'Quality Control', 'Reproducibility', 'Robotics', 'Running', 'Sampling', 'Source', 'System', 'Technology', 'Time', 'Training', 'Universities', 'Washington', 'base', 'comparative', 'complex biological systems', 'experience', 'improved', 'instrument', 'liquid chromatography mass spectrometry', 'mass spectrometer', 'novel', 'open source', 'operation', 'protein protein interaction', 'response', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2015,374279,0.06843062092225913
"A New Model of Peptide Fragmentation for Improved Protein Identification and Targ    DESCRIPTION (provided by applicant): Mass spectrometry (MS) based proteomics has emerged as a key technology in the search for disease- associated biomarkers. State-of-the-art instruments can identify thousands of proteins in a single sample by 'shotgun' proteomic analysis, where protein mixtures are proteolyzed into peptides, separated by one or more chromatographic steps, and analyzed by peptide dissociation using tandem mass spectrometry (MS/MS). The goal of this approach is to create new technologies for the accurate detection of proteins within complex samples. Achieving this target is currently limited by the major problem of inferring the peptide sequence from MS/MS spectra by sequence database searching: spectra are compared to ""model spectra"" generated from database sequences. Current algorithms suffer from poor accuracy and discrimination due to the use of simple models for predicting spectra, which ignores the rich information contained in the relative intensities of peaks in a typical MS/MS. Consequently, there is a vital need for more accurate models to predict MS/MS spectrum intensities from peptide sequences. In this proposal, we will develop a new and innovative kinetic model for predicting peptide fragmentation MS/MS spectra, and use the model to develop MS/MS identification algorithms with high discrimatory power. Spectra simulated by the kinetic model will then be used to design selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies. This will solve a bottleneck for widespread adoption of SRM methods for biomarker discovery, which is currently hindered by the slow process of identifying and optimizing SRM transitions for the assays. The following specific aims are (1) Develop an optimized kinetic model of gas-phase peptide fragmentation which predicts MS/MS spectra for any peptide sequence. Model parameters will be fit using the Levenberg- Marquardt algorithm, a robust method for non-linear least squares. (2) Extend the model to predict MS/MS fragmentation of phosphopeptides. The approaches developed in this aim can be extended to other disease- relevant post-translational modifications which profoundly alter peptide fragmentation and interfere with MS/MS identification. (3) Develop a route to successful implementation of spectrum-to-spectrum matching algorithms, an entirely new approach for large scale identification of proteins, in which MS/MS are searched directly against libraries of predicted spectra, simulated using our prototype kinetic model. We use predicted spectra to bypass the need for sequence databases, and spectrum-to-sequence strategies altogether. (4) Develop an algorithm for de novo prediction of selected reaction monitoring (SRM) assays for highly multiplexed quantitative measurement of proteins in complex mixtures.           PROJECT NARRATIVE Mass spectrometry-based proteomics has emerged as a key technology in the search for useful protein biomarkers, and holds many promises for early detection of disease, prediction of drug efficacy and resistance, and targeted molecular therapies. The field is currently limited by the major problem of inferring the peptide sequence from a fragmentation mass spectrum - until this problem is solved, many potential applications of proteomics to human health will not be achieved. We will develop a kinetic model to predict peptide fragmentation spectra for any peptide sequence; a method that will enable comprehensive protein profiling in human biofluids, and the rapid design of selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies.         ",A New Model of Peptide Fragmentation for Improved Protein Identification and Targ,8895275,R01CA155453,"['Address', 'Adoption', 'Algorithms', 'Biological Assay', 'Biological Markers', 'Bypass', 'Chemicals', 'Complex', 'Complex Mixtures', 'Databases', 'Detection', 'Discrimination', 'Disease', 'Dissociation', 'Drug resistance', 'Early Diagnosis', 'Gases', 'Goals', 'Health', 'Human', 'Ions', 'Kinetics', 'Least-Squares Analysis', 'Libraries', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular Target', 'Monitor', 'Peptides', 'Phase', 'Phosphopeptides', 'Plasma', 'Post-Translational Protein Processing', 'Process', 'Protein Analysis', 'Protein Sequence Analysis', 'Proteins', 'Proteomics', 'Reaction', 'Relative (related person)', 'Route', 'Sampling', 'Scanning', 'Screening for cancer', 'Sensitivity and Specificity', 'Set protein', 'Shotguns', 'Statistical Models', 'Techniques', 'Technology', 'Work', 'base', 'chemotherapy', 'design', 'drug efficacy', 'improved', 'innovation', 'instrument', 'instrumentation', 'interest', 'new technology', 'novel strategies', 'prevent', 'protein aminoacid sequence', 'protein profiling', 'prototype', 'tandem mass spectrometry', 'tool']",NCI,UNIVERSITY OF COLORADO,R01,2015,314363,0.009380821569455225
"Biomarker discovery for mitochondrial toxicants using metabolic footprinting Abstract Many environmental stressors have deleterious effects on mitochondrial functions, by a variety of mechanisms, and with timelines of different lengths. Mitochondrial dysfunction has multiple clinical presentations, often delayed from the onset of organelle damage. At present, biomarkers that report on mitochondrial function, to enable population studies of environmental exposures and their consequences, are lacking. We propose to identify candidate biomarkers using a metabolomics approach, in greater depth than has previously been applied to toxicologic investigations.  Metabolomic analysis provides a window on cellular and organismal functions, closer to the actual physiology than genomic or transcriptomic arrays. Using multiple platforms for separation and mass spectrometric resolution of complex mixtures, a comprehensive set of metabolites including organic acids, amino acids, steroids, complex lipids, energy charge and mitochondrial transport metabolites can be targeted. We will use this technology to develop biomarkers of mitochondrial dysfunction that will fill an important gap in current studies of environmental toxicology.  We will focus our studies on a polybrominated diphenyl ether, BDE-47, that is emerging as one of the major persistent organic pollutants in the U.S. Published data from our collaborator, Dr. Kavanagh, and our preliminary data indicate that BDE-47 impairs mitochondrial function in cell lines in vitro. Metabolites in extracellular media (metabolic footprinting) will be analyzed with primary mouse hepatocytes, one of the main targets of BDE-47 toxicity, as a function of dose and time of exposure. We will also test the hypothesis that fatty acid overload will uncover subtle mitochondrial defects by performing metabolomic analysis in isolated mitochondria. These studies will provide metabolic signatures of BDE-47 toxicity that will next be extended to in vivo studies of plasma and urine from BDE-47 treated mice. The possibility that lymphocytes may be a surrogate tissue for the mitochondrial toxicities of BDE-47 will be examined using the fatty acid overload assay.  The effects of genetic background and environment on BDE-47 toxicity are poorly understood. We will test two potential modifiers: 1) genetically engineered mice with low and high glutathione levels, and 2) fatty liver due to vitamin A deficiency. These experiments will provide novel information on potential high risk populations for BDE-47 exposure. A key question for these studies will be whether candidate biomarkers scale with toxicity (in addition to exposure dose).  In addition to discovering metabolic signatures of BDE-47 toxicity, we will examine two recently described mitochondrial responses to stress by metabolic footprinting: 1) mitochondrial proteotoxicity due to aggregation of unfolded/unassembled proteins, and 2) alternative fumarate respiration in response to hypoxia and distal block of the electron transport chain. By selecting defined mitochondrial responses, one adverse and one adaptive, we begin to categorize mitochondrial dysfunction and look for signatures that associate with specific types. In the case of fumarate respiration, a signature of high levels of succinate in secreted metabolites is already known.  This work is a close collaboration with Oliver Fiehn, expert in metabolomics screening and data analysis, and Terry Kavanagh, an expert in oxidative stress and mitochondrial toxicology. Public Health Relevance/Project Narrative Many environmental toxins inhibit mitochondria, the powerhouses of the cell, as a mechanism of toxicity. Current research in this area is hampered by the lack of convenient tests to measure early mitochondrial damage, which would promote appropriate preventive/treatment efforts for individuals and at risk populations. The goal of this research is to identify chemical changes in blood or urine that are indicators of mitochondrial damage in the body, using mass spectrometry tools to survey thousands of compounds.",Biomarker discovery for mitochondrial toxicants using metabolic footprinting,8874981,R01ES020819,"['Affect', 'Amino Acids', 'Area', 'Biochemical', 'Biochemistry', 'Bioenergetics', 'Biological Assay', 'Biological Markers', 'Biology', 'Blood', 'Body Fluids', 'Cell Line', 'Cell physiology', 'Cells', 'Characteristics', 'Charge', 'Chemicals', 'Classification', 'Clinical', 'Collaborations', 'Complex', 'Complex Mixtures', 'Data', 'Data Analyses', 'Defect', 'Diet', 'Disease', 'Distal', 'Dose', 'Electron Transport', 'Environment', 'Environmental Exposure', 'Exhibits', 'Exposure to', 'Fatty Acids', 'Fatty Liver', 'Fumarates', 'Functional disorder', 'Generations', 'Genetic', 'Genetically Engineered Mouse', 'Genomics', 'Glutathione', 'Goals', 'Harvest', 'Hepatocyte', 'Histocompatibility Testing', 'Hypoxia', 'In Vitro', 'Individual', 'Investigation', 'Length', 'Lipids', 'Liquid substance', 'Lymphocyte', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Membrane Potentials', 'Metabolic', 'Metabolic stress', 'Metabolic syndrome', 'Methods', 'Mitochondria', 'Mitochondrial Diseases', 'Modeling', 'Mus', 'Organelles', 'Oxidative Stress', 'Physiology', 'Plasma', 'Population', 'Population Study', 'Populations at Risk', 'Pre-Clinical Model', 'Preventive', 'Proteins', 'Publishing', 'Reactive Oxygen Species', 'Reporting', 'Research', 'Resolution', 'Respiration', 'Staging', 'Steroids', 'Stress', 'Succinates', 'Surveys', 'Technology', 'Testing', 'Time', 'TimeLine', 'Tissues', 'Toxic Environmental Substances', 'Toxic effect', 'Toxicology', 'Urine', 'Vitamin A', 'Vitamin A Deficiency', 'Work', 'abstracting', 'base', 'environmental stressor', 'environmental toxicology', 'extracellular', 'high risk', 'human population study', 'in vivo', 'insight', 'metabolomics', 'mitochondrial dysfunction', 'nonalcoholic steatohepatitis', 'novel', 'nucleotide metabolism', 'organic acid', 'phenyl ether', 'pollutant', 'protein misfolding', 'public health relevance', 'research study', 'response', 'screening', 'statistics', 'tool', 'toxicant', 'transcriptomics']",NIEHS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2015,377291,0.03259973834025955
"Sequential Ion/Ion Reactions for Large Peptide and Whole Protein Characterization DESCRIPTION (provided by applicant): The ability to sequence and identify proteins, map their sites of post-translational modification (PTM), and assess their abundances is central to modern biology. Mass spectrometry (MS) is the gold standard technology by which this information is obtained. Serving as the centerpiece, tandem MS (MS/MS) is a principal component. Electron transfer dissociation (ETD), a relatively new MS/MS dissociation method, has generated significant excitement for its compatibility with previously intractable peptide/protein classes. Five years ago m/z range, mass accuracy, and mass resolution considerably restricted the application of ETD. Our initial RO1 proposal successfully eliminated this limitation by coupling ETD to the orbitrap mass analyzer. The resulting system routinely analyzes peptides and proteins, with and without labile PTMs, with a high-fidelity readout (orbitrap). As a result, it realized many of our anticipated outcomes and created numerous unforeseen opportunities. Just in the PI's laboratory, the latter set includes data-dependent selection of dissociation method (i.e., Decision Tree), discovery of the unique chemical compositions of z-type ions, internal spectral calibration using ETD reagents, activated-ion ETD, and several biological applications. By 2008, the commercial implementation of our technology began to reach researchers across the globe-nearly 300 to date-enabling access to numerous previously intractable problems such as mapping Arg methylation sites, increasing coverage of low molecular weight proteins, providing unambiguous PTM site assignment, and screening glycopeptide libraries, among many others. We detail two new aims that build upon the high impact results of our initial funding period. Aim 1, how do we broaden the utility of ETD for biomedical research? Aim 2, what is the role of gas- phase purification in quantitative proteomics? We continue with a balance of instrumentation, method, informatic, and applied projects constructed upon the widely used ETD-orbitrap platform we described 3.5 years ago. Cutting edge MS based technology, Electron transfer dissociation (ETD), continues to be developed. This new MS/MS dissociation method enables previously intractable peptide/protein classes to be sequenced and identified, have their sites of post-translational modification (PTM) mapped, and assess their abundances. This is central to modern biology and has relevance for research ranging from human disease to evolution.",Sequential Ion/Ion Reactions for Large Peptide and Whole Protein Characterization,8838174,R01GM080148,"['Algorithms', 'Award', 'Beds', 'Biological', 'Biology', 'Biomedical Research', 'Calibration', 'Cells', 'Chemicals', 'Chemistry', 'Communities', 'Computer software', 'Coupled', 'Coupling', 'Data', 'Decision Trees', 'Development', 'Dissociation', 'Electron Transport', 'Equilibrium', 'Evolution', 'Fostering', 'Funding', 'Gases', 'Glycopeptides', 'Gold', 'Housing', 'Informatics', 'Ions', 'Knowledge', 'Laboratories', 'Libraries', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Methylation', 'Molecular Weight', 'Outcome', 'Peptides', 'Phase', 'Phosphorylation', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Protein Sequence Analysis', 'Proteins', 'Proteome', 'Proteomics', 'Protons', 'Reaction', 'Reaction Time', 'Reagent', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Shotgun Sequencing', 'Site', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'United States National Institutes of Health', 'Yeasts', 'acute stress', 'base', 'biological adaptation to stress', 'comparative', 'human disease', 'human tissue', 'improved', 'instrumentation', 'mass analyzer', 'model development', 'prevent', 'response', 'screening', 'tandem mass spectrometry', 'tool']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2015,337302,0.02329617877379272
"Forecasting pulmonary inflammation from in vitro assay results for nanoparticles ﻿    DESCRIPTION (provided by applicant):  The rapidly developing field of nanotechnology shows promise by allowing designers to specifically select unique combinations of material properties as needed increasing the effectiveness of applications in medicine, coatings, lubrication, semiconductors, composites, and many others. These materials with their unique combinations of properties on exposure to humans may result in unanticipated hazards, however, putting workers in nanotechnology-related industries at risk. Traditional animal testing is expensive and too slow to evaluate potential risks for the current pace of new nanomaterial development. Both technology developers and regulators need more rapid methods to evaluate new nanomaterial configurations for their risk potential. Much hope is placed in high-throughput in vitro screening assays, but the relevance of these results to the potential for human disease or even the observed toxic effects in animal exposures is unclear. Some research has proposed Quantitative Structure Activity Relationships (QSARs) to predict in vitro nanomaterial toxicity in a few specific assays, but the applicability of these models to a wider group of materials, alternative in vitro assays, or in vivo toxicity has not been explored. If the primary exposure pathway for workers in the near term is inhalation, which in vitro assays will provide the most reliable risk information for that scenario? Two recently available data sources will permit this study to investigate this question: the Environmental Protection Agency's (EPA) ToxCast data for nanomaterials and the Nanomaterial Pulmonary Toxicity Database (NTDB), a collection of published peer reviewed studies observing pulmonary inflammation in rodents upon exposures to nanomaterials. This study will pursue the following specific aims: (1.) identify combinations of in vitro assay results that can reliably forecast the results of pulmonary inflammation results in rodents; (2.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to a wider array of in vitro toxicity assays; and (3.) evaluate whether existing proposed QSARs for nanomaterial toxicity apply to in vivo pulmonary inflammation results. This study will employ machine learning methods to cluster similar nanomaterials between the various in vitro and in vivo results, and to identify combinations of in vitro assays that rank order the toxicity of nanomaterials most similarly to pulmonary inflammation results in rodents considering also how changes in specific chemical and physical particle properties exacerbate or mitigate observed toxicity. This study addresses documented research needs in the National Occupational Research Agenda (NORA) cross- sector Nanotechnology program including specific goals in the Human Health and Informatics categories. Implementation complies with the Research to Practice (r2p) Initiative in its formulation, design, and implementation plan including industry an public outreach. The insight generated by this study will improve nanomaterial risk screening capabilities and focus attention and effort on those measurements and techniques proven to be most effective and reliable enabling better management and control of the risks faced by workers.         PUBLIC HEALTH RELEVANCE:  Although toxicity risk information for nanoparticles is accumulating rapidly, the development of new nanomaterial configurations is proceeding too fast for our best risk assessment tools (i.e. animal testing) to keep up. The new availability of two large databases of in vitro assay results and pulmonary inflammation results in rodents will permit this study to investigate which in vitro assays provide the most predictive information about the results from in vivo exposures, and thus speed up the risk screening process for nanomaterials. The results of this study will have important implications for more quickly identifying new nanomaterial-related risks to workers.            ",Forecasting pulmonary inflammation from in vitro assay results for nanoparticles,8953935,R03OH010956,[' '],NIOSH,PENNSYLVANIA STATE UNIVERSITY-UNIV PARK,R03,2015,66904,0.004834351304609276
"Machine learning analysis of tandem mass spectra    DESCRIPTION (provided by applicant): Proteins are the primary functional molecules in living cells, and tandem mass spectrometry provides the most efficient means of studying proteins in a high-throughput fashion. The proposal aims to use state-of-the-art methods from the fields of machine learning, statistics and natural language processing to improve our ability to make sense of large tandem mass spectrometry data sets.  The core of the proposal is a type of probabilistic model, known as a dynamic Bayesian network that allows us to reason efficiently and accurately about complex sequential data sets. This modeling framework leverages a large body of related work from the fields of natural language processing and speech recognition. Much of this prior work has not yet been exploited by computational biologists, so the proposal represents a valuable cross-fertilization across disciplines.  More specifically, this project employs a collection of cooperating dynamic Bayesian networks to model jointly an entire mass spectrometry experiment. Relative to most existing methods for analyzing mass spectrometry data, which tend to divide the analysis of an experiment into a series of small independent subtasks, the proposed unified model jointly, considers all of the available data. This approach can thus exploit valuable dependencies among spectra and along various dimensions of the data. Dynamic Bayesian networks also provide a rigorous framework for performing inference from a combination of observed data and qualitative expert knowledge.  The project is divided into five aims, each of which concerns a particular type of mass spectrometry experiment. These experiments involve (1) identifying all of the proteins in a given complex biological sample using a standard mass spectrometry protocol; (2) identifying proteins using a modified protocol in which the mass spectrometer samples the data in a systematic, rather than data-dependent, fashion, with the goal of identifying lower abundance proteins; (3) quantifying the relative abundance of proteins within or between biological samples; (4) identifying post-translational modified proteins or proteins that contain sequence variation; and (5) performing targeted quantification of a specified set of proteins, such as proteins in a pathway of interest or protein biomarkers.  The methods described in this proposal have the potential to dramatically improve our ability to draw conclusions from and formulate hypotheses on the basis of high-throughput shotgun proteomics experiments. Experiments like the ones described above can, for example, identify proteins involved in fundamental disease processes, identify previously unknown protein isoforms, or quantify the re- sponses of proteins to environmental stressors or disease states.        The applications of mass spectrometry and its promises for improvements of human health are nu- merous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and specific diagnostic and prognostic screens. How- ever, making optimal use of mass spectrometry data requires sophisticated computational methods. This project will develop and apply novel statistical and machine learning methods for interpreting mass spectra.         ",Machine learning analysis of tandem mass spectra,8660698,R01GM096306,"['Amino Acid Sequence', 'Area', 'Biological', 'Biological Markers', 'C-Peptide', 'Cells', 'Clinical', 'Collection', 'Complex', 'Complex Mixtures', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Dependency', 'Diagnostic', 'Dimensions', 'Discipline', 'Disease', 'Fertilization', 'Goals', 'Graph', 'Health', 'Human', 'Ions', 'Knowledge', 'Life', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Natural Language Processing', 'Pathway interactions', 'Peptide Sequence Determination', 'Peptides', 'Phase', 'Post-Translational Protein Processing', 'Process', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Protocols documentation', 'Reaction', 'Relative (related person)', 'Reproducibility', 'Research Personnel', 'Sampling', 'Scanning', 'Series', 'Set protein', 'Shotguns', 'Specific qualifier value', 'Statistical Models', 'Time', 'Variant', 'Work', 'base', 'computer based statistical methods', 'computerized tools', 'design', 'disease phenotype', 'environmental stressor', 'improved', 'interest', 'liquid chromatography mass spectrometry', 'mass spectrometer', 'novel', 'prognostic', 'research study', 'response', 'speech recognition', 'statistics', 'tandem mass spectrometry', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2014,617496,0.0020540437210390004
"Binding-Site Modeling with Multiple-Instance Machine-Learning     DESCRIPTION (provided by applicant): This proposal is entitled ""Binding-Site Modeling with Multiple-Instance Machine-Learning."" One of the most challenging and longest studied problems in computer-aided drug design has been affinity prediction of small molecule ligands for their cognate protein targets. Despite decades of work, quantitative structure-activity re- lationship prediction (QSAR) approaches still suffer from poor accuracy, especially when predicting outside of closely related series of molecules. Even with high-quality structures of target proteins, approaches grounded in physics are also far from robust and accurate enough for reliable use in drug lead optimization. This proposal will build upon a foundation in multiple-instance machine learning applied to computer-aided drug design problems and develop a robust, accurate, and practically applicable affinity prediction methodology. The methodology requires only ligand structures and associated activity data for training, and it induces a virtual protein binding site composed of molecular fragments. The virtual binding pocket (or ""pocketmol"") is used in conjunction with a scoring function developed originally for molecular docking. The pocketmol configuration is chosen such that the optimal conformation and alignment of a ligand (based on the docking scoring function), yields scores for training ligands that are close to the known experimental values. Feasibility has been demon- strated in papers involving both membrane-bound receptors and enzymes.  However, multiple challenges remain and are the subject of the proposed research. There are three key issues. First, there exist many pocketmols that satisfy the requirements of fitting the training data, so general solutions must be developed to address the inductive bias of the learning procedure as well as model selection after the procedure. Second, since any particular model is the product of a learning process, it will have some domain of applicability, with some new molecules likely to be predicted well and others poorly. Further, the model will be better informed by learning with certain new molecules but not others. We must develop solutions for estimating confidence of predictions for new molecules as well as for identifying particular molecules that will be highly informative. Third, the operational application of these methods involves model building, guided chemical synthesis, and iterative refinement of models. Convincing validation will require application on temporal series of molecules synthesized for multiple targets of pharmaceutical interest. The proposed work will develop novel methods to address these challenges and will establish extensive validation on multiple pharmaceutically relevant temporal series of small molecules that were the subject of real-world lead-optimization exercises.         PUBLIC HEALTH RELEVANCE: The dominant mode of therapeutic discovery involves the design ""me-too"" drugs that are very similar in structure and effect to existing drugs. In order to address the unmet medical needs of an aging population, novel therapeutics must be developed, and this will require much more creativity in the design process. The proposed research will develop a predictive computational framework to aid in active design of structurally novel drug molecules during the drug discovery lead optimization process.            ",Binding-Site Modeling with Multiple-Instance Machine-Learning,8598096,R01GM101689,"['Address', 'Affinity', 'Binding', 'Binding Sites', 'Biological Assay', 'Chemicals', 'Collaborations', 'Computer Assisted', 'Creativeness', 'Data', 'Data Set', 'Docking', 'Drug Design', 'Enzymes', 'Exercise', 'Foundations', 'Knowledge', 'Lead', 'Learning', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Measures', 'Medical', 'Membrane', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Paper', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Physics', 'Population', 'Procedures', 'Process', 'Protein Binding', 'Proteins', 'Publishing', 'Quantitative Structure-Activity Relationship', 'Research', 'Series', 'Site', 'Solutions', 'Structure', 'System', 'Testing', 'Therapeutic', 'Training', 'Validation', 'Work', 'aging population', 'base', 'blind', 'chemical synthesis', 'computer framework', 'design', 'design and construction', 'drug discovery', 'falls', 'interest', 'novel', 'novel therapeutics', 'predictive modeling', 'process optimization', 'prospective', 'public health relevance', 'receptor binding', 'small molecule', 'virtual']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2014,299250,-0.005442746851805772
"Computational approaches to protein identification and quantification using MS/MS (Not modified) Liquid chromatography (LC) coupled with tandem mass spectrometry (MS/MS) is a widely used platform for high-throughput identification and quantification of proteins in biological samples. In addition to experimental steps in the pipeline, computational and statistical procedures play important roles in determining the content of the mixture. However, even with the best analytical platforms and modern software, only a small fraction of spectra are typically identified, thus directly impacting the quality of the biological sample analysis. If high- throughput proteomics techniques are to become routinely used in biomedical applications on the population scale, it is critical to address analytical and computational factors that contribute to the inadequate identification coverage and sensitivity. Over the past several years, we and others have spent a significant amount of research activity to understand and model analytical platforms and subsequently improve computational methods for the analyses of complex biological mixtures. While our original grant application has resulted in methods and programs already accepted by the community, there is a need and significant room for further key contributions. We see many of these contributions being related to the analyses of dynamic changes in cells and tissues, and involving changes in protein quantities, protein post-translational modifications (PTMs) and transient protein-protein interactions. Mass spectrometry-based proteomics provides an excellent platform to address each of these challenges. Thus, we plan to continue to develop novel methods for label-free quantification and remain close to our core strengths, but also strongly focus on PTMs and protein-protein interactions as new directions of this renewal application. This application includes a considerably closer collaboration between computational (Dr. Radivojac, Dr. Tang) and experimental (Dr. Arnold, Dr. Clemmer, Dr. Reilly) scientists than did our original application. The investigators bring complementary expertise and experience in a range of disciplines involving protein bioinformatics, algorithms, machine learning, as well as analytical chemistry and instrumentation. Overall, we believe that this proposal will result in significant advances for mass spectrometry-based proteomics. (Not modified) We propose to develop novel and theoretically sound methodology for several important yet challenging problems in mass spectrometry-based proteomics, including the identification of peptides containing post- translational modifications and cross-linked peptides, and the absolute quantification of proteins in complex samples.",Computational approaches to protein identification and quantification using MS/MS,8728956,R01GM103725,"['Address', 'Algorithmic Software', 'Algorithms', 'Analytical Chemistry', 'Applications Grants', 'Area', 'Bioinformatics', 'Biological', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Coupled', 'Custom', 'Data', 'Data Set', 'Development', 'Discipline', 'Funding', 'Gases', 'Goals', 'Indiana', 'Ions', 'Label', 'Learning', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Occupations', 'Peptide Library', 'Peptides', 'Phase', 'Play', 'Population', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Relative (related person)', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Site', 'Spectrometry', 'Staging', 'Synthesis Chemistry', 'Synthetic Peptide Libraries', 'Techniques', 'Tissues', 'Training', 'Universities', 'Work', 'base', 'crosslink', 'experience', 'improved', 'instrument', 'instrumentation', 'ion mobility', 'model development', 'novel', 'programs', 'protein protein interaction', 'research study', 'response', 'sound', 'tandem mass spectrometry']",NIGMS,INDIANA UNIVERSITY BLOOMINGTON,R01,2014,411329,0.01281984885258114
"Self Correcting Nanoflow LC-MS for Clinical Proteomics     DESCRIPTION (provided by applicant): The overall goal of this proposal is to improve the quality, reliability, and interlaboratory comparability of peptide mass spectrometry data. Mass spectrometry (MS) has become a fundamental technology for the identification and quantitative analysis of proteins, protein interactions, and protein post-translational modifications. These analyses are an important part of solving biological problems that involve changes in protein abundance in response to disease, drug treatment, and genetic or environmental perturbations. Unfortunately, the application of protein mass spectrometry measurements in the clinical laboratory has been limited. Unlike most clinical assays by mass spectrometry, which use microflow liquid chromatography, peptide measurements are commonly performed using a nanoflow liquid chromatograph interface to the mass spectrometer (nanoflow LC-MS). Despite their analytical power, these nanoflow LC-MS methods have been difficult to apply robustly in quantitative assays involving large numbers of samples from a challenging sample matrix. The successful completion of our project will result in a peptide analysis platform that can automatically assess problems with the nanoflow LC-MS system and correct the problem during an analytical run and will significantly improve the robustness and reproducibility of peptide mass spectrometry measurements.         PUBLIC HEALTH RELEVANCE: Mass spectrometry has been a fundamental technology for the analysis of proteins in health and disease. However, despite the analytical power of conventional mass spectrometry methods, they have not been well-suited for the comparative analysis of very large numbers of samples acquired under a large number of conditions. Thus, the continued development of novel mass spectrometry technology is essential to understanding complex biological systems so that can be characterized that have a change in abundance in response to disease, drug treatment, and genetic or environmental perturbation.",Self Correcting Nanoflow LC-MS for Clinical Proteomics,8727640,R01GM107142,"['Biological', 'Biological Assay', 'Clinical', 'Communities', 'Computer software', 'Couples', 'Data', 'Data Collection', 'Data Quality', 'Development', 'Disease', 'Environment', 'Event', 'Failure', 'Genetic', 'Goals', 'Health', 'Information Systems', 'Laboratories', 'Liquid Chromatography', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Medicine', 'Methods', 'Metric', 'Outcome', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Post-Translational Protein Processing', 'Process', 'Protein Analysis', 'Proteins', 'Proteomics', 'Protocols documentation', 'Quality Control', 'Reproducibility', 'Research', 'Robotics', 'Running', 'Sampling', 'Source', 'System', 'Technology', 'Time', 'Training', 'Universities', 'Washington', 'base', 'comparative', 'complex biological systems', 'experience', 'improved', 'instrument', 'liquid chromatography mass spectrometry', 'mass spectrometer', 'novel', 'open source', 'operation', 'protein protein interaction', 'public health relevance', 'response', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2014,371177,0.06843062092225913
"A New Model of Peptide Fragmentation for Improved Protein Identification and Targ    DESCRIPTION (provided by applicant): Mass spectrometry (MS) based proteomics has emerged as a key technology in the search for disease- associated biomarkers. State-of-the-art instruments can identify thousands of proteins in a single sample by 'shotgun' proteomic analysis, where protein mixtures are proteolyzed into peptides, separated by one or more chromatographic steps, and analyzed by peptide dissociation using tandem mass spectrometry (MS/MS). The goal of this approach is to create new technologies for the accurate detection of proteins within complex samples. Achieving this target is currently limited by the major problem of inferring the peptide sequence from MS/MS spectra by sequence database searching: spectra are compared to ""model spectra"" generated from database sequences. Current algorithms suffer from poor accuracy and discrimination due to the use of simple models for predicting spectra, which ignores the rich information contained in the relative intensities of peaks in a typical MS/MS. Consequently, there is a vital need for more accurate models to predict MS/MS spectrum intensities from peptide sequences. In this proposal, we will develop a new and innovative kinetic model for predicting peptide fragmentation MS/MS spectra, and use the model to develop MS/MS identification algorithms with high discrimatory power. Spectra simulated by the kinetic model will then be used to design selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies. This will solve a bottleneck for widespread adoption of SRM methods for biomarker discovery, which is currently hindered by the slow process of identifying and optimizing SRM transitions for the assays. The following specific aims are (1) Develop an optimized kinetic model of gas-phase peptide fragmentation which predicts MS/MS spectra for any peptide sequence. Model parameters will be fit using the Levenberg- Marquardt algorithm, a robust method for non-linear least squares. (2) Extend the model to predict MS/MS fragmentation of phosphopeptides. The approaches developed in this aim can be extended to other disease- relevant post-translational modifications which profoundly alter peptide fragmentation and interfere with MS/MS identification. (3) Develop a route to successful implementation of spectrum-to-spectrum matching algorithms, an entirely new approach for large scale identification of proteins, in which MS/MS are searched directly against libraries of predicted spectra, simulated using our prototype kinetic model. We use predicted spectra to bypass the need for sequence databases, and spectrum-to-sequence strategies altogether. (4) Develop an algorithm for de novo prediction of selected reaction monitoring (SRM) assays for highly multiplexed quantitative measurement of proteins in complex mixtures.           PROJECT NARRATIVE Mass spectrometry-based proteomics has emerged as a key technology in the search for useful protein biomarkers, and holds many promises for early detection of disease, prediction of drug efficacy and resistance, and targeted molecular therapies. The field is currently limited by the major problem of inferring the peptide sequence from a fragmentation mass spectrum - until this problem is solved, many potential applications of proteomics to human health will not be achieved. We will develop a kinetic model to predict peptide fragmentation spectra for any peptide sequence; a method that will enable comprehensive protein profiling in human biofluids, and the rapid design of selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies.         ",A New Model of Peptide Fragmentation for Improved Protein Identification and Targ,8701249,R01CA155453,"['Address', 'Adoption', 'Algorithms', 'Biological Assay', 'Biological Markers', 'Bypass', 'Chemicals', 'Complex', 'Complex Mixtures', 'Databases', 'Detection', 'Discrimination', 'Disease', 'Dissociation', 'Drug resistance', 'Early Diagnosis', 'Gases', 'Goals', 'Health', 'Human', 'Ions', 'Kinetics', 'Least-Squares Analysis', 'Libraries', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular Target', 'Monitor', 'Peptides', 'Phase', 'Phosphopeptides', 'Plasma', 'Post-Translational Protein Processing', 'Process', 'Protein Analysis', 'Protein Sequence Analysis', 'Proteins', 'Proteomics', 'Reaction', 'Relative (related person)', 'Route', 'Sampling', 'Scanning', 'Screening for cancer', 'Sensitivity and Specificity', 'Set protein', 'Shotguns', 'Simulate', 'Statistical Models', 'Techniques', 'Technology', 'Work', 'base', 'chemotherapy', 'design', 'drug efficacy', 'improved', 'innovation', 'instrument', 'instrumentation', 'interest', 'new technology', 'novel strategies', 'prevent', 'protein aminoacid sequence', 'protein profiling', 'prototype', 'tandem mass spectrometry', 'tool']",NCI,UNIVERSITY OF COLORADO,R01,2014,304932,0.009380821569455225
"Biomarker discovery for mitochondrial toxicants using metabolic footprinting  Abstract Many environmental stressors have deleterious effects on mitochondrial functions, by a variety of mechanisms, and with timelines of different lengths. Mitochondrial dysfunction has multiple clinical presentations, often delayed from the onset of organelle damage. At present, biomarkers that report on mitochondrial function, to enable population studies of environmental exposures and their consequences, are lacking. We propose to identify candidate biomarkers using a metabolomics approach, in greater depth than has previously been applied to toxicologic investigations.  Metabolomic analysis provides a window on cellular and organismal functions, closer to the actual physiology than genomic or transcriptomic arrays. Using multiple platforms for separation and mass spectrometric resolution of complex mixtures, a comprehensive set of metabolites including organic acids, amino acids, steroids, complex lipids, energy charge and mitochondrial transport metabolites can be targeted. We will use this technology to develop biomarkers of mitochondrial dysfunction that will fill an important gap in current studies of environmental toxicology.  We will focus our studies on a polybrominated diphenyl ether, BDE-47, that is emerging as one of the major persistent organic pollutants in the U.S. Published data from our collaborator, Dr. Kavanagh, and our preliminary data indicate that BDE-47 impairs mitochondrial function in cell lines in vitro. Metabolites in extracellular media (metabolic footprinting) will be analyzed with primary mouse hepatocytes, one of the main targets of BDE-47 toxicity, as a function of dose and time of exposure. We will also test the hypothesis that fatty acid overload will uncover subtle mitochondrial defects by performing metabolomic analysis in isolated mitochondria. These studies will provide metabolic signatures of BDE-47 toxicity that will next be extended to in vivo studies of plasma and urine from BDE-47 treated mice. The possibility that lymphocytes may be a surrogate tissue for the mitochondrial toxicities of BDE-47 will be examined using the fatty acid overload assay.  The effects of genetic background and environment on BDE-47 toxicity are poorly understood. We will test two potential modifiers: 1) genetically engineered mice with low and high glutathione levels, and 2) fatty liver due to vitamin A deficiency. These experiments will provide novel information on potential high risk populations for BDE-47 exposure. A key question for these studies will be whether candidate biomarkers scale with toxicity (in addition to exposure dose).  In addition to discovering metabolic signatures of BDE-47 toxicity, we will examine two recently described mitochondrial responses to stress by metabolic footprinting: 1) mitochondrial proteotoxicity due to aggregation of unfolded/unassembled proteins, and 2) alternative fumarate respiration in response to hypoxia and distal block of the electron transport chain. By selecting defined mitochondrial responses, one adverse and one adaptive, we begin to categorize mitochondrial dysfunction and look for signatures that associate with specific types. In the case of fumarate respiration, a signature of high levels of succinate in secreted metabolites is already known.  This work is a close collaboration with Oliver Fiehn, expert in metabolomics screening and data analysis, and Terry Kavanagh, an expert in oxidative stress and mitochondrial toxicology.  Public Health Relevance/Project Narrative Many environmental toxins inhibit mitochondria, the powerhouses of the cell, as a mechanism of toxicity. Current research in this area is hampered by the lack of convenient tests to measure early mitochondrial damage, which would promote appropriate preventive/treatment efforts for individuals and at risk populations. The goal of this research is to identify chemical changes in blood or urine that are indicators of mitochondrial damage in the body, using mass spectrometry tools to survey thousands of compounds.",Biomarker discovery for mitochondrial toxicants using metabolic footprinting,8691819,R01ES020819,"['Affect', 'Amino Acids', 'Area', 'Biochemical', 'Biochemistry', 'Bioenergetics', 'Biological Assay', 'Biological Markers', 'Biology', 'Blood', 'Body Fluids', 'Cell Line', 'Cell physiology', 'Cells', 'Characteristics', 'Charge', 'Chemicals', 'Classification', 'Clinical', 'Collaborations', 'Complex', 'Complex Mixtures', 'Data', 'Data Analyses', 'Defect', 'Diet', 'Disease', 'Distal', 'Dose', 'Electron Transport', 'Environment', 'Environmental Exposure', 'Exhibits', 'Exposure to', 'Fatty Acids', 'Fatty Liver', 'Fumarates', 'Functional disorder', 'Generations', 'Genetic', 'Genetically Engineered Mouse', 'Genomics', 'Glutathione', 'Goals', 'Harvest', 'Hepatocyte', 'Histocompatibility Testing', 'Hypoxia', 'In Vitro', 'Individual', 'Investigation', 'Length', 'Lipids', 'Liquid substance', 'Lymphocyte', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Membrane Potentials', 'Metabolic', 'Metabolic stress', 'Metabolic syndrome', 'Methods', 'Mitochondria', 'Mitochondrial Diseases', 'Modeling', 'Mus', 'Organelles', 'Oxidative Stress', 'Physiology', 'Plasma', 'Population', 'Population Study', 'Populations at Risk', 'Pre-Clinical Model', 'Preventive', 'Proteins', 'Publishing', 'Reactive Oxygen Species', 'Reporting', 'Research', 'Resolution', 'Respiration', 'Staging', 'Steroids', 'Stress', 'Succinates', 'Surveys', 'Technology', 'Testing', 'Time', 'TimeLine', 'Tissues', 'Toxic Environmental Substances', 'Toxic effect', 'Toxicology', 'Urine', 'Vitamin A', 'Vitamin A Deficiency', 'Work', 'abstracting', 'base', 'environmental stressor', 'environmental toxicology', 'extracellular', 'high risk', 'human population study', 'in vivo', 'insight', 'metabolomics', 'mitochondrial dysfunction', 'nonalcoholic steatohepatitis', 'novel', 'nucleotide metabolism', 'organic acid', 'phenyl ether', 'pollutant', 'protein misfolding', 'public health relevance', 'research study', 'response', 'screening', 'statistics', 'tool', 'toxicant', 'transcriptomics']",NIEHS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2014,373821,0.03259973834025955
"Sequential Ion/Ion Reactions for Large Peptide and Whole Protein Characterization    DESCRIPTION (provided by applicant): The ability to sequence and identify proteins, map their sites of post-translational modification (PTM), and assess their abundances is central to modern biology. Mass spectrometry (MS) is the gold standard technology by which this information is obtained. Serving as the centerpiece, tandem MS (MS/MS) is a principal component. Electron transfer dissociation (ETD), a relatively new MS/MS dissociation method, has generated significant excitement for its compatibility with previously intractable peptide/protein classes. Five years ago m/z range, mass accuracy, and mass resolution considerably restricted the application of ETD. Our initial RO1 proposal successfully eliminated this limitation by coupling ETD to the orbitrap mass analyzer. The resulting system routinely analyzes peptides and proteins, with and without labile PTMs, with a high-fidelity readout (orbitrap). As a result, it realized many of our anticipated outcomes and created numerous unforeseen opportunities. Just in the PI's laboratory, the latter set includes data-dependent selection of dissociation method (i.e., Decision Tree), discovery of the unique chemical compositions of z-type ions, internal spectral calibration using ETD reagents, activated-ion ETD, and several biological applications. By 2008, the commercial implementation of our technology began to reach researchers across the globe-nearly 300 to date-enabling access to numerous previously intractable problems such as mapping Arg methylation sites, increasing coverage of low molecular weight proteins, providing unambiguous PTM site assignment, and screening glycopeptide libraries, among many others. We detail two new aims that build upon the high impact results of our initial funding period. Aim 1, how do we broaden the utility of ETD for biomedical research? Aim 2, what is the role of gas- phase purification in quantitative proteomics? We continue with a balance of instrumentation, method, informatic, and applied projects constructed upon the widely used ETD-orbitrap platform we described 3.5 years ago.        Cutting edge MS based technology, Electron transfer dissociation (ETD), continues to be developed. This new MS/MS dissociation method enables previously intractable peptide/protein classes to be sequenced and identified, have their sites of post-translational modification (PTM) mapped, and assess their abundances. This is central to modern biology and has relevance for research ranging from human disease to evolution.          ",Sequential Ion/Ion Reactions for Large Peptide and Whole Protein Characterization,8625765,R01GM080148,"['Algorithms', 'Award', 'Beds', 'Biological', 'Biology', 'Biomedical Research', 'Calibration', 'Cells', 'Chemicals', 'Chemistry', 'Communities', 'Computer software', 'Coupled', 'Coupling', 'Data', 'Decision Trees', 'Development', 'Dissociation', 'Electron Transport', 'Equilibrium', 'Evolution', 'Fostering', 'Funding', 'Gases', 'Glycopeptides', 'Gold', 'Housing', 'Informatics', 'Ions', 'Knowledge', 'Laboratories', 'Libraries', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Methylation', 'Molecular Weight', 'Outcome', 'Peptides', 'Phase', 'Phosphorylation', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Protein Sequence Analysis', 'Proteins', 'Proteome', 'Proteomics', 'Protons', 'Reaction', 'Reaction Time', 'Reagent', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Shotgun Sequencing', 'Site', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'United States National Institutes of Health', 'Yeasts', 'acute stress', 'base', 'biological adaptation to stress', 'comparative', 'human disease', 'human tissue', 'improved', 'instrumentation', 'mass analyzer', 'model development', 'prevent', 'response', 'screening', 'tandem mass spectrometry', 'tool']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2014,337302,0.02329617877379272
"Machine learning analysis of tandem mass spectra    DESCRIPTION (provided by applicant): Proteins are the primary functional molecules in living cells, and tandem mass spectrometry provides the most efficient means of studying proteins in a high-throughput fashion. The proposal aims to use state-of-the-art methods from the fields of machine learning, statistics and natural language processing to improve our ability to make sense of large tandem mass spectrometry data sets.  The core of the proposal is a type of probabilistic model, known as a dynamic Bayesian network that allows us to reason efficiently and accurately about complex sequential data sets. This modeling framework leverages a large body of related work from the fields of natural language processing and speech recognition. Much of this prior work has not yet been exploited by computational biologists, so the proposal represents a valuable cross-fertilization across disciplines.  More specifically, this project employs a collection of cooperating dynamic Bayesian networks to model jointly an entire mass spectrometry experiment. Relative to most existing methods for analyzing mass spectrometry data, which tend to divide the analysis of an experiment into a series of small independent subtasks, the proposed unified model jointly, considers all of the available data. This approach can thus exploit valuable dependencies among spectra and along various dimensions of the data. Dynamic Bayesian networks also provide a rigorous framework for performing inference from a combination of observed data and qualitative expert knowledge.  The project is divided into five aims, each of which concerns a particular type of mass spectrometry experiment. These experiments involve (1) identifying all of the proteins in a given complex biological sample using a standard mass spectrometry protocol; (2) identifying proteins using a modified protocol in which the mass spectrometer samples the data in a systematic, rather than data-dependent, fashion, with the goal of identifying lower abundance proteins; (3) quantifying the relative abundance of proteins within or between biological samples; (4) identifying post-translational modified proteins or proteins that contain sequence variation; and (5) performing targeted quantification of a specified set of proteins, such as proteins in a pathway of interest or protein biomarkers.  The methods described in this proposal have the potential to dramatically improve our ability to draw conclusions from and formulate hypotheses on the basis of high-throughput shotgun proteomics experiments. Experiments like the ones described above can, for example, identify proteins involved in fundamental disease processes, identify previously unknown protein isoforms, or quantify the re- sponses of proteins to environmental stressors or disease states.        The applications of mass spectrometry and its promises for improvements of human health are nu- merous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and specific diagnostic and prognostic screens. How- ever, making optimal use of mass spectrometry data requires sophisticated computational methods. This project will develop and apply novel statistical and machine learning methods for interpreting mass spectra.         ",Machine learning analysis of tandem mass spectra,8470188,R01GM096306,"['Amino Acid Sequence', 'Area', 'Biological', 'Biological Markers', 'C-Peptide', 'Cells', 'Clinical', 'Collection', 'Complex', 'Complex Mixtures', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Dependency', 'Diagnostic', 'Dimensions', 'Discipline', 'Disease', 'Fertilization', 'Goals', 'Graph', 'Health', 'Human', 'Ions', 'Knowledge', 'Life', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Natural Language Processing', 'Pathway interactions', 'Peptide Sequence Determination', 'Peptides', 'Phase', 'Post-Translational Protein Processing', 'Probability', 'Process', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Protocols documentation', 'Reaction', 'Relative (related person)', 'Reproducibility', 'Research Personnel', 'Sampling', 'Scanning', 'Series', 'Set protein', 'Shotguns', 'Specific qualifier value', 'Statistical Models', 'Time', 'Variant', 'Work', 'base', 'computer based statistical methods', 'computerized tools', 'design', 'disease phenotype', 'environmental stressor', 'improved', 'interest', 'liquid chromatography mass spectrometry', 'mass spectrometer', 'novel', 'prognostic', 'research study', 'response', 'speech recognition', 'statistics', 'tandem mass spectrometry', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2013,602213,0.0020540437210390004
"Binding-Site Modeling with Multiple-Instance Machine-Learning     DESCRIPTION (provided by applicant): This proposal is entitled ""Binding-Site Modeling with Multiple-Instance Machine-Learning."" One of the most challenging and longest studied problems in computer-aided drug design has been affinity prediction of small molecule ligands for their cognate protein targets. Despite decades of work, quantitative structure-activity re- lationship prediction (QSAR) approaches still suffer from poor accuracy, especially when predicting outside of closely related series of molecules. Even with high-quality structures of target proteins, approaches grounded in physics are also far from robust and accurate enough for reliable use in drug lead optimization. This proposal will build upon a foundation in multiple-instance machine learning applied to computer-aided drug design problems and develop a robust, accurate, and practically applicable affinity prediction methodology. The methodology requires only ligand structures and associated activity data for training, and it induces a virtual protein binding site composed of molecular fragments. The virtual binding pocket (or ""pocketmol"") is used in conjunction with a scoring function developed originally for molecular docking. The pocketmol configuration is chosen such that the optimal conformation and alignment of a ligand (based on the docking scoring function), yields scores for training ligands that are close to the known experimental values. Feasibility has been demon- strated in papers involving both membrane-bound receptors and enzymes.  However, multiple challenges remain and are the subject of the proposed research. There are three key issues. First, there exist many pocketmols that satisfy the requirements of fitting the training data, so general solutions must be developed to address the inductive bias of the learning procedure as well as model selection after the procedure. Second, since any particular model is the product of a learning process, it will have some domain of applicability, with some new molecules likely to be predicted well and others poorly. Further, the model will be better informed by learning with certain new molecules but not others. We must develop solutions for estimating confidence of predictions for new molecules as well as for identifying particular molecules that will be highly informative. Third, the operational application of these methods involves model building, guided chemical synthesis, and iterative refinement of models. Convincing validation will require application on temporal series of molecules synthesized for multiple targets of pharmaceutical interest. The proposed work will develop novel methods to address these challenges and will establish extensive validation on multiple pharmaceutically relevant temporal series of small molecules that were the subject of real-world lead-optimization exercises.         PUBLIC HEALTH RELEVANCE: The dominant mode of therapeutic discovery involves the design ""me-too"" drugs that are very similar in structure and effect to existing drugs. In order to address the unmet medical needs of an aging population, novel therapeutics must be developed, and this will require much more creativity in the design process. The proposed research will develop a predictive computational framework to aid in active design of structurally novel drug molecules during the drug discovery lead optimization process.            ",Binding-Site Modeling with Multiple-Instance Machine-Learning,8436505,R01GM101689,"['Address', 'Affinity', 'Binding', 'Binding Sites', 'Biological Assay', 'Chemicals', 'Collaborations', 'Computer Assisted', 'Creativeness', 'Data', 'Data Set', 'Docking', 'Drug Design', 'Enzymes', 'Exercise', 'Foundations', 'Knowledge', 'Lead', 'Learning', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Measures', 'Medical', 'Membrane', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Paper', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Physics', 'Population', 'Procedures', 'Process', 'Protein Binding', 'Proteins', 'Publishing', 'Quantitative Structure-Activity Relationship', 'Research', 'Series', 'Site', 'Solutions', 'Structure', 'System', 'Testing', 'Therapeutic', 'Training', 'Validation', 'Work', 'aging population', 'base', 'blind', 'chemical synthesis', 'computer framework', 'design', 'design and construction', 'drug discovery', 'falls', 'interest', 'novel', 'novel therapeutics', 'predictive modeling', 'process optimization', 'prospective', 'public health relevance', 'receptor binding', 'small molecule', 'virtual']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2013,291402,-0.005442746851805772
"Computational approaches to protein identification and quantification using MS/MS (Not modified) Liquid chromatography (LC) coupled with tandem mass spectrometry (MS/MS) is a widely used platform for high-throughput identification and quantification of proteins in biological samples. In addition to experimental steps in the pipeline, computational and statistical procedures play important roles in determining the content of the mixture. However, even with the best analytical platforms and modern software, only a small fraction of spectra are typically identified, thus directly impacting the quality of the biological sample analysis. If high- throughput proteomics techniques are to become routinely used in biomedical applications on the population scale, it is critical to address analytical and computational factors that contribute to the inadequate identification coverage and sensitivity. Over the past several years, we and others have spent a significant amount of research activity to understand and model analytical platforms and subsequently improve computational methods for the analyses of complex biological mixtures. While our original grant application has resulted in methods and programs already accepted by the community, there is a need and significant room for further key contributions. We see many of these contributions being related to the analyses of dynamic changes in cells and tissues, and involving changes in protein quantities, protein post-translational modifications (PTMs) and transient protein-protein interactions. Mass spectrometry-based proteomics provides an excellent platform to address each of these challenges. Thus, we plan to continue to develop novel methods for label-free quantification and remain close to our core strengths, but also strongly focus on PTMs and protein-protein interactions as new directions of this renewal application. This application includes a considerably closer collaboration between computational (Dr. Radivojac, Dr. Tang) and experimental (Dr. Arnold, Dr. Clemmer, Dr. Reilly) scientists than did our original application. The investigators bring complementary expertise and experience in a range of disciplines involving protein bioinformatics, algorithms, machine learning, as well as analytical chemistry and instrumentation. Overall, we believe that this proposal will result in significant advances for mass spectrometry-based proteomics. (Not modified) We propose to develop novel and theoretically sound methodology for several important yet challenging problems in mass spectrometry-based proteomics, including the identification of peptides containing post- translational modifications and cross-linked peptides, and the absolute quantification of proteins in complex samples.",Computational approaches to protein identification and quantification using MS/MS,8549841,R01GM103725,"['Address', 'Algorithms', 'Analytical Chemistry', 'Applications Grants', 'Area', 'Bioinformatics', 'Biological', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Coupled', 'Custom', 'Data', 'Data Set', 'Development', 'Discipline', 'Funding', 'Gases', 'Goals', 'Indiana', 'Ions', 'Label', 'Learning', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Occupations', 'Peptide Library', 'Peptides', 'Phase', 'Play', 'Population', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Relative (related person)', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Site', 'Spectrometry', 'Staging', 'Synthesis Chemistry', 'Synthetic Peptide Libraries', 'Techniques', 'Tissues', 'Training', 'Universities', 'Work', 'base', 'crosslink', 'experience', 'improved', 'instrument', 'instrumentation', 'ion mobility', 'model development', 'novel', 'programs', 'protein protein interaction', 'research study', 'response', 'sound', 'tandem mass spectrometry']",NIGMS,INDIANA UNIVERSITY BLOOMINGTON,R01,2013,396933,0.01281984885258114
"Self Correcting Nanoflow LC-MS for Clinical Proteomics     DESCRIPTION (provided by applicant): The overall goal of this proposal is to improve the quality, reliability, and interlaboratory comparability of peptide mass spectrometry data. Mass spectrometry (MS) has become a fundamental technology for the identification and quantitative analysis of proteins, protein interactions, and protein post-translational modifications. These analyses are an important part of solving biological problems that involve changes in protein abundance in response to disease, drug treatment, and genetic or environmental perturbations. Unfortunately, the application of protein mass spectrometry measurements in the clinical laboratory has been limited. Unlike most clinical assays by mass spectrometry, which use microflow liquid chromatography, peptide measurements are commonly performed using a nanoflow liquid chromatograph interface to the mass spectrometer (nanoflow LC-MS). Despite their analytical power, these nanoflow LC-MS methods have been difficult to apply robustly in quantitative assays involving large numbers of samples from a challenging sample matrix. The successful completion of our project will result in a peptide analysis platform that can automatically assess problems with the nanoflow LC-MS system and correct the problem during an analytical run and will significantly improve the robustness and reproducibility of peptide mass spectrometry measurements.         PUBLIC HEALTH RELEVANCE: Mass spectrometry has been a fundamental technology for the analysis of proteins in health and disease. However, despite the analytical power of conventional mass spectrometry methods, they have not been well-suited for the comparative analysis of very large numbers of samples acquired under a large number of conditions. Thus, the continued development of novel mass spectrometry technology is essential to understanding complex biological systems so that can be characterized that have a change in abundance in response to disease, drug treatment, and genetic or environmental perturbation.            ",Self Correcting Nanoflow LC-MS for Clinical Proteomics,8558710,R01GM107142,"['Biological', 'Biological Assay', 'Clinical', 'Communities', 'Computer software', 'Couples', 'Data', 'Data Collection', 'Data Quality', 'Development', 'Disease', 'Environment', 'Event', 'Failure', 'Genetic', 'Goals', 'Health', 'Information Systems', 'Laboratories', 'Liquid Chromatography', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Medicine', 'Methods', 'Metric', 'Outcome', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Post-Translational Protein Processing', 'Process', 'Protein Analysis', 'Proteins', 'Proteomics', 'Protocols documentation', 'Quality Control', 'Reproducibility', 'Research', 'Robotics', 'Running', 'Sampling', 'Source', 'System', 'Technology', 'Time', 'Training', 'Universities', 'Washington', 'base', 'comparative', 'complex biological systems', 'experience', 'improved', 'instrument', 'liquid chromatography mass spectrometry', 'mass spectrometer', 'novel', 'open source', 'operation', 'protein protein interaction', 'public health relevance', 'response', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2013,355930,0.06843062092225913
"A New Model of Peptide Fragmentation for Improved Protein Identification and Targ    DESCRIPTION (provided by applicant): Mass spectrometry (MS) based proteomics has emerged as a key technology in the search for disease- associated biomarkers. State-of-the-art instruments can identify thousands of proteins in a single sample by 'shotgun' proteomic analysis, where protein mixtures are proteolyzed into peptides, separated by one or more chromatographic steps, and analyzed by peptide dissociation using tandem mass spectrometry (MS/MS). The goal of this approach is to create new technologies for the accurate detection of proteins within complex samples. Achieving this target is currently limited by the major problem of inferring the peptide sequence from MS/MS spectra by sequence database searching: spectra are compared to ""model spectra"" generated from database sequences. Current algorithms suffer from poor accuracy and discrimination due to the use of simple models for predicting spectra, which ignores the rich information contained in the relative intensities of peaks in a typical MS/MS. Consequently, there is a vital need for more accurate models to predict MS/MS spectrum intensities from peptide sequences. In this proposal, we will develop a new and innovative kinetic model for predicting peptide fragmentation MS/MS spectra, and use the model to develop MS/MS identification algorithms with high discrimatory power. Spectra simulated by the kinetic model will then be used to design selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies. This will solve a bottleneck for widespread adoption of SRM methods for biomarker discovery, which is currently hindered by the slow process of identifying and optimizing SRM transitions for the assays. The following specific aims are (1) Develop an optimized kinetic model of gas-phase peptide fragmentation which predicts MS/MS spectra for any peptide sequence. Model parameters will be fit using the Levenberg- Marquardt algorithm, a robust method for non-linear least squares. (2) Extend the model to predict MS/MS fragmentation of phosphopeptides. The approaches developed in this aim can be extended to other disease- relevant post-translational modifications which profoundly alter peptide fragmentation and interfere with MS/MS identification. (3) Develop a route to successful implementation of spectrum-to-spectrum matching algorithms, an entirely new approach for large scale identification of proteins, in which MS/MS are searched directly against libraries of predicted spectra, simulated using our prototype kinetic model. We use predicted spectra to bypass the need for sequence databases, and spectrum-to-sequence strategies altogether. (4) Develop an algorithm for de novo prediction of selected reaction monitoring (SRM) assays for highly multiplexed quantitative measurement of proteins in complex mixtures.           PROJECT NARRATIVE Mass spectrometry-based proteomics has emerged as a key technology in the search for useful protein biomarkers, and holds many promises for early detection of disease, prediction of drug efficacy and resistance, and targeted molecular therapies. The field is currently limited by the major problem of inferring the peptide sequence from a fragmentation mass spectrum - until this problem is solved, many potential applications of proteomics to human health will not be achieved. We will develop a kinetic model to predict peptide fragmentation spectra for any peptide sequence; a method that will enable comprehensive protein profiling in human biofluids, and the rapid design of selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies.         ",A New Model of Peptide Fragmentation for Improved Protein Identification and Targ,8504800,R01CA155453,"['Address', 'Adoption', 'Algorithms', 'Biological Assay', 'Biological Markers', 'Bypass', 'Chemicals', 'Complex', 'Complex Mixtures', 'Databases', 'Detection', 'Discrimination', 'Disease', 'Dissociation', 'Drug resistance', 'Early Diagnosis', 'Gases', 'Goals', 'Health', 'Human', 'Ions', 'Kinetics', 'Least-Squares Analysis', 'Libraries', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular Target', 'Monitor', 'Peptides', 'Phase', 'Phosphopeptides', 'Plasma', 'Post-Translational Protein Processing', 'Process', 'Protein Analysis', 'Protein Sequence Analysis', 'Proteins', 'Proteomics', 'Reaction', 'Relative (related person)', 'Route', 'Sampling', 'Scanning', 'Screening for cancer', 'Sensitivity and Specificity', 'Set protein', 'Shotguns', 'Simulate', 'Statistical Models', 'Techniques', 'Technology', 'Work', 'base', 'chemotherapy', 'design', 'drug efficacy', 'improved', 'innovation', 'instrument', 'instrumentation', 'interest', 'new technology', 'novel strategies', 'prevent', 'protein aminoacid sequence', 'protein profiling', 'prototype', 'tandem mass spectrometry', 'tool']",NCI,UNIVERSITY OF COLORADO,R01,2013,295501,0.009380821569455225
"Biomarker discovery for mitochondrial toxicants using metabolic footprinting  Abstract Many environmental stressors have deleterious effects on mitochondrial functions, by a variety of mechanisms, and with timelines of different lengths. Mitochondrial dysfunction has multiple clinical presentations, often delayed from the onset of organelle damage. At present, biomarkers that report on mitochondrial function, to enable population studies of environmental exposures and their consequences, are lacking. We propose to identify candidate biomarkers using a metabolomics approach, in greater depth than has previously been applied to toxicologic investigations.  Metabolomic analysis provides a window on cellular and organismal functions, closer to the actual physiology than genomic or transcriptomic arrays. Using multiple platforms for separation and mass spectrometric resolution of complex mixtures, a comprehensive set of metabolites including organic acids, amino acids, steroids, complex lipids, energy charge and mitochondrial transport metabolites can be targeted. We will use this technology to develop biomarkers of mitochondrial dysfunction that will fill an important gap in current studies of environmental toxicology.  We will focus our studies on a polybrominated diphenyl ether, BDE-47, that is emerging as one of the major persistent organic pollutants in the U.S. Published data from our collaborator, Dr. Kavanagh, and our preliminary data indicate that BDE-47 impairs mitochondrial function in cell lines in vitro. Metabolites in extracellular media (metabolic footprinting) will be analyzed with primary mouse hepatocytes, one of the main targets of BDE-47 toxicity, as a function of dose and time of exposure. We will also test the hypothesis that fatty acid overload will uncover subtle mitochondrial defects by performing metabolomic analysis in isolated mitochondria. These studies will provide metabolic signatures of BDE-47 toxicity that will next be extended to in vivo studies of plasma and urine from BDE-47 treated mice. The possibility that lymphocytes may be a surrogate tissue for the mitochondrial toxicities of BDE-47 will be examined using the fatty acid overload assay.  The effects of genetic background and environment on BDE-47 toxicity are poorly understood. We will test two potential modifiers: 1) genetically engineered mice with low and high glutathione levels, and 2) fatty liver due to vitamin A deficiency. These experiments will provide novel information on potential high risk populations for BDE-47 exposure. A key question for these studies will be whether candidate biomarkers scale with toxicity (in addition to exposure dose).  In addition to discovering metabolic signatures of BDE-47 toxicity, we will examine two recently described mitochondrial responses to stress by metabolic footprinting: 1) mitochondrial proteotoxicity due to aggregation of unfolded/unassembled proteins, and 2) alternative fumarate respiration in response to hypoxia and distal block of the electron transport chain. By selecting defined mitochondrial responses, one adverse and one adaptive, we begin to categorize mitochondrial dysfunction and look for signatures that associate with specific types. In the case of fumarate respiration, a signature of high levels of succinate in secreted metabolites is already known.  This work is a close collaboration with Oliver Fiehn, expert in metabolomics screening and data analysis, and Terry Kavanagh, an expert in oxidative stress and mitochondrial toxicology.  Public Health Relevance/Project Narrative Many environmental toxins inhibit mitochondria, the powerhouses of the cell, as a mechanism of toxicity. Current research in this area is hampered by the lack of convenient tests to measure early mitochondrial damage, which would promote appropriate preventive/treatment efforts for individuals and at risk populations. The goal of this research is to identify chemical changes in blood or urine that are indicators of mitochondrial damage in the body, using mass spectrometry tools to survey thousands of compounds.",Biomarker discovery for mitochondrial toxicants using metabolic footprinting,8484404,R01ES020819,"['Affect', 'Amino Acids', 'Area', 'Biochemical', 'Biochemistry', 'Bioenergetics', 'Biological Assay', 'Biological Markers', 'Biology', 'Blood', 'Body Fluids', 'Cell Line', 'Cell physiology', 'Cells', 'Characteristics', 'Charge', 'Chemicals', 'Classification', 'Clinical', 'Collaborations', 'Complex', 'Complex Mixtures', 'Data', 'Data Analyses', 'Defect', 'Diet', 'Disease', 'Distal', 'Dose', 'Electron Transport', 'Environment', 'Environmental Exposure', 'Exhibits', 'Exposure to', 'Fatty Acids', 'Fatty Liver', 'Fumarates', 'Functional disorder', 'Generations', 'Genetic', 'Genetically Engineered Mouse', 'Genomics', 'Glutathione', 'Goals', 'Harvest', 'Hepatocyte', 'Histocompatibility Testing', 'Hypoxia', 'In Vitro', 'Individual', 'Investigation', 'Length', 'Lipids', 'Liquid substance', 'Lymphocyte', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Membrane Potentials', 'Metabolic', 'Metabolic stress', 'Metabolic syndrome', 'Methods', 'Mitochondria', 'Mitochondrial Diseases', 'Modeling', 'Mus', 'Organelles', 'Oxidative Stress', 'Physiology', 'Plasma', 'Population', 'Population Study', 'Populations at Risk', 'Pre-Clinical Model', 'Preventive', 'Proteins', 'Publishing', 'Reactive Oxygen Species', 'Reporting', 'Research', 'Resolution', 'Respiration', 'Staging', 'Steroids', 'Stress', 'Succinates', 'Surveys', 'Technology', 'Testing', 'Time', 'TimeLine', 'Tissues', 'Toxic Environmental Substances', 'Toxic effect', 'Toxicology', 'Urine', 'Vitamin A', 'Vitamin A Deficiency', 'Work', 'abstracting', 'base', 'environmental stressor', 'environmental toxicology', 'extracellular', 'high risk', 'human population study', 'in vivo', 'insight', 'metabolomics', 'mitochondrial dysfunction', 'nonalcoholic steatohepatitis', 'novel', 'nucleotide metabolism', 'organic acid', 'phenyl ether', 'pollutant', 'protein misfolding', 'public health relevance', 'research study', 'response', 'screening', 'statistics', 'tool', 'toxicant', 'transcriptomics']",NIEHS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2013,370345,0.03259973834025955
"Sequential Ion/Ion Reactions for Large Peptide and Whole Protein Characterization    DESCRIPTION (provided by applicant): The ability to sequence and identify proteins, map their sites of post-translational modification (PTM), and assess their abundances is central to modern biology. Mass spectrometry (MS) is the gold standard technology by which this information is obtained. Serving as the centerpiece, tandem MS (MS/MS) is a principal component. Electron transfer dissociation (ETD), a relatively new MS/MS dissociation method, has generated significant excitement for its compatibility with previously intractable peptide/protein classes. Five years ago m/z range, mass accuracy, and mass resolution considerably restricted the application of ETD. Our initial RO1 proposal successfully eliminated this limitation by coupling ETD to the orbitrap mass analyzer. The resulting system routinely analyzes peptides and proteins, with and without labile PTMs, with a high-fidelity readout (orbitrap). As a result, it realized many of our anticipated outcomes and created numerous unforeseen opportunities. Just in the PI's laboratory, the latter set includes data-dependent selection of dissociation method (i.e., Decision Tree), discovery of the unique chemical compositions of z-type ions, internal spectral calibration using ETD reagents, activated-ion ETD, and several biological applications. By 2008, the commercial implementation of our technology began to reach researchers across the globe-nearly 300 to date-enabling access to numerous previously intractable problems such as mapping Arg methylation sites, increasing coverage of low molecular weight proteins, providing unambiguous PTM site assignment, and screening glycopeptide libraries, among many others. We detail two new aims that build upon the high impact results of our initial funding period. Aim 1, how do we broaden the utility of ETD for biomedical research? Aim 2, what is the role of gas- phase purification in quantitative proteomics? We continue with a balance of instrumentation, method, informatic, and applied projects constructed upon the widely used ETD-orbitrap platform we described 3.5 years ago.        Cutting edge MS based technology, Electron transfer dissociation (ETD), continues to be developed. This new MS/MS dissociation method enables previously intractable peptide/protein classes to be sequenced and identified, have their sites of post-translational modification (PTM) mapped, and assess their abundances. This is central to modern biology and has relevance for research ranging from human disease to evolution.          ",Sequential Ion/Ion Reactions for Large Peptide and Whole Protein Characterization,8469051,R01GM080148,"['Algorithms', 'Award', 'Beds', 'Biological', 'Biology', 'Biomedical Research', 'Calibration', 'Cells', 'Chemicals', 'Chemistry', 'Communities', 'Computer software', 'Coupled', 'Coupling', 'Data', 'Decision Trees', 'Development', 'Dissociation', 'Electron Transport', 'Equilibrium', 'Evolution', 'Fostering', 'Funding', 'Gases', 'Glycopeptides', 'Gold', 'Housing', 'Informatics', 'Ions', 'Knowledge', 'Laboratories', 'Libraries', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Methylation', 'Molecular Weight', 'Outcome', 'Peptides', 'Phase', 'Phosphorylation', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Protein Sequence Analysis', 'Proteins', 'Proteome', 'Proteomics', 'Protons', 'Reaction', 'Reaction Time', 'Reagent', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Shotgun Sequencing', 'Site', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'United States National Institutes of Health', 'Yeasts', 'acute stress', 'base', 'biological adaptation to stress', 'comparative', 'human disease', 'human tissue', 'improved', 'instrumentation', 'mass analyzer', 'model development', 'prevent', 'response', 'screening', 'tandem mass spectrometry', 'tool']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2013,325497,0.02329617877379272
"Machine learning analysis of tandem mass spectra    DESCRIPTION (provided by applicant): Proteins are the primary functional molecules in living cells, and tandem mass spectrometry provides the most efficient means of studying proteins in a high-throughput fashion. The proposal aims to use state-of-the-art methods from the fields of machine learning, statistics and natural language processing to improve our ability to make sense of large tandem mass spectrometry data sets.  The core of the proposal is a type of probabilistic model, known as a dynamic Bayesian network that allows us to reason efficiently and accurately about complex sequential data sets. This modeling framework leverages a large body of related work from the fields of natural language processing and speech recognition. Much of this prior work has not yet been exploited by computational biologists, so the proposal represents a valuable cross-fertilization across disciplines.  More specifically, this project employs a collection of cooperating dynamic Bayesian networks to model jointly an entire mass spectrometry experiment. Relative to most existing methods for analyzing mass spectrometry data, which tend to divide the analysis of an experiment into a series of small independent subtasks, the proposed unified model jointly, considers all of the available data. This approach can thus exploit valuable dependencies among spectra and along various dimensions of the data. Dynamic Bayesian networks also provide a rigorous framework for performing inference from a combination of observed data and qualitative expert knowledge.  The project is divided into five aims, each of which concerns a particular type of mass spectrometry experiment. These experiments involve (1) identifying all of the proteins in a given complex biological sample using a standard mass spectrometry protocol; (2) identifying proteins using a modified protocol in which the mass spectrometer samples the data in a systematic, rather than data-dependent, fashion, with the goal of identifying lower abundance proteins; (3) quantifying the relative abundance of proteins within or between biological samples; (4) identifying post-translational modified proteins or proteins that contain sequence variation; and (5) performing targeted quantification of a specified set of proteins, such as proteins in a pathway of interest or protein biomarkers.  The methods described in this proposal have the potential to dramatically improve our ability to draw conclusions from and formulate hypotheses on the basis of high-throughput shotgun proteomics experiments. Experiments like the ones described above can, for example, identify proteins involved in fundamental disease processes, identify previously unknown protein isoforms, or quantify the re- sponses of proteins to environmental stressors or disease states.        The applications of mass spectrometry and its promises for improvements of human health are nu- merous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and specific diagnostic and prognostic screens. How- ever, making optimal use of mass spectrometry data requires sophisticated computational methods. This project will develop and apply novel statistical and machine learning methods for interpreting mass spectra.         ",Machine learning analysis of tandem mass spectra,8288063,R01GM096306,"['Amino Acid Sequence', 'Area', 'Biological', 'Biological Markers', 'C-Peptide', 'Cells', 'Clinical', 'Collection', 'Complex', 'Complex Mixtures', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Dependency', 'Diagnostic', 'Dimensions', 'Discipline', 'Disease', 'Fertilization', 'Goals', 'Graph', 'Health', 'Human', 'Ions', 'Knowledge', 'Life', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Natural Language Processing', 'Pathway interactions', 'Peptide Sequence Determination', 'Peptides', 'Phase', 'Post-Translational Protein Processing', 'Probability', 'Process', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Protocols documentation', 'Reaction', 'Relative (related person)', 'Reproducibility', 'Research Personnel', 'Sampling', 'Scanning', 'Series', 'Set protein', 'Shotguns', 'Specific qualifier value', 'Statistical Models', 'Time', 'Variant', 'Work', 'base', 'computer based statistical methods', 'computerized tools', 'design', 'disease phenotype', 'environmental stressor', 'improved', 'interest', 'liquid chromatography mass spectrometry', 'mass spectrometer', 'novel', 'prognostic', 'research study', 'response', 'speech recognition', 'statistics', 'tandem mass spectrometry', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2012,621711,0.0020540437210390004
"Computational approaches to protein identification and quantification using MS/MS (Not modified) Liquid chromatography (LC) coupled with tandem mass spectrometry (MS/MS) is a widely used platform for high-throughput identification and quantification of proteins in biological samples. In addition to experimental steps in the pipeline, computational and statistical procedures play important roles in determining the content of the mixture. However, even with the best analytical platforms and modern software, only a small fraction of spectra are typically identified, thus directly impacting the quality of the biological sample analysis. If high- throughput proteomics techniques are to become routinely used in biomedical applications on the population scale, it is critical to address analytical and computational factors that contribute to the inadequate identification coverage and sensitivity. Over the past several years, we and others have spent a significant amount of research activity to understand and model analytical platforms and subsequently improve computational methods for the analyses of complex biological mixtures. While our original grant application has resulted in methods and programs already accepted by the community, there is a need and significant room for further key contributions. We see many of these contributions being related to the analyses of dynamic changes in cells and tissues, and involving changes in protein quantities, protein post-translational modifications (PTMs) and transient protein-protein interactions. Mass spectrometry-based proteomics provides an excellent platform to address each of these challenges. Thus, we plan to continue to develop novel methods for label-free quantification and remain close to our core strengths, but also strongly focus on PTMs and protein-protein interactions as new directions of this renewal application. This application includes a considerably closer collaboration between computational (Dr. Radivojac, Dr. Tang) and experimental (Dr. Arnold, Dr. Clemmer, Dr. Reilly) scientists than did our original application. The investigators bring complementary expertise and experience in a range of disciplines involving protein bioinformatics, algorithms, machine learning, as well as analytical chemistry and instrumentation. Overall, we believe that this proposal will result in significant advances for mass spectrometry-based proteomics. (Not modified) We propose to develop novel and theoretically sound methodology for several important yet challenging problems in mass spectrometry-based proteomics, including the identification of peptides containing post- translational modifications and cross-linked peptides, and the absolute quantification of proteins in complex samples.",Computational approaches to protein identification and quantification using MS/MS,8373375,R01GM103725,"['Address', 'Algorithms', 'Analytical Chemistry', 'Applications Grants', 'Area', 'Bioinformatics', 'Biological', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computational Technique', 'Computer software', 'Computing Methodologies', 'Coupled', 'Custom', 'Data', 'Data Set', 'Development', 'Discipline', 'Funding', 'Gases', 'Goals', 'Indiana', 'Ions', 'Label', 'Learning', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Occupations', 'Peptide Library', 'Peptides', 'Phase', 'Play', 'Population', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Relative (related person)', 'Reproducibility', 'Research Activity', 'Research Personnel', 'Role', 'Sampling', 'Scientist', 'Site', 'Spectrometry', 'Staging', 'Synthesis Chemistry', 'Synthetic Peptide Libraries', 'Techniques', 'Tissues', 'Training', 'Universities', 'Work', 'base', 'crosslink', 'experience', 'improved', 'instrument', 'instrumentation', 'ion mobility', 'model development', 'novel', 'programs', 'protein protein interaction', 'research study', 'response', 'sound', 'tandem mass spectrometry']",NIGMS,INDIANA UNIVERSITY BLOOMINGTON,R01,2012,448534,0.01281984885258114
"A New Model of Peptide Fragmentation for Improved Protein Identification and Targ    DESCRIPTION (provided by applicant): Mass spectrometry (MS) based proteomics has emerged as a key technology in the search for disease- associated biomarkers. State-of-the-art instruments can identify thousands of proteins in a single sample by 'shotgun' proteomic analysis, where protein mixtures are proteolyzed into peptides, separated by one or more chromatographic steps, and analyzed by peptide dissociation using tandem mass spectrometry (MS/MS). The goal of this approach is to create new technologies for the accurate detection of proteins within complex samples. Achieving this target is currently limited by the major problem of inferring the peptide sequence from MS/MS spectra by sequence database searching: spectra are compared to ""model spectra"" generated from database sequences. Current algorithms suffer from poor accuracy and discrimination due to the use of simple models for predicting spectra, which ignores the rich information contained in the relative intensities of peaks in a typical MS/MS. Consequently, there is a vital need for more accurate models to predict MS/MS spectrum intensities from peptide sequences. In this proposal, we will develop a new and innovative kinetic model for predicting peptide fragmentation MS/MS spectra, and use the model to develop MS/MS identification algorithms with high discrimatory power. Spectra simulated by the kinetic model will then be used to design selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies. This will solve a bottleneck for widespread adoption of SRM methods for biomarker discovery, which is currently hindered by the slow process of identifying and optimizing SRM transitions for the assays. The following specific aims are (1) Develop an optimized kinetic model of gas-phase peptide fragmentation which predicts MS/MS spectra for any peptide sequence. Model parameters will be fit using the Levenberg- Marquardt algorithm, a robust method for non-linear least squares. (2) Extend the model to predict MS/MS fragmentation of phosphopeptides. The approaches developed in this aim can be extended to other disease- relevant post-translational modifications which profoundly alter peptide fragmentation and interfere with MS/MS identification. (3) Develop a route to successful implementation of spectrum-to-spectrum matching algorithms, an entirely new approach for large scale identification of proteins, in which MS/MS are searched directly against libraries of predicted spectra, simulated using our prototype kinetic model. We use predicted spectra to bypass the need for sequence databases, and spectrum-to-sequence strategies altogether. (4) Develop an algorithm for de novo prediction of selected reaction monitoring (SRM) assays for highly multiplexed quantitative measurement of proteins in complex mixtures.           PROJECT NARRATIVE Mass spectrometry-based proteomics has emerged as a key technology in the search for useful protein biomarkers, and holds many promises for early detection of disease, prediction of drug efficacy and resistance, and targeted molecular therapies. The field is currently limited by the major problem of inferring the peptide sequence from a fragmentation mass spectrum - until this problem is solved, many potential applications of proteomics to human health will not be achieved. We will develop a kinetic model to predict peptide fragmentation spectra for any peptide sequence; a method that will enable comprehensive protein profiling in human biofluids, and the rapid design of selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies.         ",A New Model of Peptide Fragmentation for Improved Protein Identification and Targ,8323866,R01CA155453,"['Address', 'Adoption', 'Algorithms', 'Biological Assay', 'Biological Markers', 'Bypass', 'Chemicals', 'Complex', 'Complex Mixtures', 'Databases', 'Detection', 'Discrimination', 'Disease', 'Dissociation', 'Drug resistance', 'Early Diagnosis', 'Gases', 'Goals', 'Health', 'Human', 'Ions', 'Kinetics', 'Least-Squares Analysis', 'Libraries', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular Target', 'Monitor', 'Peptides', 'Phase', 'Phosphopeptides', 'Plasma', 'Post-Translational Protein Processing', 'Process', 'Protein Analysis', 'Protein Sequence Analysis', 'Proteins', 'Proteomics', 'Reaction', 'Relative (related person)', 'Route', 'Sampling', 'Scanning', 'Screening for cancer', 'Sensitivity and Specificity', 'Set protein', 'Shotguns', 'Simulate', 'Statistical Models', 'Techniques', 'Technology', 'Work', 'base', 'chemotherapy', 'design', 'drug efficacy', 'improved', 'innovation', 'instrument', 'instrumentation', 'interest', 'new technology', 'novel strategies', 'prevent', 'protein aminoacid sequence', 'protein profiling', 'prototype', 'tandem mass spectrometry', 'tool']",NCI,UNIVERSITY OF COLORADO,R01,2012,314363,0.009380821569455225
"Technology to Identify and Assay Chemical Genomic Probes    DESCRIPTION (provided by applicant): The primary objective of this proposal is to develop and deploy cutting edge technologies and chemical genomic tools and to understand the effects of small molecule inhibitors in vivo, and to characterize the model organism Saccharomyces cerevisiae on a systems level. Over the course of the past 3.5 years, as part of an NHGRI-funded project, we have applied three unique genome-wide screens to ~2,000 chemical inhibitors of growth. These data have led to several notable findings, including: 1) novel drug/target interactions, 2) a chemical phenotype for nearly all yeast genes, 3) a systems-level characterization of yeast, and 4) a better understanding of chemical structure-activity relationships as they manifest in vivo. These data have also guided the design of the next-generation chemical genomic assays proposed herein. Using our established bioinformatics and robotics infrastructure, we will design the next generation of assays to interrogate the genome's interaction with small molecules to unprecedented levels of scrutiny, while decreasing cost per chemical. PUBLIC HEALTH RELEVANCE: Small molecules, the central focus of this proposal, make up the majority of FDA approved drugs. Unfortunately, the pharmaceutical industry is currently experiencing sky-rocketing costs (~800 million dollars per new drug) in addition to steadily decreasing productivity. These struggles are attributed in part to unforeseen side-effects of promising drug candidates and by a lack of validated cellular ""targets"" to which a drug can bind and elicit a medicinal effect. The specific aims of this proposal address both of these problems.           Narrative Small molecules, the central focus of this proposal, make up the majority of FDA approved drugs. Unfortunately, the pharmaceutical industry is currently experiencing sky-rocketing costs (~800 million dollars per new drug) in addition to steadily decreasing productivity. These struggles are attributed in part to unforeseen side-effects of promising drug candidates and by a lack of validated cellular ""targets"" to which a drug can bind and elicit a medicinal effect. The specific aims of this proposal address both of these problems.",Technology to Identify and Assay Chemical Genomic Probes,8206671,R01HG003317,"['Address', 'Adverse effects', 'Animal Model', 'Binding', 'Binding Proteins', 'Bioinformatics', 'Biological Assay', 'Chemical Structure', 'Chemicals', 'Collection', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Drug Delivery Systems', 'Drug Industry', 'Drug Interactions', 'Ensure', 'Experimental Designs', 'FDA approved', 'Funding', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Growth Inhibitors', 'Health', 'Human', 'Individual', 'Knock-out', 'Letters', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Mammalian Cell', 'Molecular', 'National Human Genome Research Institute', 'Open Reading Frames', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Productivity', 'Proteins', 'Research Infrastructure', 'Resistance', 'Robotics', 'Role', 'Running', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Structure-Activity Relationship', 'Surface Plasmon Resonance', 'System', 'Technology', 'Toxic effect', 'Translating', 'Yeasts', 'base', 'cellular targeting', 'chemical genetics', 'cost', 'design', 'digital', 'dosage', 'drug candidate', 'experience', 'gain of function', 'genome wide association study', 'genome-wide', 'in vivo', 'inhibitor/antagonist', 'loss of function', 'mutant', 'next generation', 'novel', 'overexpression', 'particle', 'skills', 'small hairpin RNA', 'small molecule', 'technology development', 'tool']",NHGRI,STANFORD UNIVERSITY,R01,2012,1117030,0.006591080122278316
"Biomarker discovery for mitochondrial toxicants using metabolic footprinting  Abstract Many environmental stressors have deleterious effects on mitochondrial functions, by a variety of mechanisms, and with timelines of different lengths. Mitochondrial dysfunction has multiple clinical presentations, often delayed from the onset of organelle damage. At present, biomarkers that report on mitochondrial function, to enable population studies of environmental exposures and their consequences, are lacking. We propose to identify candidate biomarkers using a metabolomics approach, in greater depth than has previously been applied to toxicologic investigations.  Metabolomic analysis provides a window on cellular and organismal functions, closer to the actual physiology than genomic or transcriptomic arrays. Using multiple platforms for separation and mass spectrometric resolution of complex mixtures, a comprehensive set of metabolites including organic acids, amino acids, steroids, complex lipids, energy charge and mitochondrial transport metabolites can be targeted. We will use this technology to develop biomarkers of mitochondrial dysfunction that will fill an important gap in current studies of environmental toxicology.  We will focus our studies on a polybrominated diphenyl ether, BDE-47, that is emerging as one of the major persistent organic pollutants in the U.S. Published data from our collaborator, Dr. Kavanagh, and our preliminary data indicate that BDE-47 impairs mitochondrial function in cell lines in vitro. Metabolites in extracellular media (metabolic footprinting) will be analyzed with primary mouse hepatocytes, one of the main targets of BDE-47 toxicity, as a function of dose and time of exposure. We will also test the hypothesis that fatty acid overload will uncover subtle mitochondrial defects by performing metabolomic analysis in isolated mitochondria. These studies will provide metabolic signatures of BDE-47 toxicity that will next be extended to in vivo studies of plasma and urine from BDE-47 treated mice. The possibility that lymphocytes may be a surrogate tissue for the mitochondrial toxicities of BDE-47 will be examined using the fatty acid overload assay.  The effects of genetic background and environment on BDE-47 toxicity are poorly understood. We will test two potential modifiers: 1) genetically engineered mice with low and high glutathione levels, and 2) fatty liver due to vitamin A deficiency. These experiments will provide novel information on potential high risk populations for BDE-47 exposure. A key question for these studies will be whether candidate biomarkers scale with toxicity (in addition to exposure dose).  In addition to discovering metabolic signatures of BDE-47 toxicity, we will examine two recently described mitochondrial responses to stress by metabolic footprinting: 1) mitochondrial proteotoxicity due to aggregation of unfolded/unassembled proteins, and 2) alternative fumarate respiration in response to hypoxia and distal block of the electron transport chain. By selecting defined mitochondrial responses, one adverse and one adaptive, we begin to categorize mitochondrial dysfunction and look for signatures that associate with specific types. In the case of fumarate respiration, a signature of high levels of succinate in secreted metabolites is already known.  This work is a close collaboration with Oliver Fiehn, expert in metabolomics screening and data analysis, and Terry Kavanagh, an expert in oxidative stress and mitochondrial toxicology.  Public Health Relevance/Project Narrative Many environmental toxins inhibit mitochondria, the powerhouses of the cell, as a mechanism of toxicity. Current research in this area is hampered by the lack of convenient tests to measure early mitochondrial damage, which would promote appropriate preventive/treatment efforts for individuals and at risk populations. The goal of this research is to identify chemical changes in blood or urine that are indicators of mitochondrial damage in the body, using mass spectrometry tools to survey thousands of compounds.",Biomarker discovery for mitochondrial toxicants using metabolic footprinting,8336879,R01ES020819,"['Affect', 'Amino Acids', 'Area', 'Biochemical', 'Biochemistry', 'Bioenergetics', 'Biological Assay', 'Biological Markers', 'Biology', 'Blood', 'Body Fluids', 'Cell Line', 'Cell physiology', 'Cells', 'Characteristics', 'Charge', 'Chemicals', 'Classification', 'Clinical', 'Collaborations', 'Complex', 'Complex Mixtures', 'Data', 'Data Analyses', 'Defect', 'Diet', 'Disease', 'Distal', 'Dose', 'Electron Transport', 'Environment', 'Environmental Exposure', 'Exhibits', 'Exposure to', 'Fatty Acids', 'Fatty Liver', 'Fumarates', 'Functional disorder', 'Generations', 'Genetic', 'Genetically Engineered Mouse', 'Genomics', 'Glutathione', 'Goals', 'Harvest', 'Hepatocyte', 'Histocompatibility Testing', 'Hypoxia', 'In Vitro', 'Individual', 'Investigation', 'Length', 'Lipids', 'Liquid substance', 'Lymphocyte', 'Machine Learning', 'Mass Spectrum Analysis', 'Measures', 'Membrane Potentials', 'Metabolic', 'Metabolic stress', 'Metabolic syndrome', 'Methods', 'Mitochondria', 'Mitochondrial Diseases', 'Modeling', 'Mus', 'Organelles', 'Oxidative Stress', 'Physiology', 'Plasma', 'Population', 'Population Study', 'Populations at Risk', 'Pre-Clinical Model', 'Preventive', 'Proteins', 'Publishing', 'Reactive Oxygen Species', 'Reporting', 'Research', 'Resolution', 'Respiration', 'Screening procedure', 'Staging', 'Steroids', 'Stress', 'Succinates', 'Surveys', 'Technology', 'Testing', 'Time', 'TimeLine', 'Tissues', 'Toxic Environmental Substances', 'Toxic effect', 'Toxicology', 'Urine', 'Vitamin A', 'Vitamin A Deficiency', 'Work', 'abstracting', 'base', 'environmental stressor', 'environmental toxicology', 'extracellular', 'high risk', 'human population study', 'in vivo', 'insight', 'metabolomics', 'mitochondrial dysfunction', 'nonalcoholic steatohepatitis', 'novel', 'nucleotide metabolism', 'organic acid', 'phenyl ether', 'pollutant', 'protein misfolding', 'public health relevance', 'research study', 'response', 'statistics', 'tool', 'toxicant', 'transcriptomics']",NIEHS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2012,378224,0.03259973834025955
"Sequential Ion/Ion Reactions for Large Peptide and Whole Protein Characterization    DESCRIPTION (provided by applicant): The ability to sequence and identify proteins, map their sites of post-translational modification (PTM), and assess their abundances is central to modern biology. Mass spectrometry (MS) is the gold standard technology by which this information is obtained. Serving as the centerpiece, tandem MS (MS/MS) is a principal component. Electron transfer dissociation (ETD), a relatively new MS/MS dissociation method, has generated significant excitement for its compatibility with previously intractable peptide/protein classes. Five years ago m/z range, mass accuracy, and mass resolution considerably restricted the application of ETD. Our initial RO1 proposal successfully eliminated this limitation by coupling ETD to the orbitrap mass analyzer. The resulting system routinely analyzes peptides and proteins, with and without labile PTMs, with a high-fidelity readout (orbitrap). As a result, it realized many of our anticipated outcomes and created numerous unforeseen opportunities. Just in the PI's laboratory, the latter set includes data-dependent selection of dissociation method (i.e., Decision Tree), discovery of the unique chemical compositions of z-type ions, internal spectral calibration using ETD reagents, activated-ion ETD, and several biological applications. By 2008, the commercial implementation of our technology began to reach researchers across the globe-nearly 300 to date-enabling access to numerous previously intractable problems such as mapping Arg methylation sites, increasing coverage of low molecular weight proteins, providing unambiguous PTM site assignment, and screening glycopeptide libraries, among many others. We detail two new aims that build upon the high impact results of our initial funding period. Aim 1, how do we broaden the utility of ETD for biomedical research? Aim 2, what is the role of gas- phase purification in quantitative proteomics? We continue with a balance of instrumentation, method, informatic, and applied projects constructed upon the widely used ETD-orbitrap platform we described 3.5 years ago.      PUBLIC HEALTH RELEVANCE: Cutting edge MS based technology, Electron transfer dissociation (ETD), continues to be developed. This new MS/MS dissociation method enables previously intractable peptide/protein classes to be sequenced and identified, have their sites of post-translational modification (PTM) mapped, and assess their abundances. This is central to modern biology and has relevance for research ranging from human disease to evolution.            Cutting edge MS based technology, Electron transfer dissociation (ETD), continues to be developed. This new MS/MS dissociation method enables previously intractable peptide/protein classes to be sequenced and identified, have their sites of post-translational modification (PTM) mapped, and assess their abundances. This is central to modern biology and has relevance for research ranging from human disease to evolution.          ",Sequential Ion/Ion Reactions for Large Peptide and Whole Protein Characterization,8237677,R01GM080148,"['Algorithms', 'Award', 'Beds', 'Biological', 'Biology', 'Biomedical Research', 'Calibration', 'Cells', 'Chemicals', 'Chemistry', 'Communities', 'Computer software', 'Coupled', 'Coupling', 'Data', 'Decision Trees', 'Development', 'Dissociation', 'Electron Transport', 'Equilibrium', 'Evolution', 'Fostering', 'Funding', 'Gases', 'Glycopeptides', 'Gold', 'Housing', 'Informatics', 'Ions', 'Knowledge', 'Laboratories', 'Libraries', 'Maps', 'Mass Spectrum Analysis', 'Measures', 'Methods', 'Methylation', 'Molecular Weight', 'Outcome', 'Peptides', 'Phase', 'Phosphorylation', 'Post-Translational Modification Site', 'Post-Translational Protein Processing', 'Protein Sequence Analysis', 'Proteins', 'Proteome', 'Proteomics', 'Protons', 'Reaction', 'Reaction Time', 'Reagent', 'Research', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Screening procedure', 'Shotgun Sequencing', 'Site', 'Stress', 'System', 'Techniques', 'Technology', 'Testing', 'United States National Institutes of Health', 'Yeasts', 'acute stress', 'base', 'biological adaptation to stress', 'comparative', 'human disease', 'human tissue', 'improved', 'instrumentation', 'mass analyzer', 'model development', 'prevent', 'response', 'tandem mass spectrometry', 'tool']",NIGMS,UNIVERSITY OF WISCONSIN-MADISON,R01,2012,351494,0.020236913212990773
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator.  The ultimate goal of this SBIR project is to provide the DOD, DOE, and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. In Phase I, Seacoast successfully demonstrated the feasibility of using a microsensor array with a proprietary trap-and- purge preconcentrator to detect chlorinated solvents, specifically TCE, and TCA, at levels low enough to meet EPA mandated levels for drinking water. In Phase II Seacoast proposes to improve the selectivity and sensitivity of the system to better meet the needs identified by the Phase I consultant. The systems have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator traps the contaminants and releases them to a microsensor array. These sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical.  In Phase II Seacoast will specifically develop new materials to improve the sensor array selectivity, 1) by using impedance spectroscopy to study the mechanisms by which the polymer-based sensors sorb the target chemicals, 2) by implementing pattern recognition algorithms to identify chemicals for the sensor responses, and 3) by designing new preconcentrator materials that can bind these chemicals more strongly.  The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. Potential markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology.      PUBLIC HEALTH RELEVANCE: This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.           PROJECT NARRATIVE This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.",Low-Cost Electronic Nose for Groundwater Contaminants,8260510,R44ES016941,"['Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benchmarking', 'Benzene', 'Carcinogens', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Computer software', 'Cost Analysis', 'Cost Savings', 'Data', 'Data Collection', 'Detection', 'Development', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Equation', 'Equipment', 'Evaluation', 'Fingerprint', 'Fluorescence', 'Gases', 'Goals', 'Guidelines', 'Hazardous Waste', 'Industrial Health', 'Intervention', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Maps', 'Marketing', 'Measures', 'Metals', 'Methods', 'Monitor', 'National Institute of Environmental Health Sciences', 'Nose', 'Pattern Recognition', 'Pesticides', 'Phase', 'Plants', 'Poison', 'Pollution', 'Polymers', 'Process', 'Public Health', 'Recommendation', 'Research', 'Research Personnel', 'Risk', 'Route', 'Safety', 'Sampling', 'Science', 'Scientific Advances and Accomplishments', 'Site', 'Small Business Innovation Research Grant', 'Soil', 'Solvents', 'Source', 'Spectrum Analysis', 'Stream', 'Surface', 'System', 'Technology', 'Temperature', 'Time', 'Trichloroethylene', 'Water', 'Wireless Technology', 'Work', 'analytical method', 'base', 'chemical binding', 'cost', 'design', 'detector', 'drinking water', 'electric impedance', 'ground water', 'improved', 'innovation', 'instrument', 'knowledge base', 'meetings', 'method development', 'new technology', 'novel', 'operation', 'pollutant', 'programs', 'prototype', 'public health relevance', 'purge', 'remediation', 'response', 'sensor', 'success', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R44,2012,459419,0.02966515258687544
"Machine learning analysis of tandem mass spectra    DESCRIPTION (provided by applicant): Proteins are the primary functional molecules in living cells, and tandem mass spectrometry provides the most efficient means of studying proteins in a high-throughput fashion. The proposal aims to use state-of-the-art methods from the fields of machine learning, statistics and natural language processing to improve our ability to make sense of large tandem mass spectrometry data sets.  The core of the proposal is a type of probabilistic model, known as a dynamic Bayesian network that allows us to reason efficiently and accurately about complex sequential data sets. This modeling framework leverages a large body of related work from the fields of natural language processing and speech recognition. Much of this prior work has not yet been exploited by computational biologists, so the proposal represents a valuable cross-fertilization across disciplines.  More specifically, this project employs a collection of cooperating dynamic Bayesian networks to model jointly an entire mass spectrometry experiment. Relative to most existing methods for analyzing mass spectrometry data, which tend to divide the analysis of an experiment into a series of small independent subtasks, the proposed unified model jointly, considers all of the available data. This approach can thus exploit valuable dependencies among spectra and along various dimensions of the data. Dynamic Bayesian networks also provide a rigorous framework for performing inference from a combination of observed data and qualitative expert knowledge.  The project is divided into five aims, each of which concerns a particular type of mass spectrometry experiment. These experiments involve (1) identifying all of the proteins in a given complex biological sample using a standard mass spectrometry protocol; (2) identifying proteins using a modified protocol in which the mass spectrometer samples the data in a systematic, rather than data-dependent, fashion, with the goal of identifying lower abundance proteins; (3) quantifying the relative abundance of proteins within or between biological samples; (4) identifying post-translational modified proteins or proteins that contain sequence variation; and (5) performing targeted quantification of a specified set of proteins, such as proteins in a pathway of interest or protein biomarkers.  The methods described in this proposal have the potential to dramatically improve our ability to draw conclusions from and formulate hypotheses on the basis of high-throughput shotgun proteomics experiments. Experiments like the ones described above can, for example, identify proteins involved in fundamental disease processes, identify previously unknown protein isoforms, or quantify the re- sponses of proteins to environmental stressors or disease states.      PUBLIC HEALTH RELEVANCE: The applications of mass spectrometry and its promises for improvements of human health are nu- merous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and specific diagnostic and prognostic screens. How- ever, making optimal use of mass spectrometry data requires sophisticated computational methods. This project will develop and apply novel statistical and machine learning methods for interpreting mass spectra.           The applications of mass spectrometry and its promises for improvements of human health are nu- merous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and specific diagnostic and prognostic screens. How- ever, making optimal use of mass spectrometry data requires sophisticated computational methods. This project will develop and apply novel statistical and machine learning methods for interpreting mass spectra.         ",Machine learning analysis of tandem mass spectra,8038072,R01GM096306,"['Amino Acid Sequence', 'Area', 'Biological', 'Biological Markers', 'C-Peptide', 'Cells', 'Clinical', 'Collection', 'Complex', 'Complex Mixtures', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Databases', 'Dependency', 'Diagnostic', 'Dimensions', 'Discipline', 'Disease', 'Fertilization', 'Goals', 'Graph', 'Health', 'Human', 'Ions', 'Knowledge', 'Life', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Natural Language Processing', 'Pathway interactions', 'Peptide Sequence Determination', 'Peptides', 'Phase', 'Post-Translational Protein Processing', 'Probability', 'Process', 'Protein Isoforms', 'Proteins', 'Proteomics', 'Protocols documentation', 'Reaction', 'Relative (related person)', 'Reproducibility', 'Research Personnel', 'Sampling', 'Scanning', 'Series', 'Set protein', 'Shotguns', 'Specific qualifier value', 'Statistical Models', 'Time', 'Variant', 'Work', 'base', 'computer based statistical methods', 'computerized tools', 'design', 'disease phenotype', 'environmental stressor', 'improved', 'interest', 'liquid chromatography mass spectrometry', 'mass spectrometer', 'novel', 'prognostic', 'research study', 'response', 'speech recognition', 'statistics', 'tandem mass spectrometry', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2011,627642,0.02264966910387126
"A New Model of Peptide Fragmentation for Improved Protein Identification and Targ    DESCRIPTION (provided by applicant): Mass spectrometry (MS) based proteomics has emerged as a key technology in the search for disease- associated biomarkers. State-of-the-art instruments can identify thousands of proteins in a single sample by 'shotgun' proteomic analysis, where protein mixtures are proteolyzed into peptides, separated by one or more chromatographic steps, and analyzed by peptide dissociation using tandem mass spectrometry (MS/MS). The goal of this approach is to create new technologies for the accurate detection of proteins within complex samples. Achieving this target is currently limited by the major problem of inferring the peptide sequence from MS/MS spectra by sequence database searching: spectra are compared to ""model spectra"" generated from database sequences. Current algorithms suffer from poor accuracy and discrimination due to the use of simple models for predicting spectra, which ignores the rich information contained in the relative intensities of peaks in a typical MS/MS. Consequently, there is a vital need for more accurate models to predict MS/MS spectrum intensities from peptide sequences. In this proposal, we will develop a new and innovative kinetic model for predicting peptide fragmentation MS/MS spectra, and use the model to develop MS/MS identification algorithms with high discrimatory power. Spectra simulated by the kinetic model will then be used to design selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies. This will solve a bottleneck for widespread adoption of SRM methods for biomarker discovery, which is currently hindered by the slow process of identifying and optimizing SRM transitions for the assays. The following specific aims are (1) Develop an optimized kinetic model of gas-phase peptide fragmentation which predicts MS/MS spectra for any peptide sequence. Model parameters will be fit using the Levenberg- Marquardt algorithm, a robust method for non-linear least squares. (2) Extend the model to predict MS/MS fragmentation of phosphopeptides. The approaches developed in this aim can be extended to other disease- relevant post-translational modifications which profoundly alter peptide fragmentation and interfere with MS/MS identification. (3) Develop a route to successful implementation of spectrum-to-spectrum matching algorithms, an entirely new approach for large scale identification of proteins, in which MS/MS are searched directly against libraries of predicted spectra, simulated using our prototype kinetic model. We use predicted spectra to bypass the need for sequence databases, and spectrum-to-sequence strategies altogether. (4) Develop an algorithm for de novo prediction of selected reaction monitoring (SRM) assays for highly multiplexed quantitative measurement of proteins in complex mixtures.      PUBLIC HEALTH RELEVANCE:    PROJECT NARRATIVE Mass spectrometry-based proteomics has emerged as a key technology in the search for useful protein biomarkers, and holds many promises for early detection of disease, prediction of drug efficacy and resistance, and targeted molecular therapies. The field is currently limited by the major problem of inferring the peptide sequence from a fragmentation mass spectrum - until this problem is solved, many potential applications of proteomics to human health will not be achieved. We will develop a kinetic model to predict peptide fragmentation spectra for any peptide sequence; a method that will enable comprehensive protein profiling in human biofluids, and the rapid design of selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies.              PROJECT NARRATIVE Mass spectrometry-based proteomics has emerged as a key technology in the search for useful protein biomarkers, and holds many promises for early detection of disease, prediction of drug efficacy and resistance, and targeted molecular therapies. The field is currently limited by the major problem of inferring the peptide sequence from a fragmentation mass spectrum - until this problem is solved, many potential applications of proteomics to human health will not be achieved. We will develop a kinetic model to predict peptide fragmentation spectra for any peptide sequence; a method that will enable comprehensive protein profiling in human biofluids, and the rapid design of selected reaction monitoring (SRM) assays, which have become a critically important technique for measuring targeted sets of proteins in human biomarker studies.         ",A New Model of Peptide Fragmentation for Improved Protein Identification and Targ,8026467,R01CA155453,"['Address', 'Adoption', 'Algorithms', 'Biological Assay', 'Biological Markers', 'Bypass', 'Chemicals', 'Complex', 'Complex Mixtures', 'Databases', 'Detection', 'Discrimination', 'Disease', 'Dissociation', 'Drug resistance', 'Early Diagnosis', 'Gases', 'Goals', 'Health', 'Human', 'Ions', 'Kinetics', 'Least-Squares Analysis', 'Libraries', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular Target', 'Monitor', 'Peptides', 'Phase', 'Phosphopeptides', 'Plasma', 'Post-Translational Protein Processing', 'Process', 'Protein Analysis', 'Protein Sequence Analysis', 'Proteins', 'Proteomics', 'Reaction', 'Relative (related person)', 'Route', 'Sampling', 'Scanning', 'Screening for cancer', 'Sensitivity and Specificity', 'Set protein', 'Shotguns', 'Simulate', 'Statistical Models', 'Techniques', 'Technology', 'Work', 'base', 'chemotherapy', 'design', 'drug efficacy', 'improved', 'innovation', 'instrument', 'instrumentation', 'interest', 'new technology', 'novel strategies', 'prevent', 'protein aminoacid sequence', 'protein profiling', 'prototype', 'tandem mass spectrometry', 'tool']",NCI,UNIVERSITY OF COLORADO,R01,2011,314363,0.0066675400587292545
"Technology to Identify and Assay Chemical Genomic Probes    DESCRIPTION (provided by applicant): The primary objective of this proposal is to develop and deploy cutting edge technologies and chemical genomic tools and to understand the effects of small molecule inhibitors in vivo, and to characterize the model organism Saccharomyces cerevisiae on a systems level. Over the course of the past 3.5 years, as part of an NHGRI-funded project, we have applied three unique genome-wide screens to ~2,000 chemical inhibitors of growth. These data have led to several notable findings, including: 1) novel drug/target interactions, 2) a chemical phenotype for nearly all yeast genes, 3) a systems-level characterization of yeast, and 4) a better understanding of chemical structure-activity relationships as they manifest in vivo. These data have also guided the design of the next-generation chemical genomic assays proposed herein. Using our established bioinformatics and robotics infrastructure, we will design the next generation of assays to interrogate the genome's interaction with small molecules to unprecedented levels of scrutiny, while decreasing cost per chemical. PUBLIC HEALTH RELEVANCE: Small molecules, the central focus of this proposal, make up the majority of FDA approved drugs. Unfortunately, the pharmaceutical industry is currently experiencing sky-rocketing costs (~800 million dollars per new drug) in addition to steadily decreasing productivity. These struggles are attributed in part to unforeseen side-effects of promising drug candidates and by a lack of validated cellular ""targets"" to which a drug can bind and elicit a medicinal effect. The specific aims of this proposal address both of these problems.           Narrative Small molecules, the central focus of this proposal, make up the majority of FDA approved drugs. Unfortunately, the pharmaceutical industry is currently experiencing sky-rocketing costs (~800 million dollars per new drug) in addition to steadily decreasing productivity. These struggles are attributed in part to unforeseen side-effects of promising drug candidates and by a lack of validated cellular ""targets"" to which a drug can bind and elicit a medicinal effect. The specific aims of this proposal address both of these problems.",Technology to Identify and Assay Chemical Genomic Probes,8004073,R01HG003317,"['Address', 'Adverse effects', 'Animal Model', 'Binding', 'Binding Proteins', 'Bioinformatics', 'Biological Assay', 'Chemical Structure', 'Chemicals', 'Collection', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Drug Delivery Systems', 'Drug Industry', 'Drug Interactions', 'Ensure', 'Experimental Designs', 'FDA approved', 'Funding', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Growth Inhibitors', 'Health', 'Human', 'Individual', 'Knock-out', 'Letters', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Mammalian Cell', 'Molecular', 'National Human Genome Research Institute', 'Open Reading Frames', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Productivity', 'Proteins', 'Research Infrastructure', 'Resistance', 'Robotics', 'Role', 'Running', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Structure-Activity Relationship', 'Surface Plasmon Resonance', 'System', 'Technology', 'Toxic effect', 'Translating', 'Yeasts', 'base', 'cellular targeting', 'chemical genetics', 'cost', 'design', 'digital', 'dosage', 'drug candidate', 'experience', 'gain of function', 'genome wide association study', 'genome-wide', 'in vivo', 'inhibitor/antagonist', 'loss of function', 'mutant', 'next generation', 'novel', 'overexpression', 'particle', 'skills', 'small hairpin RNA', 'small molecule', 'technology development', 'tool']",NHGRI,STANFORD UNIVERSITY,R01,2011,1117031,0.006591080122278316
"Replacement Ocular Battery (ROBatt)    DESCRIPTION (provided by applicant): The objective of this grant project is the development and pre-validation of the Replacement Ocular Battery (ROBatt), a tiered testing strategy consisting of a battery of four alternative ocular irritancy assays, which will replace regulatory mandated acute ocular irritation testing using the Draize Rabbit Eye test. ROBatt consists of the Bovine Corneal Opacity and Permeability Assay (BCOP), the Chorioallantoic Membrane Vascular Assay using 10-day fertile chicken eggs (CAMVA), the Porcine Corneal Reversibility Assay (PorCORA) and the Porcine Confocal Assay (PorFocal). This tiered strategy follows a decision tree that allows for a thorough interrogation of possible ocular irritants. Although four assays are recommended, in most cases only two or three will be used depending on the degree of irritation. The Specific Aim of the ROBatt project is to validate the decision tree variables using at least 50 chemicals listed in the European Center for Ecotoxicology and Toxicology of Chemicals (ECETOC) data bank, including Corrosive (EEC R41, GHS/EPA Cat 1), Severe (EEC R36, GHS CaL 2, HMIS 2), Moderate (EPA Cat. 3, HMIS 2), Mild (HMIS 1) and Non-irritating (EPA Cat 4, HMIS 0). The long-term project goal is to submit the ROBatt testing strategy to iCCVAM/ECVAM for consideration as a standalone alternative to the Draize Rabbit Eye test. Validation and acceptance of the ROBatt testing strategy will significantly reduce the number of rabbits used in the toxicological assessment of consumer products, chemicals and raw materials by replacing rabbits with four robust alternative assays.       PUBLIC HEALTH RELEVANCE: Ocular irritation testing is extremely relevant to assuring adequate safety levels of public health as new formulations of chemicals and products are introduced. In most cases, these safety assessments are performed using the Draize Rabbit Eye test, resulting in thousands of rabbits used in testing every year. Alternatives have been discussed since the 80s without any appreciable acceptance from regulators.           n/a",Replacement Ocular Battery (ROBatt),8150947,U01NS073481,"['Acute', 'Biological Assay', 'Blood Vessels', 'Cattle', 'Chemicals', 'Chickens', 'Cornea', 'Corneal Opacity', 'Corrosives', 'Databases', 'Decision Trees', 'Development', 'Drug Formulations', 'European', 'Eye', 'Family suidae', 'Felis catus', 'Goals', 'Grant', 'Irritants', 'Oryctolagus cuniculus', 'Permeability', 'Public Health', 'Safety', 'Test Result', 'Testing', 'Toxicology', 'Validation', 'chorioallantoic membrane', 'consumer product', 'egg', 'irritation', 'public health relevance']",NINDS,"MB RESEARCH LABORATORIES, INC.",U01,2011,483139,0.027031258865183677
"Biomarker discovery for mitochondrial toxicants using metabolic footprinting    DESCRIPTION (provided by applicant): Many environmental stressors have deleterious effects on mitochondrial functions, by a variety of mechanisms, and with timelines of different lengths. Mitochondrial dysfunction has multiple clinical presentations, often delayed from the onset of organelle damage. At present, biomarkers that report on mitochondrial function, to enable population studies of environmental exposures and their consequences, are lacking. This proposal seeks to identify candidate biomarkers using a metabolomics approach, in greater depth than has previously been applied to toxicologic investigations.  Metabolomic analysis provides a window on cellular and organismal functions, closer to the actual physiology than genomic or transcriptomic arrays. Using multiple platforms for separation and mass spectrometric resolution of complex mixtures, a comprehensive set of metabolites including organic acids, amino acids, steroids, complex lipids, energy charge and mitochondrial transport metabolites can be targeted. This technology will be employed to develop biomarkers of mitochondrial dysfunction that will fill an important gap in current studies of environmental toxicology.  Studies here will focus on a polybrominated diphenyl ether, BDE-47, that is emerging as one of the major persistent organic pollutants in the U.S. Published data from a collaborator, Dr. Kavanagh, and preliminary data indicate that BDE-47 impairs mitochondrial function in cell lines in vitro. Metabolites in extracellular media (metabolic footprinting) will be analyzed with primary mouse hepatocytes, one of the main targets of BDE-47 toxicity, as a function of dose and time of exposure. The hypothesis to be tested is that fatty acid overload will uncover subtle mitochondrial defects by performing metabolomic analysis in isolated mitochondria. These studies will provide metabolic signatures of BDE-47 toxicity that will next be extended to in vivo studies of plasma and urine from BDE-47 treated mice. The possibility that lymphocytes may be a surrogate tissue for the mitochondrial toxicities of BDE-47 will be examined using the fatty acid overload assay.  The effects of genetic background and environment on BDE-47 toxicity are poorly understood.  Two potential modifiers will be examined: 1) genetically engineered mice with low and high glutathione levels, and 2) fatty liver due to vitamin A deficiency. These experiments will provide novel information on potential high risk populations for BDE-47 exposure. A key question will be whether candidate biomarkers scale with toxicity (in addition to exposure dose).  In addition to discovering metabolic signatures of BDE-47 toxicity, two recently described mitochondrial responses to stress will be tested by metabolic footprinting: 1) mitochondrial proteotoxicity due to aggregation of unfolded/unassembled proteins, and 2) alternative fumarate respiration in response to hypoxia and distal block of the ETC. By selecting defined mitochondrial responses, one adverse and one adaptive, once can begin to categorize mitochondrial dysfunction and look for signatures that associate with specific types. In the case of fumarate respiration, a signature of high levels of succinate in secreted metabolites is already known.  This work is a close collaboration with Oliver Fiehn, expert in metabolomics screening and data analysis, and Terry Kavanagh, an expert in oxidative stress and mitochondrial toxicology.      PUBLIC HEALTH RELEVANCE: Public Health Relevance/Project Narrative Many environmental toxins inhibit mitochondria, the powerhouses of the cell, as a mechanism of toxicity. Current research in this area is hampered by the lack of convenient tests to measure early mitochondrial damage, which would promote appropriate preventive/treatment efforts for individuals and at risk populations. The goal of this research is to identify chemical changes in blood or urine that are indicators of mitochondrial damage in the body, using mass spectrometry tools to survey thousands of compounds.              Public Health Relevance/",Biomarker discovery for mitochondrial toxicants using metabolic footprinting,8218308,R01ES020819,"['Affect', 'Amino Acids', 'Biochemical', 'Biochemistry', 'Bioenergetics', 'Biological Assay', 'Biological Markers', 'Biology', 'Body Fluids', 'Cell Line', 'Cell physiology', 'Cells', 'Characteristics', 'Charge', 'Classification', 'Clinical', 'Collaborations', 'Complex', 'Complex Mixtures', 'Data', 'Data Analyses', 'Defect', 'Disease', 'Distal', 'Dose', 'Environment', 'Environmental Exposure', 'Exhibits', 'Exposure to', 'Fatty Acids', 'Fatty Liver', 'Fumarates', 'Functional disorder', 'Generations', 'Genetic', 'Genetically Engineered Mouse', 'Genomics', 'Glutathione', 'Harvest', 'Hepatocyte', 'Histocompatibility Testing', 'Hypoxia', 'In Vitro', 'Investigation', 'Length', 'Lipids', 'Liquid substance', 'Lymphocyte', 'Machine Learning', 'Membrane Potentials', 'Metabolic', 'Metabolic syndrome', 'Methods', 'Mitochondria', 'Mitochondrial Diseases', 'Modeling', 'Mus', 'Organelles', 'Oxidative Stress', 'Physiology', 'Plasma', 'Population', 'Population Study', 'Pre-Clinical Model', 'Proteins', 'Publishing', 'Reactive Oxygen Species', 'Reporting', 'Resolution', 'Respiration', 'Screening procedure', 'Staging', 'Steroids', 'Stress', 'Succinates', 'Technology', 'Testing', 'Time', 'TimeLine', 'Tissues', 'Toxic Environmental Substances', 'Toxic effect', 'Toxicology', 'Urine', 'Vitamin A', 'Vitamin A Deficiency', 'Work', 'base', 'environmental stressor', 'environmental toxicology', 'extracellular', 'high risk', 'human population study', 'in vivo', 'insight', 'metabolomics', 'mitochondrial dysfunction', 'nonalcoholic steatohepatitis', 'novel', 'nucleotide metabolism', 'organic acid', 'phenyl ether', 'pollutant', 'protein misfolding', 'public health relevance', 'research study', 'response', 'statistics', 'toxicant', 'transcriptomics']",NIEHS,FRED HUTCHINSON CANCER RESEARCH CENTER,R01,2011,395592,0.03069835689078996
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator.  The ultimate goal of this SBIR project is to provide the DOD, DOE, and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. In Phase I, Seacoast successfully demonstrated the feasibility of using a microsensor array with a proprietary trap-and- purge preconcentrator to detect chlorinated solvents, specifically TCE, and TCA, at levels low enough to meet EPA mandated levels for drinking water. In Phase II Seacoast proposes to improve the selectivity and sensitivity of the system to better meet the needs identified by the Phase I consultant. The systems have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator traps the contaminants and releases them to a microsensor array. These sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical.  In Phase II Seacoast will specifically develop new materials to improve the sensor array selectivity, 1) by using impedance spectroscopy to study the mechanisms by which the polymer-based sensors sorb the target chemicals, 2) by implementing pattern recognition algorithms to identify chemicals for the sensor responses, and 3) by designing new preconcentrator materials that can bind these chemicals more strongly.  The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. Potential markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology.      PUBLIC HEALTH RELEVANCE: This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.           This proposal describes a novel technology that specifically addresses the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.         ",Low-Cost Electronic Nose for Groundwater Contaminants,8059710,R44ES016941,"['Address', 'Algorithms', 'Area', 'Artificial Intelligence', 'Benchmarking', 'Benzene', 'Carcinogens', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Computer software', 'Cost Analysis', 'Cost Savings', 'Data', 'Data Collection', 'Detection', 'Development', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Equation', 'Equipment', 'Evaluation', 'Fingerprint', 'Fluorescence', 'Gases', 'Goals', 'Guidelines', 'Hazardous Waste', 'Industrial Health', 'Intervention', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Maps', 'Marketing', 'Measures', 'Metals', 'Methods', 'Monitor', 'National Institute of Environmental Health Sciences', 'Nose', 'Pattern Recognition', 'Pesticides', 'Phase', 'Plants', 'Poison', 'Pollution', 'Polymers', 'Process', 'Public Health', 'Recommendation', 'Research', 'Research Personnel', 'Risk', 'Route', 'Safety', 'Sampling', 'Science', 'Scientific Advances and Accomplishments', 'Site', 'Small Business Innovation Research Grant', 'Soil', 'Solvents', 'Source', 'Spectrum Analysis', 'Stream', 'Surface', 'System', 'Technology', 'Temperature', 'Time', 'Trichloroethylene', 'Water', 'Wireless Technology', 'Work', 'analytical method', 'base', 'chemical binding', 'cost', 'design', 'detector', 'drinking water', 'electric impedance', 'ground water', 'improved', 'innovation', 'instrument', 'knowledge base', 'meetings', 'method development', 'new technology', 'novel', 'operation', 'pollutant', 'programs', 'prototype', 'purge', 'remediation', 'response', 'sensor', 'success', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R44,2011,532144,0.029621565434686775
"Machine learning analysis of tandem mass spectra    DESCRIPTION (provided by applicant): Project summary: Mass spectrometry, the core technology in the field of proteomics, promises to enable scientists to identify and quantify the entire complement of molecules that comprise a complex biological sample. In the biological and health sciences, mass spectrometry is commonly used in a nigh-throughput fashion to identify proteins in a mixture. Currently, the primary bottleneck in this type of experiment is computational. Existing algorithms for interpreting mass spectra are slow and fail to identify a large proportion of the given spectra. We propose to apply techniques and tools from the field of machine learning to the analysis of mass spectrometry data. We will build computational models of peptide fragmentation within the mass spectrometer, as well as larger-scale models of the entire mass spectrometry process. Using these models, we will design and validate algorithms for identifying the set of proteins that best explain an observed set of spectra. Software implementations for all of the methods will be made publicly available in a user-friendly form. In practical terms, this software will enable scientists to more easily, efficiently and accurately analyze and understand their mass spectrometry data. Relevance: The applications of mass spectrometry and its promises for improvements of human health are numerous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and specific diagnostic and prognostic screens.           n/a",Machine learning analysis of tandem mass spectra,7797540,R01EB007057,"['Abbreviations', 'Algorithms', 'Area', 'Authorship', 'Biochemical', 'Biological', 'Blast Cell', 'Calibration', 'Carbonyl Cyanide m-Chlorophenyl Hydrazone', 'Collection', 'Complement', 'Complex', 'Complex Mixtures', 'Computer Simulation', 'Computer software', 'Data', 'Databases', 'Devices', 'Diagnostic', 'Dissociation', 'FOLH1 gene', 'Genomics', 'Hand', 'Health', 'Health Sciences', 'Hour', 'Human', 'Knowledge', 'Learning', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular', 'Peptide Fragments', 'Peptides', 'Performance', 'Post-Translational Protein Processing', 'Preparation', 'Principal Investigator', 'Procedures', 'Process', 'Protein Biochemistry', 'Proteins', 'Proteomics', 'Receiver Operating Characteristics', 'Research Personnel', 'Rest', 'Running', 'Sampling', 'Scientist', 'Set protein', 'Silicon Dioxide', 'Source Code', 'Staging', 'Statistical Models', 'Techniques', 'Technology', 'Time', 'Training', 'Work', 'computer based statistical methods', 'computer cluster', 'design', 'disease phenotype', 'expectation', 'improved', 'interest', 'markov model', 'mass spectrometer', 'model design', 'prognostic', 'programs', 'research study', 'small molecule', 'tandem mass spectrometry', 'task analysis', 'tool', 'user-friendly']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2010,593600,0.09815492387605985
"Computational approaches to protein identification and quantification using MS/MS    DESCRIPTION (provided by applicant): Shotgun proteomics is one of the most commonly used approaches to MS-based biomarker discovery, due to its high throughput and sensitivity. The general strategy involves simultaneous protease digestion of all proteins in a mixture, liquid chromatography-based separation of peptides and analysis by tandem mass spectrometry (MS/MS) to produce fragmentation spectra of each peptide. Each experimental spectrum is searched against a protein database. Sequences that best match the experimental spectra are considered identified, while a set of reliably identified peptides from the same protein is necessary for a reliable protein identification. The main goal in the proposed work is to generate and interrogate MS/MS data from several proteomics platforms, including ESI/MS, MALDI/TOF/TOF, LC-IMS/TOF and MALDI-PID/TOF to develop customized computational tools that address several challenging problems in shotgun proteomics data analysis: peptide identification, protein identification and label-free protein quantification. Our proposed approach is data-driven. At its core is the application of machine learning methods to the prediction of peptide fragmentation spectra as well as the likelihood of peptide detection in a typical proteomics experiment. Improved peptide identification coupled with the predicted peptide delectability will then be used to develop new methods for improved protein identification and quantification. The methods proposed herein will be extensively evaluated and software will be made public both as web-based tools and open-source deliverables. These software tools will enable researchers using proteomics technologies to more effectively and efficiently study a variety of health related conditions. Such studies might entail disease diagnosis (biomarker discovery), disease progression (tissue profiling), or effects of treatment (drug-induced proteome changes). These studies will enhance understanding of diseases and hasten the development of effective treatments and cures. In addition, these tools will be useful in characterizing new analytical tools for proteome analysis. Here we propose to develop and extensively evaluate computational methodology that will be used to improve the interpretation of tandem mass spectrometry data. These software tools will enable researchers using proteomics technologies to more effectively and efficiently study a variety of health related conditions. Such studies that might entail disease diagnosis, disease progression, or effects of treatment, will enhance understanding of diseases and hasten the development of effective treatments and cures.          n/a",Computational approaches to protein identification and quantification using MS/MS,7916503,R01RR024236,"['Accounting', 'Address', 'Algorithms', 'Amino Acid Sequence', 'Analytical Chemistry', 'Biological Markers', 'Caring', 'Chemicals', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Digestion', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Informatics', 'Ions', 'Knowledge', 'Label', 'Learning', 'Liquid Chromatography', 'Machine Learning', 'Measures', 'Methods', 'Numerical value', 'Online Systems', 'Output', 'Peptide Hydrolases', 'Peptide Library', 'Peptide Sequence Determination', 'Peptides', 'Pharmaceutical Preparations', 'Probability', 'Problem Formulations', 'Protein Databases', 'Proteins', 'Proteome', 'Proteomics', 'Relative (related person)', 'Research Personnel', 'Sampling', 'Scheme', 'Shotguns', 'Software Tools', 'Solutions', 'Staging', 'Structure', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Trypsin', 'Work', 'analytical tool', 'base', 'computerized tools', 'design', 'disease diagnosis', 'effective therapy', 'improved', 'open source', 'programs', 'research study', 'tandem mass spectrometry', 'tool', 'treatment effect']",NCRR,INDIANA UNIVERSITY BLOOMINGTON,R01,2010,273971,0.002955634979508187
"Technology to Identify and Assay Chemical Genomic Probes    DESCRIPTION (provided by applicant): The primary objective of this proposal is to develop and deploy cutting edge technologies and chemical genomic tools and to understand the effects of small molecule inhibitors in vivo, and to characterize the model organism Saccharomyces cerevisiae on a systems level. Over the course of the past 3.5 years, as part of an NHGRI-funded project, we have applied three unique genome-wide screens to ~2,000 chemical inhibitors of growth. These data have led to several notable findings, including: 1) novel drug/target interactions, 2) a chemical phenotype for nearly all yeast genes, 3) a systems-level characterization of yeast, and 4) a better understanding of chemical structure-activity relationships as they manifest in vivo. These data have also guided the design of the next-generation chemical genomic assays proposed herein. Using our established bioinformatics and robotics infrastructure, we will design the next generation of assays to interrogate the genome's interaction with small molecules to unprecedented levels of scrutiny, while decreasing cost per chemical. PUBLIC HEALTH RELEVANCE: Small molecules, the central focus of this proposal, make up the majority of FDA approved drugs. Unfortunately, the pharmaceutical industry is currently experiencing sky-rocketing costs (~800 million dollars per new drug) in addition to steadily decreasing productivity. These struggles are attributed in part to unforeseen side-effects of promising drug candidates and by a lack of validated cellular ""targets"" to which a drug can bind and elicit a medicinal effect. The specific aims of this proposal address both of these problems.           Narrative Small molecules, the central focus of this proposal, make up the majority of FDA approved drugs. Unfortunately, the pharmaceutical industry is currently experiencing sky-rocketing costs (~800 million dollars per new drug) in addition to steadily decreasing productivity. These struggles are attributed in part to unforeseen side-effects of promising drug candidates and by a lack of validated cellular ""targets"" to which a drug can bind and elicit a medicinal effect. The specific aims of this proposal address both of these problems.",Technology to Identify and Assay Chemical Genomic Probes,8057799,R01HG003317,"['Address', 'Adverse effects', 'Animal Model', 'Binding', 'Binding Proteins', 'Bioinformatics', 'Biological Assay', 'Chemical Structure', 'Chemicals', 'Collection', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Drug Delivery Systems', 'Drug Industry', 'Drug Interactions', 'Ensure', 'Experimental Designs', 'FDA approved', 'Funding', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Growth Inhibitors', 'Human', 'Individual', 'Knock-out', 'Letters', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Mammalian Cell', 'Molecular', 'Open Reading Frames', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Productivity', 'Proteins', 'Research Infrastructure', 'Resistance', 'Robotics', 'Role', 'Running', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Skiing', 'Structure-Activity Relationship', 'Surface Plasmon Resonance', 'System', 'Technology', 'Toxic effect', 'Translating', 'Yeasts', 'base', 'cellular targeting', 'chemical genetics', 'cost', 'design', 'digital', 'dosage', 'drug candidate', 'experience', 'gain of function', 'genome wide association study', 'genome-wide', 'in vivo', 'inhibitor/antagonist', 'loss of function', 'mutant', 'next generation', 'novel', 'overexpression', 'particle', 'public health relevance', 'skills', 'small hairpin RNA', 'small molecule', 'technology development', 'tool']",NHGRI,STANFORD UNIVERSITY,R01,2010,361760,0.006591080122278316
"Technology to Identify and Assay Chemical Genomic Probes    DESCRIPTION (provided by applicant): The primary objective of this proposal is to develop and deploy cutting edge technologies and chemical genomic tools and to understand the effects of small molecule inhibitors in vivo, and to characterize the model organism Saccharomyces cerevisiae on a systems level. Over the course of the past 3.5 years, as part of an NHGRI-funded project, we have applied three unique genome-wide screens to ~2,000 chemical inhibitors of growth. These data have led to several notable findings, including: 1) novel drug/target interactions, 2) a chemical phenotype for nearly all yeast genes, 3) a systems-level characterization of yeast, and 4) a better understanding of chemical structure-activity relationships as they manifest in vivo. These data have also guided the design of the next-generation chemical genomic assays proposed herein. Using our established bioinformatics and robotics infrastructure, we will design the next generation of assays to interrogate the genome's interaction with small molecules to unprecedented levels of scrutiny, while decreasing cost per chemical. PUBLIC HEALTH RELEVANCE: Small molecules, the central focus of this proposal, make up the majority of FDA approved drugs. Unfortunately, the pharmaceutical industry is currently experiencing sky-rocketing costs (~800 million dollars per new drug) in addition to steadily decreasing productivity. These struggles are attributed in part to unforeseen side-effects of promising drug candidates and by a lack of validated cellular ""targets"" to which a drug can bind and elicit a medicinal effect. The specific aims of this proposal address both of these problems.           Narrative Small molecules, the central focus of this proposal, make up the majority of FDA approved drugs. Unfortunately, the pharmaceutical industry is currently experiencing sky-rocketing costs (~800 million dollars per new drug) in addition to steadily decreasing productivity. These struggles are attributed in part to unforeseen side-effects of promising drug candidates and by a lack of validated cellular ""targets"" to which a drug can bind and elicit a medicinal effect. The specific aims of this proposal address both of these problems.",Technology to Identify and Assay Chemical Genomic Probes,7768509,R01HG003317,"['Address', 'Adverse effects', 'Animal Model', 'Binding', 'Binding Proteins', 'Bioinformatics', 'Biological Assay', 'Chemical Structure', 'Chemicals', 'Collection', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Drug Delivery Systems', 'Drug Industry', 'Drug Interactions', 'Ensure', 'Experimental Designs', 'FDA approved', 'Funding', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Growth Inhibitors', 'Human', 'Individual', 'Knock-out', 'Letters', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Mammalian Cell', 'Molecular', 'Open Reading Frames', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Productivity', 'Proteins', 'Research Infrastructure', 'Resistance', 'Robotics', 'Role', 'Running', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Skiing', 'Structure-Activity Relationship', 'Surface Plasmon Resonance', 'System', 'Technology', 'Toxic effect', 'Translating', 'Yeasts', 'base', 'cellular targeting', 'chemical genetics', 'cost', 'design', 'digital', 'dosage', 'drug candidate', 'experience', 'gain of function', 'genome wide association study', 'genome-wide', 'in vivo', 'inhibitor/antagonist', 'loss of function', 'mutant', 'next generation', 'novel', 'overexpression', 'particle', 'public health relevance', 'skills', 'small hairpin RNA', 'small molecule', 'technology development', 'tool']",NHGRI,STANFORD UNIVERSITY,R01,2010,1128314,0.006591080122278316
"Replacement Ocular Battery (ROBatt)    DESCRIPTION (provided by applicant): The objective of this grant project is the development and pre-validation of the Replacement Ocular Battery (ROBatt), a tiered testing strategy consisting of a battery of four alternative ocular irritancy assays, which will replace regulatory mandated acute ocular irritation testing using the Draize Rabbit Eye test. ROBatt consists of the Bovine Corneal Opacity and Permeability Assay (BCOP), the Chorioallantoic Membrane Vascular Assay using 10-day fertile chicken eggs (CAMVA), the Porcine Corneal Reversibility Assay (PorCORA) and the Porcine Confocal Assay (PorFocal). This tiered strategy follows a decision tree that allows for a thorough interrogation of possible ocular irritants. Although four assays are recommended, in most cases only two or three will be used depending on the degree of irritation. The Specific Aim of the ROBatt project is to validate the decision tree variables using at least 50 chemicals listed in the European Center for Ecotoxicology and Toxicology of Chemicals (ECETOC) data bank, including Corrosive (EEC R41, GHS/EPA Cat 1), Severe (EEC R36, GHS CaL 2, HMIS 2), Moderate (EPA Cat. 3, HMIS 2), Mild (HMIS 1) and Non-irritating (EPA Cat 4, HMIS 0). The long-term project goal is to submit the ROBatt testing strategy to iCCVAM/ECVAM for consideration as a standalone alternative to the Draize Rabbit Eye test. Validation and acceptance of the ROBatt testing strategy will significantly reduce the number of rabbits used in the toxicological assessment of consumer products, chemicals and raw materials by replacing rabbits with four robust alternative assays.       PUBLIC HEALTH RELEVANCE: Ocular irritation testing is extremely relevant to assuring adequate safety levels of public health as new formulations of chemicals and products are introduced. In most cases, these safety assessments are performed using the Draize Rabbit Eye test, resulting in thousands of rabbits used in testing every year. Alternatives have been discussed since the 80s without any appreciable acceptance from regulators.           n/a",Replacement Ocular Battery (ROBatt),8068095,U01NS073481,"['Acute', 'Biological Assay', 'Blood Vessels', 'Cattle', 'Chemicals', 'Chickens', 'Cornea', 'Corneal Opacity', 'Corrosives', 'Databases', 'Decision Trees', 'Development', 'Drug Formulations', 'European', 'Eye', 'Family suidae', 'Felis catus', 'Goals', 'Grant', 'Instruction', 'Irritants', 'Oryctolagus cuniculus', 'Permeability', 'Public Health', 'Safety', 'Test Result', 'Testing', 'Toxicology', 'Validation', 'chorioallantoic membrane', 'consumer product', 'egg', 'irritation']",NINDS,"MB RESEARCH LABORATORIES, INC.",U01,2010,562935,0.027031258865183677
"Machine learning analysis of tandem mass spectra    DESCRIPTION (provided by applicant): Project summary: Mass spectrometry, the core technology in the field of proteomics, promises to enable scientists to identify and quantify the entire complement of molecules that comprise a complex biological sample. In the biological and health sciences, mass spectrometry is commonly used in a nigh-throughput fashion to identify proteins in a mixture. Currently, the primary bottleneck in this type of experiment is computational. Existing algorithms for interpreting mass spectra are slow and fail to identify a large proportion of the given spectra. We propose to apply techniques and tools from the field of machine learning to the analysis of mass spectrometry data. We will build computational models of peptide fragmentation within the mass spectrometer, as well as larger-scale models of the entire mass spectrometry process. Using these models, we will design and validate algorithms for identifying the set of proteins that best explain an observed set of spectra. Software implementations for all of the methods will be made publicly available in a user-friendly form. In practical terms, this software will enable scientists to more easily, efficiently and accurately analyze and understand their mass spectrometry data. Relevance: The applications of mass spectrometry and its promises for improvements of human health are numerous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and specific diagnostic and prognostic screens.           n/a",Machine learning analysis of tandem mass spectra,7581004,R01EB007057,"['Abbreviations', 'Algorithms', 'Area', 'Authorship', 'Biochemical', 'Biological', 'Blast Cell', 'Calibration', 'Carbonyl Cyanide m-Chlorophenyl Hydrazone', 'Collection', 'Complement', 'Complex', 'Complex Mixtures', 'Computer Simulation', 'Computer software', 'Computers', 'Data', 'Databases', 'Devices', 'Diagnostic', 'Dissociation', 'FOLH1 gene', 'Genomics', 'Hand', 'Health', 'Health Sciences', 'Hour', 'Human', 'Knowledge', 'Learning', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular', 'Peptide Fragments', 'Peptides', 'Performance', 'Post-Translational Protein Processing', 'Preparation', 'Principal Investigator', 'Procedures', 'Process', 'Protein Biochemistry', 'Proteins', 'Proteomics', 'Receiver Operating Characteristics', 'Research Personnel', 'Rest', 'Running', 'Sampling', 'Scientist', 'Set protein', 'Silicon Dioxide', 'Source Code', 'Staging', 'Statistical Models', 'Techniques', 'Technology', 'Time', 'Training', 'Work', 'computer based statistical methods', 'design', 'disease phenotype', 'expectation', 'improved', 'interest', 'markov model', 'mass spectrometer', 'model design', 'prognostic', 'programs', 'research study', 'small molecule', 'tandem mass spectrometry', 'task analysis', 'tool', 'user-friendly']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2009,607717,0.09815492387605985
"High-throughput annotation of glycan mass spectra     DESCRIPTION (provided by applicant): The correct functioning of many proteins depends on glycosylation, the addition of sugar molecules (glycans) to selected amino acids in the protein. For example, cancer cells have different glycosylation patterns than ordinary cells, and there is strong evidence that glycoproteins on the surface of egg cells play an essential role in sperm binding. Despite the importance of glycosylation, there are as yet no reliable, high-throughput methods for determining the identity and location of glycans. Glycan identification is currently a manual procedure for experts, involving a combination of chemical assays and mass spectrometry. The automation of the process would have a significant impact on our understanding of this important biological process. The proposed project aims to invent chemical procedures, algorithms, and software for high-throughput analysis of glycan mass spectrometry data. The goal is to bring glycan analysis up to the level of peptide analysis within 3 years. In contrast to peptide analysis, which can leverage genomics data, glycan analysis requires the incorporation of expert knowledge of synthetic pathways, in order to limit the huge number of theoretical combinations of monosaccharides to the much smaller number that are actually synthesized in nature. The project will have to develop novel representations for the evolving expert knowledge, because an exhaustive list- analogous to the human genome- is not currently known. Along with expert knowledge, the project will develop and validate machine learning and statistical techniques for glycan identification. In particular, the project will develop methods for internally calibrating spectra, and will learn fragmentation patterns that can statistically distinguish different types of glycosidic linkages.         n/a",High-throughput annotation of glycan mass spectra,7628516,R01GM074128,"['Address', 'Age', 'Algorithms', 'Amino Acids', 'Area', 'Automation', 'Binding', 'Biological', 'Biological Assay', 'Biological Process', 'Carbon', 'Cartoons', 'Cells', 'Chemicals', 'Communities', 'Computer software', 'Data', 'Development', 'Disclosure', 'Disease', 'Expert Systems', 'Genomics', 'Glycoproteins', 'Goals', 'Graft Rejection', 'Human Genome', 'Isomerism', 'Knowledge', 'Learning', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Manuals', 'Mass Spectrum Analysis', 'Methods', 'Modification', 'Monosaccharides', 'Nature', 'Occupations', 'Organism', 'Pathway interactions', 'Pattern', 'Peptides', 'Play', 'Polymers', 'Polysaccharides', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Signal Transduction', 'Site', 'Specialist', 'Specific qualifier value', 'Spectrum Analysis', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Training', 'Work', 'cancer cell', 'egg', 'enzyme activity', 'experience', 'glycosylation', 'glycosyltransferase', 'high throughput analysis', 'immune function', 'improved', 'novel', 'programs', 'prototype', 'sperm cell', 'sugar', 'tool']",NIGMS,PALO ALTO RESEARCH CENTER,R01,2009,329306,0.06106288705164916
"Computational approaches to protein identification and quantification using MS/MS    DESCRIPTION (provided by applicant): Shotgun proteomics is one of the most commonly used approaches to MS-based biomarker discovery, due to its high throughput and sensitivity. The general strategy involves simultaneous protease digestion of all proteins in a mixture, liquid chromatography-based separation of peptides and analysis by tandem mass spectrometry (MS/MS) to produce fragmentation spectra of each peptide. Each experimental spectrum is searched against a protein database. Sequences that best match the experimental spectra are considered identified, while a set of reliably identified peptides from the same protein is necessary for a reliable protein identification. The main goal in the proposed work is to generate and interrogate MS/MS data from several proteomics platforms, including ESI/MS, MALDI/TOF/TOF, LC-IMS/TOF and MALDI-PID/TOF to develop customized computational tools that address several challenging problems in shotgun proteomics data analysis: peptide identification, protein identification and label-free protein quantification. Our proposed approach is data-driven. At its core is the application of machine learning methods to the prediction of peptide fragmentation spectra as well as the likelihood of peptide detection in a typical proteomics experiment. Improved peptide identification coupled with the predicted peptide delectability will then be used to develop new methods for improved protein identification and quantification. The methods proposed herein will be extensively evaluated and software will be made public both as web-based tools and open-source deliverables. These software tools will enable researchers using proteomics technologies to more effectively and efficiently study a variety of health related conditions. Such studies might entail disease diagnosis (biomarker discovery), disease progression (tissue profiling), or effects of treatment (drug-induced proteome changes). These studies will enhance understanding of diseases and hasten the development of effective treatments and cures. In addition, these tools will be useful in characterizing new analytical tools for proteome analysis. Here we propose to develop and extensively evaluate computational methodology that will be used to improve the interpretation of tandem mass spectrometry data. These software tools will enable researchers using proteomics technologies to more effectively and efficiently study a variety of health related conditions. Such studies that might entail disease diagnosis, disease progression, or effects of treatment, will enhance understanding of diseases and hasten the development of effective treatments and cures.          n/a",Computational approaches to protein identification and quantification using MS/MS,7683963,R01RR024236,"['Accounting', 'Address', 'Algorithms', 'Amino Acid Sequence', 'Analytical Chemistry', 'Biological Markers', 'Caring', 'Chemicals', 'Computer software', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Digestion', 'Disease', 'Disease Progression', 'Goals', 'Health', 'Informatics', 'Ions', 'Knowledge', 'Label', 'Learning', 'Liquid Chromatography', 'Machine Learning', 'Measures', 'Methods', 'Numerical value', 'Online Systems', 'Output', 'Peptide Hydrolases', 'Peptide Library', 'Peptide Sequence Determination', 'Peptides', 'Pharmaceutical Preparations', 'Probability', 'Problem Formulations', 'Protein Databases', 'Proteins', 'Proteome', 'Proteomics', 'Relative (related person)', 'Research Personnel', 'Sampling', 'Scheme', 'Shotguns', 'Software Tools', 'Solutions', 'Staging', 'Structure', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Trypsin', 'Work', 'analytical tool', 'base', 'computerized tools', 'design', 'disease diagnosis', 'effective therapy', 'improved', 'open source', 'programs', 'research study', 'tandem mass spectrometry', 'tool', 'treatment effect']",NCRR,INDIANA UNIVERSITY BLOOMINGTON,R01,2009,268677,0.002955634979508187
"Peptide Biomarker Discovery by Mass Spectrometry for Early Detection of Liver Can    DESCRIPTION (provided by applicant):  Mass spectrometry (MS) has the promise to provide a noninvasive screening mechanism on easily accessible fluids such as plasma, serum, and urine. The characterization of peptides in these biological fluids is one of the promising strategies for biomarker discovery. However, peptide profiles obtained through current mass spectrometric methods are characterized by their high dimensionality and complex patterns with substantial amount of noise. The presence of biological variability and disease heterogeneity in human samples from diverse populations adds to the complexity of the problem. Thus, in addition to innovative analytical methods desired for sample preparation, peptide identification, and validation, robust computational methods are needed for optimal selection of useful peptidic markers. This collaborative project brings together experts in bioinformatics, biostatistics, proteomics, and mass spectrometry to develop analytical tools that address the above challenges. The specific aims are the following: (1) To develop fuzzy logic based methods to detect and calibrate MS peaks. Our peak detection method will identify peaks in a way that is consistent with peaks detected manually by MS experts. Peaks will be calibrated to accommodate isotopic distributions and machine drifts. (2) To investigate machine learning- based peak selection methods that take into account biological variability and disease heterogeneity of the human population. Spike-in and simulation studies will be conducted to obtain spectra whose true inputs are known. The spectra from these studies will be used to optimize our peak detection/calibration and selection methods, and compare the methods with other existing solutions. The optimized analytical tools will be applied to find and validate markers that detect hepatocellular carcinoma (HCC) at a treatable stage. Serum samples collected from cirrhotic and HCC patients as well as healthy controls in Egypt, United States, and Thailand will be used in this study. Mass spectra will be generated using matrix-assisted laser desorption/ionization time-of-flight (MALDI-TOF) MS of enriched low molecular weight (LMW) serum fractions of the samples. From these spectra, the most useful panel of peaks will be identified using the proposed peak detection, calibration, and selection methods. The selected peaks will be sequenced to identify the peptides they represent. Finally, the identity of the peptides and their ability to detect HCC will be examined using isotope dilution by synthesizing 13C-labeled peptide standards. The synergetic interaction of diverse disciplines contributes to the intellectual merit of this project, leading to analytical tools that will make scientific knowledge discovery more efficient. Analytical tools developed in this project will be useful for other biomarker discovery studies, where the analysis of high-dimensional mass spectral data is needed. The tools will be freely available (open source) to mass spectrometry users. PUBLIC HEALTH RELEVANCE:  Development of a diagnostic test would be of great benefit for detection of hepatocellular carcinoma (HCC) at a treatable stage. In particular, defining clinically applicable biomarkers that detect early-stage HCC in a high-risk population of cirrhotic patients has potentially far-reaching consequences for disease management and patient health. This project is important because most HCC patients present with advanced-stage disease and poor prognosis. There is a pressing need to identify biomarkers of HCC that could be used for early detection and more accurate classification of disease. This project will lead to the development of analytical tools to find and validate early-diagnosis candidate peptide biomarkers from high- dimensional MALDI-TOF spectra of low-molecular-weight serum fractions. In addition to screening high-risk populations for early signs of disease, the resulting biomarkers could be used to design and test improved treatment strategies.          n/a",Peptide Biomarker Discovery by Mass Spectrometry for Early Detection of Liver Can,7640849,R21CA130837,"['Accounting', 'Address', 'Algorithms', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biometry', 'Calibration', 'Child', 'Cirrhosis', 'Clinical', 'Code', 'Commit', 'Complex', 'Comprehensive Cancer Center', 'Computing Methodologies', 'Data', 'Detection', 'Development', 'Diagnostic tests', 'Discipline', 'Disease', 'Disease Management', 'Early Detection Research Network', 'Early Diagnosis', 'Egypt', 'Ensure', 'Fuzzy Logic', 'Goals', 'Health', 'Heterogeneity', 'Human', 'Individual', 'Information Resources', 'Isotopes', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Letters', 'Linguistics', 'Liquid substance', 'Liver', 'MALDI-TOF Mass Spectrometry', 'Machine Learning', 'Mass Spectrum Analysis', 'Medical center', 'Methodology', 'Methods', 'Michigan', 'Molecular Weight', 'Morphologic artifacts', 'Newly Diagnosed', 'Noise', 'Participant', 'Patients', 'Pattern', 'Peptides', 'Plasma', 'Population', 'Population Heterogeneity', 'Preparation', 'Primary carcinoma of the liver cells', 'Process', 'Proteins', 'Proteomics', 'Radial', 'Research Personnel', 'Resolution', 'Running', 'Sampling', 'Sampling Studies', 'Screening for Hepatocellular Cancer', 'Screening procedure', 'Serum', 'Shoulder', 'Signal Transduction', 'Solutions', 'Source', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Staging', 'Subgroup', 'System', 'Testing', 'Thailand', 'Time', 'United States', 'Universities', 'Urine', 'Validation', 'Work', 'analytical method', 'analytical tool', 'base', 'candidate identification', 'design', 'disease classification', 'high risk', 'improved', 'innovation', 'instrument', 'liquid chromatography mass spectrometry', 'member', 'open source', 'outcome forecast', 'public health relevance', 'research study', 'simulation', 'tandem mass spectrometry', 'tool', 'treatment strategy']",NCI,GEORGETOWN UNIVERSITY,R21,2009,207225,0.052078799759948044
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator. Seacoast's Phase I research will focus on developing the sensor array, demonstrating sensitivity to chlorinated hydrocarbons at relevant concentrations, and field tests in actual contaminated sites. The ultimate goal is to provide the DOD, DOE, NIEHS and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. The systems will have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator collects the contaminants and releases them to a microsensor array. The sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical. An array of differently responding sensors and pattern recognition can thereby compensate for changes in humidity, temperature, and composition. These low-power systems can be left unattended and transmit data wirelessly or through USB to a central location. The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. The potential commercial markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology. PUBLIC HEALTH RELEVANCE: This proposal will describe a potential method to specifically address the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.          n/a",Low-Cost Electronic Nose for Groundwater Contaminants,7847964,R43ES016941,"['Address', 'Algorithms', 'Characteristics', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Data', 'Data Collection', 'Detection', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Feedback', 'Fingerprint', 'Fluorescence', 'Goals', 'Humidity', 'Industrial Health', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Location', 'Machine Learning', 'Maps', 'Marketing', 'Measures', 'Methods', 'Modification', 'Monitor', 'National Institute of Environmental Health Sciences', 'Nose', 'Pattern Recognition', 'Phase', 'Poison', 'Polymers', 'Process', 'Public Health', 'Pump', 'ROC Curve', 'Recommendation', 'Research', 'Risk', 'Safety', 'Sampling', 'Science', 'Simulate', 'Site', 'Soil', 'Solutions', 'Source', 'Stream', 'Surface', 'System', 'Technology', 'Temperature', 'Testing', 'Time', 'Trichloroethylene', 'Water', 'Work', 'aqueous', 'base', 'cold temperature', 'computerized data processing', 'cost', 'cost effectiveness', 'design', 'detector', 'drinking water', 'ground water', 'innovation', 'membrane assembly', 'pollutant', 'prototype', 'public health relevance', 'remediation', 'response', 'sensor', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R43,2009,11376,0.021135868551302193
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7850408,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'discount', 'drug discovery', 'empowered', 'fluorescence imaging', 'genome-wide', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,R01,2009,26557,0.006392716982402756
"Technology to Identify and Assay Chemical Genomic Probes    DESCRIPTION (provided by applicant): The primary objective of this proposal is to develop and deploy cutting edge technologies and chemical genomic tools and to understand the effects of small molecule inhibitors in vivo, and to characterize the model organism Saccharomyces cerevisiae on a systems level. Over the course of the past 3.5 years, as part of an NHGRI-funded project, we have applied three unique genome-wide screens to ~2,000 chemical inhibitors of growth. These data have led to several notable findings, including: 1) novel drug/target interactions, 2) a chemical phenotype for nearly all yeast genes, 3) a systems-level characterization of yeast, and 4) a better understanding of chemical structure-activity relationships as they manifest in vivo. These data have also guided the design of the next-generation chemical genomic assays proposed herein. Using our established bioinformatics and robotics infrastructure, we will design the next generation of assays to interrogate the genome's interaction with small molecules to unprecedented levels of scrutiny, while decreasing cost per chemical. PUBLIC HEALTH RELEVANCE: Small molecules, the central focus of this proposal, make up the majority of FDA approved drugs. Unfortunately, the pharmaceutical industry is currently experiencing sky-rocketing costs (~800 million dollars per new drug) in addition to steadily decreasing productivity. These struggles are attributed in part to unforeseen side-effects of promising drug candidates and by a lack of validated cellular ""targets"" to which a drug can bind and elicit a medicinal effect. The specific aims of this proposal address both of these problems.           Narrative Small molecules, the central focus of this proposal, make up the majority of FDA approved drugs. Unfortunately, the pharmaceutical industry is currently experiencing sky-rocketing costs (~800 million dollars per new drug) in addition to steadily decreasing productivity. These struggles are attributed in part to unforeseen side-effects of promising drug candidates and by a lack of validated cellular ""targets"" to which a drug can bind and elicit a medicinal effect. The specific aims of this proposal address both of these problems.",Technology to Identify and Assay Chemical Genomic Probes,7580032,R01HG003317,"['Address', 'Adverse effects', 'Animal Model', 'Binding', 'Binding Proteins', 'Bioinformatics', 'Biological Assay', 'Chemical Structure', 'Chemicals', 'Collection', 'Complex', 'Computer Simulation', 'Computing Methodologies', 'Data', 'Drug Delivery Systems', 'Drug Industry', 'Drug Interactions', 'Ensure', 'Experimental Designs', 'FDA approved', 'Funding', 'Genes', 'Genetic', 'Genome', 'Genomics', 'Goals', 'Growth Inhibitors', 'Human', 'Individual', 'Knock-out', 'Letters', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Mammalian Cell', 'Molecular', 'Open Reading Frames', 'Pathway interactions', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Productivity', 'Proteins', 'Research Infrastructure', 'Resistance', 'Robotics', 'Role', 'Running', 'Saccharomyces', 'Saccharomyces cerevisiae', 'Skiing', 'Structure-Activity Relationship', 'Surface Plasmon Resonance', 'System', 'Technology', 'Toxic effect', 'Translating', 'Yeasts', 'base', 'cellular targeting', 'chemical genetics', 'cost', 'design', 'digital', 'dosage', 'drug candidate', 'experience', 'gain of function', 'genome wide association study', 'genome-wide', 'in vivo', 'inhibitor/antagonist', 'loss of function', 'mutant', 'next generation', 'novel', 'overexpression', 'particle', 'public health relevance', 'skills', 'small hairpin RNA', 'small molecule', 'technology development', 'tool']",NHGRI,STANFORD UNIVERSITY,R01,2009,1154710,0.006591080122278316
"Machine learning analysis of tandem mass spectra    DESCRIPTION (provided by applicant): Project summary: Mass spectrometry, the core technology in the field of proteomics, promises to enable scientists to identify and quantify the entire complement of molecules that comprise a complex biological sample. In the biological and health sciences, mass spectrometry is commonly used in a nigh-throughput fashion to identify proteins in a mixture. Currently, the primary bottleneck in this type of experiment is computational. Existing algorithms for interpreting mass spectra are slow and fail to identify a large proportion of the given spectra. We propose to apply techniques and tools from the field of machine learning to the analysis of mass spectrometry data. We will build computational models of peptide fragmentation within the mass spectrometer, as well as larger-scale models of the entire mass spectrometry process. Using these models, we will design and validate algorithms for identifying the set of proteins that best explain an observed set of spectra. Software implementations for all of the methods will be made publicly available in a user-friendly form. In practical terms, this software will enable scientists to more easily, efficiently and accurately analyze and understand their mass spectrometry data. Relevance: The applications of mass spectrometry and its promises for improvements of human health are numerous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and specific diagnostic and prognostic screens.           n/a",Machine learning analysis of tandem mass spectra,7365198,R01EB007057,"['Abbreviations', 'Algorithms', 'Altretamine', 'Area', 'Authorship', 'Biochemical', 'Biological', 'Blast Cell', 'Calibration', 'Carbonyl Cyanide m-Chlorophenyl Hydrazone', 'Collection', 'Complement', 'Complex', 'Complex Mixtures', 'Computer Simulation', 'Computer software', 'Computers', 'Data', 'Databases', 'Devices', 'Diagnostic', 'Dissociation', 'FOLH1 gene', 'Genomics', 'Hand', 'Health', 'Health Sciences', 'Hour', 'Human', 'Knowledge', 'Learning', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular', 'Peptide Fragments', 'Peptides', 'Performance', 'Post-Translational Protein Processing', 'Preparation', 'Principal Investigator', 'Procedures', 'Process', 'Protein Biochemistry', 'Proteins', 'Proteomics', 'Rate', 'Receiver Operating Characteristics', 'Research Personnel', 'Rest', 'Running', 'Sampling', 'Scientist', 'Score', 'Set protein', 'Silicon Dioxide', 'Source Code', 'Staging', 'Statistical Models', 'Techniques', 'Technology', 'Time', 'Today', 'Training', 'Work', 'computer based statistical methods', 'day', 'design', 'disease phenotype', 'expectation', 'improved', 'interest', 'markov model', 'mass spectrometer', 'model design', 'prognostic', 'programs', 'research study', 'small molecule', 'tandem mass spectrometry', 'task analysis', 'tool', 'user-friendly']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2008,602497,0.09815492387605985
"Intelligent Aids for Proteomic Data Mining DESCRIPTION (provided by applicant): Primary purpose of this proposal is to provide the applicant with the means and structures for achieving two goals; (1) to develop intelligent computational aids for mining proteomic data accumulating from high throughput techniques like SELDI-TOF mass spectrometry; and (2) the long-term goal is to gain independence as a biomedical informatics researcher by developing methodological expertise in Bayesian methods and proteomic technologies. Applicant will obtain further instruction in probabilistic methods of data analysis; and she will receive education on proteomic technologies that are driving today's proteome research. Training will be provided through formal coursework, directed readings, seminars and conferences in addition to research directed by excellent mentors.  Applicant's research project involves a novel combination of techniques for use in proteomic data analysis. Previous research has included the use of techniques such as genetic algorithms and neural networks for analysis of proteomic data. These techniques were not explicitly designed to take into account background and prior knowledge. Hypothesis of this project is that background knowledge and machine learning techniques can positively influence the selection of appropriate biomarkers from proteomic data, enabling efficient and accurate analysis of massive datasets arising from proteomic profiling studies. Therefore, this project will satisfy four aims: (1) development of a wrapper-based machine learning tool; (2) augment the tool with prior knowledge such as heuristic rules and relationships in the data; (3) use these features along with de-identified patient information as input to classification systems; and (4) evaluate existing techniques for interpreting tandem mass spectrometry (MS-MS or MS/MS) data, and propose, implement and evaluate a Bayesian method for identification of peptides and proteins indicated by the MS-MS spectrum. n/a",Intelligent Aids for Proteomic Data Mining,7460715,K25GM071951,"['Accounting', 'Automobile Driving', 'Bayesian Method', 'Biological Markers', 'Biological Neural Networks', 'Class', 'Classification', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Education', 'Genetic Programming', 'Goals', 'Instruction', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Mass Spectrum Analysis', 'Mentors', 'Methods', 'Mining', 'Pathway Analysis', 'Patients', 'Peptides', 'Prevention', 'Problem Solving', 'Proteins', 'Proteome', 'Proteomics', 'Purpose', 'Reading', 'Research', 'Research Personnel', 'Research Project Grants', 'Spectrometry', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Today', 'Training', 'analytical method', 'base', 'biomedical informatics', 'data mining', 'design', 'heuristics', 'novel', 'predictive modeling', 'symposium', 'tandem mass spectrometry', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K25,2008,132674,0.03963693454784666
"High-throughput annotation of glycan mass spectra     DESCRIPTION (provided by applicant): The correct functioning of many proteins depends on glycosylation, the addition of sugar molecules (glycans) to selected amino acids in the protein. For example, cancer cells have different glycosylation patterns than ordinary cells, and there is strong evidence that glycoproteins on the surface of egg cells play an essential role in sperm binding. Despite the importance of glycosylation, there are as yet no reliable, high-throughput methods for determining the identity and location of glycans. Glycan identification is currently a manual procedure for experts, involving a combination of chemical assays and mass spectrometry. The automation of the process would have a significant impact on our understanding of this important biological process. The proposed project aims to invent chemical procedures, algorithms, and software for high-throughput analysis of glycan mass spectrometry data. The goal is to bring glycan analysis up to the level of peptide analysis within 3 years. In contrast to peptide analysis, which can leverage genomics data, glycan analysis requires the incorporation of expert knowledge of synthetic pathways, in order to limit the huge number of theoretical combinations of monosaccharides to the much smaller number that are actually synthesized in nature. The project will have to develop novel representations for the evolving expert knowledge, because an exhaustive list- analogous to the human genome- is not currently known. Along with expert knowledge, the project will develop and validate machine learning and statistical techniques for glycan identification. In particular, the project will develop methods for internally calibrating spectra, and will learn fragmentation patterns that can statistically distinguish different types of glycosidic linkages.         n/a",High-throughput annotation of glycan mass spectra,7431760,R01GM074128,"['Address', 'Age', 'Algorithms', 'Amino Acids', 'Area', 'Automation', 'Binding', 'Biological', 'Biological Assay', 'Biological Process', 'Carbon', 'Cartoons', 'Cells', 'Chemicals', 'Class', 'Communities', 'Computer software', 'Data', 'Development', 'Disclosure', 'Disease', 'Expert Systems', 'Facility Construction Funding Category', 'Genomics', 'Glycoproteins', 'Goals', 'Graft Rejection', 'Human Genome', 'Isomerism', 'Knowledge', 'Learning', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Manuals', 'Mass Spectrum Analysis', 'Methods', 'Modification', 'Monosaccharides', 'Nature', 'Numbers', 'Occupations', 'Organism', 'Pathway interactions', 'Pattern', 'Peptides', 'Play', 'Polymers', 'Polysaccharides', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Range', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Score', 'Signal Transduction', 'Site', 'Specialist', 'Specific qualifier value', 'Spectrum Analysis', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Title', 'Training', 'Work', 'cancer cell', 'egg', 'enzyme activity', 'experience', 'glycosylation', 'glycosyltransferase', 'high throughput analysis', 'immune function', 'improved', 'novel', 'programs', 'prototype', 'sperm cell', 'sugar', 'tool']",NIGMS,PALO ALTO RESEARCH CENTER,R01,2008,329296,0.06106288705164916
"Computational approaches to protein identification and quantification using MS/MS    DESCRIPTION (provided by applicant): Shotgun proteomics is one of the most commonly used approaches to MS-based biomarker discovery, due to its high throughput and sensitivity. The general strategy involves simultaneous protease digestion of all proteins in a mixture, liquid chromatography-based separation of peptides and analysis by tandem mass spectrometry (MS/MS) to produce fragmentation spectra of each peptide. Each experimental spectrum is searched against a protein database. Sequences that best match the experimental spectra are considered identified, while a set of reliably identified peptides from the same protein is necessary for a reliable protein identification. The main goal in the proposed work is to generate and interrogate MS/MS data from several proteomics platforms, including ESI/MS, MALDI/TOF/TOF, LC-IMS/TOF and MALDI-PID/TOF to develop customized computational tools that address several challenging problems in shotgun proteomics data analysis: peptide identification, protein identification and label-free protein quantification. Our proposed approach is data-driven. At its core is the application of machine learning methods to the prediction of peptide fragmentation spectra as well as the likelihood of peptide detection in a typical proteomics experiment. Improved peptide identification coupled with the predicted peptide delectability will then be used to develop new methods for improved protein identification and quantification. The methods proposed herein will be extensively evaluated and software will be made public both as web-based tools and open-source deliverables. These software tools will enable researchers using proteomics technologies to more effectively and efficiently study a variety of health related conditions. Such studies might entail disease diagnosis (biomarker discovery), disease progression (tissue profiling), or effects of treatment (drug-induced proteome changes). These studies will enhance understanding of diseases and hasten the development of effective treatments and cures. In addition, these tools will be useful in characterizing new analytical tools for proteome analysis. Here we propose to develop and extensively evaluate computational methodology that will be used to improve the interpretation of tandem mass spectrometry data. These software tools will enable researchers using proteomics technologies to more effectively and efficiently study a variety of health related conditions. Such studies that might entail disease diagnosis, disease progression, or effects of treatment, will enhance understanding of diseases and hasten the development of effective treatments and cures.          n/a",Computational approaches to protein identification and quantification using MS/MS,7387128,R01RR024236,"['Accounting', 'Address', 'Algorithms', 'Amino Acid Sequence', 'Analytical Chemistry', 'Biological Markers', 'Caring', 'Chemicals', 'Computer software', 'Computing Methodologies', 'Condition', 'Coupled', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Development', 'Diagnosis', 'Digestion', 'Disease', 'Disease Progression', 'Disease regression', 'Endopeptidases', 'Goals', 'Health', 'Informatics', 'Ions', 'Knowledge', 'Label', 'Learning', 'Liquid Chromatography', 'Machine Learning', 'Measures', 'Methods', 'Numerical value', 'Online Systems', 'Output', 'Peptide Hydrolases', 'Peptide Library', 'Peptide Sequence Determination', 'Peptides', 'Pharmaceutical Preparations', 'Probability', 'Problem Formulations', 'Protein Databases', 'Proteins', 'Proteome', 'Proteomics', 'Relative (related person)', 'Research Personnel', 'Sampling', 'Scheme', 'Score', 'Shotguns', 'Software Tools', 'Solutions', 'Staging', 'Standards of Weights and Measures', 'Structure', 'Techniques', 'Technology', 'Testing', 'Tissues', 'Training', 'Trypsin', 'Work', 'analytical tool', 'base', 'computerized tools', 'concept', 'design', 'improved', 'open source', 'programs', 'research study', 'tandem mass spectrometry', 'tool', 'treatment effect']",NCRR,INDIANA UNIVERSITY BLOOMINGTON,R01,2008,267731,0.002955634979508187
"Peptide Biomarker Discovery by Mass Spectrometry for Early Detection of Liver Can    DESCRIPTION (provided by applicant):  Mass spectrometry (MS) has the promise to provide a noninvasive screening mechanism on easily accessible fluids such as plasma, serum, and urine. The characterization of peptides in these biological fluids is one of the promising strategies for biomarker discovery. However, peptide profiles obtained through current mass spectrometric methods are characterized by their high dimensionality and complex patterns with substantial amount of noise. The presence of biological variability and disease heterogeneity in human samples from diverse populations adds to the complexity of the problem. Thus, in addition to innovative analytical methods desired for sample preparation, peptide identification, and validation, robust computational methods are needed for optimal selection of useful peptidic markers. This collaborative project brings together experts in bioinformatics, biostatistics, proteomics, and mass spectrometry to develop analytical tools that address the above challenges. The specific aims are the following: (1) To develop fuzzy logic based methods to detect and calibrate MS peaks. Our peak detection method will identify peaks in a way that is consistent with peaks detected manually by MS experts. Peaks will be calibrated to accommodate isotopic distributions and machine drifts. (2) To investigate machine learning- based peak selection methods that take into account biological variability and disease heterogeneity of the human population. Spike-in and simulation studies will be conducted to obtain spectra whose true inputs are known. The spectra from these studies will be used to optimize our peak detection/calibration and selection methods, and compare the methods with other existing solutions. The optimized analytical tools will be applied to find and validate markers that detect hepatocellular carcinoma (HCC) at a treatable stage. Serum samples collected from cirrhotic and HCC patients as well as healthy controls in Egypt, United States, and Thailand will be used in this study. Mass spectra will be generated using matrix-assisted laser desorption/ionization time-of-flight (MALDI-TOF) MS of enriched low molecular weight (LMW) serum fractions of the samples. From these spectra, the most useful panel of peaks will be identified using the proposed peak detection, calibration, and selection methods. The selected peaks will be sequenced to identify the peptides they represent. Finally, the identity of the peptides and their ability to detect HCC will be examined using isotope dilution by synthesizing 13C-labeled peptide standards. The synergetic interaction of diverse disciplines contributes to the intellectual merit of this project, leading to analytical tools that will make scientific knowledge discovery more efficient. Analytical tools developed in this project will be useful for other biomarker discovery studies, where the analysis of high-dimensional mass spectral data is needed. The tools will be freely available (open source) to mass spectrometry users. PUBLIC HEALTH RELEVANCE:  Development of a diagnostic test would be of great benefit for detection of hepatocellular carcinoma (HCC) at a treatable stage. In particular, defining clinically applicable biomarkers that detect early-stage HCC in a high-risk population of cirrhotic patients has potentially far-reaching consequences for disease management and patient health. This project is important because most HCC patients present with advanced-stage disease and poor prognosis. There is a pressing need to identify biomarkers of HCC that could be used for early detection and more accurate classification of disease. This project will lead to the development of analytical tools to find and validate early-diagnosis candidate peptide biomarkers from high- dimensional MALDI-TOF spectra of low-molecular-weight serum fractions. In addition to screening high-risk populations for early signs of disease, the resulting biomarkers could be used to design and test improved treatment strategies.          n/a",Peptide Biomarker Discovery by Mass Spectrometry for Early Detection of Liver Can,7531854,R21CA130837,"['Accounting', 'Address', 'Algorithms', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biometry', 'Calibration', 'Child', 'Cirrhosis', 'Clinical', 'Code', 'Commit', 'Complex', 'Comprehensive Cancer Center', 'Computing Methodologies', 'Data', 'Detection', 'Development', 'Diagnostic tests', 'Discipline', 'Disease', 'Disease Management', 'Early Detection Research Network', 'Early Diagnosis', 'Egypt', 'Ensure', 'Fuzzy Logic', 'Goals', 'Health', 'Heterogeneity', 'Human', 'Individual', 'Information Resources', 'Isotopes', 'Knowledge', 'Label', 'Laboratories', 'Lead', 'Letters', 'Linguistics', 'Liquid substance', 'Liver', 'MALDI-TOF Mass Spectrometry', 'Machine Learning', 'Mass Spectrum Analysis', 'Medical center', 'Methodology', 'Methods', 'Michigan', 'Molecular Weight', 'Morphologic artifacts', 'Newly Diagnosed', 'Noise', 'Numbers', 'Participant', 'Patients', 'Pattern', 'Peptides', 'Plasma', 'Population', 'Population Heterogeneity', 'Preparation', 'Primary carcinoma of the liver cells', 'Process', 'Proteins', 'Proteomics', 'Public Health', 'Research Personnel', 'Resolution', 'Risk', 'Running', 'Sampling', 'Sampling Studies', 'Screening for Hepatocellular Cancer', 'Screening procedure', 'Serum', 'Shoulder', 'Signal Transduction', 'Solutions', 'Source', 'Spectrometry', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Staging', 'Standards of Weights and Measures', 'Subgroup', 'System', 'Testing', 'Thailand', 'Time', 'United States', 'Universities', 'Urine', 'Validation', 'Work', 'analytical method', 'analytical tool', 'base', 'design', 'desire', 'disease classification', 'improved', 'innovation', 'instrument', 'liquid chromatography mass spectrometry', 'member', 'open source', 'outcome forecast', 'radius bone structure', 'research study', 'simulation', 'tandem mass spectrometry', 'tool']",NCI,GEORGETOWN UNIVERSITY,R21,2008,172688,0.052078799759948044
"Low-Cost Electronic Nose for Groundwater Contaminants    DESCRIPTION (provided by applicant): Several US agencies and regulators require low-cost chemical sensors for detecting and monitoring environmental clean-up, remediation, and decommissioning processes where groundwater may be contaminated. The sensors must be capable of detecting contaminants in the sub-surface groundwater and must be compatible with use in a range of environments. Most significantly, these customers require a low-cost alternative to its current expensive and labor intensive methods, namely using mobile laboratories. The project will result in the innovative use of low-cost sensor systems that will be capable of detecting and monitoring for dense non-aqueous phase liquids in the subsurface and groundwater, unattended, and in real- time from within a push-probe, using a chemicapacitor array and miniature preconcentrator. Seacoast's Phase I research will focus on developing the sensor array, demonstrating sensitivity to chlorinated hydrocarbons at relevant concentrations, and field tests in actual contaminated sites. The ultimate goal is to provide the DOD, DOE, NIEHS and other agencies with a method to map and track subsurface contamination plumes in real-time without requiring an operator. The systems will have MEMS microcapacitor sensor arrays that can monitor for leaks of toxic chemicals, contaminants from wastes, and changes in groundwater streams. A preconcentrator collects the contaminants and releases them to a microsensor array. The sensor arrays are filled with several chemoselective polymers whose dielectric permittivity changes when exposed to different vapors, creating a fingerprint response for each chemical. An array of differently responding sensors and pattern recognition can thereby compensate for changes in humidity, temperature, and composition. These low-power systems can be left unattended and transmit data wirelessly or through USB to a central location. The most important application to public health and safety is unattended monitoring of drinking water, water treatment processes, and water sources. The potential commercial markets include building chemical process monitoring and control, toxic vapor leak detection, industrial process control, and industrial health and safety. Transitioning the developed prototype to other markets where worker and public health, environmental health and regulatory compliance will be investigated to reduce the financial risks and broaden the acceptance of the technology. PUBLIC HEALTH RELEVANCE: This proposal will describe a potential method to specifically address the need for detecting groundwater contaminants and long-term monitoring of contaminated sites, by providing an unattended sensor system that tracks contamination in real-time and transmits contaminant concentrations. Such a system would be used in tandem with other methods, to provide comprehensive contamination management at DOE, DOD, and Superfund sites where ground and water clean-up projects are already underway. The proposed work will focus on detection of chlorinated hydrocarbons, which are described as among the most common pollutants in groundwater and soils at DOE sites.          n/a",Low-Cost Electronic Nose for Groundwater Contaminants,7537117,R43ES016941,"['Address', 'Algorithms', 'Characteristics', 'Chemicals', 'Chlorinated Hydrocarbons', 'Classification', 'Collection', 'Compatible', 'Condition', 'Data', 'Data Collection', 'Detection', 'Electronics', 'Engineering', 'Environment', 'Environmental Health', 'Environmental Monitoring', 'Feedback', 'Fingerprint', 'Fluorescence', 'Goals', 'Humidity', 'Industrial Health', 'Laboratories', 'Lasers', 'Left', 'Liquid substance', 'Location', 'Machine Learning', 'Maps', 'Marketing', 'Measures', 'Methods', 'Modification', 'Monitor', 'Nose', 'Numbers', 'Pattern Recognition', 'Phase', 'Poison', 'Polymers', 'Process', 'Public Health', 'Pump', 'ROC Curve', 'Range', 'Rate', 'Recommendation', 'Research', 'Risk', 'Safety', 'Sampling', 'Science', 'Simulate', 'Site', 'Soil', 'Solutions', 'Source', 'Standards of Weights and Measures', 'Stream', 'Surface', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Time', 'Trichloroethylene', 'Water', 'Work', 'aqueous', 'base', 'cold temperature', 'computerized data processing', 'cost', 'cost effectiveness', 'design', 'detector', 'drinking water', 'ground water', 'innovation', 'membrane assembly', 'pollutant', 'prototype', 'remediation', 'response', 'sensor', 'superfund site', 'vapor', 'wasting', 'water treatment']",NIEHS,"SEACOAST SCIENCE, INC.",R43,2008,97690,0.021135868551302193
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7471355,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genome', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Numbers', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Rate', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'day', 'discount', 'drug discovery', 'fluorescence imaging', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD BURNHAM PREBYS MEDICAL DISCOVERY INSTITUTE,R01,2008,411777,0.006392716982402756
"Machine learning analysis of tandem mass spectra    DESCRIPTION (provided by applicant): Project summary: Mass spectrometry, the core technology in the field of proteomics, promises to enable scientists to identify and quantify the entire complement of molecules that comprise a complex biological sample. In the biological and health sciences, mass spectrometry is commonly used in a nigh-throughput fashion to identify proteins in a mixture. Currently, the primary bottleneck in this type of experiment is computational. Existing algorithms for interpreting mass spectra are slow and fail to identify a large proportion of the given spectra. We propose to apply techniques and tools from the field of machine learning to the analysis of mass spectrometry data. We will build computational models of peptide fragmentation within the mass spectrometer, as well as larger-scale models of the entire mass spectrometry process. Using these models, we will design and validate algorithms for identifying the set of proteins that best explain an observed set of spectra. Software implementations for all of the methods will be made publicly available in a user-friendly form. In practical terms, this software will enable scientists to more easily, efficiently and accurately analyze and understand their mass spectrometry data. Relevance: The applications of mass spectrometry and its promises for improvements of human health are numerous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and specific diagnostic and prognostic screens.           n/a",Machine learning analysis of tandem mass spectra,7194479,R01EB007057,"['Abbreviations', 'Algorithms', 'Altretamine', 'Area', 'Authorship', 'Biochemical', 'Biological', 'Blast Cell', 'Calibration', 'Carbonyl Cyanide m-Chlorophenyl Hydrazone', 'Collection', 'Complement', 'Complex', 'Complex Mixtures', 'Computer Simulation', 'Computer software', 'Computers', 'Data', 'Databases', 'Devices', 'Diagnostic', 'Dissociation', 'FOLH1 gene', 'Genomics', 'Hand', 'Health', 'Health Sciences', 'Hour', 'Human', 'Knowledge', 'Learning', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Molecular', 'Peptide Fragments', 'Peptides', 'Performance', 'Post-Translational Protein Processing', 'Preparation', 'Principal Investigator', 'Procedures', 'Process', 'Protein Biochemistry', 'Proteins', 'Proteomics', 'Rate', 'Receiver Operating Characteristics', 'Research Personnel', 'Rest', 'Running', 'Sampling', 'Scientist', 'Score', 'Set protein', 'Silicon Dioxide', 'Source Code', 'Spectrometry', 'Staging', 'Statistical Models', 'Techniques', 'Technology', 'Time', 'Today', 'Training', 'Work', 'computer based statistical methods', 'day', 'design', 'disease phenotype', 'expectation', 'improved', 'interest', 'markov model', 'mass spectrometer', 'model design', 'prognostic', 'programs', 'research study', 'small molecule', 'tandem mass spectrometry', 'task analysis', 'tool', 'user-friendly']",NIBIB,UNIVERSITY OF WASHINGTON,R01,2007,623873,0.09815492387605985
"Intelligent Aids for Proteomic Data Mining DESCRIPTION (provided by applicant): Primary purpose of this proposal is to provide the applicant with the means and structures for achieving two goals; (1) to develop intelligent computational aids for mining proteomic data accumulating from high throughput techniques like SELDI-TOF mass spectrometry; and (2) the long-term goal is to gain independence as a biomedical informatics researcher by developing methodological expertise in Bayesian methods and proteomic technologies. Applicant will obtain further instruction in probabilistic methods of data analysis; and she will receive education on proteomic technologies that are driving today's proteome research. Training will be provided through formal coursework, directed readings, seminars and conferences in addition to research directed by excellent mentors.  Applicant's research project involves a novel combination of techniques for use in proteomic data analysis. Previous research has included the use of techniques such as genetic algorithms and neural networks for analysis of proteomic data. These techniques were not explicitly designed to take into account background and prior knowledge. Hypothesis of this project is that background knowledge and machine learning techniques can positively influence the selection of appropriate biomarkers from proteomic data, enabling efficient and accurate analysis of massive datasets arising from proteomic profiling studies. Therefore, this project will satisfy four aims: (1) development of a wrapper-based machine learning tool; (2) augment the tool with prior knowledge such as heuristic rules and relationships in the data; (3) use these features along with de-identified patient information as input to classification systems; and (4) evaluate existing techniques for interpreting tandem mass spectrometry (MS-MS or MS/MS) data, and propose, implement and evaluate a Bayesian method for identification of peptides and proteins indicated by the MS-MS spectrum. n/a",Intelligent Aids for Proteomic Data Mining,7254755,K25GM071951,"['Accounting', 'Automobile Driving', 'Bayesian Method', 'Biological Markers', 'Biological Neural Networks', 'Class', 'Classification', 'Data', 'Data Analyses', 'Data Set', 'Detection', 'Development', 'Disease', 'Education', 'Genetic Programming', 'Goals', 'Instruction', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Mass Spectrum Analysis', 'Mentors', 'Methods', 'Mining', 'Pathway Analysis', 'Patients', 'Peptides', 'Prevention', 'Problem Solving', 'Proteins', 'Proteome', 'Proteomics', 'Purpose', 'Reading', 'Research', 'Research Personnel', 'Research Project Grants', 'Spectrometry', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Today', 'Training', 'analytical method', 'base', 'biomedical informatics', 'data mining', 'design', 'heuristics', 'novel', 'predictive modeling', 'symposium', 'tandem mass spectrometry', 'tool']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K25,2007,130068,0.03963693454784666
"High-throughput annotation of glycan mass spectra     DESCRIPTION (provided by applicant): The correct functioning of many proteins depends on glycosylation, the addition of sugar molecules (glycans) to selected amino acids in the protein. For example, cancer cells have different glycosylation patterns than ordinary cells, and there is strong evidence that glycoproteins on the surface of egg cells play an essential role in sperm binding. Despite the importance of glycosylation, there are as yet no reliable, high-throughput methods for determining the identity and location of glycans. Glycan identification is currently a manual procedure for experts, involving a combination of chemical assays and mass spectrometry. The automation of the process would have a significant impact on our understanding of this important biological process. The proposed project aims to invent chemical procedures, algorithms, and software for high-throughput analysis of glycan mass spectrometry data. The goal is to bring glycan analysis up to the level of peptide analysis within 3 years. In contrast to peptide analysis, which can leverage genomics data, glycan analysis requires the incorporation of expert knowledge of synthetic pathways, in order to limit the huge number of theoretical combinations of monosaccharides to the much smaller number that are actually synthesized in nature. The project will have to develop novel representations for the evolving expert knowledge, because an exhaustive list- analogous to the human genome- is not currently known. Along with expert knowledge, the project will develop and validate machine learning and statistical techniques for glycan identification. In particular, the project will develop methods for internally calibrating spectra, and will learn fragmentation patterns that can statistically distinguish different types of glycosidic linkages.         n/a",High-throughput annotation of glycan mass spectra,7239477,R01GM074128,"['Address', 'Age', 'Algorithms', 'Amino Acids', 'Area', 'Automation', 'Binding', 'Biological', 'Biological Assay', 'Biological Process', 'Carbon', 'Cartoons', 'Cells', 'Chemicals', 'Class', 'Communities', 'Computer software', 'Data', 'Development', 'Disclosure', 'Disease', 'Expert Systems', 'Facility Construction Funding Category', 'Genomics', 'Glycoproteins', 'Goals', 'Graft Rejection', 'Human Genome', 'Isomerism', 'Knowledge', 'Learning', 'Libraries', 'Link', 'Location', 'Machine Learning', 'Malignant Neoplasms', 'Mammals', 'Manuals', 'Mass Spectrum Analysis', 'Methods', 'Modification', 'Monosaccharides', 'Nature', 'Numbers', 'Occupations', 'Organism', 'Pathway interactions', 'Pattern', 'Peptides', 'Play', 'Polymers', 'Polysaccharides', 'Procedures', 'Process', 'Proteins', 'Proteomics', 'Range', 'Research Personnel', 'Resolution', 'Role', 'Sampling', 'Score', 'Signal Transduction', 'Site', 'Specialist', 'Specific qualifier value', 'Spectrum Analysis', 'Speed', 'Surface', 'System', 'Techniques', 'Technology', 'Title', 'Training', 'Work', 'cancer cell', 'egg', 'enzyme activity', 'experience', 'glycosylation', 'glycosyltransferase', 'high throughput analysis', 'immune function', 'improved', 'novel', 'programs', 'prototype', 'sperm cell', 'sugar', 'tool']",NIGMS,PALO ALTO RESEARCH CENTER,R01,2007,318904,0.06106288705164916
"Nanopore study of single antibody-antigen interactions DESCRIPTION:    Nanopore-based single-molecule detection has recently become established as a new tool in single molecule biophysics. Evidence is presented that single antibodies can be observed with a nanopore detector, which presents a wide range of possibilities for immunological research. The hypothesis to be tested is that nanopore-based detection can be used to study single molecule dynamics of antibody-antigen interaction and analyze conformational changes that occur in antibody upon binding to antigen. This application aims to develop the utility of the nanopore-based approach through improvements in both the detection device and the software used to extract information from the channel current signal. At the same time, these studies will allow the Candidate to gain expertise in immunology and the biophysical study of protein structure and function. To study the single molecule dynamics of antibody-antigen interaction, the following three specific aims are proposed:   1. Extend nanopore based detection to nanopore/antibody based detection.   2. Implement machine learning software for automated nanopore/antibody signal analysis and experimental feedback.   3. Use well-characterized, genetically engineered, antibodies to test the utility of the nanopore device to analyze motion in the antibody molecule.   These studies will expand the utility of nanopore devices to study single molecule protein interactions.   Information gained will lead to a better understanding of the molecular dynamics associated with antigen binding by antibody and the subsequent initiation of effector functions. Since most biological nanopore variants derive from pore-forming toxins, nanopore device enhancements eventually may lead to new methods for antibody and antimicrobial-peptide immunological screening. Antibody-based nanopore devices may also serve as highly sensitive immunosensors. n/a",Nanopore study of single antibody-antigen interactions,7286095,K22LM008794,"['Algorithms', 'Altretamine', 'Antibodies', 'Antigenic Specificity', 'Antigens', 'Architecture', 'Base Pairing', 'Binding', 'Biological', 'Biophysics', 'Biosensing Techniques', 'Buffers', 'Class', 'Classification', 'Computer software', 'Condition', 'DNA', 'Data', 'Detection', 'Development', 'Devices', 'Dissociation', 'Failure', 'Feedback', 'Fingerprint', 'Haptens', 'Hemolysin', 'Immunology', 'Informatics', 'Kinetics', 'Knowledge', 'Lead', 'Length', 'Machine Learning', 'Measurement', 'Measures', 'Methods', 'Motion', 'Noise', 'Pattern Recognition', 'Physiological', 'Play', 'Pliability', 'Preparation', 'Principal Investigator', 'Probability', 'Process', 'Proteins', 'Protocols documentation', 'Range', 'Rate', 'Research', 'Research Personnel', 'Resistance', 'Resolution', 'Role', 'Sampling', 'Screening procedure', 'Semiconductors', 'Signal Transduction', 'Staging', 'Statistical Methods', 'Testing', 'Time', 'Time Study', 'Toxin', 'Variant', 'antibody engineering', 'antigen antibody binding', 'antigen binding', 'antimicrobial peptide', 'base', 'cheminformatics', 'computerized data processing', 'design', 'detector', 'expectation', 'experimental analysis', 'markov model', 'molecular dynamics', 'nanopore', 'programs', 'protein structure function', 'prototype', 'single molecule', 'stem', 'tool', 'vector', 'web interface']",NLM,CHILDREN'S HOSPITAL (NEW ORLEANS),K22,2007,162000,-0.012745889014542107
"Comparative Visualization and Analysis for GCxGC    DESCRIPTION (provided by applicant): Project Summary. This project will investigate and develop effective information technologies for comparative analysis and visualization of complex data generated by comprehensive two-dimensional gas chromatography (GCxGC). GCxGC is an emerging technology that provides an order-of-magnitude greater separation capacity, significantly better signal-to-noise ratio, and higher dimensional retention-structure relations than traditional GC. The principal challenge for utilization of GCxGC, in a wide range of public-health and other applications, is the difficulty of analyzing and interpreting the large, complex data it generates. The quantity and complexity of GCxGC data necessitates the investigation and development of new information technologies. This project will develop and demonstrate innovative methods and tools for comparative analysis of GCxGC datasets. The expected results of this research and development include a PCA-based method for chemical fingerprinting, decision trees with chemical constraints for sample classification, genetic programming for template and constraint-based matching and classification, and visualization methods for comparative GCxGC analyses. These methods will be implemented in commercial software that will support researchers and laboratory analysts in a wide range of commercial applications, including health care, environmental monitoring, and chemical processing. The power of GCxGC, supported by effective information technologies, will enable better understanding of chemical compositions and processes, a foundation for future scientific advances and discoveries. Relevance to Public Health. Today, a few advanced laboratories are pioneering GCxGC for a variety of applications such as environmental monitoring of exposure profiles in air, soil, food, and water; identification and quantification of toxic products in blood, urine, milk, and breath samples; and qualitative and quantitative metabolomics to provide a holistic view of the biochemical status or biochemical phenotype of an organism. Many analyses in these applications require detailed chemical comparisons of samples, e.g..monitoring changes, comparison to reference standards, chemical matching or ""fingerprinting"", and classification. GCxGC is a powerful new technology for such comparative analyses. This proposal will provide innovative information technologies to support users in these applications.           n/a",Comparative Visualization and Analysis for GCxGC,7270029,R44RR020256,"['Air', 'Archives', 'Biochemical', 'Blood', 'Chemicals', 'Classification', 'Complex', 'Computer software', 'Computers', 'Data', 'Data Set', 'Decision Trees', 'Development', 'Emerging Technologies', 'Environmental Monitoring', 'Fingerprint', 'Food', 'Foundations', 'Future', 'Gas Chromatography', 'Genetic Programming', 'Goals', 'Healthcare', 'Image', 'Imagery', 'Information Technology', 'Investigation', 'Laboratories', 'Language', 'Machine Learning', 'Marketing', 'Methods', 'Milk', 'Monitor', 'Noise', 'Organism', 'Pattern', 'Phase', 'Phenotype', 'Principal Component Analysis', 'Process', 'Public Health', 'Range', 'Reference Standards', 'Reporting', 'Research Personnel', 'Sales', 'Sampling', 'Schedule', 'Scientific Advances and Accomplishments', 'Signal Transduction', 'Software Tools', 'Soil', 'Statistical Methods', 'Structure', 'System', 'Techniques', 'Technology', 'Today', 'Trademark', 'Urine', 'Water', 'base', 'chemical fingerprinting', 'commercial application', 'comparative', 'innovation', 'innovative technologies', 'instrument', 'metabolomics', 'new technology', 'research and development', 'tool', 'two-dimensional']",NCRR,"GC IMAGE, LLC",R44,2007,239373,0.034055498912000104
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7264516,R01EB006200,"['Address', 'Binding', 'Biological', 'Biological Assay', 'Biology', 'Biotechnology', 'Catalysis', 'Cell Cycle', 'Cellular Assay', 'Chemicals', 'Chemistry', 'Color', 'Computer Vision Systems', 'Development', 'Drug Industry', 'Enzymes', 'Foundations', 'Funding', 'Genome', 'Genomics', 'Heterogeneity', 'Human', 'Human Genome', 'Image', 'Institutes', 'Interdisciplinary Study', 'Intracellular Membranes', 'Investments', 'Laboratories', 'Licensing', 'Location', 'Measures', 'Medicine', 'Methods', 'Microscope', 'Microscopy', 'Molecular', 'Molecular Profiling', 'Motion', 'Numbers', 'Optics', 'Organelles', 'Organism', 'Outcome', 'Pathway interactions', 'Pattern', 'Performance', 'Phase', 'Phenotype', 'Physiological', 'Price', 'Protein Dynamics', 'Proteins', 'Proteomics', 'Rate', 'Reader', 'Regulation', 'Reporting', 'Research', 'Resolution', 'Resources', 'Robotics', 'Running', 'Scanning', 'Scientist', 'Screening procedure', 'Slide', 'Speed', 'Surface', 'System', 'Technology', 'Time', 'Translating', 'United States National Institutes of Health', 'base', 'cellular imaging', 'charge coupled device camera', 'day', 'discount', 'drug discovery', 'fluorescence imaging', 'high throughput screening', 'instrument', 'instrumentation', 'knowledge base', 'protein protein interaction', 'prototype', 'receptor', 'research and development', 'response', 'small molecule libraries', 'software systems', 'success', 'tool']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2007,387827,0.006392716982402756
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7214118,R42ES013321,"['Accounting', 'Animals', 'Architecture', 'Biological Assay', 'Biological Neural Networks', 'Chemicals', 'Clinical', 'Clinical Trials', 'Computer Simulation', 'Computer software', 'Contracts', 'Data', 'Data Set', 'Data Storage and Retrieval', 'Databases', 'Development', 'Disease', 'Drug Formulations', 'Drug Industry', 'Drug toxicity', 'End Point', 'Expert Systems', 'Funding', 'Future', 'Fuzzy Logic', 'Gene Expression', 'Guidelines', 'Health Care Costs', 'Hepatotoxicity', 'Investments', 'Learning', 'Liver', 'Marketing', 'Methods', 'Network-based', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Process', 'Proteomics', 'Protocols documentation', 'Quantitative Structure-Activity Relationship', 'Rate', 'Relative (related person)', 'Reliance', 'Research', 'Research Personnel', 'Screening procedure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'Training', 'Validation', 'base', 'computational chemistry', 'cost', 'data acquisition', 'design', 'highly advanced system', 'improved', 'innovation', 'knowledge base', 'metabolomics', 'quantum', 'serial analysis of gene expression', 'subtraction hybridization', 'tool']",NIEHS,"YAHSGS, LLC",R42,2007,257269,0.009203520586970304
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7125135,R42ES013321,"['artificial intelligence', 'chemical structure function', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'drug discovery /isolation', 'drug screening /evaluation', 'functional /structural genomics', 'hepatotoxin', 'microarray technology', 'toxicant screening']",NIEHS,"YAHSGS, LLC",R42,2006,387181,0.009203520586970304
"High-throughput annotation of glycan mass spectra     DESCRIPTION (provided by applicant): The correct functioning of many proteins depends on glycosylation, the addition of sugar molecules (glycans) to selected amino acids in the protein. For example, cancer cells have different glycosylation patterns than ordinary cells, and there is strong evidence that glycoproteins on the surface of egg cells play an essential role in sperm binding. Despite the importance of glycosylation, there are as yet no reliable, high-throughput methods for determining the identity and location of glycans. Glycan identification is currently a manual procedure for experts, involving a combination of chemical assays and mass spectrometry. The automation of the process would have a significant impact on our understanding of this important biological process. The proposed project aims to invent chemical procedures, algorithms, and software for high-throughput analysis of glycan mass spectrometry data. The goal is to bring glycan analysis up to the level of peptide analysis within 3 years. In contrast to peptide analysis, which can leverage genomics data, glycan analysis requires the incorporation of expert knowledge of synthetic pathways, in order to limit the huge number of theoretical combinations of monosaccharides to the much smaller number that are actually synthesized in nature. The project will have to develop novel representations for the evolving expert knowledge, because an exhaustive list- analogous to the human genome- is not currently known. Along with expert knowledge, the project will develop and validate machine learning and statistical techniques for glycan identification. In particular, the project will develop methods for internally calibrating spectra, and will learn fragmentation patterns that can statistically distinguish different types of glycosidic linkages.         n/a",High-throughput annotation of glycan mass spectra,7071180,R01GM074128,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'chemical structure', 'chemical synthesis', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'glycosylation', 'high throughput technology', 'mass spectrometry', 'mathematics', 'matrix assisted laser desorption ionization', 'polysaccharides', 'structural biology', 'technology /technique development']",NIGMS,PALO ALTO RESEARCH CENTER,R01,2006,324279,0.06106288705164916
"Intelligent Aids for Proteomic Data Mining DESCRIPTION (provided by applicant): Primary purpose of this proposal is to provide the applicant with the means and structures for achieving two goals; (1) to develop intelligent computational aids for mining proteomic data accumulating from high throughput techniques like SELDI-TOF mass spectrometry; and (2) the long-term goal is to gain independence as a biomedical informatics researcher by developing methodological expertise in Bayesian methods and proteomic technologies. Applicant will obtain further instruction in probabilistic methods of data analysis; and she will receive education on proteomic technologies that are driving today's proteome research. Training will be provided through formal coursework, directed readings, seminars and conferences in addition to research directed by excellent mentors.  Applicant's research project involves a novel combination of techniques for use in proteomic data analysis. Previous research has included the use of techniques such as genetic algorithms and neural networks for analysis of proteomic data. These techniques were not explicitly designed to take into account background and prior knowledge. Hypothesis of this project is that background knowledge and machine learning techniques can positively influence the selection of appropriate biomarkers from proteomic data, enabling efficient and accurate analysis of massive datasets arising from proteomic profiling studies. Therefore, this project will satisfy four aims: (1) development of a wrapper-based machine learning tool; (2) augment the tool with prior knowledge such as heuristic rules and relationships in the data; (3) use these features along with de-identified patient information as input to classification systems; and (4) evaluate existing techniques for interpreting tandem mass spectrometry (MS-MS or MS/MS) data, and propose, implement and evaluate a Bayesian method for identification of peptides and proteins indicated by the MS-MS spectrum. n/a",Intelligent Aids for Proteomic Data Mining,7089794,K25GM071951,"['bioinformatics', 'biomarker', 'biotechnology', 'computer assisted sequence analysis', 'computer program /software', 'computer system design /evaluation', 'data management', 'diagnosis design /evaluation', 'genetic disorder diagnosis', 'human data', 'mass spectrometry', 'proteomics']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K25,2006,127449,0.03963693454784666
"Nanopore study of single antibody-antigen interactions DESCRIPTION:    Nanopore-based single-molecule detection has recently become established as a new tool in single molecule biophysics. Evidence is presented that single antibodies can be observed with a nanopore detector, which presents a wide range of possibilities for immunological research. The hypothesis to be tested is that nanopore-based detection can be used to study single molecule dynamics of antibody-antigen interaction and analyze conformational changes that occur in antibody upon binding to antigen. This application aims to develop the utility of the nanopore-based approach through improvements in both the detection device and the software used to extract information from the channel current signal. At the same time, these studies will allow the Candidate to gain expertise in immunology and the biophysical study of protein structure and function. To study the single molecule dynamics of antibody-antigen interaction, the following three specific aims are proposed:   1. Extend nanopore based detection to nanopore/antibody based detection.   2. Implement machine learning software for automated nanopore/antibody signal analysis and experimental feedback.   3. Use well-characterized, genetically engineered, antibodies to test the utility of the nanopore device to analyze motion in the antibody molecule.   These studies will expand the utility of nanopore devices to study single molecule protein interactions.   Information gained will lead to a better understanding of the molecular dynamics associated with antigen binding by antibody and the subsequent initiation of effector functions. Since most biological nanopore variants derive from pore-forming toxins, nanopore device enhancements eventually may lead to new methods for antibody and antimicrobial-peptide immunological screening. Antibody-based nanopore devices may also serve as highly sensitive immunosensors. n/a",Nanopore study of single antibody-antigen interactions,7119996,K22LM008794,"['antigen antibody reaction', 'bioinformatics', 'biomedical automation', 'computer program /software', 'computer system design /evaluation', 'intermolecular interaction', 'molecular dynamics', 'nanotechnology', 'pore forming protein', 'protein quantitation /detection']",NLM,CHILDREN'S HOSPITAL (NEW ORLEANS),K22,2006,162000,-0.012745889014542107
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7125565,R01EB006200,"['NIH Roadmap Initiative tag', 'bioimaging /biomedical imaging', 'biomedical equipment development', 'biotechnology', 'charge coupled device camera', 'computer program /software', 'computer system hardware', 'high throughput technology', 'image enhancement', 'robotics']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2006,399410,0.006392716982402756
"LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction    DESCRIPTION (provided by applicant): The high cost ($0.8 - $1.7 billion) and long time frames (about 13 years) required to introduce new drugs to the market contributes substantially to spiraling health care costs and diseases persisting without effective cures. A major factor is the high attrition rate of new compounds failing due to toxicity identified years into clinical trials. This particular circumstance cost the pharmaceutical industry approximately $8 billion in 2003. In silico tools generally offer the promise of identifying toxicity issues much more rapidly than clinical methods, however, they are not sufficiently accurate for pharmaceutical companies to confidently make definitive early screening and related investment decisions. LiverTox is a highly advanced, self-learning liver toxicity prediction tool that represents a quantum leap over current in silico methods. It offers a highly innovative use of multiple analytical approaches to accurately predict the toxicity of candidate Pharmaceuticals in the liver. A differentiating capability is its self-learning computational neural networks (CNNs) and wavelets. They rapidly assimilate massive volumes of information from LiverTox's extensive, dynamic, and thoroughly reviewed databases. Initially, LiverTox will generate predictions derived from five independent CNN-based submodules; one trained in advanced computational chemistry methods to make quantitative structure activity relationship (QSAR) analyses; a second trained with microarray data; a third trained with Massively Parallel Signature Sequencing and Gene Expression (MPSS/GE) data; and fourth and fifth submodules trained with proteomics and metabolomics/metabonomics data, respectively. Challenging LiverTox with new chemical formulations triggers the five independent submodules to each make toxicity endpoint predictions drawing upon its knowledge base and its similarity analysis/fuzzy logic/statistical training. This tool's flexible, highly advanced system architecture and advanced learning capabilities using data obtained from diverse techniques enable it to rapidly digest new data, build upon new data acquisition techniques, and use prior lessons learned to achieve overall toxicity predictions with greater than 95% accuracy. LiverTox's ability to rapidly and accurately predict the toxicity of drug candidates will allow pharmaceutical companies to move from discovery to curing disease faster, at greatly reduced cost, and with less reliance on animal-based tests.         n/a",LiverTox: Advanced QSAR and Toxicogenomic Software for Hepatoxicity Prediction,7052491,R42ES013321,"['artificial intelligence', 'chemical structure function', 'computer data analysis', 'computer program /software', 'computer system design /evaluation', 'drug discovery /isolation', 'drug screening /evaluation', 'functional /structural genomics', 'hepatotoxin', 'microarray technology', 'toxicant screening']",NIEHS,"YAHSGS, LLC",R42,2005,180862,0.009203520586970304
"High-throughput annotation of glycan mass spectra     DESCRIPTION (provided by applicant): The correct functioning of many proteins depends on glycosylation, the addition of sugar molecules (glycans) to selected amino acids in the protein. For example, cancer cells have different glycosylation patterns than ordinary cells, and there is strong evidence that glycoproteins on the surface of egg cells play an essential role in sperm binding. Despite the importance of glycosylation, there are as yet no reliable, high-throughput methods for determining the identity and location of glycans. Glycan identification is currently a manual procedure for experts, involving a combination of chemical assays and mass spectrometry. The automation of the process would have a significant impact on our understanding of this important biological process. The proposed project aims to invent chemical procedures, algorithms, and software for high-throughput analysis of glycan mass spectrometry data. The goal is to bring glycan analysis up to the level of peptide analysis within 3 years. In contrast to peptide analysis, which can leverage genomics data, glycan analysis requires the incorporation of expert knowledge of synthetic pathways, in order to limit the huge number of theoretical combinations of monosaccharides to the much smaller number that are actually synthesized in nature. The project will have to develop novel representations for the evolving expert knowledge, because an exhaustive list- analogous to the human genome- is not currently known. Along with expert knowledge, the project will develop and validate machine learning and statistical techniques for glycan identification. In particular, the project will develop methods for internally calibrating spectra, and will learn fragmentation patterns that can statistically distinguish different types of glycosidic linkages.         n/a",High-throughput annotation of glycan mass spectra,6916805,R01GM074128,"['artificial intelligence', 'bioinformatics', 'biomedical automation', 'chemical structure', 'chemical synthesis', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'glycosylation', 'high throughput technology', 'mass spectrometry', 'mathematics', 'matrix assisted laser desorption ionization', 'polysaccharides', 'structural biology', 'technology /technique development']",NIGMS,PALO ALTO RESEARCH CENTER,R01,2005,353067,0.06106288705164916
"Intelligent Aids for Proteomic Data Mining DESCRIPTION (provided by applicant): Primary purpose of this proposal is to provide the applicant with the means and structures for achieving two goals; (1) to develop intelligent computational aids for mining proteomic data accumulating from high throughput techniques like SELDI-TOF mass spectrometry; and (2) the long-term goal is to gain independence as a biomedical informatics researcher by developing methodological expertise in Bayesian methods and proteomic technologies. Applicant will obtain further instruction in probabilistic methods of data analysis; and she will receive education on proteomic technologies that are driving today's proteome research. Training will be provided through formal coursework, directed readings, seminars and conferences in addition to research directed by excellent mentors.  Applicant's research project involves a novel combination of techniques for use in proteomic data analysis. Previous research has included the use of techniques such as genetic algorithms and neural networks for analysis of proteomic data. These techniques were not explicitly designed to take into account background and prior knowledge. Hypothesis of this project is that background knowledge and machine learning techniques can positively influence the selection of appropriate biomarkers from proteomic data, enabling efficient and accurate analysis of massive datasets arising from proteomic profiling studies. Therefore, this project will satisfy four aims: (1) development of a wrapper-based machine learning tool; (2) augment the tool with prior knowledge such as heuristic rules and relationships in the data; (3) use these features along with de-identified patient information as input to classification systems; and (4) evaluate existing techniques for interpreting tandem mass spectrometry (MS-MS or MS/MS) data, and propose, implement and evaluate a Bayesian method for identification of peptides and proteins indicated by the MS-MS spectrum. n/a",Intelligent Aids for Proteomic Data Mining,6915489,K25GM071951,"['bioinformatics', 'biomarker', 'biotechnology', 'computer assisted sequence analysis', 'computer program /software', 'computer system design /evaluation', 'data management', 'diagnosis design /evaluation', 'genetic disorder diagnosis', 'human data', 'mass spectrometry', 'proteomics']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K25,2005,123942,0.03963693454784666
"Proteomics processing using networked instrument router* DESCRIPTION (provided by applicant):  Real-time, distributed decision-making and data-processing has become necessary as high-throughput proteomics across geographic boundaries becomes more mature. The most common instrument used to characterize and analyze proteins is the Mass Spectrometer. As more Mass Spectrometers are used in parallel to create a high-throughput proteomics system, the data processing needs grow exponentially. Using a cluster of low-cost instrument routers, developed at Userspace Corporation, the goal for this project is to divide the data processing tasks into a decision tree, which converts sequential tasking into parallel tasking or multi-threaded algorithms. These instruments can be controlled and the algorithms can independently process data in parallel or offline as they emerge in large data sets from one or many Mass Spectrometers. The First Phase of study will use an LC-MS (Liquid Chromatography - Mass Spectroscopy) system that uses the ICAT (Isotope Coded Affinity Tags) technology developed at the lab of Dr. Ruedi Aebersold at the University of Washington (who is also the co-founder of the Institute for Systems Biology: ISB). The data from the Mass Spectrometers is analyzed using the COMET algorithm, also developed at the ISB. Userspace Corporation and ISB are collaborating on using Userspace's routers and framework in its Proteomics lab.      The first phase of this project will evaluate technologies and configuration required to process Mass Spectrometry data at the instrument level using a distributed network of the Userspace wireless instrument routers. The data will be processed in real-time as it becomes available to the router cluster and a rule-based decision matrix. The duration of this phase will be six months. The next phases would involve improving the data formatting, so that publication and data mining become science-centric and in a standardized XML (eXtensible Markup Language) representation. Other instruments, algorithms and processes will be added to the router library. n/a",Proteomics processing using networked instrument router*,6955044,R43AA014558,"['automated data processing', 'biotechnology', 'computer network', 'computer system design /evaluation', 'high throughput technology', 'mass spectrometry', 'parallel processing', 'proteomics']",NIAAA,USERSPACE CORPORATION,R43,2005,226700,0.04158952394859312
"Nanopore study of single antibody-antigen interactions DESCRIPTION:    Nanopore-based single-molecule detection has recently become established as a new tool in single molecule biophysics. Evidence is presented that single antibodies can be observed with a nanopore detector, which presents a wide range of possibilities for immunological research. The hypothesis to be tested is that nanopore-based detection can be used to study single molecule dynamics of antibody-antigen interaction and analyze conformational changes that occur in antibody upon binding to antigen. This application aims to develop the utility of the nanopore-based approach through improvements in both the detection device and the software used to extract information from the channel current signal. At the same time, these studies will allow the Candidate to gain expertise in immunology and the biophysical study of protein structure and function. To study the single molecule dynamics of antibody-antigen interaction, the following three specific aims are proposed:   1. Extend nanopore based detection to nanopore/antibody based detection.   2. Implement machine learning software for automated nanopore/antibody signal analysis and experimental feedback.   3. Use well-characterized, genetically engineered, antibodies to test the utility of the nanopore device to analyze motion in the antibody molecule.   These studies will expand the utility of nanopore devices to study single molecule protein interactions.   Information gained will lead to a better understanding of the molecular dynamics associated with antigen binding by antibody and the subsequent initiation of effector functions. Since most biological nanopore variants derive from pore-forming toxins, nanopore device enhancements eventually may lead to new methods for antibody and antimicrobial-peptide immunological screening. Antibody-based nanopore devices may also serve as highly sensitive immunosensors. n/a",Nanopore study of single antibody-antigen interactions,6959048,K22LM008794,"['antigen antibody reaction', 'bioinformatics', 'biomedical automation', 'computer program /software', 'computer system design /evaluation', 'intermolecular interaction', 'molecular dynamics', 'nanotechnology', 'pore forming protein', 'protein quantitation /detection']",NLM,CHILDREN'S HOSPITAL (NEW ORLEANS),K22,2005,162000,-0.012745889014542107
"Continuous-Imaging HT Screening Instrument(RMI) DESCRIPTION (provided by applicant): Completion of the genomes of humans and several other organisms creates the foundation for translating this rich knowledge base into new products for the improvement of human medicine. A critical component of realizing the promise of genomics efforts is access to well-characterized chemical compounds that bind to and alter the activities of specific gene products. To this end, modern technologies for genome-wide expression profiling and high throughput proteomics provide the enabling foundation for large-scale chemical biology initiatives, using chemical compounds as discovery tools to probe biological pathways, thereby revealing new protein targets that alter cellular phenotypes in potentially beneficial or insightful ways. It is becoming recognized that many critical points of biological pathway regulation are predicated on protein-protein interactions rather than enzyme-based catalysis of cellular products to substrates. Thus, traditional methods of drug discovery are limited in the scope of targets they can adequately address.   Screening scientists are finding that elucidation of cellular responses to chemical compounds at critical points of biological pathway regulation can be enabled by image-based cellular assays that automatically measure protein dynamics via computer vision of pattern and organelle translocations. Subunits of membrane and intracellular receptors often respond by reorganization or translocation. In addition, cellular heterogeneities that are both physiological (e.g., cell division cycle phase-specific) or apparently random can overwhelm whole-well conventional high throughput screening HTS readouts. These are examples of the ways that cell-image-based instruments can dramatically increase the information content of automated assays. The drawback of cell-image-based screening has been that instruments imaging at medium microscopy resolution (approximately 0.5 - 2.0 mu/m with 10-40x objectives) are typically limited to about 25,000 wells per day as compared with rates of 100,000 or more wells/per day for HTS conventional whole-well plate-reader HTS systems. While higher rates have been reported, these increases have been typically achieved by sacrificing resolution (e.g., even lower magnification objectives or substantial camera binning).   Here we propose to increase the fundamental image scanning bandwidth (measured in pixels/s) by 10- fold over the current Beckman Coulter IC-100 instrument, the prototype of which was developed in Dr. Price's academic laboratory and first commercialized by Q3DM Inc. This increase will be gained by application of fundamentally new principles that parallelize auto-focus and image acquisition to scan slides and microtiter plates in long, unbroken continuous-motion multi-color strips. This will result in screening speeds of over 100,000 wells per day using medium resolution objectives (10-40x dry magnification). n/a",Continuous-Imaging HT Screening Instrument(RMI),7012638,R01EB006200,"['bioimaging /biomedical imaging', 'biomedical equipment development', 'biotechnology', 'charge coupled device camera', 'computer program /software', 'computer system hardware', 'high throughput technology', 'image enhancement', 'robotics']",NIBIB,SANFORD-BURNHAM MEDICAL RESEARCH INSTIT,R01,2005,363523,0.006392716982402756
"Use of Microarray Test Data for Toxicogenomic Prediction    DESCRIPTION (provided by applicant):    This project bridges the understanding between physical and chemical principles and genomic/proteomic response by integrating three independent parallel toxicity prediction tools. Each uses computational neural networks (CNNs) and wavelets to rapidly and accurately make pharmaceutical/chemical toxicity predictions. A CNN-based Quantitative Structure-Activity Relationship (QSAR) module makes toxicological predictions based only on structure-activity analyses; a second CNN/wavelet module makes independent toxicogenomic predictions using microarray data; and a third CNN/wavelet module makes toxicogenomic predictions using Massively Parallel Signature Sequencing (MPSS) data. This multi-intelligent, three-module approach provides crosschecks to reduce false positives and false negatives while substantially increasing confidence in predictions relative to current computer-based toxicity prediction techniques. The resulting product could potentially become a primary tool used by (a) human health researchers, b) pharmaceutical companies for screening drugs early during development, c) companies designing/developing new chemicals and chemically treated materials, and (d) government organizations (e.g., military) for mission-related chemical deployments. Public benefits include reduced health and environmental risks (e.g., 4 out of 5 chemicals in use today have inadequate testing); reduced reliance on animal testing; and reduced time and cost required to bring new pharmaceuticals and chemicals into beneficial medical and commercial use.            n/a",Use of Microarray Test Data for Toxicogenomic Prediction,6743871,R41ES013321,"['computational neuroscience', 'computer data analysis', 'evaluation /testing', 'method development', 'microarray technology', 'polymerase chain reaction', 'toxicant screening', 'toxicology']",NIEHS,"YAHSGS, LLC",R41,2004,211770,0.030508246856727213
"Intelligent Aids for Proteomic Data Mining DESCRIPTION (provided by applicant): Primary purpose of this proposal is to provide the applicant with the means and structures for achieving two goals; (1) to develop intelligent computational aids for mining proteomic data accumulating from high throughput techniques like SELDI-TOF mass spectrometry; and (2) the long-term goal is to gain independence as a biomedical informatics researcher by developing methodological expertise in Bayesian methods and proteomic technologies. Applicant will obtain further instruction in probabilistic methods of data analysis; and she will receive education on proteomic technologies that are driving today's proteome research. Training will be provided through formal coursework, directed readings, seminars and conferences in addition to research directed by excellent mentors.  Applicant's research project involves a novel combination of techniques for use in proteomic data analysis. Previous research has included the use of techniques such as genetic algorithms and neural networks for analysis of proteomic data. These techniques were not explicitly designed to take into account background and prior knowledge. Hypothesis of this project is that background knowledge and machine learning techniques can positively influence the selection of appropriate biomarkers from proteomic data, enabling efficient and accurate analysis of massive datasets arising from proteomic profiling studies. Therefore, this project will satisfy four aims: (1) development of a wrapper-based machine learning tool; (2) augment the tool with prior knowledge such as heuristic rules and relationships in the data; (3) use these features along with de-identified patient information as input to classification systems; and (4) evaluate existing techniques for interpreting tandem mass spectrometry (MS-MS or MS/MS) data, and propose, implement and evaluate a Bayesian method for identification of peptides and proteins indicated by the MS-MS spectrum. n/a",Intelligent Aids for Proteomic Data Mining,6811846,K25GM071951,"['bioinformatics', 'biomarker', 'biotechnology', 'computer assisted sequence analysis', 'computer program /software', 'computer system design /evaluation', 'data management', 'diagnosis design /evaluation', 'genetic disorder diagnosis', 'human data', 'mass spectrometry', 'proteomics']",NIGMS,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,K25,2004,122697,0.03963693454784666
"Proteomics processing using networked instrument router DESCRIPTION (provided by applicant):  Real-time, distributed decision-making and data-processing has become necessary as high-throughput proteomics across geographic boundaries becomes more mature. The most common instrument used to characterize and analyze proteins is the Mass Spectrometer. As more Mass Spectrometers are used in parallel to create a high-throughput proteomics system, the data processing needs grow exponentially. Using a cluster of low-cost instrument routers, developed at Userspace Corporation, the goal for this project is to divide the data processing tasks into a decision tree, which converts sequential tasking into parallel tasking or multi-threaded algorithms. These instruments can be controlled and the algorithms can independently process data in parallel or offline as they emerge in large data sets from one or many Mass Spectrometers. The First Phase of study will use an LC-MS (Liquid Chromatography - Mass Spectroscopy) system that uses the ICAT (Isotope Coded Affinity Tags) technology developed at the lab of Dr. Ruedi Aebersold at the University of Washington (who is also the co-founder of the Institute for Systems Biology: ISB). The data from the Mass Spectrometers is analyzed using the COMET algorithm, also developed at the ISB. Userspace Corporation and ISB are collaborating on using Userspace's routers and framework in its Proteomics lab.      The first phase of this project will evaluate technologies and configuration required to process Mass Spectrometry data at the instrument level using a distributed network of the Userspace wireless instrument routers. The data will be processed in real-time as it becomes available to the router cluster and a rule-based decision matrix. The duration of this phase will be six months. The next phases would involve improving the data formatting, so that publication and data mining become science-centric and in a standardized XML (eXtensible Markup Language) representation. Other instruments, algorithms and processes will be added to the router library. n/a",Proteomics processing using networked instrument router,6702436,R43AA014558,"['automated data processing', 'biotechnology', 'computer network', 'computer system design /evaluation', 'high throughput technology', 'mass spectrometry', 'parallel processing', 'proteomics']",NIAAA,USERSPACE CORPORATION,R43,2004,194000,0.04158952394859312
"A Novel Probabilistic Engine for Virtual Screening DESCRIPTION (provided by applicant): The goal of this work is to provide a novel probabilistic computational engine for docking-based virtual screening. The engine is based on probabilistic model of Markov Random Fieds (MRF). MRF's have proven successful in other fields such as Computer Vision, and can be seen as a 3D analog of the successful 1D application of Hidden Markov Models to bioinformatics. The docking of a rigid ligand or ligand fragment into a protein active site is modeled as a weighted graphical match of an abstracted description of the ligand to an abstracted description of the active site. These abstracted descriptions are graphs, whose nodes are chemical entities (hydrogen bond acceptors/donors, hydrophobic spheres and etc.) and whose edges are associated distance constraints. The weighted graph-matching problem is expressed as an MRF, whose solution minimizes its associated free energy function. A fast, convergent message-passing scheme called Belief Propagation is used to solve the MRF. The result is a probability distribution that describes all possible placements of the ligand into the active site. Individual low-energy placements of the molecule are obtained by marginalizing this probability distribution. The method provides a fast and mathematically complete examination of possible fits of the ligand into the protein active site, and our prototype MRF application demonstrates excellent timing and completeness properties. The method also provides an attractive data structure enabling a variety of applications. The data structure intrinsically admits an enriched description of the active site. This description can incorporate an extended set of chemical substructures for matching at its nodes. It also can incorporate sets of probabilistic beliefs, expressed as probabilistic prior distributions. These can be used to bias matches according to known actives. Our goals in Phase I are to further develop our prototype into a robust MRF-based docking engine to positioning rigid molecules and molecular fragments into protein active sites. Our goals in Phase II will be to implement applications based on the MRF docking engine: (i) inclusion flexible ligand docking, (ii) incorporation of flexible side chains into docking, (iii) de-novo ligand design, and (iv) docking into multiple aligned proteins. We will seek corporate partners interested in collaborating on applying the technologies to specific problems in drug discovery in Phase I1. The technology developed will be sold as commercial software in Phase III. n/a",A Novel Probabilistic Engine for Virtual Screening,6786885,R43GM071055,"['binding sites', 'computational biology', 'computer program /software', 'computer system design /evaluation', 'ligands', 'statistics /biometry']",NIGMS,"BIOCOMPUTING GROUP, INC.",R43,2004,153420,-0.027653678956597188
"Ab-Initio Geometry Optimization of Large Molecules    DESCRIPTION (provided by applicant):  While density-functional calculations of the energy are now feasible for biomolecules, the use of density-functional geometry optimizers is still confined to relatively small molecules containing no more than thirty atoms. The key limitation of conventional density-functional geometry optimizers is that the cost of the geometry optimization scales at least quadratically with the number of atoms in the molecule. In contrast the energy at a fixed geometry can be evaluated for a cost which scales linearly with molecule size, enabling very large molecules to be treated. This proposal is based on a radical change in the algorithm for density-functional geometry optimization, potentially reducing the total cost from quadratic to linear in molecule size and enabling a quantum leap in the size of molecules that can be optimized. The proposed algorithm resembles a conventional self-consistent calculation of the energy at a fixed geometry but at convergence the proposed algorithm yields not only the density but also the optimized geometry. This is achieved by simultaneous optimization of the wavefunction and the geometry via a modified self-consistent-field procedure. The proposed algorithm will be implemented in the QChem software package and, if successful, widely distributed through QChem Inc. and Spartan Inc.           n/a",Ab-Initio Geometry Optimization of Large Molecules,6583907,R43GM067335,"['artificial intelligence', ' chemical models', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' mathematics', ' molecular dynamics', ' molecular size', ' quantum chemistry']",NIGMS,"Q-CHEM, INC.",R43,2003,99639,0.013684656353697798
"INTEGRATED STRUCTURES FOR PROTEIN MASS SPECTRAL ANALYSIS  APPLICANT'S DESCRIPTION: The proposed research will develop a new technology         for highly automated and highly sensitive analytical systems for the protein         components of complex biological systems. The technology will combine                multi-step sample processes in silicon chip formats with highly sophisticated        tandem mass spectrometry analyses. Micromachining methods that have already          been successful in producing chambers, channels, check valves, filters and           electrospray emitters will be extended to include active valves and                  micro-pumps. The methodologies needed to place chemical systems within the           chip-based structures to perform affinity isolations, enzyme digestions, and         chromatographic and/or electrophoretic separations will be developed. By             combining these operations in a single microscale device, the sample losses in       going from one step to the next will be avoided. These chip-based sample             preparation systems will be interfaced to ion trap mass analyzers capable of         multiple stages of tandem MS analysis. Control of both the on-chip processes         and the MS analysis will be accomplished using a single expert system program.       This program has the capability of analyzing data in real time and changing the      course of the analysis according to a predefined set of rules. The net result        will be a much more efficient and comprehensive method of collecting data, thus      minimizing the amount of time and sample needed. Applications of the new             technology will focus on the characterization of protein posttranslational           modifications with initial emphasis on sites of phosphorylation. The principal       goal of this research is to package very sophisticated analytical tools and          expertise in a form that can be readily exported to other laboratories.              n/a",INTEGRATED STRUCTURES FOR PROTEIN MASS SPECTRAL ANALYSIS,6639848,R01RR006217,"['analytical method', ' artificial intelligence', ' biomedical equipment development', ' computer system design /evaluation', ' electrospray ionization mass spectrometry', ' liquid chromatography', ' microprocessor /microchip', ' phosphorylation', ' posttranslational modifications', ' protein protein interaction', ' technology /technique development']",NCRR,CITY OF HOPE/BECKMAN RESEARCH INSTITUTE,R01,2003,463130,0.022505317699946775
"MCASE QSAR Expert System for Salmonella Mutagenicity   DESCRIPTION (provided by applicant): Computational expert systems provide an         inexpensive and fast alternative to short term genotoxicity assays such as the       Ames test. Validation studies show the predictive capability of the MCASE            system is about 85 percent. That is, 85 percent concordance is expected between      experiment and computational genotoxicity predictions for new chemicals. The         strong correlation between chemical structure and genotoxicity is particularly       useful for 'in silico' prescreening of new drugs in the pharmaceutical               industry.                                                                                                                                                                 The new Salmonella database modules being developed in this work will be made        available online to the public through the InfoTox web site                          (http://www.l-tox.com). Additionally, NIH grantees will be allowed unlimited         access to the Salmonella modules through InfoTox at no cost.                                                                                                              Collaboration will be sought with large drug companies, with mutual exchange of      data. Thus the databases will evolve and improve over time as new data are           submitted to form a centralized pool of mutagenicity data, that will provide a       resource for avoiding unneeded testing of chemicals structurally similarly to        those that are already thoroughly understood. Our collaborators at the FDA/CDER      will lead the effort to build this industrial consortium.                            PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                                                   n/a",MCASE QSAR Expert System for Salmonella Mutagenicity,6625981,R44CA090178,"['Salmonella typhimurium', ' alternatives to animals in research', ' artificial intelligence', ' chemical information system', ' chemical property', ' chemical structure function', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data collection', ' gene mutation', ' high throughput technology', ' informatics', ' mathematical model', ' mutagen testing', ' mutagens', ' physical property', ' statistics /biometry', ' toxicology']",NCI,"MULTICASE, INC.",R44,2003,278750,0.014025575346812213
"Toxicological Evaluation Neuralnet Tools (TENT)  DESCRIPTION (provided by applicant):  YAHSGS' Toxicological Evaluation Neuralnet Tools (TEND is designed to advance the state-of-the-art in the prediction of toxicological end points for new or untested chemicals, drugs, and compounds. TENT deploys computational neural nets (CNN), innovative computational chemistry methods, and modem statistical regression methods into interactive modules that determine (a) a chemical's 3-D structure and physical chemistry properties, (b) Quantitative Structure Activity Relationships, (C) mechanistic modes leading to toxicological responses via microassay database analysis, and (d) a broad spectrum of toxicological properties via CNN 3-D structural similarity analyses. TENTs output includes physical chemistry properties, 3-D structure, predicted toxicological impacts, and confidence level associated with each. It is anticipated that TENT will become one of the primary tools used by (a) researchers in human health and toxicological fields, (b) pharmaceutical companies to screen out drugs early in the development process prior to expending hundreds of millions on clinical in vivo and in vitro testing, (C) by companies developing new chemicals, chemical compounds, and chemically treated materials to determine potential toxicological impacts including those caused by environmental changes during and after usage, (d) companies striving to show compliance with ISO 14000 for materials used in their products, and (e) federal and military organizations for chemicals and materials contemplated for use in their mission areas. Industry experts predict that the market for TENT-type tools and applications will reach $8 -$10 billion by 2006 and three times that amount by 2016. The benefits that the US should receive from TENT could include (a) a greatly enhanced understanding of potential toxicological impacts from pharmaceuticals, chemicals, and chemically treated materials (4 out of 5 chemicals in industrial use currently have not undergone adequate testing due to time and expense), (b) companies will avoid billions of dollars in clinical testing for chemicals and drugs that ultimately fail (the funds saved can be applied to the development of new and better materials that help mankind and the environment that might otherwise go unfunded), and (c) TENT can substantially reduce the number of laboratory animals used for clinical testing.   n/a",Toxicological Evaluation Neuralnet Tools (TENT),6550075,R43ES011918,"['alternatives to animals in research', ' chemical structure function', ' computational neuroscience', ' computer program /software', ' computer simulation', ' method development', ' microarray technology', ' molecular dynamics', ' neurotoxicology', ' statistics /biometry', ' three dimensional imaging /topography', ' toxicant screening']",NIEHS,"YAHSGS, LLC",R43,2003,84450,0.009817535089618553
"Improving Quantum Chemistry Calculations DESCRIPTION (provided by applicant): We propose to extend the functionality of our commercial quantum chemistry program, Q-Chem, to effectively treat molecules containing transition metals. This enhanced capability will provide Q-Chem's end-users with the ability to accurately model complex molecules such as proteins, enzymes, and catalysts of industrial importance. While remarkable progress has been made over the last several years in the accurate modeling of systems containing transition metals, current numerical methods for achieving SCF convergence in these systems are problematic at best, resulting in long execution times or, in some cases, complete failure to find a solution. However, a novel computational technique developed at Q-Chem has been shown to dramatically improve convergence for organic molecules with known SCF convergence problems. We propose to adapt this method for use with transition metals. Our goal is to achieve the same robust SCF convergence that is realized for most organic molecules, thereby greatly increasing productivity and extending the capability of scientists to study molecules such as enzymes and industrial catalysts. During Phase (I, our efforts will be to further extend Q-Chem's capability in the molecular biology arena. This proposal seeks to improve the quantum chemical treatment of molecular systems containing transition metals. Transition metal elements are essential to natural biological processes. The technology developed in this research will enable the computer modeling of those systems that are difficult to handle with the current methodologies and therefore increase of the applications of computational modeling. PROPOSED COMMERCIAL APPLICATION: Transition-metal elements play a vital role in biological systems.  The success of this project will improve the performance of modeling of transition-metal complexes and making the modelings possible for the systems that current algorithms fail.  The resulting work will be made available to researchers in health industry and universities through our commercial software Q-Chem. n/a",Improving Quantum Chemistry Calculations,6484828,R43GM065617,"['artificial intelligence', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' heavy metals', ' mathematical model', ' mathematics', ' model design /development', ' quantum chemistry']",NIGMS,"Q-CHEM, INC.",R43,2002,109642,0.008753297821767099
"INTEGRATED STRUCTURES FOR PROTEIN MASS SPECTRAL ANALYSIS  APPLICANT'S DESCRIPTION: The proposed research will develop a new technology         for highly automated and highly sensitive analytical systems for the protein         components of complex biological systems. The technology will combine                multi-step sample processes in silicon chip formats with highly sophisticated        tandem mass spectrometry analyses. Micromachining methods that have already          been successful in producing chambers, channels, check valves, filters and           electrospray emitters will be extended to include active valves and                  micro-pumps. The methodologies needed to place chemical systems within the           chip-based structures to perform affinity isolations, enzyme digestions, and         chromatographic and/or electrophoretic separations will be developed. By             combining these operations in a single microscale device, the sample losses in       going from one step to the next will be avoided. These chip-based sample             preparation systems will be interfaced to ion trap mass analyzers capable of         multiple stages of tandem MS analysis. Control of both the on-chip processes         and the MS analysis will be accomplished using a single expert system program.       This program has the capability of analyzing data in real time and changing the      course of the analysis according to a predefined set of rules. The net result        will be a much more efficient and comprehensive method of collecting data, thus      minimizing the amount of time and sample needed. Applications of the new             technology will focus on the characterization of protein posttranslational           modifications with initial emphasis on sites of phosphorylation. The principal       goal of this research is to package very sophisticated analytical tools and          expertise in a form that can be readily exported to other laboratories.              n/a",INTEGRATED STRUCTURES FOR PROTEIN MASS SPECTRAL ANALYSIS,6540576,R01RR006217,"['analytical method', ' artificial intelligence', ' biomedical equipment development', ' computer system design /evaluation', ' electrospray ionization mass spectrometry', ' liquid chromatography', ' microprocessor /microchip', ' phosphorylation', ' posttranslational modifications', ' protein protein interaction', ' technology /technique development']",NCRR,CITY OF HOPE/BECKMAN RESEARCH INSTITUTE,R01,2002,449674,0.022505317699946775
"MCASE QSAR Expert System for Salmonella Mutagenicity   DESCRIPTION (provided by applicant): Computational expert systems provide an         inexpensive and fast alternative to short term genotoxicity assays such as the       Ames test. Validation studies show the predictive capability of the MCASE            system is about 85 percent. That is, 85 percent concordance is expected between      experiment and computational genotoxicity predictions for new chemicals. The         strong correlation between chemical structure and genotoxicity is particularly       useful for 'in silico' prescreening of new drugs in the pharmaceutical               industry.                                                                                                                                                                 The new Salmonella database modules being developed in this work will be made        available online to the public through the InfoTox web site                          (http://www.l-tox.com). Additionally, NIH grantees will be allowed unlimited         access to the Salmonella modules through InfoTox at no cost.                                                                                                              Collaboration will be sought with large drug companies, with mutual exchange of      data. Thus the databases will evolve and improve over time as new data are           submitted to form a centralized pool of mutagenicity data, that will provide a       resource for avoiding unneeded testing of chemicals structurally similarly to        those that are already thoroughly understood. Our collaborators at the FDA/CDER      will lead the effort to build this industrial consortium.                            PROPOSED COMMERCIAL APPLICATION: NOT AVAILABLE                                                                                                                   n/a",MCASE QSAR Expert System for Salmonella Mutagenicity,6481789,R44CA090178,"['Salmonella typhimurium', ' alternatives to animals in research', ' artificial intelligence', ' chemical information system', ' chemical property', ' chemical structure function', ' computer program /software', ' computer simulation', ' computer system design /evaluation', ' data collection', ' gene mutation', ' high throughput technology', ' informatics', ' mathematical model', ' mutagen testing', ' mutagens', ' physical property', ' statistics /biometry', ' toxicology']",NCI,"MULTICASE, INC.",R44,2002,359495,0.014025575346812213
"INTEGRATED STRUCTURES FOR PROTEIN MASS SPECTRAL ANALYSIS  APPLICANT'S DESCRIPTION: The proposed research will develop a new technology         for highly automated and highly sensitive analytical systems for the protein         components of complex biological systems. The technology will combine                multi-step sample processes in silicon chip formats with highly sophisticated        tandem mass spectrometry analyses. Micromachining methods that have already          been successful in producing chambers, channels, check valves, filters and           electrospray emitters will be extended to include active valves and                  micro-pumps. The methodologies needed to place chemical systems within the           chip-based structures to perform affinity isolations, enzyme digestions, and         chromatographic and/or electrophoretic separations will be developed. By             combining these operations in a single microscale device, the sample losses in       going from one step to the next will be avoided. These chip-based sample             preparation systems will be interfaced to ion trap mass analyzers capable of         multiple stages of tandem MS analysis. Control of both the on-chip processes         and the MS analysis will be accomplished using a single expert system program.       This program has the capability of analyzing data in real time and changing the      course of the analysis according to a predefined set of rules. The net result        will be a much more efficient and comprehensive method of collecting data, thus      minimizing the amount of time and sample needed. Applications of the new             technology will focus on the characterization of protein posttranslational           modifications with initial emphasis on sites of phosphorylation. The principal       goal of this research is to package very sophisticated analytical tools and          expertise in a form that can be readily exported to other laboratories.              n/a",INTEGRATED STRUCTURES FOR PROTEIN MASS SPECTRAL ANALYSIS,6333670,R01RR006217,"['analytical method', ' artificial intelligence', ' biomedical equipment development', ' computer system design /evaluation', ' electrospray ionization mass spectrometry', ' liquid chromatography', ' microprocessor /microchip', ' phosphorylation', ' posttranslational modifications', ' protein protein interaction', ' technology /technique development']",NCRR,CITY OF HOPE/BECKMAN RESEARCH INSTITUTE,R01,2001,455361,0.022505317699946775
"Multimodal Machine-Learning and High Performance Computing Strategies for Big MS Proteomics Data Project Abstract/Summary Mass spectrometry (MS) data is high-dimensional data that is used for large-scale system biology proteomics. The current state of the art mass spectrometers can generate thousands of spectra from a single organism and experiment. This high-dimensional data is processed using database searches and denovo algorithms with varying degrees of success. The overarching objective of this study is to develop, test, integrate and evaluate novel image-processing and deep-learning algorithms that will allow us to deduce and identify reliable peptide sequences in a definitive and quantitative fashion. Our long-term goal is to improve on identification of MS based proteomics data using novel and scalable algorithms. The objective of this proposal is to investigate, design and implement machine-learning deep-learning algorithms for identification of peptides from MS data. Since deep-learning is very good at discovering intricate structures in high-dimensional data it will be ideal solution for discovering dark proteomics data and more accurate deduction of peptides. We predict that the integration of these methods, along with traditional numerical algorithms, will lead to a multimodal fusion-based approach for an optimized and accurate peptide deduction system for large-scale MS data. Further, we will design and implement data augmentation, memory-efficient indexing, and high-performance computing (HPC) to achieve these outcomes more efficiently with a shorter computational time. Therefore, this new line of investigation is significant since it has the potential to improve on long-stalled effort to increase accuracy, reliability and reproducibility of MS data analysis and search tools. The proximate expected outcome of this work is a novel set of deep-learning and image-processing tools which will allow much better insight in MS based proteomics data. The results will have an important positive impact immediately because these proposed research tasks will lay the groundwork to develop a new class of algorithms and will provide rapid, high-throughput, sensitive, and reproducible and reliable tools for MS based proteomics. Project Narrative The proposed research is relevant to public health because understanding Mass Spectrometry (MS) based proteomics can allow systematic analysis of thousands of proteins with the promise of discovering new protein biomarkers for different disease conditions and better understanding of human systems biology. Because of high-dimensionality of the big data generated from MS machines efficient, accurate and reproducible tools are required to mine and analyze the data and is the subject of this proposal. Such high-performance tools will be instrumental in elucidating the microbiome which affects virtually all aspects of human health. Therefore, this proposal is relevant to NIH’s broader mission which support fundamental and innovative research strategies which can become the basis of protecting and improving human health.",Multimodal Machine-Learning and High Performance Computing Strategies for Big MS Proteomics Data,9973317,R01GM134384,"['Affect', 'Algorithms', 'Architecture', 'Big Data', 'Classification', 'Communities', 'Computational Technique', 'Computer Vision Systems', 'Data', 'Data Analyses', 'Databases', 'Deductibles', 'Development', 'Disease', 'Ensure', 'Galaxy', 'Goals', 'Health', 'High Performance Computing', 'Human', 'Investigation', 'Lead', 'Machine Learning', 'Mass Spectrum Analysis', 'Memory', 'Methods', 'Mission', 'Modeling', 'Names', 'Organism', 'Outcome', 'Peptides', 'Performance', 'Post-Translational Protein Processing', 'Process', 'Proteins', 'Proteomics', 'Public Health', 'Reproducibility', 'Research', 'Resolution', 'Sample Size', 'Sampling', 'Structure', 'System', 'Systems Biology', 'Techniques', 'Testing', 'Time', 'Training', 'United States National Institutes of Health', 'Work', 'algorithmic methodologies', 'base', 'cyber infrastructure', 'data acquisition', 'deep learning', 'deep learning algorithm', 'design', 'experimental study', 'high dimensionality', 'image processing', 'improved', 'indexing', 'innovation', 'insight', 'learning strategy', 'mass spectrometer', 'microbiome', 'multidimensional data', 'multimodality', 'novel', 'open data', 'open source', 'program dissemination', 'protein aminoacid sequence', 'protein biomarkers', 'reproductive', 'simulation', 'success', 'tool', 'vector', 'virtual']",NIGMS,FLORIDA INTERNATIONAL UNIVERSITY,R01,2020,322438,0.03084171097173784
"Optimization and joint modeling for peptide detection by tandem mass spectrometry Project Summary/Abstract Proteins are the primary functional molecules in living cells, and tandem mass spectrometry provides the most efﬁcient means of studying proteins in a high-throughput fashion. The proposal aims to use state-of-the-art methods from the ﬁelds of machine learning, statistics, and natural language processing to improve our ability to make sense of large tandem mass spectrometry data sets. Our project will focus on three key problems in the analysis of such data: 1. facilitating the use of previously annotated spectra to improve our ability to annotate new spectra by creating  a hybrid search scheme that compares an observed spectrum to a database comprised of theoretical spectra  and previously annotated spectra, 2. enabling the efﬁcient and accurate detection of peptides containing post-translational modiﬁcations and  sequence variants, and 3. detecting sets of peptide species that are co-fragmented in the mass spectrometer and hence give rise to  complex, mixture spectra. Each of these aims will improve the ability of mass spectrometrists to efﬁciently and accurately identify and quantify proteins in complex mixtures. To increase the impact of our work, we will continue to make all of our tools available as free software. Project narrative The applications of mass spectrometry, and its promises for improvements of human health, are numerous, including an increased understanding of disease phenotypes and the molecular mechanisms that underlie them, and vastly more sensitive and speciﬁc diagnostic and prognostic screens. However, making optimal use of mass spectrometry data requires sophisticated computational methods. This project will develop and apply novel statistical and machine learning methods for interpreting mass spectra.",Optimization and joint modeling for peptide detection by tandem mass spectrometry,9856476,R01GM121818,"['Algorithms', 'Amino Acid Sequence', 'Automobile Driving', 'Bayesian Network', 'Biological', 'Cells', 'Collection', 'Column Chromatography', 'Communities', 'Complex', 'Complex Mixtures', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Detection', 'Diagnostic', 'Discipline', 'Economics', 'Fertilization', 'Game Theory', 'Health', 'Human', 'Hybrids', 'Joints', 'Libraries', 'Liquid Chromatography', 'Machine Learning', 'Mass Spectrum Analysis', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Natural Language Processing', 'Operations Research', 'Peptides', 'Population', 'Post-Translational Protein Processing', 'Proteins', 'Proteomics', 'Protocols documentation', 'Sampling', 'Scheme', 'Shotguns', 'Speed', 'Statistical Models', 'Time', 'Variant', 'Work', 'complex data ', 'computerized tools', 'cost', 'disease phenotype', 'experimental study', 'improved', 'innovation', 'machine learning method', 'mass spectrometer', 'mathematical theory', 'novel', 'prognostic', 'protein aminoacid sequence', 'speech recognition', 'statistical and machine learning', 'statistics', 'tandem mass spectrometry', 'theories', 'tool']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,315830,0.08260694832740166
"Defining the Rules for Designing Fully Chemically Modified siRNAs to Treat Genetically Linked Central Nervous System Disorders PROJECT SUMMARY Small interfering RNA (siRNA) therapeutics specifically and potently block the expression of disease-related genes. siRNA clinical utility is currently limited to disease targets in the liver, but the Khvorova lab has developed a novel, fully chemically modified siRNA platform that enables delivery to the central nervous system (CNS) and results in potent modulation of gene expression in mouse and monkey brain for 6 months. This technology provides an opportunity to treat genetically-defined neurological disorders, including Huntington’s disease, amyotrophic lateral sclerosis, and Alzheimer’s disease (AD). Extensive chemical modification protects siRNAs from degradation and is essential for in vivo delivery, but lowers the gene silencing efficacy of many siRNA sequences. Bioinformatics algorithms have been developed to predict the activity of non-modified siRNAs, but these algorithms cannot predict whether a chemically modified siRNA will be functional. Identifying a hyperfunctional siRNA chemical modification pattern and developing a predictive algorithm for modified siRNA sequences will be critical for the widespread application of this platform in vivo to treat AD and other genetically-linked neurological disorders. The goal of this proposal is to identify parameters that impact the silencing efficacy of chemically modified siRNAs. Aim 1 will identify the step(s) that limit the activity of chemically modified siRNAs. Using a validated AGO2- immunoprecipitation technique and a small RNA high-throughput sequencing protocol, loading of 32 chemically modified siRNA sequences, each with 3 different chemical modification patterns, into RNA-induced silencing complex (RISC) will be quantified, and these results will be compared to their in vitro silencing activity. These efforts will provide a data set to determine the impacts of chemistry and sequence on the different steps of RISC function. Aim 2 will design and screen 192 siRNAs in 6 different chemical modification patterns (i.e., for a total of 1152 siRNAs) to systematically assess if and how changes to siRNA sequence and chemical modification patterns impact siRNA efficacy. These 1152 siRNAs will target 4 different mRNAs identified as therapeutic targets for AD. Completing this aim will identify siRNAs that effectively reduce the expression of AD targets. Using multiple bioinformatics analysis methods, including multi-parameter linear regression, support vector machine, and random forest, Aim 3 will model algorithms that specifically predict functional, chemically modified siRNAs. The best performing algorithm will be determined by independent and cross-validations. Completion of this project will decrease the extent of in vitro screening needed to identify functional chemically modified siRNAs capable of targeting disease genes in the CNS and streamline the design of siRNA therapies to treat genetically-defined neurological disorders. PROJECT NARRATIVE Small interfering RNA (siRNA) therapeutics are a promising class of drugs for the treatment of genetic disorders. Chemical modification of siRNA is necessary for delivery to the central nervous system, but may hinder the efficacy of some siRNAs. This project will define the relationships between siRNA sequence, chemical modification patterns, and efficacy to streamline the development of clinically-relevant siRNAs capable of treating genetically-defined neurological disorders.",Defining the Rules for Designing Fully Chemically Modified siRNAs to Treat Genetically Linked Central Nervous System Disorders,9992249,F31LM013111,"['Address', 'Affect', 'Affinity', 'Algorithm Design', 'Algorithmic Software', 'Algorithms', 'Alzheimer&apos', 's Disease', 'Amyotrophic Lateral Sclerosis', 'Binding', 'Bioinformatics', 'Brain', 'Cells', 'Central Nervous System Diseases', 'Chemicals', 'Chemistry', 'Clinical', 'Complex', 'Data', 'Data Set', 'Disease', 'Dose', 'Elements', 'Frequencies', 'Gene Expression', 'Gene Silencing', 'Gene Targeting', 'Genes', 'Genetic Diseases', 'Goals', 'Guidelines', 'Hela Cells', 'High-Throughput Nucleotide Sequencing', 'Huntington Disease', 'Immunoprecipitation', 'In Vitro', 'Individual', 'Investigation', 'Linear Regressions', 'Link', 'Liver', 'Messenger RNA', 'Methods', 'Modeling', 'Modification', 'Monkeys', 'Mus', 'Neuraxis', 'Neurodegenerative Disorders', 'Nucleotides', 'Pattern', 'Performance', 'Pharmacotherapy', 'Population', 'Process', 'Protocols documentation', 'RNA Degradation', 'RNA Interference', 'RNA Interference Therapy', 'RNA Sequences', 'RNA-Induced Silencing Complex', 'Seeds', 'Small Interfering RNA', 'Small RNA', 'Specificity', 'Structure', 'Techniques', 'Technology', 'Testing', 'Thermodynamics', 'Toxic effect', 'Validation', 'base', 'clinical development', 'clinically relevant', 'design', 'experimental study', 'improved', 'in vivo', 'nervous system disorder', 'novel', 'prediction algorithm', 'preference', 'random forest', 'screening', 'support vector machine', 'therapeutic RNA', 'therapeutic target']",NLM,UNIV OF MASSACHUSETTS MED SCH WORCESTER,F31,2020,30514,-0.03718881242145453
"Multiplex gene sequencing and metabolomics analysis from newborn dried blood spots to improve screening and diagnosis of metabolic disorders. Abstract: Newborn screening (NBS) using tandem mass spectrometry (MS/MS) has transformed our ability to identify and provide early, lifesaving treatment to infants with inborn errors of metabolism. While MS/MS screening identifies most affected babies, it is accompanied by frequent false-positive results that require collecting blood and urine samples for additional confirmatory testing. While DNA sequencing has become an important part of confirmatory testing, newborn dried blood spots (DBS) yield only small and highly variable DNA amounts. There is an urgent need for a more efficient second-tier NBS approach for confirming all screen-positive cases directly from the DBS cards collected at birth. This is especially critical for infants at risk for metabolic disease in their first weeks of life. The overall objective of this proposal is to combine novel DNA sequencing and mass spectrometry technology to diagnose inborn metabolic disorders from DBS, and to demonstrate the clinical feasibility of this approach for second-tier screening. To achieve this objective, the following specific aims will be pursued: (1) Develop multiplex gene sequencing (RUSPseq) and 10X linked-read sequencing for rapid genetic diagnosis without the need for additional parental testing; (2) Develop mass spectrometry (Q-TOF/LC-MS) and Random Forest (RF) machine learning to identify novel metabolic markers, which will be integrated in a novel second-tier screening panel to separate true and false-positive cases; and (3) Demonstrate clinical and translational feasibility of this approach to more rapidly identify both true and false-positive cases. We will work with the public NBS program and NBSTRN’s Pilot Research and Implementation workgroup to translate this combined approach into second-tier NBS. These outcomes will have significant impact by reducing diagnostic delays and uncertainties, and by reducing iterative testing rounds and the cost associated with them, thereby reducing the burden on the healthcare system as well as patients and their families. Project Narrative: We will establish novel genetic and metabolomic technology for newborn screening (NBS) from dried blood spots, and apply machine learning to reduce false-positive screens and delayed diagnosis of true-positive cases. Early detection and confirmation of inborn errors of metabolism that can present in the first weeks of life is critical, specifically when screening in diverse multiethnic populations where we have less understanding of the biochemical genetic and clinical phenotypes. We will work with local hospitals and the NBS program to establish clinical and translational validity to this new project, which will contribute to maintaining parental trust in public NBS.",Multiplex gene sequencing and metabolomics analysis from newborn dried blood spots to improve screening and diagnosis of metabolic disorders.,10033377,R01HD102537,"['Adoption', 'Affect', 'Archives', 'Biochemical', 'Biochemical Genetics', 'Biological Assay', 'Birth', 'Blood', 'Blood Volume', 'California', 'Chemicals', 'Clinical', 'Compound Q', 'Cystic Fibrosis Transmembrane Conductance Regulator', 'DNA', 'DNA sequencing', 'Data', 'Data Analyses', 'Detection', 'Diagnosis', 'Diagnostic', 'Differentiation Antigens', 'Early Diagnosis', 'Family', 'Genes', 'Genetic', 'Goals', 'Haplotypes', 'Healthcare Systems', 'Hospitals', 'Inborn Errors of Metabolism', 'Infant', 'Intervention', 'Laboratories', 'Lead', 'Letters', 'Life', 'Link', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Metabolic', 'Metabolic Diseases', 'Metabolic Marker', 'Methods', 'Neonatal Screening', 'Newborn Infant', 'Outcome', 'Parents', 'Patients', 'Phase', 'Physicians', 'Pilot Projects', 'Population', 'Research', 'Risk', 'Running', 'Sampling', 'Savings', 'Sensitivity and Specificity', 'Spottings', 'Symptoms', 'Technology', 'Testing', 'Time', 'Translating', 'Translations', 'Trust', 'Uncertainty', 'Urine', 'Variant', 'Work', 'carrier status', 'case control', 'clinical phenotype', 'cost', 'genetic analysis', 'genetic approach', 'genetic disorder diagnosis', 'improved', 'member', 'metabolomics', 'new technology', 'next generation sequencing', 'novel', 'novel marker', 'novel strategies', 'random forest', 'screening', 'screening panel', 'screening program', 'tandem mass spectrometry', 'web-based tool']",NICHD,YALE UNIVERSITY,R01,2020,542483,0.010161001024256733
"Binding-Site Modeling with Multiple-Instance Machine-Learning Project Summary / Abstract This proposal is entitled “Binding-Site Modeling with Multiple-Instance Machine-Learning.” A number of in- terrelated computational methods for making predictions about the biological behavior of small molecules have been the subject of development within the Jain Laboratory for over twenty years. These share a common strat- egy that considers molecular interactions at their surface interface, where proteins and ligands actually interact. These methods yield measurements of similarity between small molecules or between protein binding pockets. They also yield measurements of the complementarity of a small molecule to a protein binding site (the molecular docking problem). A generalization of these concepts makes possible the construction of a virtual binding site for quantitative activity prediction purely from data about the biological activities of a set of small molecules.  The goals of the proposed work include further improving the accuracy and breadth of applicability of the binding site modeling approach. The primary application of the approach is to guide optimization of leads within medicinal chemistry projects, and to quantify potential off-target effects during pre-clinical drug discovery.  A critical focus of the work will be in data and software dissemination, in order to accelerate the efficient development of targeted therapies. In addition to methods development, the proposed work will involve broad application of these state-of-the-art predictive modeling methods. The proposed work will proceed with the col- laborative input of our pharmaceutical industry colleagues, who have specialized knowledge and data sets that are vital for cutting-edge work in computer-aided drug design.  The expected results include more efficient lead optimization (fewer compounds to reach desired biological pa- rameters), truly effective scaffold replacement (to move away from a molecular series with biological limitations), and improved computational predictions of off-target effects during pre-clinical drug design. Project Narrative This project seeks to refine an integrated platform for physically realistic prediction of ligand binding affinities using multiple methods that span small molecule molecular similarity, molecular docking, and protein binding site similarity. These tools will provide predictive modeling unrestrained by scaffold congruence between what is known and what is to be predicted. Prediction of bioactive molecular poses and activities to guide lead optimiza- tion and to quantify off-target liability effects are applications of the effort, and data and software will be made widely available to academic and industrial research groups.",Binding-Site Modeling with Multiple-Instance Machine-Learning,9904662,R01GM101689,"['3-Dimensional', 'Address', 'Affinity', 'Behavior', 'Binding', 'Binding Proteins', 'Binding Sites', 'Biological', 'Biological Assay', 'Characteristics', 'Charge', 'Chemicals', 'Computer Assisted', 'Computer software', 'Computing Methodologies', 'Data', 'Data Set', 'Development', 'Docking', 'Drug Design', 'Drug Industry', 'Electrostatics', 'Formulation', 'Future', 'Goals', 'Hydrogen Bonding', 'Industrialization', 'Industry Collaboration', 'Knowledge', 'Laboratories', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Molecular', 'Molecular Probes', 'Performance', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Physics', 'Positioning Attribute', 'Procedures', 'Protein Conformation', 'Proteins', 'Research', 'Series', 'Structural Models', 'Surface', 'Testing', 'Variant', 'Work', 'base', 'blind', 'combinatorial', 'design', 'drug discovery', 'improved', 'interest', 'lead optimization', 'machine learning method', 'method development', 'novel', 'novel strategies', 'physical model', 'pre-clinical', 'predictive modeling', 'scaffold', 'segregation', 'small molecule', 'statistical and machine learning', 'targeted treatment', 'tool', 'treatment fees', 'virtual']",NIGMS,"UNIVERSITY OF CALIFORNIA, SAN FRANCISCO",R01,2020,310202,-0.019086843016794093
"In-silico prediction of protein-peptide interactions. IN-SILICO PREDICTION OF PROTEIN-PEPTIDE INTERACTIONS Automated docking methods are used extensively for gaining a mechanistic understanding of the molecular interactions underpinning cellular processes. While these tools work well for small molecules they perform poorly for peptides and cannot handle Intrinsically Disordered Proteins (IDPs) which play very important roles in these processes. The goal of this project is the development of an efficient and practical peptide docking software, useful for designing therapeutic peptides and gaining insight into IDPs binding ordered proteins. The proposed software supports biomedical applications ranging from investigating chemical pathways to designing and optimizing therapeutic molecules for diseases such as cancer and metabolic disorders. Under the previous award we developed and released a new method for docking fully-flexible peptides with up to 20 standard amino acids: AutoDock CrankPep (ADCP). We showed that it outperforms current state-of-the-art docking methods. For the next award, we propose to: 1) further develop ADCP to support docking IPDs with up to 70 amino acids and improve support for therapeutic peptides containing modified amino acids and complex macrocycles; 2) develop peptide-specific scoring functions to increase docking success rates and methods for predicting the free energy of binding of peptides. This will be done by exploiting the latest advances in statistical potentials for docking, as well as applying machine-learning techniques; 3) test and validate the software on our datasets, community benchmarks, and through our collaborations with outstanding biologists working on biomedical applications spanning from designing drugs for thrombosis and influenza, to modeling IDPs interacting with globular proteins; and 4) document the software and release it under an open source license on a regular basis along with datasets we compile and update on regularly. The proposed research will occur in the context of collaborations with experimental biologists working on highly relevant biomedical projects and providing experimental feedback and validation. In addition, this project will benefit from various collaborations with experts in the fields of computational biology, applied mathematics and artificial intelligence. This docking software tool will be developed by applying best practices in software engineering and be implemented as a modular, extensible, component-based software framework for peptide docking. This docking engine will be part of the widely used AutoDock software suite. The ability to model complexes formed by proteins and fully-flexible peptides or IDPs is in high demand and will greatly extend the range of peptide-based therapeutic approaches for which automated docking can be successfully applied. It will also support gaining insights into interactions of IDPs with proteins. As such, it will impact the research of many medicinal chemists and biologist and extend the use of computational tools to a wider community of scientists, thereby supporting the advancement of biomedical research. Automated docking is a workhorse for rational drug design, however, applying these methods to peptides has remained challenging, thus impeding the designing of therapeutic peptides and the study of Intrinsically Disordered Proteins (IDP) binding to their ordered partners. During the prior funding period, we made substantial progress toward peptide docking, resulting in a new docking engine: AutoDock CrankPep, which outperforms state-of-the-art docking methods for linear and cyclic peptides with up to 20 standard amino acids. We propose to further develop AutoDock CrankPep to support docking of therapeutic peptides with modified amino acids as well as IDPs with up to 70 amino acids, creating a practical docking tool for peptides that will impact the research of many computational and medicinal chemists and biologist, contribute to our understanding of biological processes, and significantly advance biomedical research.",In-silico prediction of protein-peptide interactions.,10116950,R01GM096888,"['Amino Acids', 'Area', 'Artificial Intelligence', 'Automobile Driving', 'Award', 'Benchmarking', 'Binding', 'Binding Proteins', 'Biological', 'Biological Availability', 'Biological Process', 'Biomedical Research', 'Cell physiology', 'Cells', 'Chemicals', 'Collaborations', 'Communities', 'Complex', 'Computational Biology', 'Computer software', 'Cyclic Peptides', 'Data Set', 'Development', 'Disease', 'Docking', 'Documentation', 'Drug Design', 'Educational workshop', 'Feedback', 'Free Energy', 'Funding', 'Goals', 'Half-Life', 'Influenza', 'Insulin', 'Libraries', 'Licensing', 'Ligands', 'Machine Learning', 'Malignant Neoplasms', 'Mathematics', 'Mediating', 'Metabolic Diseases', 'Methods', 'Modeling', 'Modernization', 'Mutate', 'Pathway interactions', 'Peptides', 'Performance', 'Peripheral', 'Permeability', 'Pharmaceutical Preparations', 'Play', 'Process', 'Production', 'Property', 'Proteins', 'Renaissance', 'Research', 'Role', 'Scientist', 'Signal Pathway', 'Software Engineering', 'Software Framework', 'Software Tools', 'Specificity', 'Structure', 'Study models', 'Techniques', 'Testing', 'Therapeutic', 'Thrombosis', 'Toxic effect', 'Training', 'Update', 'Validation', 'Work', 'base', 'combinatorial', 'computerized tools', 'computing resources', 'design', 'flexibility', 'globular protein', 'graphical user interface', 'improved', 'improved functioning', 'in silico', 'insight', 'interest', 'interoperability', 'novel', 'open source', 'peptide drug', 'predictive tools', 'programs', 'protein protein interaction', 'receptor', 'screening', 'small molecule', 'success', 'symposium', 'therapeutic target', 'tool', 'translational study', 'virtual screening']",NIGMS,SCRIPPS RESEARCH INSTITUTE,R01,2020,399375,-0.015223924920601114
"Using machine learning to predict odor characteristics from molecular structure PROJECT SUMMARY/ABSTRACT We cannot yet look at a chemical structure and predict if the molecule will have an odor, much less what character it will have. The goal of the proposed research is to apply machine learning to predict perceptual characteristics from chemical features of molecules. The specific aims of the proposal will determine (1) which molecules are odorous , and (2) what data are needed to model odor character. Building a highly predictive model requires two key ingredients: high-quality data and a sound modeling approach. High-quality data must be accurate (ratings are consistent and describe true odor properties) and detailed (ratings describe even small differences in odor properties). We have collected human psychophysical data on a diverse set of molecules and have trained a model to predict if a molecule has an odor, but pilot data identified odorous contaminants that limit model training and measurement of model accuracy. In Aim 1, I will apply my background in analytical chemistry to evaluate the accuracy of the data, using gas chromatography to identify and correct errors caused by chemical contaminants. In Aim 2, I will apply my experience in human sensory evaluation to measure and compare the consistency and the degree of detail in ratings that can be achieved with different sensory methods and subject training procedures. By executing my training plan, I will develop the skills in statistical programming and machine learning needed to employ a sound modeling approach to these problems. The model constructed in Aim 1 will enable prediction of odor classification (odor/odorless) for any molecule and thus define which molecules are perceptually relevant. Predicting odor character is a far more complex challenge – while a molecule can have only one of two odor classifications (odor or odorless) it may elicit any number of diverse odor character attributes (fruity, floral, musky, sweet, etc.). Descriptive Analysis (DA) is the gold standard method for generating accurate and detailed sensory profiles, but this method is time-consuming. We estimate that an odor character dataset will be large enough (“model-ready”) to predict odor character with approximately 10,000 molecules and that it would require more than 30,000 hours of human subject evaluation, or approximately 6 years for the typical trained panel, to produce this dataset using DA. Before we invest the time and resources, it is responsible to evaluate the relative data quality of more rapid sensory methods. The results of Aim 2 are expected to determine the best approach for generating a model-ready dataset by quantifying trade-offs in degree of detail (data resolution), rating consistency, and method speed of five candidate sensory methods. Together, these aims represent a significant step forward in linking chemical recipe to human odor perception, an advancement that supports the NIDCD goal of understanding normal olfactory function (how stimulus relates to percept) and has many potential applications in foods (what composition of molecules should be present to produce a target aroma percept). PROJECT NARRATIVE Currently, scientists cannot predict whether a molecule will have an odor and, if so, what odor characteristics it will have based on its chemical structure. The goal of this project is to develop predictive models linking chemical composition to odor characteristics. These models will advance our understanding of the human olfactory system and help design strategies for improving the aroma and palatability of healthy foods.",Using machine learning to predict odor characteristics from molecular structure,10142097,F32DC019030,"['Address', 'Analytical Chemistry', 'Characteristics', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Classification', 'Collection', 'Complex', 'Consumption', 'Data', 'Data Set', 'Descriptor', 'Development', 'Evaluation', 'Food', 'Fruit', 'Gas Chromatography', 'Goals', 'Gold', 'Health Food', 'Hour', 'Human', 'Human Resources', 'Knowledge', 'Learning', 'Link', 'Machine Learning', 'Mass Fragmentography', 'Measurement', 'Measures', 'Methods', 'Modeling', 'Molecular Structure', 'National Institute on Deafness and Other Communication Disorders', 'Odors', 'Olfactory Pathways', 'Palate', 'Perception', 'Positioning Attribute', 'Procedures', 'Programmed Learning', 'Property', 'Protocols documentation', 'Psychophysics', 'Quality Control', 'Recipe', 'Research', 'Research Technics', 'Resolution', 'Resources', 'Sampling', 'Science', 'Scientist', 'Sensory', 'Smell Perception', 'Speed', 'Stimulus', 'Structure', 'Testing', 'Time', 'Training', 'Work', 'base', 'data quality', 'design', 'experience', 'food science', 'human subject', 'improved', 'machine learning algorithm', 'model building', 'predictive modeling', 'prevent', 'rapid technique', 'skills', 'sound']",NIDCD,MONELL CHEMICAL SENSES CENTER,F32,2020,67446,0.026682097209898985
"Using machine learning techniques to characterize the Metabolomics Workbench Dataset PROJECT SUMMARY/ABSTRACT  Mass spectrometry in combination with chromatography provides a powerful approach to characterize small molecules produced in cells, tissues and other biological systems. In essence, measured metabolites provide a functional readout of cellular state, allowing novel biological studies that advance our understanding of health and disease. Currently, the main bottleneck in metabolomics is determining the chemical identities associated with the spectral signatures of measured masses. Despite the growth of spectral databases and advances in annotation tools that recommend the chemical structure that best explains each signature, the large majority of measured masses cannot be assigned a chemical identity. There is now consensus that gleaning partial information regarding the measured spectra in terms of chemical substructure or chemical classification can inform biological studies. This consensus is reflected in the newly updated reporting standards for metabolite annotation as proposed by the Metabolite Identification Task Group of the Metabolomics Society. As we show in our Preliminary Results, spectral characterization results in “features” that can enhance performance in machine-learning tasks such as annotation.  This work aims to enhance the use and value of the metabolomics dataset in Metabolomics Workbench by: (1) developing machine-learning tools trained on this dataset to characterize unknown spectra, and (2) adding characterization information to the Metabolomics Workbench dataset. In Aim 1, we identify spectral patterns (motifs) that can represent chemically meaningful groupings of peaks within the spectra (e.g., peaks associated with aromatic substructures, loss of a substructure fragment, etc.). We utilize neural topic models that use variational inference to identify such motifs. We expect such models to offer computational speedups and to identify more chemically coherent motifs when compared to earlier implementations of topic modeling. We generate motifs across all spectra in the Metabolomics Workbench and provide annotations for each spectrum.  In Aim 2, we map spectral signatures to chemical ontology classes. As ontologies are hierarchical and as a molecule can be associated with multiple classes at different hierarchical levels of an ontology, we cast this mapping problem as a hierarchical multi-label classification problem and use neural networks to implement such a classifier. The classifier will be trained using the Metabolomics Workbench dataset. Learned motifs from Aim 1 will be used as additional input features to improve classification. We expect that the developed classifier can be used by others to elucidate measurements of unidentified molecules with chemical ontology classes, or to generate ontology terms that can be used as features in downstream machine-learning tasks. Relevance to Public Health The project proposes to investigate machine learning techniques to enhance the utility of a Common Fund data set hosted through the Metabolomics Workbench. This data set consists of biologically relevant molecules and information about their structural composition and their mass spectrometry signatures. We anticipate that our techniques will result in annotating and adding information to the data set, which in turn will advance discoveries in biomedical research and have direct benefits to human health.",Using machine learning techniques to characterize the Metabolomics Workbench Dataset,10111982,R03OD030601,"['Biochemical', 'Biological', 'Biomedical Research', 'Catalogs', 'Cells', 'Chemical Structure', 'Chemicals', 'Chromatography', 'Classification', 'Complement', 'Computational Technique', 'Computing Methodologies', 'Consensus', 'Consumption', 'Coupled', 'Data', 'Data Set', 'Databases', 'Disease', 'Funding', 'Gas Chromatography', 'Gene Expression', 'Glean', 'Goals', 'Grouping', 'Growth', 'Health', 'Histidine', 'Human', 'Ions', 'Label', 'Liquid Chromatography', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Modeling', 'Molecular', 'Molecular Structure', 'Nature', 'Ontology', 'Pattern', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Public Health', 'Reporting', 'Research Personnel', 'Sampling', 'Societies', 'Structure', 'Taxonomy', 'Techniques', 'Time', 'Tissues', 'Training', 'Update', 'Validation', 'Variant', 'Vocabulary', 'Work', 'annotation  system', 'biological systems', 'biomarker discovery', 'cost', 'functional outcomes', 'improved', 'metabolomics', 'neural network', 'novel', 'protein expression', 'relating to nervous system', 'response', 'small molecule', 'tool']",OD,TUFTS UNIVERSITY MEDFORD,R03,2020,263120,0.00010431308156809308
"Machine Learning Tools for Discovery and Analysis of Active Metabolic Pathways ﻿    DESCRIPTION (provided by applicant): This project aims to develop new statistical machine learning methods for metabolomics data from diverse platforms, including targeted and unbiased/global mass spectrometry (MS), labeled MS experiments for measuring metabolic ﬂux and Nuclear Magnetic Resonance (NMR) platforms. Unbiased MS and NMR proﬁling studies result in identifying a large number of unnamed spectra, which cannot be directly matched to known metabolites and are hence often discarded in downstream analyses. The ﬁrst aim develops a novel kernel penalized regression method for analysis of data from unbiased proﬁling studies. It provides a systematic framework for extracting the relevant information from unnamed spectra through a kernel that highlights the similarities and differences between samples, and in turn boosts the signal from named metabolites. This results in improved power in identiﬁcation of named metabolites associated with the phenotype of interest, as well as improved prediction accuracy. An extension of this kernel-based framework is also proposed to allow for systematic integration of metabolomics data from diverse proﬁling studies, e.g. targeted and unbiased MS proﬁling technologies. The second aim pro- vides a formal inference framework for kernel penalized regression and thus complements the discovery phase of the ﬁrst aim. The third aim focuses on metabolic pathway enrichment analysis that tests both orchestrated changes in activities of steady state metabolites in a given pathway, as well as aberrations in the mechanisms of metabolic reactions. The fourth aim of the project provides a uniﬁed framework for network-based integrative analysis of static (based on mass spectrometry) and dynamic (based on metabolic ﬂux) metabolomics measurements, thus providing an integrated view of the metabolome and the ﬂuxome. Finally, the last aim implements the pro- posed methods in easy-to-use open-source software leveraging the R language, the capabilities of the Cytoscape platform and the Galaxy workﬂow system, thus providing an expandable platform for further developments in the area of metabolomics. The proposed software tool will also provide a plug-in to the Data Repository and Coordination Center (DRCC) data sets, where all regional metabolomics centers supported by the NIH Common Funds Metabolomics Program deposit curated data. PUBLIC HEALTH RELEVANCE: Metabolomics, i.e. the study of small molecules involved in metabolism, provides a dynamic view into processes that reﬂect the actual physiology of the cell, and hence offers vast potential for detection of novel biomarkers and targeted therapies for complex diseases. However, despite this potential, the development of computational methods for analysis of metabolomics data lags the rapid growth of metabolomics proﬁling technologies. The current application addresses this need by developing novel statistical machine learning methods for integrative analysis of static and dynamic metabolomics measurements, as well as easy-to-use open-source software to facilitate the application of these methods.",Machine Learning Tools for Discovery and Analysis of Active Metabolic Pathways,9899255,R01GM114029,"['Address', 'Adoption', 'Anabolism', 'Area', 'Biochemical Pathway', 'Biochemical Reaction', 'Biological', 'Biological Assay', 'Cardiovascular Diseases', 'Cell physiology', 'Cells', 'Characteristics', 'Code', 'Communities', 'Complement', 'Complex', 'Computer software', 'Computing Methodologies', 'Data', 'Data Analyses', 'Data Coordinating Center', 'Data Set', 'Deposition', 'Detection', 'Development', 'Diabetes Mellitus', 'Disease', 'Environment', 'Environmental Risk Factor', 'Equilibrium', 'Funding', 'Galaxy', 'Homeostasis', 'Knowledge', 'Label', 'Language', 'Letters', 'Linear Models', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Metabolism', 'Methodology', 'Methods', 'Names', 'Network-based', 'Nuclear Magnetic Resonance', 'Pathway interactions', 'Phase', 'Phenotype', 'Plug-in', 'Procedures', 'Process', 'Prognostic Marker', 'Proteomics', 'Reaction', 'Sampling', 'Signal Transduction', 'Software Tools', 'System', 'Technology', 'Testing', 'United States National Institutes of Health', 'Visualization', 'Work', 'base', 'biological systems', 'biomarker discovery', 'data warehouse', 'diagnostic biomarker', 'diverse data', 'experimental study', 'flexibility', 'high dimensionality', 'improved', 'insight', 'interest', 'machine learning method', 'metabolome', 'metabolomics', 'new technology', 'novel', 'novel diagnostics', 'novel marker', 'open source', 'programs', 'public health relevance', 'rapid growth', 'response', 'small molecule', 'statistical and machine learning', 'targeted treatment', 'tool', 'transcriptomics']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,336869,0.070671492253398
"Computational Techniques for Advancing Untargeted Metabolomics Analysis PROJECT SUMMARY/ABSTRACT Detecting and quantifying products of cellular metabolism using mass spectrometry (MS) has already shown great promise in biomarker discovery, nutritional analysis and other biomedical research fields. Despite recent advances in analysis techniques, our ability to interpret MS measurements remains limited. The biggest challenge in metabolomics is annotation, where measured compounds are assigned chemical identities. The annotation rates of current computational tools are low. For several surveyed metabolomics studies, less than 20% of all compounds are annotated. Another contributing factor to low annotation rates is the lack of systematic ways of designing a candidate set, a listing of putative chemical identities that can be used during annotation. Relying on exiting databases is problematic as considering the large combinatorial space of molecular arrangements, there are many biologically relevant compounds not catalogued in databases or documented in the literature. A secondary yet important challenge is interpreting the measurements to understand the metabolic activity of the sample under study. Current techniques are limited in utilizing complex information about the sample to elucidate metabolic activity. The goal of this project is to develop computational techniques to advance the interpretation of large-scale metabolomics measurements. To address current challenges, we propose to pursue three Aims: (1) Engineering candidate sets that enhance biological discovery. (2) Developing new techniques for annotation including using deep learning and incremental build out methods to recommend novel chemical structures that best explain the measurements. (3) Constructing probabilistic models to analyze metabolic activity. Each technique will be rigorously validated computationally and experimentally using chemical standards. Two detailed case studies on the intestinal microbiota will allow us to further validate our tools. Microbiota-derived metabolites have been detected in circulation and shown to engage host cellular pathways in organs and tissues beyond the digestive system. Identifying these metabolites is thus critical for understanding the metabolic function of the microbiota and elucidating their mechanisms. The complex test cases will challenge our techniques, provide feedback during development, and allow us to further disseminate our techniques. We will work closely with early adopters of our tools, as proposed in supporting letters, to further validate our tools and encourage wide adoption. All proposed tools will be open source and made accessible through the web. Our tools promise to change current practices in interpreting metabolomics data beyond what is currently possible with databases, current annotation tools, statistical and overrepresentation analysis, or combinations thereof. The use of machine learning and large data sets as proposed herein defines the most promising research direction in metabolomics analysis. PROJECT NARRATIVE  Untargeted Metabolomics is a recently developed technique that allows the measurement of thousands of molecules in a biological sample. This work proposes several novel computational techniques that address limitations of current metabolomics analysis tools. We anticipate that this work will advance discoveries in biomedical research and have direct benefits to human health.",Computational Techniques for Advancing Untargeted Metabolomics Analysis,10022125,R01GM132391,"['Address', 'Adoption', 'Biological', 'Biomedical Research', 'Blood Circulation', 'Case Study', 'Chemical Structure', 'Chemicals', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Engineering', 'Ensure', 'Feedback', 'Goals', 'Health', 'Human', 'Internet', 'Intestines', 'Label', 'Letters', 'Literature', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'MeSH Thesaurus', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Nutritional', 'Organ', 'Pathway interactions', 'Performance', 'Play', 'Probability', 'Property', 'PubChem', 'PubMed', 'Public Domains', 'Research', 'Research Personnel', 'Role', 'Running', 'Sampling', 'Statistical Models', 'Structure', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Uncertainty', 'Validation', 'Work', 'annotation  system', 'base', 'biomarker discovery', 'chemical standard', 'combinatorial', 'computerized tools', 'cost', 'dark matter', 'deep learning', 'design', 'drug development', 'drug discovery', 'experimental study', 'gastrointestinal system', 'gut microbiota', 'interest', 'large datasets', 'metabolome', 'metabolomics', 'microbiota', 'microbiota metabolites', 'neural network', 'novel', 'nutrition', 'open source', 'physical property', 'small molecule', 'tool']",NIGMS,TUFTS UNIVERSITY MEDFORD,R01,2020,378983,0.040990191105938524
"Computational Techniques for Advancing Untargeted Metabolomics Analysis PROJECT SUMMARY/ABSTRACT Detecting and quantifying products of cellular metabolism using mass spectrometry (MS) has already shown great promise in biomarker discovery, nutritional analysis and other biomedical research fields. Despite recent advances in analysis techniques, our ability to interpret MS measurements remains limited. The biggest challenge in metabolomics is annotation, where measured compounds are assigned chemical identities. The annotation rates of current computational tools are low. For several surveyed metabolomics studies, less than 20% of all compounds are annotated. Another contributing factor to low annotation rates is the lack of systematic ways of designing a candidate set, a listing of putative chemical identities that can be used during annotation. Relying on exiting databases is problematic as considering the large combinatorial space of molecular arrangements, there are many biologically relevant compounds not catalogued in databases or documented in the literature. A secondary yet important challenge is interpreting the measurements to understand the metabolic activity of the sample under study. Current techniques are limited in utilizing complex information about the sample to elucidate metabolic activity. The goal of this project is to develop computational techniques to advance the interpretation of large-scale metabolomics measurements. To address current challenges, we propose to pursue three Aims: (1) Engineering candidate sets that enhance biological discovery. (2) Developing new techniques for annotation including using deep learning and incremental build out methods to recommend novel chemical structures that best explain the measurements. (3) Constructing probabilistic models to analyze metabolic activity. Each technique will be rigorously validated computationally and experimentally using chemical standards. Two detailed case studies on the intestinal microbiota will allow us to further validate our tools. Microbiota-derived metabolites have been detected in circulation and shown to engage host cellular pathways in organs and tissues beyond the digestive system. Identifying these metabolites is thus critical for understanding the metabolic function of the microbiota and elucidating their mechanisms. The complex test cases will challenge our techniques, provide feedback during development, and allow us to further disseminate our techniques. We will work closely with early adopters of our tools, as proposed in supporting letters, to further validate our tools and encourage wide adoption. All proposed tools will be open source and made accessible through the web. Our tools promise to change current practices in interpreting metabolomics data beyond what is currently possible with databases, current annotation tools, statistical and overrepresentation analysis, or combinations thereof. The use of machine learning and large data sets as proposed herein defines the most promising research direction in metabolomics analysis. PROJECT NARRATIVE  Untargeted Metabolomics is a recently developed technique that allows the measurement of thousands of molecules in a biological sample. This work proposes several novel computational techniques that address limitations of current metabolomics analysis tools. We anticipate that this work will advance discoveries in biomedical research and have direct benefits to human health.",Computational Techniques for Advancing Untargeted Metabolomics Analysis,10145183,R01GM132391,"['Address', 'Adoption', 'Biological', 'Biomedical Research', 'Blood Circulation', 'Case Study', 'Chemical Structure', 'Chemicals', 'Complex', 'Computational Technique', 'Computing Methodologies', 'Consumption', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Engineering', 'Ensure', 'Feedback', 'Goals', 'Health', 'Human', 'Internet', 'Intestines', 'Label', 'Letters', 'Literature', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'MeSH Thesaurus', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Molecular', 'Molecular Structure', 'Nutritional', 'Organ', 'Pathway interactions', 'Performance', 'Play', 'Probability', 'Property', 'PubChem', 'PubMed', 'Public Domains', 'Research', 'Research Personnel', 'Role', 'Running', 'Sampling', 'Statistical Models', 'Structure', 'Surveys', 'Techniques', 'Testing', 'Time', 'Tissues', 'Training', 'Uncertainty', 'Validation', 'Work', 'annotation  system', 'base', 'biomarker discovery', 'chemical standard', 'combinatorial', 'computerized tools', 'cost', 'dark matter', 'deep learning', 'design', 'drug development', 'drug discovery', 'experimental study', 'gastrointestinal system', 'gut microbiota', 'interest', 'large datasets', 'metabolome', 'metabolomics', 'microbiota', 'microbiota metabolites', 'neural network', 'novel', 'nutrition', 'open source', 'physical property', 'small molecule', 'tool']",NIGMS,TUFTS UNIVERSITY MEDFORD,R01,2020,10920,0.040990191105938524
"Image-guided robot for high-throughput microinjection of Drosophila embryos PROJECT SUMMARY This proposal is submitted in response to the NIH Development of Animal Models and Related Biological Materials for Research (R21) program. The proposal develops an image-guided robotic platform that performs the automated delivery of molecular genetic tools and non-genetically encoded reagents such as chemical libraries, fluorescent dyes to monitor cellular processes, functionalized magnetic beads, or nanoparticles into thousands of Drosophila embryos in a single experimental session. The proposed work builds on recent engineering innovations in our collaborative group which has developed image-guided robotic systems that can precisely interface with single cells in intact tissue. The two Specific Aims provide for a systematic development of the proposed technologies. AIM 1 first engineers a robotic platform (‘Autoinjector’) that can scan and image Drosophila embryos in arrays of egg laying plates. We will utilize machine learning algorithms for automated detection of embryos, followed by thresholding and morphology analysis to detect embryo centroids and annotate injection sites. In AIM 2, we will utilize microprocessor-controlled fluidic circuits for programmatic delivery of femtoliter to nanoliter volumes of reagents into individual embryos. We will quantify the efficacy of the Autoinjector by comparing the survival, fertility, and transformation rates of transposon or PhiC31-mediated transgenesis to manual microinjection datasets. Finally, we will demonstrate the efficient delivery of sgRNAs and mutagenesis in the presence of Cas9. This project fits very well within the goals of the program by engineering a novel tool for producing and improving animal models. The Autoinjector will accelerate Drosophila research and empower scientists to perform novel experiments and genome-scale functional genomics screens that are currently too inefficient or labor intensive to be conducted on a large scale and may additionally enable other novel future applications. PROJECT NARRATIVE This proposal develops a technology platform that will enable automated microinjection of molecular genetic tools and non-genetically encoded tools such as chemical libraries, fluorescent dyes, functionalized magnetic beads, or nanoparticles, into thousands of Drosophila embryos in a single experimental session. The successful development of this technology will empower Drosophila biologists to perform screens and develop new applications that are currently too inefficient or labor intensive to contemplate and will accelerate research into the function of the nervous system and the molecular and genetic underpinnings of numerous diseases in this important animal model.",Image-guided robot for high-throughput microinjection of Drosophila embryos,9989196,R21OD028214,"['Animal Model', 'Biocompatible Materials', 'Biological Assay', 'Caliber', 'Cell Nucleus', 'Cell physiology', 'Cells', 'Collection', 'Computer Vision Systems', 'Cryopreservation', 'Data Set', 'Detection', 'Development', 'Disease', 'Drosophila genus', 'Drosophila melanogaster', 'Embryo', 'Engineering', 'Expenditure', 'Exploratory/Developmental Grant', 'Fertility', 'Fluorescent Dyes', 'Future', 'Gene Transfer Techniques', 'Genetic', 'Goals', 'Guide RNA', 'Image', 'Individual', 'Injections', 'Investigation', 'Laboratories', 'Liquid substance', 'Location', 'Machine Learning', 'Manuals', 'Mediating', 'Methods', 'Microinjections', 'Microprocessor', 'Microscope', 'Molecular', 'Molecular Biology', 'Molecular Genetics', 'Monitor', 'Morphology', 'Motivation', 'Mutagenesis', 'Needles', 'Nervous System Physiology', 'Performance', 'Process', 'Reagent', 'Research', 'Resources', 'Robot', 'Robotics', 'Scanning', 'Scientist', 'Signaling Molecule', 'Site', 'Space Perception', 'System', 'Technology', 'Tissues', 'Transgenes', 'Transgenic Organisms', 'United States National Institutes of Health', 'Work', 'animal model development', 'automated algorithm', 'base', 'biological research', 'cost', 'egg', 'experience', 'experimental study', 'functional genomics', 'gene product', 'genetic manipulation', 'genome-wide', 'image guided', 'improved', 'innovation', 'machine learning algorithm', 'magnetic beads', 'mutant', 'mutation screening', 'nanolitre', 'nanoparticle', 'novel', 'novel strategies', 'programs', 'response', 'robotic system', 'screening', 'small molecule libraries', 'stem', 'technology development', 'tool']",OD,UNIVERSITY OF MINNESOTA,R21,2020,222618,0.0069600633639773975
"Identification of Biomarkers and Novel Pathways of Alcoholic Liver Disease by Leveraging Metabolomics, Tissue Imaging Mass Spectrometry, and Integrative Machine Learning ABSTRACT Alcoholic liver disease (ALD) is a serious global health problem. It encompasses a spectrum of pathological conditions, ranging from simple hepatic steatosis, steatohepatitis, fibrosis, alcoholic hepatitis, to liver cirrhosis. Unfortunately, no definitive diagnostic markers exist for ALD (or its different phases), and diagnosis requires a liver biopsy which itself carries significant risk. As a result, management of ALD is frequently empiric. In recent years, some progress has been made using metabolomics to identify potential biomarkers of ALD in animal models and human cohorts. However, global metabolomic profiling of ALD in humans has proceeded slowly and as of today, no studies have been performed that relate metabolomic profiles with pathological changes occurring during the development of ALD. Our working hypothesis predicts that biomarkers specific to ALD may be more effectively identified by applying integrative machine learning to the analysis of data from two state-of-the-art analytical approaches, i.e., metabolomics and imaging mass spectrometry (IMS). As such, we propose to use plasma metabolomics (Specific Aim 1), and histological analysis and liver tissue IMS (Specific Aim 2) in three mouse models of ALD (alcohol-induced steatosis, hepatitis or mild fibrosis) to gain unique insights into the feasibility of using these approaches to identify pathogenic markers of ALD. Ethanol-induced damage to the liver results in alterations in cellular function that can be documented as changes in the metabolome of biological fluids (plasma) and hepatic cells. Metabolomics, the analysis of low molecular metabolites (e.g., lipids and small molecules) in a sample, can be used to directly investigate changes in biochemical pathways induced by alcohol in the liver, such as occurs during ALD. Tissue IMS maps molecules in a tissue section, thereby allowing the quantitation of lipids, proteins and metabolites within a tissue in unprecedented detail. When interfaced with histological analysis of a paired adjacent tissue section, the cellular source of the mapped molecules may be identified. We strongly believe that the integration of metabolomics, IMS and histology (Specific Aim 3) using integrative machine learning will greatly enhance our understanding of the biochemical basis of ALD pathophysiology, and in so doing, allow the development of diagnostic tools that can be used to detect biomarkers in other forms of ALD, thereby improving early diagnosis and treatment of ALD. The management and interpretation of large metabolomics and proteomic data generated as part of the project (10-100GB of raw IMS data per single tissue section) require advanced data-analytics solutions. We will capitalize on our recently published bespoke machine learning solution (“BASIS”) for interrogation of large “-omics” data to identify metabolic/signaling pathways and their downstream metabolites disrupted in ALD. The novelty of this proposal relies on the use of cutting-edge approaches that will allow identification of novel biomarkers and their cellular sources in predictable animal models of ALD. Such information will form a basis for more effective diagnosis and prediction of the progression of ALD. Successful completion of the proposed studies will form a foundation upon which studies in human biological fluids will be conducted in the future. In addition, it is anticipated that our studies will also lay the foundation for examination of the molecular mechanisms associated with other forms of alcohol-induced tissue injury. Such knowledge will facilitate the development of more effective treatments of alcohol abuse. NARRATIVE Excessive alcohol consumption induces alcoholic liver disease (ALD). Unfortunately, no definitive diagnostic markers exist for ALD (or its different phases), and diagnosis requires a liver biopsy which itself carries significant risk. Because the early stages of ALD can potentially be reversed by sobriety, regular screening of the general population and early diagnosis are essential. The overarching goal of this application is to establish metabolomic analyses and tissue imaging mass spectrometry coupled with integrative machine learning to identify novel pathways in and biomarkers for ALD that will be applied in humans.","Identification of Biomarkers and Novel Pathways of Alcoholic Liver Disease by Leveraging Metabolomics, Tissue Imaging Mass Spectrometry, and Integrative Machine Learning",9995686,R21AA028432,"['Alcohol-Induced Disorders', 'Alcoholic Hepatitis', 'Alcoholic Liver Diseases', 'Alcoholic liver damage', 'Alcohols', 'Animal Model', 'Biochemical', 'Biochemical Pathway', 'Biological', 'Biological Markers', 'Cell physiology', 'Cells', 'Chronic', 'Complex', 'Coupled', 'Data', 'Data Analyses', 'Data Analytics', 'Detection', 'Development', 'Diagnosis', 'Diagnostic', 'Drug or chemical Tissue Distribution', 'Early Diagnosis', 'Early treatment', 'Ethanol', 'Fatty Liver', 'Fibrosis', 'Foundations', 'Functional disorder', 'Future', 'General Population', 'Goals', 'Heavy Drinking', 'Hepatitis', 'Hepatocyte', 'Histologic', 'Histology', 'Human', 'Hybrids', 'Image', 'Individual', 'Inflammation', 'Investigation', 'Knowledge', 'Label', 'Link', 'Lipids', 'Liquid substance', 'Liver', 'Liver Cirrhosis', 'Liver diseases', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Metabolic', 'Molecular', 'Molecular Profiling', 'Molecular Structure', 'Monoclonal Antibody R24', 'National Institute on Alcohol Abuse and Alcoholism', 'Pathogenicity', 'Pathologic', 'Pathway interactions', 'Pattern', 'Phase', 'Plasma', 'Process', 'Proteomics', 'Publishing', 'Recovery', 'Resources', 'Risk', 'Sampling', 'Signal Pathway', 'Source', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Steatohepatitis', 'Structure', 'System', 'Tissue imaging', 'Tissues', 'alcohol abuse therapy', 'alcohol research', 'biobank', 'biomarker identification', 'candidate marker', 'cohort', 'diagnostic biomarker', 'effective therapy', 'global health', 'human subject', 'improved', 'insight', 'intrahepatic', 'liver biopsy', 'liver imaging', 'metabolome', 'metabolomics', 'molecular imaging', 'mouse model', 'novel', 'novel diagnostics', 'novel marker', 'potential biomarker', 'predictive marker', 'protein metabolite', 'screening', 'small molecule', 'sobriety', 'specific biomarkers', 'tissue injury', 'tool']",NIAAA,YALE UNIVERSITY,R21,2020,178842,0.022764426685239078
"Computational Explorations of Unconventional Approaches to Control Noncovalent Interactions PROJECT SUMMARY The research interests of my group are rooted in explorations of new and useful conceptual models to improve the control and prediction of noncovalent interactions. Our research involves the use of a variety of computational quantum chemical tools, applications of density functional theory (DFT), cheminformatics, and machine-learning methods. A premise of our research is that aromaticity may be used to modulate many types of noncovalent interactions (such as hydrogen bonding, π-stacking, anion-π interactions). The reciprocal relationship we find, between “aromaticity” in molecules and the strengths of “noncovalent interactions,” is surprising especially since they are typically considered as largely separate ideas in chemistry. The innovation of this research is that it will enable use of intuitive “back-of-the-envelope” electron-counting rules (such as the 4n+2πe Hückel rule for aromaticity) to make predictions of experimental outcomes regarding the impact of noncovalent interactions. A five-year goal is to realize the use of our conceptual models in real synthetic examples prepared by our experimental collaborators. My research vision is to bridge discoveries of innovative concepts to their practical impacts for biomedical and biomolecular research. PROJECT NARRATIVE This research proposal includes four projects that are jointly motivated by the challenge to control and predict noncovalent interactions in organic and biomolecular systems. The proposed work involves applications of a variety of computational quantum chemical tools and synergistic investigations with experimental collaborators. We seek to identify new and useful concepts to guide experimental designs of novel “non-natural” molecular systems (e.g., receptors, biosensors, and hydrogels) that have potential biomedical applications.",Computational Explorations of Unconventional Approaches to Control Noncovalent Interactions,10016376,R35GM133548,"['Anions', 'Back', 'Biosensor', 'Chemicals', 'Chemistry', 'Electrons', 'Experimental Designs', 'Goals', 'Hydrogels', 'Hydrogen Bonding', 'Intuition', 'Investigation', 'Modeling', 'Molecular', 'Outcome', 'Plant Roots', 'Research', 'Research Project Summaries', 'Research Proposals', 'System', 'Vision', 'Work', 'cheminformatics', 'density', 'improved', 'innovation', 'interest', 'machine learning method', 'novel', 'quantum computing', 'receptor', 'theories', 'tool']",NIGMS,UNIVERSITY OF HOUSTON,R35,2020,377200,0.010046824572802579
"Advanced Computational Approaches for NMR Data-mining ABSTRACT Nuclear magnetic resonance spectroscopy (NMR)-based metabolomics is a powerful method for identifying metabolic perturbations that report on different biological states and sample types. Compared to mass spectrometry, NMR provides robust and highly reproducible quantitative data in a matter of minutes, which makes it very suitable for first-line clinical diagnostics. Although the metabolome is known to provide an instantaneous snap-shot of the biological status of a cell, tissue, and organism, the utilization of NMR in clinical practice is hindered by cumbersome data analysis. Major challenges include high-dimensionality of the data, overlapping signals, variability of resonance frequencies (chemical shift), non-ideal shapes of signals, and low signal-to-noise ratio (SNR) for low concentration metabolites. Existing approaches fail to address these challenges and sample analysis is time-consuming, manually done, and requires considerable knowledge of NMR spectroscopy. Recent developments in the field of sparse methods for machine learning and accelerated convex optimization for high dimensional problems, as well as kernel-based spatial clustering show promise at enabling us to overcome these challenges and achieve fully automated, operator-independent analysis. We are developing two novel, powerful, and automated algorithms that capitalize on these recent developments in machine learning. In Aim 1, we describe ‘NMRQuant’ for automated identification and quantification of annotated metabolites irrespective of the chemical shift, low SNR, and signal shape variability. In Aim 2, we describe ‘SPA-STOCSY’ for automated de-novo identification of molecular fragments of unknown, non- annotated metabolites. Based on substantial preliminary data, we propose to evaluate these algorithms' sensitivity, specificity, stability, and resistance to noise on phantom, biological, and clinical samples, comparing them to current methods. We will validate the accuracy of analyses by experimental 2D NMR, spike-in, and mass spectrometry. The proposed efforts will produce new NMR analytical software for discovery of both annotated and non-annotated metabolites, substantially improving accuracy and reproducibility of NMR analysis. Such analytical ability would change the existing paradigm of NMR-based metabolomics and provide an even stronger complement to current mass spectrometry-based methods. This approach, once thoroughly validated, will enable NMR to reach wide network of applications in biomedical, pharmaceutical, and nutritional research and clinical medicine. NARRATIVE This project seeks to develop an advanced and automated platform for identifying NMR metabolomics biomarkers of diseases and for fundamental studies of biological systems. When fully developed, these approaches could be used to detect small molecules in the blood or urine, indicative of the onset of various diseases, drug toxicity, or environmental effects on the organism.",Advanced Computational Approaches for NMR Data-mining,9889134,R01GM120033,"['Address', 'Algorithms', 'Animal Disease Models', 'Biological', 'Biological Markers', 'Blood', 'Cardiovascular Diseases', 'Cells', 'Chemicals', 'Clinic', 'Clinical', 'Clinical Medicine', 'Complement', 'Computer software', 'Consumption', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Diabetes Mellitus', 'Diagnostic', 'Disease', 'Drug toxicity', 'Early Diagnosis', 'Frequencies', 'Health', 'Human', 'Knowledge', 'Left', 'Libraries', 'Link', 'Machine Learning', 'Malignant Neoplasms', 'Manuals', 'Mass Spectrum Analysis', 'Measures', 'Medical', 'Metabolic', 'Methods', 'Modeling', 'Molecular', 'NMR Spectroscopy', 'Nature', 'Neurodegenerative Disorders', 'Noise', 'Nuclear Magnetic Resonance', 'Nutritional', 'Obesity', 'Organism', 'Outcome', 'Patients', 'Pharmacologic Substance', 'Phenotype', 'Plague', 'Process', 'Regulation', 'Relaxation', 'Reporting', 'Reproducibility', 'Research', 'Residual state', 'Resistance', 'Sampling', 'Sensitivity and Specificity', 'Shapes', 'Signal Transduction', 'Societies', 'Sodium Chloride', 'Spectrum Analysis', 'Statistical Algorithm', 'Structure', 'Temperature', 'Time', 'Tissues', 'Treatment outcome', 'Urine', 'Variant', 'automated algorithm', 'automated analysis', 'base', 'biological systems', 'biomarker discovery', 'clinical diagnostics', 'clinical implementation', 'clinical practice', 'computational suite', 'data mining', 'experimental analysis', 'experimental study', 'high dimensionality', 'improved', 'infancy', 'machine learning method', 'metabolome', 'metabolomics', 'multidimensional data', 'novel', 'personalized medicine', 'phenotypic biomarker', 'small molecule', 'stem']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,356625,0.08323257777792344
"Integrated Instrument for non-natural aptamer generation Project Summary DNA and RNA aptamers are a useful class of synthetic affinity reagents. However, their performance can be greatly improved through the site-specific incorporation of chemically modified, ‘non-natural’ nucleotides that provide a greater chemical repertoire to enable superior aptamer affinity and specificity. Because a broad spectrum of chemical functional groups can be incorporated, non-natural aptamers offer the exciting potential for targeting molecules for which the generation of monoclonal antibodies remains difficult, such as small- molecule drugs, metabolites and carbohydrates. Unfortunately, the access to non-natural aptamers is severely limited. This is because the process of generating non-natural aptamers is technically challenging and limited to a few specialized laboratories. The goal of this project is to develop an integrated instrument, the Non-Natural Aptamer Array (N2A2) that eliminates these bottlenecks and enable rapid and facile non-natural aptamer discovery at virtually any research laboratory. The N2A2 will be built on a modified version of a benchtop commercial sequencer (Illumina MiSeq), and will perform every stage of non-natural aptamer discovery— including sequencing, screening and binding measurements—as part of a single work-flow. There are three main innovative aspects of our N2A2 system. First, our approach will entirely eliminate the need for polymerase engineering, and thus allows us to incorporate virtually any chemical functional group through click chemistry. Second, N2A2 will enable us to directly obtain the binding affinity (Kd) of ~10^7 aptamers directly in complex samples (e.g. cell lysate or serum), thereby resulting in aptamers with high-specificity. Finally, we will develop a machine-learning (ML) approach to identify key motifs (“k-mers”) and predict novel sequences with potentially higher affinity and specificity that can be tested using the N2A2 instrument. We believe this powerful combination of massively parallel, sequence-linked binding measurements with ML-based predictions will allow us to explore sequence space that is currently inaccessible to traditional in vitro selection methods, and enable us to discover aptamers with superior performance. The success of this project will produce an integrated instrument that greatly streamlines and accelerates the discovery of non-natural aptamers for a wide range of targets in complex media. The instrument is based on a commercially available sequencer and we will make all software available to the public. In this way, we believe the N2A2 instrument could broadly expand access to robust, high quality, custom affinity reagents for biomedical research and clinical diagnostics. Project Narrative We will develop an integrated instrument that simplifies the discovery of non-natural aptamer reagents for a wide range of molecules that are difficult to target using conventional antibody reagents. The access to these custom reagents will accelerate biomedical research and clinical diagnostics.",Integrated Instrument for non-natural aptamer generation,9872178,R01GM129313,"['Affinity', 'Algorithms', 'Antibodies', 'Binding', 'Biomedical Research', 'Carbohydrates', 'Cells', 'Chemicals', 'Chemistry', 'Chinese Hamster Ovary Cell', 'Complex', 'Computer software', 'Custom', 'DNA', 'Data', 'Directed Molecular Evolution', 'Engineering', 'Generations', 'Goals', 'Graph', 'In Vitro', 'Label', 'Laboratories', 'Laboratory Research', 'Link', 'Machine Learning', 'Measurement', 'Methods', 'Modeling', 'Monoclonal Antibodies', 'Nucleotides', 'Opioid', 'Performance', 'Pharmaceutical Preparations', 'Polymerase', 'Process', 'Proteins', 'RNA', 'Reagent', 'Reproducibility', 'Sampling', 'Serum', 'Site', 'Specificity', 'System', 'Testing', 'Tyrosine', 'Work', 'aptamer', 'base', 'clinical diagnostics', 'data analysis pipeline', 'functional group', 'improved', 'innovation', 'instrument', 'machine learning algorithm', 'novel', 'programmed cell death protein 1', 'scaffold', 'screening', 'small molecule', 'success', 'virtual']",NIGMS,STANFORD UNIVERSITY,R01,2020,314000,0.023952968166928268
"Real time optimization of electron-based fragmentation for middle and top-down proteomics in mass spectrometry The identification and quantification of biological macromolecules remains challenging despite major advances in the speed, resolution and mass accuracy of modern mass spectrometers. A key weakness with current instrumentation lies in the methods used to induce fragmentation. The reliance in particular on collision-induced dissociation (CID) has limited such analyses to bottom-up workflows of trypsin-digested peptides of 10-30 residues. At e-MSion, we have developed an efficient electron-fragmentation technology called ExD for large proteins and are now co-marketed our ExD Option with Agilent, and soon will be with Thermo and Waters instruments. What has really captured the interest of the biopharma and top-down communities in the past year is the exceptional sequence coverage of native proteins we obtain with the same ExD cell. The resulting spectra are less congested than those obtained with currently available ETD/UVPD/CID fragmentation methodologies. We have shown that our technology works faster and gives cleaner spectra with more complete dissociation with larger macromolecular protein complexes than has ever been possible before, while still preserving labile post translational modifications. In addition, fragmentation with higher energy electrons can be used to provide complementary data to improve protein and glycan identification. The challenge now has become how to optimally collect and process these data to maximize the utility of ExD fragmentation. Last summer, Xilinx released its Versal Adaptive Compute Acceleration Platform (ACAP), a massively parallel processor with 50 billion transistors targeted to transform digital signal processing, handling of big data and artificial intelligence. This ACAP technology has already accelerated Illumina DNA sequence assembly by 90-fold. Our feasibility question asks how to effectively harness this new highly parallelized technology to preprocess complex top-down mass spectra on- the-fly. This will allow us to actively optimize data acquisition by enabling adaptive operation of the ExD cell and mass spectrometer. The objective is to maximize both fragmentation and dissociation of native proteins, enabling faster and comprehensive characterization of challenging proteoforms important to the biopharmaceutical industry and biomedical researchers.  Success will offer an extremely fast, cost-effective solution to characterize complexes of macromolecules under native conditions with increased accuracy, speed, and fewer misidentifications. Our ExD technology with the Versal ACAP can be both retrofitted into existing mass spectrometers as well as being available in new generations of mass spectrometers at a price below other less-effective alternative fragmentation technologies like ETD and UVPD. Thus, it will provide new abilities for many NIH investigators to advance basic research, probe disease mechanisms and permit more sophisticated searches for both diagnostic and therapeutic biomarkers. Even with all of the scientific progress made to date, the complexity of disease-affected tissues still challenges our ability to probe what makes people sick. The goal of this Phase I SBIR project is to develop a powerful computer technology to aid in characterizing biological molecules that will improve the diagnosis and treatment of diseases ranging from arthritis, cancer, diabetes to heart disease and neurodegeneration.",Real time optimization of electron-based fragmentation for middle and top-down proteomics in mass spectrometry,10081127,R43GM139467,"['Acceleration', 'Affect', 'Arthritis', 'Artificial Intelligence', 'Automobile Driving', 'Basic Science', 'Big Data', 'Biological', 'Biological Products', 'Biological Response Modifier Therapy', 'Businesses', 'Cells', 'Collection', 'Communities', 'Complex', 'Computer software', 'Computers', 'Continuous Infusion', 'DNA Sequence', 'Data', 'Data Analyses', 'Data Collection', 'Diabetes Mellitus', 'Diagnosis', 'Digital Signal Processing', 'Disease', 'Dissociation', 'Electronics', 'Electrons', 'Engineering', 'Face', 'Family', 'Feasibility Studies', 'Generations', 'Goals', 'Grant', 'Health', 'Heart Diseases', 'Individual', 'Industrialization', 'Industry', 'Ions', 'Isoleucine', 'Laboratories', 'Leucine', 'Macromolecular Complexes', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Methodology', 'Methods', 'Modernization', 'Multiprotein Complexes', 'Nerve Degeneration', 'Noise', 'Optics', 'Peptides', 'Periodicity', 'Phase', 'Polysaccharides', 'Post-Translational Protein Processing', 'Price', 'Process', 'Protein Analysis', 'Protein Fragment', 'Proteins', 'Proteomics', 'Reading', 'Research Personnel', 'Resolution', 'Signal Transduction', 'Small Business Innovation Research Grant', 'Speed', 'Structure', 'Techniques', 'Technology', 'Time', 'Tissues', 'Transistors', 'Trypsin', 'United States National Institutes of Health', 'Vendor', 'Water', 'Work', 'base', 'blind', 'computational platform', 'computerized data processing', 'cost effective', 'data acquisition', 'diagnostic biomarker', 'disulfide bond', 'electron energy', 'encryption', 'experience', 'fragment X', 'improved', 'instrument', 'instrumentation', 'interest', 'macromolecule', 'mass spectrometer', 'meetings', 'operation', 'preservation', 'programs', 'protein complex', 'signal processing', 'success', 'therapeutic biomarker']",NIGMS,"E-MSION, INC.",R43,2020,212830,0.017194198421037542
"COMPUTATIONAL TOOLS FOR PROTEOFORM IDENTIFICATION BY TOP-DOWN DATA INDEPENDENT ACQUISITION MASS SPECTROMETRY Summary Mass spectrometry-based top-down proteomics has become one of the most informative approaches in protein analysis because it provides the bird's-eye view of intact proteoforms (protein forms) generated from post-translational modifications and sequence variations. Data dependent acquisition and data independent acquisition are the two main methods in top-down mass spectrometry. The former has been the dominant one, but it has two main challenges in proteome-wide studies: low protein coverage: a regular experiment of human cells can identify only 200 – 400 proteins, and low reproducibility: a technical triplet shares only about one third of identified proteoforms. Top-down data independent acquisition mass spectrometry (TD-DIA-MS) has the potential to significantly increase protein coverage and improve reproducibility in proteome-wide studies. However, its application has been hampered by the complexity of the data and the lack of efficient software tools. To address this problem, we will propose new algorithms and machine learning models and develop the first software package for proteoform identification by TD-DIA-MS. The proposed research will be conducted by a group of researchers with complementary expertise. All the proposed algorithms will be implemented as user-friendly open source software tools. Narrative This project addresses the proteoform identification problem by top-down data independent acquisition mass spectrometry. We will propose new machine learning models and new algorithms for high-throughput proteome-wide identification of complex proteoforms with post-translational modifications and sequence variations by using top- down data independent acquisition mass spectrometry. The proposed methods will facilitate the study of the function of complex proteoforms and the discovery of proteome biomarkers.",COMPUTATIONAL TOOLS FOR PROTEOFORM IDENTIFICATION BY TOP-DOWN DATA INDEPENDENT ACQUISITION MASS SPECTROMETRY,10049810,R01GM118470,"['Address', 'Algorithmic Software', 'Algorithms', 'Amino Acid Sequence', 'Biological', 'Biological Markers', 'Cells', 'Communities', 'Complex', 'Computer software', 'Coupling', 'Data', 'Data Analyses', 'Databases', 'Diabetes Mellitus', 'Disease', 'Drug Targeting', 'Escherichia coli', 'Evaluation', 'Feedback', 'Human', 'Insulin-Dependent Diabetes Mellitus', 'Machine Learning', 'Mass Spectrum Analysis', 'Methods', 'Modeling', 'Mus', 'Peptides', 'Post-Translational Protein Processing', 'Protein Analysis', 'Proteins', 'Proteome', 'Proteomics', 'Rattus', 'Reproducibility', 'Research', 'Research Personnel', 'Sampling', 'Software Tools', 'System', 'Technology', 'Testing', 'Time', 'Triplet Multiple Birth', 'Variant', 'Yeasts', 'base', 'computerized tools', 'design', 'effectiveness evaluation', 'experimental study', 'improved', 'insight', 'insulinoma', 'migration', 'open source', 'predictive modeling', 'signature molecule', 'software development', 'tool', 'user-friendly']",NIGMS,INDIANA UNIV-PURDUE UNIV AT INDIANAPOLIS,R01,2020,335435,0.021472439960982994
"Next Generation Testing Strategies for Assessment of Genotoxicity Project Summary  It is well recognized that current batteries of genetic toxicology assays exhibit two critical deficiencies. First, the throughput capacity of in vitro mammalian cell genotoxicity tests is low, and does not meet current needs. Second, conventional assays provide simplistic binary calls, genotoxic or non-genotoxic. In this scheme there is little or no consideration for potency, and virtually no information is provided about molecular targets and mechanisms. These deficiencies in hazard characterization prevent genotoxicity data from optimally contributing to modern risk assessments, where this information is essential. We will address these major problems with current in vitro mammalian cell genetic toxicity assays by developing methods and associated commercial assay kits that dramatically enhance throughput capacity, and delineate genotoxicants' primary molecular targets, while simultaneously providing information about potency. Once biomarkers and a family of multiplexed assays have been developed for these purposes, an interlaboratory trial will be performed with prototype assay kits to assess the transferability of the methods. Project Narrative  DNA damage that cannot be faithfully repaired results in gene mutation and/or chromosomal aberrations, and these effects are known to contribute to cancer and other severe diseases. Thus, there is an important need for sensitive assays to evaluate chemicals for genotoxic and other deleterious effects. The work proposed herein will address issues that have plagued genotoxicity assessments for the last several decades: low throughput, lack of potency metrics, and little to no information about molecular targets. We will address these major problems with current genetic toxicity assays by developing new methods and associated commercial assay kits.",Next Generation Testing Strategies for Assessment of Genotoxicity,9838229,R44ES029014,"['Address', 'Affect', 'Aneugens', 'Antioxidants', 'Appearance', 'Benchmarking', 'Biological Assay', 'Biological Markers', 'Biological Response Modifiers', 'Bleomycin', 'Caspase', 'Cell Cycle', 'Cell Nucleus', 'Cells', 'Chemicals', 'Chromosome abnormality', 'Chromosomes', 'Classification', 'Cleaved cell', 'Colcemid', 'Companions', 'Complex', 'Computer Models', 'DNA', 'DNA Damage', 'DNA Double Strand Break', 'DNA Repair', 'DNA-PKcs', 'Data', 'Data Analyses', 'Data Set', 'Disease', 'Dose', 'Epitopes', 'Etoposide', 'Exhibits', 'Family', 'GADD45A gene', 'Gamma-H2AX', 'Gene Mutation', 'Genetic', 'Goals', 'Harvest', 'Histone H3', 'Human', 'In Vitro', 'Intercalating Agents', 'Investigation', 'Kinetics', 'Label', 'Laboratories', 'Logistic Regressions', 'Machine Learning', 'Malignant Neoplasms', 'Mammalian Cell', 'Methods', 'Microtubules', 'Modeling', 'Modernization', 'Modification', 'Molecular Target', 'Mutagenicity Tests', 'NF-kappa B', 'Nuclear', 'Pathway interactions', 'Phase', 'Physiologic pulse', 'Procedures', 'Protocols documentation', 'Reagent', 'Reference Values', 'Risk Assessment', 'Schedule', 'Scheme', 'Series', 'Stains', 'TP53 gene', 'Testing', 'Time', 'Toxic effect', 'Toxicogenetics', 'Training', 'Validation', 'Work', 'aurora kinase', 'base', 'clastogen', 'computerized tools', 'design', 'experimental study', 'genotoxicity', 'hazard', 'inhibitor/antagonist', 'next generation', 'prediction algorithm', 'prevent', 'prototype', 'random forest', 'repaired', 'response', 'targeted agent', 'tool', 'treatment optimization', 'virtual']",NIEHS,"LITRON LABORATORIES, LTD.",R44,2020,474671,0.012552430589009381
"Determination of structure, dynamics and energetics of enzyme reactions Project Summary  Understanding enzyme mechanisms is of paramount importance from both the basic biophysics perspective of understanding life processes and the role of enzymes in diseases. To achieve a detailed understanding of enzyme catalysis, the effects of protein structure and dynamics on the reaction energetics need to be elucidated. We propose a combined computational and experimental approach that combines the synthetic, computational and structural biology expertise of a team of investigators that has been working together for >15 years to create a “molecular movie” where the position, movement and energy of every atom in the system followed over the entire reaction pathway. The proposal exploits the emerging convergence of timescales accessible by molecular simulation using GPUs and time resolved structural biology. Specific Aim 1 describes the simulation of the complete reaction pathway of Pseudomonas mevalonii (Pm) HMGCoA Reductase (HMGR) and will use transition state force fields (TSFFs) generated by the quantum guided molecular mechanics method to allow the µsec MD simulations of the chemical steps. TSFFs not only circumvent the well-known boundary problem of QM/MM, but are also 102-104 times faster. This allows a realistic modeling of the coupling of µsec dynamics and catalysis that was demonstrated in the last grant period to be essential for understanding the reaction. Together with accelerated MD simulations of the conformational changes involved in the reaction using standard force fields, these computational studies cover the fsec to µsec timescale. In Specific Aim 2, the computational results will be merged with the results of a three-tiered approach to obtain structural snapshots with progressively increasing time resolution: (i) “Frozen” intermediates that map out the overall pathway on long timescales, (ii) time resolved Laue crystallography using pH jump initiation on the msec timescale and (iii) use of photocaged substrates to allow time resolved Laue experiments on the µsec timescale. This approach will be applied to the study of HMGR, an enzyme of high biophysical and biomedical significance that has a complex reaction mechanism involving three chemical steps, six large-scale conformational changes and two cofactor exchange steps. The project is highly innovative because it (i) uses a combination of MD simulations using TSFFs and time resolved crystallography to span timescales of at least 12 orders of magnitude, (ii) iteratively couples the Markov State analysis of long timescale trajectories to the Singular Value Decomposition used to analyze time resolved crystallography data, thus providing new tools to generate and experimentally validate trial structures (iii) applies global optimization and machine learning techniques to allow the automated fitting of TSFFs for proteins, which will enhance the application of this powerful method to other proteins and (iv) provides new photocaged substrates for the study of enzyme mechanisms to the chemical biology community. All tool compounds, methods and codes developed in this project will be made available to the scientific community. Public Health Statement  The detailed study of enzyme mechanisms is a cornerstone of biophysical chemistry that, while basic in nature, has had a major impact on human health including the development of new mechanism-based drugs for a range of diseases and an understanding of the mechanism of action for existing drugs that allows the design of combination therapies. The combination of Laue crystallography and long-scale MD simulations will allow simultaneous studies of structure, dynamics and energetic studies with unprecedented detail. The application to HMG CoA Reductase, arguably the single most important drug target in western industrialized countries, will demonstrate the applicability of the methodology to an enzyme of high mechanistic complexity. 1","Determination of structure, dynamics and energetics of enzyme reactions",9897100,R01GM111645,"['Active Sites', 'Anti-Bacterial Agents', 'Biochemistry', 'Biological', 'Biology', 'Biophysics', 'Catalysis', 'Chemicals', 'Cholesterol', 'Code', 'Collaborations', 'Combined Modality Therapy', 'Communities', 'Complex', 'Computational Biology', 'Computing Methodologies', 'Couples', 'Coupling', 'Crystallization', 'Crystallography', 'Data', 'Developed Countries', 'Development', 'Disease', 'Drug Targeting', 'Enzymatic Biochemistry', 'Enzymes', 'Equilibrium', 'Free Energy', 'Freezing', 'Goals', 'Grant', 'Health', 'Human', 'Hydroxymethylglutaryl-CoA reductase', 'Knowledge', 'Life', 'Link', 'Machine Learning', 'Maps', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Movement', 'Mutagenesis', 'Nature', 'Oxidoreductase', 'Pathway interactions', 'Pharmaceutical Preparations', 'Positioning Attribute', 'Process', 'Protein Dynamics', 'Proteins', 'Pseudomonas', 'Public Health', 'Reaction', 'Research Personnel', 'Resolution', 'Roentgen Rays', 'Role', 'Running', 'Science', 'Structure', 'System', 'Techniques', 'Time', 'Validation', 'Work', 'base', 'biophysical chemistry', 'cofactor', 'computer studies', 'design', 'electron density', 'enzyme mechanism', 'experience', 'experimental study', 'improved', 'innovation', 'machine learning method', 'millisecond', 'molecular dynamics', 'molecular mechanics', 'molecular scale', 'movie', 'new therapeutic target', 'particle', 'protein structure', 'quantum', 'simulation', 'structural biology', 'synthetic biology', 'theories', 'tool']",NIGMS,UNIVERSITY OF NOTRE DAME,R01,2020,335664,-0.03232640195471743
"Spatiotemporal control of concentration gradients with electrochemistry in extracelluar space Project Summary  The natural environment is intrinsically spatiotemporally heterogenous at both macroscopic and microscopic levels. What shapes such a heterogeneity includes the concentration gradients of biologically relevant chemical species in the extracellular medium including dioxygen (O2), reactive oxygen species (ROS), as well as essential redox-active transition metals. While a significant amount of effort has been devoted to spectroscopically image these chemical moieties, our capability to spatiotemporally control their concentration distributions in the extracellular medium remains limited. This is especially the case for biofilms and microbiota, in which the microorganisms’ small length scales pose significant challenges for concentration modulation. The inadequate control of concentration heterogeneity limits our capability of mimicking the natural environments in vitro and investigating how local concentration gradients affect microbial functionality. Therefore, there is a need for an advanced method of controlling chemical concentrations at microscopic level.  Our proposed research aims to use electrochemical nano-/micro-electrodes to spatiotemporally control the concentration gradients in the extracellular medium. When an electrochemical reaction occurs on an electrode’s surface, a concentration gradient is established near the electrode. Taking advantages of this phenomena with the assistance of numerical simulation, we will employ an array of nano-/micro-electrodes with individually addressable electrochemical potentials to program any arbitrary spatiotemporal concentration profiles. We will fine-tune the surface chemistry and the electrochemical properties of these electrodes to ensure biocompatibility and reaction specificity. The developed system will be applied to biofilms and we aim to investigate how the microbial social behavior will be affected by a perturbation of local O2 concentration. Moreover, we will use this device to mimic the heterogenous environment in the gut and culture gut microbiota in vitro. An algorithm based on machine learning will be employed to actively adjust electrode potentials, maintaining a stable concentration profile despite the accumulation of gut microorganisms.  Ultimately, our work will expand our capability of controlling the concentration heterogeneity in nature. The developed electrochemical system will serve an in vitro platform to culture microorganisms in their native environment, or as a tool to perturb the concentration profiles. Combining electrochemistry, inorganic chemistry, and nanomaterials the research will enable a deeper understanding of the spatial distribution and temporal response of microbial systems. Project Narrative The natural environment is intrinsically heterogenous yet our control of concentrations for chemical species is limited at microscopic level. The proposed research is relevant to the mission of the NIH because it describes the development of technology that will expand our capability of controlling chemical concentration profiles in a variety of microbial systems relevant to the public health. The research described here will enable a deeper understanding of disease-related microbial systems and help to formulate strategies to combat diseases.",Spatiotemporal control of concentration gradients with electrochemistry in extracelluar space,10029526,R35GM138241,"['Affect', 'Algorithms', 'Biological', 'Chemicals', 'Chemistry', 'Devices', 'Dioxygen', 'Disease', 'Electrochemistry', 'Electrodes', 'Ensure', 'Environment', 'Heterogeneity', 'In Vitro', 'Individual', 'Inorganic Chemistry', 'Length', 'Machine Learning', 'Methods', 'Microbial Biofilms', 'Microscopic', 'Mission', 'Nanoarray Analytical Device', 'Nature', 'Oxidation-Reduction', 'Property', 'Public Health', 'Reaction', 'Reactive Oxygen Species', 'Research', 'Shapes', 'Social Behavior', 'Spatial Distribution', 'Specificity', 'Surface', 'System', 'Transition Elements', 'United States National Institutes of Health', 'Work', 'base', 'biomaterial compatibility', 'combat', 'extracellular', 'gut microbiota', 'microbial', 'microbiota', 'microorganism', 'microorganism culture', 'nano', 'nanomaterials', 'programs', 'response', 'simulation', 'spatiotemporal', 'spectroscopic imaging', 'technology development', 'tool']",NIGMS,UNIVERSITY OF CALIFORNIA LOS ANGELES,R35,2020,371084,-0.018486766636609614
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,9968331,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Diet', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computational pipelines', 'computerized tools', 'dark matter', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'in silico', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2020,1024120,0.0696303955939617
"Pacific Northwest Advanced Compound Identification Core OVERALL SUMMARY The capability to chemically identify thousands of metabolites and other chemicals in clinical samples will revolutionize the search for environmental, dietary, and metabolic determinants of disease. By comparison to near-comprehensive genetic information, comparatively little is understood of the totality of the human metabolome, largely due to insufficiencies in molecular identification methods. Through innovations in computational chemistry and advanced ion mobility separations coupled with mass spectrometry, we propose to overcome a significant, long standing obstacle in the field of metabolomics: the absence of methods for accurate and comprehensive identification of metabolites without relying on data from analysis of authentic chemical standards. A paradigm shift in metabolomics, we will use gas-phase molecular properties that can be both accurately predicted computationally and consistently measured experimentally, and which can thus be used for comprehensive identification of the metabolome without the need for authentic chemical standards. The outcomes of this proposal directly advance the mission and goals of the NIH Common Fund by: (i) transforming metabolomics science by enabling consideration of the totality of the human metabolome through optimized identification of currently unidentifiable molecules, eventually reaching hundreds of thousands of molecules, and (ii) developing standardized computational tools and analytical methods to increase the national capacity for biomedical researchers to identify metabolites quickly and accurately. This work is significant because it enables comprehensive and confident chemical measurement of the metabolome. This work is innovative because it utilizes an integrated quantum-chemistry and machine learning computational pipeline to accurately predict physical-chemical properties of metabolites coupled to measurements. OVERALL NARRATIVE This project will utilize integrated quantum-chemistry and machine learning computational computational approaches coupled with advanced instrumentation to characterize the human metabolome, and identify currently unidentifiable molecules without the use of authentic chemical standards. Results from these studies will contribute to the goal of understanding diseases, and the tools and resources will be made publically available for biomedical researchers.",Pacific Northwest Advanced Compound Identification Core,10260964,U2CES030170,"['Adoption', 'Algorithms', 'Analytical Chemistry', 'Attributes of Chemicals', 'Biological', 'Biological Markers', 'Biomedical Research', 'Chemical Structure', 'Chemicals', 'Clinical', 'Communities', 'Computers and Advanced Instrumentation', 'Computing Methodologies', 'Coupled', 'Data', 'Data Analyses', 'Databases', 'Dependence', 'Diet', 'Disease', 'Educational workshop', 'Engineering', 'Exposure to', 'Funding', 'Gases', 'Genetic', 'Goals', 'High Performance Computing', 'Human', 'Isotopes', 'Libraries', 'Liquid substance', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Methodology', 'Methods', 'Mission', 'Molecular', 'Outcome', 'Pacific Northwest', 'Phase', 'Predictive Analytics', 'Probability', 'Procedures', 'Property', 'Reference Standards', 'Research Personnel', 'Resolution', 'Resources', 'Sampling', 'Science', 'Serum', 'Source', 'Standardization', 'Structure', 'Supercomputing', 'Techniques', 'Technology', 'Testing', 'Time', 'Toxin', 'Training', 'Uncertainty', 'United States National Institutes of Health', 'Urine', 'Work', 'analytical method', 'base', 'chemical property', 'chemical standard', 'comparative', 'computational chemistry', 'computational pipelines', 'computerized tools', 'dark matter', 'drug candidate', 'drug discovery', 'experience', 'genetic information', 'human disease', 'improved', 'in silico', 'innovation', 'instrumentation', 'ion mobility', 'metabolome', 'metabolomics', 'non-genetic', 'novel', 'novel therapeutics', 'programs', 'quantum chemistry', 'small molecule libraries', 'stereochemistry', 'tool']",NIEHS,BATTELLE PACIFIC NORTHWEST LABORATORIES,U2C,2020,152500,0.0696303955939617
"Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry Mass spectrometry imaging (MSI) is a powerful technique that enables label-free spatial mapping of different classes of biomolecules in biological systems. Because it does not require any special sample pretreatment, ambient MSI is particularly attractive for high throughput automated imaging applications. The throughput of ambient MSI experiments is typically limited by the inherently slow microprobe-type sampling from surfaces, which is a characteristic shortcoming of many chemical imaging modalities. This project will combine several highly innovative approaches to address challenges associated with the high-throughput high- resolution ambient MSI of lipids and metabolites using nanospray desorption electrospray ionization (nano-DESI). Nano-DESI is an ambient ionization technique, which relies on gentle localized liquid extraction of molecules from tissue sections into a flowing solvent confined between two glass capillaries. The extracted molecules are efficiently delivered to a mass spectrometer inlet and ionized by soft electrospray ionization. Nano-DESI MSI enables detection of hundreds of metabolites, lipids, and peptides in tissue sections with high sensitivity, high spatial resolution, and without special sample pretreatment. Furthermore, on-the-fly quantification of lipids and metabolites in tissue sections during nano-DESI imaging experiments is achieved by doping the working solvent with appropriate standards of known concentration. This project will extend these powerful capabilities of nano-DESI MSI to enable high-throughput imaging of large tissue sections of interest to the HubMAP Consortium. This will be achieved using a combination of a conceptually different nano-DESI probe design optimized for robustness, ease of fabrication, and spatial resolution and a suite of advanced machine learning and compressed sensing computational approaches. These developments will be applicable to different types of human tissues and will transform quantitative molecular imaging of multiple classes of biomolecules in tissue sections. Although the capabilities of the new imaging platform will be demonstrated using non-diseased tissue, these developments will be broadly applicable to scientific problems associated with understanding health and disease Project Narrative This research is focused on the development of a transformative technology for rapid, quantitative, and robust imaging of different classes of biomolecules in human tissues using mass spectrometry. This new technology will contribute to understanding complex processes in biological tissues that play a role in both health and disease.",Novel Platform for Quantitative Subcellular Resolution Imaging of Human Tissues Using Mass Spectrometry,10026443,UH3CA255132,"['Address', 'Automation', 'Biological', 'Blood capillaries', 'Characteristics', 'Chemicals', 'Collaborations', 'Complex', 'Computer software', 'Data', 'Data Analyses', 'Detection', 'Development', 'Disease', 'Electrospray Ionization', 'Ensure', 'Glass', 'Health', 'Histology', 'Human BioMolecular Atlas Program', 'Image', 'Imaging Techniques', 'Ions', 'Label', 'Lipids', 'Liquid substance', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Microfluidics', 'Microscope', 'Molecular', 'Mus', 'Oligosaccharides', 'Optics', 'Peptides', 'Performance', 'Pharmaceutical Preparations', 'Phase', 'Play', 'Process', 'Proteins', 'Proteomics', 'RNA', 'Research', 'Resolution', 'Role', 'Sampling', 'Sensitivity and Specificity', 'Slide', 'Solvents', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Structure', 'Surface', 'Techniques', 'Technology', 'Time', 'Tissue Sample', 'Tissues', 'United States National Institutes of Health', 'Validation', 'automated analysis', 'biological systems', 'data acquisition', 'design', 'experimental study', 'human imaging', 'human tissue', 'imaging capabilities', 'imaging modality', 'imaging platform', 'innovation', 'interest', 'ionization technique', 'mass spectrometer', 'member', 'metabolomics', 'molecular imaging', 'nano', 'nanoprobe', 'new technology', 'novel', 'operation', 'preservation', 'quantitative imaging', 'reconstruction', 'scale up', 'tool']",NCI,PURDUE UNIVERSITY,UH3,2020,630000,0.04978721529258343
"Next-generation integrated quantum force fields for biomedical applications Next-generation integrated quantum force ﬁelds for biomedical applications PI: Darrin M. York, Rutgers University, Piscataway, NJ 08854-8087 USA.  We have recently developed novel framework for next-generation quantum mechanical force ﬁelds (QMFFs) designed to meet the challenges of biomolecular simulations and drug discovery applications. QMFFs have tremendous computational advantages relative to their fully QM counterparts, being inherently parallelizable and linearly scaling, offering tremendous computational speedup, and promising quantitative accuracy potentially superior to full QM methods. QMFFs accurately model multipolar electrostatics, charge penetration effects, and non-linear polarization response. QMFFs thus offer a transformative technology for drug discovery applications, in particular, for advancing the predictive capability of free energy simulations in lead reﬁnement. These are critically important for the diverse chemical space of drug molecules, including halogen bonding, cation-  and metal-ligand interactions. Further, QMFFs offer a mechanism for modeling covalent inhibitors. Speciﬁcally, we propose to: I. Develop new QMFFs for drug discovery. QMFFs will be developed based on both semiempirical and ab initio density-functional methods in the following stages: 1) determination of multipolar mapping parameters enhancing the DFTB electrostatic potential to reach greater accuracy, 2) augmentation of electronic response terms using chemical potential equalization (CPE) corrections using an orthogonal perturbation-response approach to solve the under-polarization problem of DFTB methods, 3) parameterization of non-electrostatic non-bonded interac- tion parameters using realistic potentials that capture many-body exchange and dispersion interactions, and 4) exploration of statistical potentials, using machine learning approaches applied to quantum data sets, to correct internal conformational energies and short-range interactions. II. Develop new free energy methods to enable protein-ligand binding predictions using QMFFs. We will develop a novel integrated free energy pipeline to pre- dict alchemical binding free energies for ligands and inhibitors. This will include new GPU-accelerated methods for  -space self-adaptive mixture sampling ( -SAMS) and 2D-vFEP analysis, coupled with conformational space enhanced sampling methods for alchemical steps of the thermodynamic cycle, and advancements in free en- ergy “book-ending” methods (BBQm) to efﬁciently connect molecular mechanical force ﬁeld and QMFF model representations. III. Test and validate QMFFs and free energy methods, and apply to MIF inhibitor binding. The methods will be broadly tested against established data sets for solvation free energies, and a drug discovery data set. More in-depth validation studies will be conducted by examining the relative binding free energies of inhibitors of the macrophage inhibitory factor (MIF). Finally, exploratory applications will examine mechanisms, characterize transition states and predict rates for covalent inhibition for a series of MIF inhibitors. Next-generation integrated quantum force ﬁelds for biomedical applications PI: Darrin M. York, Laboratory for Biomolecular Simulation Research, Rutgers University, Piscat- away, NJ 08854-8087 USA.  We propose a novel strategy to develop a class of integrated quantum mechanical force ﬁelds (QMFFs) that create highly accurate physical models for complex biomolecular simulations. Com- bined with recently developed high-precision free energy simulation and analysis tools, the pro- posed QMFFs will overcome current critical barriers to progress for drug discovery and deliver accurate and precise predictions for drug binding afﬁnity to enhance lead optimization. The pro- posed work will be applied to understand ligand-protein binding in the macrophage inhibitory factor (MIF), and provide insight that may guide the design of new non-covalent and targeted covalent inhibitors to MIF and other systems.",Next-generation integrated quantum force fields for biomedical applications,10005389,R01GM107485,"['Affinity', 'Attention', 'Binding', 'Binding Proteins', 'Books', 'Cations', 'Charge', 'Chemicals', 'Complex', 'Computer software', 'Coupled', 'Data', 'Data Set', 'Development', 'Drug Targeting', 'Electrostatics', 'Free Energy', 'Halogens', 'Inflammatory', 'Laboratories', 'Lead', 'Libraries', 'Ligand Binding', 'Ligands', 'Machine Learning', 'Mechanics', 'Metals', 'Methods', 'Modeling', 'Molecular', 'Molecular Conformation', 'Penetration', 'Periodicity', 'Pharmaceutical Preparations', 'Phase', 'Problem Solving', 'Proteins', 'Research', 'Sampling', 'Series', 'Structure', 'Surface', 'System', 'Technology', 'Testing', 'Thermodynamics', 'Universities', 'Variant', 'Work', 'base', 'density', 'design', 'drug discovery', 'flexibility', 'inhibitor/antagonist', 'innovation', 'insight', 'lead optimization', 'macrophage', 'mechanical force', 'nervous system disorder', 'next generation', 'novel', 'novel strategies', 'physical model', 'programs', 'quantum', 'response', 'simulation', 'tool', 'validation studies']",NIGMS,"RUTGERS, THE STATE UNIV OF N.J.",R01,2020,320588,-0.010670578666584097
"Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets PROJECT SUMMARY/ABSTRACT Recent advances in high-resolution mass spectrometry (HRMS) instrumentation have not been fully leveraged to upgrade the information content of metabolomics datasets obtained from stable isotope labeling studies. This is primarily due to lack of validated software tools for extracting and interpreting isotope enrichments from HRMS datasets. The overall objective of the current application is to develop tools that enable the metabolomics community to fully leverage stable isotopes to profile metabolic network dynamics. Two new tools will be implemented within the open-source OpenMS software library, which provides an infrastructure for rapid development and dissemination of mass spectrometry software. The first tool will automate tasks required for extracting isotope enrichment information from HRMS datasets, and the second tool will use this information to group ion peaks into interaction networks based on similar patterns of isotope labeling. The tools will be validated using in-house datasets derived from metabolic flux studies of animal and plant systems, as well as through feedback from the metabolomics community. The rationale for the research is that the software tools will enable metabolomics investigators to address important questions about pathway dynamics and regulation that cannot be answered without the use of stable isotopes. The first aim is to develop a software tool to automate data extraction and quantification of isotopologue distributions from HRMS datasets. The software will provide several key features not included in currently available metabolomics software: i) a graphical, interactive user interface that is appropriate for non-expert users, ii) support for native instrument file formats, iii) support for samples that are labeled with multiple stable isotopes, iv) support for tandem mass spectra, and v) support for multi-group or time-series comparisons. The second aim is to develop a companion software that applies machine learning and correlation-based algorithms to group unknown metabolites into modules and pathways based on similarities in isotope labeling. The third aim is to validate the tools through comparative analysis of stable isotope labeling in test standards and samples from animal and plant tissues, including time-series and dual-tracer experiments. A variety of collaborators and professional working groups will be engaged to test and validate the software, and the tools will be refined based on their feedback. The proposed research is exceptionally innovative because it will provide the advanced software capabilities required for both targeted and untargeted analysis of isotopically labeled metabolites, but in a flexible and user-friendly environment. The research is significant because it will contribute software tools that automate and standardize the data processing steps required to extract and utilize isotope enrichment information from large-scale metabolomics datasets. This work will have an important positive impact on the ability of metabolomics investigators to leverage information from stable isotopes to identify unknown metabolic interactions and quantify flux within metabolic networks. In addition, it will enable entirely new approaches to study metabolic dynamics within biological systems. PROJECT NARRATIVE The proposed research is relevant to public health because it will develop novel software tools to quantify and interpret data from stable isotope labeling experiments, which can be used to uncover relationships between metabolites and biochemical pathways. These tools have potential to accelerate progress toward identifying the causes and cures of many important diseases that impact metabolism.",Tools for Leveraging High-Resolution MS Detection of Stable Isotope Enrichments to Upgrade the Information Content of Metabolomics Datasets,10002192,U01CA235508,"['Address', 'Algorithms', 'Animals', 'Biochemical Pathway', 'Biological', 'Communities', 'Companions', 'Complement', 'Computer software', 'Data', 'Data Set', 'Detection', 'Development', 'Disease', 'Environment', 'Feedback', 'Infrastructure', 'Ions', 'Isotope Labeling', 'Isotopes', 'Knowledge', 'Label', 'Letters', 'Libraries', 'Machine Learning', 'Manuals', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolism', 'Methods', 'Modeling', 'Network-based', 'Outcome', 'Pathway interactions', 'Pattern', 'Plants', 'Process', 'Public Health', 'Publishing', 'Regulation', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Series', 'Software Tools', 'Stable Isotope Labeling', 'System', 'Technology', 'Testing', 'Time', 'Tissues', 'Tracer', 'Validation', 'Work', 'base', 'biological systems', 'comparative', 'computerized data processing', 'data standards', 'experience', 'experimental study', 'file format', 'flexibility', 'improved', 'innovation', 'instrument', 'instrumentation', 'metabolic abnormality assessment', 'metabolic phenotype', 'metabolic profile', 'metabolomics', 'novel', 'novel strategies', 'open source', 'operation', 'stable isotope', 'tandem mass spectrometry', 'tool', 'user-friendly', 'working group']",NCI,VANDERBILT UNIVERSITY,U01,2020,427122,0.05225838875779643
"Imaging Mass Spectrometry for metabolome mapping SUMMARY In response to NOT-GM-20-013, we are requesting a supplement to our R01 5R01GM120033-04 for an MALDI imaging source unit to be attached to an existing Q ExactiveMass Spectrometer (Ultra-High Mass Range Hybrid Quadrupole-Orbitrap™) for spatial mapping of metabolites in thin tissue sections. Within our R01 award, to analyze NMR metabolome data we are developing two novel, powerful, and automated algorithms that capitalize on recent developments in machine learning. We have coded these algorithms and tested their sensitivity and specificity on both synthesized and real data. We then applied these methods to human disease models and identified putative biomarkers. To validate these biomarkers, we have developed methods to analyze animal tissues and human brain organoids using imaging mass spectrometry (IMS), which permits spatial localization of metabolites without labeling. This targeted IMS metabolic phenotyping approach complements our untargeted NMR methods: it allows us to determine whether the individual metabolites identified by NMR represent bona fide biomarkers and to develop metabolic hypotheses for their association with disease. We submit this request for imaging mass spectrometer hardware because a nearby IMS facility on which we have relied has closed and no other IMS facility exists in greater Houston area. Performing the IMS studies ourselves, with the help of collaborators, will accelerate our discovery about the role small molecules and metabolites play in health and disease. This instrument will help us better i) perform metabolome screens to identify the effects of SARS-CoV-2 on neural cell types in human brain organoid models; ii) perform high-throughput drug screening to stimulate neural stem cells to produce new neurons in the brain organoid models to regenerate damaged tissue; and iii) use our NMR algorithms to develop a protocol for quantitative imaging. None of these studies will be possible without the imaging mass spectrometer. Given our access to state-of-the-art equipment, data-collection expertise, and new analytical algorithms that are especially sensitive and specific to NMR spectral data, we are uniquely positioned to advance biomarker and diagnostics tools and screening methods for metabolites and synthetic small molecules. Using an imaging mass spectrometer to map metabolite distribution may help us discover diagnostic and prognostic biomarkers not only for SARS-CoV-2, but for a broad spectrum of brain disorders that lead to neurodegeneration. Such broad usage of our platform would be transformative for neuroscientists, neurologists, and their patients. NARRATIVE The metabolome is a dynamic and sensitive biological system that reflects both innate processes and environmental influences, and can therefore tell us much about an organism's health and homeostasis. In our R01, we are developing two novel, powerful, and automated algorithms to analyze NMR metabolome data. We are requesting an MALDI imaging source unit to attach to an existing Q ExactiveMass Spectrometer (Ultra- High Mass Range Hybrid Quadrupole-Orbitrap™) to validate our ongoing NMR studies and accelerate the translation of our biomarker discoveries to the clinical realm.",Imaging Mass Spectrometry for metabolome mapping,10175695,R01GM120033,"['2019-nCoV', 'Algorithms', 'Area', 'Award', 'Biological Markers', 'Brain', 'Brain Diseases', 'Clinical', 'Code', 'Complement', 'Data', 'Data Collection', 'Development', 'Diagnostic', 'Disease', 'Disease model', 'Equipment', 'Health', 'Homeostasis', 'Human', 'Hybrids', 'Image', 'Individual', 'Label', 'Lead', 'Machine Learning', 'Maps', 'Mass Spectrum Analysis', 'Metabolic', 'Methods', 'Modeling', 'Nerve Degeneration', 'Neurologist', 'Neurons', 'Organism', 'Organoids', 'Patients', 'Play', 'Positioning Attribute', 'Process', 'Prognostic Marker', 'Protocols documentation', 'Role', 'Sensitivity and Specificity', 'Source', 'Spectrometry, Mass, Matrix-Assisted Laser Desorption-Ionization', 'Testing', 'Thinness', 'Tissues', 'Translations', 'animal tissue', 'automated algorithm', 'biological systems', 'biomarker discovery', 'cell type', 'diagnostic biomarker', 'high-throughput drug screening', 'human disease', 'instrument', 'mass spectrometer', 'metabolic phenotype', 'metabolome', 'nerve stem cell', 'novel', 'quantitative imaging', 'response', 'screening', 'small molecule', 'targeted imaging', 'tissue regeneration', 'tool']",NIGMS,BAYLOR COLLEGE OF MEDICINE,R01,2020,209619,0.0325824778507693
"Illuminating Function of the Understudied Druggable Kinome Project Summary/Abstract Kinases are among the most important drug targets and clinically significant kinase inhibitors have been developed for multiple diseases. A subset of kinases, the understudied dark kinases (DKs), have received little or no attention because foundational data on their biochemical and biological functions is not available. This proposal will collect such data by perturbing DKs genetically and with small molecules and then measuring the cellular consequences using multiplex proteomic, gene expression, metabolomic and imaging assays. A subset of DKs with potential links to human disease will be intensively studied as a means to qualify new therapeutic drug targets. Data collected in this project will be aggregated with existing information from previous NIH-funded large-scale structural and genomic projects to create a Dark Kinase Knowledgebase (DKK) that provides gene-by-gene and network-level information on the dark kinome and its interaction with other signal transduction and regulatory networks. Close coordination with the NIH LINCS project will ensure data interoperability and make efficient use of informatics tools. The DKK will be developed in collaboration with the IDG Knowledge Management Center (KMC), adhere to standards for Findable, Accessible, Interoperable and Reusable (FAIR) data, and be accessible to human users and machines (via an API). Commercially available DK reagents be validated and extended with new genetic and chemical tools provided to the Resource Dissemination Center (RDOC). The overall approach will be iterative, with simpler methods applied first (e.g. simple gene knockout) and more sophisticated methods subsequently (e.g. stable CRIPSRa/i) pursued by an interdisciplinary team of chemists, computational biologists, mass spectroscopists and pharmacologists working on five linked aims. Aim 1 will develop a computational algorithm for prioritizing DKs, develop and maintain the DKK, and perform network-level analysis on the kinome using supervised and unsupervised machine learning. Aim 2 will measure kinase abundance in normal and perturbed cells using parallel reaction monitoring with stable isotope dilution (PRM-SID) and RNASeq and data analyzed using network inference tools to provide insight into dark and light kinome in diverse cell types. Aim 3 will perturb DKs with genetic tools such as CRIPSR/Cas9-mediated gene knockout, CRIPSRa/i to induce more subtle-up and down regulation and inducible gene inaction. The impact on cell fate, morphology and signal transduction will then be determined using PRM-SID, phosphoproteomics, RNASeq, gene reporter assays, metabolomics profiling and highly multiplex single-cell imaging. Aim 4 will extend DK analysis to small molecule inhibitors by carefully profiling existing drugs against DKs and by designing and synthesizing new chemical ligands. Aim 5 will involve collaboration with other investigators to assay the expression and function of DKs in primary human cells and tissues relevant to the NIH Precision Medicine Initiative. All aims will be pursued in parallel for a progressively expanding resource of data and tools for continued study of DKs. Project Narrative/Health Relevance Advancing understanding of understudied kinases, a highly druggable class of proteins, will increase knowledge about signal transduction and control over cellular physiology and is likely to reveal a subset of proteins that should be advanced as targets for new therapeutic drugs.",Illuminating Function of the Understudied Druggable Kinome,10015261,U24DK116204,"['Algorithms', 'Anabolism', 'Arthritis', 'Attention', 'Biochemical', 'Biological', 'Biological Assay', 'Biological Process', 'Cell Line', 'Cell physiology', 'Cells', 'Chemicals', 'Chronic Obstructive Airway Disease', 'Clustered Regularly Interspaced Short Palindromic Repeats', 'Collaborations', 'Collection', 'Complement', 'Computational algorithm', 'Cystic Fibrosis', 'Data', 'Data Analyses', 'Development', 'Diabetes Mellitus', 'Disease', 'Down-Regulation', 'Drug Targeting', 'Engineering', 'Ensure', 'FAIR principles', 'Foundations', 'Funding', 'Gene Expression', 'Generations', 'Genes', 'Genetic', 'Goals', 'Health', 'Homeostasis', 'Human', 'Image', 'Individual', 'Information Resources Management', 'Knowledge', 'Libraries', 'Ligands', 'Light', 'Link', 'Logic', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mediating', 'Metadata', 'Methods', 'Modeling', 'Molecular', 'Monitor', 'Morphology', 'Mutate', 'Pharmaceutical Preparations', 'Phenotype', 'Phosphotransferases', 'Play', 'Precision Medicine Initiative', 'Production', 'Proteins', 'Proteomics', 'Reaction', 'Reagent', 'Reporter', 'Reporter Genes', 'Research', 'Research Personnel', 'Resolution', 'Resources', 'Role', 'Signal Transduction', 'Signal Transduction Pathway', 'Site', 'Supervision', 'Technology', 'Testing', 'Therapeutic', 'Tissues', 'Tumor Tissue', 'United States National Institutes of Health', 'Up-Regulation', 'Validation', 'base', 'cell type', 'cellular imaging', 'clinically significant', 'computerized tools', 'data interoperability', 'data resource', 'data reuse', 'data tools', 'design', 'human disease', 'informatics tool', 'innovation', 'insight', 'kinase inhibitor', 'knockout gene', 'knowledge base', 'metabolic profile', 'metabolomics', 'new therapeutic target', 'novel', 'novel therapeutics', 'phosphoproteomics', 'programs', 'protein protein interaction', 'screening', 'small molecule', 'small molecule inhibitor', 'stable isotope', 'structural genomics', 'therapeutic development', 'therapeutic target', 'tool', 'transcription factor', 'transcriptome sequencing', 'unsupervised learning']",NIDDK,UNIV OF NORTH CAROLINA CHAPEL HILL,U24,2020,2259159,-0.001296085531721469
"Modeling Homeostasis of Human Blood Metabolites PROJECT SUMMARY  Metabolite levels in human blood are regulated by a relatively strict system of homeostatic control. Previous investigations of homeostasis have taken a number of approaches, and models of glucose and a few other metabolites have been developed, typically focused on a single organ. However, while potentially extremely useful, an accurate and quantitative model of blood metabolite levels under homeostasis does not currently exist.  It is well known that numerous demographic and clinical factors such as gender, age, BMI, smoking, etc., as well as pre-analytical factors and many diseases, significantly affect the levels of blood metabolites. Numerous studies in the field of metabolomics have attempted to account for the effects of many such factors. However, efforts to quantify these effects and validate them across different studies have so far been challenging, and resulted in consistent failures to validate discovered putative biomarkers. The challenges to integrate metabolite profiles with clinical and demographic factors are complicated by the high dimensionality of the data and the numerous correlations among the metabolites. Traditional statistical methods are incapable of accounting for these factors, and hence, investigations suffer from a high false discovery rate (FDR).  To overcome these challenges, we propose to develop quantitative statistical models of blood metabolite levels in healthy adults, and thereby produce a predictive model of homeostasis. Our preliminary work indicates that we can predict metabolite levels with much reduced variance using the reproducibly measured levels of a large pool of blood metabolites and clinical and demographic variables. We propose to develop sophisticated models of homeostasis based on advanced statistical methods and evaluate their predictive performance across different sample sets and metabolite classes.  The proposed project has four main Aims: (1) Obtain broad-based metabolomics data on blood samples collected from geographically distinct sites to explore the effects of a range of confounding effects on metabolite levels. (2) Model individual or biologically related groups of metabolite levels using multivariate statistical approaches to determine the contribution of clinical/demographic and pre-analytical variables and their predictability across collection site. (3) Investigate the interactions between metabolites and clinical/demographic variables using machine learning approaches to identify stable metabolites and key interactions. (4) Provide the community with user-friendly software packages for the prediction of blood metabolite levels under homeostasis.  An overall model of the metabolite concentrations in blood will be highly useful for a number of applications that include a better understanding of systems biology at the whole organism level, and ultimately improved risk prediction, disease diagnosis, treatment monitoring and outcomes analysis. PROJECT NARRATIVE A quantitative model of blood homeostasis based on predicting the normal levels of small molecules in the blood can help identify diseases or other stresses that cause changes to those levels. The proposed statistical methods that will be used to develop this homeostasis model have the potential to efficiently identify more reliable disease markers and to more accurately predict disease risk.",Modeling Homeostasis of Human Blood Metabolites,9995722,R01GM131491,"['Accounting', 'Address', 'Adult', 'Affect', 'Age', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biometry', 'Blood', 'Blood specimen', 'Clinical', 'Collection', 'Communities', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Demographic Factors', 'Development', 'Dimensions', 'Disease', 'Disease Marker', 'Evaluation', 'Failure', 'Gases', 'Gender', 'Geographic Locations', 'Geography', 'Glucose', 'Homeostasis', 'Human', 'Individual', 'Investigation', 'Ions', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Metabolic', 'Metabolic Pathway', 'Metabolite Interaction', 'Modeling', 'Monitor', 'NMR Spectroscopy', 'Organ', 'Outcome', 'Performance', 'Risk', 'Sampling', 'Site', 'Smoking', 'Source', 'Statistical Methods', 'Statistical Models', 'Stress', 'Supervision', 'System', 'Systems Biology', 'Technology', 'Temperature', 'Time', 'Training', 'Validation', 'Whole Organism', 'Work', 'base', 'clinical effect', 'cohort', 'computerized tools', 'data quality', 'disease diagnosis', 'disorder risk', 'improved', 'interoperability', 'metabolome', 'metabolomics', 'multidimensional data', 'predictive modeling', 'sample collection', 'small molecule', 'software development', 'user friendly software', 'user-friendly', 'validation studies']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,395738,0.010830745164952573
"Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC PROJECT SUMMARY The Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC (CMP-GA) is a cross-cutting team with advanced high-throughput chemical analytics and big data capabilities to develop a comprehensive map of molecular transducers of physical activity. The investigative team excels in ultrasensitive, precise and spatially resolved analyses of small molecules, lipids, and proteins. The team members have strong academic records as innovative, independent scientists, core laboratory directors and effective collaborators in complex research initiatives. Instrumentation includes state-of-the-art ultra-high resolution accurate mass high-field Orbitrap tandem mass spectrometry (MS) and ultraperformance liquid chromatography (UPLC); three- dimensional (3-D) molecular imaging via high throughput multi-modal MS at 5 m resolution; unique ion mobility-mass spectrometry machine-learning approaches for chemical identifications; and other such as GC- Orbitrap, 1D and 2D high field (800 MHz) NMR spectroscopy, ICP-MS, immunoassays, chemical and enzymatic assays, etc. The analytical laboratories are integrated through the NIH-supported Atlanta Clinical and Translational Sciences Institute, and operate within the outstanding research environment of Emory University and the Georgia Institute of Technology (GA Tech). CMP-GA has six elements organized to provide 1) leadership in the design and implementation of MoTrPAC goals; 2) bioinformatics, computational support and data delivery to the MoTrPAC Data Coordinating Center; 3) global, targeted and spatially resolved metabolomics; 4) metabolite forensics for unequivocal chemical identification of novel molecular transducers; 5) innovative proteomic and chemoproteomic technologies to define transducers within the redox proteome, ubiquitinome, acetylome, kinome and nuclear proteome; and 6) identification and quantification of lipid transducers. Through the successful completion of these aims and collaboration with the MoTrPAC consortium, investigators of CMP-GA will deliver a publically-available data resource and molecular transducer map that will enhance and accelerate mechanistic research on diseases and conditions affected by physical activity. PROJECT NARRATIVE This is a comprehensive metabolomics and proteomics chemical analysis site to support the Molecular Transducers of Physical Activity Consortium (MoTrPAC). Advanced analytical methods, including mass spectrometry, bioinformatics and chemical forensics are used to provide targeted and global analysis of small molecules, lipids, proteins to develop a molecular transducer map for physical activity.",Georgia Comprehensive Metabolomics and Proteomics Unit for MoTrPAC,9869890,U24DK112341,"['3-Dimensional', 'Adipocytes', 'Affect', 'Aging', 'Animal Experimentation', 'Animals', 'Automobile Driving', 'Big Data', 'Bioinformatics', 'Biological Assay', 'Chemicals', 'Clinical', 'Clinical Research', 'Clinical Sciences', 'Collaborations', 'Communication', 'Complement', 'Complex', 'Custom', 'Data', 'Data Coordinating Center', 'Development', 'Disease', 'Educational workshop', 'Elements', 'Environment', 'Exercise', 'Forensic Medicine', 'Goals', 'Health', 'Health Benefit', 'Immunoassay', 'Institutes', 'Isotopes', 'Label', 'Laboratories', 'Leadership', 'Link', 'Lipids', 'Liquid Chromatography', 'Machine Learning', 'Malignant Neoplasms', 'Maps', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Molecular', 'Molecular Structure', 'Molecular Target', 'Monitor', 'Muscle', 'NMR Spectroscopy', 'Neurodegenerative Disorders', 'Nuclear', 'Oral', 'Oxidation-Reduction', 'Oxidative Stress', 'Particle Size', 'Peptide Mapping', 'Phosphotransferases', 'Physical activity', 'Plasma', 'Post-Translational Protein Processing', 'Procedures', 'Process', 'Proteins', 'Proteome', 'Proteomics', 'Protocols documentation', 'Publications', 'Reaction', 'Records', 'Research', 'Research Personnel', 'Resolution', 'Sampling', 'Scientist', 'Signal Transduction', 'Site', 'System', 'Systems Biology', 'Technology', 'Time', 'Training', 'Transducers', 'Translational Research', 'United States National Institutes of Health', 'Universities', 'Validation', 'advanced analytics', 'advanced system', 'analytical method', 'chemoproteomics', 'cytokine', 'data resource', 'design', 'differential expression', 'innovation', 'instrumentation', 'ion mobility', 'lectures', 'member', 'metabolomics', 'molecular imaging', 'multimodality', 'novel', 'oxidized lipid', 'phenotypic biomarker', 'response', 'small molecule', 'tandem mass spectrometry', 'tool', 'ultra high resolution']",NIDDK,EMORY UNIVERSITY,U24,2020,1637275,0.029869634989698374
"Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria PROJECT SUMMARY Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacterial infections are increasing in incidence and novel antibiotics are urgently needed to combat this growing threat to public health. A major roadblock to the development of novel antibiotics is our poor understanding of the structural features of small molecules that correlate with bacterial penetration and efflux. As a result, while potent biochemical inhibitors can often be identified for new targets, developing them into compounds with whole-cell antibacterial activity has proven challenging. To address this critical problem, we propose herein a comprehensive, multidisciplinary approach to develop quantitative models to predict small-molecule penetration and efflux in Gram-negative bacteria. We have pioneered a general platform for systematic, quantitative evaluation of small-molecule accumulation in bacteria, using label-free LC-MS/MS detection and multivariate cheminformatic analysis. We have also developed unique isogenic strain sets of wild-type, hyperporinated, efflux-knockout, and doubly-compromised E. coli, P. aeruginosa, and A. baumannii that allow us to dissect the individual contributions of outer/inner membrane penetration and active efflux to net accumulation, using a kinetic model that accurately recapitulates available experimental data. Moreover, we have developed machine learning and neural network approaches to QSAR (quantitative structure–activity relationship) modeling of pharmacological properties that will now be used to develop predictive cheminformatic models for Gram-negative accumulation, penetration, and efflux. This project will be carried out by a multidisciplinary SPEAR-GN Project Team (Small-molecule Penetration & Efflux in Antibiotic-Resistant Gram-Negatives, “speargun”) involving the labs of Derek Tan (MSK, PI), Helen Zgurskaya (OU, PI), Bradley Sherborne (Merck, Lead Collaborator), Valentin Rybenkov (OU, Co-I), Adam Duerfeldt (OU, Co-I), Carl Balibar (Merck, Collaborator), and David McLaren (Merck, Collaborator), comprising extensive combined expertise in organic and diversity-oriented synthesis, biochemistry, microbiology, high- throughput screening, mass spectrometry, biophysical modeling, cheminformatics, and medicinal chemistry. Herein, we will design and synthesize chemical libraries with diverse structural and physicochemical properties; analyze their accumulation in the isogenic strain sets in both high-throughput and high-density assay formats; extract kinetic parameters for penetration and efflux from the resulting experimental datasets; develop and validate robust QSAR models for accumulation, penetration, and efflux; and demonstrate the utility of these models in medicinal chemistry campaigns to develop novel Gram-negative antibiotics against three targets. This project will provide a major advance in the field of antibacterial drug discovery, providing powerful enabling tools to the scientific community to address this major threat to public health. PUBLIC HEALTH RELEVANCE Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria. Antibiotic-resistant Gram-negative bacteria pose a growing threat to public health in the U.S. and globally. A major obstacle to the development of new antibiotics to combat such infections is our poor understanding of the chemical requirements for small molecules to enter Gram-negative cells and to avoid ejection by efflux pumps. The proposed comprehensive, multidisciplinary research program aims to develop predictive computational tools to identify such molecules by carrying out large-scale, quantitative analyses of the accumulation of diverse small molecules in Gram-negative bacteria. These tools will then enable medicinal chemistry campaigns to develop novel antibiotics.",Predictive Models for Small-Molecule Accumulation in Gram-Negative Bacteria,9982190,R01AI136795,"['Acinetobacter baumannii', 'Address', 'Algorithmic Software', 'Anti-Bacterial Agents', 'Antibiotic Resistance', 'Antibiotics', 'Architecture', 'Bacteria', 'Biochemical', 'Biochemistry', 'Biological Assay', 'Biological Availability', 'Cells', 'Chemicals', 'Communities', 'Data', 'Data Set', 'Detection', 'Development', 'Effectiveness', 'Escherichia coli', 'Gram-Negative Bacteria', 'Gram-Negative Bacterial Infections', 'Human', 'Incidence', 'Individual', 'Infection', 'Interdisciplinary Study', 'Kinetics', 'Knock-out', 'Label', 'Lead', 'Libraries', 'Machine Learning', 'Mammalian Cell', 'Mass Spectrum Analysis', 'Measurement', 'Measures', 'Membrane', 'Microbiology', 'Modeling', 'Oral', 'Partner in relationship', 'Penetration', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Pharmacology', 'Property', 'Pseudomonas aeruginosa', 'Public Health', 'Quantitative Evaluations', 'Quantitative Structure-Activity Relationship', 'Role', 'Structure', 'Testing', 'Variant', 'analog', 'base', 'biophysical model', 'cell envelope', 'cheminformatics', 'combat', 'computerized tools', 'density', 'design', 'drug discovery', 'efflux pump', 'high throughput screening', 'improved', 'inhibitor/antagonist', 'interdisciplinary approach', 'kinetic model', 'lead optimization', 'learning network', 'multidisciplinary', 'neural network', 'novel', 'predictive modeling', 'programs', 'prospective', 'public health relevance', 'screening', 'small molecule', 'small molecule libraries', 'success', 'tool']",NIAID,SLOAN-KETTERING INST CAN RESEARCH,R01,2020,1239304,0.009840935820182086
"Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design PROJECT SUMMARY/ABSTRACT The study of biomolecular interactions and design of new therapeutics requires accurate physical models of the atomistic interactions between small molecules and biological macromolecules. Over the least few decades, molecular mechanics force ﬁelds have demonstrated the potential that physical models hold for quantitative biophysical modeling and predictive molecular design. However, a signiﬁcant technology gap exists in our ability to build force ﬁelds that achieve high accuracy, can be systematically improved in a statistically robust manner, be extended to new areas of chemistry, can model post-translational and covalent modiﬁcations, are able to quantify systematic errors in predictions, and can be broadly applied across a high-performance software packages. In this project, we willl bridge this technology gap to enable new generations of accurate quantitative biomolec- ular modeling and (bio)molecular design for chemical biology and drug discovery. In Aim 1, we will produce a modern, open infrastructure to enable practitioners to rapidly and conveniently construct and employ accurate and statistically robust physical force ﬁelds via automated machine learning methods. In Aim 2, we will construct open, machine-readable experimental and quantum chemical datasets that will accelerate next-generation force ﬁeld development. In Aim 3, we will develop statistically robust Bayesian inference techniques to enable the auto- mated construction of type assignment schemes that avoid overﬁtting and selection of physical functional forms statistically justﬁed by the data. This approach will also provide an estimate of the systematic error in predicted properties arising from uncertainty in parameters or functional form choices—generally the dominant source of error—to be quantiﬁed with little added expense. In Aim 4, we will integrate and apply this infrastructure to produce open, transferable, self-consistent force ﬁelds that achieve high accuracy and broad coverage for modeling small molecule interactions with biomolecules (including unnatural amino or nucleic acids and covalent modiﬁcations by organic molecules), with the ultimate goal of covering all major biomolecules. This research is signiﬁcant in that the technology developed in this project has the potential to radically transform the study of biomolecular phenomena by providing highly accurate force ﬁelds with exceptionally broad chemical coverage via fully consistent parameterization of organic (bio)molecules. In addition, we will produce new tools to automate force ﬁeld creation and tailoring to speciﬁc problem domains, quantify the systematic error in predictions, and identify new data for improving force ﬁeld accuracy. This will greatly improve our ability to study diverse biophysical processes at the molecular level, and to rationally design new small-molecule, protein, and nucleic acid therapeutics. This supplement to the original RO1 is to purchase a small GPU cluster to enable rapid prototyping of many of the approaches that are proposed in this project outlined in the four aims. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life carry out their functions and to design new medications. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms. This equipment supplement will provide computational resources for testing of new techniques throughout the duration of the grant.",Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design,10157034,R01GM132386,"['Address', 'Area', 'Automobile Driving', 'Award', 'Bayesian Analysis', 'Binding', 'Biological', 'Biology', 'Biophysical Process', 'Biophysics', 'Charge', 'Chemicals', 'Chemistry', 'Complex', 'Computer Simulation', 'Computer software', 'DNA', 'Data', 'Data Set', 'Databases', 'Development', 'Drug Design', 'Electrostatics', 'Ensure', 'Equipment', 'Error Sources', 'Generations', 'Goals', 'Grant', 'Heart', 'Individual', 'Infrastructure', 'Investigation', 'Learning', 'Life', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Molecular', 'Nucleic Acids', 'Perception', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Property', 'Proteins', 'RNA', 'Readability', 'Reproducibility', 'Research', 'Roentgen Rays', 'Scheme', 'Science', 'Scientist', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Technology', 'Temperature', 'Testing', 'Therapeutic', 'Thermodynamics', 'Training', 'Uncertainty', 'Validation', 'Work', 'base', 'biophysical model', 'chemical synthesis', 'cheminformatics', 'computing resources', 'data infrastructure', 'design', 'drug discovery', 'experience', 'experimental study', 'improved', 'interest', 'machine learning method', 'macromolecule', 'models and simulation', 'molecular mechanics', 'multidisciplinary', 'new technology', 'next generation', 'novel therapeutics', 'nucleic acid-based therapeutics', 'open data', 'open source', 'physical model', 'physical property', 'prototype', 'quantum', 'simulation', 'simulation software', 'small molecule', 'software infrastructure', 'sound', 'tool', 'unnatural amino acids']",NIGMS,UNIVERSITY OF COLORADO,R01,2020,96003,0.006464973405259766
"Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design PROJECT SUMMARY/ABSTRACT The study of biomolecular interactions and design of new therapeutics requires accurate physical models of the atomistic interactions between small molecules and biological macromolecules. Over the least few decades, molecular mechanics force ﬁelds have demonstrated the potential that physical models hold for quantitative biophysical modeling and predictive molecular design. However, a signiﬁcant technology gap exists in our ability to build force ﬁelds that achieve high accuracy, can be systematically improved in a statistically robust manner, be extended to new areas of chemistry, can model post-translational and covalent modiﬁcations, are able to quantify systematic errors in predictions, and can be broadly applied across a high-performance software packages. In this project, we aim to bridge this technology gap to enable new generations of accurate quantitative biomolec- ular modeling and (bio)molecular design for chemical biology and drug discovery. In Aim 1, we will produce a modern, open infrastructure to enable practitioners to rapidly and conveniently construct and employ accurate and statistically robust physical force ﬁelds via automated machine learning methods. In Aim 2, we will construct open, machine-readable experimental and quantum chemical datasets that will accelerate next-generation force ﬁeld development. In Aim 3, we will develop statistically robust Bayesian inference techniques to enable the auto- mated construction of type assignment schemes that avoid overﬁtting and selection of physical functional forms statistically justﬁed by the data. This approach will also provide an estimate of the systematic error in predicted properties arising from uncertainty in parameters or functional form choices—generally the dominant source of error—to be quantiﬁed with little added expense. In Aim 4, we will integrate and apply this infrastructure to produce open, transferable, self-consistent force ﬁelds that achieve high accuracy and broad coverage for modeling small molecule interactions with biomolecules (including unnatural amino or nucleic acids and covalent modiﬁcations by organic molecules), with the ultimate goal of covering all major biomolecules. This research is signiﬁcant in that the technology developed in this project has the potential to radically transform the study of biomolecular phenomena by providing highly accurate force ﬁelds with exceptionally broad chemical coverage via fully consistent parameterization of organic (bio)molecules. In addition, we will produce new tools to automate force ﬁeld creation and tailoring to speciﬁc problem domains, quantify the systematic error in predictions, and identify new data for improving force ﬁeld accuracy. This will greatly improve our ability to study diverse biophysical processes at the molecular level, and to rationally design new small-molecule, protein, and nucleic acid therapeutics. This approach will bring statistical rigor to the ﬁeld of force ﬁeld construction and application by providing a means to make data-driven decisions, while enhancing reproducibility by enabling it to become a rigorous and reproducible science using a fully open infrastructure and datasets. PROJECT NARRATIVE Scientists use computer simulations of proteins, DNA, and RNA, at atomic detail, to learn how these molecules of life do their jobs. They also use simulations to help design new medications – compounds that can bind and inﬂuence the behavior of these molecules of life, and thereby block diseases at the molecular level. We aim to greatly increase the utility of all of these simulations by improving the accuracy of the formulas they use to compute the forces acting between atoms.",Open data-driven infrastructure for building biomolecular force fields for predictive biophysics and drug design,9887804,R01GM132386,"['Address', 'Area', 'Automobile Driving', 'Bayesian Analysis', 'Binding', 'Biological', 'Biology', 'Biophysical Process', 'Biophysics', 'Charge', 'Chemicals', 'Chemistry', 'Complex', 'Computer Simulation', 'Computer software', 'DNA', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Drug Design', 'Electrostatics', 'Ensure', 'Error Sources', 'Generations', 'Goals', 'Heart', 'Individual', 'Infrastructure', 'Investigation', 'Learning', 'Life', 'Measurement', 'Methods', 'Modeling', 'Modernization', 'Modification', 'Molecular', 'Nucleic Acids', 'Occupations', 'Perception', 'Performance', 'Pharmaceutical Preparations', 'Process', 'Property', 'Proteins', 'RNA', 'Readability', 'Reproducibility', 'Research', 'Roentgen Rays', 'Scheme', 'Science', 'Scientist', 'Specific qualifier value', 'Structure', 'System', 'Techniques', 'Technology', 'Temperature', 'Therapeutic', 'Thermodynamics', 'Training', 'Uncertainty', 'Validation', 'Work', 'base', 'behavior influence', 'biophysical model', 'chemical synthesis', 'cheminformatics', 'data infrastructure', 'design', 'drug discovery', 'experience', 'experimental study', 'improved', 'interest', 'machine learning method', 'macromolecule', 'models and simulation', 'molecular mechanics', 'multidisciplinary', 'new technology', 'next generation', 'novel therapeutics', 'nucleic acid-based therapeutics', 'open data', 'open source', 'physical model', 'physical property', 'quantum', 'simulation', 'simulation software', 'small molecule', 'software infrastructure', 'sound', 'tool', 'unnatural amino acids']",NIGMS,UNIVERSITY OF COLORADO,R01,2020,675565,0.008521775344850397
"High-Throughput De Novo Glycan Sequencing Glycosylation fulfills important physiological functions, including protein folding, embryogenesis, cell adhesion, pathogen recognition, and immune response. The multifaceted roles glycosylation plays derive from the presence of a range of glycan epitopes, where a small structural variation can have a profound impact on functions. Further, a glycome consists of many closely related structures, with their relative amounts determined by metabolic conditions in a cell- and growth-specific manner. Altered glycosylation is linked to many diseases, including cardiovascular, pulmonary, neurological and autoimmune disorders, and cancer. Thus, there is a clear need for analytical methods that can rapidly identify and quantify the many glycoforms in a glycome from different health and disease states. Finally, no genome-predicted glycan database exists due to the unscripted nature of glycan biosynthesis, and discovery of new glycan structures must be achieved by de novo methods. Although tandem mass spectrometry-based biopolymer sequencing has been the major catalyst to the recent rapid advance of 'omics, the prevailing collisionally activated dissociation method often fails to provide sufficient glycan structural detail at the MS2 level, whereas the MSn approach lacks the speed, sensitivity, and quantitative potential for high-throughput glycome analysis. We have recently developed an electronic excitation dissociation (EED) method that can yield rich structural information in a single stage of MS/MS analysis. However, the impact of EED on glycomics research is currently limited by its poor accessibility, insufficient coupling to on-line glycan separation methods, and difficulty in interpretation of complex glycan EED tandem mass spectra. Here, we propose to develop an integrated approach that combines EED with on-line liquid chromatography (LC) separation and a novel bioinformatics tool to achieve high-throughput, de novo, and comprehensive glycome characterization. We will explore the potential of EED for analysis of glycans in various derivatized forms, study their fragmentation behaviors, and establish fragmentation rules for the development of bioinformatics software. We will optimize conditions for efficient coupling of EED to reversed-phase, and porous graphitic carbon LC, and develop an LC-EED-MS/MS approach for simultaneous characterization and quantitation of glycan mixtures. We will implement EED on a Q-TOF instrument to improve its access to the glycoscience community. Finally, we will develop and rigorously test the performance of a novel bioinformatics software that can rapidly and accurately determine each glycan's structure from its tandem MS spectra. The proposed algorithm is fundamentally different from most existing software, in that it no longer relies solely on glycosidic and cross-ring fragments for topology and linkage analysis, but rather adopts a machine learning approach that considers the contexts of various types of fragment peaks, and the spectral features associated with different linkage configurations and structural motifs. The availability of such a high-throughput, de novo glycan sequencing tool will have an immense impact on many biomedical research fields, as glycosylation plays critical roles in almost all biological pathways. High-Throughput De Novo Glycan Sequencing Project narrative Characterization of glycans from biological sources requires sensitive and high-throughput analytical methods that can separate and identify each glycoform in a complex mixture. We propose to develop an HPLC-EED- MS/MS method for comprehensive glycome characterization. We will also develop a novel bioinformatics program that can accurately determine the glycan structure from its EED tandem mass spectrum de novo.",High-Throughput De Novo Glycan Sequencing,10000171,R01GM132675,"['Address', 'Adopted', 'Algorithm Design', 'Algorithms', 'Anabolism', 'Autoimmune Diseases', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Research', 'Biopolymers', 'Carbon', 'Cardiovascular Diseases', 'Cell Adhesion', 'Communities', 'Complex', 'Complex Mixtures', 'Computer software', 'Coupling', 'Data', 'Data Set', 'Databases', 'Development', 'Disease', 'Dissociation', 'Effectiveness', 'Electron Transport', 'Embryonic Development', 'Epitopes', 'Fourier transform ion cyclotron resonance', 'Genome', 'Glycoconjugates', 'Glycosides', 'Health', 'High Pressure Liquid Chromatography', 'Immune response', 'Impairment', 'Individual', 'Isomerism', 'Link', 'Liquid Chromatography', 'Liquid substance', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Metabolic', 'Methods', 'Natural graphite', 'Nature', 'Pathologic Processes', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Physiological Processes', 'Physiology', 'Play', 'Polysaccharides', 'Research', 'Research Project Grants', 'Role', 'Sampling', 'Scheme', 'Source', 'Specificity', 'Speed', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Vacuum', 'Variant', 'analytical method', 'base', 'bioinformatics tool', 'catalyst', 'cell growth', 'design', 'genetic linkage analysis', 'glycosylation', 'improved', 'instrument', 'mass spectrometer', 'nervous system disorder', 'novel', 'pathogen', 'performance tests', 'programs', 'protein folding', 'reconstruction', 'tandem mass spectrometry', 'therapeutic target', 'tool', 'ultraviolet']",NIGMS,BOSTON UNIVERSITY MEDICAL CAMPUS,R01,2020,447308,0.012839898274211997
"High-Throughput De Novo Glycan Sequencing Awarded Abstract: Glycosylation fulfills important physiological functions, including protein folding, embryogenesis, cell adhesion, pathogen recognition, and immune response. The multifaceted roles glycosylation plays derive from the presence of a range of glycan epitopes, where a small structural variation can have a profound impact on functions. Further, a glycome consists of many closely related structures, with their relative amounts determined by metabolic conditions in a cell- and growth-specific manner. Altered glycosylation is linked to many diseases, including cardiovascular, pulmonary, neurological and autoimmune disorders, and cancer. Thus, there is a clear need for analytical methods that can rapidly identify and quantify the many glycoforms in a glycome from different health and disease states. Finally, no genome-predicted glycan database exists due to the unscripted nature of glycan biosynthesis, and discovery of new glycan structures must be achieved by de novo methods. Although tandem mass spectrometry-based biopolymer sequencing has been the major catalyst to the recent rapid advance of 'omics, the prevailing collisionally activated dissociation method often fails to provide sufficient glycan structural detail at the MS2 level, whereas the MSn approach lacks the speed, sensitivity, and quantitative potential for high-throughput glycome analysis. We have recently developed an electronic excitation dissociation (EED) method that can yield rich structural information in a single stage of MS/MS analysis. However, the impact of EED on glycomics research is currently limited by its poor accessibility, insufficient coupling to on-line glycan separation methods, and difficulty in interpretation of complex glycan EED tandem mass spectra. Here, we propose to develop an integrated approach that combines EED with on-line liquid chromatography (LC) separation and a novel bioinformatics tool to achieve high-throughput, de novo, and comprehensive glycome characterization. We will explore the potential of EED for analysis of glycans in various derivatized forms, study their fragmentation behaviors, and establish fragmentation rules for the development of bioinformatics software. We will optimize conditions for efficient coupling of EED to reversed-phase, and porous graphitic carbon LC, and develop an LC-EED-MS/MS approach for simultaneous characterization and quantitation of glycan mixtures. We will implement EED on a Q-TOF instrument to improve its access to the glycoscience community. Finally, we will develop and rigorously test the performance of a novel bioinformatics software that can rapidly and accurately determine each glycan's structure from its tandem MS spectra. The proposed algorithm is fundamentally different from most existing software, in that it no longer relies solely on glycosidic and cross-ring fragments for topology and linkage analysis, but rather adopts a machine learning approach that considers the contexts of various types of fragment peaks, and the spectral features associated with different linkage configurations and structural motifs. The availability of such a high-throughput, de novo glycan sequencing tool will have an immense impact on many biomedical research fields, as glycosylation plays critical roles in almost all biological pathways. Awarded Project Narrative Characterization of glycans from biological sources requires sensitive and high-throughput analytical methods that can separate and identify each glycoform in a complex mixture. We propose to develop an HPLC-EED- MS/MS method for comprehensive glycome characterization. We will also develop a novel bioinformatics program that can accurately determine the glycan structure from its EED tandem mass spectrum de novo.",High-Throughput De Novo Glycan Sequencing,10135336,R01GM132675,"['Address', 'Adopted', 'Algorithms', 'Anabolism', 'Autoimmune Diseases', 'Award', 'Behavior', 'Binding', 'Bioinformatics', 'Biological', 'Biological Markers', 'Biomedical Research', 'Biopolymers', 'Carbon', 'Cardiovascular Diseases', 'Cell Adhesion', 'Communities', 'Complex', 'Complex Mixtures', 'Computer software', 'Coupling', 'Custom', 'Data', 'Data Analyses', 'Data Set', 'Databases', 'Development', 'Disease', 'Dissociation', 'Effectiveness', 'Electron Transport', 'Embryonic Development', 'Epitopes', 'Fourier transform ion cyclotron resonance', 'Genome', 'Glycoconjugates', 'Glycosides', 'Health', 'High Pressure Liquid Chromatography', 'Hybrids', 'Immune response', 'Impairment', 'Individual', 'Isomerism', 'Link', 'Liquid Chromatography', 'Liquid substance', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Mass Spectrum Analysis', 'Metabolic', 'Methods', 'Natural graphite', 'Nature', 'Pathologic Processes', 'Pathway interactions', 'Pattern', 'Phase', 'Physiological', 'Physiological Processes', 'Physiology', 'Play', 'Polysaccharides', 'Research', 'Research Project Grants', 'Role', 'Sampling', 'Scheme', 'Source', 'Specificity', 'Speed', 'Structure', 'Structure-Activity Relationship', 'Surface', 'Techniques', 'Vacuum', 'Variant', 'analytical method', 'base', 'bioinformatics tool', 'catalyst', 'cell growth', 'commercialization', 'design', 'genetic linkage analysis', 'glycosylation', 'improved', 'instrument', 'ion mobility', 'mass spectrometer', 'nervous system disorder', 'novel', 'pathogen', 'performance tests', 'programs', 'protein folding', 'rapid technique', 'reconstruction', 'tandem mass spectrometry', 'therapeutic target', 'tool', 'ultraviolet']",NIGMS,BOSTON UNIVERSITY MEDICAL CAMPUS,R01,2020,150000,0.01263156073392601
"Developing an in vitro to in vivo pipeline of mammary gland exposure-response relationships to per- and poly-fluoroalkyl substances (PFAS) Project Abstract  Per- and polyfluoroalkyl substances (PFAS) are a family of over 5000 man-made chemicals that are ubiquitous in the environment, due to their chemical stability and bioaccumulative properties. Many of these “forever chemicals” have been linked with health concerns, including strong evidence of developmental health and harm to hormone-sensitive tissues. Manufacturers continue to substitute new PFAS for which exposure- based health risks are unknown. There is an urgent public health need to determine the effects of PFAS in use on both mammary gland development and increased breast cancer incidence. Current exposure studies use rodent models that require cumbersome end-point analyses as well as large monetary and time investments.  Our proposal is aimed at developing an in vitro to in vivo extrapolation (IVIVE) pipeline of mammary gland development and maintenance to identify and prioritize potentially toxic PFAS, to ultimately mitigate number of animals needed for environmental exposure studies. Our approach is to develop in vitro models of the mammary gland of increasing complexity but decreasing throughput, identifying links between high-throughput and high- complexity model endpoint readouts to best prioritize large chemical libraries. A key technology to establish links across multiple in vitro culture platforms is optical coherence tomography-based structural-functional imaging (OCT-SFI), developed by MPI Oldenburg, which non-invasively visualizes label-free cells, their intracellular motility, and morphology of formed spheroids, within optically turbid tissue models.  Our first specific aim advances a high-throughput paper-based culture system, developed by MPI Lockett, to study mammary epithelial cell invasion in physiologically relevant tissue microenvironments. The platform will evaluate 96 different exposure conditions in parallel. Our second specific aim employs 3D co-culture models that include fibroblasts to model stromal signaling known to affect mammary gland development. OCT-SFI will provide cellular motility and morphology of the organotypic spheroids that form in these cultures. Finally, our third aim will screen a library of 40 PFAS, with a particular focus on the perfluoroethercarboxylic acids (PFECAs) currently used in industrial coatings. In addition, 12 PFAS will be screened for which there is existing in vivo rodent model data available, and comparisons between in vitro assay outputs and in vivo gland remodeling will be used to refine the assay models and establish initial thresholds for screening.  The models developed as part of this proposal will thus be predictive of biology, enabling the high-throughput capability needed for future screening of all PFAS as well as other emerging endocrine disruptors. The project’s risk is balanced by the known imaging capabilities of OCT-SFI to probe responses in 3D spheroid and paper- based co-cultures. The high-throughput nature of this IVIVE pipeline makes it ideal for screening libraries of potential toxicants, providing information-rich datasets of spatially and temporally resolved morphological and molecular changes across the tissue-like structures. Project Narrative This proposal aims to develop a pipeline to screen and prioritize libraries of potentially toxic man-made chemicals found in the environment for further analyses, with particular emphasis on per- and poly-fluoroalkyl substances (PFAS) of which there are over 5000 currently known. Current environmental exposure testing methods evaluate mammary gland development in live mice because the mammary gland is highly susceptible to chemical exposure; yet, such methods are slow and expensive. Our proposal uses mammary cell culture models in increasingly complex, tissue-like environments, in combination with high-speed 3D optical imaging techniques, and ultimately compare the platform with a few candidate PFAS against existing data in live mice, setting the stage for future high-throughput screening of potential environmental toxicants.",Developing an in vitro to in vivo pipeline of mammary gland exposure-response relationships to per- and poly-fluoroalkyl substances (PFAS),10152786,R01ES032730,"['3-Dimensional', 'Acids', 'Affect', 'Animals', 'Architecture', 'Biological Assay', 'Biology', 'Biometry', 'Breast Cancer Epidemiology', 'Breast Epithelial Cells', 'Cell Culture Techniques', 'Cell Line', 'Cells', 'Cellular Morphology', 'Characteristics', 'Chemical Exposure', 'Chemicals', 'Clinical Trials', 'Coculture Techniques', 'Complex', 'Data', 'Data Set', 'Development', 'Endocrine Disruptors', 'Environment', 'Environmental Exposure', 'Epithelial', 'Epithelium', 'Estrogen receptor positive', 'Exposure to', 'Family', 'Fiber', 'Fibroblasts', 'Functional Imaging', 'Future', 'Gene Proteins', 'Gland', 'Growth', 'Health', 'Hormones', 'Imaging Techniques', 'In Vitro', 'Incidence', 'Industrialization', 'Investments', 'Label', 'Libraries', 'Link', 'Maintenance', 'Malignant Neoplasms', 'Mammary gland', 'Manufacturer Name', 'Mesenchymal', 'Methods', 'Modeling', 'Molecular', 'Morphology', 'Mus', 'National Institute of Environmental Health Sciences', 'Nature', 'North Carolina', 'Odds Ratio', 'Optical Coherence Tomography', 'Optics', 'Output', 'Paper', 'Pathology', 'Physiological', 'Poly-fluoroalkyl substances', 'Property', 'Public Health', 'Rattus', 'Research Personnel', 'Research Project Grants', 'Resources', 'Risk', 'Rodent', 'Rodent Model', 'S-Phase Fraction', 'Scanning', 'Scoring Method', 'Signal Transduction', 'Speed', 'Structure', 'System', 'Techniques', 'Technology', 'Testing', 'Time', 'Tissue Model', 'Tissues', 'Toxic Environmental Substances', 'Up-Regulation', 'Work', 'assay development', 'base', 'carcinogenesis', 'carcinogenicity', 'cell motility', 'chemical stability', 'data modeling', 'deep learning', 'deep learning algorithm', 'high throughput screening', 'imaging capabilities', 'in vitro Assay', 'in vitro Model', 'in vivo', 'intercellular communication', 'machine learning algorithm', 'malignant breast neoplasm', 'malignant phenotype', 'mammary epithelium', 'mammary gland development', 'man', 'model design', 'non-invasive imaging', 'novel', 'optical imaging', 'premalignant', 'protein biomarkers', 'response', 'screening', 'small molecule libraries', 'three dimensional cell culture', 'three-dimensional modeling', 'tool', 'toxicant']",NIEHS,UNIV OF NORTH CAROLINA CHAPEL HILL,R01,2020,559511,-0.0037448388734143637
"Multimodal mass spectrometry imaging of mouse and human liver We propose to develop a multimodal mass spectrometry imaging pipeline with novel desorption sources and data integration that will enable simultaneously mapping of biomolecule abundance in 3-dimensions in biological tissues at high spatial resolution (micron to submicron) and high speed (>10 ms/pixel) in a near-native environment. This would provide previously inaccessible information on cellular and tissue organization, and how homeostasis and disease intersect at the level of tissue physiology. A major challenge for performing multi- omics using mass spectrometry imaging has been the (i) lack of universal ionization methods, (ii) limited sample preparation protocols for preserving chemical gradients, (iii) low sensitivity, and (iv) limited tools for integration of large quantities of data. Our laboratories are developing systematic MS imaging for high sensitivity and high resolution analysis of diverse tissues. We discovered that water-based gas cluster ion beams (H2O-GCIB) operating at high energy yield ionization enhancements of multiple biomolecules (e.g., metabolites, lipids, and peptides/protein fragments) with high sensitivity at 1 µm lateral resolution and without labeling or complicated sample preparation. Coupled with unique Secondary Ion Mass Spectrometry (SIMS) instrumentation and cryogenic sample handling, we have imaged biomolecules directly in cells and tissues in a near-native state (i.e., frozen-hydration) with feature resolution of 1-10 µm. Low concentration biomolecules (e.g. cardiolipin and metabolites) that were impossible to localize in single cells previously are now visible with 3-dimensional localization. Moreover, the sufficient signal per pixel, we can use automated data analysis to characterize biologically active functional sites within 1 µm2 and areas of interest in single cells. We further developed data integration methods to combine imaging data from adjacent sections to create a multi-model imaging data sets. We propose to develop a pipeline for MS imaging analysis of biomolecules, and to elucidate molecular heterogeneity in tissues using multimodal imaging. To support the multi-modal analysis pipeline, we will develop an integrated data analysis platform. Integration of multiomics remains challenging, particularly spatially localize multiple biomolecules at single cell level. The direct visualization of cellular contents provides information on biomolecular composition, interactions and functions. This network of biomolecules is the driving force of specific behavior of cells in physiological states. Despite this, a comprehensive grasp of these interactions at cellular level has not moved beyond segregated methods. Our efforts will result in an integrated multimodal imaging platform to summon the best characteristics of each image form, acquiring a complete picture the biomolecular network at spatial resolution of 1 µm. With this direct visualization, we will address how metabolism links with functional biomarkers that stem from metabolism-associated protein complexes and phase-separated membrane-less organelles at the subcellular level, and how this drive different cell death modalities, including different modes of cell death. We propose to develop a new mass spectrometry imaging pipeline that will enable mapping of biomolecules in in biological tissues at high spatial resolution. This will provide previously inaccessible information on cellular and tissue organization, and how homeostasis and disease intersect at the level of tissue physiology.",Multimodal mass spectrometry imaging of mouse and human liver,10118811,UG3CA256962,"['3-Dimensional', 'Active Sites', 'Address', 'Age', 'Algorithms', 'Apoptosis', 'Area', 'Atlases', 'Biochemical', 'Biological', 'Biological Markers', 'Biopsy', 'Blood', 'Brain', 'Cardiolipins', 'Cell Death', 'Cells', 'Characteristics', 'Chemicals', 'Chemistry', 'Computer Vision Systems', 'Coupled', 'Cytometry', 'Data', 'Data Analyses', 'Data Set', 'Development', 'Disease', 'Electrospray Ionization', 'Environment', 'Eosine Yellowish', 'Freezing', 'Gases', 'Genetic Transcription', 'Health', 'Heart', 'Heterogeneity', 'Homeostasis', 'Human', 'Hydration status', 'Image', 'Immunohistochemistry', 'Individual', 'Ions', 'Kidney', 'Knowledge', 'Label', 'Laboratories', 'Lateral', 'Link', 'Lipids', 'Liver', 'Liver Fibrosis', 'Liver diseases', 'Machine Learning', 'Mass Spectrum Analysis', 'Membrane', 'Messenger RNA', 'Metabolic Marker', 'Metabolism', 'Methods', 'Modality', 'Modeling', 'Modification', 'Molecular', 'Morphology', 'Multimodal Imaging', 'Mus', 'Optics', 'Organelles', 'Peptides', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Physiological', 'Physiology', 'Preparation', 'Primary carcinoma of the liver cells', 'Protein Fragment', 'Protocols documentation', 'Resolution', 'Sampling', 'Signal Transduction', 'Site', 'Source', 'Spatial Distribution', 'Spectrometry, Mass, Electrospray Ionization', 'Spectrometry, Mass, Secondary Ion', 'Speed', 'Technology', 'Time', 'Tissue imaging', 'Tissues', 'Transcript', 'Visualization', 'Water', 'analysis pipeline', 'base', 'cell behavior', 'cell type', 'cryogenics', 'data analysis pipeline', 'data integration', 'data mining', 'data visualization', 'driving force', 'experimental study', 'grasp', 'high resolution imaging', 'human tissue', 'image reconstruction', 'imaging platform', 'improved', 'insight', 'instrumentation', 'interest', 'ionization', 'ionization technique', 'molecular imaging', 'multimodality', 'multiple omics', 'novel', 'preservation', 'protein complex', 'reconstruction', 'single-cell RNA sequencing', 'stem', 'submicron', 'tool', 'tumorigenesis']",NCI,COLUMBIA UNIV NEW YORK MORNINGSIDE,UG3,2020,300000,-0.010716696003527523
"Digital representation of chemical mixtures to aid drug discovery and formulation PROJECT SUMMARY Collaborative Drug Discovery, Inc. (CDD) proposes to develop a suite of software modules to enable scientists to unambiguously represent chemical mixtures in standard machine-readable formats, filling an urgent and widely-recognized need. Chemicals are typically formulated as mixtures. Recording and communicating infor- mation about chemical mixtures is essential for scientists and support staff in the pharmaceutical industry, in academia, in non-profit research organizations, in government, at specialty chemical vendors, and at commer- cial manufacturers to: • discover, develop, formulate, manufacture and regulate drugs; • manage reagent inventories; comply with laboratory safety requirements; inform first responders; • describe and reproduce biomedical experiments; and • assess and disseminate information about toxicity risks of chemical reagents and consumer products.  A working committee of the International Union of Pure and Applied Chemistry (IUPAC) is close to for- malizing “Mixtures InChI” (or MInChI), which will extend the International Chemical Identifier (InChI) to be- come the first standard to encompass mixtures. MInChI will effectively index mixtures in the same way that InChI indexes individual compounds.  In Phase 1 CDD developed the data structures and software necessary to enable adoption and utilization of MInChI and create the first general-purpose system for recording information about chemical mixtures that is computable and interoperable. In Phase 2 CDD will continue to develop a sophisticated automated transla- tion tool that will accurately convert legacy catalogs of chemical mixtures from plaintext descriptions or ad hoc formats so that they are properly represented in a machine readable format that can in turn be easily rendered into MInChI identifiers. The broad vision is to help industry to overcome the barriers to adoption so that ma- chine readable mixture descriptions can quickly deliver benefits for drug discovery, chemical safety, and toxi- cology. PROJECT NARRATIVE The proposed project will create novel computational tools that will help researchers to efficiently and accu- rately document the composition of chemical mixtures in a format that computers can easily interpret, process, and exchange. This innovative capability will help to accelerate the discovery and development of novel and improved drugs against a wide range of diseases. It will also help to advance our understanding of the toxicol- ogy of mixtures (which often differs from the toxicology of individual components) and improve laboratory safety both in industry and in educational settings. !",Digital representation of chemical mixtures to aid drug discovery and formulation,9902210,R44TR002528,"['Academia', 'Adoption', 'Ally', 'Books', 'Catalogs', 'Chemical Structure', 'Chemicals', 'Chemistry', 'Code', 'Commercial Catalogs', 'Computer software', 'Computers', 'Data', 'Databases', 'Development', 'Disease', 'Drug Formulations', 'Drug Industry', 'Elements', 'English Language', 'Equipment and supply inventories', 'Goals', 'Government', 'Human', 'Individual', 'Industry', 'Infrastructure', 'Intelligence', 'International', 'Laboratories', 'Manufacturer Name', 'Methods', 'Modeling', 'Molecular Structure', 'Names', 'Pharmaceutical Preparations', 'Pharmacologic Substance', 'Phase', 'Polymers', 'Process', 'Readability', 'Reagent', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Scientist', 'Services', 'Shorthand', 'Solvents', 'Specific qualifier value', 'Structure', 'Supervision', 'System', 'Technology', 'Text', 'Time', 'Toxic effect', 'Toxicology', 'Traction', 'Translations', 'Vendor', 'Vision', 'cofactor', 'computerized tools', 'consumer product', 'cost', 'data structure', 'deep learning', 'digital', 'drug discovery', 'experimental study', 'first responder', 'improved', 'indexing', 'innovation', 'interoperability', 'male', 'medical specialties', 'member', 'natural language', 'novel', 'open source', 'quality assurance', 'structured data', 'tool']",NCATS,"COLLABORATIVE DRUG DISCOVERY, INC.",R44,2020,748733,0.011249935044774933
"Skyline Targeted Proteomics Environment Development on Skyline started in 2008 to fill a critical need for a software tool that enabled targeted proteomics experiments. Since then, Skyline has grown into an entire ecosystem of tools, expanding well beyond targeted proteomics. The Skyline software ecosystem is one of the most widely used software platforms in all of mass spectrometry, supporting thousands of investigators in their research. The synergy between Skyline software development and its vast and thriving user community uniquely generate exciting new opportunities for quantitative mass spectrometry. Skyline has been a key factor in the success and growth of this new field, with Skyline itself becoming one of the most significant software tools in mass spectrometry. Since 2015, we have expanded Skyline software, from just the traditional targeted proteomics experiments that used selected reaction monitoring (SRM) with triple quadrupole (QQQ) mass spectrometers, to broadly encompass ALL types of quantitative proteomics experiments, including data dependent acquisition (DDA) experiments using MS1 peak areas (aka MS1 filtering), targeted tandem mass spectrometry (aka parallel reaction monitoring or PRM) experiments and data independent acquisition (DIA). As of Oct 2019, Skyline has been installed >97,500 times (117% increase since 2015), has over 14,000 registered users (122% increase since 2015) on its website (http://skyline.ms) and is booted up >9,000 times per week (exceeding 17,500 bootups in a single week). The Skyline project has grown beyond the bounds of a single tool. Currently, there are 14 Skyline external tools (55% increase since 2015) that rely on a formalized framework in Skyline and available through its tool store, with more still in development. The prior grant cycle has greatly expanded a community of users and developers working with a common set of tools to analyze quantitative data from all six major mass spectrometry vendors. Specifically, our proposal has five aims. 1) Improve Skyline’s analysis of DDA data, 2) Improve Skyline’s analysis of DIA data, 3) Expand support of new molecule types within Skyline, 4) Support for new quantitative data types, and 5) Provide continued support and training for the Skyline ecosystem. Mass spectrometry has been a fundamental technology for the analysis diverse molecule types in health and disease. Targeted mass spectrometry measurements offer a promising alternative to immunological based assays that are the standard for quantitative protein measurements in clinical and basic research laboratories. Critical to these experiments is our software, Skyline and the associated ecosystem of tools, which have been developed to handle the generation of instrument methods and the subsequent analysis of the resulting data.",Skyline Targeted Proteomics Environment,10049625,R01GM103551,"['Algorithms', 'Area', 'Basic Science', 'Biological Assay', 'Clinical Research', 'Collection', 'Communities', 'Complement', 'Computer software', 'Data', 'Data Analyses', 'Data Discovery', 'Data Scientist', 'Databases', 'Development', 'Disease', 'Ecosystem', 'Educational workshop', 'Engineering', 'Environment', 'Flow Injection Analysis', 'Funding', 'Generations', 'Grant', 'Health', 'Immunologics', 'Infrastructure', 'Laboratory Research', 'Lipids', 'Machine Learning', 'Mass Spectrum Analysis', 'Measurement', 'Methods', 'Modification', 'Monitor', 'Peptides', 'Polysaccharides', 'Proteins', 'Proteomics', 'Reaction', 'Research', 'Research Personnel', 'Running', 'Sampling', 'Software Tools', 'Technology', 'Time', 'Training', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vendor', 'base', 'biomedical scientist', 'computerized data processing', 'crosslink', 'data acquisition', 'experimental study', 'improved', 'innovation', 'instrument', 'ion mobility', 'mass spectrometer', 'meetings', 'new growth', 'open source', 'search engine', 'small molecule', 'software development', 'success', 'synergism', 'tandem mass spectrometry', 'tool', 'web site', 'webinar']",NIGMS,UNIVERSITY OF WASHINGTON,R01,2020,258335,0.07632065994303593
"Automated Molecular Identity Disambiguator (AutoMID) PROJECT SUMMARY Small molecules are one of the most important classes of therapeutics alleviating suffering and in many cases death for hundreds of millions of people worldwide. Small molecules also serve as invaluable tools to study biology, often with the goal to validate novel targets for the development of future therapeutic drugs. Reproducibility of experimental results and the interoperability and reusability of resulting datasets depend on accurate descriptions of associated research objects, and most critically on correct representations of small molecules that are tested in biological assays. For example, it is not possible to develop predictive models of protein target - small molecule interactions if their chemical structure representations are not correct. Many factors contribute to errors in reported chemical structures in small molecule screening and omics reference databases, scientific publications, and many other web-based resources and documents. Because of the complexity of representing small molecules chemical structure graphs and the lack of thorough curation, errors are frequently introduced by non-experts and error propagation across different digital research assets is a pervasive problem. To address this challenging problem via a scalable approach, we propose the Automated Molecular Identity Disambiguator (AutoMID). AutoMID will be usable in batch mode at scale via an API, for example to assist chemical structure standardization and registration by maintainers of digital research assets, and also via interactive (UI) mode for everyday researchers to quickly and easily validate or correct their small molecule representations. AutoMID will leverage extensive highly standardized linked databases of chemical structures and associated information including names, synonyms, biological activity and physical properties and their sources / provenance and leverage expert rules and AI to enable reliable disambiguation of chemical structure identities at scale. PROJECT NARRATIVE Small molecules are one of the most important types of drugs. They also serve as invaluable tools to study biology. The complexity of representing chemical graphs and the lack of thorough curation leads to frequent small molecule structure errors, which propagate across digital research assets, impeding their interoperability and reusability. To address this challenging problem, we propose the Automated Molecular Identity Disambiguator (AutoMID). Built on expert knowledge and AI, AutoMID will enable researchers and maintainers of data repositories to reliably identify and resolve ambiguities in chemical structures at scale.",Automated Molecular Identity Disambiguator (AutoMID),9987129,R01LM013391,"['Address', 'Adoption', 'Biological', 'Biological Assay', 'Biology', 'Categories', 'Cessation of life', 'Chemical Structure', 'Chemicals', 'Classification', 'Complex', 'Data', 'Data Element', 'Data Set', 'Data Sources', 'Databases', 'Deposition', 'Detection', 'Development', 'FAIR principles', 'Future', 'Goals', 'Graph', 'Hand', 'Hybrids', 'In Vitro', 'Individual', 'Knowledge', 'Legal patent', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Metadata', 'Modeling', 'Molecular', 'Molecular Structure', 'Names', 'Pharmaceutical Chemistry', 'Pharmaceutical Preparations', 'Postdoctoral Fellow', 'Privatization', 'Property', 'Proteins', 'Publications', 'Records', 'Reporting', 'Reproducibility', 'Research', 'Research Personnel', 'Resources', 'Semantics', 'Source', 'Standardization', 'Structure', 'Testing', 'Therapeutic', 'Time', 'Training', 'base', 'cheminformatics', 'data harmonization', 'data modeling', 'data warehouse', 'design', 'digital', 'high throughput screening', 'improved', 'in silico', 'in vivo', 'interoperability', 'knowledge curation', 'novel', 'online resource', 'physical property', 'predictive modeling', 'relational database', 'screening', 'small molecule', 'software systems', 'tool', 'user-friendly']",NLM,UNIVERSITY OF MIAMI SCHOOL OF MEDICINE,R01,2020,293345,0.02729348137645137
"Integrative chemical-biological profiling to determine primary drivers of wildfire smoke-induced toxicity PROJECT SUMMARY  Wildfire occurrence, duration, and intensity have heightened in recent decades and continue to impact the health of millions of individuals worldwide. Smoke that is emitted from wildfires consists of a complex mixture of particulate matter and toxic gases. The chemical composition of wildfire smoke is dependent upon the type of biomass burn conditions and fuel type, which are heavily influenced by geographical region. The chemical mixtures within wildfire smoke that humans are exposed to can consequently cause variable health outcomes through potentially different biological mechanisms. Human exposure to wildfire smoke represents a growing concern in public health, and adequately characterizing health risks associated with biomass smoke across varying burn conditions and geographic areas is not possible with the data currently available.  The variabilities in toxicological responses across wildfire smoke exposure conditions have yet to be fully established and evaluated in the context of chemical composition. The growing threat of wildfires necessitates the elucidation of individual and/or co-occurring components of wildfire smoke that act as the primary drivers of toxicity. To address this important research issue, we expand upon a foundational study that has previously characterized the chemical constituents in various biomass burn scenarios and evaluated, in part, toxicological responses to these exposures in the mouse lung. Here, we leverage this extensive database and banked samples to: 1. characterize in vivo transcriptomic responses and pathway alterations associated with biomass smoke in the mouse lung; 2. integrate chemical-toxicity profiles using computational approaches to prioritize chemicals that are likely driving toxicity responses; and 3. further evaluate chemical drivers of biomass smoke toxicity responses using in vitro approaches.  This research will be carried out through a collaboration with laboratories at the University of North Carolina at Chapel Hill and the U.S. Environmental Protection Agency, allowing for a unique combination of expertise for studying the primary drivers of wildfire smoke-induced toxicity. This expertise includes skills in computational toxicology, exposure science, and molecular biology, coupled with experience studying adverse health effects and immune responses induced by exposure to air pollutants. PROJECT NARRATIVE Exposure to wildfire smoke continues to be a growing threat to public health, yet the primary drivers of toxicity and disease are not completely understood. This proposal represents an innovative approach to increase understanding on the health effects of wildfires by leveraging a robust dataset of chemical-biological profiles from mice exposed to biomass smoke condensate samples derived from variable conditions. New data will also be generated alongside additional in vitro testing to more comprehensively examine mechanisms of toxicity and identify the primary drivers of wildfire smoke-induced toxicity, resulting in improved abilities to predict region- specific health risks attributable to wildfires.",Integrative chemical-biological profiling to determine primary drivers of wildfire smoke-induced toxicity,9956440,R21ES031740,"['Address', 'Affect', 'Air', 'Air Pollutants', 'Analytical Chemistry', 'Automobile Driving', 'Biological', 'Biological Assay', 'Biomass', 'Cardiovascular Diseases', 'Cells', 'Cessation of life', 'Chemically Induced Toxicity', 'Chemicals', 'Collaborations', 'Complex', 'Complex Mixtures', 'Coupled', 'Critical Pathways', 'DNA Damage', 'Data', 'Data Set', 'Databases', 'Disease', 'Exposure to', 'Female', 'Foundations', 'Functional disorder', 'Gases', 'Gene Expression', 'Genes', 'Geographic Locations', 'Health', 'Human', 'Immune', 'Immune response', 'In Vitro', 'Individual', 'Inflammation', 'Inhalation', 'Inhalation Exposure', 'Laboratories', 'Lung', 'Lung diseases', 'Machine Learning', 'Malignant Neoplasms', 'Measures', 'Methods', 'Molecular Biology', 'Mus', 'North Carolina', 'Outcome', 'Particulate Matter', 'Pathway interactions', 'Phenotype', 'Population', 'Positioning Attribute', 'Proteins', 'Public Health', 'Research', 'Risk', 'Sampling', 'Science', 'Smoke', 'Structure of parenchyma of lung', 'System', 'Tissues', 'Toxic effect', 'Toxicogenomics', 'Toxicology', 'United States Environmental Protection Agency', 'Universities', 'Variant', 'Wildfire', 'asthma exacerbation', 'base', 'biomass fuel', 'biomass smoke', 'computational toxicology', 'data integration', 'data reduction', 'data warehouse', 'experience', 'exposed human population', 'genotoxicity', 'improved', 'in vitro testing', 'in vivo', 'innovation', 'lung injury', 'male', 'novel', 'protein biomarkers', 'public health relevance', 'respiratory', 'response', 'skills', 'smoke inhalation', 'toxicant', 'transcriptomics']",NIEHS,UNIV OF NORTH CAROLINA CHAPEL HILL,R21,2020,227277,-0.01871796506552296
"Reconstruction of heterogeneous and small macromolecules by cyro-EM PROJECT SUMMARY Single-particle electron cryomicroscopy (cryo-EM) has recently joined X-ray crystallography and NMR spectroscopy as a high-resolution structural method for biological macromolecules. In addition, cryo-EM produces images of individual molecules, and therefore has the potential to resolve conformational changes. The proposal aims to develop new algorithms and software for extending the application of cryo-EM to molecules that are either too small or too flexible to be mapped by existing computational tools for cryo-EM. This extension requires solving two of the most challenging computational problems posed by cryo-EM. First, mapping the structural variability of macromolecules is widely recognized as the main computational challenge in cryo-EM. Structural variations are of great significance to biologists, as they provide insight into the functioning of molecular machines. Existing computational tools are limited to a small number of distinct conformations, and therefore are incapable of tackling highly mobile biomolecules with multiple, continuous spectra of conformational changes. The first area of investigation in this project is the development of a computational framework to analyze continuous variability. The proposed approach is based on a new mathematical representation of continuously changing structures and its efficient estimation using Markov chain Monte Carlo (MCMC) algorithms. MCMC algorithms have found great success in many other scientific disciplines, yet they have been mostly overlooked for cryo-EM single particle analysis. Second, a major limiting factor for present cryo-EM studies is the molecule size. Images of small molecules (below ~50kDa) have too little signal to allow existing methods to provide valid 3-D reconstructions. It is commonly believed that cryo-EM cannot be used for molecules that are too small to be reliably detected and picked from micrographs. Challenging that widespread belief, the second area of investigation focuses on developing a groundbreaking approach for reconstructing small molecules directly from micrographs without particle picking. The new approach is based on autocorrelation analysis and completely bypasses particle picking and orientation assignment and requires just one pass over the data. The single-pass approach opens new possibilities for real-time processing during data acquisition. PROJECT NARRATIVE Determining structures of proteins and other large molecules is an essential step in the basic understanding of biological processes, and a first step in rational drug design. We propose to develop new, faster and more reliable computer algorithms to significantly increase the power of structure-determination using electron cryomicroscopy (cryo-EM). Importantly, our methods will broaden the application of cryo-EM to molecules that are either too small or too flexible to be mapped by existing techniques.",Reconstruction of heterogeneous and small macromolecules by cyro-EM,9943364,R01GM136780,"['3-Dimensional', 'Algorithmic Software', 'Algorithms', 'Area', 'Belief', 'Biological', 'Biological Process', 'Bypass', 'Collaborations', 'Complex', 'Computational algorithm', 'Computer software', 'Cryoelectron Microscopy', 'Crystallization', 'Data', 'Data Set', 'Detection', 'Development', 'Diffusion', 'Dimensions', 'Discipline', 'Drug Design', 'Fostering', 'G-Protein-Coupled Receptors', 'Heterogeneity', 'Human Genome', 'Image', 'Individual', 'Institution', 'Investigation', 'Ion Channel', 'Ion Pumps', 'Machine Learning', 'Maps', 'Markov Chains', 'Markov chain Monte Carlo methodology', 'Mathematics', 'Methods', 'Modeling', 'Molecular Conformation', 'Molecular Machines', 'Molecular Motors', 'Molecular Weight', 'Motion', 'NMR Spectroscopy', 'Names', 'Noise', 'Particle Size', 'Phase', 'Polymerase', 'Preparation', 'Proteins', 'Pythons', 'Research', 'Resolution', 'Ribosomes', 'Roentgen Rays', 'Sampling', 'Signal Transduction', 'Spliceosomes', 'Structural Protein', 'Structure', 'Techniques', 'Time', 'Uncertainty', 'Update', 'Variant', 'Work', 'X-Ray Crystallography', 'base', 'computer framework', 'computerized data processing', 'computerized tools', 'data acquisition', 'expectation', 'flexibility', 'high dimensionality', 'improved', 'insight', 'interest', 'macromolecule', 'molecular mass', 'novel strategies', 'open source', 'particle', 'programs', 'protein complex', 'protein structure', 'receptor', 'reconstruction', 'small molecule', 'statistics', 'success', 'theories', 'three dimensional structure']",NIGMS,PRINCETON UNIVERSITY,R01,2020,328440,0.008460643873622678
"A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing Project Summary: Neurotoxicological evaluation of new compounds intended for human use or of potential human exposure is mandated by international regulatory bodies and largely relies on lethality testing in higher-order vertebrate animals. High screening costs, long experimental times, and legislative requirements to reduce dependence on animal testing have led many industries to search for alternative technologies. In vitro toxicology testing uses isolated cells or monotypic cell culture and can only provide limited insight since these models lack biologically relevant intact multi-typic cellular network structures. While both technologies have been augmented by in silico technologies, there is still a non-trivial gap between what can be learned and translated from simple, fast, inexpensive in vitro methods versus longer, complex, and costly in vivo studies in higher order animals. Newormics’ approach to filling this gap is to enable in vivo neurotoxicological assessment in Caenorhabditis elegans, an accepted alternative invertebrate model organism, by developing neuron-specific toxicity assays, delivered via a proprietary high-density, large-scale microfluidic immobilization device for high-content, high throughput analysis. Building on advances made during Phase I and important market learnings from participation in the NIH I-Corps program, Phase II proposes several new elements of innovation to achieve our goals in 3 specific aims. In Aim 1, we will convert our first-generation microfluidic device to a high-density (384- well) vivoChip with improved microfabrication technologies, incorporate on-chip culture for transfer-less exposure and testing, and integrate automation for chip loading, imaging, and analysis. These measures will significantly increase test scale (from 80 compounds per chip to 280) and lower the consumable and labor costs per test. In Aim 2, building on our dopaminergic neurotox assay from Phase I, we will develop four neurotox assays with brightly fluorescently labeled dopaminergic, serotonergic, GABAergic, and cholinergic neurons providing the unprecedented ability to assess subtle phenotypic effects of chemicals on individual intact, functional neurons. To achieve real-time image processing, multi-parameter phenotyping, and managing the terabytes of image data generated per test, we will build a computational platform empowered by a graphic user interface. This platform will be used for image compilation, user-annotated phenotype definition and scoring, and automated report generation with appropriate statistical analysis. In Aim 3, with our industry partners, we will validate our platform and assays using reference chemicals. As more chemicals are tested, we will build a database which can be further mined. The outcome of this work will enable many industries to reduce lethal animal testing and get safer industrial and personal consumer products to market faster for economic benefit, reaching regulatory compliance for reduced animal use, and improved healthcare for neurological diseases. Narrative: The proposed work will enable the use of a small invertebrate model organism, C. elegans, for neuron-specific analysis of neurodegeneration phenotypes from high-resolution fluorescence images of individual neurons at high throughputs. The proposed imaging system and the neuron-specific assays will provide an unprecedented ability to assess developmental neurotoxicity in an intact, live, whole organism, down to a neuronal mechanism- of-action level. This project will fill the gap between in vitro and in vivo toxicology testing with an effective invertebrate model organism as alternate to vertebrate animal testing.",A Multiwell Plate Format Microfluidic Immobilization Chip for High-Content Imaging of Whole Animals for in vivoNeurotoxicology Testing,10082215,R44MH118841,"['3-Dimensional', 'Address', 'Animal Model', 'Animal Testing', 'Animals', 'Automation', 'Biological', 'Biological Assay', 'Caenorhabditis elegans', 'Cell Culture Techniques', 'Cells', 'Chemicals', 'Complement', 'Complex', 'Computer software', 'Data', 'Databases', 'Dendrites', 'Dependence', 'Development', 'Devices', 'Dopamine', 'Eating', 'Economics', 'Elements', 'Evaluation', 'Exposure to', 'Feedback', 'Future', 'Gel', 'Generations', 'Goals', 'Healthcare', 'Hour', 'Human', 'Image', 'Immobilization', 'In Vitro', 'Individual', 'Industrialization', 'Industry', 'Industry Standard', 'Innovation Corps', 'International', 'Invertebrates', 'Label', 'Learning', 'Liquid substance', 'Machine Learning', 'Manuals', 'Market Research', 'Measures', 'Methods', 'Microfabrication', 'Microfluidic Microchips', 'Microfluidics', 'Modeling', 'Nerve Degeneration', 'Nervous system structure', 'Neurons', 'Neurotransmitters', 'Organoids', 'Outcome', 'Phase', 'Phenotype', 'Population', 'Positioning Attribute', 'Process', 'Protocol Compliance', 'Protocols documentation', 'Reporting', 'Research Activity', 'Resolution', 'Robotics', 'Serotonin', 'Services', 'Specificity', 'Speed', 'Statistical Data Interpretation', 'Structure', 'System', 'Technology', 'Testing', 'Time', 'Toxic effect', 'Toxicity Tests', 'Toxicology', 'Translating', 'United States National Institutes of Health', 'Validation', 'Variant', 'Vertebrates', 'Whole Organism', 'Work', 'base', 'cholinergic neuron', 'computational platform', 'connectome', 'consumer product', 'cost', 'cost effective', 'density', 'design', 'developmental neurotoxicity', 'developmental toxicity', 'empowered', 'experimental study', 'exposed human population', 'fluorescence imaging', 'gamma-Aminobutyric Acid', 'graphical user interface', 'high resolution imaging', 'high throughput analysis', 'image processing', 'imaging platform', 'imaging system', 'improved', 'in silico', 'in vitro Model', 'in vivo', 'in vivo Model', 'industry partner', 'innovation', 'insight', 'interest', 'nervous system disorder', 'neurotoxicity', 'neurotoxicology', 'programs', 'real-time images', 'reproductive toxicity', 'screening', 'small molecule libraries', 'success', 'terabyte', 'testing services', 'young adult']",NIMH,"NEWORMICS, LLC",R44,2020,749858,-0.005724780468800444
