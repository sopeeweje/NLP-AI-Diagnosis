text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Human Face Representation in Deep Convolutional Neural Networks The human visual system can recognize a familiar face across wide variations of viewpoint, illumination, expression, and appearance. This remarkable computational feat is accomplished by large-­scale networks of neurons. We will test a face space theory of the representations that emerge at the top layer of deep learning convolutional neural networks (DCNNs) as a model of human visual representations of faces. Computer-based face recognition has improved in recent years due to DCNNs and the easy availability of labeled training data (faces and identities) from the web. Inspired by the primate visual system, DCNNs are feed­forward artificial neural networks that can map images of faces into representations that support recognition over widely variable images. Although the calculations executed by the simulated neurons are simple, enormous numbers of computations are used to convert an image into a representation. The end result of this processing is a highly compact representation of a face that retains image detail in an invariant, identity­-specific face code. This code is fundamentally different than any representation of faces considered in vision science. This theory we test combines key components of previous face space models (similarity, learning history) with new features (imaging conditions, personal face history) in a unitary space that represents both identity and facial appearance across variable images. We will test whether this model can account for human recognition of familiar faces, which is highly robust to image variability (pose, illumination, expression). The model will also be applied to understanding long standing difficulties humans (and machines) have with faces of other races. We aim to bridge critical gaps in our knowledge of how DCNNs work, linking psychological, neural, and computational perspectives. A fundamentally new theory of face representation will alter the questions we ask about face representations in all three fields. A new focus on understanding how we (or neural networks) “perceive” a single familiar identity in widely variable images will give rise to a search for representations that gracefully merge the properties of faces with the real-­world image conditions in which they are experienced. This project presents a unique opportunity to study, manipulate, and learn from these representations, and to apply the findings to broader questions about high-­level vision from neural and perceptual perspectives. Human recognition of familiar faces is highly robust to image variability (pose, illumination, expression)—a skill that is likely due to the quality and quantity of experience we have with the faces of people we know well. Deep convolutional neural networks are modeled after the primate visual system and have made impressive gains recently on the problem of robust face recognition. Understanding the visual nature of the face “feature” codes that emerge in these networks can give insight into long-standing questions about how the human visual system can, but does not always, represent a face in a way that generalizes across images that vary widely.",Human Face Representation in Deep Convolutional Neural Networks,10129967,R01EY029692,"['Affect', 'Appearance', 'Categories', 'Code', 'Computers', 'Data', 'Data Set', 'Face', 'Face Processing', 'Familiarity', 'Human', 'Image', 'Individual', 'Internet', 'Knowledge', 'Label', 'Learning', 'Lighting', 'Link', 'Maps', 'Methods', 'Modeling', 'Nature', 'Neural Network Simulation', 'Neurons', 'Performance', 'Persons', 'Primates', 'Property', 'Published Comment', 'Race', 'Recording of previous events', 'Space Models', 'Testing', 'Training', 'Variant', 'Vision', 'Visual', 'Visual system structure', 'Work', 'artificial neural network', 'base', 'convolutional neural network', 'deep learning', 'experience', 'feedforward neural network', 'human model', 'improved', 'insight', 'neural network', 'psychologic', 'relating to nervous system', 'representation theory', 'skills', 'theories', 'vision science']",NEI,UNIVERSITY OF TEXAS DALLAS,R01,2021,361998
"Temporal Pattern Perception Mechanisms for Acoustic Communication Project Summary/Abstract: Processing acoustic communication signals is among the most difficult yet vital abilities of the auditory system. These abilities lie at the heart of language and speech processing, and their success or failure has profound impacts on quality of life across the lifespan. Understanding the neurobiological mechanisms that support these basic abilities holds promise for advancing assistive listening devices, and for improving diagnoses and treatments for learning disabilities and communication disorders, such as auditory processing disorder, dyslexia, and specific language impairment. Non-invasive neuroscience techniques in humans reveal the loci of language-related processing but do not answer how individual neurons and neural circuits implement language-relevant computations. Thus, circuit-level neuro-computational mechanisms that support acoustic communication signal processing remain poorly understood. Multiple lines of research suggest that songbirds can provide an excellent model for investigating shared auditory processing abilities relevant to language. This proposal investigates neural mechanisms of auditory temporal pattern processing abilities shared between songbirds and humans. In Aim 1, we test the cellular-level predictions of a powerful modelling framework, called predictive coding, proposed as a general computational mechanism to support the learned recognition of complex temporally patterned signals at multiple timescales. We combine state-of-the-art machine learning methods with multi-electrode electrophysiology, to test explicit models for natural stimulus representation, prediction, and error coding in single cortical neurons and neural populations. One aspect of auditory perception integral to speech is the discretization of the signal into learned categorically perceived sounds (phonemes). In Aim 2, we use the predictive coding framework to investigate the learned categorical perception of natural auditory categories in populations of cortical neurons. In humans, the transition statistics between adjacent phonemes can aid or alter phoneme categorization, providing cues for language learners and listeners to disambiguate perceptually similar sounds. Aim2 also examines how categorical neural representations are affected by temporal context. In addition to which phonemes occur in a sequence, speech processing also requires knowing where those elements occur. Sensitivities to the statistical regularities of speech sequences are established long before infants learn to speak, and continue to affect both recognition and comprehension throughout adulthood. Songbirds also attend to the statistical regularities in their vocal communication signals. In Aim 3, we focus on how sequence-specific information is encoded by single neurons and neural populations in auditory cortex. The proposed approach permits progress in the near term towards establishing the basic neurobiological substrates of foundational language-relevant abilities and a general framework within which more complex, uniquely human processes, can be proposed and eventually tested. Project Narrative: Normal speech comprehension and communication are rooted in basic auditory cognitive processes. Deficits in these processes accompany severe communication disorders (e.g. auditory processing disorder, dyslexia, specific language impairment, autism), and their abnormal function can compound the negative impacts of hearing impairments. The proposed project investigates the neuronal mechanisms of auditory temporal pattern processing using natural communication signals, with the ultimate goal of understanding the neurobiological basis of language-relevant abilities and improving treatment of communication processing disorders.",Temporal Pattern Perception Mechanisms for Acoustic Communication,10160864,R01DC018055,"['Acoustics', 'Adult', 'Affect', 'Algorithms', 'Animal Model', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Biological Models', 'Categories', 'Code', 'Cognition Disorders', 'Cognitive', 'Communication', 'Communication impairment', 'Complex', 'Comprehension', 'Computer Models', 'Cues', 'Data', 'Detection', 'Diagnosis', 'Disease', 'Dyslexia', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Failure', 'Foundations', 'Generations', 'Goals', 'Grouping', 'Hearing Aids', 'Heart', 'Human', 'Individual', 'Infant', 'Language', 'Language Development', 'Learning', 'Learning Disabilities', 'Longevity', 'Machine Learning', 'Modality', 'Modeling', 'Neurobiology', 'Neurons', 'Neurosciences', 'Parietal', 'Pattern', 'Perception', 'Physiological', 'Plant Roots', 'Population', 'Process', 'Quality of life', 'Research', 'Sensory', 'Signal Transduction', 'Songbirds', 'Speech', 'Speech Perception', 'Speech Sound', 'Stimulus', 'Stream', 'Sturnus vulgaris', 'Superior temporal gyrus', 'Techniques', 'Testing', 'Time', 'Work', 'auditory processing', 'autism spectrum disorder', 'bird song', 'cognitive process', 'computer framework', 'experience', 'experimental study', 'hearing impairment', 'improved', 'language comprehension', 'language processing', 'learned behavior', 'machine learning method', 'model development', 'neural circuit', 'neurobiological mechanism', 'neuromechanism', 'pattern perception', 'relating to nervous system', 'response', 'sensory input', 'sensory system', 'signal processing', 'sound', 'spatiotemporal', 'specific language impairment', 'speech processing', 'speech recognition', 'statistics', 'success']",NIDCD,"UNIVERSITY OF CALIFORNIA, SAN DIEGO",R01,2021,335661
"Shared and specific mechanisms of auditory and visual category learning PROJECT SUMMARY/ABSTRACT The ability to learn new perceptual categories enables some of the most complex human behaviors, from speech perception to visual object recognition. Current understanding of the mechanisms involved in perceptual category learning relies on the fundamental assumption that the processes underlying such learning are shared across the senses. However, the vast majority of this work has focused on the visual modality. As a consequence, the research regarding how humans learn to group complex auditory information into categories has relied greatly on conclusions from the research in the visual domain without testing this critical assumption. However, recent evidence from the attention literature suggests that even seemingly domain-general cognitive processes, such as working memory, are accomplished via sensory-biased regions in frontal cortex. The current investigation will directly compare the computational and neural mechanisms supporting auditory and visual category learning by training the same individuals on categories in both modalities while in an fMRI scanner. Aim #1 of this investigation will identify the shared and sensory-biased circuits supporting feedback processing during auditory and visual category learning. If the neural circuits supporting perceptual category learning are shared across the modalities, it is expected that similar regions will be recruited to a similar extent during feedback processing. If instead, the neural circuits are distinct for particular modalities, it is expected that sensory-biased regions will emerge as supporting category learning for auditory and visual modalities. Aim #2 will utilize advanced machine learning techniques (multivariate pattern classification and representational similarity analyses) to characterize the emergence of category-level neural representations over the course of learning. Aim #3 will identify the functional and structural connectivity of the circuits as they contribute to perceptual category learning. The proposed research will directly test the fundamental assumption about the nature of this complex problem that affects everyday behaviors. This research has the potential to impact understanding of cases where modality- specific learning abilities might be impaired, such as phonetic learning and language-related impairments in dyslexia, autism, and specific language impairment. The proposed research will provide the training foundation to support the PI’s long-term objective of developing theories of perceptual category learning that are constrained by neurobiology and behavior and will specify the behavioral, computational, and neural mechanisms of such learning. This project presents the opportunity to directly test a critical assumption underlying understanding of perceptual category learning. The proposed research will take place in an exceptional training environment and the PI will be mentored by a team of knowledgeable and accomplished scientists. The research will provide the PI with training in functional magnetic resonance experiment design and analysis which will prepare her well for a career as an independent scientist in computational cognitive neuroscience. PROJECT NARRATIVE The proposed research will contribute to fundamental knowledge about how seemingly general-purpose cognitive systems may demonstrate modality specificity. The goal of this investigation is to characterize the differences in cognitive processing during category learning when the information comes from the auditory or visual modalities. The findings from this work may inform mechanistic approaches to understanding modality- specific deficits in language-based disorders, such as dyslexia, autism, and specific language impairment.",Shared and specific mechanisms of auditory and visual category learning,10197776,F32DC018979,"['Affect', 'Area', 'Attention', 'Auditory', 'Behavior', 'Behavioral', 'Brain', 'Brain region', 'Categories', 'Classification', 'Cognitive', 'Complex', 'Corpus striatum structure', 'Disease', 'Dyslexia', 'Environment', 'Esters', 'Feedback', 'Finches', 'Foundations', 'Functional Magnetic Resonance Imaging', 'Goals', 'Hobbies', 'Human', 'Hybrids', 'Impairment', 'Individual', 'Investigation', 'Knowledge', 'Language', 'Learning', 'Literature', 'Machine Learning', 'Magnetic Resonance', 'Mentors', 'Modality', 'Modeling', 'Nature', 'Neurobiology', 'Participant', 'Pattern', 'Process', 'Property', 'Research', 'Scientist', 'Sensory', 'Short-Term Memory', 'Specific qualifier value', 'Specificity', 'Speech', 'Speech Perception', 'Structure', 'Techniques', 'Testing', 'Theoretical model', 'Training', 'Visual', 'Work', 'auditory stimulus', 'autism spectrum disorder', 'base', 'behavior measurement', 'career', 'cognitive neuroscience', 'cognitive process', 'cognitive system', 'design', 'experimental study', 'frontal lobe', 'individual variation', 'innovation', 'learning ability', 'neural circuit', 'neuromechanism', 'object recognition', 'programs', 'recruit', 'relating to nervous system', 'response', 'sound', 'specific language impairment', 'theories', 'visual learning']",NIDCD,UNIVERSITY OF PITTSBURGH AT PITTSBURGH,F32,2021,65994
"Cortical computations underlying binocular motion integration PROJECT SUMMARY / ABSTRACT Neuroscience is highly specialized—even visual submodalities such as motion, depth, form and color processing are often studied in isolation. One disadvantage of this isolation is that results from each subfield are not brought together to constrain common underlying neural circuitry. Yet, to understand the cortical computations that support vision, it is important to unify our fragmentary models that capture isolated insights across visual submodalities so that all relevant experimental and theoretical efforts can benefit from the most powerful and robust models that can be achieved. This proposal aims to take the first concrete step in that direction by unifying models of direction selectivity, binocular disparity selectivity and 3D motion selectivity (also known as motion-in-depth) to reveal circuits and understand computations from V1 to area MT. Motion in 3D inherently bridges visual submodalities, necessitating the integration of motion and binocular processing, and we are motivated by two recent paradigm-breaking physiological studies that have shown that area MT has a robust representation of 3D motion. In Aim 1, we will create the first unified model and understanding of the relationship between pattern and 3D motion in MT. In Aim 2, we will construct the first unified model of motion and disparity processing in MT. In Aim 3, we will develop a large-scale biologically plausible model of these selectivities that represents realistic response distributions across an MT population. Having a population output that is complete enough to represent widely-used visual stimuli will amplify our ability to link to population read-out theories and to link to results from psychophysical studies of visual perception. Key elements of our approach are (1) an iterative loop between modeling and electrophysiological experiments; (2) building a set of shared models, stimuli, data and analysis tools in a cloud-based system that unifies efforts across labs, creating opportunities for deep collaboration between labs that specialize in relevant submodalities, and encouraging all interested scientists to contribute and benefit; (3) using model-driven experiments to answer open, inter-related questions that involve motion and binocular processing, including motion opponency, spatial integration, binocular integration and the timely problem of how 3D motion is represented in area MT; (4) unifying insights from filter-based models and conceptual, i.e., non-image- computable, models to generate the first large-scale spiking hierarchical circuits that predict and explain how correlated signals and noise are transformed across multiple cortical stages to carry out essential visual computations; and (5) carrying out novel simultaneous recordings across visual areas. This research also has potential long-term benefits in medicine and technology. It will build fundamental knowledge about functional cortical circuitry that someday may be useful for interpreting dysfunctions of the cortex or for helping biomedical engineers construct devices to interface to the brain. Insights gained from the visual cortex may also help to advance computer vision technology. NARRATIVE The processing of visual motion and depth information is essential for a wide variety of important human abilities, including navigating through the world, avoiding collisions, catching and grabbing objects and interpreting complex scenes. To understand how neurons in the visual cortex transform and represent the information that underlies these abilities, we aim to initiate the development of a more complete, biologically constrained and openly available computer model of motion and depth processing that will be used to guide, and to interpret and incorporate results from, primate visual neurophysiological and psychophysical experiments. Gaining an understanding of the normal function of cortical neural circuitry is an important step in building the fundamental knowledge that someday may help to improve the ability to assess dysfunctions of the cortex and may help bioengineers create devices that interface to cortical circuitry to treat disorders and overcome disabilities.",Cortical computations underlying binocular motion integration,10188534,R01EY027023,"['3-Dimensional', 'Affect', 'Architecture', 'Biological', 'Biomedical Engineering', 'Brain', 'Collaborations', 'Color', 'Complex', 'Computer Models', 'Computer Vision Systems', 'Cues', 'Data', 'Data Analyses', 'Development', 'Devices', 'Disadvantaged', 'Discrimination', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Elements', 'Foundations', 'Frequencies', 'Functional disorder', 'Human', 'Joints', 'Knowledge', 'Link', 'Literature', 'Medicine', 'Modeling', 'Motion', 'Neurons', 'Neurosciences', 'Noise', 'Output', 'Pathway interactions', 'Pattern', 'Performance', 'Physiological', 'Physiology', 'Population', 'Primates', 'Production', 'Psychophysics', 'Reproducibility', 'Research', 'Role', 'Scientist', 'Signal Transduction', 'Stimulus', 'System', 'Technology', 'Testing', 'Time', 'Vision', 'Vision Disparity', 'Visual', 'Visual Cortex', 'Visual Motion', 'Visual Perception', 'area MT', 'base', 'cloud based', 'color processing', 'disability', 'experimental study', 'extrastriate visual cortex', 'fitness', 'improved', 'in vivo', 'insight', 'interest', 'neural circuit', 'neurophysiology', 'novel', 'predictive modeling', 'relating to nervous system', 'response', 'spatial integration', 'spatiotemporal', 'theories', 'tool', 'visual neuroscience', 'visual process', 'visual processing', 'visual stimulus']",NEI,UNIVERSITY OF WASHINGTON,R01,2021,387514
"Causal role of higher-order thalamo-cortical oscillations in sustained attention PROPOSAL SUMMARY/ABSTRACT Sustained attention – the continuous allocation of cognitive resources to respond to infrequent but behaviorally relevant stimuli – is impaired in many psychiatric disorders and represents an important aspect of cognitive control. Sustained attention requires top-down control and engagement with the external world, which is linked to both frontoparietal and thalamic controlling signals on primary sensor cortices. Despite the extensive behavioral characterization of sustained attention in animal models using the five-choice serial reaction time task (5-CSRTT), very little is known about the oscillatory interaction between the dorsal attention network and thalamo-cortical dynamics and its potential as a stimulation target for enhancing sustained attention. The objective of this project is to dissect the causal role of higher-order thalamo-cortical oscillations in sustained attention via temporally-precise rhythmic stimulation. I will focus on three regions in the visual thalamo-cortical network: higher-order visual thalamus (lateral aspect of lateral posterior nucleus, LPl), posterior parietal cortex (PPC), and primary visual cortex (V1). I will test the central hypothesis that LPl-cortical theta (4-7 Hz) functional connectivity causally coordinates PPC-V1 functional connectivity to facilitate sustained attention. The rationale of this work is that the proposed temporally-precise rhythmic optogenetic perturbations will directly test the causal role of thalamo-cortical functional connectivity in sustained attention. Accordingly, the two specific aims are: (1) Delineate the functional role of higher-order thalamo-cortical oscillations in sustained attention, (2) Determine the causal role of thalamo-cortical functional connectivity in sustained attention via temporally-precise rhythmic optogenetics. This work is significant because it will causally test a convergent model in which higher-order visual thalamus coordinates the parietal top-down control signals onto visual cortex that is crucial for developing circuit- based therapies to enhance sustained attention. The work is innovative due to its integration of closed-loop optogenetics circuit interrogation, multisite electrophysiology, freely-moving sustained attention task, and machine-learning tools for the investigation of the causal role of oscillatory synchronization. The overall positive impact of the proposed study is to provide a more comprehensive map of how the higher-order visual thalamus interacts with the frontoparietal control signal to modulate V1, and thus mediates sustained attention, a transdiagnostic cognitive function that shows impairment in many psychiatric disorders including attention deficit hyperactivity disorder, bipolar disorder, and schizophrenia. The implication of this study is that it may reveal a general mechanism underlying the interaction between two higher-order processing structures signaling to lower sensory cortices during cognitive processing. PROJECT NARRATIVE Sustained attention enables us to focus our cognitive resources on an activity for a prolonged period of time, and when impaired causes profound deficits in both cognition and behavior. Sustained attention is modulated by the thalamo-cortical rhythms. The research generated in this proposal will investigate (1) what oscillatory feature in the higher-order thalamo-cortical circuit is crucial for sustained attention, and (2) how the temporally- precise enhancing or disrupting of a thalamo-cortical oscillatory feature alters the functional connectivity in the circuit and behavioral outcomes mediated by sustained attention.",Causal role of higher-order thalamo-cortical oscillations in sustained attention,10199754,F31MH118799,"['Anatomy', 'Animal Model', 'Animals', 'Attention', 'Attention deficit hyperactivity disorder', 'Attentional deficit', 'Behavior', 'Behavioral', 'Bipolar Disorder', 'Cognition', 'Cognitive', 'Cognitive deficits', 'Communication', 'Communities', 'Computers', 'Conflict (Psychology)', 'Couples', 'Data', 'Dorsal', 'Electrophysiology (science)', 'Exhibits', 'Ferrets', 'Foundations', 'Frequencies', 'Functional disorder', 'Impairment', 'Implant', 'Impulsivity', 'Investigation', 'Lasers', 'Lateral', 'Lateral posterior nucleus of thalamus', 'Length', 'Link', 'Machine Learning', 'Maps', 'Mediating', 'Mental disorders', 'Methods', 'Microelectrodes', 'Modeling', 'Neurons', 'Parietal', 'Parietal Lobe', 'Performance', 'Periodicity', 'Phase', 'Physiologic pulse', 'Prefrontal Cortex', 'Process', 'Psyche structure', 'Reaction Time', 'Research', 'Resources', 'Rewards', 'Role', 'Schizophrenia', 'Signal Transduction', 'Statistical Models', 'Stimulus', 'Structure', 'Techniques', 'Testing', 'Thalamic structure', 'Therapeutic', 'Time', 'Touch sensation', 'Training', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'base', 'behavioral outcome', 'calmodulin-dependent protein kinase II', 'cognitive control', 'cognitive function', 'functional disability', 'innovation', 'neurotransmission', 'novel', 'optogenetics', 'recruit', 'relating to nervous system', 'sensor', 'sensory cortex', 'signal processing', 'sustained attention', 'theories', 'tool', 'visual stimulus']",NIMH,UNIV OF NORTH CAROLINA CHAPEL HILL,F31,2021,40048
"Prefrontal contributions to contextual representation Project Abstract/Summary This application describes a 3-year training plan that will enable me, a cognitive neuroscientist with prior training in electroencephalography (EEG), to conduct research on contextual memory representation using neuroimaging (fMRI) and computational modeling. EEG is useful for examining the timing properties of neural activity, but cannot localize activity to specific regions of the brain. In this proposal, I will receive training on a high-spatial resolution neuroimaging technique (fMRI), which will allow me to develop theories of neural function that are constrained by both space and time. I will also build on my prior degree in applied statistics and receive additional training in computational neuroscience, which will enable me to develop computational theories at the macro-circuit level. I will be supervised by Dr. Sharon Thompson-Schill, an expert fMRI experimentalist and theorist of lateral prefrontal cortex function, who has extensive experience researching the context-dependent nature of semantic memory. I will be co-supervised by Dr. Anna Schapiro, an expert on statistical learning and computational modeling of the brain. I propose to examine how prefrontal cortex (PFC) represents statistical dependencies among sequentially presented visual and auditory input. I will examine how the temporal extent and level of abstraction of sequential representations changes across ventral PFC. This will connect findings from several literatures, ranging from decision-making to emotion processing and language comprehension, within a single unifying framework. In addition, I will explore whether ‘deep’ or ‘shallow’ recurrent neural networks better capture the sensitivity profile of ventral PFC, informing the question of whether the brain conducts ‘deep’ learning. In Aim 1, I will conduct behavioral piloting and collect data for two neuroimaging experiments on hierarchical sequential processing. I will have participants learn the statistical properties of hierarchically organized sequences of abstract visual (Aim 1a&b) and auditory (Aim 1b) images. I then test for neural sensitivity to statistical learning at each hierarchical level using pattern similarity analysis, comparing the neural response to the sequences before and after learning. In Aim 2, I will conduct computational modeling of the neuroimaging data in Aim 1, with held out data to ensure robustness and reproducibility. I compare the neuroimaging data to internal model representations derived from single-layer (‘shallow’) and multi-layer (‘deep’) recurrent neural networks trained on the same sequences as the humans in Aim 1. By modeling the neural representation of context itself, the current proposal will help fill a critical gap in our understanding of how the brain predicts upcoming sensory input, enabling rapid processing of the world around us. It will also inform our understanding of several psychiatric disorders that involve prefrontal cortex disfunction and disturbances of contextual processing, such as schizophrenia, anxiety and depression. Project Narrative As we navigate the world we are bombarded by a flood of sensations that our brain must rapidly make sense of, and understanding the context we are in as it relates to the likelihood of upcoming experiences is important for enhancing the speed and accuracy of this process. This proposal examines how sensory context is represented in the brain, by having people learn statistical regularities in artificial sequences of images and syllables and modeling neural activity in prefrontal cortex as they are exposed to different sensory “contexts” using fMRI. Through computational modeling of prefrontal cortex, we can enhance our understanding of the function of a brain region implicated in many neuropsychological disorders where the perception of context is distorted or disrupted, including anxiety, depression, and schizophrenia.",Prefrontal contributions to contextual representation,10144850,F32MH123002,"['Anxiety', 'Attention', 'Auditory', 'Behavioral', 'Behavioral Model', 'Brain', 'Brain region', 'Cognitive', 'Complex', 'Computer Models', 'Cues', 'Data', 'Decision Making', 'Dependence', 'Electroencephalography', 'Electrophysiology (science)', 'Emotions', 'Ensure', 'Esthesia', 'Event', 'Exhibits', 'Exposure to', 'Floods', 'Fractals', 'Functional Magnetic Resonance Imaging', 'Grain', 'Hearing', 'Heart', 'Human', 'Image', 'Knowledge', 'Language', 'Lateral', 'Learning', 'Linguistics', 'Literature', 'Maps', 'Measures', 'Medial', 'Mediating', 'Memory', 'Mental Depression', 'Mental disorders', 'Methods', 'Mind', 'Modality', 'Modeling', 'Nature', 'Neural Network Simulation', 'Neurophysiology - biologic function', 'Neuropsychology', 'Parietal', 'Participant', 'Pattern', 'Perceptual Disorders', 'Prefrontal Cortex', 'Process', 'Property', 'Psychology', 'Reproducibility', 'Research', 'Resolution', 'Schizophrenia', 'Semantic memory', 'Semantics', 'Sensory', 'Shapes', 'Signal Transduction', 'Specificity', 'Speed', 'Stimulus', 'Stream', 'Structure', 'Supervision', 'Techniques', 'Testing', 'Time', 'Training', 'Validation', 'Visual', 'Work', 'base', 'computational neuroscience', 'computerized tools', 'deep learning', 'experience', 'experimental study', 'insight', 'interest', 'language comprehension', 'neural model', 'neuroimaging', 'recurrent neural network', 'relating to nervous system', 'response', 'sensory input', 'sensory stimulus', 'sequence learning', 'social', 'sound', 'statistical learning', 'statistics', 'theories']",NIMH,UNIVERSITY OF PENNSYLVANIA,F32,2021,66390
"Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology Project Summary Listening in noise is a core problem in everyday hearing. Sound sources of interest routinely occur amid irrelevant distractors, as when you talk with someone in a bustling coffee shop. This background “noise” distorts the pattern of spikes in the auditory nerve, often to a profound degree. Thus, to recognize sources of interest, the auditory system must somehow separate or suppress the effects of the background. Typical human hearing is remarkably noise-robust, but listeners with age-related hearing loss or other forms of impaired hearing struggle in noisy environments – and are not much helped by contemporary hearing aids. Previous work on the neural basis of noise robustness has typically employed simple, synthetic noise sources, which lack the structure present in real-world sounds, and this work has focused on subcortical regions or on primary auditory cortex. Reasoning that real-world conditions might necessitate more complicated solutions, in the applicant's doctoral work, he considered everyday sources of noise, and leveraged the large-scale coverage afforded by fMRI to examine noise robustness throughout human auditory cortex. Real-world “background noise” was operationalized as a natural sound with statistical properties that are stable over time (i.e., are stationary), conveying little new information about the world (e.g., swamp insects, an air conditioner, rain on pavement). The applicant measured fMRI responses in human listeners to a broad set of natural sounds presented in quiet, as well as embedded in the real-world background noises. Primary auditory cortical responses were substantially altered by the background, but non-primary responses were substantially more robust. This effect was not seen for simple synthetic backgrounds as had been used in previous work, suggesting that becoming robust to real-world background noises require different mechanisms. The applicant's thesis work demonstrates where noise invariance arises, but understanding how will require data with finer spatial and temporal resolution, and thus the proposed postdoctoral research will consist of training in single-unit electrophysiology using marmosets. Aim 1A builds on previous work examining single- unit noise robustness in artificial conditions, extending such work to real-world noise. Aim 1B leverages texture models to probe what aspects of real-world backgrounds disrupt the encoding of foregrounds. Aim 2A deploys linear reconstruction techniques to probe population representations. Aim 2B involves optimizing deep neural networks for noise invariance tasks, and using them as an encoding model to predict single-unit responses. Furthermore, such networks will be deployed as nonlinear decoding algorithms, reconstructing stimuli from neuronal populations. Throughout all aims, the work will characterize neuronal responses in non-primary areas, and in particular in parabelt, which is understudied in primates. The proposed work may enable improvements in hearing aid algorithms or neural prosthetics. Lastly, this training will lay the groundwork for the applicant's long-term goal of developing a marmoset model for hearing loss. Project Narrative Typical human hearing is remarkably robust to the presence of background noise, but listeners with age- related hearing loss or other forms of impaired hearing struggle in noisy environments – and often do not benefit from contemporary hearing aids in these conditions. In my doctoral work, using fMRI in humans I showed that real-world background noise engages different mechanisms than the simpler synthetic noise typically employed in previous work. In my postdoctoral work I will be trained in marmoset electrophysiology to zoom in to the level of neural circuits to probe the mechanisms that generate auditory cortex's robustness to background noise.",Mechanisms for invariance in auditory cortex: Investigations with marmoset electrophysiology,10115690,F32DC017628,"['Acoustic Nerve', 'Address', 'Air', 'Algorithms', 'Area', 'Attention', 'Auditory', 'Auditory Prosthesis', 'Auditory area', 'Auditory system', 'Basic Science', 'Brain', 'Callithrix', 'Clinical', 'Code', 'Coffee', 'Computer Models', 'Data', 'Data Analyses', 'Development', 'Electrophysiology (science)', 'Environment', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Hearing', 'Hearing Aids', 'Human', 'Impaired cognition', 'Individual', 'Insecta', 'Investigation', 'Measures', 'Microelectrodes', 'Modeling', 'Neurons', 'Noise', 'Pattern', 'Performance', 'Physiological', 'Population', 'Presbycusis', 'Primates', 'Process', 'Property', 'Quality of life', 'Rain', 'Research', 'Silicon', 'Source', 'Stimulus', 'Structure', 'Techniques', 'Texture', 'Time', 'Training', 'Work', 'algorithm training', 'base', 'deep learning', 'deep neural network', 'experience', 'experimental study', 'hearing impairment', 'improved', 'interest', 'neural circuit', 'neural prosthesis', 'neuromechanism', 'programs', 'reconstruction', 'relating to nervous system', 'response', 'signal processing', 'social', 'sound', 'temporal measurement']",NIDCD,COLUMBIA UNIVERSITY HEALTH SCIENCES,F32,2021,66390
"Cortical visual processing for navigation Project summary Vision plays a key role in our ability to navigate through the environment, from identifying landmarks and obstacles to determining location and heading. While studies of visual cortex have provided an understanding of properties such as orientation selectivity and object recognition, much less is known about how cortical circuitry extracts and processes features from the visual scene to support navigation. In particular, there are two challenges. First, the nature of the visual stimulus is dramatically different in navigation, where the subject's movement through the world creates a complex and dynamic visual input, in contrast to standard synthetic stimuli presented to stationary subjects. Second, the types of visual features and computations that must be performed are different in navigation than in standard detection or discrimination paradigms. Our goal in this proposal is to determine how the brain extracts relevant visual features from the rich, dynamic visual input that typiﬁes active exploration, and investigate how the neural representation of these features can support visual navigation.  We will investigate this through three parallel aims, that build up from the representation of the visual scene in V1 during freely moving navigation, to the computation of speciﬁc variables needed for navigation. In our ﬁrst aim, we will measure the visual input in freely moving mice using miniature head-mounted cameras, together with neural activity in V1, to determine how neural dynamics represent the visual scene during natural navigation. In our second aim, we will use large ﬁeld-of-view two-photon imaging of multiple cortical areas, while mice navigate in a naturalistic open-world virtual reality system, to determine how visual features are represented across visual cortical areas. In our third aim, we will use 2-photon imaging in mice in a rotational arena to determine how visual input is used to dynamically update a key navigational variable: heading direction. Together, this project bridges foundational measurements in freely moving animals with mechanistic circuit investigations, to provide insights into an important aspect of visual system function. Project Narrative This project will study how the brain processes visual information to support navigation, which is important for guiding goal-directed movement through the world. The results of this work will provide knowledge about normal visual function and insights for treating impaired vision via prosthetic or assistive devices.",Cortical visual processing for navigation,10208550,R01NS121919,"['Animals', 'Area', 'Behavior', 'Behavioral', 'Brain', 'Code', 'Complex', 'Conflict (Psychology)', 'Cues', 'Data', 'Detection', 'Discrimination', 'Electrophysiology (science)', 'Environment', 'Foundations', 'Frequencies', 'Goals', 'Head', 'Hippocampus (Brain)', 'Image', 'Investigation', 'Knowledge', 'Location', 'Measurement', 'Measures', 'Modeling', 'Motion', 'Movement', 'Mus', 'Nature', 'Neural Network Simulation', 'Play', 'Population', 'Process', 'Property', 'Prosthesis', 'Rotation', 'Sampling', 'Self-Help Devices', 'Sensory', 'Signal Transduction', 'Space Models', 'Stimulus', 'Structure', 'Testing', 'Update', 'Vision', 'Visual', 'Visual Cortex', 'Visual impairment', 'Visual system structure', 'Visuospatial', 'Work', 'deep neural network', 'entorhinal cortex', 'experimental study', 'high dimensionality', 'insight', 'novel', 'object recognition', 'optic flow', 'orientation selectivity', 'relating to nervous system', 'response', 'statistics', 'synergism', 'theories', 'two-photon', 'virtual reality', 'virtual reality system', 'virtual world', 'visual information', 'visual process', 'visual processing', 'visual stimulus']",NINDS,UNIVERSITY OF CALIFORNIA SANTA BARBARA,R01,2021,2833387
"Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex Project Summary The use of stimuli with increasingly naturalistic properties has become critical to advance our understanding of vision. Many studies demonstrate that simple artificial stimuli (e.g. sinusoidal gratings and white noise) fail to engage nonlinearities that profoundly alter responses in the retina, lateral geniculate nucleus (LGN), and primary visual cortex (V1). A recent and striking example comes from the use of naturalistic ‘flow’ stimuli, which engage robust responses in V1 that are not predicted from responses to gratings. This gap in understanding motivates the development of a stimulus ensemble and analysis framework that produces a quantitative understanding of visual processing to increasingly naturalistic stimuli and the nonlinearities that they engage. Our objective is to understand how flow stimuli are processed from retina through visual cortex. To meet this goal, we will make neural population recordings in retina (Aims 1 & 3), LGN (Aims 1 & 3) and V1 (Aim 3) using matched experimental conditions and a unified theoretical/modeling framework to map the transformations that occur across these stages of visual processing. Our central hypothesis is that V1 transforms a discrete and heavily light-level-de- pendent retinal representation of natural stimuli into a continuous (uniform) representation that is relatively in- variant to changes in the mean luminance. This invariance places a strong constraint on the class of nonlineari- ties that transform retinal responses to those observed in LGN and V1. We test this hypothesis in three aims: (1) determine early visual processing (retina & LGN) of naturalistic flow stimuli; (2) develop an encoding manifold to capture the population activity at each processing stage and transforms from one stage to the next; (3) test the ability of the manifold description to predict the impact of light adaptation on processing flow stimuli from retina to V1. Aim 1 will yield a matched experimental dataset to an interesting and novel class of ecologically-relevant stimuli. Aim 2 will yield a quantitative framework by which to understand the transformations that occur between retina, LGN, and V1. Aim 3 will provide a platform for globally perturbing the output of the retina by switching from photopic to mesopic and scotopic conditions, and thereby compare predictions of our model to measured changes in LGN and V1 activity. The primary significance of this research is that it will provide a computationally and experimentally unified framework for understanding the transformations that occur in the processing of stim- uli across multiple stages of visual processing. The major innovations are (1) presenting visual stimuli for retinal recordings that are matched to eye movements and pupil dynamics in alert animals; (2) creating a novel analysis framework that captures the responses of neurons at all three levels and the inter-level transformations to in- creasingly complex stimuli; (3) utilizing light adaptation as a method of perturbing retinal output to test our model and the stability (invariance) of LGN and V1 responses to adapting retinal signals. The expected outcome is a data-driven model of the processing from retina to LGN and V1 that generalizes from starlight to sunlight. Project Narrative Restoring vision to the blind likely requires understanding how retinal signals are communicated to the brain and how these signals are transformed in the thalamocortical pathway. This project aims to acquire an understanding of these transformations in the context of complex and more naturalistic visual stimuli.",Elucidating novel features of visual processing and physiological connectivity from retina to primary visual cortex,10229447,R01EY031059,"['Affect', 'Animals', 'Brain', 'Collaborations', 'Complex', 'Cone', 'Data', 'Data Set', 'Development', 'Environment', 'Eye Movements', 'Future', 'Goals', 'Lateral Geniculate Body', 'Light', 'Light Adaptations', 'Machine Learning', 'Maps', 'Mathematics', 'Measurement', 'Measures', 'Mediating', 'Methods', 'Modeling', 'Movement', 'Mus', 'Neurons', 'Noise', 'Optics', 'Outcome', 'Output', 'Pathway interactions', 'Physiological', 'Population', 'Process', 'Property', 'Pupil', 'Research', 'Retina', 'Retinal Ganglion Cells', 'Rod', 'Signal Transduction', 'Stimulus', 'Structure', 'Sunlight', 'Techniques', 'Testing', 'Theoretical model', 'Variant', 'Vision', 'Visual Cortex', 'Visual system structure', 'Work', 'area striata', 'base', 'blind', 'cell type', 'computational neuroscience', 'experimental study', 'in vivo', 'innovation', 'luminance', 'multi-electrode arrays', 'novel', 'predictive modeling', 'receptive field', 'relating to nervous system', 'response', 'retinal neuron', 'sight restoration', 'stimulus processing', 'visual processing', 'visual stimulus']",NEI,DUKE UNIVERSITY,R01,2021,487568
"GAZE AND THE VISUAL CONTROL OF FOOT PLACEMENT WHEN WALKING OVER ROUGH TERRAIN PROJECT SUMMARY & ABSTRACT  Human locomotion through natural environments requires the coordination of all levels of the sensorimotor hierarchy, from the cortical areas involved in processing of visual information and high level planning to the subcortical and spinal structures involved in the regulation of the gait and posture. However, despite the complex neural bases of human locomotion, the output is highly regular and well organized around the basic physical dynamics and biomechanics that define the stability and energetic costs of moving a bipedal body through space. There is a rich and growing body of literature describing detailed knowledge each of the individual components of human locomotion, including neural mechanisms, muscular neuromechanics, and biomechanics. However, very little research exists on the way that visual input is used to dynamically control locomotion, and the overall control structure of the integrated neural and mechanical system during natural locomotion through a complex and dynamic world. This lack of integrative research not only restricts the breadth of impact of research from these individual disciplines, but also limits our ability to develop adequate treatment plans for loss of locomotor ability deriving from systems-level factors such as aging, stroke, and Parkinson’s disease. In order to to fill this critical gap in our knowledge about human locomotion, it is necessary to develop an integrated research program that examines the interactions between the visual, neural, and mechanical bases of human movement through the world. In service of this general goal, this proposal outlines research projects aimed at specific unanswered questions about locomotion over different terrains. This proposal comprises three specific research and training aims on the visual control of locomotion over rough terrain. Aim 1 focuses on the behavioral task itself, Aim 2 investigates the sensory stimulus experienced during real-world locomotion, and Aim 3 examines the motor integration of visually specified goals into the ongoing gait cycle. Aim 1 investigates effects of changing environmental uncertainty and task demands on gaze allocation strategies during locomotion over real-world rough terrain. Aim 2 analyzes and models the visual stimulus experienced during locomotion over real-world rough terrain. Aim 3 determines how visually specified target footholds and targets are integrated into the ongoing preferred steady-state gait. Together these aims will significantly advance our understanding of how humans use vision to control their movement through the natural world, which greatly increase our ability to develop clinical diagnosis and treatment for loss of locomotor function. PROJECT NARRATIVE  Very little research exists on the way that visual input is used to dynamically control locomotion, and the overall control structure of the integrated neural and mechanical system during natural locomotion. This lack of integrative research limits our ability to develop adequate treatment plans for loss of locomotor ability deriving from systems-level factors such as aging, stroke, and Parkinson’s disease. In order to fill this critical gap in our knowledge about human locomotion, this proposal develops an integrated research program that examines the interactions between the visual, neural, and mechanical bases of human movement through the world.",GAZE AND THE VISUAL CONTROL OF FOOT PLACEMENT WHEN WALKING OVER ROUGH TERRAIN,10224830,R00EY028229,"['3-Dimensional', 'Aging', 'Algorithms', 'Area', 'Attention', 'Behavior', 'Behavioral', 'Biomechanics', 'Clinical Treatment', 'Cognitive', 'Complex', 'Computer Vision Systems', 'Development', 'Discipline', 'Environment', 'Eye', 'Gait', 'Goals', 'Human', 'Image', 'Individual', 'Knowledge', 'Link', 'Literature', 'Locomotion', 'Measures', 'Mechanics', 'Mentors', 'Modeling', 'Motion', 'Motor', 'Movement', 'Muscle', 'Musculoskeletal', 'Nature', 'Neuromechanics', 'Output', 'Parkinson Disease', 'Pattern', 'Phase', 'Photic Stimulation', 'Positioning Attribute', 'Postdoctoral Fellow', 'Posture', 'Protocols documentation', 'Regulation', 'Research', 'Research Activity', 'Research Project Grants', 'Research Training', 'Services', 'Signal Transduction', 'Specific qualifier value', 'Spinal', 'Stroke', 'Structure', 'System', 'Training', 'Training Programs', 'Uncertainty', 'Vision', 'Visual', 'Visual Fields', 'Walking', 'Wireless Technology', 'area MST', 'area MT', 'base', 'clinical Diagnosis', 'cost', 'design', 'environmental change', 'experience', 'experimental study', 'foot', 'gaze', 'insight', 'instrument', 'kinematics', 'multidisciplinary', 'neuromechanism', 'neuromuscular', 'novel', 'optic flow', 'programs', 'relating to nervous system', 'response', 'sensory stimulus', 'skills', 'statistics', 'treadmill', 'treatment planning', 'visual control', 'visual information', 'visual processing', 'visual stimulus', 'visual-motor integration']",NEI,NORTHEASTERN UNIVERSITY,R00,2021,229062
"Decoding parametric attributes of auditory working memories from human brain activity Decoding parametric attributes of auditory working memories from human brain activity Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Auditory WM dysfunctions are evidenced in individuals with speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as central auditory processing disorders (CAPD). Better understanding of auditory WM would help develop more precise biomarkers and targeted interventions for these deficits. Evidence for neuronal activation related to auditory WM patterns have been found in laboratory animals as well as in non- invasive human neuroimaging studies, both in auditory cortices (AC) and elsewhere in the brain. Recent human fMRI data also provide some evidence on item-specific activation patterns in ACs and frontal cortices. However, exactly where in the brain auditory WM content is stored and, more importantly, how the memorized information is represented is still unclear.  This research program pursues a better understanding of human auditory WM by attempting to infer its contents from the brain: Using state-of-the-art non-invasive neuroimaging and advanced signal-analysis methods we will search for cortical activation patterns that would predict item-specific WM information. We will examine brain function non-invasively with magneto- and electroencephalography (MEG/EEG), transcranial magnetic stimulation (TMS), and functional MRI (fMRI), and validate the findings using intracranial EEG (iEEG) measurements in presurgical patients. Recent studies suggest that, instead of persistent activation patterns, WM is supported by short-term synaptic facilitation, i.e., ""activity-silent"" population-level mechanisms. We hypothesize that these activity-silent representations could be decoded by analyzing the aftereffects of generic auditory ""impulse stimuli"" or TMS, which are utilized to ""ping"" the underlying cortical network during memory maintenance. We also hypothesize that although auditory WM likely involves co-operation of multiple brain regions, which are involved in articulatory-motor functions, perceptual categorization, or semantic processing, the retention of auditory-sensory attributes such as spectrotemporal modulation patterns critically depends on ACs. To examine WM of such auditory attributes, we will use tasks with dynamic ripple sound stimuli, which are spectrotemporally similar to human vocalizations but resist non-auditory processing strategies.  The major significance of this project is that it will increase the understanding of auditory WM, a crucial cognitive function whose neuronal bases have remained elusive. The results may also help develop more precise tools for characterizing auditory WM dysfunctions in hearing and communication deficits as well as in disorders such as dyslexia, attention deficit/hyperactivity disorder (ADHD), and schizophrenia. Auditory working memory (WM) refers to our capacity to maintain and manipulate relevant sound information to support communication and problem solving. Our research program pursues a better theoretical understanding of this crucial cognitive function using advanced multimodal neuroimaging methods, validated using intracranial recordings in pre-surgical patients. Our results may also help develop more precise tools for characterizing auditory WM dysfunctions in speech perception disorders, language and reading impairments, and other disorders involving dysfunction of auditory cognition, such as attention deficit/hyperactivity disorder (ADHD) and schizophrenia.",Decoding parametric attributes of auditory working memories from human brain activity,10105316,R01DC016915,"['Attention deficit hyperactivity disorder', 'Auditory', 'Auditory area', 'Biological Markers', 'Brain', 'Brain region', 'Central Auditory Processing Disorder', 'Cognition', 'Communication', 'Data', 'Disease', 'Dyslexia', 'Electroencephalography', 'Functional Magnetic Resonance Imaging', 'Hearing', 'Hearing problem', 'Human', 'Impairment', 'Individual', 'Intervention', 'Laboratory Animals', 'Language', 'Machine Learning', 'Magnetic Resonance Imaging', 'Maintenance', 'Measurement', 'Memory', 'Memory impairment', 'Methods', 'Modeling', 'Motor', 'Neurons', 'Operative Surgical Procedures', 'Output', 'Patients', 'Pattern', 'Perceptual Disorders', 'Population', 'Principal Component Analysis', 'Problem Solving', 'Reading', 'Research', 'Schizophrenia', 'Sensory', 'Short-Term Memory', 'Signal Transduction', 'Source', 'Speech Perception', 'Stimulus', 'Synapses', 'Techniques', 'Testing', 'Transcranial magnetic stimulation', 'base', 'cognitive function', 'cortex mapping', 'electric field', 'experimental study', 'frontal lobe', 'multimodality', 'neuroimaging', 'operation', 'programs', 'semantic processing', 'sound', 'tool', 'vocalization']",NIDCD,MASSACHUSETTS GENERAL HOSPITAL,R01,2021,599963
"Early representation of 3D volumetric shape in visual object processing Project Summary The goal of this project is to test a novel theoretical framework for understanding how the ventral pathway subserves object vision. In the standard framework, a series of neural operations on 2D image data through many intermediate cortical stages, including area V4, leads to high-level perceptual representations, including representation of object identity, at the final stages of the ventral pathway. However, our preliminary microelectrode data from a fixating monkey show that many neurons in V4 represent volumetric (volume- enclosing) 3D shape, not 2D image patterns. These neurons respond to many different 2D images that convey the same 3D shape with different shape-in-depth cues, including shading, reflection, and refraction. They even respond preferentially to random dot stereograms that convey 3D volumetric shape with no 2D cues whatsoever. Moreover, our preliminary results with 2-photon functional imaging in anesthetized monkey V4 show that 3D shape signals are grouped by their similarity, and also group with isomorphic (same outline) 2D shape signals (which could contribute evidence to corresponding 3D shape inferences). We propose to capitalize on these preliminary data by demonstrating the prevalence of 3D shape tuning in area V4, analyzing the 3D shape coding strategies used by these neurons, and measuring how 2D and 3D shape signals are arranged at a microscopic level across the surface of V4. We expect these results to provide strong evidence that extraction of 3D shape fragments is a primary goal of V4 processing. This early extraction of 3D shape information, just two synapses beyond primary visual cortex, would suggest a competing framework for understanding the ventral pathway, in which the initial goal is to represent 3D physical structure, independent of the various 2D image cues used to infer it. In this framework, object recognition would be based on preceding information about 3D physical structure, which would explain why human object recognition is so robust to image changes, in a way that the best computational vision systems are not. The scientific impact of this work would be to divert vision experiments toward understanding representation of real world 3D structure (rather than 2D planar stimuli) and to encourage computational vision scientists to incorporate early 3D shape processing into the deep convolutional network models that are the current state of the art. Narrative This study will help explain how the human brain achieves such remarkably robust perception of visual objects. The results will help guide future rehabilitative and prosthetic strategies for patients with visual impairments, by elucidating neural strategies that could be used to bring computer vision prosthetics up to human performance levels, and by discovering specific neural signals for object information that could be replicated by electrode array implants in higher-level visual cortex.",Early representation of 3D volumetric shape in visual object processing,10173788,R01EY029420,"['3-Dimensional', '3D world', 'Area', 'Biological', 'Brain', 'Calcium Signaling', 'Code', 'Computer Vision Systems', 'Cues', 'Data', 'Electrodes', 'Functional Imaging', 'Future', 'Genetic Programming', 'Glass', 'Goals', 'Human', 'Image', 'Implant', 'Lead', 'Learning', 'Measures', 'Medial', 'Microelectrodes', 'Microscopic', 'Microscopy', 'Modeling', 'Monkeys', 'Network-based', 'Neurons', 'Ocular Prosthesis', 'Pathway interactions', 'Patients', 'Pattern', 'Performance', 'Population', 'Prevalence', 'Prosthesis', 'Rehabilitation therapy', 'Scientist', 'Series', 'Shapes', 'Signal Transduction', 'Stimulus', 'Structure', 'Surface', 'Synapses', 'System', 'Testing', 'Texture', 'Three-dimensional analysis', 'Time', 'V4 neuron', 'Vision', 'Visual Cortex', 'Visual Perception', 'Visual impairment', 'Work', 'area V4', 'area striata', 'base', 'convolutional neural network', 'experimental study', 'individual response', 'network models', 'neurotransmission', 'nonhuman primate', 'novel', 'object perception', 'object recognition', 'operation', 'relating to nervous system', 'response', 'three dimensional structure', 'two-photon', 'virtual reality', 'visual object processing']",NEI,JOHNS HOPKINS UNIVERSITY,R01,2021,532112
"Function and circuitry of adaptive inhibition in the retina Studies of the visual system face a number of challenges, two of which are the intricacy of the cell types and synaptic connections that comprise the nervous system, and the complexity of the computational processes that underlie vision. Although the retina is one of the most characterized and well understood neural circuits of the visual system, it nonetheless has a great diversity of cell types, connections and computations. The normal function of the retina is to convey information about natural visual scenes, which have complex spatial and temporal structure. The processing of natural scenes has the greatest relevance towards a fundamental understanding retinal function, and the greatest clinical relevance. Yet most studies of retinal visual processing and circuitry focus on responses to simple artificial stimuli rarely encountered normally, such as flashing spots, drifting stripes and flickering checkerboards. With respect to retinal cell types greatest diversity lies in a class of inhibitory interneurons known as amacrine cells. These cells make extensive lateral and feedback connections, and although they form stereotyped connections between each other, excitatory bipolar cells, and ganglion cells that transit signals in the optic nerve, the functional effects of nearly all of these cell types are poorly understood. This proposal aims towards a direct characterization of the functional effects of amacrine cells under ethologically relevant stimuli, including natural scenes. We combine approaches of perturbation and recording using electrical and optical methods as well as computational modeling to characterize the specific contributions of amacrine cells to stimuli that include the representation of moving objects. We take advantage of recently developed computational approaches that can simultaneously capture the retinal response to a broad range of stimuli including natural scenes, capture a wide range of phenomena previously characterized only with artificial stimuli, and that have internal units highly correlated with retinal interneurons. Our goals are to 1) Create a quantitative understanding of the functional contributions of a class of sustained amacrine cells in the salamander retina for specific stimuli including those that represent moving objects and natural scenes, and test hypotheses related to dynamic effects on visual sensitivity and sensory features generated by those amacrine cells 2) Use molecularly defined amacrine cells in the mouse to quantitatively characterize the functional contribution of specific amacrine cell types to specific stimuli including artificial moving objects and natural scenes. These studies create a new way to generate and test hypotheses related to the quantitative effect of any interneuron on retinal output under any visual stimulus. Understanding how retinal circuitry creates visual processing under natural scenes is critical to our understanding of retinal mechanisms and diseases involving the degeneration of the retinal circuitry. In addition, the computational descriptions of retinal responses will be directly useful in the design of electronic retinal prosthesis systems. The retina is a complex network of many cell types, including the most diverse but poorlyunderstood class of cells, amacrine cells. By understanding how inhibitory neurons change neural processing in the retina under natural visual scenes, we can begin to address how these cells and their connections degenerate during retinal diseases, an essential step in designing treatments for these diseases. Furthermore, by creating accurate computational models of the retinal response to natural scenes, this research will be immediately applicable to electronic retinal prosthesis systems that aim to restore vision in cases of photoreceptor degeneration.",Function and circuitry of adaptive inhibition in the retina,10086475,R01EY022933,"['Address', 'Amacrine Cells', 'Archives', 'Cells', 'Complex', 'Computer Models', 'Data', 'Disease', 'Electrophysiology (science)', 'Face', 'Feedback', 'Future', 'Goals', 'Injections', 'Interneurons', 'Lateral', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Molecular', 'Motion', 'Mus', 'Nervous system structure', 'Neural Network Simulation', 'Neurons', 'Optic Nerve', 'Optical Methods', 'Output', 'Pathway interactions', 'Periodicity', 'Population', 'Process', 'Property', 'Research', 'Retina', 'Retinal Degeneration', 'Retinal Diseases', 'Retinal Ganglion Cells', 'Salamander', 'Sensory', 'Signal Transduction', 'Spottings', 'Stereotyping', 'Stimulus', 'Structure', 'Synapses', 'System', 'Techniques', 'Testing', 'Theoretical Studies', 'Time', 'Vision', 'Visual', 'Visual system structure', 'biological systems', 'cell type', 'clinically relevant', 'computerized tools', 'computing resources', 'connectome', 'convolutional neural network', 'design', 'experimental study', 'extracellular', 'ganglion cell', 'inhibitory neuron', 'interest', 'neural circuit', 'novel strategies', 'photoreceptor degeneration', 'predicting response', 'receptive field', 'relating to nervous system', 'response', 'retinal prosthesis', 'sight restoration', 'therapy design', 'tool', 'visual processing', 'visual stimulus']",NEI,STANFORD UNIVERSITY,R01,2021,380427
"Access to parietal action representations after stroke lesions in visual cortex PROJECT SUMMARY  The ability to recognize and use objects according to their function (e.g., fork, hammer, pencil) requires integration of visual, semantic and action knowledge across occipital, temporal and parietal areas. Left parietal regions support critical aspects of object-directed action, such as grasping and object manipulation. This research activity uses a combination of fMRI and behavioral measures in patients with ischemic strokes to early and extrastriate visual areas to test the following hypotheses: Aim 1: There is a visual pathway to the parietal grasp region (aIPS) that bypasses processing in primary visual cortex. Aim 2: Left ventral extrastriate cortex is necessary to access manipulation information for visually presented objects. Aim 3A: Ballistic grasping actions to objects in the hemianopic field are influenced by volumetric properties (size, orientation) of targets. Aim 3B: Left ventral extrastriate lesions impair object function (e.g., `scissors used to cut') and disrupt access to manipulation knowledge from visual input. The research leverages strengths of fMRI (whole brain correlational measure) and neuropsychology (causal inference) to test new hypotheses about vision and action.  `Tools' (i.e., small manipulable objects) are an excellent domain in which to address broader questions about the integration of sensory, motor and cognitive processing. This is because tool recognition and tool use require the integration of distinct sensory, motor and cognitive representations, and the neural substrates of tool processing are well described. The research program emphasizes fresh perspectives on longstanding ideas about the dorsal and ventral visual pathways, by a) undertaking the first systematic investigation of the types of information about objects that are extracted by visual pathways that bypass primary visual cortex, and by b) studying how some parietal areas depend on inputs from the ventral stream in order to access the correct action for a given object. The research activity innovates by testing hypotheses about how lesions at different stages in the cortical visual hierarchy affect downstream processing in parietal cortex, combining neural and behavioral measures to study brain damaged patients (generating causal evidence), and by combining univariate and multivariate measures to `read out' the information content of brain regions (parietal cortex) that are anatomically remote from a lesion. The research advances understanding of how lesions in one brain region disrupt computations in other parts of the brain that depend on the damaged region for their inputs, a phenomenon (`dynamic diaschisis') that applies to brain injury generally. Advancing understanding of these basic issues using causal data has broad implications for understanding how the brain selects the correct action for the correct object, and more generally for theories of conceptual organization and causal reasoning. Understanding how the brain accesses actions from visual input has implications for related fields, such as robotics, neuroprosthetics, and evidenced based approaches for rehabilitating function after brain injury. Project Narrative Functional MRI and behavioral testing are used to test hypotheses about how strokes affecting occipital and temporal cortex disrupt access to action representations in parietal cortex. This research will advance understanding of how the brain processes visual information in support of everyday actions.",Access to parietal action representations after stroke lesions in visual cortex,10130533,R01EY028535,"['Address', 'Affect', 'Alexia', 'Anatomy', 'Area', 'Ballistics', 'Behavioral Assay', 'Brain', 'Brain Injuries', 'Brain region', 'Bypass', 'Cognitive', 'Data', 'Dorsal', 'Eating', 'Face', 'Functional Magnetic Resonance Imaging', 'Goals', 'Grain', 'Imaging Device', 'Impairment', 'Investigation', 'Ischemic Stroke', 'Knowledge', 'Left', 'Lesion', 'Literature', 'Location', 'Machine Learning', 'Measures', 'Methods', 'Modeling', 'Motor', 'Neural Pathways', 'Neuropsychology', 'Occipital lobe', 'Parahippocampal Gyrus', 'Parietal', 'Parietal Lobe', 'Participant', 'Pathway interactions', 'Patients', 'Population', 'Process', 'Property', 'Prosopagnosia', 'Reading', 'Research', 'Research Activity', 'Robotics', 'Role', 'Semantics', 'Sensory', 'Stimulus', 'Stream', 'Stroke', 'Structure of supramarginal gyrus', 'Temporal Lobe', 'Testing', 'Vision', 'Visual', 'Visual Cortex', 'Visual Fields', 'Visual Pathways', 'Visual system structure', 'Work', 'area striata', 'base', 'behavior measurement', 'behavior test', 'blind', 'cognitive development', 'evidence base', 'extrastriate', 'extrastriate visual cortex', 'fovea centralis', 'grasp', 'information processing', 'innovation', 'lens', 'multisensory', 'neuroprosthesis', 'post stroke', 'programs', 'relating to nervous system', 'sensory integration', 'theories', 'tool', 'visual information', 'visual motor', 'visual object processing', 'visual process', 'visual processing']",NEI,CARNEGIE-MELLON UNIVERSITY,R01,2021,410316
"Imaging Functional Connectivity in Visual Cortex The mammalian visual cortex is critical for vision and has been used as a model for the rest of the cerebral cortex. In spite of this, little is known about the detailed operations of its microcircuits. In fact, the cortex is composed of many different cell types, and, it is likely that each cell type has a particular circuit function.  In the past cycle we focused on four major subtypes of cortical GABAergic interneurons (PV, SOM, VIP and chandeliers) in mouse visual cortex, using two- photon photoactivation and transgenic mice to map connections to and from interneurons in a systematic fashion. We found that interneurons often make synaptic connections with every single neighboring cell, and this promiscuity could be an important feature of the cortical inhibitory “circuit blueprint”.  In the course of these experiments we unexpectedly discovered that groups of coactive neurons, which we termed “neuronal ensembles”, account for the majority of the cortical response to visual stimuli. Moreover, ensembles also dominate spontaneous activity and have distinct spatiotemporal characteristics. Further, using two-photon optogenetics we found by chance that ensembles can be artificially imprinted into the cortex and they can be recalled by stimulating individual neurons, showing pattern completion, even days after imprinting. These intriguing results suggest that ensembles could be multicellular building blocks of cortical function, implementing a population neural code.  To pursue this discovery and test these ideas we now propose an experimental “deep dive” into the properties of these ensembles, in order to characterize their basic phenomenology, understand their synaptic circuit mechanisms and test their role in the behavior of the animal in sensory discrimination. The project will be carried out in primary visual cortex of awake behaving mice and make use of a novel two-photon holographic microscopy method that enables us to image and optically manipulate neurons in different cortical layers simultaneously.  Our work will provide a systematic anatomical and functional description of neuronal ensembles, how they regulate the activity of the cortex and how they can be manipulated and reconfigured. This could help in novel therapeutic strategies by reconfiguring pathological circuits and correct visual deficits. Imaging Functional Connectivity in Visual Cortex The role of coordinated neuronal activity by groups of neurons in the visual cortex is still poorly understood. In the last cycle of the grant we discovered that one can reconfigure cortical activity in mouse visual cortex using optogenetics, by imprinting and recalling artificial activity patterns, and we now propose to understand how these patterns are build and whether their manipulation can lead to changes in behavior. This work could help to understand how neural circuits in the visual cortex operate and can be altered and also help to design novel strategies to ameliorate amblyopia and cortical cerebral visual impairment by reconfiguring abnormal circuits.  ",Imaging Functional Connectivity in Visual Cortex,10169447,R01EY011787,"['3-Dimensional', 'Amblyopia', 'Anatomy', 'Animal Behavior', 'Animals', 'Behavior', 'Behavioral', 'Brain', 'Cells', 'Cerebral cortex', 'Characteristics', 'Child', 'Code', 'Computational algorithm', 'Discrimination', 'Disease', 'Electrophysiology (science)', 'Epidemic', 'Generations', 'Goals', 'Grant', 'Image', 'In Vitro', 'Individual', 'Injury', 'Interneurons', 'Lead', 'Machine Learning', 'Maps', 'Mediating', 'Methods', 'Microscopy', 'Modeling', 'Morphology', 'Mus', 'Neocortex', 'Neurons', 'Optical Methods', 'Optics', 'Outcome', 'Pathologic', 'Pattern', 'Perceptual learning', 'Population', 'Premature Infant', 'Preparation', 'Process', 'Property', 'Research', 'Research Personnel', 'Rest', 'Role', 'Slice', 'Structure', 'Synapses', 'Synaptic plasticity', 'Techniques', 'Testing', 'Three-Dimensional Imaging', 'Time', 'Transgenic Mice', 'Vision', 'Visual', 'Visual Cortex', 'Work', 'area striata', 'awake', 'cell type', 'cortical visual impairment', 'design', 'developmental plasticity', 'excitatory neuron', 'experimental study', 'imprint', 'in vivo', 'mouse genetics', 'nerve supply', 'neural circuit', 'neural network', 'novel', 'novel strategies', 'novel therapeutic intervention', 'novel therapeutics', 'operation', 'optogenetics', 'phenomenological models', 'photoactivation', 'programs', 'relating to nervous system', 'response', 'sensory discrimination', 'spatiotemporal', 'two-photon', 'visual stimulus']",NEI,COLUMBIA UNIV NEW YORK MORNINGSIDE,R01,2021,384357
"Sound encoding by neural populations in auditory cortex during behavior Project Summary Throughout life, humans and other animals adapt their hearing to perceive features of sound that are important for successful behavioral decisions. Normal-hearing humans are able to detect and discriminate important sounds in crowded noisy scenes and to understand the speech of individuals the first time they meet. However, patients with peripheral hearing loss or central processing disorders often have problems hearing in these challenging settings. Even when they can perceive sounds accurately, the additional listening effort required negatively impacts other cognitive functions. A better understanding of how the healthy auditory system operates in cognitively challenging contexts will support new treatments for these deficits. This project will study how the auditory system represents sound information as it operates in challenging acoustic environments. There are three specific aims. First, high-density microelectrode arrays will be used to record the simultaneous activity of neural populations in auditory cortex during behaviors that require detecting sounds masked by noise or learning new sound-reward associations. Recording from multiple neurons will enable characterizing how information is encoded by the simultaneous activity of neural populations. These experiments will test the hypothesis that population activity in auditory cortex generates representations that are invariant to irrelevant distracting sounds. Second, optogenetic tools will be used to identify distinct neuronal cell types (excitatory versus inhibitory) in cortex. This study will test the hypothesis that tonic activation of inhibitory neurons can explain changes in population activity during behavior. Third, machine learning tools will be used to model the simultaneously recorded neural activity. These experiments will test the hypothesis that neurons in the same local anatomical circuit in auditory cortex encode information about a relatively small domain in the space of all possible auditory stimuli. Models fit to experimental data will also describe how changes in behavioral state shift the way neurons encode sounds and describe sources of correlated population activity that impact neural discriminability during behavior. Together these experiments will establish new links between neural representation of sound and the cognitive processes that extract important information from sound for successful behavior. Project Narrative Patients with hearing impairment and central neurological disorders have difficulty keeping track of speech and other complex sounds, particularly in challenging noisy environments. We seek to understand how populations of neurons in auditory cortex change their activity as the brain adapts to noisy environments. These experiments will provide insight into basic function of the healthy brain that can inform treatment of hearing disorders.",Sound encoding by neural populations in auditory cortex during behavior,10302718,R01DC014950,"['Acoustics', 'Affect', 'Anatomy', 'Animals', 'Area', 'Arousal', 'Attention', 'Auditory', 'Auditory Perception', 'Auditory Perceptual Disorders', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Brain', 'Categories', 'Code', 'Cognitive', 'Complex', 'Computer Models', 'Crowding', 'Data', 'Dimensions', 'Discrimination', 'Electrophysiology (science)', 'Enhancers', 'Environment', 'Ferrets', 'Frequencies', 'Hearing', 'Hearing problem', 'Human', 'Individual', 'Interneurons', 'Label', 'Lasers', 'Learning', 'Life', 'Link', 'Machine Learning', 'Masks', 'Measures', 'Mediating', 'Methods', 'Microelectrodes', 'Modeling', 'Monitor', 'Neurons', 'Noise', 'Operating System', 'Patients', 'Performance', 'Peripheral', 'Play', 'Population', 'Process', 'Property', 'Pupil', 'Reporting', 'Rewards', 'Role', 'Sensory', 'Shapes', 'Signal Transduction', 'Source', 'Speech', 'Stimulus', 'Testing', 'Time', 'Training', 'Virus', 'auditory processing', 'auditory stimulus', 'cell type', 'cognitive function', 'cognitive process', 'deep neural network', 'density', 'excitatory neuron', 'experimental study', 'flexibility', 'frontal lobe', 'hearing impairment', 'improved', 'indexing', 'inhibitory neuron', 'insight', 'machine learning method', 'nervous system disorder', 'neural model', 'neuromechanism', 'neurophysiology', 'new technology', 'normal hearing', 'novel', 'optogenetics', 'receptive field', 'relating to nervous system', 'sound', 'tool']",NIDCD,OREGON HEALTH & SCIENCE UNIVERSITY,R01,2021,320591
"Perceptual integration of luminance, texture and color cues for visual boundary segmentation Project Summary One of the most essential computations performed by the visual system is segmenting images into regions corresponding to distinct surfaces. This in turn requires identifying the boundaries separating image regions, a process known as boundary segmentation. Computational analyses of natural images have revealed that many visual cues are available at region boundaries, including differences in luminance, texture, and color. It is known that these cues combine for tasks like edge localization and orientation discrimination. However, it remains unclear how these various cues are weighted and combined for boundary segmentation.  In collaborative work with Canadian colleagues at McGill University in Montreal, we have developed a novel machine learning framework for characterizing human performance on boundary segmentation tasks using naturalistic micro-pattern stimuli. Our method makes use of the Filter-Rectify-Filter (FRF) model often applied to characterizing texture boundary segmentation. The major innovation of our approach is that we fit the FRF model directly to thousands of psychophysical stimulus-response observations to estimate its major defining parameters. We have recently applied this approach to investigating spatial strategies for contrast boundary segmentation and comparing competing hypotheses of how contrast modulation is integrated across orientation channels. In this grant, we propose to apply both classical psychophysical techniques and our novel machine learning methodology to understanding the computations employed to combine luminance, texture and color cues for segmentation.  In Aim 1, we focus on modeling segmentation of luminance-defined boundaries, comparing the case where each surface has uniform luminance, giving rise to a sharp edge (luminance step), to the more naturalistic case where the two surfaces have differing proportions of dark and light micro-patterns on either side of the boundary with no sharp edge (luminance texture). We will apply our machine learning methodology to test the hypothesis that different neural mechanisms may be involved in segmenting these two different kinds of luminance boundaries. In Aim 2, we ask how observers integrate first-order (luminance) and second-order (texture) cues for boundary segmentation, and if there are differences in cue combination strategies for luminance steps and luminance textures. We will also compare models embodying competing hypotheses of the underlying neural mechanisms of cue combination. In Aim 3, we extend the analyses in Aims 1 and 2 beyond simple luminance differences to include differences in color. Finally, Aim 4 is a pedagogical aim of promoting undergraduate research. Project Narrative Segmenting natural images into regions corresponding to distinct surfaces is an essential visual task, yet the underlying computations for boundary segmentation remain poorly understood. In this project, we will apply classical psychophysical techniques and our novel machine learning methodology to understand how multiple cues, including luminance, texture, and color, combine to enable boundary segmentation. We hope to develop and test computational models of boundary segmentation, with the ultimate goal of gaining insight into the underlying neural mechanisms employed for this essential natural vision task.","Perceptual integration of luminance, texture and color cues for visual boundary segmentation",10201916,R15EY032732,"['Address', 'Biological', 'Color', 'Computational Biology', 'Computer Analysis', 'Computer Models', 'Cues', 'Data', 'Discrimination', 'Educational process of instructing', 'Environment', 'Goals', 'Grant', 'Human', 'Image', 'Journals', 'Laboratories', 'Light', 'Literature', 'Machine Learning', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Pattern', 'Performance', 'Positioning Attribute', 'Process', 'Psychophysics', 'Publications', 'Research', 'Response to stimulus physiology', 'Series', 'Side', 'Source', 'Stimulus', 'Surface', 'Techniques', 'Testing', 'Texture', 'Universities', 'Vision', 'Vision research', 'Visual', 'Visual system structure', 'Work', 'computer studies', 'experience', 'innovation', 'insight', 'interest', 'laboratory curriculum', 'luminance', 'neuromechanism', 'neurophysiology', 'novel', 'pedagogy', 'undergraduate research', 'undergraduate student', 'vision science']",NEI,FLORIDA GULF COAST UNIVERSITY,R15,2021,374345
"Mechanisms of attentional control: Structure and dynamics from simultaneous EEG-fMRI and machine learning PROJECT SUMMARY/ABSTRACT Selective attention is an essential cognitive ability that permits us to effectively process and act upon relevant information while ignoring distracting events. A network involving frontal and parietal cortex for top-down attentional control, referred to as the Dorsal Attention Network (DAN), is active during both spatial and non- spatial (feature-based) attention. However, we know very little about the fine structure of attentional control activity in the DAN, how this structure changes to represent different to-be-attended stimulus features, how the connectivity within the DAN, and between the DAN and sensory cortex shifts when attending different features, or how these top-down processes and their influence in sensory cortex unfold over time. This gap in our knowledge is a critical problem for our models and theories of attention, and because attentional deficits are involved in a wide variety of neuropsychiatric disorders including autism, attention deficit disorder, dementia, and schizophrenia. The working model guiding this research is that top-down attentional control, based on different to-be-attended stimulus attributes, is guided by a smaller-scale neural fine structure within the DAN and prefrontal cortex that makes specific connections with specialized areas of visual cortex coding the attended attributes. Moreover, the time course of activity within the DAN in relation to that in sensory cortex follows a top-down cascading model, being earliest in frontal, then parietal cortex, and finally sensory cortex for preparatory, voluntary, attentional control. To identify the functional networks for attentional control for different forms of attention, and to define their time courses, this project uses innovative simultaneous recording of electroencephalographic (EEG) and functional magnetic resonance imaging (fMRI) data. Advanced signal processing and modeling, including multivariate pattern analysis (MVPA), graph theoretic connectivity analysis, and Granger causality analysis will be used to reveal the fine functional anatomy and time course of attentional control and selection. The project includes three experiments that vary the to-be-attended stimulus attributes from spatial location to stimulus features (color and motion), and pursues three aims. Aim 1 is to reveal the fine structure of top-down preparatory attentional control for different to-be-attended stimulus features. Aim 2 is to elucidate the specific connectivity between fine structures for preparatory attentional control in the DAN and their target sensory structures in sensory cortex. Aim 3 is to reveal the time course of top-down attentional control for different to-be-attended stimulus attributes. PROJECT NARRATIVE The capacity to focus attention is at the core of human mental functioning, and therefore, elucidating the neural bases of attention remains a central challenge for neuroscience, representing an essential aim in translational efforts to ameliorate attentional deficits in a wide variety of neuropsychiatric disorders including autism, attention deficit disorder, dementia, and schizophrenia.",Mechanisms of attentional control: Structure and dynamics from simultaneous EEG-fMRI and machine learning,10115818,R01MH117991,"['Anatomy', 'Attention', 'Attention Deficit Disorder', 'Attentional deficit', 'Brain', 'Code', 'Color', 'Cues', 'Data', 'Dementia', 'Discrimination', 'Dorsal', 'Etiology', 'Event', 'Face', 'Functional Magnetic Resonance Imaging', 'Graph', 'Human', 'Inferior', 'Knowledge', 'Location', 'Machine Learning', 'Modeling', 'Motion', 'Neurosciences', 'Parietal Lobe', 'Pattern', 'Perception', 'Physiological', 'Prefrontal Cortex', 'Process', 'Property', 'Research', 'Schizophrenia', 'Sensory', 'Specific qualifier value', 'Specificity', 'Stimulus', 'Structure', 'Testing', 'Time', 'Visual', 'Visual Cortex', 'Work', 'attentional control', 'autism spectrum disorder', 'base', 'cognitive ability', 'data integration', 'experimental study', 'extrastriate visual cortex', 'frontal lobe', 'indexing', 'innovation', 'mental function', 'neuropsychiatric disorder', 'predictive modeling', 'relating to nervous system', 'selective attention', 'sensory cortex', 'signal processing', 'theories', 'tool']",NIMH,UNIVERSITY OF CALIFORNIA AT DAVIS,R01,2021,530307
"Neural mechanisms of active vision in the fovea Neural mechanisms of active vision in the fovea In many ways human vision is like a camera, with a lens that forms an image on a spatially arranged sensor (the retina). However, it is unlike a camera because the sensor has uneven sampling and is constantly moving with the eyes. Recent behavioral and theoretical work suggest these eye movements serve a faciliatory role in high acuity vision – where the eye movements are part of the computations and enhance spatial resolution. However, the neurophysiological mechanisms to support this facilitation remain unknown. More broadly, little is known about the neural mechanisms that integrate across the retinal motion generated by eye movements, especially in the central visual field (the fovea). This is particularly important because over 8 million Americans suffer from central vision loss due to retinal disorders. Even if the retinal signals could be repaired, it is imperative to understand how the brain reads out foveal signals to ensure recovery of high-acuity visual processing, and fixational eye movements are a part of that process. The proposed career development plan aims to address these questions by measuring visual processing in the foveal representation of primary visual cortex (V1) during natural visual behavior. This proposal uses custom high-resolution eye-tracking, a novel visual foraging paradigm, largescale neurophysiology, and state-of-the-art machine learning to make these measurements possible. The proposed research will not only generate fundamental understanding of how eye-movements facilitate visual processing, but also will integrate the experimental and theoretical tools required to support neurophysiological studies of active visual processing without a loss of rigor or detail. The candidate has extensive expertise in awake- behaving neurophysiology and computational modeling and the training plan is designed to support his further training in statistical modeling, high-resolution eye-tracking, and modern machine-learning techniques for analyzing neural population data. The primary mentor, Dr. Daniel Butts, is a world expert in statistical models of neural activity during active vision; Co-mentor, Dr. Michele Rucci, is a world leader in high-resolution eye tracking and theoretical approaches to active vision; and Co-mentor, Dr. Jude Mitchell, is a pioneer in establishing the marmoset model of visual neuroscience and an expert in neurophysiology of visual attention. Together, they will provide the guidance to establish the candidate’s transition to a successful independent research career. The goal of this proposal is to identify the impact of fixational eye movements on neural representations in visual cortex in the central visual field. Over 9 million Americans have central vision loss from age-related macular degeneration. Results from this proposal will build a fundamental understanding of how retinal signals from the fovea are processed by visual cortex during natural visual behavior.",Neural mechanisms of active vision in the fovea,10106203,K99EY032179,"['Address', 'Age related macular degeneration', 'American', 'Behavior', 'Behavioral', 'Blindness', 'Brain', 'Callithrix', 'Code', 'Cognitive', 'Computer Models', 'Custom', 'Data', 'Data Set', 'Development', 'Development Plans', 'Disease', 'Ensure', 'Esthesia', 'Eye', 'Eye Movements', 'Foundations', 'Frequencies', 'Funding', 'Goals', 'Grant', 'Human', 'Image', 'Laboratories', 'Machine Learning', 'Measurement', 'Measures', 'Mentors', 'Modeling', 'Modernization', 'Monkeys', 'Motion', 'Neurons', 'Outcome', 'Peripheral', 'Phase', 'Physiology', 'Population', 'Positioning Attribute', 'Primates', 'Process', 'Recovery', 'Research', 'Resolution', 'Retina', 'Retinal Diseases', 'Role', 'Saccades', 'Sampling', 'Series', 'Signal Transduction', 'Statistical Models', 'Stream', 'System', 'Techniques', 'Testing', 'Training', 'Universities', 'V1 neuron', 'V4 neuron', 'Vision', 'Visual', 'Visual Acuity', 'Visual Cortex', 'Visual Fields', 'Visual Pathways', 'Visual attention', 'Work', 'active vision', 'area striata', 'awake', 'base', 'career', 'career development', 'central visual field', 'computerized tools', 'design', 'extrastriate', 'extrastriate visual cortex', 'flexibility', 'fovea centralis', 'interest', 'lens', 'neural model', 'neuromechanism', 'neurophysiology', 'new technology', 'novel', 'professor', 'receptive field', 'relating to nervous system', 'repaired', 'response', 'retinal imaging', 'sample fixation', 'sensor', 'skills', 'spatial vision', 'spatiotemporal', 'statistics', 'tool', 'visual information', 'visual neuroscience', 'visual process', 'visual processing', 'visual tracking']",NEI,"UNIV OF MARYLAND, COLLEGE PARK",K99,2021,116969
"Motor Modulation of Auditory Processing Project Summary Vocal communication depends on distinguishing our own vocal sounds (vocal feedback) from other sounds. Vocal motor-related corollary discharge (vocal CD) signals that suppress auditory responses to predictable vocal feedback help make this distinction. Notably, vocal CD signals in the human auditory cortex are especially important to speech and their dysfunction is thought to cause auditory hallucinations. Despite the key roles postulated for vocal CD signals, the challenges of monitoring and manipulating their activity in vocalizing animals has prevented systematic analyses. The long-term objective of this application is to understand with synaptic, cellular, and circuit resolution how vocal CD signals modulate auditory cortical responses to vocal feedback, detailed knowledge of which is essential to understand adaptive and maladaptive aspects of audition. We will gain detailed knowledge of synaptic, cellular, and circuit mechanisms underlying this process by studying the mouse, the vertebrate most suited to advanced genetic, electrophysiological, and optical tools. In the prior funding period, we used these tools to advance our understanding the synaptic and circuit mechanisms by which movement-related CD signals modulate auditory cortical activity. These advances included mapping a motor to auditory cortical circuit, determining that various head and body movements activate this pathway to suppress auditory cortical responses to sounds, and showing that this pathway can “learn” to selectively suppress sounds that are predictably yoked to locomotor movements. We also observed auditory cortical suppression in vocalizing male mice, but vocalization occurred during female courtship and was always accompanied by other movements, as well as by social and sexual stimuli. Therefore, whether vocalization-specific CD signals modulate the auditory cortex and suppress predictable vocal feedback remain unknown. Fortunately, we also developed methods for optogenetically gating ultrasonic vocalizations (USVs) and for distorting vocal feedback in the isolated, head-fixed mouse. Here we propose to combine these methods with other state of the art techniques, including multi-electrode arrays, in vivo multiphoton imaging, controlled manipulation of vocalization-related auditory feedback, and novel computational methods for voco-acoustic analysis. In the first Aim, we will test the idea that vocalization suppresses auditory cortical activity and use machine learning methods to rigorously quantify and compare spontaneous and optogenetically-evoked USVs. In the second Aim, we will isolate cortical contributions to the vocal modulation of auditory cortical activity. In the third Aim, we will distort vocal feedback to determine if vocal suppression of the auditory cortex is predictive, and use computational methods to systematically quantify vocal distortion. Together, these Aims will provide novel insights into the synaptic, cellular, and circuit mechanisms by which vocal CD signals influence auditory cortical processing. Project Narrative Normal hearing depends on the brain’s ability to anticipate and suppress responses to self-generated vocal sounds, while impaired suppression generates auditory hallucinations. We aim to show how vocal motor signals suppress auditory activity in the brain, thus informing how hearing works in health and disease.",Motor Modulation of Auditory Processing,10121250,R01DC013826,"['Acoustics', 'Address', 'Animals', 'Arousal', 'Auditory', 'Auditory Hallucination', 'Auditory area', 'Auditory system', 'Behavior', 'Behavioral', 'Bone Conduction', 'Brain', 'Cells', 'Communication', 'Complex', 'Computing Methodologies', 'Courtship', 'Disease', 'Electrodes', 'Electrophysiology (science)', 'Feedback', 'Female', 'Functional disorder', 'Funding', 'Genetic', 'Goals', 'Grant', 'Head', 'Head Movements', 'Health', 'Hearing', 'Human', 'Image', 'Impairment', 'Interneurons', 'Knowledge', 'Learning', 'Locomotion', 'Maps', 'Measures', 'Methods', 'Monitor', 'Monkeys', 'Motor', 'Movement', 'Mus', 'Neurons', 'Optical Methods', 'Optics', 'Pathway interactions', 'Physiological', 'Process', 'Production', 'Property', 'Pyramidal Cells', 'Resolution', 'Signal Transduction', 'Social Environment', 'Speech', 'Stimulus', 'Synapses', 'Techniques', 'Testing', 'Thalamic structure', 'Time', 'Ultrasonics', 'Variant', 'Work', 'auditory feedback', 'auditory processing', 'auditory stimulus', 'autoencoder', 'deaf', 'excitatory neuron', 'experience', 'experimental study', 'flexibility', 'in vivo', 'inhibitory neuron', 'insight', 'machine learning method', 'male', 'multi-electrode arrays', 'multiphoton imaging', 'neural circuit', 'normal hearing', 'novel', 'optogenetics', 'prevent', 'response', 'social', 'sound', 'tool', 'two-photon', 'unsupervised learning', 'vocalization']",NIDCD,DUKE UNIVERSITY,R01,2021,429899
