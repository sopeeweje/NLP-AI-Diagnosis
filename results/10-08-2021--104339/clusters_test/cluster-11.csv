text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Temporal relation discovery for clinical text Project Summary / Abstract The current proposal continues the investigation on the topic of temporal relation extraction from the Electronic Medical Records (EMR) clinical narrative funded by the NLM since 2010 (Temporal Histories of Your Medical Events, or THYME; thyme.healthnlp.org). Through our efforts so far, we have defined the topic as an active area of research attracting attention across the world. Since its inception, the project has pushed the boundaries of this highly challenging task by investigating new computational methods within the context of the latest developments in the fields of natural language processing (NLP), machine learning (ML), artificial intelligence (AI) and biomedical informatics (BMI) resulting in 60+ publications/presentations. We have made our best performing methods available to the community open source as part of the Apache Clinical Text Analysis and Knowledge Extraction System (cTAKES; ctakes.apache.org). In 2015, 2016, 2017 and 2018, we organized an international shared task (Clinical TempEval) on the topic under the umbrella of the highly prestigious SemEval, thus inviting the international community to work with our THYME data and improve on our results. Clinical TempEval has been highly successful with many participants each year, resulting in new discoveries and many publications. We have made all our data along with our gold standard annotations available to the community through the hNLP Center (center.healthnlp.org).  The underlying theme of this renewal is novel methods for combining explicit domain knowledge (linguistic, semantic, biomedical ontological, clinical), readily available unlabeled data (health-related social media, EMRs), and modern machine learning techniques (e.g. neural networks) for temporal relation extraction from the EMR clinical narrative. Therefore, our renewal proposes a novel and much needed exploration of this line of research:  Specific Aim 1: Develop computational models for novel rich semantic representations such as the Abstract Meaning Representations to encapsulate a single, coherent, full-document graphical representation of meaning for temporal relation extraction  Specific Aim 2: Develop computational methods to infuse domain knowledge (linguistic, semantic, biomedical ontological, clinical) into modern machine learning techniques such as NNs for temporal relation extraction – through input representations, pre-trained vectors, or architectures  Specific Aim 3: Develop novel methods for combining labeled and unlabeled data from various sources (EMR, health-related social media, newswire) for temporal relation extraction from the clinical narrative  Specific Aim 4: Apply the best performing methods for temporal relation extraction developed in SA1-3 to temporally sensitive phenotypes for direct translational sciences studies. Dissemination efforts through publications and open source releases into Apache cTAKES. Project Narrative Temporal relations are of prime importance in biomedicine as they are intrinsically linked to diseases, signs and symptoms, and treatments. Understanding the timeline of clinically relevant events is key to the next generation of translational research where the importance of generalizing over large amounts of data holds the promise of deciphering biomedical puzzles. The goal of our current proposal is to automatically discover temporal relations from clinical free text and structured EMR data and create an aggregated patient-level timeline.",Temporal relation discovery for clinical text,10176589,R01LM010090,"['Address', 'Apache', 'Architecture', 'Area', 'Artificial Intelligence', 'Attention', 'Clinical', 'Cognitive', 'Communities', 'Complex', 'Computer Models', 'Computerized Medical Record', 'Computing Methodologies', 'Coupled', 'Data', 'Development', 'Disease', 'Encapsulated', 'Engineering', 'Event', 'Fostering', 'Foundations', 'Funding', 'Goals', 'Gold', 'Health', 'Image', 'International', 'Investigation', 'Knowledge', 'Knowledge Extraction', 'Label', 'Linguistics', 'Link', 'Machine Learning', 'Medical', 'Methods', 'Modernization', 'Natural Language Processing', 'Nature', 'Participant', 'Patient Care', 'Patients', 'Phenotype', 'Publications', 'Recording of previous events', 'Research', 'Semantics', 'Signs and Symptoms', 'Solid', 'Source', 'Speed', 'Structure', 'System', 'Techniques', 'Text', 'Thyme', 'Time', 'TimeLine', 'Training', 'Translational Research', 'Vision', 'Work', 'advanced disease', 'base', 'biomedical informatics', 'biomedical ontology', 'clinically relevant', 'cohesion', 'electronic data', 'electronic structure', 'epidemiology study', 'improved', 'individualized medicine', 'learning community', 'neural network', 'next generation', 'novel', 'open source', 'programs', 'relating to nervous system', 'social media', 'support vector machine', 'symptom treatment', 'vector']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,531398
"CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare Project Summary Wide adoption of electronic health records (EHRs) has led to huge clinical databases, which enable the rapid growth of healthcare analytics market. One particular challenge for analyzing EHRs data is that much detailed patient information is embedded in clinical documents and not directly available for downstream analysis. Therefore, clinical natural language processing (NLP) technologies, which can unlock information embedded in clinical narratives, have received great attention, with an estimated global market of $2.65 billion by 2021 . In our previous work, we have developed CLAMP (Clinical Language Annotation, Modeling, and Processing), a clinical NLP tool with demonstrated superior performance through multiple international NLP challenges and a large user community (over 1,500 downloads by users from over 700 organizations). Commercialization of CLAMP by Melax Technologies Inc. has been successful (i.e., with a dozen licensed customers now); but it also reveals its limitations as a desktop application in the Cloud era. Therefore, we propose to extend CLAMP to a new Cloud- based, Service-oriented platform (called CLAMP-CS), which will address the identified challenges by: 1) improving clinical NLP performance and reducing annotation cost by leveraging the state-of-the-art algorithms such as deep learning, active learning and transfer learning and making them accessible to less experienced users; 2) following new service-oriented architectures to make CLAMP-CS available via SaaS and PaaS, ready for Cloud-based development and deployment; and 3) improving CLAMP-CS interoperability with downstream applications following two widely used standard representations: HL7 FHIR (Fast Healthcare Interoperability Resources) and OMOP CMD (Common Data Model), to support the use cases in clinical operations and research respectively. With these advanced features, we believe CLAMP-CS will be a leading clinical NLP system in the market and it will accelerate the adoption of NLP technology for diverse healthcare applications and clinical/translational research. Project Narrative In this study, we plan to develop a new clinical natural language processing (NLP) tool based on the existing widely used CLAMP (Clinical Language Annotation, Modeling, and Processing) system, to support enterprise development and deployment of NLP solutions in healthcare. We believe that the new generation of Cloud- based, service-oriented NLP tool will accelerate the adoption of NLP technology for diverse healthcare applications and clinical and translational research.","CLAMP-CS: a Cloud-based, Service-oriented, high-performance Natural Language Processing Platform for Healthcare",10136739,R44TR003254,"['Active Learning', 'Address', 'Adopted', 'Adoption', 'Algorithms', 'Architecture', 'Attention', 'Belief', 'Clinical', 'Clinical Research', 'Closure by clamp', 'Cloud Computing', 'Communities', 'Custom', 'Data', 'Development', 'Diagnosis', 'Electronic Health Record', 'Environment', 'Fast Healthcare Interoperability Resources', 'Generations', 'Grant', 'Growth', 'Health Sciences', 'Healthcare', 'Hospital Administration', 'International', 'Language', 'Licensing', 'Machine Learning', 'Medical', 'Modeling', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Operations Research', 'Output', 'Patients', 'Performance', 'Psychological Transfer', 'Records', 'Research', 'Services', 'System', 'Technology', 'Texas', 'Time', 'Translational Research', 'Universities', 'Work', 'active method', 'base', 'clinical application', 'clinical database', 'cloud based', 'commercialization', 'cost', 'data modeling', 'deep learning', 'deep learning algorithm', 'experience', 'improved', 'insight', 'interoperability', 'language training', 'learning algorithm', 'model building', 'next generation', 'novel', 'prevent', 'rapid growth', 'tool', 'user-friendly', 'web app']",NCATS,"MELAX TECHNOLOGIES, INC.",R44,2021,496453
"Extended Methods and Software Development for Health NLP Project Summary Our program vision is to unravel the information buried in health-related narratives by advancing text-processing methods in a unified way across all the genres of health texts and distributing them through an advanced NLP software platform under solid governance and sustainability. The crosscutting theme is the investigation of methods for health NLP made possible by big data, fused with health knowledge. The underlying theme of this renewal is the development of methods towards generalizable, efficient and knowledge-rich models in the context of modern machine learning techniques, particularly models implementing attention mechanisms and using large unlabeled datasets. There is growing penetration of deep learning approaches in the field of health natural language processing. Our proposal aims to address critical methodological gaps and understudied areas in the current unprecedented fast-paced environment. Therefore, our renewal lays out novel and much needed explorations of health NLP research which we will advance through our specific aims. Our datasets will continue to span the spectrum of health-related data – Electronic Medical Records clinical narrative, patient-authored on- line community posts, and health-related social media. The evaluation of the methods we will develop will be performed on the key clinical tasks of concept extraction, relation extraction, and phenotyping with comparisons to other traditional or deep learning algorithms as baselines. We will demonstrate impact of our methods and tools through several use cases, ranging from clinical point of care to public health, to translational and precision medicine. Finally, we will disseminate our work through community activities to advance the state of the art in health natural language processing. Project Narrative There is a deluge of health texts. Natural Language Processing (NLP) holds much promise to unravel valuable information from these large data streams with the goal to advance medicine and the wellbeing of patients. We will advance state-of-the-art NLP by designing robust, scalable methods that leverage health big data, demonstrating relevance on high-impact use cases, and disseminating NLP tools for the research community and public at large.",Extended Methods and Software Development for Health NLP,10209178,R01GM114355,"['Address', 'Adult', 'Algorithms', 'Apache', 'Area', 'Attention', 'Big Data', 'Childhood', 'Clinical', 'Communities', 'Community Health', 'Computer software', 'Computerized Medical Record', 'Data', 'Data Set', 'Detection', 'Development', 'Environment', 'Evaluation', 'Foundations', 'Funding', 'Goals', 'Health', 'Healthcare', 'Information Retrieval', 'Institution', 'Investigation', 'Joints', 'Knowledge', 'Knowledge Extraction', 'Learning', 'Machine Learning', 'Manuals', 'Medical', 'Medicine', 'Methodology', 'Methods', 'Modeling', 'Modernization', 'Names', 'Natural Language Processing', 'Neural Network Simulation', 'Ontology', 'Patients', 'Penetration', 'Personal Satisfaction', 'Phenotype', 'Physicians', 'Public Health', 'Publications', 'Research', 'Risk', 'Solid', 'Source', 'Supervision', 'System', 'Techniques', 'Text', 'Time', 'Training', 'Training and Infrastructure', 'Uncertainty', 'Unified Medical Language System', 'Vision', 'Work', 'commercialization', 'data streams', 'deep learning', 'deep learning algorithm', 'design', 'electronic data', 'health data', 'health knowledge', 'insight', 'learning strategy', 'medical specialties', 'method development', 'multitask', 'neural network', 'novel', 'online community', 'open source', 'point of care', 'precision medicine', 'programs', 'social media', 'software development', 'structured data', 'tool', 'translational medicine']",NIGMS,BOSTON CHILDREN'S HOSPITAL,R01,2021,463346
"Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment Project Summary The purpose of this proposal is to develop two strategies, natural language processing (NLP) and automated speech analysis (ASA), to enable automated identification of patients with cognitive impairment (CI), from mild cognitive impairment (MCI) to Alzheimer’s Disease Related Dementias (ADRD) in clinical settings. The number of older adults in the United States with MCI and ADRD is increasing and yet the ability of clinicians and researchers to identify them at scale has advanced little over recent decades and screening with clinical assessments is done inconsistently. Alternative strategies using available data, like analysis of diagnostic codes in the clinical record or insurance claims, have very low sensitivity. NLP and ASA used with machine learning are technologies that could greatly increase ability to detect MCI and ADRD in clinical contexts. NLP automatically converts text in the electronic health record (EHR) into structured concepts suitable for analysis. Thus, clinicians’ documentation of signs and symptoms or orders of tests and services that reflect or address cognitive limitations can be efficiently captured, possibly long before the clinician uses an ADRD-related diagnostic code. ASA directly measures cognition by recognizing different features of cognition captured in speech. Extracting features through both NLP and ASA could thus provide a unique measure of cognition and its impact on the individual and their caregivers. Early detection of MCI and ADRD can help researchers identify appropriate patients for research and help clinicians and health systems target patients for preventive care and care coordination. For these reasons, more efficient, highly scalable strategies are needed to identify people with MCI and ADRD. The Specific Aims of this proposal are to (1) Develop and validate a ML algorithm using features extracted from the EHR with NLP to identify patients with CI, (2) Develop and validate a ML algorithm using features extracted from ASA of audio recordings of patient-provider encounters during routine primary care visits to identify patients with CI, (3) Develop and validate a ML algorithm using both NLP and ASA extracted features to create an integrated CI diagnostic algorithm. We will develop machine learning algorithms using NLP and ASA extracted features trained against neurocognitive assessment data on 800 primary care patients in New York City and validate them in an independent sample of 200 patients in Chicago. In secondary analyses we will train ML algorithms to identify MCI and its subtypes. This project will be the most rigorous development of NLP, ASA, and ML algorithms for CI yet performed, the first to test ASA in primary care settings, and the first to test NLP and ASA feature extraction strategies in combination. The multi-disciplinary team of clinicians, health services researchers, and neurocognitive and data scientists will apply machine learning to develop these highly scalable, automated technologies for identification of MCI and ADRD. 1 Project Narrative The ability of clinicians, health systems and researchers to identify patients with mild cognitive impairment (MCI) and Alzheimer’s Disease Related Dementias (ADRD) is limited. This project will apply machine learning to natural language processing (NLP) of electronic health record data and automated speech analysis (ASA) of patient-doctor conversations during primary care visits to identify patients with MCI and ADRD using automated and scalable procedures. The analytic algorithms will be developed with neurocognitive assessment data on 800 primary care patients in New York City and validated in an independent sample of 200 patients in Chicago. 1",Natural Language Processing and Automated Speech Recognition to Identify Older Adults with Cognitive Impairment,10144364,R01AG066471,"['Acoustics', 'Acute', 'Address', 'Algorithms', 'Alzheimer&apos', 's disease related dementia', 'Caregivers', 'Chicago', 'Clinical', 'Clinical assessments', 'Code', 'Cognition', 'Cognitive', 'Data', 'Data Analyses', 'Data Element', 'Data Scientist', 'Data Set', 'Development', 'Diagnosis', 'Diagnostic', 'Documentation', 'Early Diagnosis', 'Elderly', 'Electronic Health Record', 'Health Services', 'Health system', 'Impaired cognition', 'Individual', 'Insurance Carriers', 'Machine Learning', 'Measures', 'Mental disorders', 'Methods', 'Natural Language Processing', 'Neurocognitive', 'New York City', 'Parkinson Disease', 'Patient Care', 'Patients', 'Persons', 'Physicians', 'Population', 'Positioning Attribute', 'Preventive care', 'Primary Health Care', 'Procedures', 'Provider', 'Psychiatric Diagnosis', 'Reference Standards', 'Research', 'Research Personnel', 'Resource Allocation', 'Risk Factors', 'Sampling', 'Semantics', 'Sensitivity and Specificity', 'Services', 'Signs and Symptoms', 'Speech', 'Structure', 'Study Subject', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'United States', 'Validation', 'Visit', 'adverse event risk', 'aging population', 'automated speech recognition', 'base', 'care coordination', 'clinical encounter', 'cognitive function', 'cognitive testing', 'deep learning', 'demographics', 'electronic data', 'electronic structure', 'falls', 'feature extraction', 'financial incentive', 'health care settings', 'improved', 'insurance claims', 'learning classifier', 'machine learning algorithm', 'mental state', 'mild cognitive impairment', 'multidisciplinary', 'prevent', 'primary care setting', 'recruit', 'risk mitigation', 'screening', 'secondary analysis', 'structured data', 'success', 'testing services', 'tool', 'treatment choice', 'unstructured data']",NIA,ICAHN SCHOOL OF MEDICINE AT MOUNT SINAI,R01,2021,805312
"Fine-grained spatial information extraction for radiology reports ABSTRACT Automated biomedical image classification has seen enormous improvements in performance over recent years, particularly in radiology. However, the machine learning (ML) methods that have achieved this remarkable performance often require enormous amounts of labeled data for training. An increasingly accepted means of acquiring this data is through the use of natural language processing (NLP) on the free-text reports associated with an image For example, take the following brain MRI report snippet:  There is evidence of left parietal encephalomalacia consistent with known history of prior stroke. Small  focal area of hemosiderin deposition along the lateral margins of the left lateral ventricle. Here, the associated MRI could be labeled for both Encephalomalacia and Hemosiderin. NLP methods to automatically label images in this way have been used to create several large image classification datasets However, as this example demonstrates, radiology reports often contain far more granular information than prior NLP methods attempted to extract. Both findings in the above example mention their anatomical location, which linguistically is referred to as a spatial grounding, as the location anchors the finding in a spatial reference. Further, the encephalomalacia finding is connected to the related diagnosis of stroke, while the hemosiderin finding provides a morphological description (small focal area). This granular information is important for image classification, as advanced deep learning methods are capable of utilizing highly granular structured data. This is logical, as for instance a lung tumor has a slightly different presentation than a liver tumor. If an ML algorithm can leverage both the coarse information (the general presentation of a tumor) while also recognizing the subtle granular differences, it can find an optimal balance between specificity and generalizability. From an imaging perspective, this can also be seen as a middle ground between image-level labels (which are cheap but require significant data for training—a typical dataset has thousands of images or more) and segmentation (which is expensive to obtain, but provides better training data—a typical dataset has 40 to 200 images), as the fine-grained spatial labels correspond to natural anatomical segments. Our fundamental hypothesis in this project is that if granular information can be extracted from radiology reports with NLP, this will improve downstream radiological image classification when training on a sufficiently large dataset. For radiology, the primary form of granularity is spatial (location, shape, orientation, etc.), so this will be the focus of our efforts. We further hypothesize that these NLP techniques will be generalizable to most types of radiology reports. For the purpose of this R21-scale project, however, we will focus on three distinct types of reports with different challenges: chest X-rays (one of the most-studied and largest-scale image classification types), extremity X-rays (which offer different findings than chest X-rays), and brain MRIs (which present a different image modality and the additional complexity of three dimensions). NARRATIVE This project is interested in developing natural language processing (NLP) methods for better understanding the spatial relationships described in the free text data within radiology reports found in electronic health record (EHR) systems. We will (i) develop an ontology, (ii) manually create a dataset for training NLP methods, (iii) develop automatic NLP methods compatible the ontology and corpus, and (iv) evaluate automatic image classification methods that use the output of the NLP system as image labels.",Fine-grained spatial information extraction for radiology reports,10116379,R21EB029575,"['3-Dimensional', 'Address', 'Algorithms', 'Anatomy', 'Architecture', 'Area', 'Brain', 'Classification', 'Data', 'Data Set', 'Deposition', 'Devices', 'Diagnosis', 'Electronic Health Record', 'Encephalomalacia', 'Equilibrium', 'Goals', 'Grain', 'Hemosiderin', 'Human', 'Image', 'Information Retrieval', 'Label', 'Lateral', 'Left', 'Limb structure', 'Linguistics', 'Liver neoplasms', 'Location', 'Lung Neoplasms', 'Machine Learning', 'Magnetic Resonance Imaging', 'Manuals', 'Methods', 'Morphology', 'Natural Language Processing', 'Ontology', 'Output', 'Parietal', 'Performance', 'Radiology Specialty', 'Recording of previous events', 'Reporting', 'Research', 'Roentgen Rays', 'Shapes', 'Specificity', 'Stroke', 'System', 'Techniques', 'Text', 'Thoracic Radiography', 'Training', 'Trust', 'base', 'bioimaging', 'deep learning', 'design', 'imaging modality', 'improved', 'innovation', 'interest', 'large datasets', 'lateral ventricle', 'learning strategy', 'machine learning algorithm', 'machine learning method', 'radiological imaging', 'scale up', 'spatial relationship', 'structured data', 'tool', 'tumor']",NIBIB,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R21,2021,195000
"Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks Project Summary In this project we develop new methods for extracting important information from electronic health records based on recurrent neural networks. These methods represent the hierarchical and sequential nature of human language, leverage large scale datasets to make learning sophisticated representations possible, and make use of novel sources of supervision that are available at this scale. The model architecture we propose is a hierarchical recurrent neural network (RNN). This architecture explicitly represents temporality at multiple different time scales, with stacked RNN layers representing words, sentences, paragraphs, and documents. At the word level, the model is trained to predict important pieces of clinical information, such as negation and temporality, using existing labeled data sets. Training for clinical information extraction at the lowest level ensures that the higher-level models have a foundation of medically relevant inputs. We are still left with the challenge of training higher-level networks, because these models require massive amounts of labeled training data to learn. We solve this problem by taking advantage of the temporal aspect of information in an EHR, and having each higher-level recurrent layer train getting supervision from the future. For example, the document RNN is trained to predict billing codes and NLP concept codes that were found in the subsequent document. This source of supervision is scalable, and our preliminary data shows that it is effective at learning how to generate generalizable patient representations. The patient representations that our model learns are shareable across multiple tasks, potentially streamlining EHR-based research by eliminating what was previously a manual step – designing text-based variables to represent patients. We demonstrate a new workflow for text-based EHR research, showing how the same representations can be used for two completely distinct phenotyping tasks. These phenotyping studies make use of high-quality datasets of patients with pulmonary hypertension and autism spectrum disorder at Boston Children’s Hospital. PH is relatively rare, so finding every patient with a phenotyping algorithm is important for clinical research. ASD has several sub-phenotypes, and finding large numbers of patients from each sub- phenotype can help to better understand the mechanisms of ASD. Along with demonstrating the applicability of our representations on these specific clinical research use cases, we incorporate our patient representations into the i2b2 clinical research software, making them available to all clinical investigators using this platform at Boston Children’s Hospital. Project Narrative This project develops methods for extracting universal patient representations from unstructured text in electronic health records. These methods leverage huge amounts of clinical data, recurrent neural network architectures, and novel training techniques to incorporate information at multiple time scales. These methods are evaluated using public datasets to promote reproducibility, and applied to clinical research tasks that extend the knowledge of patients with pulmonary hypertension and autism spectrum disorder at Boston Children’s Hospital.",Learning Universal Patient Representations from Clinical Text with Hierarchical Recurrent Neural Networks,10085674,R01LM012973,"['Architecture', 'Boston', 'Brain', 'Childhood', 'Classification', 'Clinical', 'Clinical Data', 'Clinical Investigator', 'Clinical Research', 'Code', 'Computer software', 'Data', 'Data Set', 'Electronic Health Record', 'Ensure', 'Event', 'Face', 'Felis catus', 'Foundations', 'Future', 'Healthcare Systems', 'Human', 'Human Characteristics', 'Human Resources', 'Information Retrieval', 'Intensive Care Units', 'Israel', 'Knowledge', 'Label', 'Language', 'Learning', 'Left', 'Linguistics', 'Location', 'Logistic Regressions', 'Machine Learning', 'Manuals', 'Medical', 'Medical center', 'Methods', 'Modeling', 'Natural Language Processing', 'Neural Network Simulation', 'Patients', 'Pediatric Hospitals', 'Performance', 'Phenotype', 'Problem Solving', 'Process', 'Pulmonary Hypertension', 'Rare Diseases', 'Records', 'Recurrence', 'Reproducibility', 'Research', 'Research Personnel', 'Source', 'Statistical Methods', 'Supervision', 'System', 'Text', 'Time', 'Training', 'Training Technics', 'Uncertainty', 'autism spectrum disorder', 'base', 'clinically relevant', 'cohort', 'comorbidity', 'data resource', 'deep neural network', 'design', 'disease phenotype', 'large scale data', 'learning strategy', 'machine translation', 'neural network', 'neural network architecture', 'novel', 'phenotyping algorithm', 'recurrent neural network', 'relating to nervous system']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,366696
"Prediction of therapist cultural competency using Natural Language Processing (NLP) models PROJECT SUMMARY  Racial-ethnic minorities (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) individuals experience high levels of psychological distress. Psychological treatments can be effective in addressing mental health concerns, but disparities in quality of care still exist. Although systemic and institutional factors contribute to disparities in care, mental health providers are also critical to examine. A primary focus of efforts to understand and reduce provider contributions to mental health care disparities has been to examine cultural competency (CC), which involves a provider’s ability to navigate the cultural aspects of clinical interactions. Patient ratings of CC are generally associated with treatment outcomes and therapeutic processes. While patient perceptions of provider CC are important, a reliance on retrospective patient ratings limits what we know about how cultural identities are discussed, and the language that constitutes culturally sensitive care. Many studies of provider CC also require observers or patients to make complex judgments based on internal provider characteristics that are not reliably observable (e.g. rate provider awareness of their own cultural values). More studies are needed that examine patient-provider interactions in treatment in order to assess the impact of specific provider behaviors, and how they relate to perceptions of provider CC. Recently, Natural Language Processing (NLP) models have been applied to psychotherapy conversations to automatically capture the use of evidence based treatments, topics of conversation, empathy, and emotional expression. Prior research demonstrating the feasibility of automatically identifying topics of conversation in psychotherapy suggest that NLP models could be trained to automatically identify specific moments in sessions where patients and providers are talking about cultural issues. NLP models could allow researchers to not only examine how specific patterns of provider-patient interactions drive CC, but might also provide rapid feedback to providers, and in turn help address disparities in care. The purpose of the current study is to do the foundational work to develop and evaluate NLP tools that capture the cultural content of provider-patient interactions among REM and LGBTQ patients. First, utilizing 32,436 labeled talk turns from 200 psychotherapy sessions we will evaluate the accuracy of NLP models in recognizing the discussion of cultural topics in psychotherapy. Second, we will use NLP models to explore differences in the content of 1,235 psychotherapy sessions that were rated as highly positive or negative on a measure of cultural competence. PROJECT NARRATIVE Although disparities in the quality of mental health treatment for racial-ethnic minority (REM) and lesbian, gay, bisexual, transgender, and queer (LGBTQ) patients are well known, to date there are no tools that can identify specific patterns of provider-patient interactions that drive disparities in care. This project will evaluate the ability of Natural Language Processing (NLP) models to recognize discussion of cultural topics in psychotherapy among REM and LGBTQ patients, and explore differences in patient-provider interactions with low and high patient ratings of provider cultural competency.",Prediction of therapist cultural competency using Natural Language Processing (NLP) models,10126722,F31MD014941,"['Address', 'Alcohol or Other Drugs use', 'Anxiety', 'Awareness', 'Caring', 'Characteristics', 'Client', 'Clinical', 'Code', 'Complex', 'Computerized Medical Record', 'Data', 'Discrimination', 'Empathy', 'Evidence based treatment', 'Face', 'Feedback', 'Foundations', 'Funding', 'Goals', 'Grant', 'Health Personnel', 'Healthcare', 'Individual', 'Judgment', 'Label', 'Language', 'Lesbian Gay Bisexual Transgender Queer', 'Machine Learning', 'Measures', 'Mental Depression', 'Mental Health', 'Methods', 'Modeling', 'National Institute on Alcohol Abuse and Alcoholism', 'Natural Language Processing', 'Outcome', 'Patients', 'Pattern', 'Perception', 'Performance', 'Process', 'Provider', 'Psychotherapy', 'Quality of Care', 'Reporting', 'Research', 'Research Personnel', 'Suicide', 'Technology', 'Text', 'Therapeutic', 'Training', 'Treatment outcome', 'Work', 'base', 'commercial application', 'community setting', 'cultural competence', 'cultural values', 'disparity reduction', 'effective intervention', 'ethnic minority population', 'experience', 'health care disparity', 'improved', 'provider behavior', 'psychologic', 'psychological distress', 'racial and ethnic', 'sexual identity', 'showing emotion', 'substance abuse treatment', 'symptomatic improvement', 'tool', 'treatment disparity', 'university student', 'willingness']",NIMHD,UNIVERSITY OF UTAH,F31,2021,46036
"Semi-Automating Data Extraction for Systematic Reviews Summary ​Semi-Automating Data Extraction for Systematic Reviews (​Renewal) Evidence-based Medicine (EBM) aims to inform patient care using all available evidence. Realizing this aim in practice would require access to concise, comprehensive, and up-to-date structured summaries of the evidence relevant to a particular clinical question. Systematic reviews of biomedical literature aim to provide such summaries, and are a critical component of the EBM arsenal and modern medicine more generally. However, such reviews are extremely laborious to conduct. Furthermore, owing to the rapid expansion of the biomedical literature base, they tend to go out of date quickly as new evidence emerges. These factors hinder the practice of evidence-based care. In this renewal proposal, we seek to continue our ground-breaking efforts on developing, evaluating, and deploying novel machine learning (ML) and natural language processing (NLP) methods to automate or semi-automate the evidence synthesis process. This will extend our innovative and successful efforts developing RobotReviewer and related technologies under the current grant. Concretely, for this renewal we propose to move from extraction of clinically salient data elements from individual trials to synthesis of these elements across trials. Our first aim is to extend our ML and NLP models to produce (as one deliverable) a publicly available, continuously and automatically updated semi-structured evidence database, comprising extracted data for all evidence, both published and unpublished. Unpublished trials will be identified via trial registries. Taking this up-to-date evidence repository as a starting point, we then propose cutting-edge ML and NLP models that will generate first drafts of evidence syntheses, automatically. More specifically we propose novel neural cross-document summarization models that will capitalize on the semi-structured information automatically extracted by our existing models, in addition to article texts. These models will be deployed in a new version of RobotReviewer, called RobotReviewerLive, intended to be a prototype for “living” systematic reviews. To rigorously evaluate the practical utility of the proposed methodological innovations, we will pilot their use to support real, ongoing, exemplar living reviews. Semi-Automating Data Extraction for Systematic Reviews (​Renewal) Narrative We propose novel machine learning and natural language processing methods that will aid biomedical literature summarization and synthesis, and thereby support the conduct of evidence-based medicine (EBM). The proposed models and technologies will motivate core methodological innovations and support real-time, up-to-date, semi-automated biomedical evidence syntheses (“systematic reviews”). Such approaches are necessary if we are to have any hope of practicing evidence-based care in our era of information overload.",Semi-Automating Data Extraction for Systematic Reviews,10199049,R01LM012086,"['American', 'Automation', 'Caring', 'Clinical', 'Collection', 'Consumption', 'Data', 'Data Element', 'Databases', 'Development', 'Elements', 'Evaluation', 'Evidence Based Medicine', 'Evidence based practice', 'Feedback', 'Grant', 'Hybrids', 'Individual', 'Informatics', 'Internet', 'Literature', 'Machine Learning', 'Manuals', 'Measures', 'Medical Informatics', 'Metadata', 'Methodology', 'Methods', 'Modeling', 'Modern Medicine', 'Natural Language Processing', 'Outcome', 'Output', 'Paper', 'Patient Care', 'Population Intervention', 'Process', 'PubMed', 'Publications', 'Publishing', 'Registries', 'Reporting', 'Research', 'Resources', 'Risk', 'Stroke', 'Structure', 'Surveillance Methods', 'System', 'Technology', 'Text', 'Textbooks', 'Time', 'Training', 'United States National Institutes of Health', 'Update', 'Vision', 'Work', 'base', 'cardiovascular health', 'database structure', 'design', 'evidence base', 'improved', 'indexing', 'innovation', 'machine learning method', 'natural language', 'neural network', 'novel', 'open source', 'programs', 'prospective', 'prototype', 'recruit', 'relating to nervous system', 'repository', 'search engine', 'structured data', 'study characteristics', 'study population', 'success', 'systematic review', 'tool', 'usability', 'working group']",NLM,NORTHEASTERN UNIVERSITY,R01,2021,292031
"Advanced End-to-End Relation Extraction with Deep Neural Networks ABSTRACT Relations linking various biomedical entities constitute a crucial resource that enables biomedical data science applications and knowledge discovery. Relational information spans the translational science spectrum going from biology (e.g., protein–protein interactions) to translational bioinformatics (e.g., gene–disease associations), and eventually to clinical care (e.g., drug–drug interactions). Scientists report newly discovered relations in nat- ural language through peer-reviewed literature and physicians may communicate them in clinical notes. More recently, patients are also reporting side-effects and adverse events on social media. With exponential growth in textual data, advances in biomedical natural language processing (BioNLP) methods are gaining prominence for biomedical relation extraction (BRE) from text. Most current efforts in BRE follow a pipeline approach containing named entity recognition (NER), entity normalization (EN), and relation classiﬁcation (RC) as subtasks. They typically suffer from error snowballing — errors in a component of the pipeline leading to more downstream errors — resulting in lower performance of the overall BRE system. This situation has lead to evaluation of different BRE substaks conducted in isolation. In this proposal we make a strong case for strictly end-to-end evaluations where relations are to be produced from raw text. We propose novel deep neural network architectures that model BRE in an end-to-end fashion and directly identify relations and corresponding entity spans in a single pass. We also extend our architectures to n-ary and cross-sentence settings where more than two entities may need to be linked even as the relation is expressed across multiple sentences. We also propose to create two new gold standard BRE datasets, one for drug–disease treatment relations and another ﬁrst of a kind dataset for combination drug therapies. Our main hypothesis is that our end-to-end extraction models will yield supe- rior performance when compared with traditional pipelines. We test this through (1). intrinsic evaluations based on standard performance measures with several gold standard datasets and (2). extrinsic application oriented assessments of relations extracted with use-cases in information retrieval, question answering, and knowledge base completion. All software and data developed as part of this project will be made available for public use and we hope this will foster rigorous end-to-end benchmarking of BRE systems. NARRATIVE Relations connecting biomedical entities are at the heart of biomedical research given they encapsulate mech- anisms of disease etiology, progression, and treatment. As most such relations are ﬁrst disclosed in textual narratives (scientiﬁc literature or clinical notes), methods to extract and represent them in a structured format are essential to facilitate applications such as hypotheses generation, question answering, and information retrieval. The high level objective of this project is to develop and evaluate novel end-to-end supervised machine learning methods for biomedical relation extraction using latest advances in deep neural networks.",Advanced End-to-End Relation Extraction with Deep Neural Networks,10200889,R01LM013240,"['Adverse event', 'Architecture', 'Area', 'Benchmarking', 'Bioinformatics', 'Biology', 'Biomedical Research', 'Classification', 'Clinical', 'Code', 'Collaborations', 'Combination Drug Therapy', 'Communities', 'Complex', 'Computer software', 'Data', 'Data Set', 'Dependence', 'Disease', 'Distant', 'Drug Interactions', 'Encapsulated', 'Etiology', 'Evaluation', 'Fostering', 'Funding', 'Future', 'Generations', 'Genes', 'Gold', 'Growth', 'Hand', 'Heart', 'Information Retrieval', 'Information Sciences', 'Intramural Research', 'Joints', 'Knowledge Discovery', 'Label', 'Language', 'Lead', 'Link', 'Literature', 'Manuals', 'Maps', 'Measures', 'Methodology', 'Methods', 'Modeling', 'Molecular', 'Names', 'Natural Language Processing', 'Patients', 'Peer Review', 'Performance', 'Periodicity', 'Pharmaceutical Preparations', 'Physicians', 'Process', 'Psychological Transfer', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Review Literature', 'Scientist', 'Semantics', 'Software Tools', 'Source', 'Standardization', 'Structure', 'Supervision', 'System', 'Terminology', 'Testing', 'Text', 'Training', 'Translational Research', 'Trees', 'base', 'biomedical data science', 'clinical care', 'deep neural network', 'improved', 'insight', 'interest', 'knowledge base', 'machine learning method', 'natural language', 'neural network', 'neural network architecture', 'new therapeutic target', 'novel', 'off-label use', 'protein protein interaction', 'relating to nervous system', 'side effect', 'social media', 'supervised learning', 'syntax']",NLM,UNIVERSITY OF KENTUCKY,R01,2021,332681
"Facilitate Observational Studies of Alzheimer's Disease and Alzheimer's Disease-Related Dementias Using Ontology and Natural Language Processing Project Summary As the 6th leading cause of death in the US, Alzheimer's disease (AD) and Alzheimer's disease-related dementias (ADRD) affect about 5.7 million Americans. However, up until now, our understanding of risk factors of AD/ADRD is still limited and our efforts on developing effective treatments for AD/ADRD have been greatly disappointing. Therefore, there is an urgent need to develop new methods to conduct AD/ADRD research more efficiently. One of the potential approaches is to leverage large, longitudinal, observational clinical data accumulated in electronic health records (EHRs). Nevertheless, current uses of EHRs for AD/ADRD research is very limited, often requiring manual data extraction and normalization (i.e., manual chart review), which is labor-intensive and time-consuming. Therefore, in this study, we plan to develop novel ontology and natural language processing (NLP) based informatics methods and tools to automatically extract and normalize AD/ADRD-related clinical data in EHRs, thus facilitating efficient AD/ADRD observational studies using EHRs. We propose the following three specific aims to achieve this goal: 1) Build an information model for EHR-based AD/ADRD research using a formal ontology representation approach; and 2) Extract and normalize AD/ADRD information in clinical documents using NLP technologies; and 3) Evaluate developed informatics methods and tools through demonstration studies and disseminate them to support observational AD/ADRD research. PROJECT NARRATIVE In this project, we propose to develop novel informatics approaches to automatically extract detailed clinical information about Alzheimer's disease (AD) and Alzheimer's disease-related dementias (ADRD) patients (e.g., disease diagnosis, prognosis, treatment, and response) from heterogeneous electronic health records databases. This technology will allow more efficient information extraction from patients' records, thus facilitating clinical research on AD/ADRD.",Facilitate Observational Studies of Alzheimer's Disease and Alzheimer's Disease-Related Dementias Using Ontology and Natural Language Processing,10235325,RF1AG072799,"['Affect', 'Alzheimer&apos', 's Disease', 'Alzheimer&apos', 's disease related dementia', 'Alzheimer&apos', 's disease risk', 'American', 'Cardiovascular Diseases', 'Cause of Death', 'Clinical', 'Clinical Data', 'Clinical Research', 'Communities', 'Computerized Medical Record', 'Consumption', 'Data', 'Data Science', 'Data Sources', 'Data Store', 'Databases', 'Disease', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Elements', 'Genomics', 'Goals', 'Health Care Costs', 'Hospice Care', 'Informatics', 'Information Retrieval', 'Long-Term Care', 'Manuals', 'Methods', 'National Human Genome Research Institute', 'Natural Language Processing', 'Natural Language Processing pipeline', 'Observational Study', 'Onset of illness', 'Ontology', 'Patient-Focused Outcomes', 'Patients', 'Population', 'Prevalence', 'Procedures', 'Records', 'Reporting', 'Research', 'Research Institute', 'Resources', 'Risk Factors', 'Severities', 'System', 'Technology', 'Time', 'Translational Research', 'Validation', 'Work', 'base', 'cohort', 'disease diagnosis', 'effective therapy', 'health data', 'improved', 'informatics tool', 'information model', 'network informatics', 'novel', 'outcome forecast', 'predictive modeling', 'programs', 'repository', 'risk prediction', 'risk stratification', 'tool', 'treatment response']",NIA,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,RF1,2021,2371994
"National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives Project Summary and Abstract Narratives of electronic health records (EHRs) contain useful information that is difficult to automatically extract, index, search, or interpret. Natural language processing (NLP) technologies can extract this information and convert it in to a structured format that is more readily accessible by computerized systems. However, the development of NLP systems is contingent on access to relevant data and EHRs are notoriously difficult to obtain because of privacy reasons. Despite the recent efforts to de-identify and release narrative EHRs for research, these data are still very rare. As a result, clinical NLP, as a field has lagged behind. To address this problem, since 2006, we organized thirteen shared tasks, accompanied with workshops and journal publications. Twelve of these shared tasks have focused on the development of clinical NLP systems and the remaining one on the usability of these systems. We have covered both depth and breadth in terms of shared tasks, preparing tasks that study cutting-edge NLP problems on a variety of EHR data from multiple institutions. Our shared tasks are the longest running series of clinical NLP shared tasks, with ever growing EHR data sets, tasks, and participation. Our most popular three data sets have been cited 495 (2010 data), 284 (2006 de-id data), and 274 (2009 data) times, respectively, representing hundreds of articles that have come out of these three data sets alone. Our goal in this proposal is to continue the efforts we started in 2006 under i2b2 shared task challenges (i2b2, NIH NLM U54LM008748, PI: Kohane and R13 LM011411, PI: Uzuner) to de-identify EHRs, annotate them with gold- standard annotations for clinical NLP tasks, and release them to the research community for the development and head-to-head comparison of clinical NLP systems, for the advancement of the state of the art. Continuing our efforts under National NLP Clinical Challenges (n2c2) based at the Health Data Science program of the newly established Department of Biomedical Informatics at Harvard Medical School, we aim to form partnerships with the community to grow the shared task efforts in several ways: (1) grow the available de-identified EHR data sets through partnerships that can contribute to the volume and variety of the data, and (2) grow the available gold-standard annotations in terms of depth and breadth of NLP tasks. Given these aims and partnerships, we plan to hold a series of shared tasks. We will complement these shared tasks with workshops that meet in conjunction with the Fall Symposium of the American Medical Informatics Association and with journal special issues so that advancement of the state of the art can be sped up and future generations can build on the past. Project Narrative We propose to organize a series of shared tasks, workshops, and journal publications for fostering the continuous development of clinical Natural Language Processing (NLP) technologies that can extract information from narratives of Electronic Health Records (EHRs). Our aim is to grow the annotated gold standard EHR data sets that are available to the research community through partnerships and to bring together clinical NLP researchers with informatics researchers for building collaborations. We will engage the community in shared tasks and disseminate the knowledge generated by these shared tasks through workshops and journal special issues for the advancement of the state of the art.",National NLP Clinical Challenges (n2c2): Challenges in Natural Language Processing for Clinical Narratives,10139100,R13LM013127,"['Access to Information', 'Address', 'American', 'Clinic', 'Clinical', 'Collaborations', 'Communities', 'Community Developments', 'Complement', 'Data', 'Data Science', 'Data Set', 'Development', 'Educational workshop', 'Electronic Health Record', 'Evaluation', 'Fostering', 'Future', 'Future Generations', 'Goals', 'Gold', 'Grant', 'Growth', 'Hand', 'Head', 'Healthcare', 'Improve Access', 'Individual', 'Informatics', 'Institution', 'Israel', 'Journals', 'Knowledge', 'Measures', 'Medical Informatics', 'Medical center', 'Methodology', 'Natural Language Processing', 'Outcome', 'Paper', 'Peer Review', 'Performance', 'Privacy', 'Publications', 'Publishing', 'Records', 'Research', 'Research Personnel', 'Rest', 'Running', 'Series', 'Source', 'Structure', 'System', 'Systems Development', 'Targeted Research', 'Technology', 'Time', 'United States National Institutes of Health', 'Universities', 'base', 'biomedical informatics', 'clinical development', 'computerized', 'falls', 'head-to-head comparison', 'health data', 'indexing', 'medical schools', 'meetings', 'practical application', 'programs', 'symposium', 'usability', 'working group']",NLM,GEORGE MASON UNIVERSITY,R13,2021,20000
"Audio Generation and Optimization from Existing Resources for Patient Education Project Summary/Abstract Health literacy is vital to achieving and maintaining good health. Several national programs have emphasized this goal and its importance. Text is generally much more efficient and cost-effective for presenting healthcare information on a large scale than interactive tools and videos. Over the past decade, therefore, most medical information has been provided as text, e.g., via printed pamphlets or on websites. We are entering a new era where a new similarly effective mode of information dissemination is becoming increasingly available: audio accessed with mobile devices. Millions of households have and use smart speakers and virtual assistants and they are increasingly used by patients and consumers to gather information. Hospitals also plan to gradually integrate them among their tools. However, there exist few if any guidelines on optimal generation and use of audio. The overall goal of this project is to discover how to support the creation of optimal audio from existing text sources for consumer and patient education. To accomplish this, four aims are proposed. The first aim is to identify audio features that affect information comprehension and retention. Here, features in audio content and style (e.g., word frequency or grammatical complexity) of the underlying information will be tested for impact. In addition, two groups of features specific to the audio medium will be tested: the delivery features (e.g., speed and pauses) as well as meta-features (e.g., speaker characteristics such as gender or accent and bias in listeners). This first aim will rely on large-scale datasets, semi-automatically generated and augmented with user scores for comprehension gathered using Amazon Mechanical Turk (MTurk). Statistical and machine learning approaches will be used to tease out the best features and combinations. The second aim focuses on discovering how to augment text for audio and finding the optimal combination of text and audio for information comprehension and retention. Different combinations will be tested online with MTurk participants using controlled user studies. The third aim is to update, test and provide the existing online free text editor to generate optimized audio. We will also start dissemination of the tool to potential users including API access to components. The project will conclude with a summative evaluation with representative consumers recruited at a local community health center and further dissemination of preferences, practical obstacles, and best practices for the medical community to help increase health literacy through this new, popular audio medium. If successful, this project will generate best practices for the medical community in using audio as an additional method for bringing healthcare information to the general public; it will provide an online, free tool to generate audio leveraging these best practices and will include API access so that other researchers can easily integrate tool components into their research and tools; and it will provide immediate practical lessons from working with consumers relevant for clinical practice. Project Narrative Improving health literacy is an important national goal and necessary for achieving and maintaining health. The increased adoption of smart speakers and virtual assistants by consumers and in medical settings has created novel opportunities to educate the population by delivering health information through audio or audio combined with text. Because few (if any) tools exist to improve content and generate optimal audio, we aim to discover supportive and adverse features of audio/text information provision and create a free, online software tool for optimizing health-related text with demonstrated impact on information comprehension and retention.",Audio Generation and Optimization from Existing Resources for Patient Education,10295641,R01LM011975,"['Accent', 'Adoption', 'Affect', 'Affordable Care Act', 'Age', 'Arizona', 'Characteristics', 'Collaborations', 'Communication', 'Communities', 'Comprehension', 'Computer software', 'Computers', 'Data', 'Development', 'Effectiveness', 'Evaluation', 'Frequencies', 'Gender', 'General Population', 'Generations', 'Goals', 'Government', 'Growth', 'Guidelines', 'Health', 'Healthcare', 'Hospitals', 'Household', 'Information Dissemination', 'Machine Learning', 'Measures', 'Mechanics', 'Medical', 'Methods', 'Modeling', 'Natural Language Processing', 'Neighborhood Health Center', 'Operative Surgical Procedures', 'Outcome', 'Pamphlets', 'Participant', 'Patient Education', 'Patients', 'Pilot Projects', 'Population', 'Research', 'Research Personnel', 'Resources', 'Software Tools', 'Source', 'Specific qualifier value', 'Speed', 'Technology', 'Testing', 'Text', 'Update', 'Voice', 'Work', 'Work Simplification', 'Writing', 'application programming interface', 'clinical encounter', 'clinical practice', 'clinically relevant', 'cost effective', 'design', 'digital', 'experience', 'handheld mobile device', 'health literacy', 'improved', 'information processing', 'innovation', 'intelligent personal assistant', 'interactive tool', 'large scale data', 'novel', 'open source', 'preference', 'programs', 'real world application', 'recruit', 'skills', 'statistical and machine learning', 'symposium', 'tool', 'web site']",NLM,UNIVERSITY OF ARIZONA,R01,2021,257905
"Large scale clinical and economic impact analysis of potentially malignant incidental findings in radiology reports Abstract Unexpected findings, or incidentalomas, are increasing dramatically with the growth in the use of imaging technology within healthcare organizations. Incidentalomas may indicate significant health problems, such as malignancy in the medium or long term. However, they also may lead to overinvestigation, unnecessary radiation exposure, overtreatment, substantial downstream expenditures, and patient anxiety. Several systematic reviews have explored the prevalence and outcomes of incidentalomas. These studies used inconsistent and often inappropriate synthesis methods, commonly only focusing on one imaging scan or organ in a very limited number of patients. As a result, there is need for large-scale study of incidentalomas that can inform their follow up and guide efforts to optimize health outcomes. To address this need, we propose to build natural language processing (NLP) approaches to identify cancer-related incidentalomas reported in radiology reports (Aim 1) and to create the first large-scale incidentaloma database covering over half-a-million patients (Aim 2). Our research dataset will contain radiology reports, clinical notes containing imaging orders, as well as structured data such as demographic information (e.g., age) and diagnoses codes of patients who received radiologic imaging tests in University of Washington Medical Center (UWMC), Harborview Medical Center (HMC), Seattle Cancer Care Alliance (SCCA), and Northwest Hospital and Medical Center (NWMC) between 2007-2019. Our patient population will be linked to Hutchinson Institute for Cancer Outcomes Research (HICOR) data repository for detailed cancer outcomes and claims data. The created database will be used for clinical and economic analysis of incidentalomas (Aim 3). We will (1) evaluate the concordance between radiologists' documentation of incidentaloma follow-up and established clinical guidelines for thyroid, lung, adrenal, kidney, liver, and pancreas incidentalomas, (2) determine risk of subsequent cancer diagnosis and median survival for each category of incidentaloma, and (3) determine the incremental cost associated with follow-up imaging in patients with incidentalomas. All models and their implementations produced during the execution of this project will be shared with the community as open source. Additionally, the de-identified incidentaloma database will be made available to the research community under a data use agreement. By identifying risk factors for cancer diagnosis and death for common incidental findings, we will be able to provide critical information for future clinical practice guideline development and appropriate use criteria. We assembled a highly interdisciplinary team of experts in NLP, medical informatics, radiology, oncology, health outcomes, and health economics to ensure the successful completion of the proposed project. Project Narrative Incidentalomas may indicate significant health problems, such as malignancy to the patient in the short or medium term, but also may lead to overtreatment, which comes with substantial downstream expenditures as well as patient anxiety. In this project, we will build natural language processing approaches to extract cancer related incidentalomas reported in radiology reports (Aim 1) and create the first large scale incidentaloma database for half-a-million patients who received radiologic imaging tests in University of Washington Medical Center, Harborview Medical Center, Seattle Cancer Care Alliance, and Northwest Hospital and Medical Center between 2007 and 2019 (Aim 2). This database will be used for clinical and economic analysis of incidentalomas (Aim 3).",Large scale clinical and economic impact analysis of potentially malignant incidental findings in radiology reports,10116614,R01CA248422,"['Abdomen', 'Active Learning', 'Address', 'Adherence', 'Adrenal Glands', 'Age', 'Agreement', 'Angiography', 'Anxiety', 'Caregivers', 'Categories', 'Cessation of life', 'Chest', 'Clinical', 'Clinical Data', 'Clinical Practice Guideline', 'Code', 'Communication', 'Communities', 'Data', 'Data Set', 'Databases', 'Development', 'Diagnosis', 'Disease', 'Documentation', 'Economics', 'Ensure', 'Epidemic', 'Expenditure', 'Funding', 'Future', 'Gold', 'Growth', 'Guidelines', 'Health', 'Healthcare', 'Hospitals', 'Image', 'Imaging technology', 'Incidental Findings', 'Institutes', 'Interdisciplinary Study', 'Investigation', 'Kidney', 'Lead', 'Link', 'Liver', 'Lung', 'Lung nodule', 'Machine Learning', 'Malignant - descriptor', 'Malignant Neoplasms', 'Medical Informatics', 'Medical center', 'Methods', 'Modeling', 'Modernization', 'Natural Language Processing', 'Oncology', 'Organ', 'Outcome', 'Outcomes Research', 'Pancreas', 'Pancreatic Cyst', 'Patient Noncompliance', 'Patient risk', 'Patients', 'Performance', 'Prevalence', 'Pulmonary Embolism', 'Radiation exposure', 'Radiology Specialty', 'Recommendation', 'Reporting', 'Research', 'Research Project Grants', 'Risk', 'Risk Factors', 'Running', 'Scanning', 'Semantics', 'Services', 'Technology', 'Testing', 'Text', 'Thyroid Gland', 'Thyroid Nodule', 'Training', 'Universities', 'Washington', 'base', 'cancer care', 'cancer diagnosis', 'cancer risk', 'clinical database', 'cohort', 'comorbidity', 'cost', 'data repository', 'economic evaluation', 'economic impact', 'follow-up', 'health care delivery', 'health care service organization', 'health economics', 'improved', 'machine learning method', 'mortality', 'novel', 'open source', 'overtreatment', 'patient population', 'radiological imaging', 'radiologist', 'repository', 'structured data', 'surveillance imaging', 'systematic review', 'tumor']",NCI,UNIVERSITY OF WASHINGTON,R01,2021,674025
"Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing The adoption of Electronic Health Record (EHR) systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format with tremendous potential but an equally large concern for patient confidentiality breaches. Secondary use of clinical data is essential to fulfill the potential for high quality healthcare, improved healthcare management, and effective clinical research. NIH expects that larger research projects share their research data in a way that protects the confidentiality of research subjects. De-identification of patient data has been proposed as a solution to both facilitate secondary use of clinical data and protect patient data confidentiality. The majority of clinical data found in the EHR is represented as narrative text clinical notes, and de-identification of clinical text is a tedious and costly manual endeavor. Automated approaches based on Natural Language Processing have been implemented and evaluated, allowing for higher accuracy and much faster de- identification than manual approaches. Clinacuity, Inc. proposes to advance a text de-identification system from a prototype to an accurate, adaptable, and robust system, integrated into the research infrastructure at our implementation and testing site (Medical University of South Carolina, Charleston, SC), and ready for commercialization efforts. To accomplish this undertaking, we will focus on the following specific aims and related objectives, while continuing to prepare the commercialization of the integrated system, with detailed market analysis, commercial roadmap development, and modern media communication: 1) Enhance the text de-identification system performance, scalability, and quality to produce an enterprise-grade solution ready for deployment; 2) Enable use of structured data for enhanced text de-identification (when structured PII is available) and for complete patient records de-identification (i.e., records combining structured and unstructured data). This aim also includes implementing “one-way” pseudo-identifier cryptographic hashing to enable securely linking already de-identified patient records; 3) Integrate the text de-identification system with a research data capture and management system. This includes implementation of the de-identification system as a secure web service, with standards-based access and integration. This de-identification system has potential commercial applications in clinical research and in healthcare settings. It will improve access to richer, more detailed, and more accurate clinical data (in clinical text) for clinical researchers. It will ease research data sharing (as expected for larger NIH-funded research projects) and help healthcare organizations protect patient data confidentiality. Significant time-savings will also be offered, with a process at least 200-1000 times faster than manual de-identification. The adoption of Electronic Health Record systems is growing at a fast pace in the U.S., and this growth results in very large quantities of patient clinical data becoming available in electronic format, with tremendous potential, but also equally growing concern for patient confidentiality breaches. De-identification of patient data has been proposed as a solution to both facilitate secondary uses of clinical data and protect patient data confidentiality. This project will advance a text de-identification system from a prototype to an accurate, adaptable and robust system allowing for complete patient records de-identification, integrated in the research infrastructure at our implementation and testing site and ready for commercialization efforts. It will improve access to richer, more detailed, and more accurate clinical data for clinical researchers, ease research data sharing and help healthcare organizations protect patient data confidentiality. !",Clinical Text Automatic De-Identification to Support Large Scale Data Reuse and Sharing,10098325,R42GM116479,"['Adoption', 'Clinical', 'Clinical Data', 'Clinical Research', 'Code', 'Communications Media', 'Confidentiality of Patient Information', 'Data', 'Deimplementation', 'Development', 'Electronic Health Record', 'Environment', 'Fast Healthcare Interoperability Resources', 'Funding', 'Growth', 'Health Insurance Portability and Accountability Act', 'Improve Access', 'Link', 'Manuals', 'Medical', 'Modernization', 'National Institute of General Medical Sciences', 'Natural Language Processing', 'Patient Care', 'Patient Data Privacy', 'Patients', 'Performance', 'Personally Identifiable Information', 'Phase', 'Privacy', 'Process', 'Records', 'Reference Standards', 'Research', 'Research Infrastructure', 'Research Personnel', 'Research Project Grants', 'Research Subjects', 'Risk', 'Savings', 'Secure', 'Site', 'South Carolina', 'Speed', 'Structure', 'System', 'Test Result', 'Testing', 'Text', 'Time', 'Training', 'Trust', 'United States National Institutes of Health', 'Universities', 'Visualization', 'base', 'commercial application', 'commercialization', 'cost', 'cryptography', 'data reuse', 'data sharing', 'health care quality', 'health care service organization', 'health care settings', 'health management', 'improved', 'large scale data', 'participant enrollment', 'prototype', 'software development', 'standard measure', 'structured data', 'systems research', 'unstructured data', 'web services']",NIGMS,"CLINACUITY,INC.",R42,2021,725232
