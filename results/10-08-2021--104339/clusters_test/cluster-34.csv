text,title,id,project_number,terms,administration,organization,mechanism,year,funding
"Transforming Patient Safety Event Data into Actionable Insights through Advanced Analytics Abstract The objective of the proposed research is to develop an innovative algorithms and a software tool to reduce the burden of safety event report classification and analysis so that report data can be transformed to actionable insights. Making safety event data more actionable will support the proactive identification of safety hazards before patients are harmed. We will achieve our research objective through (1) the development of natural language processing algorithms to classify safety event reports into actionable medication error categories; (2) the development of prototype software that will automatically categorize and visualize safety event reports to support trend identification; and (3) the pilot testing of prototype software with hospital and patient safety organization safety analysts. This project utilizes the extensive expertise of the research team in human factors and safety science, including computer science, specifically regarding information retrieval and data classification. Our research team includes patient safety organizations and collaboration with the computer science department at Georgetown University. The proposal is directly aligned with AHRQ’s priority area of making health care safer. Contributions from this research will include an expansion of our understanding of natural language processing and its application to categorizing clinical text, advances in visual analytics, and the development of a software tool to support patient safety analysts. The outputs of this research will serve both healthcare organizations and patient safety organizations allowing them to more efficiently and effectively analyze safety report data. Project Narrative This project is relevant to public health because it applies human factors and computer science to develop software to improve the analysis of patient safety event report data to reduce safety hazards and prevent patient harm. Patient safety event report data will be analyzed using natural language processing algorithms to more efficiently classify events into error categories. Based on these algorithms, prototype software will be developed, tested, and disseminated with the goal of automatic categorization and visualization of safety event reports to identify important safety hazards.",Transforming Patient Safety Event Data into Actionable Insights through Advanced Analytics,10249058,R01HS026481,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2021,395495
"Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign Project Summary/Abstract Written The objective of the proposed research is to reduce the patient safety hazards associated with electronic medication administration records (eMARs) by, (1) understanding current usability and safety gaps, and (2) creating design and development documents, wireframes, and prototypes to serve as the foundation for future eMARs that will eliminate these gaps. In particular, we focus on communication and information flow challenges between nurses, pharmacists, and physicians during medication administration and use of the eMAR. The proposed research is in direct response to special emphasis notice (NOT-HS-16-009). We will develop a broad understanding of usability and safety hazards associated with eMARs by analyzing a large dataset of 1.7 million patient safety event reports and detailed medication error related narratives. We will then conduct heuristic analyses of current eMARs, and interviews and observations of physicians, nurses, and pharmacists. These data will serve to inform the development of eMAR design documents, wireframes, and prototypes as the foundation for future development. This project utilizes the extensive expertise of the research team in human factors and safety science, health information technology (health IT), informatics, and data science. Our research team includes physicians, nurses, pharmacists, and human factors engineers, and experts in natural language processing. In addition, our partnerships include a patient safety organization and a health IT vendor. The proposal addresses fundamental aspects of the call for proposals by providing new insights on the safety of health IT and improves current practices by developing use cases and new prototypes for immediate use by healthIT vendors. Contributions from this research will include a fundamental understanding of the role of health IT during medication administration with a focus on communication and information flow, design, development and testing documents for vendors and providers, and eMAR wireframes and prototypes to improve development. Our research will also provide organizations like the Office of the National Coordinator with medication related test scenarios to assess current health IT systems. Project Narrative This project is relevant to public health because it applies the sciences of human factors and informatics to improve the usability and safety of the electronic medication administration records (eMARs), which will ultimately improve patient care. Patient safety event report data will be analyzed to identify usability and safety hazards in eMARs, and interviews and observations will be conducted to identify clinician needs. Based on this knowledge eMAR design documents, wireframes, and prototypes will be developed, tested, and disseminated with the goal of improving communication and information flow to reduce medication related errors.",Improving Patient Safety and Clinician Cognitive Support Through eMAR Redesign,10141229,R01HS025136,[' '],AHRQ,MEDSTAR HEALTH RESEARCH INSTITUTE,R01,2021,392540
"COVID-19 disease course analysis using multi-site large-scale EHR data Project Summary/Abstract  Since its ﬁrst case reported in December 2019, the coronavirus disease-2019 (COVID-19) has caused a pan- demic in 188 countries/regions, and has precipitated an unprecedented health, economic and social crisis. In order to cope with the volatile dynamic and severity of the pandemic, it is imperative that we characterize the various clinical courses of COVID-19 infection, and determine whether and how demographic, clinical and other variables inﬂuence them. Knowledge of the disease's transmission, symptomatology, clinical course, treatment and outcomes is rapidly evolving based on many sources. An important source for advancing this knowledge is data from electronic health records (EHR) and health information exchanges (HIE) because they can pro- vide a real-time, unvarnished view of the disease. Using large-scale, well-integrated and rich EHR data enables comprehensive proﬁling and quantiﬁcation of the COVID-19 disease course that can directly inform clinical prac- tice. The long-term goal of our research is to develop Artiﬁcial Intelligence (AI) tools to facilitate access to and analysis of clinical data. The goal of this application is to develop effective algorithms and tools to mine clinical data to categorize disease courses of COVID-19, and determine the effect of clinical and other variables asso- ciated with them. We will develop our algorithms using data from a large and comprehensive health information exchange, the Indiana Network for Patient Care (INPC), which has about 40,000 COVID-19 patients and fairly complete EHR data about them. We will evaluate the algorithms against other data sets, including EHR data from the OSU Wexner Medical Center and the National COVID Cohort Collaborative (N3C). The speciﬁc aims of this project are to (1) develop COVID-19 disease course groupings, (2) relate comorbidities and other clinical variables to the COVID-19 disease course, and (3) validate the developed algorithms on N3C data. This pro- posal is signiﬁcant because the methods developed in this project have the potential to signiﬁcantly increase our capability for computational analysis of large and rich patient data during the pandemic and beyond; the knowl- edge derived from our comprehensive proﬁling of COVID-19 courses over large, inclusive patient populations supported by rich EHR data can positively impact clinical practice; and the tools developed in this project will be released to the public as a free COVID-19 research re- source. It is innovative because our methods integrate novel methods such as patient clustering using clinical variables and disease progression trajectories, and pa- tient trajectory comparison, with established univariate and predictive analysis; our primary approach will lever- age the oldest and one of the country's largest HIEs to derive detailed and comprehensive knowledge about a large patient population; and the strong preliminary data generated by this project can help improve COVID-19 patient phenotyping, disease characterization and diagnosis. Project Narrative  The coronavirus disease-2019 (COVID-19) has caused a pandemic in 188 countries/regions, and has pre- cipitated an unprecedented health, economic and social crisis. It is imperative that we characterize the various clinical courses of COVID-19 infection, and determine whether and how demographic, clinical and other vari- ables inﬂuence them. This project will use large-scale, comprehensive EHR data from the Indiana Network for Patient Care (INPC), the Ohio State University Wexner Medical Center (OSUWMC) and National COVID Cohort Collaborative (N3C) to develop effective algorithms and tools to accomplish this goal.",COVID-19 disease course analysis using multi-site large-scale EHR data,10196001,R21LM013678,"['Address', 'Age', 'Algorithmic Software', 'Algorithms', 'Artificial Intelligence', 'COVID-19', 'COVID-19 pandemic', 'COVID-19 patient', 'Cardiovascular Diseases', 'Caring', 'Case Study', 'Centers for Disease Control and Prevention (U.S.)', 'Chills', 'Clinical', 'Clinical Course of Disease', 'Clinical Data', 'Cluster Analysis', 'Communicable Diseases', 'Computer Analysis', 'Coronavirus', 'Coughing', 'Country', 'Critical Care', 'Data', 'Data Collection', 'Data Set', 'Diabetes Mellitus', 'Diagnosis', 'Disadvantaged', 'Disease', 'Disease Management', 'Disease Progression', 'Dyspnea', 'Electronic Health Record', 'Fever', 'Functional disorder', 'Geographic Locations', 'Goals', 'Grouping', 'Guidelines', 'Headache', 'Health', 'Hypoxia', 'Image', 'Indiana', 'Interdisciplinary Study', 'Kidney Diseases', 'Knowledge', 'Lung', 'Medical center', 'Methods', 'Modeling', 'Myalgia', 'Ohio', 'Outcome', 'Patient Care', 'Patients', 'Phenotype', 'Physicians', 'Play', 'Pneumonia', 'Postdoctoral Fellow', 'Public Health', 'Publishing', 'Research', 'Research Personnel', 'Respiratory Failure', 'Role', 'SARS-CoV-2 infection', 'Salvelinus', 'Severities', 'Severity of illness', 'Shock', 'Shortness of Breath', 'Signs and Symptoms', 'Site', 'Smell Perception', 'Source', 'Symptoms', 'System', 'Taste Perception', 'Time', 'Treatment outcome', 'Universities', 'Work', 'base', 'clinical effect', 'clinical practice', 'cohort', 'comorbidity', 'coronavirus disease', 'disease transmission', 'electronic data', 'health economics', 'improved', 'innovation', 'novel', 'pandemic disease', 'patient population', 'respiratory', 'response', 'social', 'symptomatology', 'tool']",NLM,OHIO STATE UNIVERSITY,R21,2021,229308
"Improving Quality of Electronic Health Record Ophthalmic Data for Big Data Analytics PROJECT SUMMARY The widespread adoption of EHRs has enabled the collection of massive amounts of digital ophthalmic data which have great potential for secondary use in research, quality improvement, and clinical decision support. While the amount of digital ophthalmic data recorded in the EHR is substantial and could be analyzed using the latest techniques for big data, questions about the quality of the data are a barrier to its reuse. Now that the American Academy of Ophthalmology has aggregated digital ophthalmic data from the EHR into the IRIS Registry, data quality is even more imperative for reaching the potential of the registry. To date, there has not be a comprehensive evaluation of the data quality of digital ophthalmic data, nor have there been any solutions for improving its quality. These are important gaps that will limit the utility of EHR data as a tool for knowledge discovery in ophthalmology. The goal of this grant is to assess the quality of digital ophthalmic exam data in order to improve its ability to be reused for research. Our hypothesis is that studying the variability of data quality in large datasets will provide insights into improving its quality. The first aim employs an established framework for data quality analysis to assess the intrinsic quality of a single institution’s EHR data as well as its fitness for use--the ability to be applied to a particular research scenario. In this proposal, we are evaluating the data’s ability to identify patient cohorts for clinical trials and to accurately calculate outcome based clinical quality measures. The variability in data’s quality and fitness among providers, subspecialties, diagnoses, and visit types will be analyzed. The second aim validates the analysis of the first aim by repeating it for all of the ophthalmic data in the IRIS Registry. For this analysis, the differences in quality and fitness between institutions and EHR vendors will also be assessed, along with the barriers to data quality and reuse. For both aims, ophthalmology experts will review the results to make recommendations for improving data quality and utility for digital ophthalmic data. In the future, these recommendations will provide a direction for correcting these quality issues and for ultimately advancing knowledge discovery in ophthalmic care. PROJECT NARRATIVE Electronic health records (EHRs) have not yet reached their potential for transforming healthcare, particularly for reusing clinical data for research. The American Academy of Ophthalmology has aggregated ophthalmic data from the EHR into the IRIS Registry, and data quality is even more imperative to achieve to reach the potential of this registry. Using methodological data quality analysis, we will analyze the quality of a single institution’s ophthalmic data and again for multiple institutions’ ophthalmic data in the IRIS Registry, documenting barriers for data quality and reuse that will lead to improving knowledge discovery from this data.",Improving Quality of Electronic Health Record Ophthalmic Data for Big Data Analytics,10149327,R21LM013937,"['Academy', 'Adoption', 'Age related macular degeneration', 'American', 'Big Data', 'Big Data Methods', 'Caring', 'Clinical', 'Clinical Data', 'Clinical Research', 'Clinical Trials', 'Cohort Studies', 'Collection', 'Complex', 'Data', 'Data Discovery', 'Data Store', 'Diabetic Retinopathy', 'Diagnosis', 'Disease Progression', 'Electronic Health Record', 'Evaluation', 'Exfoliation Syndrome', 'Eye', 'Future', 'Glaucoma', 'Goals', 'Grant', 'Hand', 'Health Sciences', 'Healthcare', 'Human', 'Image', 'Individual', 'Informatics', 'Institutes', 'Institution', 'Intelligence', 'Iris', 'Knowledge Discovery', 'Manuals', 'Measurement', 'Measures', 'Medical Informatics', 'Medicine', 'Methodology', 'Methods', 'Ophthalmology', 'Oregon', 'Outcome', 'Patients', 'Process', 'Provider', 'Recommendation', 'Registries', 'Research', 'Research Personnel', 'Retinopathy of Prematurity', 'Secondary to', 'Source', 'Structure', 'System', 'Techniques', 'Terminology', 'Treatment outcome', 'Universities', 'Vendor', 'Vision', 'Visit', 'base', 'clinical decision support', 'clinical encounter', 'cohort', 'data framework', 'data harmonization', 'data quality', 'data registry', 'data reuse', 'data submission', 'deep learning', 'digital', 'electronic data', 'experience', 'fitness', 'improved', 'insight', 'large datasets', 'large scale data', 'research study', 'tool', 'treatment comparison']",NLM,OREGON HEALTH & SCIENCE UNIVERSITY,R21,2021,186725
"Incorporating Learning Effects into Medical Device Active Safety Surveillance Methods Implantable medical devices have revolutionized contemporary cardiovascular care, and are used in a wide spectrum of acute and chronic cardiovascular conditions. However, medical device design fault or incorrect use may lead to significant risk of patient injury and represents an important preventable public health risk in the United States. To help identify device-related safety issues, a strategy of active, prospective, post-market safety surveillance has been recommended by the FDA, and evaluated methodologically. This type of surveillance offers significant advantages over traditional adverse event reporting strategies. However, all such approaches are challenged by the need to incorporate learning effects into expectations regarding safety. These learning impacts been repeatedly shown to have dramatic impacts on outcomes during early device experience. Quantifying learning effects on the outcomes associated with high-risk cardiovascular devices will improve our understanding of intrinsic device performance, thereby identifying patient populations best treated with such devices while simultaneously providing necessary feedback to device manufacturers to support iterative improvement in device design. Separately, understanding the impacts of learning may identify opportunities for targeted training as well as help to tease apart institutional and operator characteristics that may accelerate the achievement of optimal outcomes in the use of the specific cardiovascular device.  This proposal seeks to extend the previously validated, open-source, active, prospective device safety surveillance tool, by developing and validating robust learning curve (LC) detection and quantification algorithms, designed to simultaneously account for the effects at the operator and institutional levels. We propose a “blinded” development strategy, in which one team will generate robust synthetic clinical data simulator with LC impacts, and the other team develops and applies LC detection and quantification algorithms, without knowledge of the underlying relationships, determine performance and accuracy through sequential refinement and validation steps. We propose to formally validate the optimized LC tools in real-world data through re-analysis of previously published LC effects on transcatheter valves and vascular closure devices using national cardiovascular registries. In addition, the LC tools will be incorporated into two active, prospective device safety surveillance studies of novel implantable cardiovascular devices using large clinical registries. This proposal seeks to understand the impact of institutional and physician learning on the safety of newly approved cardiovascular devices, and to use this knowledge to support and improve effective medical device safety surveillance. We propose a “blinded” strategy of separating simulated dataset generation from the learning effects detection and quantification algorithm development. Incorporating learning effects adjustment into a validated, prospective, near-real-time safety surveillance system, this research will improve public health by identifying poorer performing cardiovascular devices, and provide physicians, device manufacturers and public health officials with better information to optimize the use of medical devices, iteratively improve their design, and identify opportunities for enhanced training that will result in improved patient outcomes.",Incorporating Learning Effects into Medical Device Active Safety Surveillance Methods,10088471,R01HL149948,"['Achievement', 'Acute', 'Address', 'Adverse event', 'Algorithm Design', 'Algorithms', 'Blinded', 'Blood Vessels', 'Cardiovascular system', 'Caring', 'Characteristics', 'Chronic', 'Clinical', 'Clinical Data', 'Complex', 'Data', 'Data Aggregation', 'Data Analytics', 'Data Set', 'Detection', 'Development', 'Device Designs', 'Device Safety', 'Devices', 'Early Diagnosis', 'Elements', 'Environment', 'Etiology', 'Evaluation', 'Event', 'Feedback', 'Generations', 'Implant', 'Injections', 'Injury', 'Institution', 'Investigation', 'Knowledge', 'Lead', 'Learning', 'Literature', 'Machine Learning', 'Manufacturer Name', 'Medical Device', 'Medical Device Designs', 'Medical Device Safety', 'Methodology', 'Methods', 'Modeling', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Physicians', 'Process', 'Provider', 'Public Health', 'Publishing', 'Registries', 'Reporting', 'Risk', 'Safety', 'Signal Transduction', 'Specific qualifier value', 'Statistical Models', 'Structure', 'Surveillance Methods', 'Time', 'Training', 'United States', 'Validation', 'Variant', 'adverse outcome', 'algorithm development', 'cardiovascular risk factor', 'clinical heterogeneity', 'design', 'expectation', 'experience', 'high risk', 'implantable device', 'improved', 'novel', 'open source', 'patient population', 'post-market', 'prospective', 'safety outcomes', 'simulation', 'surveillance strategy', 'surveillance study', 'systems research', 'tool']",NHLBI,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,768996
"PheMAP: Measured, Automated Profile to Facilitate High Throughput Phenotyping Electronic health records (EHRs) are a powerful and efficient tool for biological discovery globally. However, a vital step for EHR-based research is valid, accurate, and reliable phenotyping (i.e., correctly identifying individuals with a particular trait of interest). Conventional approaches to phenotyping are ad hoc, domain expert dependent, rule-based, and usually specific to EHR environments. However, each requires an extensive investment of time and resources to develop due to the heterogeneity, complexity, inaccuracy, and frequent fragmentation of EHRs. The lack of general, automatic, and portable approaches to enable accurate high- throughput phenotyping is a critical barrier that hampers our ability to leverage valuable clinical data in EHRs for better healthcare. We propose a new generalizable high-throughput approach: Phenotyping by Measured, Automated Profile (PheMAP) that we have developed from public resources and will further refine and implement across various EHRs. We recognize that mass information about phenotypes is often described in significant detail and continuedly accumulated within publicly available resources (e.g., MedlinePlus and Wikipedia). We hypothesize this information can be retrieved, filtered, organized, measured, and formalized into standard EHR phenotype profiles. Indeed, we have used such an ensemble approach to integrate four generalizable online medication resources (e.g., SIDER and RxNorm) to create MEDI--a resource linking 2,136 medications and 13,304 indications. In preliminary studies, we extended this strategy to phenotyping and created a prototype PheMAP. For each phenotype, we identified relevant clinical concepts and weighted each based on its importance to the phenotype. We then mapped all associated concepts to commonly-used clinical terminologies. Our preliminary studies showed an average consistency of 98.6%±0.8% between our early-stage PheMAP and three validated eMERGE algorithms (Type 2 Diabetes, dementia, and hypothyroidism). We seek support to refine and optimize PheMAP and develop tools to allow researchers to implement PheMAP efficiently in different EHRs. This will allow researchers to rapidly and accurately determine the status of thousands of phenotypes for millions of individuals with minimal human intervention. Since PheMAP is created using independent resources that are more generalizable than a local clinical dataset, the implementation will generate more consistent outcomes in different EHRs for large-scale analyses.The work we propose is a necessary step toward being able to conduct high-throughput genome-wide and phenome-wide association analyses (GWASs and PheWASs). We will use data from multiple biobanks to accomplish these tasks. Specifically, we will achieve the following goals in this grant: 1.refine PheMAP and conduct large-scale validation, 2. implement PheMAP and perform representative GWASs and PheWASs, 3. Use PheMAP to conduct GWASs for unstudied or understudied diseases and phenotypes, and 4. Share PheMAP to facilitate research using EHRs. Electronic health records (EHRs) are a powerful and efficient tool for biological discovery globally while a vital step for EHR-based research is valid, accurate, and reliable phenotyping. Conventional approaches to phenotyping are ad hoc, domain expert dependent, rule-based, and usually specific to EHR environments. We propose to refine, validate, and share a new generalizable high-throughput approach: Phenotyping by Measured, Automated Profile (PheMAP) that allows researchers to rapidly and accurately determine the status of thousands of phenotypes for millions of individuals with minimal human intervention.","PheMAP: Measured, Automated Profile to Facilitate High Throughput Phenotyping",10095131,R01GM139891,"['Algorithms', 'Benchmarking', 'Biological', 'Catalogs', 'Clinical', 'Clinical Data', 'Data', 'Data Set', 'Dementia', 'Disease', 'Effectiveness', 'Electronic Health Record', 'Electronic Medical Records and Genomics Network', 'Environment', 'Evaluation', 'Genes', 'Genotype', 'Goals', 'Grant', 'Healthcare', 'Heritability', 'Heterogeneity', 'Human', 'Hypothyroidism', 'Individual', 'Institution', 'Intervention', 'Investments', 'Knowledge', 'Left', 'Link', 'Machine Learning', 'Maps', 'Measures', 'Medical center', 'MedlinePlus', 'Modeling', 'Non-Insulin-Dependent Diabetes Mellitus', 'Ontology', 'Outcome', 'Performance', 'Pharmaceutical Preparations', 'Phenotype', 'Physicians', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Resources', 'Sampling', 'Sensorineural Hearing Loss', 'Signal Transduction', 'Site', 'Statistical Models', 'Terminology', 'Time', 'Validation', 'Work', 'base', 'biobank', 'biomedical ontology', 'clinically relevant', 'cost', 'data modeling', 'disease phenotype', 'experience', 'genome wide association study', 'genome-wide', 'implementation tool', 'interest', 'novel', 'off-label drug', 'off-label use', 'phenome', 'phenotyping algorithm', 'portability', 'prototype', 'tool', 'trait']",NIGMS,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,432500
"Leveraging Electronic Health Records and Genomic Biobanks for Kidney Stone Disease PROJECT SUMMARY Kidney stones are highly prevalent and recurrent. Our current understanding of kidney stone disease risk factors and disease associations has relied primarily on data from chart review, nonspecific administrative datasets, and secondary analyses of observation studies. Current study designs suffer from small sample sizes, heterogenous patient groups, and lack of standardized accuracy data and outcome definitions. The widespread adoption of electronic health records (EHRs) provides novel research opportunities for kidney stone disease. EHRs contain a robust clinical repository of data collected over time from clinical care. However, there are currently limited tools to identify and characterize kidney stone patients in the EHR. The objective of this study is to establish feasibility of utilizing EHR data to investigate kidney stone disease. To structure EHR data in an efficient and cost-effective manner, natural language processing and deep learning methods can be designed for identifying and phenotyping kidney stone patients and clinical outcomes. Our de-identified EHR is linked to a DNA biobank that can enable investigation of genetic associations with disease. This project has two specific aims. In Aim 1, we will perform genetic association studies in our EHR and linked DNA biobank. We will replicate previously described associations with genetic variants and kidney stone disease. We will then perform a genome-wide association study to discover novel associations. In Aim 2, our goal is to develop and validate a computable framework to extract clinical outcomes of kidney stone disease from the EHR. Clinically meaningful outcomes include symptomatic stone passage and radiographic stone characterization. We will develop and test natural language processing and deep learning algorithms to extract keywords and context-based information in clinical notes and reports. We will train and test these algorithms using manual annotation as the gold standard. This aim will enable rigorous phenotyping of each kidney stone patient using structured and unstructured EHR data. Successful completion of this project will lay the groundwork towards advancing genomic medicine and precision health to support clinical decision-making in kidney stone patients. PROJECT NARRATIVE Our overall goal is to establish the feasibility of kidney stone research using electronic health record data. Genetic association studies will be performed to replicate known and discover new variants with kidney stone disease. A computerized framework will be developed and validated to extract kidney stone patient outcomes.",Leveraging Electronic Health Records and Genomic Biobanks for Kidney Stone Disease,10103906,R21DK127075,"['Address', 'Adoption', 'Algorithms', 'Area', 'Bioinformatics', 'Clinical', 'Clinical Data', 'Collaborations', 'Coronary heart disease', 'DNA', 'Data', 'Data Set', 'Diabetes Mellitus', 'Diagnostic radiologic examination', 'Disease', 'Disease susceptibility', 'Electronic Health Record', 'Emergency department visit', 'Event', 'Future', 'Genetic Variation', 'Genetic study', 'Genomic medicine', 'Genomics', 'Genotype', 'Goals', 'Gold', 'Hypertension', 'Investigation', 'Kidney Calculi', 'Link', 'Manuals', 'Methods', 'Mind', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Phenotype', 'Precision Health', 'Radiology Specialty', 'Recurrence', 'Reporting', 'Research', 'Research Design', 'Research Personnel', 'Risk Factors', 'Sample Size', 'Sampling', 'Scanning', 'Standardization', 'Structure', 'Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Variant', 'Vision', 'Work', 'artificial neural network', 'base', 'biobank', 'case control', 'clinical care', 'clinical data repository', 'clinical decision support', 'clinical decision-making', 'clinical practice', 'clinically relevant', 'computerized', 'cost effective', 'deep learning', 'deep learning algorithm', 'design', 'disorder risk', 'electronic structure', 'genetic association', 'genetic variant', 'genome wide association study', 'genomic tools', 'knowledge base', 'learning strategy', 'machine learning algorithm', 'novel', 'phenotypic data', 'secondary analysis', 'support tools', 'text searching', 'tool', 'treatment response', 'unstructured data', 'web site']",NIDDK,VANDERBILT UNIVERSITY MEDICAL CENTER,R21,2021,259500
"Leveraging Data Science and Informatics in an Automated Detection System of Surgical Errors Technological advancements continue to improve surgical outcomes. However, these technologies also introduce new challenges such as communication complexities, equipment troubleshooting under intense pressure, and higher cognitive demand on OR team members. In other words, surgery will continue to be risky despite technological improvements. There is evidence the number of avoidable complications may be underreported, that approximately 39% of in-hospital adverse events are surgical related, and that as many as 4,000 surgical never events (events which should not have occurred) happen in the US each year. The eventual goal of this research is to develop an automated detection system (ADS) of high- risk surgical states. The ADS will prevent surgical safety incidents before they occur through real-time monitoring and notification of appropriate operating room (OR) team members ahead- of-time if there is a looming risk. Thereby allowing the team to reconsider next steps and address the underlying issues, and hence reduce the rates of negative surgical outcomes. This project demonstrates the feasibility and merit of essential components for an ADS. Specifically, the surgical safety literature provides compelling evidence that surgical work-flow disruption (FD) sequences are informative indicators of error causation, therefore it is likely that a future ADS will model and monitor surgical state through tracking flow disruptions. Our current aims are to (1) finish implementation of the Research & Exploratory Analysis Driven Time-data Visualization (READ-TV) research tool; open-source software to visualize FD patterns and other longitudinal data. (2) Develop a stochastic model to predict whether high-risk, disruptive FD sequences will occur based on FD rates at earlier time points. (3) Link FD patterns and sequences with surgical outcomes by developing a text classifier to identify whether or not a surgical safety incident or near-miss occurred based on the associated EHR note. The classifier will be a deep learning model trained with tens of thousands of surgical EHR notes. The text analysis in the third aim will provide insight to FD types and sequences that are more error prone, thereby revealing the FD patterns that an ADS should warn an OR team to avoid. Additional benefits of this text analysis include a possible confirmation of the existence of incident underreporting. Upon completion of the 3 aims, we will have a computational foundation for an ADS: our research tool (aim 1: READ-TV visualization software) and analyses (aim 3: link flow disruptions to safety incidents through EHR note analysis) will advance interpretation of flow disruption (FD) sequences, and our stochastic models (aim 2: predict future surgical state from FD sequences) will prospectively predict error-prone states. This foundation can be extended in future projects through research in automatic transcription of flow disruptions, and the proper mode of alert delivery if the surgery is prone to enter an error-prone state. Surgery by nature is risky for the patient and will continue to be so for the foreseeable future despite technological advancements. The surgical safety literature provides compelling evidence that surgical work-flow disruption (FD) sequences are informative indicators of error causation, and we propose that an automated detection system (ADS) can detect if a surgery has an entered a high-risk state through monitoring of FD sequences, thereby alerting the OR team and preemptively preventing a safety incident. As the first steps for such a system: our research visualization tool (Aim 1) will advance interpretation and clustering of FD sequences, our text-based artificial intelligence models (Aim 3) will link FD patterns and surgery characteristics to safety incidents through computational analysis of over 150,000 surgical notes, and our stochastic models (Aim 2) will verify that a high-risk surgical state can be predicted ahead-of-time by monitoring disruption sequences.",Leveraging Data Science and Informatics in an Automated Detection System of Surgical Errors,10149122,F31LM013402,"['Address', 'Adverse event', 'Artificial Intelligence', 'Characteristics', 'Clinical', 'Code', 'Cognitive', 'Communication', 'Communities', 'Companions', 'Computer Analysis', 'Computer software', 'Custom', 'Data', 'Data Science', 'Detection', 'Electronic Health Record', 'Engineering', 'Ensure', 'Equipment', 'Etiology', 'Event', 'Foundations', 'Future', 'Genetic Transcription', 'Goals', 'Grant', 'Hospitals', 'Informatics', 'Information Systems', 'Lead', 'Link', 'Literature', 'Machine Learning', 'Manuals', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nature', 'Notification', 'Operating Rooms', 'Operative Surgical Procedures', 'Outcome', 'Patient-Focused Outcomes', 'Patients', 'Pattern', 'Prevalence', 'Procedures', 'Publishing', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Safety', 'Series', 'Source Code', 'Surgical Error', 'System', 'Technology', 'Testing', 'Text', 'Time', 'Training', 'Update', 'Vision', 'Visualization', 'Visualization software', 'Work', 'adverse outcome', 'base', 'data visualization', 'data warehouse', 'deep learning', 'demographics', 'detection platform', 'high risk', 'improved', 'insight', 'large datasets', 'member', 'novel', 'open source', 'operation', 'predictive modeling', 'pressure', 'prevent', 'prospective', 'real time monitoring', 'robot assistance', 'surgery outcome', 'surgical risk', 'text searching', 'tool']",NLM,MEDICAL UNIVERSITY OF SOUTH CAROLINA,F31,2021,43491
"Automating Delirium Identification and Risk Prediction in Electronic Health Records Abstract. Delirium, or acute confusional state, affects 30-40% of hospitalized older adults, with the added cost of care estimated to be up to $7 billion. Although originally conceptualized as a transient disorder, delirium is now recognized to have significant consequences, including increased risk of death, functional decline, and long-term cognitive impairment. As up to 75% cases are not recognized by providers, there is an urgent need for additional methods to identify delirium for clinical and research purposes, and to stratify patients based on delirium risk. In this proposal, we present a novel approach to the identification of delirium based on large-scale data mining (i.e., pattern recognition) algorithms using machine learning and natural language processing applied to electronic health record (EHR) data, which will automate chart-based determination of delirium status and risk prediction. We will combine these algorithms with data collected through our recently implemented Virtual Acute Care for Elders (ACE) quality improvement project, which institutes delirium screening once per shift by nursing staff for all individuals over age 65 admitted to the University of Alabama at Birmingham (UAB) Hospital. This unprece- dented volume of data will allow us to achieve the necessary sample sizes for effective training and validation of our data mining algorithms. Data mining algorithms that discover patterns of associations in data, rather than testing predetermined hypotheses, are well suited to application in large-scale algorithms for identification of delirium. Using our Virtual ACE and hospital EHR data, we will be able to evaluate more than 10,000 individual features (e.g., text words and phrases, laboratory and other diagnostic tests, concurrent medical conditions) as- sociated with delirium, which will be classified as risk factors for delirium, as signs, symptoms, and descriptors of delirium itself, and as complications and consequences of delirium, based on expert consensus. We will then use these features to develop rules for identification of delirium in the EHR, as well as risk prediction models that can be integrated into the EHR to provide individualized assessments of delirium risk. This study will lay the foundation for methods of automated delirium identification and risk prediction in healthcare settings that are unable to implement the screening by providers done in our Virtual ACE, as well as for large-scale epidemiological investigations of delirium using EHR data, expanding the current armamentarium for studying this common and debilitating disorder. Project Narrative. Delirium, or acute confusional state, affects up to 7 million hospitalized older adults annu- ally and is associated with long-term declines in cognition and function, but is not recognized by providers in up to 75% of cases. The growth of electronic health records offers a unique opportunity to improve recognition of delir- ium, as methods for identifying delirium based on chart review by clinicians have been developed but are time- and resource-intensive. In this secondary data analysis, we will examine methods for automating delirium recog- nition and risk prediction in electronic health records using machine learning and natural language processing computer algorithms, which in turn will lead to improved care for this serious but often overlooked disorder.",Automating Delirium Identification and Risk Prediction in Electronic Health Records,10091381,R01AG060993,"['Acute', 'Address', 'Adult', 'Affect', 'Agreement', 'Alabama', 'Algorithms', 'Ally', 'Assessment tool', 'Automation', 'Caring', 'Characteristics', 'Clinical Research', 'Cognition', 'Cognitive', 'Computational algorithm', 'Confusion', 'Consensus', 'Data', 'Data Analyses', 'Data Set', 'Delirium', 'Descriptor', 'Detection', 'Development', 'Diagnostic tests', 'Discipline of Nursing', 'Disease', 'Elderly', 'Electronic Health Record', 'Epidemiology', 'Foundations', 'Growth', 'Health system', 'Hospitals', 'Impaired cognition', 'Individual', 'Inpatients', 'Institutes', 'Institutionalization', 'Laboratories', 'Link', 'Logistics', 'Long-Term Care for Elderly', 'Machine Learning', 'Measurable', 'Medical', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Nurses', 'Nursing Staff', 'Operative Surgical Procedures', 'Patients', 'Pattern', 'Pattern Recognition', 'Persons', 'Prevention', 'Property', 'Provider', 'ROC Curve', 'Reference Standards', 'Research', 'Resources', 'Risk', 'Risk Factors', 'Sample Size', 'Sampling', 'Signs and Symptoms', 'Testing', 'Text', 'Time', 'Training', 'Universities', 'Validation', 'acute care', 'adverse outcome', 'base', 'care costs', 'confusion assessment method', 'data mining', 'epidemiology study', 'functional decline', 'functional disability', 'health care settings', 'high dimensionality', 'human old age (65+)', 'improved', 'instrument', 'interest', 'large scale data', 'model development', 'mortality risk', 'novel', 'novel strategies', 'patient stratification', 'phrases', 'prediction algorithm', 'programs', 'risk prediction', 'risk prediction model', 'screening', 'validation studies', 'virtual', 'ward']",NIA,UNIVERSITY OF ALABAMA AT BIRMINGHAM,R01,2021,376860
"Safety Promotion through Early Event Detection in the Elderly (SPEEDe) ABSTRACT Adverse events (AEs) – harm to patients that results from medical care – affect as many as 13.5% of hospitalized patients; half of these AEs are preventable and AEs particularly affect the elderly. AEs are notoriously difficult to measure accurately. A variety of paper and electronic trigger tools have been developed to identify AEs; however, their positive predictive value (PPV) is low, requiting subsequent, time-intensive manual chart review to accurately measure AEs. In the proposed project, we will use innovative, state-of-the-art machine interactive learning (IML) techniques to refine existing AE triggers, improving their accuracy substantially. We will also develop a novel AE Explorer to speed review of possible AEs, as well as an innovative package of predictive analytics tools and methods to measure and detect them. Our approach combines and compares expert-driven improvement with the most recent IML techniques to make triggers more accurate, with the ultimate goal of creating triggers that are accurate enough to stand in as proxies for actual measurement of harm. We call our approach Safety Promotion through Early Event Detection in the Elderly, or SPEEDe. Our team of accomplished machine learning, patient safety, risk management, AE detection, geriatric medicine and trigger tool experts will work together to carry out the specific aims of this project: (1) prototype and rapidly iterate a trigger review dashboard (the Adverse Event Explorer) using a user-centered design process, (2) develop and evaluate novel Interactive Machine Learning approaches for more efficient and accurate adverse event chart review and trigger refinement, and (3) Integrate Interactive Machine Learning into the Adverse Event Explorer and evaluate it prospectively in a clinical setting. PROJECT NARRATIVE Adverse events – harm to patients that results from medical care – are common and difficult to identify and measure using existing tools. Accurate real-time measures of adverse events would enable organizations to track harm over time, identify and prioritize areas for safety improvements, evaluate whether patient safety programs are effective, and communicate risks of harm to patients and caregivers. Through SPEEDe, we will develop an innovative machine- learning approach for accurately detecting adverse events in the elderly in real-time.",Safety Promotion through Early Event Detection in the Elderly (SPEEDe),10109965,R01AG062499,"['Active Learning', 'Adopted', 'Adverse event', 'Affect', 'Area', 'Benchmarking', 'Caregivers', 'Caring', 'Cessation of life', 'Clinical', 'Computer software', 'Detection', 'Elderly', 'Environment', 'Event', 'Feedback', 'Foundations', 'Frequencies', 'Geriatrics', 'Goals', 'Gold', 'Grant', 'Hospitals', 'Human', 'Human Resources', 'Incentives', 'Intuition', 'Learning', 'Machine Learning', 'Manuals', 'Measurement', 'Measures', 'Medical', 'Memory', 'Minority', 'Modeling', 'Paper', 'Patients', 'Performance', 'Personal Satisfaction', 'Policies', 'Predictive Analytics', 'Predictive Value', 'Process', 'Proxy', 'Reporting', 'Research', 'Resources', 'Risk', 'Risk Management', 'Safety', 'Sampling', 'Screening procedure', 'Speed', 'System', 'Techniques', 'Testing', 'Time', 'Training', 'United States', 'Woman', 'Work', 'advanced analytics', 'analytical method', 'analytical tool', 'base', 'biomedical informatics', 'cost', 'dashboard', 'detection platform', 'detector', 'forging', 'hands-on learning', 'health information technology', 'improved', 'innovation', 'iterative design', 'machine learning method', 'novel', 'open source', 'patient safety', 'prevent', 'programs', 'prospective', 'prototype', 'supervised learning', 'tool', 'user centered design']",NIA,VANDERBILT UNIVERSITY MEDICAL CENTER,R01,2021,661688
"Patient Safety Event Surveillance Using Machine Learning and Free Text Clinical Notes PROJECT SUMMARY/ABSTRACT The proposed project aims to make healthcare safer through collection of patient-centered outcomes as the input data to support a safety and improvement model of the Learning Health System (LHS). The project will accomplish these aims by leveraging existing machine learning methods to classify free text documents, such as clinician notes, for the presence or absence of specific events of interest. The project shares this focus with two long-term objectives. The first broad project goal is to collect important data to address knowledge gaps in the incidence and clinical epidemiology of 5 serious pediatric inpatient healthcare acquired conditions (HACs). These 5 HACs are: peripheral IV infiltrates, venous thromboembolisms (VTEs), pressure injuries, patient falls, and incidents involving harm to providers. The second goal is to evaluate a novel approach to routine patient safety event surveillance that is scalable, transferrable, adaptable to other conditions and settings, and with low cost of sustainable ongoing operation. The project has two specific aims to achieve these goals:  Aim 1: Implement enhanced surveillance for 5 pediatric HACs. Compare characteristics  of previously and newly identified cases. Describe high-risk populations.  Aim 2: Estimate completeness of existing systems. Evaluate effects of enhanced  surveillance on quality improvement activities; incidence of HACs; and cost to operate  system, including staff time and resources. The project team has developed a machine learning interface implemented in open license Windows software. The team has a lengthy track record making these methods accessible to clinicians and lay users in research, clinical operations, quality improvement, and injury prevention settings. The current project proposes an innovative application of these technologies, methods, and tools to the important problem of patient safety surveillance. An expected outcome of this project will be substantial advance in knowledge for each of the 5 pediatric HACs proposed for enhanced surveillance. Results will be reported in terms of existing data completeness and clinical epidemiology. Findings will directly address concerns over limitations of existing data sources and thereby drive patient safety improvement activities. An additional expected outcome will be the rigorous evaluation of a novel approach to patient safety surveillance. This will include analysis of the costs and benefits of enhanced surveillance with machine learning versus current approaches, and the cost-effectiveness of the approach compared to reliance on existing data, and external validation at a partner community hospital. PROJECT NARRATIVE This project addresses important challenges to reduce common sources of harm in pediatric healthcare, namely the “Healthcare-Acquired Conditions (HACs)” monitored by the National Solutions for Patient Safety quality improvement initiative. It uses a new approach to identify previously unreported safety events that affect hospitalized pediatric patients. The findings from these studies will identify high-risk patient populations and new approaches for quality improvement to reduce the frequency of these events of harm among hospitalized children.",Patient Safety Event Surveillance Using Machine Learning and Free Text Clinical Notes,10202727,R01HS026246,[' '],AHRQ,BOSTON CHILDREN'S HOSPITAL,R01,2021,396733
"Health Information Technology for Surveillance of Health Care-Associated Infections PROJECT SUMMARY/ABSTRACT Health care-associated infections (HAIs) affect one in every 20 hospitalized patients and account for $10 billion dollars in potentially preventable health care expenditures annually. Current efforts at detection of HAIs are limited to manual chart review which hinders the generalizability and scalability of HAI detection. My goal in seeking a Mentored Clinical Scientist Career Development Award is to acquire the necessary training, practical experience, and knowledge to develop a health services research career as a principal investigator focusing on leveraging novel health information technology (HIT) tools to improve the measurement of surgical health care quality, safety, and effectiveness. To continue my progress towards this goal, the objective of this project is to address the challenges of HAI detection by developing a robust and portable automated HAI surveillance toolkit. This toolkit will combine structured electronic health record (EHR) data with rich information locked in clinical notes using machine learning and natural language processing (NLP) to identify HAIs after surgical procedures. Our overall hypothesis is that combining structured variables from the EHR supplemented with NLP will improve our ability to identify HAIs after surgical procedures. To test the central hypothesis and accomplish the objectives for this application, I will pursue the following three specific aims: 1) Determine the EHR data elements indicative of postoperative HAIs and evaluate the performance of a novel HAI surveillance algorithm; 2) Identify the presence of postoperative SSIs from clinical notes using an automated portable NLP-based algorithm; 3) Apply user-centered design to create a high fidelity prototype of a surgical quality dashboard incorporating our HAI case detection methodology. This contribution is a significant first step in a continuum of research that utilizes the large amounts of data in the EHR combined with novel HIT methods to improve the measurement of surgical health-care quality, safety, and effectiveness. This approach is significant because the tools developed in this proposal have potential to serve as a prototype for identification and monitoring hospitals adverse events and could be replicated on a national scale. The proposed research is innovative in its approach using a combination of structured and unstructured data in the EHR along with novel machine learning and NLP tools to create a generalizable surveillance toolkit for the detection of HAIs. This proposal is responsive to the AHRQ Special Emphasis Notice (NOT-HS-13-011) specifically addressing the use of HIT to improve quality measurement. I have assembled a mentoring team who all internationally recognized experts with long and successful track records of funding and trainee mentorship. This project will provide the means to place me on a trajectory towards a health services research career focused on improving the measurement of surgical health-care quality, safety, and effectiveness using novel HIT tools. In summary, my previous training and experience, innovative research plan, high-quality training plan, first-rate mentorship team, and supportive research environment give me the highest likelihood of success to research independence with the proposed K08 award. PROJECT NARRATIVE/RELEVANCE TO PUBLIC HEALTH The proposed research and career development plan are relevant to public health because health care- associated infections (HAIs) affect about one in every 20 hospitalized patients and account for $30 billion dollars in potentially preventable health care expenditures annually. The objective of this project is to develop robust and portable automated surveillance toolkit that combines structured EHR data with rich information locked in clinical notes using natural language processing to identify HAIs after surgical procedures. The proposed research has the potential to serve as a prototype for identification and monitoring of numerous hospitals adverse events and could be replicated on a national scale.",Health Information Technology for Surveillance of Health Care-Associated Infections,10186798,K08HS025776,[' '],AHRQ,UNIVERSITY OF UTAH,K08,2021,160142
"Coupling Results Data from ClinicalTrials.gov and Bibliographic Databases to Accelerate Evidence Synthesis Project Summary Clinical trials are foundational to evidence-based medicine, but results reporting from trials is incomplete and frequently delayed. It is estimated that as many as half of clinical trials are not published and as many as half of published trials underreport or misreport outcomes. This type of results reporting distorts the evidence available to clinicians—particularly when it comes to assessing the safety of interventions like drugs and devices—and may place patients at unnecessary risk. There is a critical need for novel methods to identify and monitor drug safety data. Through the infrastructure provided by ClinicalTrials.gov, structured trial results (including safety findings) are now becoming available for an increasing number of trials in a comprehensive and timely fashion. However, access and use of these data in evidence synthesis tasks remain limited. ClinicalTrials.gov is the largest single registry for clinical studies worldwide and includes more than 260,000 registered studies. Of the 108,941 completed trials registered with the site, 20% have uploaded results data for a total of 7.85 million participants. Results data reported on ClinicalTrials.gov have the potential to fill gaps created by delays and biases in published articles and provide an earlier and more complete overview of available trial evidence. We propose to develop novel informatics approaches based on combinations of information retrieval and machine learning methods to facilitate access and analysis of trial results reported in this registry. Focusing on trials testing drug interventions in type 2 diabetes, obesity, and oncology, we perform this work in three specific aims: 1) Develop semi-automated trial screening for identifying and aggregating trials relevant to a clinical intervention; 2) Extract adverse event and safety outcomes data from results reported in the registry; and 3) Perform validation studies to assess detection of adverse events and performance of semi- automated meta-analyses of safety outcomes. Methods developed in this project will facilitate timely, broad- scale use of trial results reported on ClinicalTrials.gov in order to augment the availability of comprehensive and timely drug safety data. All methods will be made publicly available in order to support adverse event monitoring and systematic reviews of drug interventions. Project Narrative The availability of results from clinical trials is frequently incomplete or delayed, limiting the evidence available to clinicians making treatment decisions. When results on the safety of interventions, such as drugs, are not properly disseminated, patients may be exposed to harm. National policies require comprehensive and timely reporting of trial results in trial registries (e.g. ClinicalTrials.gov), representing a novel data type that could be used for drug safety surveillance. However, the use of these data has remained limited to date. We propose innovative informatics methods to enable access and analysis of this emerging data source in order to augment the availability of comprehensive and timely drug safety data.",Coupling Results Data from ClinicalTrials.gov and Bibliographic Databases to Accelerate Evidence Synthesis,10136717,R01LM012976,"['Adverse drug event', 'Adverse event', 'Bibliographic Databases', 'Bibliography', 'Clinical', 'Clinical Medicine', 'Clinical Research', 'Clinical Trials', 'Consumption', 'Coupling', 'Data', 'Data Reporting', 'Data Set', 'Data Sources', 'Databases', 'Detection', 'Devices', 'Drug Monitoring', 'Drug usage', 'Equilibrium', 'Evidence Based Medicine', 'Exposure to', 'Foundations', 'Goals', 'Health', 'Heterogeneity', 'Individual', 'Informatics', 'Information Retrieval', 'Infrastructure', 'International', 'Intervention', 'Learning', 'Link', 'Machine Learning', 'Manuals', 'Maps', 'Meta-Analysis', 'Methods', 'Monitor', 'Non-Insulin-Dependent Diabetes Mellitus', 'Obesity', 'Oncology', 'Outcome', 'Participant', 'Patients', 'Performance', 'Pharmaceutical Preparations', 'Policies', 'Procedures', 'Process', 'Public Health Informatics', 'Publishing', 'Records', 'Registries', 'Reporting', 'Research Personnel', 'Resources', 'Risk', 'Rofecoxib', 'Safety', 'Signal Transduction', 'Site', 'Standardization', 'Structure', 'Time', 'Unified Medical Language System', 'Validation', 'Work', 'adverse event monitoring', 'base', 'cluster trial', 'concept mapping', 'design', 'drug testing', 'innovation', 'machine learning method', 'medication safety', 'novel', 'rosiglitazone', 'safety outcomes', 'screening', 'supervised learning', 'systematic review', 'tool', 'treatment arm', 'trial design', 'validation studies', 'vector']",NLM,BOSTON CHILDREN'S HOSPITAL,R01,2021,328000
"Dynamic learning for post-vaccine event prediction using temporal information in VAERS Project Summary Vaccines have been one of the most successful public health interventions to date. They are, however, pharmaceutical products that carry risks. Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine- preventable illnesses. The CDC/FDA Vaccine Adverse Event Reporting System (VAERS) contains up to 30,000 reports per year over the past 25 years. VAERS reports include both structured data (e.g., vaccination date, first onset date, age, and gender) and unstructured narratives that often provide detailed clinical information about the clinical events and the temporal relationship of the series of event occurrences post vaccination. The structured data only provide one onsite date whereas temporal information of the sequence of events post vaccination is contained in the unstructured narratives. Current status –While structured data in the VAERS are widely used, the narratives are generally ignored because of the challenges inherent in working with unstructured data. Without these narratives, potentially valuable information is lost. Goals - In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Specifically, built upon the state-of-art ontology and natural language processing technologies, we will develop and validate a Temporal Information Modeling, Extraction and Reasoning system for Vaccine data (TIMER-V), which will automatically extract post-vaccination events and their temporal relationships from VAERS reports, semantically infer temporal relations, and integrate the exacted unstructured data with the structured data. Furthermore, we will provide and maintain a publicly available data access interface to query the new integrated data repository, which will facilitate vaccine safety research, casual inference, and other temporal related discovery. We will also develop and validate models to predict severe AEs using the co-occurrence or temporal patterns of the series of AEs post vaccination. To the best of our knowledge, this is the first attempt to make use of the unstructured narratives in the VAERS reports to facilitate the temporal related discovery to a broad community of investigators in pharmacology, pharmacoepidemiology, vaccine safety research, among others. Project Narrative Effective analyses of post-vaccination adverse events (AEs) is vital to assuring the safety of vaccines, a key public health intervention for reducing the frequency of vaccine-preventable illnesses. In response to the FOA, PA-15-312, this proposed project focuses on the specific objective on “creation/evaluation of statistical methodologies for analyzing data on vaccine safety, including data available from existing data sources such as passive reporting systems or healthcare databases”. Currently the FDA/CDC Vaccine Adverse Event Reporting System (VAERS) only includes one onsite date in its database. The textual narratives in the reports are generally ignored primarily due to their unstructured nature. These narratives, however, contain more detailed information about the series of events that happened after vaccination, which could be valuable for more informed clinical studies. We propose to develop a novel framework to extract and accurately interpret the temporal information contained in the narratives through informatics approaches, and to develop prediction models for risk of severe AEs. Our new methods, their applications to VAERS database, and their dissemination will facilitate the entire research network for pursuing temporal related discovery with high methodological rigor.",Dynamic learning for post-vaccine event prediction using temporal information in VAERS,10097968,R01AI130460,"['Abbreviations', 'Address', 'Adverse event', 'Age', 'Centers for Disease Control and Prevention (U.S.)', 'Clinic', 'Clinical', 'Clinical Research', 'Communities', 'Data', 'Data Analyses', 'Data Sources', 'Database Management Systems', 'Databases', 'Development', 'Evaluation', 'Event', 'Frequencies', 'Funding', 'Gender', 'Goals', 'Gold', 'Healthcare', 'Individual', 'Informatics', 'Information Retrieval', 'Learning', 'Manuals', 'Measles-Mumps-Rubella Vaccine', 'Methodology', 'Methods', 'Modeling', 'Natural Language Processing', 'Nature', 'Ontology', 'Patients', 'Pattern', 'Performance', 'Pharmacoepidemiology', 'Pharmacologic Substance', 'Pharmacology', 'Process', 'Reporter', 'Reporting', 'Research', 'Research Personnel', 'Risk', 'Semantics', 'Series', 'Serious Adverse Event', 'Severities', 'Signal Transduction', 'Source', 'System', 'Technology', 'Testing', 'Time', 'Vaccination', 'Vaccines', 'Validation', 'base', 'data access', 'data repository', 'detection method', 'flexibility', 'improved', 'influenza virus vaccine', 'information model', 'novel', 'predictive modeling', 'public health intervention', 'response', 'risk prediction', 'risk prediction model', 'structured data', 'unstructured data', 'vaccine safety']",NIAID,UNIVERSITY OF TEXAS HLTH SCI CTR HOUSTON,R01,2021,669017
"Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics ABSTRACT Total joint arthroplasty (TJA) is the most common and fastest growing surgical procedure in the nation. Despite the high procedure volume, the evidence base for TJA procedures and associated interventions are limited. This is mainly due to lack of high quality data sources and the logistical difficulties associated with manually extracting TJA information from the unstructured text of the Electronic Health Records (EHR). Meanwhile, the rapid adoption of EHR and the advances in health information technology offer the potential to transform unstructured EHR notes into structured, codified format that can then be analyzed and shared with local and national arthroplasty registries and other agencies. We therefore propose to leverage unique data resources and natural language processing (NLP) technologies to build an informatics infrastructure for automated EHR data extraction and analysis. We will (1) develop a high performance, externally validated and user centric NLP- enabled algorithm for extraction of complex TJA-specific data elements from the structured and unstructured text of the EHR, (2) validate the algorithm externally in multiple EHR platforms and hospital settings, and (3) conduct a demonstration project focused on prediction of prosthetic joint infections using data elements collected by the NLP-enabled algorithm. Our overarching goal is to develop valid, open source and portable NLP-enabled data collection and risk prediction tools and disseminate them widely to hospitals participating in regional and national TJA registries. This research is significant as it leverages strong data resources and expertise to tackle the pressing need for high quality data and accurate prediction models in TJA. Automated data collection and processing capabilities will lead to an upsurge in secondary use of EHR to advance scientific knowledge on TJA risk factors, healthcare quality and patient outcomes. Accurate prediction of high risk patients for prosthetic joint infections will guide prevention and treatment decisions resulting in significant health benefits to TJA patients. The research is innovative because TJA-specific bioinformatics technology will shift TJA research from current under-powered, single-center studies to large, multi-center registry-based observational studies and clinical trials. Our deliverables have the potential to exert a sustained downstream effect on future TJA research, practice and policy. PUBLIC HEALTH RELEVANCE Lack of high quality data is a critical barrier to progress in total joint arthroplasty (TJA) research. We will utilize health information technology to automate extraction of rich TJA information from the electronic health records, and develop a robust risk prediction score for prosthetic joint infections, a devastating and yet preventable complication of TJA. Widespread adoption of these tools will enhance data collection capabilities and enable affordable large scale studies for practice improvements through secondary use of real-world data. Accurate prediction of post- operative infection risk among TJA candidates will guide individualized preventive strategies for modifiable risk factors, thereby reducing the burden of prosthetic joint infections in TJA patients.",Enhance Arthroplasty Research through Electronic Health Records and Nlp-Enabled Informatics,10103780,R01AR073147,"['Adoption', 'Algorithms', 'American', 'Bioinformatics', 'Clinic', 'Clinical', 'Clinical Data', 'Clinical Trials', 'Complex', 'Complication', 'Data', 'Data Collection', 'Data Element', 'Data Set', 'Data Sources', 'Decision Making', 'Development', 'Devices', 'Documentation', 'Electronic Health Record', 'Epidemic', 'Evidence based practice', 'Future', 'Goals', 'Gold', 'Guide prevention', 'Health Benefit', 'Hospitals', 'Individual', 'Informatics', 'Institution', 'Intervention', 'Joint Prosthesis', 'Knowledge', 'Logistics', 'Manuals', 'Marketing', 'Medicare', 'Methods', 'Modeling', 'Monitor', 'Natural Language Processing', 'Observational Study', 'Operative Surgical Procedures', 'Patient-Focused Outcomes', 'Patients', 'Performance', 'Policies', 'Postoperative Period', 'Prevention', 'Prevention strategy', 'Procedures', 'Provider', 'Publishing', 'Registries', 'Replacement Arthroplasty', 'Research', 'Risk', 'Risk Factors', 'Safety', 'Scientific Advances and Accomplishments', 'Source', 'Structure', 'Techniques', 'Technology', 'Testing', 'Text', 'Time', 'United States', 'age group', 'base', 'computerized data processing', 'cost', 'data access', 'data resource', 'electronic data', 'electronic structure', 'epidemiology study', 'evidence base', 'health care quality', 'health information technology', 'high risk', 'improved', 'individual patient', 'infection risk', 'informatics infrastructure', 'informatics tool', 'innovation', 'joint infection', 'modifiable risk', 'novel', 'open source', 'outcome prediction', 'patient population', 'portability', 'pragmatic trial', 'predictive modeling', 'prototype', 'public health relevance', 'risk prediction', 'risk prediction model', 'structured data', 'surgery outcome', 'tool', 'willingness']",NIAMS,MAYO CLINIC ROCHESTER,R01,2021,574852
"Preventing medication dispensing errors in pharmacy practice with interpretable machine intelligence PROJECT SUMMARY Medical errors are the 3rd leading cause of death in the United States behind cancer and cardiovascular disease. The largest proportion of medical errors involve medications. Medication errors result in 3 million outpatient medical appointments, 1 million emergency department visits, and 125,000 hospital admissions each year. Astoundingly, over 4 billion prescriptions are dispensed every year in the United States alone. Although dispensing error rates are generally low at 0.06%, the sheer volume of dispensed medications translates to 2.4 million incorrectly dispensed medications each year. In the pharmacy, dispensing errors arise when pharmacists do not detect that the medication filled inside a prescription vial is different from the medication ordered on the prescription's label. These dispensing errors can result in patient harm, added strain on the healthcare system, and costly legal action against the pharmacy. Machine intelligence (MI) can be employed to assist in the verification process to help avoid dangerous and costly pharmacy dispensing errors.4–6 However for the human-MI partnership to function optimally, the MI should be capable of conveying accurate information that encourages providers to make sound cognitive decisions such that optimal trust is maintained, and temporal and cognitive demand is reduced. Imperative to this goal is to design MI from which interpretable information can be extracted, convey this information in an effective manner and calibrate user's trust in MI as either over-trust or under-trust can lead to near miss and incident errors. This proposed project will further our knowledge for designing interpretable MI outputs and inform the development of MI models that encourage pharmacy staff to make sound clinical decisions that lead to better patient outcomes while improving work-life at lower costs of care. This study develops interpretable MI methods in the context of medication images classification and designs effective MI advice and reasoning that lead to lower cognitive demand and increased trust in the MI. Our hypothesis is that interpretable MI will lead to improved work performance and more calibrated trust compared to uninterpretable M. The objectives of this proposal are to: 1) design interpretable machine intelligence to double-check dispensed medication images in real-time; 2) evaluate changes in pharmacy staff trust due to the long-term use of interpretable machine intelligence; and 3) determine the effect of interpretable machine intelligence on long-term pharmacy staff work performance. PROJECT NARRATIVE Medical errors are the 3rd leading cause of death in the United States behind cancer and cardiovascular disease and the largest proportion of medical errors involve medications. These dispensing errors occur approximately 2,400,000 times every year in the United States alone and can result in patient safety issues and add unnecessarily to the already strained healthcare system.The objectives of this proposal are to: 1) design interpretable machine intelligence to double-check dispensed medication images in real-time; 2) evaluate changes in pharmacy staff trust due to the long-term use of interpretable machine intelligence; and 3) determine the effect of interpretable machine intelligence on long-term pharmacy staff work performance.",Preventing medication dispensing errors in pharmacy practice with interpretable machine intelligence,10183536,R01LM013624,"['Artificial Intelligence', 'Cardiovascular Diseases', 'Cause of Death', 'Classification', 'Clinical', 'Cognitive', 'Dangerousness', 'Data', 'Decision Making', 'Detection', 'Development', 'Emergency department visit', 'Evaluation', 'Goals', 'Healthcare', 'Healthcare Systems', 'Hospitalization', 'Human', 'Image', 'Knowledge', 'Label', 'Lead', 'Legal', 'Life', 'Malignant Neoplasms', 'Measures', 'Medical Errors', 'Medication Errors', 'Methods', 'Modeling', 'Outpatients', 'Output', 'Patient-Focused Outcomes', 'Patients', 'Performance at work', 'Pharmaceutical Preparations', 'Pharmacists', 'Pharmacy facility', 'Process', 'Provider', 'Research', 'Stream', 'System', 'Testing', 'Time', 'Translating', 'Trust', 'Uncertainty', 'United States', 'Vial device', 'Work', 'base', 'care costs', 'cost', 'deep learning', 'design', 'experience', 'experimental study', 'improved', 'insight', 'medical appointment', 'patient safety', 'prevent', 'sound', 'support tools', 'tool', 'visual tracking']",NLM,UNIVERSITY OF MICHIGAN AT ANN ARBOR,R01,2021,288814
"Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project PROJECT SUMMARY The National Institutes on Aging (NIA) has recommended strengthening research infrastructures to address future aging research questions (2016 Data Infrastructure Review Committee Report and PAR-16-367). In particular, they recommend: 1) integrating biological data into larger population-based studies; 2) increasing use of electronic health record (EHR) data and linking to medical care claims data; and 3) developing new approaches to collecting data to answer important scientific questions about mechanisms of aging. The Rochester Epidemiology Project (REP; NIA R01 AG034676) is a unique infrastructure for studies of aging, because the REP collects longitudinal EHR data on all health conditions that come to medical attention for a large, Midwestern population. Therefore, the REP allows investigators to study all age-related diseases and outcomes. However, the REP has three significant gaps. First, the REP does not include biospecimens. Second, the REP is missing health care delivered outside of the health care institutions that partner with the REP, and it does not include information on filled prescriptions. Third, a significant proportion of EHR data is difficult to access due to two factors: 1) the full text of the EHRs includes extensive clinical notes about aging outcomes and geriatric syndromes, but these notes are not routinely coded for billing, and can only be accessed through laborious manual review; and 2) the REP health care partners use three different EHR systems, making it difficult to apply electronic data extraction tools across all partners. To address these three gaps, we will develop an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to create a new, comprehensive research infrastructure (“Bio-REP”) to support aging research. In the R21 phase, we will develop a comprehensive research infrastructure that combines the REP data with Mayo Clinic Biobank biospecimens, medical claims data from the Centers for Medicare and Medicaid Services (CMS; Aim 1), and geriatric syndrome data that are included in the unstructured EHR clinical notes using Natural Language Processing techniques (NLP; Aim 2). In the R33 phase, we will deploy NLP algorithms developed in Aim 2 in the clinical notes from two additional EHR systems (Aim 3), and we will conduct two demonstration projects. First, we will measure associations between novel aging-related biomarkers and aging-related outcomes (Aim 4). Second, we will determine whether two common medications that are hypothesized to impact aging (metformin and angiotensin receptor blockers) modify associations between aging biomarkers and aging outcomes (Aim 5). The new, robust Bio-REP infrastructure will support a wide range of efficient, cost-effective observational studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population. PROJECT NARRATIVE We will establish an interdisciplinary collaboration across experts in aging research, epidemiologic methods, biobanking, and medical informatics to develop and test a new, comprehensive research infrastructure (“Bio- REP”) to support aging research. The Bio-REP will support efficient, cost-effective studies to characterize associations between aging-related biomarkers and specific diseases, geriatric syndromes, and drug utilization. Such studies are urgently needed to design effective clinical trials to improve the health span of the aging population.",Interdisciplinary Infrastructure for Aging Research: Rochester Epidemiology Project,10224079,R33AG058738,"['Address', 'Age-Years', 'Aging', 'Agreement', 'Algorithms', 'Angiotensin Receptor', 'Area', 'Benchmarking', 'Biological', 'Biological Markers', 'Caring', 'Ceramides', 'Clinic', 'Clinical', 'Clinical Trials', 'Code', 'Data', 'Delirium', 'Diagnosis', 'Diagnostic Services', 'Disease', 'Disease Outcome', 'Drug Utilization', 'Elderly', 'Electronic Health Record', 'Enrollment', 'Epidemiologic Methods', 'Epidemiology', 'Future', 'Grant', 'Health', 'Healthcare', 'Infrastructure', 'Institution', 'Link', 'Manuals', 'Measures', 'Medical', 'Medical Informatics', 'Medical Records', 'Metformin', 'National Institute on Aging', 'Natural Language Processing', 'Observational Study', 'Outcome', 'Persons', 'Pharmaceutical Preparations', 'Phase', 'Phenotype', 'Polypharmacy', 'Population', 'Population Study', 'Proteins', 'Recommendation', 'Reporting', 'Research', 'Research Infrastructure', 'Research Personnel', 'Resources', 'Review Committee', 'Structure', 'Syndrome', 'System', 'Techniques', 'Testing', 'Text', 'Time', 'United States Centers for Medicare and Medicaid Services', 'age related', 'aging population', 'biobank', 'cost effective', 'data infrastructure', 'design', 'electronic data', 'falls', 'healthspan', 'improved', 'interdisciplinary collaboration', 'medical attention', 'novel', 'novel marker', 'novel strategies', 'senescence', 'tool']",NIA,MAYO CLINIC ROCHESTER,R33,2021,792718
