{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8258f090-a368-430b-b051-3902995fbfde",
   "metadata": {},
   "source": [
    "# Fisher Exact Test for Independence\n",
    "\n",
    "Fisher exact test is a more precise generalization of the Chi-Sq test that makes fewer assumptions, but is less \"famous\" because it is only made possible with computational power. Basically, Chi-Sq makes some normality assumptions (that only hold with \"large\" numbers of observations in every cell - often interpreted to mean every cell must have more than 5 expected observations in each cell). This normality assumption allows it to analytically obtain a p-value for any $n * m$ contigency table. However, in this case, there are multiple cells where the expected observations are less than 5.\n",
    "\n",
    "Instead of relying on a normality assumption, Fisher's Exact Test is similar to the technique I used in the interrater_agreement notebook. Based on the null hypothesis (that the variables `category` and `funding_source`\n",
    "are independent), it generates some large number (`n_simulations`) of random contigency tables. Then, it counts the proportion of these simulations that are as extreme or more extreme than the observed contigency table.\n",
    "\n",
    "Note: This notebook is written in Jupyter. However, the scipy implementation of Fisher's Exact Test is only for $2*2$ contigency tables, so I'm using rpy2 to port R code into Python. You will need to have R installed (and the `stats` package) to run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64f3297e-a36c-43fa-8b36-d44a2c759e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import itertools\n",
    "import rpy2.robjects.numpy2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "stats = importr('stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "65c744e8-fee5-4fc2-aa92-276f8344aa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 277   15   28    9   37    0]\n",
      " [ 777   62   88    8  118   26]\n",
      " [ 982  148   52   32   80   19]\n",
      " [ 412   42   34   12   60    0]\n",
      " [ 907   54   43    0  104    6]\n",
      " [1592  218   84   42  308    9]\n",
      " [ 872  122   59   34  154   30]\n",
      " [ 120    4    3    0   18    0]\n",
      " [ 167   20   24   14   10   21]]\n"
     ]
    }
   ],
   "source": [
    "cat_data = pd.read_csv(\"categories by mechanism.csv\") #TOCHANGE\n",
    "\n",
    "categories = cat_data.iloc[:, 0].tolist()\n",
    "grant_types = cat_data.columns[1:]\n",
    "cont_table = np.asarray(cat_data.iloc[:, 1:cat_data.shape[1]])\n",
    "\n",
    "cat_pairwise = list(itertools.combinations(range(0, len(categories)), 2))\n",
    "\n",
    "print(cont_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "089768fc-6362-4ce6-acd9-2189526a8b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value for #R01 vs Not is: [9.9999e-06]\n",
      "P-value for #U01 vs Not is: [9.9999e-06]\n",
      "P-value for #R44 vs Not is: [9.9999e-06]\n",
      "P-value for #U24 vs Not is: [9.9999e-06]\n",
      "P-value for #R21 vs Not is: [9.9999e-06]\n",
      "P-value for #U54 vs Not is: [9.9999e-06]\n"
     ]
    }
   ],
   "source": [
    "n_simulations = 100000 #TOCHANGE higher n_simulations leads to more accurate results - 100,000 is probably sufficient, but can do 1,000,000 if it is \"final\" data\n",
    "alpha = 0.05 #TOCHANGE 0.05 is a good default for upper range of p-value\n",
    "\n",
    "grant_cont_tables = []\n",
    "for i in range(0, len(grant_types)):\n",
    "    is_grant_i = cont_table[:, i]\n",
    "    not_grant_i = np.delete(cont_table, i, axis = 1).sum(axis = 1)\n",
    "    \n",
    "    bin_cont_table = np.column_stack((is_grant_i, not_grant_i))\n",
    "    \n",
    "    grant_type_p = stats.fisher_test(bin_cont_table, \n",
    "                        simulate_p_value = True,\n",
    "                        B = n_simulations)[0]\n",
    "    \n",
    "    grant_cont_tables.append(bin_cont_table)\n",
    "    \n",
    "    print(\"P-value for \" + grant_types[i] + \" vs Not is: \" + str(grant_type_p))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "29419c96-80de-4de1-b2ef-6ec588effea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "grant_col = []\n",
    "cat1_col = []\n",
    "cat2_col = []\n",
    "pval_col = []\n",
    "sig_posthoc = []\n",
    "cat1_prop = []\n",
    "cat2_prop = []\n",
    "\n",
    "for grant_index in range(0, len(grant_cont_tables)):\n",
    "    bin_cont_table = grant_cont_tables[grant_index]\n",
    "    \n",
    "    for pairwise_index in range(0, len(cat_pairwise)):\n",
    "        comparison = cat_pairwise[pairwise_index]\n",
    "        \n",
    "        pairwise_cont_table = bin_cont_table[comparison, :]\n",
    "        cat_props = pairwise_cont_table[:, 0] / pairwise_cont_table.sum(axis = 1)\n",
    "        category_1 = categories[comparison[0]]\n",
    "        category_2 = categories[comparison[1]]\n",
    "\n",
    "        pairwise_p = stats.fisher_test(pairwise_cont_table, \n",
    "                        simulate_p_value = True,\n",
    "                        B = n_simulations)[0]\n",
    "        bonf_sig = pairwise_p < alpha / len(cat_pairwise)\n",
    "\n",
    "        grant_col.append(grant_types[grant_index])\n",
    "        cat1_col.append(category_1)\n",
    "        cat2_col.append(category_2)\n",
    "        pval_col.append(pairwise_p)\n",
    "        sig_posthoc.append(bonf_sig)\n",
    "        cat1_prop.append(cat_props[0])\n",
    "        cat2_prop.append(cat_props[1])\n",
    "        \n",
    "pairwise_fishers = pd.DataFrame({\n",
    "    \"grant_type\" : grant_col,\n",
    "    \"category_1\" : cat1_col,\n",
    "    \"category_2\" : cat2_col,\n",
    "    \"uncorrected_pvalues\" : pval_col,\n",
    "    \"sig_post_correction\" : sig_posthoc,\n",
    "    \"category_1_prop\" : cat1_prop,\n",
    "    \"category_2_prop\" : cat2_prop\n",
    "},\n",
    "    index = list(range(len(grant_col))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "88ddafb3-c0c1-4e1a-bb54-706bb618249d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairwise_fishers\n",
    "pairwise_fishers.to_csv(\"pairwise_fishers.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c81940-238a-4cac-947e-5f28242445fc",
   "metadata": {},
   "source": [
    "Assuming this is actual data, a number of the pairwise comparisons have significant p-values at alpha = 0.05 even after correcting for multiple comparisons. These pairwise comparisons have `sig_post_correction` of `True`. Fisher's Exact Test for 2x2 contigency table can be interpreted as a binomial test, which I think has a more intuitive interpretation that a Chi-square test of Independence.\n",
    "\n",
    "An example interpretation for row 11 is: \"A higher proportion of successful grant submissions in the Human behavior and interaction category were awarded R01s when compared to those in the Data, model, and device types category.\"\n",
    "\n",
    "Note that the `category_1` and `category_2` columns are interchangeable. For example, if you want to find all pairwise comparisons involving the category Data, model, and device types, you would need to find all rows such that that category is in either `category_1` or `category_2`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
